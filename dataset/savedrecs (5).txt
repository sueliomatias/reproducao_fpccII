PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
C	Zhu, JR; Kumaran, R; Xu, CY; Höllerer, T		Bruder, G; Olivier, AH; Cunningham, A; Peng, EY; Grubert, J; Williams, I		Zhu, Jiarui; Kumaran, Radha; Xu, Chengyuan; Hollerer, Tobias			Free-form Conversation with Human and Symbolic Avatars in Mixed Reality	2023 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, ISMAR	International Symposium on Mixed and Augmented Reality		English	Proceedings Paper	22nd IEEE International Symposium on Mixed and Augmented Reality (ISMAR)	OCT 16-20, 2023	Sydney, AUSTRALIA	IEEE, IEEE Comp Soc, IEEE VGTC, UNSW Sydney, Monash Univ, Monash Informat Technol, CSIRO DATA 61, Autodesk, Qualcomm, Niantic, UNSW, AI Inst, Univ S Australia, Australian Res Ctr Interact & Virtual Environm		Artificial intelligence (AI); large language models (LLMs); mixed reality; Human-centered computing; Empirical studies in HCI; Computing methodologies; Mixed / augmented reality Computing methodologies; Virtual reality	PERCEPTION; EMBODIMENT; APPEARANCE; BODY	The integration of large language models and mixed reality technologies has enabled users to engage in free-form conversations with virtual agents across different "realities". However, if and how the agent's visual representation, especially when combined with mixed reality environments, will affect the conversation content or user experience is not yet fully understood. In this work, we design and conduct a user study involving two types of visual representations (a human avatar and a symbolic avatar) and two mixed reality environments (virtual reality and augmented reality), facilitating a free-form conversation experience with GPT-3 powered agents. We found evidence that the use of virtual or augmented realities can influence conversation content. Users chatting with avatars in virtual reality made significantly more references to the location or the space, suggesting they tended to perceive conversations as occurring in the agent's space, whereas the physical AR environment was perhaps more perceived as the user's space. Conversations with the human avatar improve user recall of the conversation, even though there is no evidence of increased information extracted during the conversation. These observations and our analysis of post-study questionnaires suggest that human avatars can positively impact user memory and experience. We hope our findings and the open-source implementation will help facilitate future research on free-form conversational agents in mixed reality.	[Zhu, Jiarui; Kumaran, Radha; Xu, Chengyuan; Hollerer, Tobias] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA	University of California System; University of California Santa Barbara	Zhu, JR (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.	jiarui_zhu@ucsb.edu; rkumaran@ucsb.edu; cxu@ucsb.edu; holl@cs.ucsb.edu	Zhu, Jiarui/KGL-5631-2024	Zhu, Jiarui/0009-0007-1926-5956	ONR [N00014-23-1-2118]	ONR(United States Department of DefenseUnited States NavyOffice of Naval Research)	This work was supported in part by ONR grant N00014-23-1-2118.	Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; [Anonymous], 2015, P 16 ANN M SPEC INT, DOI DOI 10.18653/V1/W15-4640; Babu S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P215; Bordes A., 2017, Learning end -to -end goal -oriented dialog; Brown T., 2020, P 34 INT C NEUR INF, V33, P1877; Chang Z, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1194313; CORBIN J, 1990, Z SOZIOL, V19, P418, DOI 10.1007/BF00988593; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077; Ghoshal Moinak, 2022, 2022 IEEE Conference on Games (CoG), P594, DOI 10.1109/CoG51982.2022.9893708; Hassan S. Z., P 2 WORKSH GAM SYST, P9; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Kim K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P529, DOI [10.1109/VR46266.2020.1581084624004, 10.1109/VR46266.2020.00-30]; Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039; Li Jiwei, 2016, NAACL; Miller JB, 1996, MEMORY, V4, P615, DOI 10.1080/741940999; Miller R.G., 1997, Beyond ANOVA: Basics of Applied Statistics, DOI DOI 10.1201/B15236; Moore N, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/38669; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036; Norouzi N., 2020, ICAT-EGVE; Ouyang L., 2022, NEURIPS; Pakanen M, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100457; Pejsa T, 2017, LECT NOTES ARTIF INT, V10498, P347, DOI 10.1007/978-3-319-67401-8_45; Poppenk J, 2008, HIPPOCAMPUS, V18, P909, DOI 10.1002/hipo.20453; Qu C, 2013, VIRTUAL REAL-LONDON, V17, P307, DOI 10.1007/s10055-013-0231-z; Quandt L, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418042; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P373, DOI 10.1145/2766462.2767738; Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074; Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863; Sordoni A., 2015, P C N AM CHAPT ASS C, P196, DOI DOI 10.3115/V1/N15-1020; Stuart J, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.864676; Stuart J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P455, DOI 10.1109/VR51125.2022.00065; Sutskever I, 2014, ADV NEUR IN, V27; Tang A., 2004, Comparing Differences in Presence during Social Interaction in Augmented Reality versus Virtual Reality Environments: An Exploratory Study; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629; Wolf E, 2022, INT SYM MIX AUGMENT, P489, DOI 10.1109/ISMAR55827.2022.00065; Yan R, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/2911451.2911542; You C, 2022, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2022, DOI 10.1145/3514197.3549686; Zalake M, 2021, PROCEEDINGS OF THE 21ST ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA), P216, DOI 10.1145/3472306.3478345; Zalake M, 2021, INT J HUM-COMPUT ST, V156, DOI 10.1016/j.ijhcs.2021.102708; Zalake M, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P329, DOI 10.1145/3267851.3267863; Zho XY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1118	48	0	0	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1554-7868		979-8-3503-2838-7	INT SYM MIX AUGMENT			2023							751	760		10.1109/ISMAR59233.2023.00090	http://dx.doi.org/10.1109/ISMAR59233.2023.00090			10	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2OX					2024-07-03	WOS:001123174400077
C	Rocchietti, G; Frieder, O; Muntean, CI; Nardini, FM; Perego, R			IEEE	Rocchietti, Guido; Frieder, Ophir; Muntean, Cristina Ioana; Nardini, Franco Maria; Perego, Raffaele			Commonsense injection in Conversational Systems: An adaptable framework for query expansion.	2023 IEEE INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT			English	Proceedings Paper	22nd IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	OCT 26-29, 2023	Venice, ITALY	Inst Elect & Elect Engineers, IEEE Comp Soc, Web Intelligence Consortium, Ca Foscari Univ Venice, IOS Press		conversational systems; query expansion; commonsense knowledge; KBs; information retrieval		Recent advancements in conversational agents are leading a paradigm shift in how people search for their information needs, from text queries to entire spoken conversations. This paradigm shift poses a new challenge: a single question may lack the context driven by the entire conversation. We propose and evaluate a framework to deal with multi-turn conversations with the injection of commonsense knowledge. Specifically, we propose a novel approach for conversational search that uses pre-trained large language models and commonsense knowledge bases to enrich queries with relevant concepts. Our framework comprises a generator of candidate concepts related to the context of the conversation and a selector for deciding which candidate concept to add to the current utterance to improve retrieval effectiveness. We use the TREC CAsT datasets and ConceptNet to show that our framework improves retrieval performance by up to 82% in terms of Recall@200 and up to 154% in terms of NDCG@3 as compared to the performance achieved by the original utterances in the conversations.	[Rocchietti, Guido] Univ Pisa, ISTI, CNR, Pisa, Italy; [Frieder, Ophir] Georgetown Univ, Washington, DC USA; [Muntean, Cristina Ioana; Nardini, Franco Maria; Perego, Raffaele] ISTI CNR, Pisa, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); University of Pisa; Georgetown University; Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)	Rocchietti, G (corresponding author), Univ Pisa, ISTI, CNR, Pisa, Italy.	guido.rocchietti@isti.cnr.it; ophir@ir.cs.georgetown.edu; cristinaioana.muntean@isti.cnr.it; francomaria.nardini@isti.cnr.it; raffaele.perego@isti.cnr.it	Perego, Raffaele/O-5821-2015	Perego, Raffaele/0000-0001-7189-4724	European Union (EU) under the NextGeneration EU programme [PE00000013]; EU's Horizon Europe research and innovation programme EFRA [101093026]; Horizon Europe - Pillar II [101093026] Funding Source: Horizon Europe - Pillar II	European Union (EU) under the NextGeneration EU programme(European Union (EU)Marie Curie Actions); EU's Horizon Europe research and innovation programme EFRA; Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	Funding for this research has been provided by: PNRR - M4C2 - Investimento 1.3, Partenariato Esteso PE00000013 - "FAIR - Future Artificial Intelligence Research" Spoke 1 "Human-centered AI" funded by the European Union (EU) under the NextGeneration EU programme; the EU's Horizon Europe research and innovation programme EFRA (Grant Agreement Number 101093026). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the EU or European Commission-EU. Neither the EU nor the granting authority can be held responsible for them.	Aliannejadi M, 2020, CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P33, DOI 10.1145/3343413.3377968; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dietz L., 2017, P TEXT RETRIEVAL C T, P13; Galimzhanova E., 2023, IEEEWIC INT C WEB IN; Hao J., 2022, EMNLP 2022; Ishii E., 2022, Integrating question rewriting in conversational question answering: A reinforcement learning approach, P12; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Jin D., 2022, Improving bot response contradiction detection via utterance rewriting, P10; Lin SC, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3446426; Liu H., 2021, arXiv; Macdonald C, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4526, DOI 10.1145/3459637.3482013; Mele I, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2057, DOI 10.1145/3397271.3401268; Mele I, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102682; Nguyen T., CoCo@ NIPs; OpenAI, 2023, GPT-4 Technical Report; Petroni F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2523; Pradeep R, 2021, Arxiv, DOI arXiv:2101.05667; Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232; Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028; Si SZ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4839; Song SY, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P6, DOI 10.1145/3366424.3382671; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Su H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P22; Vakulenko S, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P355, DOI 10.1145/3437963.3441748; Voskarides N, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P921, DOI 10.1145/3397271.3401130; Xin J., 2021, P 20 CHINESE NATL C, P976; Yu S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1933, DOI 10.1145/3397271.3401323	27	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0918-8				2023							48	55		10.1109/WI-IAT59888.2023.00013	http://dx.doi.org/10.1109/WI-IAT59888.2023.00013			8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3LB					2024-07-03	WOS:001139644800007
J	Ortiz-Barajas, JG; Bel-Enguix, G; Gómez-Adorno, H				Ortiz-Barajas, Jesus-German; Bel-Enguix, Gemma; Gomez-Adorno, Helena			Sentence-CROBI: A Simple Cross-Bi-Encoder-Based Neural Network Architecture for Paraphrase Identification	MATHEMATICS			English	Article						paraphrase identification; transformers; cross-encoders; bi-encoders		Since the rise of Transformer networks and large language models, cross-encoders have become the dominant architecture for various Natural Language Processing tasks. When dealing with sentence pairs, they can exploit the relationships between those pairs. On the other hand, bi-encoders can obtain a vector given a single sentence and are used in tasks such as textual similarity or information retrieval due to their low computational cost; however, their performance is inferior to that of cross-encoders. In this paper, we present Sentence-CROBI, an architecture that combines cross-encoders and bi-encoders to obtain a global representation of sentence pairs. We evaluated the proposed architecture in the paraphrase identification task using the Microsoft Research Paraphrase Corpus, the Quora Question Pairs dataset, and the PAWS-Wiki dataset. Our model obtains competitive results compared with the state-of-the-art by using model ensembles and a simple model configuration. These results demonstrate that a simple architecture that combines sentence pair and single-sentence representations without using complex pre-training or fine-tuning algorithms is a viable alternative for sentence pair tasks.	[Ortiz-Barajas, Jesus-German] Univ Nacl Autonoma Mexico, Posgrad Ciencia & Ingn Comp, Mexico City 04510, DF, Mexico; [Bel-Enguix, Gemma] Univ Nacl Autonoma Mexico, Inst Ingn, Mexico City 04510, DF, Mexico; [Gomez-Adorno, Helena] Univ Nacl Autonoma Mexico, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 04510, DF, Mexico	Universidad Nacional Autonoma de Mexico; Universidad Nacional Autonoma de Mexico; Universidad Nacional Autonoma de Mexico	Bel-Enguix, G (corresponding author), Univ Nacl Autonoma Mexico, Inst Ingn, Mexico City 04510, DF, Mexico.	gbele@iingen.unam.mx	; Bel-Enguix, Gemma/D-2685-2018	Gomez Adorno, Helena/0000-0002-6966-9912; Ortiz-Barajas, Jesus-German/0000-0003-0655-5667; Bel-Enguix, Gemma/0000-0002-1411-5736	PAPIIT projects [TA400121, TA101722]; CONACYT [CB A1-S-27780]; CONACYT PNPC scholarship [CVU 1086461]	PAPIIT projects(Programa de Apoyo a Proyectos de Investigacion e Innovacion Tecnologica (PAPIIT)); CONACYT(Consejo Nacional de Ciencia y Tecnologia (CONACyT)); CONACYT PNPC scholarship	This research was partially funded by PAPIIT projects TA400121 and TA101722, CONACYT CB A1-S-27780, and CONACYT PNPC scholarship with No. CVU 1086461.	[Anonymous], 2020, ADV NEUR IN; Bhagat R, 2013, COMPUT LINGUIST, V39, P463, DOI 10.1162/COLI_a_00166; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Chen YR, 2021, IEEE ACCESS, V9, P144129, DOI 10.1109/ACCESS.2021.3122273; de Wynter A, 2020, Arxiv, DOI arXiv:2010.10499; de Wynter A, 2020, Arxiv, DOI arXiv:2010.07990; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; Dopierre T, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2454; Dror Rotem, 2018, P 56 ANN M ASS COMP, V1, P1383, DOI [10.18653/v1/P18-1128, DOI 10.18653/V1/P18-1128]; Gao Tianyu, 2021, 2021 C EMP METH NAT, P6894, DOI 10.18653/v1/2021.emnlp-main.552; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921; He Pengcheng, 2020, arXiv; Humeau S., 2019, ARXIV; Izsak P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10644; Jiang HM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2177; Lan Z., 2020, INT C LEARNING REPRE; Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487; Liu Y., 2019, CoRR abs/1907.11692; Min SW, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2791; Montoya MAM, 2016, RLA-REV LINGUIST TEO, V54, P85; Peng QW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5579; Perez-Almendros Carla, 2022, P 16 INT WORKSHOP SE, DOI [10.18653/v1/2022.semeval-1.38, DOI 10.18653/V1/2022.SEMEVAL-1.38]; Phang J, 2018, ARXIV; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Sinha K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2888; Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968; Vaswani A, 2017, ADV NEUR IN, V30; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wang A., 2019, Glue: A multi-task benchmark and analysis platform for natural language understanding; Wang W., 2020, ARXIV; Wei J., 2022, ARXIV; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xu S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124144; Zhang Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1298	41	0	0	0	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	OCT	2022	10	19							3578	10.3390/math10193578	http://dx.doi.org/10.3390/math10193578			16	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	5G4KG		gold			2024-07-03	WOS:000866968600001
C	Kim, J; Chong, J; Lane, I			International Speech Communications Association	Kim, Jungsuk; Chong, Jike; Lane, Ian			Efficient On-The-Fly Hypothesis Rescoring in a Hybrid GPU/CPU-based Large Vocabulary Continuous Speech Recognition Engine	13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3			English	Proceedings Paper	13th Annual Conference of the International-Speech-Communication-Association	SEP 09-13, 2012	Portland, OR	Int Speech Commun Assoc		Large Vocabulary Continuous Speech Recognition; WFST; On-The-Fly Rescoring; Graphics Processing Units		Effectively exploiting the resources available on modern multicore and manycore processors for tasks such as large vocabulary continuous speech recognition (LVCSR) is far from trivial. While prior works have demonstrated the effectiveness of manycore graphic processing units (GPU) for high-throughput, limited vocabulary speech recognition, they are unsuitable for recognition with large acoustic and language models due to the limited 1-6GB of memory on GPUs. To overcome this limitation, we introduce a novel architecture for WFST-based LVCSR that jointly leverages manycore graphic processing units (GPU) and multicore processors (CPU) to efficiently perform recognition even when large acoustic and language models are applied. In the proposed approach, recognition is performed on the GPU using an H-level WFST, composed using a unigram language model. During decoding partial hypotheses generated over this network are rescored on-the-fly using a large language model, which resides on the CPU. By maintaining N-best hypotheses during decoding our proposed architecture obtains comparable accuracy to a standard CPU-based WFST decoder while improving decoding speed by a factor of 11 x.	[Kim, Jungsuk; Chong, Jike; Lane, Ian] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Kim, J (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	jungsuk.kim@sv.cmu.edu; jike.chong@sv.cmu.edu; lane@cs.cmu.edu						[Anonymous], NVIDIA GEFORCE GTX68; Chong JK, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1489; Dixon P. R., 2009, IEEE INT C AC SPEECH; Heafield K., 2011, P 6 WORKSHOP STAT MA, P187; Hori T, 2007, IEEE T AUDIO SPEECH, V15, P1352, DOI 10.1109/TASL.2006.889790; Hsiao R., 2011, HDB NATURAL LANGUAGE, P496; Kim J, 2011, INT CONF ACOUST SPEE, P1733; Kveton P., 2010, P INTERSPEECH; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; Nallasamy U., 2011, HDB NATURAL LANGUAGE, P535; Oonishi T, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2110; Schalkwyk J., 2010, GOOGLE SEARCH VOICE; You K, 2009, IEEE SIGNAL PROC MAG, V26, P124, DOI 10.1109/MSP.2009.934124	13	1	2	0	2	ISCA-INT SPEECH COMMUNICATION ASSOC	BAIXAS	C/O EMMANUELLE FOXONET, 4 RUE DES FAUVETTES, LIEU DIT LOUS TOURILS, BAIXAS, F-66390, FRANCE			978-1-62276-759-5				2012							1034	1037						4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BFO97					2024-07-03	WOS:000320827200259
J	Farhat, F; Chaudhry, BM; Nadeem, M; Sohail, SS; Madsen, DO				Farhat, Faiza; Chaudhry, Beenish Moalla; Nadeem, Mohammad; Sohail, Shahab Saquib; Madsen, Dag Oivind			Evaluating Large Language Models for the National Premedical Exam in India: Comparative Analysis of GPT-3.5, GPT-4, and Bard	JMIR MEDICAL EDUCATION			English	Article						accuracy; AI model; artificial intelligence; Bard; ChatGPT; educational task; GPT-4; Generative Pre-trained Transformers; large language models; medical education, medical exam; natural language processing; performance; premedical exams; suitability		Background: Large language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for Objective: This comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. Methods: In this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models. Results: It was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59. Conclusions: The study's findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs' performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.	[Farhat, Faiza] Aligarh Muslim Univ, Dept Zool, Aligarh, India; [Chaudhry, Beenish Moalla] Univ Louisiana Lafayette, Sch Comp & Informat, Lafayette, LA USA; [Nadeem, Mohammad] Aligarh Muslim Univ, Dept Comp Sci, Aligarh, India; [Sohail, Shahab Saquib] VIT Bhopal Univ, Sch Comp Sci & Engn, Sehore, India; [Madsen, Dag Oivind] Univ South Eastern Norway, Sch Business, Bredalsveien 14, N-3511 Honefoss, Norway	Aligarh Muslim University; University of Louisiana Lafayette; Aligarh Muslim University; VIT Bhopal University; University College of Southeast Norway	Madsen, DO (corresponding author), Univ South Eastern Norway, Sch Business, Bredalsveien 14, N-3511 Honefoss, Norway.	dag.oivind.madsen@usn.no	FARHAT, FAIZA/KIK-8175-2024; sohail, shahab/O-3263-2019; Madsen, Dag Oivind/I-1587-2016	sohail, shahab/0000-0002-5944-7371; Madsen, Dag Oivind/0000-0001-8735-3332; Nadeem, Mohammad/0000-0003-3664-5014; FARHAT, FAIZA/0000-0002-1310-1586; Chaudhry, Beenish Moalla/0000-0002-0437-6924				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; [Anonymous], 2023, Bard; Arumugam V, 2019, QUAL ASSUR EDUC, V27, P197, DOI 10.1108/QAE-07-2018-0080; Beerbaum D, 2023, Social Science Research Network; Bommineni VL, 2023, medRxiv, DOI [10.1101/2023.03.05.23286533, 10.1101/2023.03.05.23286533, DOI 10.1101/2023.03.05.23286533]; Borji A, 2023, Battle of the Wordsmiths: comparing ChatGPT, GPT-4, Claude, and Bard; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Choi JH, 2022, J LEGAL EDUC, V71, P387; Chowdhery A, 2023, J MACH LEARN RES, V24; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Farhat F, 2024, ANN BIOMED ENG, V52, P1111, DOI 10.1007/s10439-023-03326-7; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hong WCH, 2023, J Educ Technol Inov., V5; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu JL, 2023, iScience. CellPress; Liu X, PREPRINT; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McGee RW, 2023, ResearchGate; OpenAI's, 2022, ChatGPT; Rane N., 2023, Social Science Research Network; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sohail SS, 2024, ANN BIOMED ENG, V52, P1131, DOI 10.1007/s10439-023-03335-6; Sohail SS, 2024, ANN BIOMED ENG, V52, P446, DOI 10.1007/s10439-023-03305-y; Teebagy S, 2023, PREPRINT; Terwiesch C., 2023, Would ChatGPT get a Wharton MBA? A prediction based on its performance in the operations management course; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Wood DA, 2023, ISS ACCOUNT EDUC, V38, P81, DOI 10.2308/ISSUES-2023-013; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	34	7	7	17	17	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e51523	10.2196/51523	http://dx.doi.org/10.2196/51523			12	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	KE2S4	38381486	gold, Green Published			2024-07-03	WOS:001178222600002
J	Dzeparoska, K; Tizghadam, A; Leon-Garcia, AA				Dzeparoska, Kristina; Tizghadam, Ali; Alberto Leon-Garcia, Alberto			Emergence: An Intent Fulfillment System	IEEE COMMUNICATIONS MAGAZINE			English	Article; Early Access						Task analysis; Automation; Complexity theory; ITU; Training; Monitoring; Ethernet		Network management complexities stem from the multitude of resources, services, and applications that are to be built on top of heterogeneous and distributed infrastructure. To address these complexities, a vendor-agnostic, logical, and abstract view of the infrastructure is essential. Intent-based networking (IBN) helps address complexity by providing a set of abstractions (e.g., functional, data, infrastructure), but the intelligent and automatic decomposition of an intent into a course of actions is a challenging task. In this article, we propose a policy-based approach to model functional abstractions, and decompose intents into a hierarchy of policies. We use closed control loop automation, guided by Finite State Machines (FSM) to execute the policies and deploy the intents. To make our approach widely applicable, we provide a mapping to the Metro Ethernet Forum (MEF) Policy Driven Orchestration (PDO) model. We also discuss opportunities for IBN in large language models, and demonstrate our system through a cloud intent that includes a VNF and a health check service.	[Dzeparoska, Kristina; Tizghadam, Ali] Univ Toronto, Toronto, ON, Canada; [Tizghadam, Ali] TELUS Commun Inc, Vancouver, BC, Canada; [Alberto Leon-Garcia, Alberto] Univ Toronto, Elect & Comp Engn, Toronto, ON, Canada	University of Toronto; University of Toronto	Dzeparoska, K (corresponding author), Univ Toronto, Toronto, ON, Canada.	KRISTINA.DZEPAROSKA@MAIL.UTORONTO.CA						[Anonymous], 2021, ETSI GS ZSM 009-1 V1.1.1; [Anonymous], 2000, ITU-T Recommendation P.862; [Anonymous], 2021, ETSI GS ENI 005 V2.1.1; [Anonymous], 2021, Metro Ethernet Forum; Bezahaf M, 2019, PROCEEDINGS OF THE 2019 10TH INTERNATIONAL CONFERENCE ON NETWORKS OF THE FUTURE (NOF 2019), P138, DOI [10.1109/nof47743.2019.9015045, 10.1109/NoF47743.2019.9015045]; Bezahaf M, 2021, PROCEEDINGS OF THE 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2021): ACCELERATING NETWORK SOFTWARIZATION IN THE COGNITIVE AGE, P31, DOI 10.1109/NetSoft51509.2021.9492554; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Clemm A, 2022, RFC 9315; Dzeparoska K, 2021, IEEE ACCESS, V9, P159882, DOI 10.1109/ACCESS.2021.3129990; Leivadeas A., 2022, IEEE Commun. Surveys & Tutorials; Li C., 2022, Intent Classification; Lin JY, 2023, IEEE Confer on Netwo, P539, DOI 10.1109/NetSoft57336.2023.10175410; Pang L, 2020, IEEE ACCESS, V8, P22862, DOI 10.1109/ACCESS.2020.2969208; Strassner J., 2021, Future Networks, Services and Management: Underlay and Overlay, Edge, Applications, Slicing, Cloud, Space, AI/ML, and Quantum Computing, P399; Yang CA, 2023, IEEE COMMUN MAG, V61, P106, DOI 10.1109/MCOM.002.2200119	15	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0163-6804	1558-1896		IEEE COMMUN MAG	IEEE Commun. Mag.	2024 JAN 31	2024										10.1109/MCOM.001.2300270	http://dx.doi.org/10.1109/MCOM.001.2300270		JAN 2024	6	Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Telecommunications	MT8B9					2024-07-03	WOS:001195967800001
C	Gupta, T; Kembhavi, A			IEEE	Gupta, Tanmay; Kembhavi, Aniruddha			Visual Programming: Compositional visual reasoning without training	2023 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 17-24, 2023	Vancouver, CANADA	IEEE, CVF, IEEE Comp Soc				We present VISPROG, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions. VISPROG avoids the need for any task-specific training. Instead, it uses the in-context learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models, image processing subroutines, or python functions to produce intermediate outputs that may be consumed by subsequent parts of the program. We demonstrate the flexibility of VISPROG on 4 diverse tasks - compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image editing. We believe neuro-symbolic approaches like VISPROG are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform.	[Gupta, Tanmay; Kembhavi, Aniruddha] PRIOR Allen Inst AI, Seattle, WA 98103 USA		Gupta, T (corresponding author), PRIOR Allen Inst AI, Seattle, WA 98103 USA.							Alayrac Jean-Baptiste, 2022, ABS220414198 ARXIV; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Bapna Ankur, 2022, ABS220201374 ARXIV; Bradski G, 2000, DR DOBBS J, V25, P120; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cheng B., 2021, NEURIPS; Devlin J., 2018, BERT PRE TRAINING DE; Gupta Tanmay, 2021, ABS210400743 ARXIV; Hu RH, 2018, LECT NOTES COMPUT SC, V11211, P55, DOI 10.1007/978-3-030-01234-2_4; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Kamath Amita, 2022, ECCV; Khot Tushar, 2022, ABS221002406 ARXIV; Kim Wonjae, 2021, ICML; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Lu Jiasen, 2022, ABS220608916 ARXIV; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Minderer Matthias, 2022, ABS220506230 ARXIV; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel Colin, 2020, ABS191010683 ARXIV; Ramesh A., 2021, ABS210212092 ARXIV; Reed Scott, 2022, ABS220506175 ARXIV; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Singh Ishika, 2022, ABS220911302 ARXIV; Suhr Alane, 2019, ABS181100491 ARXIV; Wang Xuezhi, 2022, ABS220311171 ARXIV; Wei Jason, 2022, ABS220111903 ARXIV; Welker S., 2022, Socratic models: Composing zero-shot multimodal reasoning with language; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Yang Z., 2022, AAAI; Yu Jiahui, 2022, ABS220610789 ARXIV	33	3	4	9	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		979-8-3503-0129-8	PROC CVPR IEEE			2023							14953	14962		10.1109/CVPR52729.2023.01436	http://dx.doi.org/10.1109/CVPR52729.2023.01436			10	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV6TF		Green Submitted			2024-07-03	WOS:001062522107027
C	Shoa, A; Oliva, R; Slater, M; Friedman, D			ACM	Shoa, Alon; Oliva, Ramon; Slater, Mel; Friedman, Doron			Sushi with Einstein: Enhancing Hybrid Live Events with LLM-Based Virtual Humans	PROCEEDINGS OF THE 23RD ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS, IVA 2023			English	Proceedings Paper	23rd ACM International Conference on Intelligent Virtual Agents (IVA)	SEP 19-22, 2023	Wurzburg, GERMANY	Assoc Comp Machinery, ACM SIGAI		VR; AI; Persona Reconstruction; GPT3		It is becoming increasingly easier to set up multi-user virtual reality sessions, and these can become viable alternatives to video conference in events such as international conferences. Moreover, it is possible to enhance such events with automated virtual humans, who may participate in the discussion. This paper presents the behind-the-scenes work of a panel session titled "Is virtual reality genuine reality?", which was held during a physical symposium, "XR for the people," in June 2022. The panel featured a virtual Albert Einstein, based on a large language model (LLM), as a panelist, alongside three international experts having a live conference panel discussion. The VR discussion was broadcast live on stage, and a moderator was able to communicate with both the live audience, the virtual world participants, and the virtual agent (Einstein). We provide lessons learned from the implementation and from the live production, and discuss the potential and pitfalls of using LLM-based virtual humans for multi-user VR in live hybrid events.	[Shoa, Alon] Reichman Univ, Adv Real Lab, Herzliyya, Israel; [Oliva, Ramon; Slater, Mel] Univ Barcelona, Event Lab, Dept Clin Psychol & Psychobiol, Barcelona, Spain; [Slater, Mel] Univ Barcelona, Event Lab, Inst Neurosci, Barcelona, Spain; [Friedman, Doron] Reichman Univ, Adv Real Lab, Sch Commun, Herzliyya, Israel	Reichman University; University of Barcelona; University of Barcelona; Reichman University	Shoa, A (corresponding author), Reichman Univ, Adv Real Lab, Herzliyya, Israel.	shoa.alon@gmail.com; ramon.oliva.martinez@gmail.com; melslater@gmail.com; doronf@runi.ac.il			European Union [101017884, 951930]; European Research Council Advanced Grant MoTIVE [742989]; H2020 - Industrial Leadership [951930] Funding Source: H2020 - Industrial Leadership	European Union(European Union (EU)); European Research Council Advanced Grant MoTIVE(European Research Council (ERC)); H2020 - Industrial Leadership(European Union (EU)H2020 - Industrial Leadership)	Thiswork was partially supported by projects GuestXR (#101017884) and Socrates EU projects (#951930), which have received funding from the European Union's Horizon 2020 research and innovation program. MS is supported by the European Research Council Advanced Grant MoTIVE (#742989). The Einstein model was designed by Maya Shekel as part of Ronit Elyoseph's Ph.D. thesis research. The development and production of this joint work within the 'Advanced Reality Lab' and 'EventLab'. We would like to credit to the stuff members that helped in the production: Virtual cinematographer: Maya Shekel; Event production: AlonWeizman (VRGo), Gal Yaar; physical moderator: Dr Jeremy Fogel; Panelists: Prof David Chalmers, Prof Mel Slater, Prof Doron Friedman, and Prof Albert Einstein.	Baudrillard Jean., 1994, SIMULACRA SIMULATION; Benjamin Walter., 1936, Marxists Internet Archive; Birnhack M, 2022, INT J LAW INFORM TEC, V30, P280, DOI 10.1093/ijlit/eaac019; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Budzianowski P, 2019, Arxiv, DOI arXiv:1907.05774; Cassell J, 1999, SPRING INT SER ENG C, V511, P143; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Friedman D, 2006, EXPERT SYST APPL, V30, P694, DOI 10.1016/j.eswa.2005.07.027; Friedman D, 2004, P IEEE VIRT REAL ANN, P191, DOI 10.1109/VR.2004.1310074; Friedman Doron, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P28, DOI 10.1007/978-3-642-23974-8_3; Friedman Doron, 2013, Virtual substitute teacher: introducing the concept of a classroom proxy; Friedman Doron, 2016, Human Computer Confluence Transforming Human Experience Through Symbiotic Technologies, P156; Heck R, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198306; Käding C, 2017, LECT NOTES COMPUT SC, V10118, P588, DOI 10.1007/978-3-319-54526-4_43; Kishore S, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00065; Marinelli D, 1998, 1998 IEEE 4TH WORKSHOP INTERACTIVE VOICE TECHNOLOGY FOR TELECOMMUNICATIONS APPLICATIONS - IVTTA '98, P43, DOI 10.1109/IVTTA.1998.727691; Oliva Ramon, 2023, The making of a Newspaper Interview in Virtual Reality: Realistic Avatars, Philosophy and Sushi; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Slater M., 2020, Frontiers in Virtual Reality, V1, P1, DOI [10.3389/frvir.2020.00001, DOI 10.3389/FRVIR.2020.00001]; Steed A, 2012, IEEE COMPUT GRAPH, V32, P10, DOI 10.1109/MCG.2012.110; Traum D, 2015, LECT NOTES COMPUT SC, V9445, P269, DOI 10.1007/978-3-319-27036-4_26; Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282	22	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9994-4				2023										10.1145/3570945.3607317	http://dx.doi.org/10.1145/3570945.3607317			6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4YH		hybrid, Green Published			2024-07-03	WOS:001157038100022
C	Kandpal, N; Wallace, E; Raffel, C		Chaudhuri, K; Jegelka, S; Song, L; Szepesvari, C; Niu, G; Sabato, S		Kandpal, Nikhil; Wallace, Eric; Raffel, Colin			Deduplicating Training Data Mitigates Privacy Risks in Language Models	INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 162	Proceedings of Machine Learning Research		English	Proceedings Paper	39th International Conference on Machine Learning (ICML)	JUL 17-23, 2022	Baltimore, MD					Past work has shown that large language models are susceptible to privacy attacks, where adversaries generate sequences from a trained model and detect which sequences are memorized from the training set. In this work, we show that the success of these attacks is largely due to duplication in commonly used web-scraped training sets. We first show that the rate at which language models regenerate training sequences is superlinearly related to a sequence's count in the training set. For instance, a sequence that is present 10 times in the training data is on average generated similar to 1000x more often than a sequence that is present only once. We next show that existing methods for detecting memorized sequences have near-chance accuracy on non-duplicated training sequences. Finally, we find that after applying methods to deduplicate training data, language models are considerably more secure against these types of privacy attacks. Taken together, our results motivate an increased focus on deduplication in privacy-sensitive applications and a reevaluation of the practicality of existing privacy attacks.	[Kandpal, Nikhil; Raffel, Colin] Univ N Carolina, Chapel Hill, NC 27599 USA; [Wallace, Eric] Univ Calif Berkeley, Berkeley, CA USA	University of North Carolina; University of North Carolina Chapel Hill; University of California System; University of California Berkeley	Kandpal, N (corresponding author), Univ N Carolina, Chapel Hill, NC 27599 USA.	nkandpa2@cs.unc.edu						Brown G, 2021, ACM S THEORY COMPUT, P123, DOI 10.1145/3406325.3451131; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2022, Arxiv, DOI [arXiv:2112.03570, 10.48550/ARXIV.2112.03570]; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; Coavoux M., 2018, P 2018 C EMPIRICAL M; Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14; Fan A., 2018, ACL; Feldman V., 2020, Advances in Neural Information Processing Systems; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gokaslan Aaron, 2019, OPEN WEBTEXT CORPUS; Hernandez D, 2022, Arxiv, DOI arXiv:2205.10487; Hidano S, 2017, ANN CONF PRIV SECUR, P115, DOI 10.1109/PST.2017.00023; Inan H. A., 2021, PRIVACY PRESERVING M; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Lehman E., 2021, P 2021 C N AM CHAPTE; Li Xiaotong, 2022, ICLR; Long Y., 2018, arXiv; McCoy RT, 2021, Arxiv, DOI arXiv:2111.09509; Mireshghallah F., 2021, P 2021 C N AM CHAPTE; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Raffel C, 2020, J MACH LEARN RES, V21; Recht B, 2018, Arxiv, DOI arXiv:1806.00451; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Song C., 2019, P 25 ACM SIGKDD INT; Song CZ, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3372297.3417270; Tan ZW, 2018, P ACM MEAS ANAL COMP, V2, DOI 10.1145/3179411; van den Burg Gerrit JJ, 2021, NEURIPS; Vaswani A, 2017, ADV NEUR IN, V30; Watson L, 2022, Arxiv, DOI arXiv:2111.08440; West P., 2021, ACL; Yang ZQ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P225, DOI 10.1145/3319535.3354261; Yeom S, 2018, P IEEE COMPUT SECUR, P268, DOI 10.1109/CSF.2018.00027; Yu D, 2022, Arxiv, DOI arXiv:2110.06500; Zhang CY, 2023, Arxiv, DOI arXiv:2112.12938; Zhao XD, 2022, Arxiv, DOI [arXiv:2205.01863, DOI 10.48550/ARXIV.2205.01863, 10.48550/ARXIV.2205.01863]; Ziegler Albert., 2021, GitHub Copilot: Parrot or Crow?	42	9	10	4	5	JMLR-JOURNAL MACHINE LEARNING RESEARCH	SAN DIEGO	1269 LAW ST, SAN DIEGO, CA, UNITED STATES	2640-3498			PR MACH LEARN RES			2022							10697	10707						11	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU4IU					2024-07-03	WOS:000900064900032
J	Da, LC; Liou, KR; Chen, TJ; Zhou, XS; Luo, XY; Yang, YZ; Wei, H				Da, Longchao; Liou, Kuanru; Chen, Tiejin; Zhou, Xuesong; Luo, Xiangyong; Yang, Yezhou; Wei, Hua			Open-ti: open traffic intelligence with augmented language model	INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS			English	Article; Early Access						Large language models; Traffic simulation; Traffic signal control	DEMAND ESTIMATION; MATRIX	Transportation has greatly benefited the cities' development in the modern civilization process. Intelligent transportation, leveraging advanced computer algorithms, could further increase people's daily commuting efficiency. However, intelligent transportation, as a cross-discipline, often requires practitioners to comprehend complicated algorithms and obscure neural networks, bringing a challenge for the advanced techniques to be trusted and deployed in practical industries. Recognizing the expressiveness of the pre-trained large language models, especially the potential of being augmented with abilities to understand and execute intricate commands, we introduce Open-TI. Serving as a bridge to mitigate the industry-academic gap, Open-TI is an innovative model targeting the goal of Turing Indistinguishable Traffic Intelligence, it is augmented with the capability to harness external traffic analysis packages based on existing conversations. Marking its distinction, Open-TI is the first method capable of conducting exhaustive traffic analysis from scratch-spanning from map data acquisition to the eventual execution in complex simulations. Besides, Open-TI is able to conduct task-specific embodiment like training and adapting the traffic signal control policies (TSC), explore demand optimizations, etc. Furthermore, we explored the viability of LLMs directly serving as control agents, by understanding the expected intentions from Open-TI, we designed an agent-to-agent communication mode to support Open-TI conveying messages to ChatZero (control agent), and then the control agent would choose from the action space to proceed the execution. We eventually provide the formal implementation structure, and the open-ended design invites further community-driven enhancements. A demo video is provided at: https://youtu.be/pZ4-5PXz9Xs.	[Da, Longchao; Liou, Kuanru; Chen, Tiejin; Yang, Yezhou; Wei, Hua] Arizona State Univ, Sch Comp & Augmented Intelligence, 350 Lemon St, Tempe, AZ 85287 USA; [Zhou, Xuesong; Luo, Xiangyong] Arizona State Univ, Sch Sustainable Engn & Built Environm, 350 Lemon St, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Wei, H (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, 350 Lemon St, Tempe, AZ 85287 USA.	longchao@asu.edu; kliou@asu.edu; tchen169@asu.edu; xzhou74@asu.edu; xluo70@asu.edu; yz.yang@asu.edu; hua.wei@asu.edu			National Science Foundation	National Science Foundation(National Science Foundation (NSF))	No Statement Available	Abrahamsson T, 1998, Estimation of origin-destination matrices using traffic counts-a literature survey; Behrisch Michael, 2011, P SIMUL 2011 3 INT C; Boukerche A, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107484; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chao QW, 2020, COMPUT GRAPH FORUM, V39, P287, DOI 10.1111/cgf.13803; Chen M., 2021, arXiv; Chowdhery A, 2023, J MACH LEARN RES, V24; Cools SB, 2008, ADV INFORM KNOWL PRO, P41, DOI 10.1007/978-1-84628-982-8_3; Da L, 2024, Arxiv, DOI arXiv:2308.14284; Dai Z, 2020, TRANSPORT RES C-EMER, V114, P598, DOI 10.1016/j.trc.2020.03.001; de Souza F, 2019, PROCEDIA COMPUT SCI, V151, P858, DOI 10.1016/j.procs.2019.04.118; de Zarzà I, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23229225; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, DOI DOI 10.48550/ARXIV.1711.03938; Fedorov A, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0234-z; Fellendorf M, 2010, INT SER OPER RES MAN, V145, P63, DOI 10.1007/978-1-4419-6142-6_2; Fu H, 2022, TRANSPORT RES E-LOG, V157, DOI 10.1016/j.tre.2021.102555; Gulino C, 2023, Arxiv, DOI arXiv:2310.08710; Hua Wei, 2020, ACM SIGKDD Explorations Newsletter, V22, P12, DOI 10.1145/3447556.3447565; Krishnakumari P, 2020, TRANSPORT RES C-EMER, V113, P38, DOI 10.1016/j.trc.2019.05.014; Kumarage S, 2023, TRANSPORT RES B-METH, V176, DOI 10.1016/j.trb.2023.102804; Li MH, 2023, Arxiv, DOI arXiv:2304.08244; Li Y., 2023, bioRxiv, P2023; Liang YB, 2023, Arxiv, DOI arXiv:2303.16434; Liu CX, 2024, Arxiv, DOI arXiv:2401.10134; Liu Y., 2023, Meta-Radiol ogy; Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938; Lu JW, 2023, TRANSPORT RES C-EMER, V153, DOI 10.1016/j.trc.2023.104223; Mahmassani H.S., 2001, Networks Spatial Econ., V1, P267; Mahmassani HS, 2005, SYST CONTROL-FOUND A, P305, DOI 10.1007/0-8176-4409-1_16; Maroto J, 2006, IEEE T INTELL TRANSP, V7, P513, DOI 10.1109/TITS.2006.883937; Masek P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111872; Medina A, 2002, ACM SIGCOMM COMP COM, V32, P161, DOI 10.1145/964725.633041; Mei H, 2023, MACH LEARN, DOI 10.1007/s10994-023-06412-y; Mialon G., 2023, arXiv; Mullakkal-Babu FA, 2021, IEEE T INTELL TRANSP, V22, P3430, DOI 10.1109/TITS.2020.2990376; NVIDIA, 2023, Simulation for self-driving vehicles; OPPE S, 1989, ACCIDENT ANAL PREV, V21, P225, DOI 10.1016/0001-4575(89)90013-4; Osorio C, 2019, TRANSPORT RES B-METH, V124, P18, DOI 10.1016/j.trb.2019.01.005; Pamula T, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105550; Qadri SSSM, 2020, EUR TRANSP RES REV, V12, DOI 10.1186/s12544-020-00439-1; Tang JB, 2024, Arxiv, DOI arXiv:2310.13023; Tirumala K., 2022, Advances in Neural Information Processing Systems, V35, P38274; Tong L, 2019, URBAN RAIL TRANSIT, V5, P1, DOI 10.1007/s40864-018-0100-x; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Wang YB, 2023, Arxiv, DOI arXiv:2309.02233; Wei H, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1913, DOI 10.1145/3357384.3357902; Wei H, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1290, DOI 10.1145/3292500.3330949; Wei H, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2496, DOI 10.1145/3219819.3220096; Willumsen L.G., 1978, Estimation of an Od Matrix from Traffic Counts-A Review; YUKAWA S, 1995, J PHYS SOC JPN, V64, P35, DOI 10.1143/JPSJ.64.35; Zhang HC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3620, DOI 10.1145/3308558.3314139; Zhang SY, 2023, Arxiv, DOI arXiv:2309.06719; Zheng GJ, 2019, Arxiv, DOI arXiv:1905.04716; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]; Zhou X, 2013, Dynamic origin-destination demand flow estimation utilizing heterogeneous data sources under congested traffic conditions; Zhou X., 2022, Multimodal Transp., V1; Zhou XS, 2003, TRANSPORT RES REC, P30; Zhou XS, 2006, TRANSPORT RES REC, P176; Zhou XS, 2010, TRANSPORT SCI, V44, P254, DOI 10.1287/trsc.1100.0319	60	0	0	6	6	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1868-8071	1868-808X		INT J MACH LEARN CYB	Int. J. Mach. Learn. Cybern.	2024 MAY 9	2024										10.1007/s13042-024-02190-8	http://dx.doi.org/10.1007/s13042-024-02190-8		MAY 2024	26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QJ0P7					2024-07-03	WOS:001220393500003
J	Zheng, XL; Li, JY; Lu, MY; Wang, FY				Zheng, Xiaolong; Li, Jingyu; Lu, Mengyao; Wang, Fei-Yue			New Paradigm for Economic and Financial Research With Generative AI: Impact and Perspective	IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS			English	Article; Early Access						Economics; Biological system modeling; Data models; Task analysis; Behavioral sciences; Big Data; Analytical models; finance; generative artificial intelligence (GAI); reinforcement learning from human feedback (RLHF); research paradigm		In the past few years, we have witnessed the rapid development and exponential growth of generative artificial intelligence (GAI) technologies including large language models (LLMs)-enabled ChatGPT and peripheral innovations. These technologies are designed to be humanlike intelligence and intuitive by providing direct access to systems using application programming interfaces (APIs). The GAI applications can fundamentally change economic and financial activities, through revolutionizing the ways that humans interact with machines and giving rise to new modes of production and behavior patterns. It is imperative to develop a new research paradigm that is more suitable than the currently dominating conventional research paradigms. This article presents the new paradigm for economic and financial research with GAI, covering the research objectives, scientific data, and models, and explores the underlying impact and perspective that bring to this field. We elaborate on the potential five scenarios including portfolio management, economic and financial prediction, extreme scenario analysis, policy analysis, and financial fraud detection. The new research paradigm with GAI proposed in this article can provide significant insights for a comprehensive understanding of innovation and transformation in this domain.	[Zheng, Xiaolong; Wang, Fei-Yue] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China; [Zheng, Xiaolong; Wang, Fei-Yue] Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China; [Zheng, Xiaolong; Wang, Fei-Yue] Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China; [Li, Jingyu; Lu, Mengyao] Beijing Univ Technol, Sch Econ & Management, Beijing 100124, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Beijing University of Technology	Wang, FY (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China.; Li, JY (corresponding author), Beijing Univ Technol, Sch Econ & Management, Beijing 100124, Peoples R China.	xiaolong.zheng@ia.ac.cn; lijy@bjut.edu.cn; lumengyao@emails.bjut.edu.cn; feiyue@ieee.org	Li, Jingyu/HLV-6856-2023	Li, Jingyu/0000-0001-9466-6820	Ministry of Science and Technology of China [2020AAA0108401]; Natural Science Foundation of China [72225011, 72201012, 72293575]	Ministry of Science and Technology of China(Ministry of Science and Technology, China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the Ministry of Science and Technology of China under Grant 2020AAA0108401 and in part by the Natural Science Foundation of China under Grants 72225011, 72201012,and 72293575.(Xiaolong Zheng and Jingyu Li contributed equally to this work.)	Aiyappa R, 2023, Arxiv, DOI [arXiv:2303.12767, DOI 10.48550/ARXIV.2303.12767]; Ba H, 2019, Arxiv, DOI arXiv:1907.03355; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bursztyn L, 2014, ECONOMETRICA, V82, P1273, DOI 10.3982/ECTA11991; Carvajal-Patiño D, 2022, RES INT BUS FINANC, V62, DOI 10.1016/j.ribaf.2022.101747; Chen RJ, 2021, NAT BIOMED ENG, V5, P493, DOI 10.1038/s41551-021-00751-8; Chen Y., 2023, A manager and an AI walk into a bar: Does ChatGPT make biased decisions like we do?, DOI DOI 10.2139/SSRN.4380365; Ding WW, 2022, IEEE T COMPUT SOC SY, V9, P1563, DOI 10.1109/TCSS.2022.3204745; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Epstein Z, 2023, SCIENCE, V380, P1110, DOI 10.1126/science.adh4451; Goldstein I, 2021, REV FINANC STUD, V34, P3213, DOI 10.1093/rfs/hhab038; Kim J, 2023, Arxiv, DOI [arXiv:2304.11856, 10.48550/arXiv.2304.11856, DOI 10.48550/ARXIV.2304.11856]; Korinek A., 2023, LANGUAGE MODELS COGN; Leippold M., 2023, Swiss Finance Institute Research Paper No. 23-11, DOI [10.2139/ssrn.4337182, DOI 10.2139/SSRN.4337182]; Leippold M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2022.103617; Li JY, 2023, IEEE T COMPUT SOC SY, V10, P269, DOI 10.1109/TCSS.2021.3134487; Li X, 2023, IEEE T SYST MAN CY-S, V53, P5545, DOI 10.1109/TSMC.2023.3273896; Li X, 2023, IEEE T SYST MAN CY-S, V53, P2148, DOI 10.1109/TSMC.2022.3228594; Li X, 2022, IEEE INTELL SYST, V37, P18, DOI 10.1109/MIS.2022.3197950; Lopez-Lira A., 2023, Can ChatGPT forecast stock price movements? Return predictability and large language models, DOI [10.2139/ssrn.4412788, DOI 10.2139/SSRN.4412788]; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Niszczota P., 2023, GPT as a financial advisor, DOI [10.2139/ssrn.4384861, DOI 10.2139/SSRN.4384861]; Noguer M., 2023, Generative models for time series in finance, DOI [10.2139/ssrn.4343967, DOI 10.2139/SSRN.4343967]; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Parkes DC, 2015, SCIENCE, V349, P267, DOI 10.1126/science.aaa8403; Peng Sida, 2023, arXiv, DOI DOI 10.48550/ARXIV.2302.06590; Pérez J, 2023, APPL INTELL, V53, P1469, DOI 10.1007/s10489-022-03557-6; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Saetra HS, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102372; Song CC, 2020, REV FINANC STUD, V33, P916, DOI 10.1093/rfs/hhz074; Tian H, 2022, INFORMS J COMPUT, V34, P1940, DOI 10.1287/ijoc.2022.1172; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Wang FY, 2007, IEEE INTELL SYST, V22, P65, DOI 10.1109/MIS.2007.4338496; Wang FY, 2007, IEEE INTELL SYST, V22, P79, DOI 10.1109/MIS.2007.41; Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583; Xie QW, 2023, FINANC RES LETT, V52, DOI 10.1016/j.frl.2022.103545; Zarifhonarvar A., 2023, Economics of ChatGPT: A labor market view on the occupational impact of artificial intelligence, DOI DOI 10.2139/SSRN.4350925; Zhang XW, 2023, IEEE T COMPUT SOC SY, V10, P2847, DOI 10.1109/TCSS.2022.3199819; Zheng XL, 2023, FRONT ENG MANAG, V10, P177, DOI 10.1007/s42524-022-0241-1; Zheng XL, 2022, IEEE T COMPUT SOC SY, V9, P45, DOI 10.1109/TCSS.2021.3122260	43	0	0	69	69	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-924X			IEEE T COMPUT SOC SY	IEEE Trans. Comput. Soc. Syst.	2024 JAN 2	2024										10.1109/TCSS.2023.3334306	http://dx.doi.org/10.1109/TCSS.2023.3334306		JAN 2024	11	Computer Science, Cybernetics; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EE9A4					2024-07-03	WOS:001137349700001
C	Dhole, KD; Agichtein, E		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Dhole, Kaustubh D.; Agichtein, Eugene			GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Query Reformulation; Zero-Shot; Prompting; Relevance Feedback		Query Reformulation(QR) is a set of techniques used to transform a user's original search query to a text that better aligns with the user's intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better reformulations with relative nDCG@10 improvements up to 18% and MAP improvements upto 24% over the previous zero-shot state-of-art. On the MSMarco Passage Ranking task, GenQREnsembleRF shows relative gains of 5% MRR using pseudo-relevance feedback, and 9% nDCG@10 using relevant feedback documents.	[Dhole, Kaustubh D.; Agichtein, Eugene] Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA	Emory University	Dhole, KD (corresponding author), Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA.	kaustubh.dhole@emory.edu; eugene.agichtein@emory.edu						Abdul-Jaleel N., 2004, Comput. Sci. Dept. Fac. Publ. Ser., V189; Alaofi M, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1869, DOI 10.1145/3539618.3591960; Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416; Arora S., 2022, 11 INT C LEARN REPR; Bondarenko A., 2020, Lecture Notes in Computer Science, V12260, P384, DOI DOI 10.1007/978-3-030-58219-726; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Craswell Nick, 2020, Overview of the TREC 2019 deep learning track; Dhole K., 2023, Northern Eur. J. Lang. Technol., V9; Dhuliawala S, 2023, Arxiv, DOI [arXiv:2309.11495, 10.48550/arXiv.2309.11495]; Gao J., 2012, P EMNLP; Gao LY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1762; HARMAN D, 1992, INFORM PROCESS MANAG, V28, P439, DOI 10.1016/0306-4573(92)90001-G; Hasibi F, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1265, DOI 10.1145/3077136.3080751; Hsu DF, 2005, INFORM RETRIEVAL, V8, P449, DOI 10.1007/s10791-005-6994-4; Jagerman R, 2023, Arxiv, DOI arXiv:2305.03653; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012; Li H, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3570724; Li YF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5315; MacAvaney S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2429, DOI 10.1145/3404835.3463254; Macdonald C, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4526, DOI 10.1145/3459637.3482013; Mo FR, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4998; Mohankumar AK, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3423, DOI 10.1145/3447548.3467202; Nguyen DHN, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510844; Nogueira Rodrigo, 2019, Online Preprint, V6, P2; Paulus R., 2018, ICLR, V13; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Pradeep R, 2021, Arxiv, DOI arXiv:2101.05667; Raffel C, 2020, J MACH LEARN RES, V21; Si L., 2006, TREC; Srivastava A., 2023, Trans. Mach. Learn. Res., P1; Thakur N., 2021, BEIR: a heterogeneous benchmark for zero-shot evaluation of information retrieval models; Voorhees Ellen, 2020, ACM SIGIR Forum, V54, DOI 10.1145/3451964.3451965; Voorhees E. M., 2005, SIGIR Forum, V39, P11, DOI 10.1145/1067268.1067272; Wang X., 2023, 1 WORKSH GEN INF RET; Wang X., 2023, Self-consistency improves chain of thought reasoning in language models; Wang X, 2023, ACM T WEB, V17, DOI 10.1145/3572405; Weller O, 2024, Arxiv, DOI arXiv:2309.08541; Wiher G, 2022, T ASSOC COMPUT LING, V10, P997, DOI 10.1162/tacl_a_00502; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yu HC, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3592, DOI 10.1145/3459637.3482124; Zhao TZ, 2021, PR MACH LEARN RES, V139	44	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56062-0; 978-3-031-56063-7	LECT NOTES COMPUT SC			2024	14610						326	335		10.1007/978-3-031-56063-7_24	http://dx.doi.org/10.1007/978-3-031-56063-7_24			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DZ					2024-07-03	WOS:001211833300024
J	Haar, M; Sonntagbauer, M; Kluge, S				Haar, Markus; Sonntagbauer, Michael; Kluge, Stefan			Stellenwert von Natural Language Processing und chatbasierten Generative Language Models	MEDIZINISCHE KLINIK-INTENSIVMEDIZIN UND NOTFALLMEDIZIN			English	Article						Forschung; Publikationen; Ethik in der Forschung; Kunstliche Intelligenz; Computergestutzte neuronale Netze; Research; Publications; Research ethics; Artificial intelligence; Computational neural networks		BackgroundNatural language processing (NLP) has experienced significant growth in recent years and shows potential for broad impacts in scientific research and clinical practice.ObjectiveThis study comprises an exploration of the role of NLP in scientific research and its subsequent effects on traditional publication practices, as well as an evaluation of the opportunities and challenges offered by large language models (LLM) and a reflection on necessary paradigm shifts in research culture.Materials and methodsCurrent LLMs, such as ChatGPT, and their potential applications were compared and assessed. An analysis of the literature and case studies on the integration of LLMs into scientific and clinical practice was conducted.Results and conclusionLLMs provide enhanced access to and processing capabilities of text-based information and represent a vast potential for (medical) research as well as daily clinical practice. Chat-based LLMs enable efficient completion of often time-consuming tasks, but due to their tendency for hallucinations, have a significant limitation. Current developments require critical examination and a paradigm shift to fully exploit the benefits of LLMs and minimize potential risks.	[Haar, Markus; Sonntagbauer, Michael; Kluge, Stefan] Univ Klinikum Hamburg Eppendorf, Klin Intens Med, Hamburg, Germany; [Haar, Markus] Univ Klinikum Hamburg Eppendorf, Klin Intens Med, Martinistr 52, D-20251 Hamburg, Germany	University of Hamburg; University Medical Center Hamburg-Eppendorf; University of Hamburg; University Medical Center Hamburg-Eppendorf	Haar, M (corresponding author), Univ Klinikum Hamburg Eppendorf, Klin Intens Med, Martinistr 52, D-20251 Hamburg, Germany.	m.haar@uke.de		Haar, Markus/0000-0003-2461-5002				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], About us; [Anonymous], 2023, US NC BI; [Anonymous], 2023, NATURE SUBMISSION GU; [Anonymous], 2023, INTRO LARGE LANGUAGE; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Deng YH, 2019, ARTIF INTELL MED, V93, P29, DOI 10.1016/j.artmed.2018.10.001; Devlin J., 2018, BERT PRE TRAINING DE; Eleparts, 2023, About us; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Glaese A., 2022, IMPROVING ALIGNMENT; Grammarly, 2023, ABOUT US; Hoffmann F, 2021, J CLIN EPIDEMIOL, V138, P1, DOI 10.1016/j.jclinepi.2021.05.022; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kirchenbauer J., 2023, A WATERMARK LARGE LA; Kung TH., 2022, PERFORMANCE CHATGPT, DOI 10.1101; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Madiega T, 2023, IN PRESS; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Microsoft, 2023, ANN PYTH EXC COMB PO; Nuthakki S., 2019, NATURAL LANGUAGE PRO; OpenAI, 2023, ChatGPT can now see, hear, and speak; QuillBot, 2023, US; Radford A., 2018, IMPROVING LANGUAGE U; Security GFO for I, 2023, LARG LANG MOD OPP RI; Shuster K., 2022, BLENDERBOT 3 A DEPLO; Singer M, 2016, JAMA-J AM MED ASSOC, V315, P801, DOI 10.1001/jama.2016.0287; Sonntagbauer M, 2023, MED KLIN-INTENSIVMED, V118, P366, DOI 10.1007/s00063-023-01019-6; Sun WY, 2013, J AM MED INFORM ASSN, V20, P814, DOI 10.1136/amiajnl-2013-001760; Tang BZ, 2013, J AM MED INFORM ASSN, V20, P828, DOI 10.1136/amiajnl-2013-001635; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Vaswani A., 2017, Advances in neural information processing systems, P6000; Woll C., 2011, WIE LASSEN SICH FORS; Yue X., 2023, AUTOMATIC EVALUATION, DOI [10.18653/v1/2023.findings-emnlp.307, DOI 10.18653/V1/2023.FINDINGS-EMNLP.307]	34	0	0	8	9	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2193-6218	2193-6226		MED KLIN-INTENSIVMED	Med Klin Intensivmed Notfmed	APR	2024	119	3			SI		181	188		10.1007/s00063-023-01098-5	http://dx.doi.org/10.1007/s00063-023-01098-5		DEC 2023	8	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	NB6E6	38108880				2024-07-03	WOS:001128434700001
C	Roth, K; Kim, JM; Koepke, AS; Vinyals, O; Schmid, C; Akata, Z			IEEE	Roth, Karsten; Kim, Jae Myung; Koepke, A. Sophia; Vinyals, Oriol; Schmid, Cordelia; Akata, Zeynep			Waffling around for Performance: Visual Classification with Random Words and Broad Concepts	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				The visual classification performance of vision-language models such as CLIP has been shown to benefit from additional semantic knowledge from large language models (LLMs) such as GPT-3. In particular, averaging over LLMgenerated class descriptors, e.g. "waffle, which has a round shape", can notably improve generalization performance. In this work, we critically study this behavior and propose WaffleCLIP, a framework for zero-shot visual classification which simply replaces LLM-generated descriptors with random character and word descriptors. Without querying external models, we achieve comparable performance gains on a large number of visual classification tasks. This allows WaffleCLIP to both serve as a low-cost alternative, as well as a sanity check for any future LLM-based vision-language model extensions. We conduct an extensive experimental study on the impact and shortcomings of additional semantics introduced with LLM-generated descriptors, and showcase how - if available - semantic context is better leveraged by querying LLMs for high-level concepts, which we show can be done to jointly resolve potential class name ambiguities. Code is available here: https://github.com/ExplainableML/WaffleCLIP.	[Roth, Karsten; Kim, Jae Myung; Koepke, A. Sophia; Akata, Zeynep] Univ Tubingen, Tubingen AI Ctr, Tubingen, Germany; [Vinyals, Oriol] Google DeepMind, Mountain View, CA USA; [Schmid, Cordelia] PSL Res Univ, CNRS, Ecole Normale Super, Inria, Paris, France; [Akata, Zeynep] MPI Intelligent Syst, Stuttgart, Germany	Eberhard Karls University of Tubingen; Inria; Centre National de la Recherche Scientifique (CNRS); Universite PSL; Ecole Normale Superieure (ENS); Max Planck Society	Roth, K (corresponding author), Univ Tubingen, Tubingen AI Ctr, Tubingen, Germany.				DFG [276693517]; BMBF [FKZ: 01IS18039A]; ERC [853489 -DEXIM]; EXC [2064/1, 390727645]; European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program; International Max Planck Research School for Intelligent Systems (IMPRS-IS)	DFG(German Research Foundation (DFG)); BMBF(Federal Ministry of Education & Research (BMBF)); ERC(European Research Council (ERC)); EXC; European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program; International Max Planck Research School for Intelligent Systems (IMPRS-IS)	This work was supported by DFG project number 276693517, by BMBF FKZ: 01IS18039A, by the ERC (853489 -DEXIM), and by EXC number 2064/1 -project number 390727645. KR and JMK thank the European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program and the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for support.	Bahng H, 2022, Arxiv, DOI arXiv:2203.17274; Bansal H, 2023, Arxiv, DOI arXiv:2302.02503; BELINKOV Y., 2018, INT C LEARN REPR; Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bujwid Sebastian, 2021, WORKSH VIS LANG TEGR; Chen AC, 2023, Arxiv, DOI arXiv:2211.11635; Chen Guangyi, 2023, ICLR; Chen JA, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2147; Cheng Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1756; Choudhury Subhabrata, 2021, BMVC; Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461; Davidson TR, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P856; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dunlap Lisa, 2023, Using language to extend to unseen domains; Elhoseiny M, 2017, PROC CVPR IEEE, P6288, DOI 10.1109/CVPR.2017.666; Feng SY, 2021, ARXIV; Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x; Hao XS, 2023, IEEE WINT CONF APPL, P379, DOI 10.1109/WACVW58289.2023.00042; He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775; Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242; Hendrycks D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8320, DOI 10.1109/ICCV48922.2021.00823; Hendrycks D, 2021, PROC CVPR IEEE, P15257, DOI 10.1109/CVPR46437.2021.01501; Huang T., 2022, arXiv; Kirchhof Michael, 2022, ECCV; Kobayashi S., 2018, P 2018 C N AM CHAPT, P452; Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Loedeman J, 2023, Arxiv, DOI arXiv:2210.06466; Lu YN, 2022, PROC CVPR IEEE, P5196, DOI 10.1109/CVPR52688.2022.00514; Maji S, 2013, Arxiv, DOI arXiv:1306.5151; Mao Chengzhi, 2023, Doubly right object recognition: A why prompt for visual rationales; Menon Sachit, 2023, ICLR; Miller GA., 1998, Wordnet: an electronic lexical database; Naeem Muhammad Ferjad, 2022, NeurIPS; Naeem Muhammad Ferjad, 2023, CVPR; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Niu Xing, 2020, ACL; Novack Z, 2023, Arxiv, DOI arXiv:2302.02551; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Paszke A, 2019, ADV NEUR IN, V32; Paz-Argaman Tzuf, 2020, EMNLP; Pratt S, 2023, Arxiv, DOI arXiv:2209.03320; QI XIAOJUAN, 2023, ICLR; Radford A, 2021, PR MACH LEARN RES, V139; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Roth K., 2022, CVPR; Roth K, 2022, PROC CVPR IEEE, P16156, DOI 10.1109/CVPR52688.2022.01570; Sahin GG, 2022, COMPUT LINGUIST, V48, P5, DOI 10.1162/coli_a_00425; Shen S, 2022, Arxiv, DOI arXiv:2204.09222; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Shu ML, 2022, Arxiv, DOI arXiv:2209.07511; Sun Lichao, 2020, Computational Linguistics; TongzhouWang Phillip, 2020, ICML; Udandarao V, 2023, Arxiv, DOI arXiv:2211.16198; Varanasi Stalin, 2018, How robust are character-based word embeddings in tagging and mt against wrod scramlbing or randdm nouse?; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang HH, 2019, ADV NEUR IN, V32; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Wu JY, 2023, Arxiv, DOI arXiv:2212.10556; Xing YH, 2022, Arxiv, DOI arXiv:2208.08340; Yuksekgonul M., 2023, 11 INT C LEARN REPR; Zhang H., 2018, ICLR; Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1; Zimmermann Roland S., 2021, ICML	67	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							15700	15711		10.1109/ICCV51070.2023.01443	http://dx.doi.org/10.1109/ICCV51070.2023.01443			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO		Green Submitted			2024-07-03	WOS:001169500500007
J	Lankford, S; Afli, H; Way, A				Lankford, Seamus; Afli, Haithem; Way, Andy			adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds	INFORMATION			English	Article						MLLMs; LLMs; multilingual language models; large language models; low-resource languages; neural machine translation; human evaluation; Irish; Marathi		The advent of Multilingual Language Models (MLLMs) and Large Language Models (LLMs) has spawned innovation in many areas of natural language processing. Despite the exciting potential of this technology, its impact on developing high-quality Machine Translation (MT) outputs for low-resource languages remains relatively under-explored. Furthermore, an open-source application, dedicated to both fine-tuning MLLMs and managing the complete MT workflow for low-resources languages, remains unavailable. We aim to address these imbalances through the development of adaptMLLM, which streamlines all processes involved in the fine-tuning of MLLMs for MT. This open-source application is tailored for developers, translators, and users who are engaged in MT. It is particularly useful for newcomers to the field, as it significantly streamlines the configuration of the development environment. An intuitive interface allows for easy customisation of hyperparameters, and the application offers a range of metrics for model evaluation and the capability to deploy models as a translation service directly within the application. As a multilingual tool, we used adaptMLLM to fine-tune models for two low-resource language pairs: English to Irish (EN <-> GA) and English to Marathi (EN <-> MR). Compared with baselines from the LoResMT2021 Shared Task, the adaptMLLM system demonstrated significant improvements. In the EN -> GA direction, an improvement of 5.2 BLEU points was observed and an increase of 40.5 BLEU points was recorded in the GA -> EN direction representing relative improvements of 14% and 117%, respectively. Significant improvements in the translation performance of the EN <-> MR pair were also observed notably in the MR -> EN direction with an increase of 21.3 BLEU points which corresponds to a relative improvement of 68%. Finally, a fine-grained human evaluation of the MLLM output on the EN -> GA pair was conducted using the Multidimensional Quality Metrics and Scalar Quality Metrics error taxonomies. The application and models are freely available.	[Lankford, Seamus; Way, Andy] Dublin City Univ, ADAPT Ctr, Sch Comp, Dublin D09 DXA0, Ireland; [Lankford, Seamus; Afli, Haithem] Munster Technol Univ, Dept Comp Sci, Cork T12 P928, Ireland	Dublin City University	Lankford, S (corresponding author), Dublin City Univ, ADAPT Ctr, Sch Comp, Dublin D09 DXA0, Ireland.; Lankford, S (corresponding author), Munster Technol Univ, Dept Comp Sci, Cork T12 P928, Ireland.	seamus.lankford@mtu.ie		Way, Andy/0000-0001-5736-5930; Lankford, Seamus/0000-0003-1693-9533	Science Foundation Ireland through ADAPT Centre at Dublin City University [13/RC/2106]; Staff Doctorate Scheme at the Munster Technological University	Science Foundation Ireland through ADAPT Centre at Dublin City University(Science Foundation Ireland); Staff Doctorate Scheme at the Munster Technological University	This research is supported by Science Foundation Ireland through ADAPT Centre (Grant 13/RC/2106) (https://www.adaptcentre.ie, accessed on 22 November 2023) at Dublin City University. This research was also funded by the Staff Doctorate Scheme at the Munster Technological University.	Abid A, 2019, Arxiv, DOI [arXiv:1906.02569, DOI 10.48550/ARXIV.1906.02569]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Artstein R, 2017, Handbook of linguistic annotation, P297; Bannour N., 2021, P 2 WORKSHOP SIMPLE, P11, DOI DOI 10.18653/V1/2021.SUSTAINLP-1.2; Bayon M.D.C., 2019, P MACHINE TRANSLATIO, P30; Belz A., 2021, P WORKSHOP HUMAN EVA; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bisong E., 2019, BUILDING MACHINE LEA; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Callison-Burch C., 2014, P 2 WORKSH STAT MACH, P136; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Costa-jussa, 2022, arXiv, DOI DOI 10.48550/ARXIV.2207.04672; Denkowski M., 2016, P 9 WORKSH STAT MACH, P376; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Freitag M, 2021, T ASSOC COMPUT LING, V9, P1460, DOI 10.1162/tacl_a_00437; Henderson P, 2020, J MACH LEARN RES, V21; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Iftikhar L., 2023, EC Paediatrics, V12, P45; Imankulova A., 2021, P MACH TRANSL SUMM 1; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Klubicka F, 2018, MACH TRANSL, V32, P195, DOI 10.1007/s10590-018-9214-x; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lacoste A, 2019, Arxiv, DOI [arXiv:1910.09700, 10.48550/arXiv.1910.09700]; Läubli S, 2020, J ARTIF INTELL RES, V67, P653; Lankford S., 2021, P 4 WORKSHOP TECHNOL, P144; Lankford S., 2021, P 18 BIENNIAL MACHIN, P48; Lankford S, 2023, LANG RESOUR EVAL, V57, P1671, DOI 10.1007/s10579-023-09671-2; Lankford S, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6753; Lankford S, 2022, INFORMATION, V13, DOI 10.3390/info13070309; Lepikhin D, 2020, Arxiv, DOI [arXiv:2006.16668, DOI 10.48550/ARXIV.2006.16668]; Lommel A., 2014, P 17 ANN C EUR ASS M, P165; Lommel A, 2018, MACH TRANS TECH APPL, V1, P109, DOI 10.1007/978-3-319-91241-7_6; Lommel A, 2014, TRADUMATICA, P455, DOI 10.5565/rev/tradumatica.77; Ma Q., 2017, P 2 C MACH TRANS AM, P598; Melamed I. D., 2003, COMPANION VOLUME P H, P61; Ojha A.K., 2021, P 4 WORKSHOP TECHNOL, P114; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Snover M., 2006, P 7 C ASS MACH TRANS, P223; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Vaswani A, 2017, ADV NEUR IN, V30; Winata G., 2011, P 1 WORKSH MULT REPR, P1; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38	50	1	1	6	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	DEC	2023	14	12							638	10.3390/info14120638	http://dx.doi.org/10.3390/info14120638			24	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	DG8L6		gold			2024-07-03	WOS:001130965600001
J	Collins, KM; Jiang, AQ; Frieder, S; Wong, LE; Zilka, M; Bhatt, U; Lukasiewicz, T; Wu, YH; Tenenbaum, JB; Hart, W; Gowers, T; Li, WD; Weller, A; Jamnik, M				Collins, Katherine M.; Jiang, Albert Q.; Frieder, Simon; Wong, Lionel; Zilka, Miri; Bhatt, Umang; Lukasiewicz, Thomas; Wu, Yuhuai; Tenenbaum, Joshua B.; Hart, William; Gowers, Timothy; Li, Wenda; Weller, Adrian; Jamnik, Mateja			Evaluating language models for mathematics through interactions	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						human-computer interaction; theorem proving; language models; AI		There is much excitement about the opportunity to harness the power of large language models (LLMs) when building problem -solving assistants. However, the standard methodology of evaluating LLMs relies on static pairs of inputs and outputs; this is insufficient for making an informed decision about which LLMs are best to use in an interactive setting, and how that varies by setting. Static assessment therefore limits how we understand language model capabilities. We introduce CheckMate, an adaptable prototype platform for humans to interact with and evaluate LLMs. We conduct a study with CheckMate to evaluate three language models (InstructGPT, ChatGPT, and GPT-4) as assistants in proving undergraduate -level mathematics, with a mixed cohort of participants from undergraduate students to professors of mathematics. We release the resulting interaction and rating dataset, MathConverse. By analyzing MathConverse, we derive a taxonomy of human query behaviors and uncover that despite a generally positive correlation, there are notable instances of divergence between correctness and perceived helpfulness in LLM generations, among other findings. Further, we garner a more granular understanding of GPT-4 mathematical problemsolving through a series of case studies, contributed by experienced mathematicians. We conclude with actionable takeaways for ML practitioners and mathematicians: models that communicate uncertainty, respond well to user corrections, and can provide a concise rationale for their recommendations, may constitute better assistants. Humans should inspect LLM output carefully given their current shortcomings and potential for surprising fallibility.	[Collins, Katherine M.; Jiang, Albert Q.; Zilka, Miri; Bhatt, Umang; Hart, William; Gowers, Timothy; Li, Wenda; Weller, Adrian; Jamnik, Mateja] Univ Cambridge, Cambridge CB2 1TN, England; [Frieder, Simon; Lukasiewicz, Thomas] Univ Oxford, Oxford OX1 4BH, England; [Wong, Lionel; Tenenbaum, Joshua B.] MIT, Cambridge, MA 02139 USA; [Bhatt, Umang; Weller, Adrian] Alan Turing Inst, London NW1 2DB, England; [Bhatt, Umang] NYU, New York, NY 10011 USA; [Lukasiewicz, Thomas] Vienna Univ Technol, A-1040 Vienna, Austria; [Wu, Yuhuai] x AI, New York, NY 10038 USA; [Gowers, Timothy] Coll France, F-75001 Paris, France	University of Cambridge; University of Oxford; Massachusetts Institute of Technology (MIT); New York University; Technische Universitat Wien; Universite PSL; College de France	Collins, KM; Jiang, AQ (corresponding author), Univ Cambridge, Cambridge CB2 1TN, England.	kmc61@cam.ac.uk; qc213@cam.ac.uk		Hart, William/0009-0003-3453-8394; Zilka, Miri/0000-0001-9640-8139	Marshall Commission; Cambridge Trust; Peterhouse Graduate Studentship; Alan Turing Institute under the EPSRC [EP/N510129/1]; ONR MURI [N00014-16-1-2007, N00014-22-1-2740]; Center for Brain, Minds, and Machines by NSF STC Award [CCF-1231216]; NSF [2214177, CCF-2217064, IIS-2212310]; Air Force Office of Scientific Research [FA9550-22-1-0249]; ARO [W911NF-23-1-0034]; Massachusetts Institute of Technology-International Business Machines (MIT-IBM) Watson AI Lab; MIT Quest for Intelligence; Leverhulme Trust [ECF-2021-429]; DeepMind; Leverhulme Trust via the Leverhulme Centre for the Future of Intelligence (CFI); European Lighthouse on Secure and Safe AI (ELSA); AXA Research Fund; EU TAILOR [952215]; ERC Advanced Grant ALEXANDRIA [GA 742178]; Turing AI Fellowship [EP/V025279/1]; ELSA; Leverhulme Trust via CFI; Engineering and Physical Sciences Research Council (EPSRC) [EP/T019603/1]	Marshall Commission; Cambridge Trust; Peterhouse Graduate Studentship; Alan Turing Institute under the EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ONR MURI(MURIUnited States Department of DefenseUnited States NavyOffice of Naval Research); Center for Brain, Minds, and Machines by NSF STC Award; NSF(National Science Foundation (NSF)); Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); ARO; Massachusetts Institute of Technology-International Business Machines (MIT-IBM) Watson AI Lab; MIT Quest for Intelligence; Leverhulme Trust(Leverhulme Trust); DeepMind; Leverhulme Trust via the Leverhulme Centre for the Future of Intelligence (CFI)(Leverhulme Trust); European Lighthouse on Secure and Safe AI (ELSA); AXA Research Fund(AXA Research Fund); EU TAILOR; ERC Advanced Grant ALEXANDRIA(European Research Council (ERC)); Turing AI Fellowship; ELSA; Leverhulme Trust via CFI(Leverhulme Trust); Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Special thanks to Fabian Gloeckle, for support and informative discussions throughout the project. We additionally thank in no particular order Anshula Gandhi, Jonas Bayer, Angeliki Koutsoukou-Argyraki, Fredy Yip, Mariusz Mirek, Gabriel Poesia, Noah Goodman, Valerie Chen, Nina Grgic-Hlaaa, Ilia Sucholutsky, Shoaib Ahmed Siddiqui, Ankit Anand, and Ced Zhang for valuable discussions around assistive systems in AI and mathematics, and Large Language Models (LLM). We are thankful to our reviewers for their thoughtful feedback. K.M.C. acknowledges support from the Marshall Commission and the Cambridge Trust. A.Q.J. acknowledges support from the Peterhouse Graduate Studentship. S.F. and T.L. acknowledge support from the Alan Turing Institute under the EPSRC Grant EP/N510129/1. L.W. and J.T. gratefully acknowledge support from ONR MURI Grant N00014-16-1-2007; from the Center for Brain, Minds, and Machines (funded by NSF STC Award CCF-1231216); from NSF Grant 2214177; from NSF Grant CCF-2217064 and IIS-2212310; from Air Force Office of Scientific Research Grant FA9550-22-1-0249; from ONR MURI grant N00014-22-1-2740; from ARO Grant W911NF-23-1-0034; from the Massachusetts Institute of Technology-International Business Machines (MIT-IBM) Watson AI Lab; from the MIT Quest for Intelligence. M.Z. acknowledges support from the Leverhulme Trust Grant ECF-2021-429. U.B. acknowledges support from DeepMind, the Leverhulme Trust via the Leverhulme Centre for the Future of Intelligence (CFI), and from European Lighthouse on Secure and Safe AI (ELSA). T.L. acknowledges support from the AXA Research Fund and the EU TAILOR Grant 952215. W.L. is supported by the ERC Advanced Grant ALEXANDRIA (Project GA 742178). A.W. acknowledges support from a Turing AI Fellowship under Grant EP/V025279/1, ELSA, and the Leverhulme Trust via CFI. M.J. acknowledges support from the Engineering and Physical Sciences Research Council (EPSRC) under Grant EP/T019603/1.	Akyürek AF, 2023, Arxiv, DOI arXiv:2305.08844; Amini A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2357; Anil R., 2023, PaLM 2 Technical Report; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Ba J., 2023, CSC413/2516 Winter 2023 University of Toronto; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bhatt U, 2024, Arxiv, DOI [arXiv:2304.06701, 10.48550/arXiv.2304.06701]; Bhatt U, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P401, DOI 10.1145/3461702.3462571; Bhatt U, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P648, DOI 10.1145/3351095.3375624; Bishop Phillip A, 2015, Int J Exerc Sci, V8, P297; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Burnell R, 2023, SCIENCE, V380, P136, DOI 10.1126/science.adf6369; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Collins K. M., Zenodo, DOI [10.5281/zenodo.11207783, DOI 10.5281/ZENODO.11207783]; Cummings M L., 2017, Decision making in aviation, P289, DOI 10.4324/9781315095080-17; Davies A, 2021, NATURE, V600, P70, DOI 10.1038/s41586-021-04086-x; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; Dziri N, 2023, Arxiv, DOI [arXiv:2305.18654, 10.48550/arXiv.2305.18654, DOI 10.48550/ARXIV.2305.18654]; First E, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P1229, DOI 10.1145/3611643.3616243; Frieder S., 2024, Adv. Neural Inf. Process Syst., V36; GitHub, 2021, GitHub copilot your AI pair programmer; Golovneva O, 2023, Arxiv, DOI arXiv:2212.07919; Gowers W. T., 2022, How can it be feasible to find proofs?; Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889; Jiang AQ, 2022, Arxiv, DOI arXiv:2210.12283; Kazemi M, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P6547; Kelly M., 2023, An Item Response Theory Approach; Kiciman E., 2023, Causal reasoning and large language models: Opening a new frontier for causality; Kocielnik R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300641; Kopf A., 2023, OPENASSISTANT CONVER; Lee M., 2022, Evaluating human-language model interaction; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517545; Li ZN, 2022, Arxiv, DOI [arXiv:2211.08671, 10.48550/arXiv.2211.08671, DOI 10.48550/ARXIV.2211.08671]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu BF, 2016, PUBLIC RELAT REV, V42, P479, DOI 10.1016/j.pubrev.2016.03.003; McGrath T, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2206625119; Meng Kevin, 2022, Advances in Neural Information Processing Systems, P17359; Miller T, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P333, DOI 10.1145/3593013.3594001; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Mitchell E., 2022, INT C MACHINE LEARNI, P15817; Moravec Hans., 1988, Mind Children: The Future of Robot and Human Intelligence; OpenAI, 2022, Introducing chatgpt; OpenAI, 2023, ChatGPT plugins; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ouyang L., 2022, NEURIPS; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Piantadosi S. T., 2022, NEURIPS 2022 WORKSH; Poesia G, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0044; Ringer T, 2020, CPP '20: PROCEEDINGS OF THE 9TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON CERTIFIED PROGRAMS AND PROOFS, P99, DOI 10.1145/3372885.3373823; Sevastjanova R., 2022, arXiv; Shen H, 2023, Arxiv, DOI [arXiv:2303.06333, 10.48550/arXiv.2303.06333, DOI 10.48550/ARXIV.2303.06333]; Si CL, 2023, Arxiv, DOI arXiv:2210.09150; Spiegelhalter D, 2017, ANNU REV STAT APPL, V4, P31, DOI 10.1146/annurev-statistics-010814-020148; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vasconcelos H., 2023, PREPRINT, DOI [DOI 10.48550/ARXIV.2302.07248, 10.48550/arXiv.2302.07248]; Wei JS, 2022, ADV NEUR IN; Welleck S., 2022, NeurIPS; Wilder B, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1526; Wong L, 2023, Arxiv, DOI [arXiv:2306.12672, 10.48550/arXiv.2306.12672, DOI 10.48550/ARXIV.2306.12672]; Wu ZX, 2024, Arxiv, DOI arXiv:2305.08809; Xiao Y., 2022, FINDINGS ASS COMPUTA, P7273; Zelikman E., 2022, Bootstrapping Reasoning With Reasoning; Zerilli J, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100455; Zheng K., 2022, 10 INT C LEARN REPR; Zhou D., 2023, Least-to-most prompting enables complex reasoning in large language models	68	0	0	2	2	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUN 11	2024	121	24							e2318124121	10.1073/pnas.2318124121	http://dx.doi.org/10.1073/pnas.2318124121			11	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UQ1C2	38830100	hybrid, Green Submitted			2024-07-03	WOS:001249422400005
J	Huang, YX; Gomaa, A; Semrau, S; Haderlein, M; Lettmaier, S; Weissmann, T; Grigo, J; Tkhayat, HB; Frey, B; Gaipl, U; Distel, L; Maier, A; Fietkau, R; Bert, C; Putz, F				Huang, Yixing; Gomaa, Ahmed; Semrau, Sabine; Haderlein, Marlen; Lettmaier, Sebastian; Weissmann, Thomas; Grigo, Johanna; Tkhayat, Hassen Ben; Frey, Benjamin; Gaipl, Udo; Distel, Luitpold; Maier, Andreas; Fietkau, Rainer; Bert, Christoph; Putz, Florian			Benchmarking ChatGPT-4 on a radiation oncology in-training exam and Red Journal Gray Zone cases: potentials and challenges for ai-assisted medical education and decision making in radiation oncology	FRONTIERS IN ONCOLOGY			English	Article						large language model; radiotherapy; natural language processing; artificial intelligence; Gray Zone; clinical decision support (CDS)	CANCER; THERAPY	PurposeThe potential of large language models in medicine for education and decision-making purposes has been demonstrated as they have achieved decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. This work aims to evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology.MethodsThe 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone cases are used to benchmark the performance of ChatGPT-4. The TXIT exam contains 300 questions covering various topics of radiation oncology. The 2022 Gray Zone collection contains 15 complex clinical cases.ResultsFor the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 62.05% and 78.77%, respectively, highlighting the advantage of the latest ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in radiation oncology are identified to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of statistics, CNS & eye, pediatrics, biology, and physics than knowledge of bone & soft tissue and gynecology, as per the ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 performs better in diagnosis, prognosis, and toxicity than brachytherapy and dosimetry. It lacks proficiency in in-depth details of clinical trials. For the Gray Zone cases, ChatGPT-4 is able to suggest a personalized treatment approach to each case with high correctness and comprehensiveness. Importantly, it provides novel treatment aspects for many cases, which are not suggested by any human experts.ConclusionBoth evaluations demonstrate the potential of ChatGPT-4 in medical education for the general public and cancer patients, as well as the potential to aid clinical decision-making, while acknowledging its limitations in certain domains. Owing to the risk of hallucinations, it is essential to verify the content generated by models such as ChatGPT for accuracy.	[Huang, Yixing; Gomaa, Ahmed; Semrau, Sabine; Haderlein, Marlen; Lettmaier, Sebastian; Weissmann, Thomas; Grigo, Johanna; Tkhayat, Hassen Ben; Frey, Benjamin; Gaipl, Udo; Distel, Luitpold; Fietkau, Rainer; Bert, Christoph; Putz, Florian] Friedrich Alexander Univ Erlangen Nurnberg, Univ Hosp Erlangen, Dept Radiat Oncol, Erlangen, Germany; [Huang, Yixing; Gomaa, Ahmed; Semrau, Sabine; Haderlein, Marlen; Lettmaier, Sebastian; Weissmann, Thomas; Grigo, Johanna; Frey, Benjamin; Gaipl, Udo; Distel, Luitpold; Fietkau, Rainer; Bert, Christoph; Putz, Florian] Comprehens Canc Ctr Erlangen EMN CCC ER EMN, Erlangen, Germany; [Tkhayat, Hassen Ben; Maier, Andreas] Friedrich Alexander Univ Erlangen Nurnberg, Pattern Recognit Lab, Erlangen, Germany	University of Erlangen Nuremberg; University of Erlangen Nuremberg	Putz, F (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Univ Hosp Erlangen, Dept Radiat Oncol, Erlangen, Germany.; Putz, F (corresponding author), Comprehens Canc Ctr Erlangen EMN CCC ER EMN, Erlangen, Germany.	Florian.Putz@uk-erlangen.de	Bert, Christoph/C-2585-2013	Bert, Christoph/0000-0002-8539-6600; Huang, Yixing/0000-0003-2627-3077; Putz, Florian/0000-0003-3966-2872				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Al-Rashdan A, 2022, INT J RADIAT ONCOL, V113, P489, DOI 10.1016/j.ijrobp.2020.09.036; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Amin MB, 2017, CA-CANCER J CLIN, V67, P93, DOI 10.3322/caac.21388; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Berghen C, 2022, INT J RADIAT ONCOL, V113, P252, DOI 10.1016/j.ijrobp.2021.03.014; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cats A, 2018, LANCET ONCOL, V19, P616, DOI 10.1016/S1470-2045(18)30132-3; Christiansen P, 2017, PSYCHOPHARMACOLOGY, V234, P827, DOI 10.1007/s00213-016-4518-0; de Boer SM, 2019, LANCET ONCOL, V20, P1273, DOI 10.1016/S1470-2045(19)30395-X; Ebrahimi B, 2023, INT J RADIAT ONCOL, V116, P977, DOI 10.1016/j.ijrobp.2023.03.075; Erlandsson J, 2017, LANCET ONCOL, V18, P336, DOI 10.1016/S1470-2045(17)30086-4; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Goodman CR, 2022, INT J RADIAT ONCOL, V114, P571, DOI 10.1016/j.ijrobp.2022.02.029; Hagag A., 2023, arXiv preprint arXiv:2306.14596, P1; Holmes J, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1219326; Hottinger AF, 2016, NEURO-ONCOLOGY, V18, P1338, DOI 10.1093/neuonc/now182; Huang YX, 2022, MED PHYS, V49, P5773, DOI 10.1002/mp.15863; Johnson J., 2021, Int J Radiat Oncol Biol Phys, V112, P4; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kirchheiner K, 2016, RADIOTHER ONCOL, V118, P160, DOI 10.1016/j.radonc.2015.12.025; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Mamounas EP, 2019, J CLIN ONCOL, V37, DOI 10.1200/JCO.2019.37.15_suppl.TPS600; Oertel M, 2022, STRAHLENTHER ONKOL, V198, P765, DOI 10.1007/s00066-022-01939-w; Open AI, 2023, OpenAI.com, P6; Palma David A, 2017, Int J Radiat Oncol Biol Phys, V97, P1, DOI 10.1016/j.ijrobp.2016.11.052; Phillips R, 2020, JAMA ONCOL, V6, P650, DOI 10.1001/jamaoncol.2020.0147; Prpic M, 2022, INT J RADIAT ONCOL, V112, P581, DOI 10.1016/j.ijrobp.2019.05.028; Rogacki K., 2021, Appl Radiat Oncol, V10, P41; Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264; Scarpelli DB, 2022, INT J RADIAT ONCOL, V113, P11, DOI 10.1016/j.ijrobp.2021.03.013; Shin M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2214840120; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Tchelebi LT, 2022, INT J RADIAT ONCOL, V114, P827, DOI 10.1016/j.ijrobp.2022.08.033; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tremont A, 2017, OCHSNER J, V17, P405; Vaswani A, 2017, ADV NEUR IN, V30; Waisberg E., 2023, Ir J Med Sci, P1; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P831, DOI 10.1109/JAS.2023.123552; Wang H., 2023, arXiv preprint arXiv:2304.06975, P1; Wang H, 2023, STRAHLENTHER ONKOL, V199, P485, DOI 10.1007/s00066-022-02039-5; Wang S., 2023, arXiv preprint arXiv:2302.07257, P1; Wei J., 2022, NEURIPS; Weissmann T, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1115258; Xing YX, 2020, MED PHYS, V47, P753, DOI 10.1002/mp.13953; Yang YH, 2022, STRAHLENTHER ONKOL, V198, P183, DOI 10.1007/s00066-021-01874-2; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	53	9	9	17	23	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2234-943X			FRONT ONCOL	Front. Oncol.	SEP 14	2023	13								1265024	10.3389/fonc.2023.1265024	http://dx.doi.org/10.3389/fonc.2023.1265024			13	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	AO0L7	37790756	gold, Green Published			2024-07-03	WOS:001119288400001
J	de Zarzà, I; de Curtò, J; Roig, G; Manzoni, P; Calafate, CT				de Zarza, I.; de Curto, J.; Roig, Gemma; Manzoni, Pietro; Calafate, Carlos T.			Emergent Cooperation and Strategy Adaptation in Multi-Agent Systems: An Extended Coevolutionary Theory with LLMs	ELECTRONICS			English	Article						multi-agent systems; human-computer interaction; large language models; cooperative games; game theory	ALGORITHM	The increasing complexity of Multi-Agent Systems (MASs), coupled with the emergence of Artificial Intelligence (AI) and Large Language Models (LLMs), have highlighted significant gaps in our understanding of the behavior and interactions of diverse entities within dynamic environments. Traditional game theory approaches have often been employed in this context, but their utility is limited by the static and homogenous nature of their models. With the transformative influence of AI and LLMs on business and society, a more dynamic and nuanced theoretical framework is necessary to guide the design and management of MASs. In response to this pressing need, we propose an Extended Coevolutionary (EC) Theory in this paper. This alternative framework incorporates key aspects of coevolutionary dynamics, adaptive learning, and LLM-based strategy recommendations to model and analyze the strategic interactions among heterogeneous agents in MASs. It goes beyond game theory by acknowledging and addressing the diverse interactions (economic transactions, social relationships, information exchange) and the variability in risk aversion, social preferences, and learning capabilities among entities. To validate the effectiveness of the EC framework, we developed a simulation environment that enabled us to explore the emergence of cooperation and defection patterns in MASs. The results demonstrated the potential of our framework to promote cooperative behavior and maintain robustness in the face of disruptions. The dynamics and evolution of the Multi-Agent System over time were also visualized using advanced techniques. Our findings underscore the potential of harnessing LLMs to facilitate cooperation, enhance social welfare, and promote resilient strategies in multi-agent environments. Moreover, the proposed EC framework offers valuable insights into the interplay between strategic decision making, adaptive learning, and LLM-informed guidance in complex, evolving systems. This research not only responds to the current challenges faced in modeling MASs, but also paves the way for future research in this rapidly developing field.	[de Zarza, I.; de Curto, J.; Roig, Gemma] Univ Frankfurt Main, Informat & Math, GOETHE, D-60323 Frankfurt, Germany; [de Zarza, I.; de Curto, J.; Manzoni, Pietro; Calafate, Carlos T.] Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain; [de Zarza, I.; de Curto, J.] Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicacio, Barcelona 08018, Spain; [Roig, Gemma] HESSIAN Ctr Hessian AI, D-64293 Darmstadt, Germany	Goethe University Frankfurt; Universitat Politecnica de Valencia; UOC Universitat Oberta de Catalunya	de Curtò, J (corresponding author), Univ Frankfurt Main, Informat & Math, GOETHE, D-60323 Frankfurt, Germany.; de Curtò, J (corresponding author), Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain.; de Curtò, J (corresponding author), Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicacio, Barcelona 08018, Spain.	dezarza@em.uni-frankfurt.de; decurto@em.uni-frankfurt.de; roig@cs.uni-frankfurt.de; pmanzoni@disca.upv.es; calafate@disca.upv.es		de Zarza i Cubero, I./0000-0002-5844-7871; de Curto y Diaz, J./0000-0002-8334-4719; Roig, Gemma/0000-0002-6439-8076	GOETHE-University Frankfurt am Main; MCIN/AEI [PID2021-122580NB-I00]; ERDF	GOETHE-University Frankfurt am Main; MCIN/AEI; ERDF(European Union (EU))	We thank the following funding sources from GOETHE-University Frankfurt am Main: DePP-Dezentrale Plannung von Platoons im Stra beta engueterverkehr mit Hilfe einer KI auf Basis einzelner LKW' and Center for Data Science & AI'. We acknowledge the support of R & D project PID2021-122580NB-I00, which is funded by MCIN/AEI/10.13039/501100011033 and ERDF.	Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]; Angeline P., 1993, Proceedings of the Second Annual Conference on Evolutionary Programming, P154; [Anonymous], 2002, ADV EC ECONOMETRICS, DOI 10.1017/CBO9780511610240.008; Axelrod R., 1997, Complexity, V3, P16, DOI 10.1002/(SICI)1099-0526(199711/12)3:2<16::AID-CPLX4>3.0.CO;2-K; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919; Camerer CF., 2003, Behavioral game theory: Experiments in strategic interaction; Deng ZY, 2022, IEEE T VEH TECHNOL, V71, P12461, DOI 10.1109/TVT.2022.3196366; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Fudenberg D, 1998, EUR ECON REV, V42, P631, DOI 10.1016/S0014-2921(98)00011-7; Gong DW, 2020, IEEE T EVOLUT COMPUT, V24, P142, DOI 10.1109/TEVC.2019.2912204; GRANOVETTER M, 1985, AM J SOCIOL, V91, P481, DOI 10.1086/228311; Gu Xiuye, 2021, arXiv; Gupta M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062422; Ho ED, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031032; Huang C., 2023, P IEEE INT C ROBOTIC; Li G, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9040420; Macy MW, 2002, ANNU REV SOCIOL, V28, P143, DOI 10.1146/annurev.soc.28.110601.141117; Meselhi MA, 2020, IEEE ACCESS, V8, P203369, DOI 10.1109/ACCESS.2020.3036438; Mitchell M., 1998, INTRO GENETIC ALGORI, DOI [10.7551/mitpress/3927.001.0001, DOI 10.1016/S0898-1221(96)90227-8]; Muglich D., 2022, Advances in Neural Information Processing Systems, V35, P6410; Myerson RB., 1991, GAME THEORY ANAL CON; NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48; NOWAK MA, 1992, NATURE, V359, P826, DOI 10.1038/359826a0; Oroojlooy A, 2023, APPL INTELL, V53, P13677, DOI 10.1007/s10489-022-04105-y; Osborne M.J, 2004, An introduction to game theory, V3; Rosin CD, 1997, EVOL COMPUT, V5, P1, DOI 10.1162/evco.1997.5.1.1; Shah D., 2022, P C ROB LEARN, V205, P492; Shoham Y, 2009, MULTIAGENT SYSTEMS: ALGORITHMIC, GAME-THEORETIC, AND LOGICAL FOUNDATIONS, P1; Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299; Stone P., 2010, P 9 INT C AUTONOMOUS, V1, P157; Vakhnin A, 2021, ALGORITHMS, V14, DOI 10.3390/a14050146; Vaswani A, 2017, ADV NEUR IN, V30; Von Neumann J, 1947, THEORY GAMES EC BEHA; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Weiss G, 1999, MULTIAGENT SYSTEMS, P1; Wooldridge M., 2009, An Introduction to Multiagent Systems; Yang M.S., 2022, Advances in Neural Information Processing Systems, V35, P36366; Yu C., 2022, ADV NEURAL INF PROCE, V35, P24611, DOI DOI 10.48550/ARXIV.2103.01955	39	4	4	34	57	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2023	12	12							2722	10.3390/electronics12122722	http://dx.doi.org/10.3390/electronics12122722			19	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	K5PW4		gold			2024-07-03	WOS:001016969200001
J	Porcelli, L; Mastroianni, M; Ficco, M; Palmieri, F				Porcelli, Lorenzo; Mastroianni, Michele; Ficco, Massimo; Palmieri, Francesco			A User-Centered Privacy Policy Management System for Automatic Consent on Cookie Banners	COMPUTERS			English	Article						Personal Information Management System (PIMS); User Privacy Policy Management System (UPPMS); privacy paradox; Large Language Model (LLM); Generative Pre-trained Transformer (GPT); cookie banner; Transparency and Consent Framework (TCF); General Data Protection Regulation (EU GDPR)	PARADOX	Despite growing concerns about privacy and an evolution in laws protecting users' rights, there remains a gap between how industries manage data and how users can express their preferences. This imbalance often favors industries, forcing users to repeatedly define their privacy preferences each time they access a new website. This process contributes to the privacy paradox. We propose a user support tool named the User Privacy Preference Management System (UPPMS) that eliminates the need for users to handle intricate banners or deceptive patterns. We have set up a process to guide even a non-expert user in creating a standardized personal privacy policy, which is automatically applied to every visited website by interacting with cookie banners. The process of generating actions to apply the user's policy leverages customized Large Language Models. Experiments demonstrate the feasibility of analyzing HTML code to understand and automatically interact with cookie banners, even implementing complex policies. Our proposal aims to address the privacy paradox related to cookie banners by reducing information overload and decision fatigue for users. It also simplifies user navigation by eliminating the need to repeatedly declare preferences in intricate cookie banners on every visited website, while protecting users from deceptive patterns.	[Porcelli, Lorenzo; Mastroianni, Michele; Ficco, Massimo; Palmieri, Francesco] Univ Salerno, Dept Comp Sci, I-84084 Fisciano, Italy	University of Salerno	Porcelli, L (corresponding author), Univ Salerno, Dept Comp Sci, I-84084 Fisciano, Italy.	lporcelli@unisa.it; mmastroianni@unisa.it; mficco@unisa.it; fpalmieri@unisa.it	Palmieri, Francesco/AAT-9080-2020; Mastroianni, Michele/AAK-4443-2020; Ficco, Massimo/I-5056-2017	Palmieri, Francesco/0000-0003-1760-5527; Mastroianni, Michele/0000-0001-6415-1180; Ficco, Massimo/0000-0003-4199-8199; Porcelli, Lorenzo/0009-0004-2539-2431	SERICS; Italian Ministry of University and Research	SERICS; Italian Ministry of University and Research(Ministry of Education, Universities and Research (MIUR))	This paper is part of the research activity carried out within the project PON "Ricerca e Innovazione" 2014-2020, action IV.6 "Contratti di ricerca su tematiche Green", issued by the Italian Ministry of University and Research.	Acquisti A, 2020, J CONSUM PSYCHOL, V30, P736, DOI 10.1002/jcpy.1191; Aguirre E, 2015, J RETAILING, V91, P34, DOI 10.1016/j.jretai.2014.09.005; Amaral O, 2023, 2023 IEEE 31 INT REQ, P53, DOI [10.1109/RE57278.2023.00015, DOI 10.1109/RE57278.2023.00015]; Athey S., DIGITAL PRIVACY PARA; Belcheva V, 2023, INFORMATION, V14, DOI 10.3390/info14110622; Degeling M, 2019, Arxiv, DOI arXiv:1808.05096; Fernandes T, 2023, J CONSUM MARK, V40, P181, DOI 10.1108/JCM-03-2021-4510; Gerber N, 2018, COMPUT SECUR, V77, P226, DOI 10.1016/j.cose.2018.04.002; Gur I, 2023, Arxiv, DOI [arXiv:2210.03945, 10.48550/arXiv.2210.03945, DOI 10.48550/ARXIV.2210.03945]; Habib H., 2022, P 2022 CHI C HUMAN F, P1; Hils Maximilian, 2021, Proceedings on Privacy Enhancing Technologies, V2021, P249, DOI 10.2478/popets-2021-0069; Hils Maximilian, 2020, IMC '20: Proceedings of the ACM Internet Measurement Conference, P317, DOI 10.1145/3419394.3423647; Iacono M., 2023, Computational Science and Its Applications - ICCSA 2023 Workshops: Proceedings. Lecture Notes in Computer Science (14109), P134, DOI 10.1007/978-3-031-37120-2_9; Machuletz Dominique, 2020, Proceedings on Privacy Enhancing Technologies, V2020, P481, DOI 10.2478/popets-2020-0037; Matte C, 2020, P IEEE S SECUR PRIV, P791, DOI 10.1109/SP40000.2020.00076; Mehrnezhad Maryam, 2022, Proceedings on Privacy Enhancing Technologies, V2022, P105, DOI 10.2478/popets-2022-0006; Nouwens M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376321; Overby H., 2019, Encyclopedia of Cryptography, Security and Privacy, P1, DOI [10.1007/978-3-642-27739-9_1619-1, DOI 10.1007/978-3-642-27739-9_1619-1]; Porcelli L., 2023, P INT C COMPUTATIONA, P145, DOI [10.1007/978-3-031-37108-0_10, DOI 10.1007/978-3-031-37108-0_10]; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Ravichander A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4125; Sánchez D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041762; Skiera B., The Impact of the General Data Protection Regulation (GDPR) on the Online Advertising Market; Solove DJ, 2021, GEORGE WASH LAW REV, V89, P1; Thaler RH, 2018, SCIENCE, V361, P431, DOI 10.1126/science.aau9241; Utz C, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P973, DOI 10.1145/3319535.3354212; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Zaeem RN, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3127519; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	29	0	0	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2073-431X			COMPUTERS	Computers	FEB	2024	13	2							43	10.3390/computers13020043	http://dx.doi.org/10.3390/computers13020043			21	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	JA2A5		gold			2024-07-03	WOS:001170351900001
J	Wang, ZP; Bhandary, P; Wang, YZ; Moore, JH				Wang, Zhiping Paul; Bhandary, Priyanka; Wang, Yizhou; Moore, Jason H.			Using GPT-4 to write a scientific review article: a pilot evaluation study	BIODATA MINING			English	Article							CHATGPT; AI	GPT-4, as the most advanced version of OpenAI's large language models, has attracted widespread attention, rapidly becoming an indispensable AI tool across various areas. This includes its exploration by scientists for diverse applications. Our study focused on assessing GPT-4's capabilities in generating text, tables, and diagrams for biomedical review papers. We also assessed the consistency in text generation by GPT-4, along with potential plagiarism issues when employing this model for the composition of scientific review papers. Based on the results, we suggest the development of enhanced functionalities in ChatGPT, aiming to meet the needs of the scientific community more effectively. This includes enhancements in uploaded document processing for reference materials, a deeper grasp of intricate biomedical concepts, more precise and efficient information distillation for table generation, and a further refined model specifically tailored for scientific diagram creation.	[Wang, Zhiping Paul; Bhandary, Priyanka; Wang, Yizhou; Moore, Jason H.] Cedars Sinai Med Ctr, Pacific Design Ctr, Dept Computat Biomed, 700 N San Vicente Blvd,Suite G-541, West Hollywood, CA 90069 USA	Cedars Sinai Medical Center	Moore, JH (corresponding author), Cedars Sinai Med Ctr, Pacific Design Ctr, Dept Computat Biomed, 700 N San Vicente Blvd,Suite G-541, West Hollywood, CA 90069 USA.	jason.moore@csmc.edu						Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Alshami A, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11070351; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Broestl L., 2021, ENDOCRINOLOGY, V162, pbqab192, DOI [10.1210/endocr/bqab192, DOI 10.1210/ENDOCR/BQAB192]; ChatGPT and Academic Integrity Concerns, Detecting Artificial Intelligence Generated Content | Language Education and Technology; Chen DS, 2013, IMMUNITY, V39, P1, DOI 10.1016/j.immuni.2013.07.012; Conroy G, 2023, NATURE, V622, P234, DOI 10.1038/d41586-023-03144-w; Dhillon P, 2022, FEBS J, V289, P3592, DOI 10.1111/febs.16565; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Homolak J, 2023, CROAT MED J, V64, P293; Huang JS, 2023, AM J CANCER RES, V13, P1148; Introducing Gemini, Google's most capable AI model yet; Jin BW, 2024, Arxiv, DOI [arXiv:2312.02783, 10.48550/arXiv.2312.02783]; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Misra DP, 2023, J ROY COLL PHYS EDIN, V53, P90, DOI 10.1177/14782715231181023; Mondal H, 2023, INDIAN J OPHTHALMOL, V71, P3600, DOI 10.4103/IJO.IJO_718_23; nature, Health sciences added to the Nature Index. | News | Nature Index; nature, ChatGPT listed as author on research papers. many scientists disapprove; Polkinghorn WR, 2013, CANCER DISCOV, V3, P1245, DOI 10.1158/2159-8290.CD-13-0172; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Rubin JB, 2022, TRENDS CANCER, V8, P303, DOI 10.1016/j.trecan.2022.01.013; Scopus AI, Trusted content. Powered by responsible AI; Van Noorden R, 2023, NATURE, V621, P672, DOI 10.1038/d41586-023-02980-0; Yuan HY, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P97	29	0	0	0	0	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1756-0381			BIODATA MIN	BioData Min.	JUN 18	2024	17	1							16	10.1186/s13040-024-00371-3	http://dx.doi.org/10.1186/s13040-024-00371-3			14	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	UQ9E0	38890715	gold			2024-07-03	WOS:001249633000001
C	Nozza, D; Bianchi, F; Lauscher, A; Hovy, D			Assoc Computat Linguist	Nozza, Debora; Bianchi, Federico; Lauscher, Anne; Hovy, Dirk			Measuring Harmful Sentence Completion in Language Models for LGBTQIA plus Individuals	PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022)			English	Proceedings Paper	2nd Workshop on Language Technology for Equality, Diversity and Inclusion (LTEDI)	MAY 27, 2022	Dublin, IRELAND	OE Gaillimh NUI Galway, Irish Res Council, Insight, Sci Fdn Ireland, Microsoft Res, SSN				Warning: This paper contains examples of language that some people may find offensive or upsetting. Current language technology is ubiquitous and directly influences individuals' lives worldwide. Given the recent trend in AI on training and constantly releasing new and powerful large language models (LLMs), there is a need to assess their biases and potential concrete consequences. While some studies have highlighted the shortcomings of these models, there is only little on the negative impact of LLMs on LGBTQIA+ individuals. In this paper, we investigated a state-of-the-art template-based approach for measuring the harmfulness of English LLMs sentence completion when the subjects belong to the LGBTQIA+ community. Our findings show that, on average, the most likely LLM-generated completion is an identity attack 13% of the time. Our results raise serious concerns about the applicability of these models in production environments.	[Nozza, Debora; Bianchi, Federico; Lauscher, Anne; Hovy, Dirk] Bocconi Univ, Via Sarfatti 25, Milan, Italy	Bocconi University	Nozza, D (corresponding author), Bocconi Univ, Via Sarfatti 25, Milan, Italy.	debora.nozza@unibocconi.it; f.bianchi@unibocconi.it; anne.lauscher@unibocconi.it; dirk.hovy@unibocconi.it	Bianchi, Federico/JZT-6891-2024; Nozza, Debora/AAD-7453-2019	Bianchi, Federico/0000-0002-6155-5531; Nozza, Debora/0000-0002-7998-2267	European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program [949944]; Fondazione Cariplo [2020-4288]	European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program(European Research Council (ERC)); Fondazione Cariplo(Fondazione Cariplo)	This project has partially received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (grant agreement No. 949944, INTEGRATOR), and by Fondazione Cariplo (grant No. 2020-4288, MONICA). Debora Nozza, Federico Bianchi, Anne Lauscher, and Dirk Hovy are members of the MilaNLP group, and the Data and Marketing Insights Unit of the Bocconi Institute for Data Science and Analysis.	Attanasio Giuseppe, 2022, P 1 WORKSHOP EFFICIE; Attanasio Giuseppe, 2022, FINDINGS ASS COMPUTA; Attanasio Giuseppe, 2020, EVALITA EVALUATION N, P48; Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Basile Valerio, 2019, P 13 INT WORKSHOP SE, P54, DOI [DOI 10.18653/V1/S19-2007, 10.18653/v1/S19-2007]; Bassignana Elisa, 2018, P CLIC IT; Bharathi Raja Chakravarthi, 2022, P 2 WORKSHOP LANGUAG; Bianchi F, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10065; Bianchi F, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3895; Bianchi Federico, 2022, P 1 WORKSHOP EFFICIE; Bolukbasi T, 2016, ADV NEUR IN, V29; Cao Qingqing., 2020, Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing, P141; Chiril P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1397; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Dev S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1968; Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659; Devlin J., 2018, BERT PRE TRAINING DE; Fersini E., 2018, EVALITA CLIC IT; Fersini E., 2020, Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language, P9; Fersini Elisabetta, 2020, P 7 EVALUATION CAMPA; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Hosseini H, 2017, Arxiv, DOI arXiv:1702.08138; Hovy D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P591; Kennedy B, 2022, LANG RESOUR EVAL, V56, P79, DOI 10.1007/s10579-021-09569-x; Lauscher A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4782; Lauscher A, 2022, Arxiv, DOI arXiv:2202.11923; Lauscher A, 2020, AAAI CONF ARTIF INTE, V34, P8131; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Manzini Thomas, 2019, P 2019 C N AM CHAPTE, V1, P615; McGaughey Sebastian., 2020, GAY LESBIAN REV WORL, V27, P27; Mollas I, 2022, COMPLEX INTELL SYST, V8, P4663, DOI 10.1007/s40747-021-00608-2; Mulki H, 2021, ACM INT CONF PR SER, P7, DOI 10.1145/3503162.3503178; Nadeem Moin, P 59 ANN M ASS COMPU, V1, P5356; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nozza D, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P907; Nozza D, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P149, DOI 10.1145/3350546.3352512; Nozza Debora, 2022, P 2 WORKSHOP LANGUAG; Nozza Debora, 2022, P 1 WORKSHOP CHALLEN; Nozza Debora, 2021, P 2021 C N AM CHAPTE, P2398; Ousidhoum N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4262; Ousidhoum N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4675; Park Ji Ho, 2018, ARXIV180807231; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Röttger P, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P41; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Sun T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1630; Wolf Thomas, 2020, 2020 C EMP METH NAT; Zeinert Philine, P 59 ANN M ASS COMPU, V1, P3181	50	7	7	4	6	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-43-8				2022							26	34						9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Social Issues	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Issues	BT7BS					2024-07-03	WOS:000847166600004
J	Liu, JQJ; Hui, KTK; Al Zoubi, F; Zhou, ZZX; Samartzis, D; Yu, CCH; Chang, JR; Wong, AYL				Liu, Jae Q. J.; Hui, Kelvin T. K.; Al Zoubi, Fadi; Zhou, Zing Z. X.; Samartzis, Dino; Yu, Curtis C. H.; Chang, Jeremy R.; Wong, Arnold Y. L.			The great detectives: humans versus AI detectors in catching large language model-generated medical writing	INTERNATIONAL JOURNAL FOR EDUCATIONAL INTEGRITY			English	Article						Artificial intelligence; ChatGPT; Paraphrasing tools; Generative AI; Academic integrity; AI content detectors; Peer review; Perplexity scores; Scientific rigour; Accuracy	CHATGPT	Background The application of artificial intelligence (AI) in academic writing has raised concerns regarding accuracy, ethics, and scientific rigour. Some AI content detectors may not accurately identify AI-generated texts, especially those that have undergone paraphrasing. Therefore, there is a pressing need for efficacious approaches or guidelines to govern AI usage in specific disciplines.Objective Our study aims to compare the accuracy of mainstream AI content detectors and human reviewers in detecting AI-generated rehabilitation-related articles with or without paraphrasing.Study design This cross-sectional study purposively chose 50 rehabilitation-related articles from four peer-reviewed journals, and then fabricated another 50 articles using ChatGPT. Specifically, ChatGPT was used to generate the introduction, discussion, and conclusion sections based on the original titles, methods, and results. Wordtune was then used to rephrase the ChatGPT-generated articles. Six common AI content detectors (Originality.ai, Turnitin, ZeroGPT, GPTZero, Content at Scale, and GPT-2 Output Detector) were employed to identify AI content for the original, ChatGPT-generated and AI-rephrased articles. Four human reviewers (two student reviewers and two professorial reviewers) were recruited to differentiate between the original articles and AI-rephrased articles, which were expected to be more difficult to detect. They were instructed to give reasons for their judgements.Results Originality.ai correctly detected 100% of ChatGPT-generated and AI-rephrased texts. ZeroGPT accurately detected 96% of ChatGPT-generated and 88% of AI-rephrased articles. The areas under the receiver operating characteristic curve (AUROC) of ZeroGPT were 0.98 for identifying human-written and AI articles. Turnitin showed a 0% misclassification rate for human-written articles, although it only identified 30% of AI-rephrased articles. Professorial reviewers accurately discriminated at least 96% of AI-rephrased articles, but they misclassified 12% of human-written articles as AI-generated. On average, students only identified 76% of AI-rephrased articles. Reviewers identified AI-rephrased articles based on 'incoherent content' (34.36%), followed by 'grammatical errors' (20.26%), and 'insufficient evidence' (16.15%).Conclusions and relevance This study directly compared the accuracy of advanced AI detectors and human reviewers in detecting AI-generated medical writing after paraphrasing. Our findings demonstrate that specific detectors and experienced reviewers can accurately identify articles generated by Large Language Models, even after paraphrasing. The rationale employed by our reviewers in their assessments can inform future evaluation strategies for monitoring AI usage in medical education or publications. AI content detectors may be incorporated as an additional screening tool in the peer-review process of academic journals.	[Liu, Jae Q. J.; Hui, Kelvin T. K.; Al Zoubi, Fadi; Zhou, Zing Z. X.; Yu, Curtis C. H.; Chang, Jeremy R.; Wong, Arnold Y. L.] Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Peoples R China; [Samartzis, Dino] Rush Univ, Med Ctr, Dept Orthoped Surg, Chicago, IL USA	Hong Kong Polytechnic University; Rush University	Wong, AYL (corresponding author), Hong Kong Polytech Univ, Dept Rehabil Sci, Hong Kong, Peoples R China.	arnold.wong@polyu.edu.hk		Al Zoubi, Fadi/0000-0002-7950-8979; WONG, Arnold YL/0000-0002-5911-5756	GP Batteries Industrial Safety Trust Fund (R-ZDDR)	GP Batteries Industrial Safety Trust Fund (R-ZDDR)	The current study was supported by the GP Batteries Industrial Safety Trust Fund (R-ZDDR).	Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; [Anonymous], 2023, Scholar Hangout; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; ChatGPT Statistics, 2023, Detailed Insights On Users; Crothers E., 2023, Machine-generated text: a comprehensive survey of threat models and detection methods; Fisher JS, 2018, J MEM LANG, V102, P130, DOI 10.1016/j.jml.2018.05.008; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; GPTZero, 2023, How do I interpret burstiness or perplexity?; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Imran M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13605; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Liang WX, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100779; Manohar N, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34616; Mehnen L, 2023, medRxiv, DOI [10.1101/2023.04.20.23288859, 10.1101/2023.04.20.23288859, DOI 10.1101/2023.04.20.23288859]; OpenAI, 2023, Introducing chatgpt; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Prillaman McKenzie, 2023, Nature, DOI 10.1038/d41586-023-03479-4; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Top 10 AI Detector Tools, 2023, You Should Use; Walters WH., 2023, Open Information Science, V7, P20220158, DOI [10.1515/opis-2022-0158, DOI 10.1515/OPIS-2022-0158]; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942; Weber-Wulff D, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00146-z; Welding L., 2023, BestCollegesMarch 17; Wordtune, 2023, About us; Yeadon Will, 2023, Physics Education, DOI 10.1088/1361-6552/acc5cf; Zong H, 2023, medRxiv	30	0	0	6	6	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1833-2595			INT J EDUC INTEGR	Int. J. Educ. Intege.	MAY 20	2024	20	1							8	10.1007/s40979-024-00155-6	http://dx.doi.org/10.1007/s40979-024-00155-6			14	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	RJ9D9		gold			2024-07-03	WOS:001227405700001
J	Zhang, X; Zhou, ZC; Ming, C; Sun, YY				Zhang, Xiang; Zhou, Zichun; Ming, Chen; Sun, Yi-Yang			GPT-Assisted Learning of Structure-Property Relationships by Graph Neural Networks: Application to Rare-Earth-Doped Phosphors	JOURNAL OF PHYSICAL CHEMISTRY LETTERS			English	Article							PYTHON LIBRARY; EU2+	Two challenges facing machine learning tasks in materials science are data set construction and descriptor design. Graph neural networks circumvent the need for empirical descriptors by encoding geometric information in graphs. Large language models have shown promise for database construction via text extraction. Here, we apply OpenAI's Generative Pre-trained Transformer 4 (GPT-4) and the Crystal Graph Convolutional Neural Network (CGCNN) to the problem of discovering rare-earth-doped phosphors for solid-state lighting. We used GPT-4 to datamine the chemical formulas and emission wavelengths of 264 Eu2+-doped phosphors from 274 articles. A CGCNN model was trained on the acquired data set, achieving a test R (2) of 0.77. Using this model, we predicted the emission wavelengths of over 40 000 inorganic materials. We also used transfer learning to fine-tune a bandgap-predicting CGCNN model for emission wavelength prediction. The workflow requires minimal human supervision and is generalizable to other fields.	[Zhang, Xiang; Zhou, Zichun; Ming, Chen; Sun, Yi-Yang] Chinese Acad Sci, Shanghai Inst Ceram, State Key Lab High Performance Ceram & Superfine M, Shanghai 201899, Peoples R China	Chinese Academy of Sciences; Shanghai Institute of Ceramics, CAS	Sun, YY (corresponding author), Chinese Acad Sci, Shanghai Inst Ceram, State Key Lab High Performance Ceram & Superfine M, Shanghai 201899, Peoples R China.	yysun@mail.sic.ac.cn	Sun, Yi-Yang/HLX-6133-2023; Ming, Chen/GLN-5980-2022; ZHANG, Changbo/D-5745-2015	ZHANG, Changbo/0000-0003-3435-0247; Liu, Zhongqi/0000-0001-7955-5831; Zhang, Xiang/0009-0000-7503-0835	National Key Research and Development Program of China [2021YFB3500501]; National Key Research and Development Program of China	National Key Research and Development Program of China; National Key Research and Development Program of China	Xiang Zhang is grateful to Professor J. C. Grossman for his guidance and the opportunity to study in his group. This work is supported by the National Key Research and Development Program of China under Grant 2021YFB3500501.	Anil R., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.10403; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Barai VL, 2019, J LUMIN, V208, P437, DOI 10.1016/j.jlumin.2019.01.008; Behler J, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.146401; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Choudhary K, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00650-1; Costa D. S., 2021, P THE21ST ACM S DOCU; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dorenbos P, 2003, J LUMIN, V104, P239, DOI 10.1016/S0022-2313(03)00078-4; Frieder S., 2023, Neural Information Processing SystemsDatasets and Benchmarks Track, parXiv:2301.13867, DOI [10.48550/arXiv.2301.13867, DOI 10.48550/ARXIV.2301.13867]; Fung V, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00554-0; George NC, 2013, ANNU REV MATER RES, V43, P481, DOI 10.1146/annurev-matsci-073012-125702; Gilmer J, 2017, PR MACH LEARN RES, V70; Gori M, 2005, IEEE IJCNN, P729; Hawizy L, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-17; Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Jensen Z, 2021, ACS CENTRAL SCI, V7, P858, DOI 10.1021/acscentsci.1c00024; Jessop DM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-41; Jiang L., 2022, J. Mater. Informatics, V2, P14, DOI [10.20517/jmi.2022.21, DOI 10.20517/JMI.2022.21]; Kim TG, 2023, J SCI-ADV MATER DEV, V8, DOI 10.1016/j.jsamd.2023.100550; Kingma D. P., 2017, ARXIV; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Knox W. B., 2011, PROCEEDINGSOF ICML W; Kohlschu''tter C., 2010, P OFTHE 3 ACM INT C; Kononova O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102155; Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1; Koyama Y, 2023, MATER ADV, V4, P231, DOI 10.1039/d2ma00881e; Krallinger M, 2017, CHEM REV, V117, P7673, DOI 10.1021/acs.chemrev.6b00851; Lai SQ, 2022, ACS MATER AU, V2, P374, DOI 10.1021/acsmaterialsau.1c00081; Lai SQ, 2020, J PHYS CHEM LETT, V11, P5680, DOI 10.1021/acs.jpclett.0c01471; MacFarlane J., 2023, Pandoc; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Mathpix Inc., 2020, Mathpix; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; NAKAMURA S, 1994, APPL PHYS LETT, V64, P1687, DOI 10.1063/1.111832; Ong SP, 2013, COMP MATER SCI, V68, P314, DOI 10.1016/j.commatsci.2012.10.028; OpenAI, 2023, GPT-4 Technical Report, DOI [10.48550/arXiv.2303.08774, DOI 10.48550/ARXIV.2303.08774]; PARR TJ, 1995, SOFTWARE PRACT EXPER, V25, P789, DOI 10.1002/spe.4380250705; Paszke A, 2019, ADV NEUR IN, V32; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Qin X, 2017, CHEM REV, V117, P4488, DOI 10.1021/acs.chemrev.6b00691; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reiser P, 2022, COMMUN MATER, V3, DOI 10.1038/s43246-022-00315-6; Saal JE, 2013, JOM-US, V65, P1501, DOI 10.1007/s11837-013-0755-4; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Thoppilan R., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2201.08239; Togo A, 2015, SCRIPTA MATER, V108, P1, DOI 10.1016/j.scriptamat.2015.07.021; Vaswani A, 2017, ADV NEUR IN, V30; Wang L, 2018, CHEM REV, V118, P1951, DOI 10.1021/acs.chemrev.7b00284; Xiao Z., 2023, bioRxiv, p2023, DOI [10.1101/2023.06.14.544984, DOI 10.1101/2023.06.14.544984]; Xie T, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.145301; Zagorac D, 2019, J APPL CRYSTALLOGR, V52, P918, DOI 10.1107/S160057671900997X	57	2	2	13	13	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1948-7185			J PHYS CHEM LETT	J. Phys. Chem. Lett.	DEC 8	2023	14	50					11342	11349		10.1021/acs.jpclett.3c02848	http://dx.doi.org/10.1021/acs.jpclett.3c02848			8	Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Atomic, Molecular & Chemical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	CZ3S0	38064589	Green Submitted			2024-07-03	WOS:001129019200001
J	Granitzer, M; Voigt, S; Fathima, NA; Golasowski, M; Guetl, C; Hecking, T; Hendriksen, G; Hiemstra, D; Martinovic, J; Mitrovic, J; Mlakar, I; Moiras, S; Nussbaumer, A; Oester, P; Potthast, M; Srdic, MS; Megi, S; Slaninova, K; Stein, B; de Vries, AP; Vondrak, V; Wagner, A; Zerhoudi, S				Granitzer, Michael; Voigt, Stefan; Fathima, Noor Afshan; Golasowski, Martin; Guetl, Christian; Hecking, Tobias; Hendriksen, Gijs; Hiemstra, Djoerd; Martinovic, Jan; Mitrovic, Jelena; Mlakar, Izidor; Moiras, Stavros; Nussbaumer, Alexander; oester, Per; Potthast, Martin; Srdic, Marjana Sencar; Megi, Sharikadze; Slaninova, Katerina; Stein, Benno; de Vries, Arjen P.; Vondrak, Vit; Wagner, Andreas; Zerhoudi, Saber			Impact and development of an Open Web Index for open web search	JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article								Web search is a crucial technology for the digital economy. Dominated by a few gatekeepers focused on commercial success, however, web publishers have to optimize their content for these gatekeepers, resulting in a closed ecosystem of search engines as well as the risk of publishers sacrificing quality. To encourage an open search ecosystem and offer users genuine choice among alternative search engines, we propose the development of an Open Web Index (OWI). We outline six core principles for developing and maintaining an open index, based on open data principles, legal compliance, and collaborative technology development. The combination of an open index with what we call declarative search engines will facilitate the development of vertical search engines and innovative web data products (including, e.g., large language models), enabling a fair and open information space. This framework underpins the EU-funded project OpenWebSearch.EU, marking the first step towards realizing an Open Web Index.	[Granitzer, Michael; Mitrovic, Jelena; Zerhoudi, Saber] Univ Passau, Passau, Germany; [Voigt, Stefan] Open Search Fdn, Starnberg, Germany; [Voigt, Stefan; Hecking, Tobias] German Aerosp Ctr DLR, Cologne, Germany; [Fathima, Noor Afshan; Moiras, Stavros] CERN, Geneva, Switzerland; [Golasowski, Martin; Vondrak, Vit] Tech Univ Ostrava, VSB, IT4I, Ostrava, Czech Republic; [Guetl, Christian] Graz Univ Technol, Graz, Austria; [Hendriksen, Gijs; Hiemstra, Djoerd; de Vries, Arjen P.] Radboud Univ Nijmegen, Nijmegen, Netherlands; [Mlakar, Izidor] A1, Lublijana, Slovenia; [oester, Per] IT Ctr Sci, CSC, Espoo, Finland; [Potthast, Martin] Univ Leipzig, Leipzig, Germany; [Potthast, Martin] ScaDS AI, Leipzig, Germany; [Megi, Sharikadze] Leibniz Supercomp Ctr, Munich, Germany; [Stein, Benno] Bauhaus Univ Weimar, Weimar, Germany; [Granitzer, Michael] Univ Passau, D-94032 Passau, Germany	University of Passau; Helmholtz Association; German Aerospace Centre (DLR); European Organization for Nuclear Research (CERN); Technical University of Ostrava; Graz University of Technology; Radboud University Nijmegen; Leipzig University; Bauhaus-Universitat Weimar; University of Passau	Granitzer, M (corresponding author), Univ Passau, D-94032 Passau, Germany.	michael.granitzer@uni-passau.de	Guetl, Christian/AAD-5918-2021; Mlakar, Izidor/V-2688-2019; Martinovič, Jan/G-3846-2019; Hiemstra, Djoerd/L-1863-2016	Guetl, Christian/0000-0001-9589-1966; Mlakar, Izidor/0000-0002-4910-1879; Hecking, Tobias/0000-0003-0833-7989; Mitrovic, Jelena/0000-0003-3220-8749; Granitzer, Michael/0000-0003-3566-5507; Oster, Per/0000-0001-5836-8850; Hiemstra, Djoerd/0000-0003-4967-2900; Hendriksen, Gijs/0000-0003-0945-3148; Fathima, Noor Afshan/0009-0008-9707-6453; de Vries, Arjen/0000-0002-2888-4202	European Commission [101070014]; Horizon Europe - Pillar II [101070014] Funding Source: Horizon Europe - Pillar II	European Commission(European Union (EU)European Commission Joint Research Centre); Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	European Commission, Grant/Award Number: 101070014	Anand A., 2020, Conversational search (dagstuhl seminar 19461); Baeza-Yates R, 2012, LECT NOTES COMPUT SC, V7608, P16, DOI 10.1007/978-3-642-34109-0_2; Barker R., 2018, Journal of Interactive Advertising, V18, P85, DOI DOI 10.1080/15252019.2018.1487810; Bengio Y., 2008, Scholarpedia, V3, P3881, DOI DOI 10.4249/SCHOLARPEDIA.3881; Bevendorff J, 2018, LECT NOTES COMPUT SC, V10772, P820, DOI 10.1007/978-3-319-76941-7_83; Blind K., 2021, IMPACT OPEN SOURCE S, V10; Caselli T., 2020, P 5 WORKSH ONL AB HA; Cliqz GmbH, 2019, NEW SEARCH ENG CLIQZ; Cornacchia R, 2006, LECT NOTES COMPUT SC, V3936, P543; Das A., 2012, NEXT GENERATION SEAR, P1; Epstein Robert, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134677; Erenli K., 2021, INT CYBERSECURITY LA, V2, P183, DOI [10.1365/s43439-021-00017-8, DOI 10.1365/S43439-021-00017-8]; Fuhr N., 2018, SIGIR Forum, P46, DOI DOI 10.1145/3190580.3190588; Hagiu A, 2020, HARVARD BUS REV, V98, P94; Herrmann M., 2014, P IEEE 14 INT C PEER, P1, DOI 10.1109/P2P.2014.6934312; Hofler P., 2014, P WORKSH LINK DAT WE; Hogan A., 2021, SYNTHESIS LECT DATA, DOI [DOI 10.2200/S01125ED1V01Y202109DSK022, 10.2200/S01125ED1V01Y202109DSK022, DOI 10.1145/3447772]; Kamphuis C., 2021, P 2 INT C DES EXP SE, P10; Khare R., 2006, Proceedings of the 15th international conference on World Wide Web, P865, DOI [DOI 10.1145/1135777.1135917, 10. 1145/1135777.1135917]; Koster M., 2022, ROBOTS EXCLUSION PRO, P1, DOI [10.17487/RFC9309, DOI 10.17487/RFC9309]; Lewandowski D, 2019, COMMUN ACM, V62, P24, DOI 10.1145/3312479; Lewandowski D, 2015, ONLINE INFORM REV, V39, P278, DOI 10.1108/OIR-03-2015-0089; Lex Elisabeth, 2010, 2010 21st International Conference on Database and Expert Systems Applications, P10, DOI 10.1109/DEXA.2010.24; LibreTechTips, 2020, DET TESTS SEARCH ENG; Macdonald C, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4526, DOI 10.1145/3459637.3482013; Mohr G., 2008, WARC FILE FORMAT 1 0; OpenAI, 2023, GPT 4 TECHNICAL REPO; Potthast M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1117, DOI 10.1145/3331184.3331327; Qwant SAS, 2019, MICR TOOLS STRENGTH; Sanger Larry., 2005, Open sources, V2, P307; Seifert C, 2017, IEEE INT CON INF VIS, P35, DOI 10.1109/iV.2017.23; van Hulst JM, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2197; Wachsmuth H, 2015, LECT NOTES COMPUT SC, V9383, P1, DOI 10.1007/978-3-319-25741-9	33	3	3	6	21	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2330-1635	2330-1643		J ASSOC INF SCI TECH		MAY	2024	75	5			SI		512	520		10.1002/asi.24818	http://dx.doi.org/10.1002/asi.24818		AUG 2023	9	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	NC3H8		Green Submitted, hybrid, Green Accepted			2024-07-03	WOS:001043677800001
C	Bhargav, S; Schuth, A; Hauff, C			ACM	Bhargav, Samarth; Schuth, Anne; Hauff, Claudia			When the Music Stops: Tip-of-the-Tongue Retrieval for Music	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Music Retrieval; Tip-of-the-Tongue Retrieval; Cross Modal Retrieval	AGREEMENT	We present a study of Tip-of-the-tongue (ToT) retrieval for music, where a searcher is trying to find an existing music entity, but is unable to succeed as they cannot accurately recall important identifying information. ToT information needs are characterized by complexity, verbosity, uncertainty, and possible false memories. We make four contributions. (1) We collect a dataset-ToT(Music)-of 2,278 information needs and ground truth answers. (2) We introduce a schema for these information needs and show that they often involve multiple modalities encompassing several Music IR sub-tasks such as lyric search, audio-based search, audio fingerprinting, and text search. (3) We underscore the difficulty of this task by benchmarking a standard text retrieval approach on this dataset. (4) We investigate the efficacy of query reformulations generated by a large language model (LLM), and show that they are not as effective as simply employing the entire information need as a query-leaving several open questions for future research.	[Bhargav, Samarth] Univ Amsterdam, Amsterdam, Netherlands; [Schuth, Anne; Hauff, Claudia] Spotify, Amsterdam, Netherlands	University of Amsterdam	Bhargav, S (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.	s.bhargav@uva.nl; aschuth@spotify.com; claudiah@spotify.com		Bhargav, Samarth/0000-0001-5204-8514; Schuth, Anne/0000-0002-5841-2134	NWO Innovational Research Incentives Scheme [Vidi (016), Vidi.189.039]	NWO Innovational Research Incentives Scheme	The authors would like to thank Gulfaraz Rahman and Ruben van Heusden for helping with the preliminary annotation work. The authors also thank Daniel Lazarovski and Humberto Corona Pampin for their input. Part of this research was supported by the NWO Innovational Research Incentives Scheme Vidi (016.Vidi.189.039). All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.	Arguello J, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P5, DOI 10.1145/3406522.3446021; Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Azzopardi Leif, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P455, DOI 10.1145/1277741.1277820; Bhargav S, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P48, DOI 10.1145/3488560.3498421; Buffa M, 2021, LECT NOTES COMPUT SC, V12731, P515, DOI 10.1007/978-3-030-77385-4_31; Buffa Michel, 2020, WASABI DATASET RDF K, DOI [10.5281/zenodo.5603369, DOI 10.5281/ZEN0D0.5603369]; Campos R, 2018, LECT NOTES COMPUT SC, V10772, P806, DOI 10.1007/978-3-319-76941-7_80; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Doh SeungHeon, 2022, ARXIV221114558; Downie J. S., 2002, INT SOC MUS INF RETR; Elizalde B, 2019, INT CONF ACOUST SPEE, P4095, DOI 10.1109/ICASSP.2019.8682632; Elsweiler D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P25; Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336; Ghias A., 1995, P 3 ACM INT C MULT, P231, DOI DOI 10.1145/217279.215273; Hagen Matthias, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P513, DOI 10.1007/978-3-319-16354-3_57; Haitsma J., 2002, ISMIR, P107; Hashemi H, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2984, DOI 10.1145/3447548.3467188; Hauff C, 2011, LECT NOTES COMPUT SC, V6931, P176, DOI 10.1007/978-3-642-23318-0_17; Hauff Claudia, 2012, P IIIX, P274, DOI [10.1145/2362724.2362773, DOI 10.1145/2362724.2362773]; Helen Marko, 2007, 2007 IEEE INT C AC S, V1, pI; Hirjee Hussein, 2010, P INT SOC MUS INF RE, P147; Hong S, 2017, ARXIV170406761; Hongliang Ye, 2020, 2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P1792, DOI 10.1109/ITAIC49862.2020.9339157; Jorgensen Ida Kathrine Hammeleff, 2020, INT C FDN DIG GAM, DOI [10.1145/3402942.3402971, DOI 10.1145/3402942.3402971]; Kim B, 2019, INT CONF ACOUST SPEE, P4100, DOI 10.1109/ICASSP.2019.8683461; Kim J., 2009, P 18 ACM C INFORM KN, P1297; Koepke A Sophia, 2022, IEEE T MULTIMEDIA; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Müller M, 2007, LECT NOTES COMPUT SC, V4675, P112; Oncescu Andreea-Maria, 2021, ARXIV210502192; REN Z, 2012, COMPUT LINGUIST, P306; Ring N, 2009, LECT NOTES COMPUT SC, V5839, P157, DOI 10.1007/978-3-642-04769-5_14; Sadeghi Sargol, 2014, P 2014 AUSTRALASIAN, P105, DOI [10.1145/2682862.2682867, DOI 10.1145/2682862.2682867]; Sasaki Shoto, 2014, ISMIR, P585; Simonetta F, 2019, 2019 INTERNATIONAL WORKSHOP ON MULTILAYER MUSIC REPRESENTATION AND PROCESSING (MMRP 2019), P10, DOI [10.1109/MMRP.2019.8665366, 10.1109/MMRP.2019.00012]; Wang K., 2016, ABS160706215 ARXIV; Xu Xin, 2009, P INT C MUS INF RETR, P417; Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746; Zhang YC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2406, DOI 10.1109/ICASSP.2018.8461729; Zhu TG, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6010023	40	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							2506	2510		10.1145/3539618.3592086	http://dx.doi.org/10.1145/3539618.3592086			5	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		Green Submitted, hybrid			2024-07-03	WOS:001118084002108
C	Marin-Morales, J; Llanes-Jurado, J; Minissi, ME; Gómez-Zaragozá, L; Altozano, A; Alcañiz, M			IEEE	Marin-Morales, Javier; Llanes-Jurado, Jose; Minissi, Maria Eleonora; Gomez-Zaragoza, Lucia; Altozano, Alberto; Alcaniz, Mariano			Gaze and Head Movement Patterns of Depressive Symptoms During Conversations with Emotional Virtual Humans	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, ACII	International Conference on Affective Computing and Intelligent Interaction		English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			depressive disorder; virtual human; emotion elicitation; clustering; statistical learning; large language models; mental health		Depressive symptoms involve dysfunctional social attitudes and heightened negative emotional states. Identifying biomarkers requires data collection in realistic environments that activate depression-specific phenomena. However, no previous research analysed biomarkers in combination with AI-powered conversational virtual humans (VH) for mental health assessment. This study aims to explore gaze and head movements patterns related to depressive symptoms during conversations with emotional VH. A total of 105 participants were evenly divided into a control group and a group of subjects with depressive symptoms (SDS). They completed six semi-guided conversations designed to evoke basic emotions. The VHs were developed using a cognitive-inspired framework, enabling real-time voice-based conversational interactions powered by a Large Language Model, and including emotional facial expressions and lip synchronization. They have embedded life-history, context, attitudes, emotions and motivations. Signal processing techniques were applied to obtain gaze and head movements features, and heatmaps were generated. Then, parametric and non-parametric statistical tests were applied to evaluate differences between groups. Additionally, a two-dimensional t-SNE embedding was created and combined with k-means clustering. Results indicate that SDS exhibited shorter blinks and longer saccades. The control group showed affiliative lateral head gyros and accelerations, while the SDS demonstrated stress-related back-and-forth movements. SDS also displayed the avoidance of eye contact. The exploratory multivariate statistical unsupervised learning achieved 72.3% accuracy. The present study analyse biomarkers in affective processes with multiple social contextual factors and information modalities in ecological environments, and enhances our understanding of gaze and head movements patterns in individuals with depressive symptoms, ultimately contributing to the development of more effective assessments and intervention strategies.	[Marin-Morales, Javier; Llanes-Jurado, Jose; Minissi, Maria Eleonora; Gomez-Zaragoza, Lucia; Altozano, Alberto; Alcaniz, Mariano] Univ Politecn Valencia, Inst Univ Invest Tecnol Ctr Ser Humane, Valencia, Spain	Universitat Politecnica de Valencia	Marin-Morales, J (corresponding author), Univ Politecn Valencia, Inst Univ Invest Tecnol Ctr Ser Humane, Valencia, Spain.	jamarmo@htech.upv.es; jllajur@htech.upv.es; meminiss@htech.upv.es; lugoza@htech.upv.es; aaltfer@htech.upv.es; malcaniz@htech.upv.es			Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain [PAID-06-22, PAID-10-20]	Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain	This work was supported by the Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain [Ayuda a Primeros Proyectos de Investigacion (PAID-06-22); (PAID-10-20)].	Alghowinem S, 2013, INT CONF AFFECT, P283, DOI 10.1109/ACII.2013.53; [Anonymous], 2008, Orienting of Attention; Bredin H., 2021, arXiv; Burden David., 2019, Virtual humans: Today and tomorrow; Chitale V, 2022, GAMES HEALTH J, V11, P341, DOI 10.1089/g4h.2021.0227; Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004; Dattani S., 2021, Mental Health; Dev A, 2022, IEEE ACCESS, V10, P16756, DOI 10.1109/ACCESS.2022.3146711; DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061; Ekman P., 1978, ENVIRON PSYCH NONVER, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007; Gross JJ, 2014, CLIN PSYCHOL SCI, V2, P387, DOI 10.1177/2167702614536164; He L, 2022, INFORM FUSION, V80, P56, DOI 10.1016/j.inffus.2021.10.012; Huys QJM, 2016, NAT NEUROSCI, V19, P404, DOI 10.1038/nn.4238; Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x; Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4; Segrin C, 2000, CLIN PSYCHOL REV, V20, P379, DOI 10.1016/S0272-7358(98)00104-4; Suslow T, 2020, J AFFECT DISORDERS, V274, P632, DOI 10.1016/j.jad.2020.05.140; Tonsen M, 2020, Arxiv, DOI [arXiv:2009.00508, 10.48550/arXiv.2009.00508]	19	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2156-8103		979-8-3503-2743-4	INT CONF AFFECT			2023										10.1109/ACIIW59127.2023.10388134	http://dx.doi.org/10.1109/ACIIW59127.2023.10388134			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IH					2024-07-03	WOS:001161369900021
J	Matz, SC; Teeny, JD; Vaid, SS; Peters, H; Harari, GM; Cerf, M				Matz, S. C.; Teeny, J. D.; Vaid, S. S.; Peters, H.; Harari, G. M.; Cerf, M.			The potential of generative AI for personalized persuasion at scale	SCIENTIFIC REPORTS			English	Article							WILLINGNESS-TO-ACCEPT; REGULATORY FIT; PREVENTION; MOTIVATION; ATTITUDES; APPEALS	Matching the language or content of a message to the psychological profile of its recipient (known as "personalized persuasion") is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.	[Matz, S. C.; Peters, H.; Cerf, M.] Columbia Business Sch, New York, NY 10027 USA; [Matz, S. C.] Columbia Business Sch, Ctr Adv Technol & Human Performance, New York, NY 10027 USA; [Teeny, J. D.] Kellogg Sch Management, Evanston, IL USA; [Vaid, S. S.] Stanford Univ, Harvard Business Sch, Dept Commun, Negotiat Org & Mkt Unit, Stanford, CA USA; [Harari, G. M.] Stanford Univ, Dept Commun, Stanford, CA USA	Columbia University; Columbia University; Northwestern University; Stanford University; Stanford University	Matz, SC (corresponding author), Columbia Business Sch, New York, NY 10027 USA.; Matz, SC (corresponding author), Columbia Business Sch, Ctr Adv Technol & Human Performance, New York, NY 10027 USA.	sm4409@gsb.columbia.edu	Teeny, Jacob/KCY-3391-2024	Teeny, Jacob/0000-0001-6112-534X				AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T; Alkis N, 2015, PERS INDIV DIFFER, V87, P147, DOI 10.1016/j.paid.2015.07.037; Anderson S., 2023, The Drum; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Anthropic, 2023, Technical report Anthropic; Aylsworth T, 2022, J BUS ETHICS, V175, P689, DOI 10.1007/s10551-020-04590-6; Bai H., 2023, OSF preprint, DOI [10.31219/osf.io/stakv, DOI 10.31219/OSF.IO/STAKV]; Bailenson JN, 2006, POLIT PSYCHOL, V27, P373, DOI 10.1111/j.1467-9221.2006.00505.x; Bhageshphur K., 2019, Forbes Magazine; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Boerman SC, 2017, J ADVERTISING, V46, P363, DOI 10.1080/00913367.2017.1339368; Bogg T, 2022, J AM COLL HEALTH, DOI 10.1080/07448481.2022.2103382; Boutyline A, 2017, POLIT PSYCHOL, V38, P551, DOI 10.1111/pops.12337; Cesario J, 2008, SOC PERSONAL PSYCHOL, V2, P444, DOI 10.1111/j.1751-9004.2007.00055.x; Christian H, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00459-1; Cutler A., 2022, J. Pers. Soc. Psychol, V20, P20; Fazio RH., 2014, The MODE Model: Attitude-Behavior Processes as a Function of Motivation and Opportunity. In Dual-Process Theories of the Social Mind, P155; Feinberg M, 2019, SOC PERSONAL PSYCHOL, DOI 10.1111/spc3.12501; Feinberg M, 2015, PERS SOC PSYCHOL B, V41, P1665, DOI 10.1177/0146167215607842; Feinberg M, 2013, PSYCHOL SCI, V24, P56, DOI 10.1177/0956797612449177; Gerber AS, 2013, POLIT BEHAV, V35, P687, DOI 10.1007/s11109-012-9216-y; Gerber AS, 2010, AM POLIT SCI REV, V104, P111, DOI 10.1017/S0003055410000031; Gladstone JJ., 2019, Psychol. Sci, V20, p0956797619849435; Gladstone JJ, 2022, SOC PSYCHOL PERS SCI, V13, P595, DOI 10.1177/19485506211028390; Goldberg LR, 2006, J RES PERS, V40, P84, DOI 10.1016/j.jrp.2005.08.007; Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1; Graham J., 2008, J. Pers. Soc. Psychol, V20, P2; Graham J, 2013, ADV EXP SOC PSYCHOL, V47, P55, DOI 10.1016/B978-0-12-407236-7.00002-4; Graham MH, 2021, PUBLIC OPIN QUART, V85, P28, DOI 10.1093/poq/nfab009; Graves C., 2023, Harvard Business Review; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hagendorff T, 2023, Arxiv, DOI [arXiv:2212.05206, 10.48550/arXiv.2212.05206, DOI 10.48550/ARXIV.2212.05206]; Hauser JR, 2009, MARKET SCI, V28, P202, DOI 10.1287/mksc.1080.0459; Hersh ED, 2013, J POLIT, V75, P520, DOI 10.1017/S0022381613000182; Higgins E.T., 2019, SHARED REALITY WHAT; Higgins ET, 2001, EUR J SOC PSYCHOL, V31, P3, DOI 10.1002/ejsp.27; Hirsh JB, 2012, PSYCHOL SCI, V23, P578, DOI 10.1177/0956797611436349; Hu K., 2023, Reuters; Hughes A., 2017, 5 Facts about U.S. Political Donations; Jackler R K., 2019, JUUL advertising over its first three years on the market. Research into the Impact of Tobacco Advertising; Joyal-Desmarais K, 2022, PSYCHOL BULL, V148, P465, DOI 10.1037/bul0000377; Karinshak E., 2023, Proc. ACM Hum. Comput. Interact, V7; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110; Latimer AE, 2005, J HEALTH COMMUN, V10, P137, DOI 10.1080/10810730500263364; Latimer AE, 2008, J EXP SOC PSYCHOL, V44, P826, DOI 10.1016/j.jesp.2007.07.013; Lloyd-Smith P, 2018, J ENVIRON ECON MANAG, V91, P133, DOI 10.1016/j.jeem.2018.07.003; Lockwood P, 2002, J PERS SOC PSYCHOL, V83, P854, DOI 10.1037//0022-3514.83.4.854; Lukito J, 2020, POLIT COMMUN, V37, P238, DOI 10.1080/10584609.2019.1661889; Marr B., 2023, Forbes Magazine; Matz S., 2017, Routledge International Handbook of Consumer Psychology, P656; Matz SC, 2017, P NATL ACAD SCI USA, V114, P12714, DOI 10.1073/pnas.1710966114; Matz SC., 2017, Proc. Natl. Acad. Sci., V20, P20; Matz SC., 2022, Am. Psychol, V20, P20; Matz SC., 2019, Curr. Opin. Psychol, V20, P20; MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x; McCrae RR, 2002, INT CUL PSY, P105; Mehta I., 2023, TechCrunch; Miller KM, 2011, J MARKETING RES, V48, P172, DOI 10.1509/jmkr.48.1.172; OGUINN TC, 1989, J CONSUM RES, V16, P147, DOI 10.1086/209204; OpenAI, 2023, GPT 4 SYST CARD; Ozer DJ, 2006, ANNU REV PSYCHOL, V57, P401, DOI 10.1146/annurev.psych.57.102904.190127; Park G, 2015, J PERS SOC PSYCHOL, V108, P934, DOI 10.1037/pspp0000020; Parkins C., 2017, The Economist.; Peters H, 2024, Arxiv, DOI [arXiv:2309.08631, DOI 10.48550/ARXIV.2309.08631, 10.48550/arXiv.2309.08631]; Podsakoff PM, 2003, J APPL PSYCHOL, V88, P879, DOI 10.1037/0021-9010.88.5.879; Psychology ES., 2000, Advances in Experimental Social Psychology, P1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramon Y, 2021, INFORMATION, V12, DOI 10.3390/info12120518; Schmidt J, 2020, J ACAD MARKET SCI, V48, P499, DOI 10.1007/s11747-019-00666-6; Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791; Segalin C, 2017, IEEE T AFFECT COMPUT, V8, P268, DOI 10.1109/TAFFC.2016.2516994; Soto CJ, 2017, J RES PERS, V68, P69, DOI 10.1016/j.jrp.2017.02.004; Stachl C., 2021, Personality Science, V2, DOI [DOI 10.5964/PS.6115, 10.5964/ps.6115]; Stachl C, 2019, Behavioral Patterns in Smartphone Usage Predict Big Five Personality Traits, DOI [10.31234/osf.io/ks4vd, DOI 10.31234/OSF.IO/KS4VD]; Tappin B, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2216261120; Teeny JD, 2021, J CONSUM PSYCHOL, V31, P382, DOI 10.1002/jcpy.1198; The White House Office of Science and Technology Policy, 2022, BLUEPR AI BILL RIGHT; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Voelkel JG, 2018, SOC PSYCHOL PERS SCI, V9, P917, DOI 10.1177/1948550617729408; Whittington D, 2017, ANNU REV RESOUR ECON, V9, P317, DOI 10.1146/annurev-resource-121416-125602; Wu YY, 2015, P NATL ACAD SCI USA, V112, P1036, DOI 10.1073/pnas.1418680112; Zhang XY, 2022, AAAI CONF ARTIF INTE, P12423	85	1	2	26	26	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	FEB 26	2024	14	1							4692	10.1038/s41598-024-53755-0	http://dx.doi.org/10.1038/s41598-024-53755-0			16	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	KB2G1	38409168	Green Submitted, gold, Green Published			2024-07-03	WOS:001177429500111
C	Almohaimeed, S; Almohaimeed, S; Bölöni, L			IEEE	Almohaimeed, Saad; Almohaimeed, Saleh; Boloni, Ladislau			Transfer Learning and Lexicon-Based Approaches for Implicit Hate Speech Detection: A Comparative Study of Human and GPT-4 Annotation	18TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC 2024	IEEE International Conference on Semantic Computing		English	Proceedings Paper	18th IEEE International Conference on Semantic Computing (ICSC)	FEB 05-07, 2024	Laguna Hills, CA	IEEE, IEEE Comp Soc		implicit hate; hate speech; abusive language; transfer learning; lexicon-based; GPT-4 annotation		Detecting harmful speech is the subject of significant research effort both in the academia and industry. While good progress was made on detecting explicit hate speech, detecting implicit hate remains difficult as it requires a deep understanding of the allusions of the text and the social context in which it was uttered. In this paper we study the effectiveness of several approaches to implicit hate speech detection, including lexicon-based approaches, transfer learning, and the use of up-to-date large language models, such as GPT-4. By combining lexicon-based approach with the targeted topics, we performed transfer learning experiments using knowledge from seven public harmful speech datasets. Various combinations of the proposed approaches showed an improvement of 0.6 - 2.3% in the F1-Macro score compared to the baselines. We observed that while GPT-4 annotations show a good agreement with human labels, there is often a conflict when interpreting sarcasm, text shortening based on context, and speech that targets individuals. Warning: due to the nature of the research subject, this paper contains explicit and potentially offensive language.	[Almohaimeed, Saad; Almohaimeed, Saleh; Boloni, Ladislau] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Almohaimeed, S (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.	sa583575@ucf.edu; sa247216@ucf.edu; ladislau.boloni@ucf.edu			National Science Foundation [2114948]	National Science Foundation(National Science Foundation (NSF))	We would like to express our gratitude to the anonymous reviewers for their insightful feedback. This work was partially supported by the National Science Foundation under award 2114948.	Alatawi HS, 2021, IEEE ACCESS, V9, P106363, DOI 10.1109/ACCESS.2021.3100435; Almohaimeed S., 2023, PROC DATA CENTRIC MA; Bonta V., 2019, Asian Journal of Computer Science and Technology, V8S, P1, DOI [10.51983/ajcst-2019.8.s2.2037, 10.51983/ajcst-2019.8.S2.2037, DOI 10.51983/AJCST-2019.8.S2.2037]; Davidson Thomas, 2017, 11 INT AAAI C WEB SO; ElSherief M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P345; Founta A., 2018, PROC INT AAAI C WEB, V12; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mathew B, 2021, AAAI CONF ARTIF INTE, V35, P14867; Mathur A., 2020, P INT AAAI C WEB SOC, V14, P209; Mozafari M, 2020, STUD COMPUT INTELL, V881, P928, DOI 10.1007/978-3-030-36687-2_77; Ousidhoum N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4675; Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P363; Schmidt A., 2017, P 5 INT WORKSHOP NAT, P1; Stankovic SV, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00766-9; Vashistha N, 2021, INFORMATION, V12, DOI 10.3390/info12010005; Waseem Z., 2016, P NAACL STUD RES WOR, P88, DOI DOI 10.18653/V1/N16-2013; Zampieri M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1415	18	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2325-6516		979-8-3503-8535-9	IEEE INT C SEMANT CO			2024							142	147		10.1109/ICSC59802.2024.00028	http://dx.doi.org/10.1109/ICSC59802.2024.00028			6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7TH					2024-07-03	WOS:001196221400021
J	Passby, L; Jenko, N; Wernham, A				Passby, Lauren; Jenko, Nathan; Wernham, Aaron			Performance of ChatGPT on Specialty Certificate Examination in Dermatology multiple-choice questions	CLINICAL AND EXPERIMENTAL DERMATOLOGY			English	Article								ChatGPT is a large language model trained on increasingly large datasets by OpenAI to perform language-based tasks. It is capable of answering multiple-choice questions, such as those posed by the Specialty Certificate Examination (SCE) in Dermatology. We asked two iterations of ChatGPT: ChatGPT-3.5 and ChatGPT-4 84 multiple-choice sample questions from the sample SCE in Dermatology question bank. ChatGPT-3.5 achieved an overall score of 63%, and ChatGPT-4 scored 90% (a significant improvement in performance; P < 0.001). The typical pass mark for the SCE in Dermatology is 70-72%. ChatGPT-4 is therefore capable of answering clinical questions and achieving a passing grade in these sample questions. There are many possible educational and clinical implications for increasingly advanced artificial intelligence (AI) and its use in medicine, including in the diagnosis of dermatological conditions. Such advances should be embraced provided that patient safety is a core tenet, and the limitations of AI in the nuances of complex clinical cases are recognized.	[Passby, Lauren] Univ Hosp Birmingham NHS Fdn Trust, Solihull Hosp, Dept Dermatol, Solihull, England; [Jenko, Nathan] Royal Orthopaed Hosp NHS Fdn Trust, Dept Radiol, Birmingham, England; [Wernham, Aaron] Leicester Royal Infirm, Dept Dermatol, Leicester, England; [Wernham, Aaron] Manor Hosp, Dept Dermatol, Walsall Healthcare NHS Trust, Walsall, England	Heart of England NHS Foundation Trust; Royal Orthopaedic Hospital; University of Leicester	Passby, L (corresponding author), Univ Hosp Birmingham NHS Fdn Trust, Solihull Hosp, Dept Dermatol, Solihull, England.	l.passby@nhs.net		Jenko, Nathan/0000-0003-2882-6923; Wernham, Aaron/0000-0001-5920-6888				Birkett L, 2023, BRIT J ANAESTH, V131, pe34, DOI 10.1016/j.bja.2023.04.025; General Medical Council, DERM CURR; Katz Daniel Martin, 2023, GPT-4 Passes the Bar Exam, DOI DOI 10.2139/SSRN.4389233; MRCPUK, DERM SAMPL QUEST; MRCPUK, DERM SPEC CERT EX SC; Nori H., 2023, ARXIV; OpenAI, GPT 4 IS OPENAIS MOS; OpenAI, CHATGPT CHATB MAY 12; Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X	9	25	25	6	13	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0307-6938	1365-2230		CLIN EXP DERMATOL	Clin. Exp. Dermatol.	SEP 6	2023	49	7					722	727		10.1093/ced/llad197	http://dx.doi.org/10.1093/ced/llad197		JUN 2023	6	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	WF2S2	37264670				2024-07-03	WOS:001062527800001
C	Biderman, S; Raff, E			ACM	Biderman, Stella; Raff, Edward			Fooling MOSS Detection with Pretrained Language Models	PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022			English	Proceedings Paper	31st ACM International Conference on Information and Knowledge Management (CIKM)	OCT 17-21, 2022	Atlanta, GA	Assoc Comp Machinery		language models; multimodal transformers; education technology; open source software	PLAGIARISM	As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [60] can complete introductory level programming assignments without triggering suspicion from MOSS [2], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research.	[Biderman, Stella; Raff, Edward] Booz Allen Hamilton, Mclean, VA 22102 USA; [Biderman, Stella] EleutherAI, New York, NY 10003 USA	Booz Allen Hamilton Holding Corporation	Biderman, S (corresponding author), Booz Allen Hamilton, Mclean, VA 22102 USA.; Biderman, S (corresponding author), EleutherAI, New York, NY 10003 USA.	biderman_stella@bah.com; raff_edward@bah.com		Biderman, Stella/0000-0001-8228-1042				Affouneh S., 2020, Interdisciplinary Journal of Virtual Learning in Medical Sciences, V11, P135, DOI DOI 10.30476/IJVLMS.2020.86120.1033; Aiken Alex, 2000, MOSS MEASURE SOFTWAR; Austin Jacob, 2021, ARXIV210807732; Biderman Stella, 2020, Pitfalls in machine learning research: Reexamining the development cycle; Birhane Abeba, 2021, ARXIV210615590; Black Sid, 2022, ARXIV220406745; Bowyer K. W., 1999, FRONT ED C 1999 FIE9, V3, P13; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen Xiang, 2021, ARXIV210407650; Chong Miranda, 2010, P 4 INT PLAG C IPC 2; Cleary MN, 2017, PHI DELTA KAPPAN, V99, P66, DOI 10.1177/0031721717745548; Crowson Katherine, 2022, arXiv; Darmetko Tomasz, 2021, THESIS; Dawson P, 2020, ASSESS EVAL HIGH EDU, V45, P473, DOI 10.1080/02602938.2019.1662884; Devore-McDonald B, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428206; Drori Iddo, 2021, ARXIV211108171; Drori Iddo, 2021, ARXIV211215594; Eret E, 2010, PROCD SOC BEHV, V2, P3303, DOI 10.1016/j.sbspro.2010.03.505; FAIDHI JAW, 1987, COMPUT EDUC, V11, P11, DOI 10.1016/0360-1315(87)90042-X; Feldman V, 2020, ACM S THEORY COMPUT, P954, DOI 10.1145/3357713.3384290; Foltynek Tomas, 2020, Sustainable Digital Communities. 15th International Conference, iConference 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12051), P816, DOI 10.1007/978-3-030-43687-2_68; Fried Daniel, 2022, ARXIV220405999; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Han Seungju, 2022, ARXIV220410825; He X, 2021, PHYS FLUIDS, V33, DOI 10.1063/5.0066106; Holtzman A., 2019, P INT C LEARN REPR; Hu Zhiqiang, 2020, ARXIV201012742; Johnson Gabbrielle, 2022, J MORAL PHILOS SPECI; Juliana Rudy Pramono, 2020, TRANSFORMATION LEARN, V20, P1; Karnalim O, 2019, INFORM EDUC, V18, P321, DOI 10.15388/infedu.2019.15; Krishna K, 2020, INT C LEARN REPR; Lancaster T., 2004, Comput. Sci. Edu., V14, P101, DOI DOI 10.1080/08993400412331363843; Leahy Connor, 2021, STATE AI ETHICS REPO, V4; Lee Mina, 2022, ARXIV220106796; Lee Y, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022), P62; Li W., 2020, P 58 ANN M ASS COMP, P6232, DOI 10.18653/v1/2020.acl-main.555; Li Xiang Lisa, 2021, arXiv; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Pengfei, 2021, arXiv; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Luke Divya, 2014, 2018 5 INT S EM TREN; Mazeika M., 2021, 35 C NEUR INF PROC S, P1; Mukherjee Rohan, 2021, 35 C NEUR INF PROC S; Narayan Shashi, 2018, P 2018 C N AM CHAPT, P280, DOI [DOI 10.18653/V1/N18-1158, 10.18653/v1/N18-1158]; Oppenlaender Jonas, 2022, ARXIV220413988; Pawelczak D, 2018, IEEE GLOB ENG EDUC C, P1048, DOI 10.1109/EDUCON.2018.8363346; Raffel C., 2019, arXiv preprint arXiv:1910.10683; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Sanh Victor., 2022, 10 INT C LEARN REPR; Sheahen D, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P285, DOI 10.1145/2876034.2893435; Sheikh W, 2022, COMPUT APPL ENG EDUC, V30, P821, DOI 10.1002/cae.22488; Shporer Avi, 2021, PREPRINT; Simon, 2020, ITICSE-WGR'20: PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P1, DOI 10.1145/3437800.3439201; Singh A, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P81, DOI 10.1145/3051457.3051466; Tran S., 2021, P AS C MACH LEARN AC, P470; Underwood Ted, 2022, STARTWORDS, DOI DOI 10.17613/FAAA-1R21; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Weisz JD, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P369, DOI 10.1145/3490099.3511157; Wu ZH, 2021, LECT NOTES COMPUT SC, V12762, P171, DOI 10.1007/978-3-030-78462-1_13; Xu Frank F, 2022, ARXIV220213169; Yasid Muhammad, 2020, J ADV RES DYNAMICAL, V2020; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Zhang S., 2022, arXiv	66	9	9	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9236-5				2022							2933	2943		10.1145/3511808.3557079	http://dx.doi.org/10.1145/3511808.3557079			11	Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV8AK		Green Submitted			2024-07-03	WOS:001074639602087
J	Schafer, M; Nadi, S; Eghbali, A; Tip, F				Schafer, Max; Nadi, Sarah; Eghbali, Aryaz; Tip, Frank			An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						Test generation; JavaScript; language models	SELECTION	Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to various aspects of software development, including their suggested use for automated generation of unit tests, but while requiring additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without requiring additional training or manual effort. Concretely, we consider an approach where the LLM is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. Furthermore, if a generated test fails, our approach attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We implement our approach in TESTPILOT, an adaptive LLM-based test generation tool for JavaScript that automatically generates unit tests for the methods in a given project's API. We evaluate TESTPILOT using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API functions. The generated tests achieve a median statement coverage of 70.2% and branch coverage of 52.8%. In contrast, the state-of-the feedback-directed JavaScript test generation technique, Nessie, achieves only 51.3% statement coverage and 25.6% branch coverage. Furthermore, experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. We also find that 92.8% of TESTPILOT's generated tests have <= 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies. Finally, we run TESTPILOT with two additional LLMs, OpenAI's older code-cushman-002 LLM and StarCoder, an LLM for which the training process is publicly documented. Overall, we observed similar results with the former (68.2% median statement coverage), and somewhat worse results with the latter (54.0% median statement coverage), suggesting that the effectiveness of the approach is influenced by the size and training set of the LLM, but does not fundamentally depend on the specific model.	[Schafer, Max] GitHub, Kidlington OX5 1AY, England; [Nadi, Sarah] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada; [Eghbali, Aryaz] Univ Stuttgart, D-70569 Stuttgart, Baden Wurttembe, Germany; [Tip, Frank] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA	University of Alberta; University of Stuttgart; Northeastern University	Schafer, M (corresponding author), GitHub, Kidlington OX5 1AY, England.	max-schaefer@github.com; nadi@ualberta.ca; aryaz.egh@gmail.com; f.tip@northeastern.edu	Eghbali, Aryaz/JLL-2695-2023	Eghbali, Aryaz/0000-0001-9763-8147; Nadi, Sarah/0000-0002-0091-6030; Tip, Frank/0000-0002-1862-3498	National Science Foundation	National Science Foundation(National Science Foundation (NSF))	No Statement Available	Allamanis M., 2018, PROC 6 INT C LEARN R; Allamanis M, 2021, ADV NEUR IN, V34; Almasi MM, 2017, 2017 IEEE/ACM 39TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE TRACK (ICSE-SEIP 2017), P263, DOI 10.1109/ICSE-SEIP.2017.27; Andreasen E, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3106739; [Anonymous], OpenAI LLMs: Deprecations; [Anonymous], StarCoder: A State-of-the-Art LLM for Code-huggingface; [Anonymous], Github copilot; [Anonymous], Codeql; [Anonymous], npm levenshtein distance package; [Anonymous], OpenAI Codex; [Anonymous], 2023, The Daikon invariant detector; [Anonymous], Node.js error codes; Arteca E, 2022, PROC INT CONF SOFTW, P1494, DOI 10.1145/3510003.3510106; Artzi S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P571, DOI 10.1145/1985793.1985871; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bareiss P., 2022, PROC 37 ACMIEEE INT; Beck K., 2000, Extreme Programming Explained: Embrace Change; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Cadar C., 2006, CCS '06: Proceedings of the 13th ACM conference on Computer and communications security, New York, NY, USA, P322; Chen M., 2021, arXiv; CLIFF N, 1993, PSYCHOL BULL, V114, P494, DOI 10.1037/0033-2909.114.3.494; Csallner C, 2004, SOFTWARE PRACT EXPER, V34, P1025, DOI 10.1002/spe.602; Daka E, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P107, DOI 10.1145/2786805.2786838; Daka E, 2014, PROC INT SYMP SOFTW, P201, DOI 10.1109/ISSRE.2014.11; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dinella E, 2022, PROC INT CONF SOFTW, P2130, DOI 10.1145/3510003.3510141; Fard A. M., 2014, Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering, ASE'14, P67, DOI 10.1145/2642937.2642991; Fard AM, 2015, IEEE INT CONF AUTOM, P190, DOI 10.1109/ASE.2015.26; Fraser G., 2011, Proceedings of the 11th International Conference on Quality Software (QSIC 2011), P31, DOI 10.1109/QSIC.2011.19; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Godefroid P, 2005, ACM SIGPLAN NOTICES, V40, P213, DOI 10.1145/1064978.1065036; Grano G, 2018, INT C PROGRAM COMPRE, P348, DOI 10.1145/3196321.3196363; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Hellendoorn V. J., 2020, PROC 8 INT C LEARN R; istanbul.js, Istanbul coverage tool; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Karampatsis RM, 2020, PROC INT CONF SOFTW, P1073, DOI 10.1145/3377811.3380342; Kim S, 2021, PROC INT CONF SOFTW, P150, DOI 10.1109/ICSE43902.2021.00026; Lahiri SK, 2023, Arxiv, DOI arXiv:2208.05950; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li GD, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P449, DOI 10.1145/2635868.2635913; Li J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4159; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu Z., 2023, PROC ACM SIGSOFT INT, P859; Marchetto A, 2011, EMPIR SOFTW ENG, V16, P103, DOI 10.1007/s10664-010-9149-1; Mastropaolo A., 2022, IEEE Transactions on Software Engineering; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; McMinn P., 2011, 2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops (ICSTW), P153, DOI 10.1109/ICSTW.2011.100; Mezzetti G., 2018, PROC 32 EUR C OBJECT, V109, p7:1; MILLER BP, 1990, COMMUN ACM, V33, P32, DOI 10.1145/96267.96279; Mirshokraie Shabnam, 2015, 2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST), DOI 10.1109/ICST.2015.7102595; Mirshokraie Shabnam, 2012, Web Engineering. Proceedings 12th International Conference, ICWE 2012, P238, DOI 10.1007/978-3-642-31753-8_18; Mirshokraie S, 2013, IEEE INT CONF AUTOM, P610, DOI 10.1109/ASE.2013.6693121; Mocha, about us; Myers G, 1999, J ACM, V46, P395, DOI 10.1145/316542.316550; Pacheco C., 2007, OOPSLA 2007 COMPANIO, P815; Pacheco Carlos., 2008, International Symposium on Software Testing and Analysis (ISSTA), P87, DOI 10.1145/1390630.1390643; Palomba F, 2016, 2016 IEEE/ACM 9TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST), P5, DOI [10.1109/SBST.2016.010, 10.1145/2897010.2897016]; Panichella A, 2020, PROC IEEE INT CONF S, P523, DOI 10.1109/ICSME46990.2020.00056; Panichella A, 2018, IEEE T SOFTWARE ENG, V44, P122, DOI 10.1109/TSE.2017.2663435; Pradel M, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276517; Pradel M, 2022, COMMUN ACM, V65, P86, DOI 10.1145/3460348; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Saxena P, 2010, P IEEE S SECUR PRIV, P513, DOI 10.1109/SP.2010.38; Schleimer S., 2003, P 2003 ACM SIGMOD IN, P76, DOI [10.1145/872757.872770, DOI 10.1145/872757.872770]; Schuler D., 2011, Proceedings 2011 IEEE Fourth International Conference on Software Testing, Verification and Validation (ICST 2011), P90, DOI 10.1109/ICST.2011.32; Selakovic M, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276531; Sen K., 2005, Program, V30, P263; Shore J., 2021, The Art of Agile Development, V2nd; Siddiqui S., 2021, Learning Test-Driven Development; Stallenberg D, 2022, LECT NOTES COMPUT SC, V13711, P67, DOI 10.1007/978-3-031-21251-2_5; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tanida H., 2014, PROC 9 INT C SOFTWAR, P259; Tillmann N., 2014, P 29 ACMIEEE INT C A, P385, DOI DOI 10.1145/2642937; Tufano M., 2021, Unit test case generation with transformers and focal context; Tufano M, 2022, 3RD ACM/IEEE INTERNATIONAL CONFERENCE ON AUTOMATION OF SOFTWARE TEST (AST 2022), P54, DOI 10.1145/3524481.3527220; Watson C, 2020, PROC INT CONF SOFTW, P1398, DOI 10.1145/3377811.3380429; Yoo S, 2012, SOFTW TEST VERIF REL, V22, P67, DOI [10.1002/stv.430, 10.1002/stvr.430]; Yu H, 2022, PROC INT CONF SOFTW, P163, DOI 10.1145/3510003.3510149; Zalewski M., American Fuzzy Lop	81	2	2	26	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JAN	2024	50	1					85	105		10.1109/TSE.2023.3334955	http://dx.doi.org/10.1109/TSE.2023.3334955			21	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EQ4Q6		Green Submitted			2024-07-03	WOS:001140380900008
J	Lai, HH; Ge, L; Sun, MY; Pan, B; Huang, JJ; Hou, LY; Yang, QY; Liu, JY; Liu, JN; Ye, ZY; Xia, DN; Zhao, WL; Wang, XM; Liu, M; Talukdar, JR; Tian, JH; Yang, KH; Estill, J				Lai, Honghao; Ge, Long; Sun, Mingyao; Pan, Bei; Huang, Jiajie; Hou, Liangying; Yang, Qiuyu; Liu, Jiayi; Liu, Jianing; Ye, Ziying; Xia, Danni; Zhao, Weilong; Wang, Xiaoman; Liu, Ming; Talukdar, Jhalok Ronjan; Tian, Jinhui; Yang, Kehu; Estill, Janne			Assessing the Risk of Bias in Randomized Clinical Trials With Large Language Models	JAMA NETWORK OPEN			English	Article							DOUBLE-BLIND; PRIMARY INSOMNIA; INTERRATER RELIABILITY; REBOUND INSOMNIA; WEIGHT-LOSS; LONG-TERM; RED MEAT; EFFICACY; SAFETY; DIET	Importance Large language models (LLMs) may facilitate the labor-intensive process of systematic reviews. However, the exact methods and reliability remain uncertain. Objective To explore the feasibility and reliability of using LLMs to assess risk of bias (ROB) in randomized clinical trials (RCTs). Design, Setting, and Participants A survey study was conducted between August 10, 2023, and October 30, 2023. Thirty RCTs were selected from published systematic reviews. Main Outcomes and Measures A structured prompt was developed to guide ChatGPT (LLM 1) and Claude (LLM 2) in assessing the ROB in these RCTs using a modified version of the Cochrane ROB tool developed by the CLARITY group at McMaster University. Each RCT was assessed twice by both models, and the results were documented. The results were compared with an assessment by 3 experts, which was considered a criterion standard. Correct assessment rates, sensitivity, specificity, and F1 scores were calculated to reflect accuracy, both overall and for each domain of the Cochrane ROB tool; consistent assessment rates and Cohen kappa were calculated to gauge consistency; and assessment time was calculated to measure efficiency. Performance between the 2 models was compared using risk differences. Results Both models demonstrated high correct assessment rates. LLM 1 reached a mean correct assessment rate of 84.5% (95% CI, 81.5%-87.3%), and LLM 2 reached a significantly higher rate of 89.5% (95% CI, 87.0%-91.8%). The risk difference between the 2 models was 0.05 (95% CI, 0.01-0.09). In most domains, domain-specific correct rates were around 80% to 90%; however, sensitivity below 0.80 was observed in domains 1 (random sequence generation), 2 (allocation concealment), and 6 (other concerns). Domains 4 (missing outcome data), 5 (selective outcome reporting), and 6 had F1 scores below 0.50. The consistent rates between the 2 assessments were 84.0% for LLM 1 and 87.3% for LLM 2. LLM 1's kappa exceeded 0.80 in 7 and LLM 2's in 8 domains. The mean (SD) time needed for assessment was 77 (16) seconds for LLM 1 and 53 (12) seconds for LLM 2. Conclusions In this survey study of applying LLMs for ROB assessment, LLM 1 and LLM 2 demonstrated substantial accuracy and consistency in evaluating RCTs, suggesting their potential as supportive tools in systematic review processes.	[Lai, Honghao; Ge, Long; Yang, Qiuyu; Liu, Jiayi; Ye, Ziying; Xia, Danni; Zhao, Weilong] Lanzhou Univ, Sch Publ Hlth, Dept Hlth Policy & Management, Lanzhou, Peoples R China; [Lai, Honghao; Ge, Long; Yang, Qiuyu; Liu, Jiayi; Ye, Ziying; Xia, Danni; Zhao, Weilong] Lanzhou Univ, Evidence Based Social Sci Res Ctr, Sch Publ Hlth, 199 Donggang West Rd, Lanzhou 730000, Peoples R China; [Ge, Long; Tian, Jinhui; Yang, Kehu] Key Lab Evidence Based Med & Knowledge Translat Ga, Lanzhou, Peoples R China; [Sun, Mingyao] Lanzhou Univ, Evidence Based Nursing Ctr, Sch Nursing, Lanzhou, Peoples R China; [Pan, Bei; Hou, Liangying; Wang, Xiaoman; Liu, Ming; Tian, Jinhui; Yang, Kehu; Estill, Janne] Lanzhou Univ, Sch Basic Med Sci, Evidence Based Med Ctr, Lanzhou, Peoples R China; [Huang, Jiajie; Liu, Jianing] Gansu Univ Chinese Med, Coll Nursing, Lanzhou, Peoples R China; [Hou, Liangying; Liu, Ming; Talukdar, Jhalok Ronjan] McMaster Univ, Dept Hlth Res Methods Evidence & Impact, Hamilton, ON, Canada; [Estill, Janne] Univ Geneva, Inst Global Hlth, Geneva, Switzerland	Lanzhou University; Lanzhou University; Lanzhou University; Lanzhou University; Gansu University of Chinese Medicine; McMaster University; University of Geneva	Ge, L (corresponding author), Lanzhou Univ, Evidence Based Social Sci Res Ctr, Sch Publ Hlth, 199 Donggang West Rd, Lanzhou 730000, Peoples R China.	gelong2009@163.com	Talukdar, Jhalok Ronjan/AFX-3353-2022	Talukdar, Jhalok Ronjan/0000-0001-9739-5632				ALLEN RP, 1987, J CLIN PHARMACOL, V27, P768, DOI 10.1002/j.1552-4604.1987.tb02994.x; [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI [10.3736/jcim20090918, DOI 10.1371/JOURNAL.PMED.1000097]; [Anonymous], Tool to Assess Risk of Bias in Cohort Studies; Arno A, 2022, ANN INTERN MED, V175, P1001, DOI 10.7326/M22-0092; Benassi-Evans B, 2009, MUTAGENESIS, V24, P271, DOI 10.1093/mutage/gep006; Black J, 2017, SLEEP MED, V36, P86, DOI 10.1016/j.sleep.2017.05.009; BYRT T, 1993, J CLIN EPIDEMIOL, V46, P423, DOI 10.1016/0895-4356(93)90018-V; Carlson AL, 2019, ENDOCR PRACT, V25, P306, DOI 10.4158/EP-2018-0177; ChatGPT Prompt Engineering for Developers, DeepLearning.AI; Cherney DZI, 2021, DIABETES OBES METAB, V23, P2632, DOI 10.1111/dom.14513; Claude Introducing, Anthropic; Davis CR, 2017, AM J CLIN NUTR, V105, P1305, DOI 10.3945/ajcn.116.146803; de Mello VDF, 2008, J RENAL NUTR, V18, P440, DOI 10.1053/j.jrn.2008.04.010; Del Prato S, 2014, DIABETES OBES METAB, V16, P1239, DOI 10.1111/dom.12377; Djulbegovic B, 2017, LANCET, V390, P415, DOI 10.1016/S0140-6736(16)31592-6; Elliott JH, 2017, J CLIN EPIDEMIOL, V91, P23, DOI 10.1016/j.jclinepi.2017.08.010; Fan BY, 2017, NEUROL ASIA, V22, P41; Fanaroff AC, 2019, LANCET, V394, P633, DOI 10.1016/S0140-6736(19)31256-5; Frias JP, 2018, LANCET, V392, P2180, DOI 10.1016/S0140-6736(18)32260-8; Gao F, 2020, DIABETES OBES METAB, V22, P2375, DOI 10.1111/dom.14163; Griffin HJ, 2013, DIABETES OBES METAB, V15, P572, DOI 10.1111/dom.12056; Guyatt GH, 2008, BRIT MED J, V336, P924, DOI 10.1136/bmj.39489.470347.AD; Hirt J, 2021, J NURS SCHOLARSHIP, V53, P246, DOI 10.1111/jnu.12628; Hunninghake DB, 2000, J AM COLL NUTR, V19, P351, DOI 10.1080/07315724.2000.10718931; Ikonomidis I, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.119.015716; Introducing ChatGPT, Anthropic; Jardim PSJ, 2022, BMC MED RES METHODOL, V22, DOI 10.1186/s12874-022-01649-y; Lankford A, 2012, SLEEP MED, V13, P133, DOI 10.1016/j.sleep.2011.09.006; Lanza E, 2007, CANCER EPIDEM BIOMAR, V16, P1745, DOI 10.1158/1055-9965.EPI-07-0127; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Meir AY, 2019, J NUTR, V149, P1004, DOI 10.1093/jn/nxy321; Mignot E, 2022, LANCET NEUROL, V21, P125, DOI 10.1016/S1474-4422(21)00436-1; Minozzi S, 2020, J CLIN EPIDEMIOL, V126, P37, DOI 10.1016/j.jclinepi.2020.06.015; Murphy KJ, 2012, NUTRIENTS, V4, P711, DOI 10.3390/nu4070711; Nahra R, 2021, DIABETES CARE, V44, P1433, DOI 10.2337/dc20-2151; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Pan B, 2023, DRUGS, V83, P587, DOI 10.1007/s40265-023-01859-8; Pitt SC, 2021, JAMA SURG, V156, P785, DOI 10.1001/jamasurg.2021.0543; Poddar KH, 2013, APPETITE, V71, P379, DOI 10.1016/j.appet.2013.09.008; r-project, R: The R Project for Statistical Computing; Randall S, 2012, SLEEP, V35, P1551, DOI 10.5665/sleep.2208; Savovic J, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-37; Seino Y, 2015, J DIABETES INVEST, V6, P443, DOI 10.1111/jdi.12316; Shi QY, 2023, BMJ-BRIT MED J, V381, DOI 10.1136/bmj-2022-074068; Siemieniuk RAC, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m2980; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sivertsen B, 2006, JAMA-J AM MED ASSOC, V295, P2851, DOI 10.1001/jama.295.24.2851; Subbiah V, 2023, NAT MED, V29, P49, DOI 10.1038/s41591-022-02160-z; Taskinen MR, 2011, DIABETES OBES METAB, V13, P65, DOI 10.1111/j.1463-1326.2010.01326.x; Turner-McGrievy GM, 2015, NUTRITION, V31, P350, DOI 10.1016/j.nut.2014.09.002; Voshaar RCO, 2004, EUR NEUROPSYCHOPHARM, V14, P301, DOI 10.1016/j.euroneuro.2003.09.007; Xu HJ, 2020, SLEEP MED, V76, P113, DOI 10.1016/j.sleep.2020.10.018; Yabiku K, 2017, CLIN THER, V39, P558, DOI 10.1016/j.clinthera.2017.01.015; Yan XL, 2013, INT J PSYCHIAT CLIN, V17, P239, DOI 10.3109/13651501.2012.735242; Zeraatkar D, 2019, ANN INTERN MED, V171, P721, DOI 10.7326/M19-0622	55	0	0	1	1	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	MAY 22	2024	7	5							e2412687	10.1001/jamanetworkopen.2024.12687	http://dx.doi.org/10.1001/jamanetworkopen.2024.12687			12	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RV6I8	38776081	gold			2024-07-03	WOS:001230472100003
J	Strader, J; Hughes, N; Chen, WL; Speranzon, A; Carlone, L				Strader, Jared; Hughes, Nathan; Chen, William; Speranzon, Alberto; Carlone, Luca			Indoor and Outdoor 3D Scene Graph Generation Via Language-Enabled Spatial Ontologies	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						AI-based methods; 3D scene graphs; semantic scene understanding; spatial ontologies		This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., "a beach contains sand"), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.	[Strader, Jared; Hughes, Nathan; Carlone, Luca] MIT, Lab Informat & Decis Syst LIDS, Cambridge, MA 02139 USA; [Chen, William] Univ Calif Berkeley, Berkeley Artificial Intelligence Res BAIR, Berkeley, CA 94720 USA; [Speranzon, Alberto] Lockheed Martin, Adv Technol Labs, Eagan, MN 55121 USA	Massachusetts Institute of Technology (MIT); University of California System; University of California Berkeley; Lockheed Martin	Strader, J (corresponding author), MIT, Lab Informat & Decis Syst LIDS, Cambridge, MA 02139 USA.	jstrader@mit.edu; na26933@mit.edu; verityw@berkeley.edu; alberto.speranzon@lmco.com; lcarlone@mit.edu			ARL DCIST Program	ARL DCIST Program	No Statement Available	Agia C., 2022, P C ROBOT LEARNING C, P46; Armeni I, 2019, IEEE I CONF COMP VIS, P5663, DOI 10.1109/ICCV.2019.00576; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Badreddine S, 2022, ARTIF INTELL, V303, DOI 10.1016/j.artint.2021.103649; Berg M, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P1888, DOI 10.1109/ICRA46639.2022.9812355; Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081; Chen C, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4687; Chen W, 2023, Arxiv, DOI arXiv:2209.05629; Dhamo H., 2021, P INT C COMP VIS, P16352; Fagin R., 2020, arXiv; Fey M., 2019, ICLR 2019 WORKSH REP, P1; Gothoskar N., 2021, Advances in Neural Information Processing Systems, V34, P9600; Greve E, 2024, Arxiv, DOI arXiv:2309.06635; Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081; Hsu J, 2023, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR52729.2023.00257; Hughes N, 2024, INT J ROBOT RES, DOI 10.1177/02783649241229725; Hughes N, 2022, ROBOT SCI SYS; Jain J, 2023, PROC CVPR IEEE, P2989, DOI 10.1109/CVPR52729.2023.00292; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Movshovitz-Attias Y, 2015, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2015.7298778; Pan JZ, 2023, Arxiv, DOI arXiv:2308.06374; Qiu Y., 2023, IEEE INT C AUT SCI E, P1, DOI [10.1109/CASE56687.2023.10260650, DOI 10.1109/CASE56687.2023.10260650]; Rana K., 2023, C ROBOT LEARNING COR, P23; Ravichandran Z, 2022, IEEE INT CONF ROBOT, P9272, DOI 10.1109/ICRA46639.2022.9812179; Reinke A, 2022, IEEE ROBOT AUTOM LET, V7, P9043, DOI 10.1109/LRA.2022.3181357; Rosinol A, 2021, INT J ROBOT RES, V40, P1510, DOI 10.1177/02783649211056674; Rosinol A, 2020, IEEE INT CONF ROBOT, P1689, DOI [10.1109/ICRA40945.2020.9196885, 10.1109/icra40945.2020.9196885]; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Seymour Z, 2022, INT C PATT RECOG, P4146, DOI 10.1109/ICPR56361.2022.9956224; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Sun K, 2024, Arxiv, DOI arXiv:2308.10168; Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072; van Krieken E, 2022, ARTIF INTELL-AMST, V302, DOI 10.1016/j.artint.2021.103602; Velickovic G., 2018, 6 INT C LEARNING REP; Wald J, 2020, PROC CVPR IEEE, P3960, DOI 10.1109/CVPR42600.2020.00402; Wu SC, 2021, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR46437.2021.00743; Zareian Alireza, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P606, DOI 10.1007/978-3-030-58592-1_36; Zhang S., 2021, Adv. Neural Inf. Process. Syst., V34, P18620; Zheng WF, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108153; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544	40	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	JUN	2024	9	6					4886	4893		10.1109/LRA.2024.3384084	http://dx.doi.org/10.1109/LRA.2024.3384084			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	OC3N2		Green Submitted			2024-07-03	WOS:001205022300006
J	Camilleri, MA				Camilleri, Mark Anthony			Factors affecting performance expectancy and intentions to use ChatGPT: Using SmartPLS to advance an information technology acceptance framework	TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE			English	Article						Unified Theory of Acceptance and use of; Technology; Information Adoption Model; Chat Generative Pre -Trained Transformer; ChatGPT; AI Chatbot; Natural language generation	PERCEIVED INTERACTIVITY; CONSUMER ACCEPTANCE; SERVICE QUALITY; SOCIAL MEDIA; ADOPTION; MODEL; SATISFACTION; PERCEPTIONS; CUSTOMERS; IMPACT	Few studies have explored the use of artificial intelligence-enabled (AI-enabled) large language models (LLMs). This research addresses this knowledge gap. It investigates perceptions and intentional behaviors to utilize AI dialogue systems like Chat Generative Pre-Trained Transformer (ChatGPT). A survey questionnaire comprising measures from key information technology adoption models, was used to capture quantitative data from a sample of 654 respondents. A partial least squares (PLS) approach assesses the constructs' reliabilities and validities. It also identifies the relative strength and significance of the causal paths in the proposed research model. The findings from SmartPLS4 report that there are highly significant effects in this empirical investigation particularly between source trustworthiness and performance expectancy from AI chatbots, as well as between perceived interactivity and intentions to use this algorithm, among others. In conclusion, this contribution puts forward a robust information technology acceptance framework that clearly evidences the factors that entice online users to habitually engage with text-generating AI chatbot technologies. It implies that although they may be considered as useful interactive systems for content creators, there is scope to continue improving the quality of their responses (in terms of their accuracy and timeliness) to reduce misinformation, social biases, hallucinations and adversarial prompts.	[Camilleri, Mark Anthony] Univ Malta, Fac Media & Knowledge Sci, Dept Corp Commun, Msida MSD2080, Malta; Northwestern Univ, Medill Sch, 1845 Sheridan Rd, Evanston, IL 60208 USA; Business Sch, Buccleuch Pl, Edinburgh EH8 9JS, Scotland	University of Malta; Northwestern University	Camilleri, MA (corresponding author), Univ Malta, Fac Media & Knowledge Sci, Dept Corp Commun, Msida MSD2080, Malta.		Camilleri, Mark Anthony/R-4574-2016	Camilleri, Mark Anthony/0000-0003-1288-4256	University of Malta's Research Innovation and Development Trust [RSF2024-CRC-R2]	University of Malta's Research Innovation and Development Trust	This research was partially funded through the University of Malta's Research Innovation and Development Trust (RSF2024-CRC-R2) .<STRONG> </STRONG>	Abbad MMM, 2021, EDUC INF TECHNOL, V26, P7205, DOI 10.1007/s10639-021-10573-5; AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T; Al-Saedi K, 2020, TECHNOL SOC, V62, DOI 10.1016/j.techsoc.2020.101293; Alalwan AA, 2020, INT J INFORM MANAGE, V50, P28, DOI 10.1016/j.ijinfomgt.2019.04.008; Alam MZ, 2020, INT J INFORM MANAGE, V50, P128, DOI 10.1016/j.ijinfomgt.2019.04.016; [Anonymous], 2016, Official Journal of European Union, pL119; Ashfaq M, 2020, TELEMAT INFORM, V54, DOI 10.1016/j.tele.2020.101473; Assaker G, 2020, J HOSP MARKET MANAG, V29, P428, DOI 10.1080/19368623.2019.1653807; Baabdullah AM, 2022, TECHNOL FORECAST SOC, V181, DOI 10.1016/j.techfore.2022.121772; Balakrishnan J, 2022, TECHNOL FORECAST SOC, V180, DOI 10.1016/j.techfore.2022.121692; Bauer HH, 2006, J BUS RES, V59, P866, DOI 10.1016/j.jbusres.2006.01.021; Beh PK, 2021, BEHAV INFORM TECHNOL, V40, P282, DOI 10.1080/0144929X.2019.1685597; Bingham CB, 2019, STRATEG ENTREP J, V13, P121, DOI 10.1002/sej.1312; Brachten F, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102375; Bressolles G, 2014, J RETAIL CONSUM SERV, V21, P889, DOI 10.1016/j.jretconser.2014.07.004; CACIOPPO JT, 1981, AM PSYCHOL, V36, P441, DOI 10.1037/0003-066X.36.5.441; Camilleri Mark Anthony, 2022, ICETM '22: Proceedings of the 2022 5th International Conference on Education Technology Management, P199, DOI 10.1145/3582580.3582616; Camilleri M.A., 2020, Spanish Journal of Marketing - ESIC, V24, DOI [DOI 10.1108/SJME-04-2020-0074, 10.1108/sjme-04-2020-0074]; Camilleri MA, 2023, INT J HOSP MANAG, V114, DOI 10.1016/j.ijhm.2023.103575; Camilleri MA, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.13406; Camilleri MA, 2023, J HOSP TOUR TECHNOL, V14, P188, DOI 10.1108/JHTT-12-2021-0345; Camilleri MA, 2023, J SERV MARK, V37, P96, DOI 10.1108/JSM-12-2021-0477; Camilleri MA, 2022, TECHNOL SOC, V71, DOI 10.1016/j.techsoc.2022.102098; Chen LJ, 2020, INT J PUBLIC ADMIN, V43, P850, DOI 10.1080/01900692.2019.1660989; Cheung CMK, 2008, INTERNET RES, V18, P229, DOI 10.1108/10662240810883290; COMPEAU DR, 1995, INFORM SYST RES, V6, P118, DOI 10.1287/isre.6.2.118; Cortez RM, 2020, IND MARKET MANAG, V88, P125, DOI 10.1016/j.indmarman.2020.05.004; DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x; Driediger F, 2019, J RETAIL CONSUM SERV, V48, P224, DOI 10.1016/j.jretconser.2019.02.005; Tien DH, 2019, ASIA PAC MANAG REV, V24, P238, DOI 10.1016/j.apmrv.2018.06.003; Erkan I., 2018, Journal of Marketing Communications, V24, P617, DOI [DOI 10.1080/13527266.2016.1184706, 10.1080/13527266.2016.1184706]; Erkan I, 2016, COMPUT HUM BEHAV, V61, P47, DOI 10.1016/j.chb.2016.03.003; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Ferguson JL, 2020, IND MARKET MANAG, V89, P594, DOI 10.1016/j.indmarman.2019.02.003; Fishbein M., 1975, UNDERSTANDING ATTITU, P148; FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Gursoy D, 2019, INT J INFORM MANAGE, V49, P157, DOI 10.1016/j.ijinfomgt.2019.03.008; Hari H, 2022, INT J HUM-COMPUT INT, V38, P1212, DOI 10.1080/10447318.2021.1988487; Henseler J, 2015, J ACAD MARKET SCI, V43, P115, DOI 10.1007/s11747-014-0403-8; Ho JC, 2020, TECHNOL SOC, V63, DOI 10.1016/j.techsoc.2020.101360; Hoeken H, 2020, J ADVERTISING, V49, P195, DOI 10.1080/00913367.2019.1663317; Huang DH, 2021, J INNOV KNOWL, V6, P135, DOI 10.1016/j.jik.2020.09.002; Hwang H, 2023, EUR BUS REV, V35, P261, DOI 10.1108/EBR-11-2022-0224; Jiang Y, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107485; Jin XL, 2009, COMPUT HUM BEHAV, V25, P1172, DOI 10.1016/j.chb.2009.04.008; John SP, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2020.102052; Kamal SA, 2020, TECHNOL SOC, V60, DOI 10.1016/j.techsoc.2019.101212; Kamble S, 2019, INT J PROD RES, V57, P2009, DOI 10.1080/00207543.2018.1518610; Kang JW, 2019, INT J HOSP MANAG, V78, P189, DOI 10.1016/j.ijhm.2018.10.011; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kaya B, 2019, J INTERNET COMMER, V18, P369, DOI 10.1080/15332861.2019.1668658; Lallmahomed MZI, 2017, TELEMAT INFORM, V34, P57, DOI 10.1016/j.tele.2017.01.003; Leong CM, 2022, J MARK ANAL, V10, P145, DOI 10.1057/s41270-021-00132-9; Li L, 2021, ELECTRON MARK, V31, P575, DOI 10.1007/s12525-020-00454-z; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liew TW, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0123-4; Lou C, 2022, INT J ADVERT, V41, P655, DOI 10.1080/02650487.2021.1951510; Luqman A, 2023, INFORM MANAGE-AMSTER, V60, DOI 10.1016/j.im.2023.103843; Malodia S, 2021, IEEE T ENG MANAGE, DOI 10.1109/TEM.2021.3117884; McMillan SJ, 2002, J ADVERTISING, V31, P29, DOI 10.1080/00913367.2002.10673674; MIT, 2023, ChatGPT is going to change education, not destroy it; Molinillo S, 2020, COMPUT HUM BEHAV, V108, DOI 10.1016/j.chb.2019.04.004; Moore GC, 1991, INFORM SYST RES, V2, P192, DOI 10.1287/isre.2.3.192; OECD, 2023, AI Language Models: Technological, Socio-economic and Policy Considerations; Onofrei G, 2022, J BUS RES, V142, P100, DOI 10.1016/j.jbusres.2021.12.031; OpenAI, 2023, What Is ChatGPT. Commonly Asked Questions About ChatGPT; OpenAI, 2023, OpenAI's Most Advanced System, Producing Safer Andmore Useful Responses; Parasuraman A, 2005, J SERV RES-US, V7, P213, DOI 10.1177/1094670504271156; Patil P, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102144; Peltier JW, 2024, J RES INTERACT MARK, V18, P54, DOI 10.1108/JRIM-01-2023-0030; Peng LF, 2016, ELECTRON COMMER RES, V16, P145, DOI 10.1007/s10660-016-9213-z; Podsakoff PM, 2024, ANNU REV ORGAN PSYCH, V11, P17, DOI 10.1146/annurev-orgpsych-110721-040030; Queiroz MM, 2021, INT J PROD RES, V59, P6087, DOI 10.1080/00207543.2020.1803511; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Raza SA, 2021, J EDUC COMPUT RES, V59, P183, DOI 10.1177/0735633120960421; Reuters, 2023, Italy restores ChatGPT after OpenAI responds to regulator; Rohde P, 2021, EUR J MARKETING, V55, P2700, DOI 10.1108/EJM-06-2019-0530; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Shahzad F, 2018, TECHNOL SOC, V55, P33, DOI 10.1016/j.techsoc.2018.05.006; Shankar V, 2021, J RETAILING, V97, P13, DOI 10.1016/j.jretai.2020.10.006; Sharma S, 2024, IEEE T ENG MANAGE, V71, P1846, DOI 10.1109/TEM.2022.3157976; Shi J, 2018, INTERNET RES, V28, P393, DOI 10.1108/IntR-01-2017-0038; Sohn K, 2020, TELEMAT INFORM, V47, DOI 10.1016/j.tele.2019.101324; Song JH, 2008, J MARKETING, V72, P99, DOI 10.1509/jmkg.72.2.99; Sussman SW, 2003, INFORM SYST RES, V14, P47, DOI 10.1287/isre.14.1.47.14767; Takefuji Y, 2023, BRIT DENT J, V234, P845, DOI 10.1038/s41415-023-6041-0; Tam C, 2020, INFORM SYST FRONT, V22, P243, DOI 10.1007/s10796-018-9864-5; THOMPSON RL, 1991, MIS QUART, V15, P125, DOI 10.2307/249443; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926; Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540; Venkatesh V, 2008, DECISION SCI, V39, P273, DOI 10.1111/j.1540-5915.2008.00192.x; Venkatesh V, 2012, MIS QUART, V36, P157; Winter S, 2020, MEDIA PSYCHOL, V23, P79, DOI 10.1080/15213269.2019.1572521; Wolfinbarger M, 2003, J RETAILING, V79, P183, DOI 10.1016/S0022-4359(03)00034-4; Yoo B., 2001, Quarterly Journal of Electronic Commerce, V2, P31, DOI DOI 10.1007/978-3-319-11885-7_129; Zhang H, 2014, INFORM MANAGE-AMSTER, V51, P1017, DOI 10.1016/j.im.2014.07.005; Zhao L, 2012, DECIS SUPPORT SYST, V53, P825, DOI 10.1016/j.dss.2012.05.019; Zhao YY, 2020, INT J HOSP MANAG, V91, DOI 10.1016/j.ijhm.2020.102683	102	5	5	87	87	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0040-1625	1873-5509		TECHNOL FORECAST SOC	Technol. Forecast. Soc. Chang.	APR	2024	201								123247	10.1016/j.techfore.2024.123247	http://dx.doi.org/10.1016/j.techfore.2024.123247		FEB 2024	13	Business; Regional & Urban Planning	Social Science Citation Index (SSCI)	Business & Economics; Public Administration	LG6E1		hybrid, Green Published			2024-07-03	WOS:001185662800001
C	Labbé, T; Castel, P; Sanner, JM; Saleh, M			IEEE	Labbe, Thomas; Castel, Pierre; Sanner, Jean-Michel; Saleh, Majd			ChatGPT for phenotypes extraction: one model to rule them all?	2023 45TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE & BIOLOGY SOCIETY, EMBC	IEEE Engineering in Medicine and Biology Society Conference Proceedings		English	Proceedings Paper	45th Annual International Conference of the IEEE-Engineering-in-Medicine-and-Biology-Society (EMBC)	JUL 24-27, 2023	Sydney, AUSTRALIA	IEEE, IEEE Engn Med & Biol Soc				Information Extraction (IE) is a core task in Natural Language Processing (NLP) where the objective is to identify factual knowledge in textual documents (often unstructured), and feed downstream use cases with the resulting output. In genomic medicine for instance, being able to extract the most precise list of phenotypes associated to a patient allows to improve genetic disease diagnostic, which represents a vital step in the modern deep phenotyping approach. As most of the phenotypic information lies in clinical reports, the challenge is to build an IE pipeline to automatically recognize phenotype concepts from free-text notes. A new machine learning paradigm around large language models (LLM) has given rise of an increasing number of academic works on this topic lately, where sophisticated combinations of different technics have been employed to improve the phenotypes extraction accuracy. Even more recently released, the ChatGPT1 application nevertheless raises the question of the relevance of these approches compared to this new generic one based on an instruction-oriented LLM. In this paper, we propose a rigorous evaluation of ChatGPT and the current state-of-the-art solutions on this specific task, and discuss the possible impacts and the technical evolutions to consider in the medical domain.	[Labbe, Thomas; Sanner, Jean-Michel] Orange Labs, Rennes, France; [Labbe, Thomas; Castel, Pierre; Sanner, Jean-Michel; Saleh, Majd] Res Inst, Rennes, France	Orange SA	Labbé, T (corresponding author), Orange Labs, Rennes, France.; Labbé, T (corresponding author), Res Inst, Rennes, France.	thomas.labbe@orange.com; majd.saleh@bcom.com		Saleh, Majd/0000-0003-1800-0028				Anazi S, 2017, HUM GENET, V136, P1419, DOI 10.1007/s00439-017-1843-2; Ankit Vani, 2017, GROUNDED RECURRENT N; Aronson AR, 2001, J AM MED INFORM ASSN, P17; Brown, 2020, LANGUAGE MODELS ARE; Danz P, 2019, TOXICS, V7, DOI 10.3390/toxics7030047; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng Y., IEEE ACM T COMPUTATI, P1; Habibi M, 2017, BIOINFORMATICS, V33, pI37, DOI 10.1093/bioinformatics/btx228; Jonquet Clement, 2009, Summit Transl Bioinform, V2009, P56; Köhler S, 2021, NUCLEIC ACIDS RES, V49, pD1207, DOI 10.1093/nar/gkaa1043; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu C, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103318; Lobo M, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/8565739; Luo Ling, 2020, ABS200908478 CORR; Ouyang, 2022, TRAINING LANGUAGE MO; Piotr Bojanowski, 2016, ARXIV160704606; Son JH, 2018, AM J HUM GENET, V103, P58, DOI 10.1016/j.ajhg.2018.05.010; Yuan, 2022, BRIEF BIOINFORM, V23, P02	18	1	1	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1557-170X	1558-4615	979-8-3503-2447-1	IEEE ENG MED BIO			2023										10.1109/EMBC40787.2023.10340611	http://dx.doi.org/10.1109/EMBC40787.2023.10340611			4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2ZJ	38082605	Green Submitted			2024-07-03	WOS:001133788302189
C	Yang, JK; Cen, J; Peng, WX; Liu, S; Hong, FZ; Li, XT; Zhou, KY; Chen, QF; Liu, ZW		Oh, A; Neumann, T; Globerson, A; Saenko, K; Hardt, M; Levine, S		Yang, Jingkang; Cen, Jun; Peng, Wenxuan; Liu, Shuai; Hong, Fangzhou; Li, Xiangtai; Zhou, Kaiyang; Chen, Qifeng; Liu, Ziwei			4D Panoptic Scene Graph Generation	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 36, NEURIPS 2023	Advances in Neural Information Processing Systems		English	Proceedings Paper	37th Conference on Neural Information Processing Systems (NeurIPS)	DEC 10-16, 2023	New Orleans, LA					We are living in a three-dimensional space while moving forward through a fourth dimension: time. To allow artificial intelligence to develop a comprehensive understanding of such a 4D environment, we introduce 4D Panoptic Scene Graph (PSG-4D), a new representation that bridges the raw visual data perceived in a dynamic 4D world and high-level visual understanding. Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent entities with precise location and status information, and edges, which capture the temporal relations. To facilitate research in this new area, we build a richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of 1M frames, each of which is labeled with 4D panoptic segmentation masks as well as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer, a Transformer-based model that can predict panoptic segmentation masks, track masks along the time axis, and generate the corresponding scene graphs via a relation component. Extensive experiments on the new dataset show that our method can serve as a strong baseline for future research on PSG-4D. In the end, we provide a real-world application example to demonstrate how we can achieve dynamic scene understanding by integrating a large language model into our PSG-4D system.	[Yang, Jingkang; Peng, Wenxuan; Hong, Fangzhou; Li, Xiangtai; Liu, Ziwei] Nanyang Technol Univ, S Lab, Singapore, Singapore; [Cen, Jun; Chen, Qifeng] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Liu, Shuai] Beijing Univ Posts & Telecommun, Beijing, Peoples R China; [Zhou, Kaiyang] Hong Kong Baptist Univ, Hong Kong, Peoples R China	Nanyang Technological University; Hong Kong University of Science & Technology; Beijing University of Posts & Telecommunications; Hong Kong Baptist University	Liu, ZW (corresponding author), Nanyang Technol Univ, S Lab, Singapore, Singapore.	jingkang001@ntu.edu.sg; ziwei.liu@ntu.edu.sg	Zhou, Kaiyang/KTI-8952-2024		Ministry of Education, Singapore, under its MOE AcRF Tier 2 [MOE-T2EP20221-0012]; NTU NAP; RIE2020 Industry Alignment Fund - Industry Collaboration Projects (IAF-ICP) Funding Initiative; National Key R&D Program of China [2022ZD0161501]	Ministry of Education, Singapore, under its MOE AcRF Tier 2; NTU NAP; RIE2020 Industry Alignment Fund - Industry Collaboration Projects (IAF-ICP) Funding Initiative; National Key R&D Program of China	This study is supported by the Ministry of Education, Singapore, under its MOE AcRF Tier 2 (MOE-T2EP20221-0012), NTU NAP, and under the RIE2020 Industry Alignment Fund - Industry Collaboration Projects (IAF-ICP) Funding Initiative, the National Key R&D Program of China under grant number 2022ZD0161501, as well as cash and in-kind contribution from the industry partner(s).	Amiri S, 2022, IEEE ROBOT AUTOM LET, V7, P5560, DOI 10.1109/LRA.2022.3157567; [Anonymous], 2014, Grand Theft Auto V; [Anonymous], 2019, CVPR, DOI DOI 10.1109/CVPR.2019.00678; [Anonymous], 2017, CVPR, DOI DOI 10.1109/CVPR.2017.25; Armeni Iro, 2019, ICCV; Bae Jaewon, 2023, Robot Intelligence Technology and Applications 7: Results from the 10th International Conference on Robot Intelligence Technology and Applications. Lecture Notes in Networks and Systems (642), P136, DOI 10.1007/978-3-031-26889-2_13; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Chang Angel., 2017, 3DV; Cheng BW, 2022, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR52688.2022.00135; Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319; Cong YR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16352, DOI 10.1109/ICCV48922.2021.01606; Cong Yuren, 2022, ARXIV220111460; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Driess D., 2023, arXiv preprint arXiv:2303.03378; Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929; Fu HZ, 2017, IEEE T IMAGE PROCESS, V26, P1418, DOI 10.1109/TIP.2017.2651369; Goyal A., 2020, Advances in Neural Information Processing Systems, V33, P10514; Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961; Hickson S, 2014, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2014.51; Hu Y.-T., 2021, P CVPR; Hu YT, 2021, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR46437.2021.00147; Huang Wenlong, 2022, ABS220107207 ARXIV; Ji Jingwei, 2020, CVPR; Khan N, 2019, IEEE I CONF COMP VIS, P7810, DOI 10.1109/ICCV.2019.00790; Kim UH, 2020, IEEE T CYBERNETICS, V50, P4921, DOI 10.1109/TCYB.2019.2931042; Kirillov A., 2023, ARXIV230402643; Koppula H, 2013, INT C MACH LEARN, P792; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Li RJ, 2022, PROC CVPR IEEE, P19464, DOI 10.1109/CVPR52688.2022.01888; Li X., 2022, CVPR; Li X., 2023, ICCV; Li Xiangtai, 2023, Transformer-Based Visual Segmentation: A Survey; Liu Yunze, 2022, P IEEE CVF C COMP VI, P21013; Lorenz J, 2023, IEEE INT CONF COMP V, P62, DOI 10.1109/ICCVW60793.2023.00013; Ma Xiaojian, 2022, ARXIV221007474; OpenAI, 2023, : GPT-4 technical report.; Otsuji K., 1993, Proceedings ACM Multimedia 93, P251, DOI 10.1145/166266.166295; Özsoy E, 2022, LECT NOTES COMPUT SC, V13437, P475, DOI 10.1007/978-3-031-16449-1_45; Pan Xiaqing, 2023, P IEEE CVF INT C COM, P20133; Rana Krishan, 2023, ARXIV230706135; Raychaudhuri Sonia, 2023, ARXIV230403696; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rosinol A, 2021, INT J ROBOT RES, V40, P1510, DOI 10.1177/02783649211056674; Shang XD, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P279, DOI 10.1145/3323873.3325056; Shang Xindi, 2017, ACM MM; Suhail Mohammed, 2021, CVPR; Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252; Tobler RF, 2011, VISUAL COMPUT, V27, P687, DOI 10.1007/s00371-011-0572-0; Wald Johanna, 2020, P IEEE CVF C COMP VI, P3961; Wang Jinghao, 2023, ARXIV230708699; Wang Zhongdao, 2021, NEURIPS; Weikersdorfer D, 2013, IEEE IMAGE PROC, P2708, DOI 10.1109/ICIP.2013.6738558; Weng XS, 2020, IEEE INT C INT ROBOT, P10359, DOI 10.1109/IROS45743.2020.9341164; Weng XS, 2020, PROC CVPR IEEE, P6498, DOI 10.1109/CVPR42600.2020.00653; Wu SC, 2021, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR46437.2021.00743; Wu Y, 2022, ADV BIOL-GER, V6, DOI 10.1002/adbi.202200023; Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33; Xie Q, 2018, IEEE T MULTIMEDIA, V20, P580, DOI 10.1109/TMM.2017.2751965; Xu T, 2017, ENVIRON SCI TECH LET, V4, P132, DOI 10.1021/acs.estlett.7b00010; Yang JK, 2022, LECT NOTES COMPUT SC, V13687, P178, DOI 10.1007/978-3-031-19812-0_11; Yang Jingkang, 2023, ARXIV231008588; Yang Jingkang, 2023, CVPR; YANG JR, 2023, NATL SCI REV, V14; Yang Zongxin, 2021, NeurIPS; Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611; Zhang GY, 2017, IEEE SIGNAL PROC LET, V24, P1666, DOI 10.1109/LSP.2017.2731952; Zhang S., 2021, Adv. Neural Inf. Process. Syst., V34, P18620; Zhang S, 2022, LECT NOTES COMPUT SC, V13666, P180, DOI 10.1007/978-3-031-20068-7_11; Zhang WW, 2019, IEEE I CONF COMP VIS, P2365, DOI 10.1109/ICCV.2019.00245; Zhao Chengyang, 2023, P IEEE CVF INT C COM, P2839; Zhong Y., 2021, ICCV; Zhou Zijian, 2023, ARXIV230315994	73	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258			ADV NEUR IN			2023														14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8HB					2024-07-03	WOS:001202273400008
J	Schroeder, KM; Elkassabany, N				Schroeder, Kristopher M.; Elkassabany, Nabil			Artificial intelligence and regional anesthesiology education curriculum development: navigating the digital noise	REGIONAL ANESTHESIA AND PAIN MEDICINE			English	Article; Early Access						EDUCATION; TECHNOLOGY; REGIONAL ANESTHESIA	MEDICINE	Artificial intelligence (AI) has demonstrated a disruptive ability to enhance and transform clinical medicine. While the dexterous nature of anesthesiology work offers some protections from AI clinical assimilation, this technology will ultimately impact the practice and augment the ability to provide an enhanced level of safe and data-driven care. Whether predicting difficulties with airway management, providing perioperative or critical care risk assessments, clinical-decision enhancement, or image interpretation, the indications for AI technologies will continue to grow and are limited only by our collective imagination on how best to deploy this technology. An essential mission of academia is education, and challenges are frequently encountered when working to develop and implement comprehensive and effectively targeted curriculum appropriate for the diverse set of learners assigned to teaching faculty. Curriculum development in this context frequently requires substantial efforts to identify baseline knowledge, learning needs, content requirement, and education strategies. Large language models offer the promise of targeted and nimble curriculum and content development that can be individualized to a variety of learners at various stages of training. This technology has not yet been widely evaluated in the context of education deployment, but it is imperative that consideration be given to the role of AI in curriculum development and how best to deploy and monitor this technology to ensure optimal implementation.	[Schroeder, Kristopher M.] Univ Wisconsin Madison, Anesthesiol, Madison, WI 53706 USA; [Elkassabany, Nabil] Univ Virginia, Sch Med, Charlottesville, VA USA	University of Wisconsin System; University of Wisconsin Madison; University of Virginia	Schroeder, KM (corresponding author), Univ Wisconsin Madison, Anesthesiol, Madison, WI 53706 USA.	kmschro1@wisc.edu						Adams MCB, 2023, REGION ANESTH PAIN M, V48, P439, DOI 10.1136/rapm-2023-104526; Afonso AM, 2024, ANESTHESIOLOGY, V140, P38, DOI 10.1097/ALN.0000000000004784; Afonso AM, 2021, ANESTHESIOLOGY, V134, P683, DOI 10.1097/ALN.0000000000003722; Aldridge MJ, 2023, BRIT J ANAESTH, V131, pe36, DOI 10.1016/j.bja.2023.04.033; Alexander John C, 2018, Proc (Bayl Univ Med Cent), V31, P117, DOI 10.1080/08998280.2017.1391036; Arora A, 2020, BRIT J ANAESTH, V125, pE407, DOI 10.1016/j.bja.2020.06.049; Bowness JS, 2023, BRIT J ANAESTH, V130, P217, DOI 10.1016/j.bja.2022.06.031; Bowness JS, 2022, REGION ANESTH PAIN M, V47, P375, DOI 10.1136/rapm-2021-103368; Chuan A, 2021, REGION ANESTH PAIN M, V46, P867, DOI 10.1136/rapm-2021-102934; Connor CW, 2019, ANESTHESIOLOGY, V131, P1346, DOI 10.1097/ALN.0000000000002694; Davoud SC, 2023, CURR ANESTHESIOL REP, V13, P31, DOI 10.1007/s40140-023-00558-0; Erdem G, 2022, J CLIN ANESTH, V78, DOI 10.1016/j.jclinane.2021.110597; Fletcher G, 2003, BRIT J ANAESTH, V90, P580, DOI 10.1093/bja/aeg112; Hagedorn JM, 2024, J PAIN RES, V17, P509, DOI 10.2147/JPR.S429594; Hashimoto DA, 2020, ANESTHESIOLOGY, V132, P379, DOI 10.1097/ALN.0000000000002960; Hewson DW, 2023, BRIT J ANAESTH, V130, P245, DOI [10.1016/j.bja.2022.12.005, 10.1016/j.bja.2022.07.049]; Hofer IS, 2020, ANESTH ANALG, V130, P1115, DOI 10.1213/ANE.0000000000004575; Hurley NC, 2023, TRANSFUSION, V63, P1833, DOI 10.1111/trf.17526; Jamal Amr, 2023, Cureus, V15, pe43036, DOI 10.7759/cureus.43036; Karmakar A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.44306; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lonsdale H, 2020, ANESTH ANALG, V130, P1111, DOI 10.1213/ANE.0000000000004751; Maheshwari K, 2023, ANESTH ANALG, V136, P637, DOI 10.1213/ANE.0000000000005952; Porter S, 2022, REGION ANESTH PAIN M, V47, P672, DOI 10.1136/rapm-2022-103854; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Sun HP, 2021, ANESTH ANALG, V132, P1120, DOI 10.1213/ANE.0000000000005316; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thomas P., 2015, Curriculum development for medical education, VThird; Tighe P, 2011, PAIN MED, V12, P1566, DOI 10.1111/j.1526-4637.2011.01228.x; Woodworth G, 2020, REGION ANESTH PAIN M, V45, P660, DOI 10.1136/rapm-2020-101480	30	0	0	0	0	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1098-7339	1532-8651		REGION ANESTH PAIN M	Region. Anesth. Pain Med.	2024 JUN 14	2024										10.1136/rapm-2024-105522	http://dx.doi.org/10.1136/rapm-2024-105522		JUN 2024	3	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	WA1T5	38876802				2024-07-03	WOS:001252063800001
C	Ferro, N; Gonzalo, J; Karlgren, J; Müller, H		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Ferro, Nicola; Gonzalo, Julio; Karlgren, Jussi; Muller, Henning			The CLEF 2024 Monster Track: One Lab to Rule Them All	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT VI	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Generative language models; LLM; Shared task; Quality benchmarks; CLEF		Generative Artificial Intelligence (AI) and Large Language Models (LLMs) are revolutionizing technology and society thanks to their versatility and applicability to a wide array of tasks and use cases, in multiple media and modalities. As a new and relatively untested technology, LLMs raise several challenges for research and application alike, including questions about their quality, reliability, predictability, veracity, as well as on how to develop proper evaluation methodologies to assess their various capacities. This evaluation lab will focus on a specific aspect of LLMs, namely their versatility. The CLEF Monster Track is organized as a meta-challenge across a selection of tasks chosen from other evaluation labs running in CLEF 2024, and participants will be asked to develop or adapt a generative AI or LLM-based system that will be run on all the tasks with no or minimal task adaptation. This will allow us to systematically evaluate the performance of the same LLM-based system across a wide range of very different tasks and to provide feedback to each targeted task about the performance of a general-purpose LLM system compared to systems specifically developed for the task. Since the datasets for CLEF 2024 have not yet been released publicly, we will be able to experiment with previously unseen data, thus reducing the risk of contamination, which is one of the most serious problems faced by LLM evaluation datasets.	[Ferro, Nicola] Univ Padua, Padua, Italy; [Gonzalo, Julio] UNED, Madrid, Spain; [Karlgren, Jussi] SiloGen, Helsinki, Finland; [Karlgren, Jussi] SiloGen, Stockholm, Sweden; [Muller, Henning] HES SO Valais, Valais, Switzerland; [Muller, Henning] Univ Geneva, Geneva, Switzerland	University of Padua; Universidad Nacional de Educacion a Distancia (UNED); University of Applied Sciences & Arts Western Switzerland; University of Geneva	Gonzalo, J (corresponding author), UNED, Madrid, Spain.	julio@lsi.uned.es						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432; Chen JW, 2023, Arxiv, DOI arXiv:2309.01431; Chen M., 2021, arXiv; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Clark C, 2019, Arxiv, DOI arXiv:1905.10044; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Gao TY, 2023, Arxiv, DOI arXiv:2305.14627; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hromei C.D., 2023, CEUR Workshop Proceedings; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Kamalloo E, 2023, Arxiv, DOI arXiv:2307.16883; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Mihaylov T, 2018, Arxiv, DOI [arXiv:1809.02789, 10.48550/arXiv.1809.02789]; Ouyang L., 2022, P 36 ANN C NEUR INF; Rashkin H, 2023, COMPUT LINGUIST, V49, P777, DOI 10.1162/coli_a_00486; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Schwartz S.H., 2012, OVERVIEW SCHWARTZ TH, V2, DOI [10.9707/2307-0919.1116, DOI 10.9707/2307-0919.1116, https://doi.org/10.9707/2307-0919.1116]; Srivastava Aarohi, 2022, arXiv; Talmor A, 2019, Arxiv, DOI arXiv:1811.00937; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Zellers R, 2019, Arxiv, DOI arXiv:1905.07830; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]	27	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56071-2; 978-3-031-56072-9	LECT NOTES COMPUT SC			2024	14613						11	18		10.1007/978-3-031-56072-9_2	http://dx.doi.org/10.1007/978-3-031-56072-9_2			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9ED					2024-07-03	WOS:001211836300002
C	Dierickx, L; Lindén, CG; Opdahl, AL		Ceolin, D; Caselli, T; Tulin, M		Dierickx, Laurence; Linden, Carl-Gustav; Opdahl, Andreas L.			The Information Disorder Level (IDL) Index: A Human-Based Metric to Assess the Factuality of Machine-Generated Content	DISINFORMATION IN OPEN ONLINE MEDIA, MISDOOM 2023	Lecture Notes in Computer Science		English	Proceedings Paper	5th Multidisciplinary International Symposium on Disinformation in Open Online Media (MISDOOM)	NOV 21-22, 2023	Amsterdam, NETHERLANDS	European Res Ctr Informat Syst		Generative AI; natural language processing; social science	JOURNALIST; NEWS	Large language models have enabled the rapid production of misleading or fake narratives, presenting a challenge for direct detection methods. Considering that generative artificial intelligence tools are likely to be used either to inform or to disinform, evaluating the (non)human nature of machine-generated content is questioned, especially regarding the 'hallucination' phenomenon, which relates to generated content that does not correspond to real-world input. In this study, we argue that assessing machine-generated content is most reliable when done by humans because doing so involves critical consideration of the meaning of the information and its informative, misinformative or dis-informative value, which is related to the accuracy and reliability of the news. To explore human-based judgement methods, we developed the Information Disorder Level (IDL) index, a language-independent metric to evaluate the factuality of machine-generated content. It has been tested on a corpus of forty made-up and actual news stories generated with ChatGPT. For newsrooms using generative AI, results suggest that every piece of machine-generated content should be vetted and post-edited by humans before being published. From a digital media literacy perspective, the IDL index is a valuable tool to understand the limits of generative AI and trigger a reflection on what constitutes the factuality of a reported event.	[Dierickx, Laurence; Linden, Carl-Gustav; Opdahl, Andreas L.] Univ Bergen, Bergen, Norway	University of Bergen	Opdahl, AL (corresponding author), Univ Bergen, Bergen, Norway.	l.dierickx@uib.no; carl-gustav.linden@uib.no; andreas.opdahl@uib.no	Opdahl, Andreas Lothe/B-5508-2015	Opdahl, Andreas Lothe/0000-0002-3141-1385; Dierickx, Laurence/0000-0001-5926-8720	EU CEF Grant [2394203]	EU CEF Grant	This research was funded by EU CEF Grant No. 2394203.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Belz A., 2006, P 11 C EUR CHAPT ASS, P313; Buholayka M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39386; Clerwall C, 2014, JOURNAL PRACT, V8, P519, DOI 10.1080/17512786.2014.883116; Crothers E, 2023, Arxiv, DOI arXiv:2210.07321; Dale R., 2007, P WORKSHOP SHARED TA, P1; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Dierickx L., 2023, Int. J. Commun., V17, P21; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Ferrara E., 2023, First Monday; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gehrmann S, 2019, Arxiv, DOI arXiv:1906.04043; Giansiracusa N., 2021, APress; Graefe A., 2015, 11 DUBROVNIK MEDIA D; Graves L., 2018, UNDERSTANDING PROMIS; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haim M, 2017, DIGIT JOURNAL, V5, P1044, DOI 10.1080/21670811.2017.1345643; Hanitzsch T, 2007, COMMUN THEOR, V17, P367, DOI 10.1111/j.1468-2885.2007.00303.x; Hanley HWA, 2024, Arxiv, DOI arXiv:2305.09820; Henriksson T., 2023, New survey finds half of newsrooms use Generative AI tools; only 20% have guidelines in place-WAN-IFRA; Johnston J, 2012, JOURNALISM STUD, V13, P517, DOI 10.1080/1461670X.2011.629803; Jurish B., 2013, JLCL, V28, P61; Kirchner Jan Hendrik, 2023, New ai classifier for indicating ai-written text; Kumarage T, 2023, Arxiv, DOI arXiv:2309.03164; Lazarski Eric, 2021, Designs, V5, DOI 10.3390/designs5030042; Lester JC, 1997, COMPUT LINGUIST, V23, P65; Li Z, 2023, arXiv; Matusov Evgeny, 2005, P 2 INT WORKSHOP SPO; Melin M, 2018, IEEE ACCESS, V6, P43356, DOI 10.1109/ACCESS.2018.2861987; Pu J., 2022, arXiv; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Reiter E, 2009, COMPUT LINGUIST, V35, P529, DOI 10.1162/coli.2009.35.4.35405; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Schlichtkrull M, 2023, Arxiv, DOI arXiv:2304.14238; Schuster T, 2020, COMPUT LINGUIST, V46, P499, DOI [10.1162/COLI_a_00380, 10.1162/coli_a_00380]; Tandoc EC, 2021, MEDIA COMMUN-LISBON, V9, P110, DOI 10.17645/mac.v9i1.3331; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; Thomson C, 2020, Arxiv, DOI [arXiv:2011.03992, DOI arXiv:2011.03992.null]; van der Kaa HAJ., 2014, P COMPUTATION JOURNA; van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151; Walter N, 2021, MASS COMMUN SOC, V24, P500, DOI 10.1080/15205436.2020.1864406; Ward SJA, 2020, ROUTL HANDBK, P101; Wardle Claire, 2017, Information Disorder: Toward an Interdisciplinary Framework for Research and Policymaking; Weber-Wulff D, 2023, Arxiv, DOI [arXiv:2306.15666, 10.48550/arXiv.2306.15666, DOI 10.48550/ARXIV.2306.15666]; Wölker A, 2021, JOURNALISM, V22, P86, DOI 10.1177/1464884918757072; Zellers R, 2020, Arxiv, DOI arXiv:1905.12616	47	0	0	6	6	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-47895-6; 978-3-031-47896-3	LECT NOTES COMPUT SC			2023	14397						60	71		10.1007/978-3-031-47896-3_5	http://dx.doi.org/10.1007/978-3-031-47896-3_5			12	Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Communication; Computer Science	BW5HO		Green Published, hybrid			2024-07-03	WOS:001160755400005
J	Kawasaki, R				Kawasaki, Ryo			How Can Artificial Intelligence Be Implemented Effectively in Diabetic Retinopathy Screening in Japan?	MEDICINA-LITHUANIA			English	Review						diabetic retinopathy; artificial intelligence; systematic screening; large language models	VALIDATION	Diabetic retinopathy (DR) is a major microvascular complication of diabetes, affecting a substantial portion of diabetic patients worldwide. Timely intervention is pivotal in mitigating the risk of blindness associated with DR, yet early detection remains a challenge due to the absence of early symptoms. Screening programs have emerged as a strategy to address this burden, and this paper delves into the role of artificial intelligence (AI) in advancing DR screening in Japan. There are two pathways for DR screening in Japan: a health screening pathway and a clinical referral path from physicians to ophthalmologists. AI technologies that realize automated image classification by applying deep learning are emerging. These technologies have exhibited substantial promise, achieving sensitivity and specificity levels exceeding 90% in prospective studies. Moreover, we introduce the potential of Generative AI and large language models (LLMs) to transform healthcare delivery, particularly in patient engagement, medical records, and decision support. Considering the use of AI in DR screening in Japan, we propose to follow a seven-step framework for systematic screening and emphasize the importance of integrating AI into a well-designed screening program. Automated scoring systems with AI enhance screening quality, but their effectiveness depends on their integration into the broader screening ecosystem. LLMs emerge as an important tool to fill gaps in the screening process, from personalized invitations to reporting results, facilitating a seamless and efficient system. However, it is essential to address concerns surrounding technical accuracy and governance before full-scale integration into the healthcare system. In conclusion, this review highlights the challenges in the current screening pathway and the potential for AI, particularly LLM, to revolutionize DR screening in Japan. The future direction will depend on leadership from ophthalmologists and stakeholders to address long-standing challenges in DR screening so that all people have access to accessible and effective screening.	[Kawasaki, Ryo] Osaka Univ, Grad Sch Med, Dept Social Med, Div Publ Hlth, Suita 5650871, Japan; [Kawasaki, Ryo] Osaka Univ Hosp, Artificial Intelligence Ctr Med Res & Applicat, Suita 5650871, Japan	Osaka University; Osaka University	Kawasaki, R (corresponding author), Osaka Univ, Grad Sch Med, Dept Social Med, Div Publ Hlth, Suita 5650871, Japan.; Kawasaki, R (corresponding author), Osaka Univ Hosp, Artificial Intelligence Ctr Med Res & Applicat, Suita 5650871, Japan.	rkawasaki@pbhel.med.osaka-u.ac.jp		Kawasaki, Ryo/0000-0002-7492-6303	Grants-in-Aid for Scientific Research (Japan)	Grants-in-Aid for Scientific Research (Japan)(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	No Statement Available	Abràmoff MD, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0040-6; Beede E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376718; Bellemo V, 2019, LANCET DIGIT HEALTH, V1, pE35, DOI 10.1016/S2589-7500(19)30004-4; Betzler BK, 2023, LANCET DIGIT HEALTH, V5, pE917, DOI 10.1016/S2589-7500(23)00201-7; deepeyevision.com, DeepEyeVision Inc Web Site; drscreening2005.org.uk, The Screening for Diabetic Retinopathy in Europe Web Site; Garvican L, 2000, DIABETIC MED, V17, P627, DOI 10.1046/j.1464-5491.2000.00353.x; Gulshan V, 2019, JAMA OPHTHALMOL, V137, P987, DOI 10.1001/jamaophthalmol.2019.2004; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Heydon P, 2021, BRIT J OPHTHALMOL, V105, P723, DOI 10.1136/bjophthalmol-2020-316594; Ihana-Sugiyama N, 2023, J DIABETES INVEST, V14, P883, DOI 10.1111/jdi.14018; Japan Society for Ningen Dock, About us; Japanese Society of Cardiovascular Disease Prevention, About us; Maeda John, TED Talk; Ministry of Health Labour and Welfare, SPEC HLTH CHECK SPEC; Norgaard MF, 2018, OPHTHALMIC RES, V60, P9, DOI 10.1159/000486284; Nosrati H, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8050442; Raumviboonsuk P, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0099-8; Saeedi P, 2019, DIABETES RES CLIN PR, V157, DOI 10.1016/j.diabres.2019.107843; Steinmetz JD, 2021, LANCET GLOB HEALTH, V9, pE144, DOI [10.1016/S2214-109X(20)30489-7, 10.1016/S2214-109X(20)30425-3]; Teo ZL, 2021, OPHTHALMOLOGY, V128, P1580, DOI 10.1016/j.ophtha.2021.04.027; The Japanese Society of Ophthalmic Diabetology Clinical Guideline Committee, 2020, J. Jpn. Ophthalmol. Soc, V124, P953; van der Heijden AA, 2018, ACTA OPHTHALMOL, V96, P63, DOI 10.1111/aos.13613; Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5; Yau JWY, 2012, DIABETES CARE, V35, P556, DOI 10.2337/dc11-1909; Zhang YF, 2020, BMJ OPEN DIAB RES CA, V8, DOI 10.1136/bmjdrc-2020-001596	26	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1010-660X	1648-9144		MEDICINA-LITHUANIA	Med. Lith.	FEB	2024	60	2							243	10.3390/medicina60020243	http://dx.doi.org/10.3390/medicina60020243			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	JI6L4	38399532	Green Published, gold			2024-07-03	WOS:001172574500001
J	Loakes, D				Loakes, Debbie			Automatic speech recognition and the transcription of indistinct forensic audio: how do the new generation of systems fare?	FRONTIERS IN COMMUNICATION			English	Article						forensic linguistics; transcription; automatic speech recognition (ASR); phonetics; artificial intelligence		This study provides an update on an earlier study in the "Capturing Talk" research topic, which aimed to demonstrate how automatic speech recognition (ASR) systems work with indistinct forensic-like audio, in comparison with good-quality audio. Since that time, there has been rapid technological advancement, with newer systems having access to extremely large language models and having their performance proclaimed as being human-like in accuracy. This study compares various ASR systems, including OpenAI's Whisper, to continue to test how well automatic speaker recognition works with forensic-like audio. The results show that the transcription of a good-quality audio file is at ceiling for some systems, with no errors. For the poor-quality (forensic-like) audio, Whisper was the best performing system but had only 50% of the entire speech material correct. The results for the poor-quality audio were also generally variable across the systems, with differences depending on whether a .wav or .mp3 file was used and differences between earlier and later versions of the same system. Additionally, and against expectations, Whisper showed a drop in performance over a 2-month period. While more material was transcribed in the later attempt, more was also incorrect. This study concludes that forensic-like audio is not suitable for automatic analysis.	[Loakes, Debbie] Univ Melbourne, Sch Languages & Linguist, Res Hub Language Forens Evidence, Parkville, Vic, Australia	University of Melbourne	Loakes, D (corresponding author), Univ Melbourne, Sch Languages & Linguist, Res Hub Language Forens Evidence, Parkville, Vic, Australia.	dloakes@unimelb.edu.au			University of Melbourne10.13039/501100001782	University of Melbourne10.13039/501100001782	The author thanks Helen Fraser for assistance with ideas in this manuscript and discussion of issues surrounding the main themes within and Yuko Kinoshita for running the March 2023 Whisper attempt.	Andronic Iustina, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P22, DOI 10.1007/978-3-030-60276-5_3; Bender E., 2022, Cognitive Science Society YouTube; Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006; Bridle J., 2023, The Guardian16 de marzo de; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; Fetzer J.H., 1990, Artificial In- telligence: Its Scope and Limits. Studies in Cognitive Systems, P3, DOI [10.1007/978-94-009-190 0-6_1, DOI 10.1007/978-94-009-1900-6_1, 10.1007/978-94-009-1900-6_1]; Fraser H., 2023, 31 IAFPA C, P21; Fraser H, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.898410; Harrington L., 2022, 2022 C INT ASS FOREN; Harrington L., 2023, Paper ID: 593, P3131; Harrington L, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1165233; Koenecke A, 2020, P NATL ACAD SCI USA, V117, P7684, DOI 10.1073/pnas.1915768117; Loakes D, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.803452; Love R, 2021, FRONT COMMUN, V6, DOI 10.3389/fcomm.2021.797448; Markl Nina, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P521, DOI 10.1145/3531146.3533117; Markl N, 2022, Arxiv, DOI [arXiv:2202.12603, 10.48550/arXiv.2202.12603, DOI 10.48550/ARXIV.2202.12603]; McCarthy J., 2007, WHAT IS ARTIFICIAL INTELLIGENCE?; Morozov E., 2013, To Save Everything, Click Here: The Folly of Technological Solutionism; Nolan F, 2009, INT J SPEECH LANG LA, V16, P31, DOI 10.1558/ijsll.v16i1.31; 'Shaughnessy D, 2023, COMPUT SPEECH LANG, V83, DOI 10.1016/j.csl.2023.101538; Perrigo Billy, 2023, Openai used kenyan workers on less than $2 per hour: Exclusive; Plumb T., 2022, How descript's generative AI makes video editing as easy as updating text Venturebeat.com; Preston L., 2022, The Guardian; Rodriguez J., 2022, OpenAI's new super model: Whisper achieves human level performance in speech recognition medium; Wassink AB, 2022, SPEECH COMMUN, V140, P50, DOI 10.1016/j.specom.2022.03.009	25	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2297-900X		FRONT COMMUN	Front. Commun.	FEB 14	2024	9								1281407	10.3389/fcomm.2024.1281407	http://dx.doi.org/10.3389/fcomm.2024.1281407			9	Communication	Emerging Sources Citation Index (ESCI)	Communication	JJ3M9		gold			2024-07-03	WOS:001172759500001
C	Macina, J; Daheim, N; Wang, LZ; Sinha, T; Kapur, M; Gurevych, I; Sachan, M		Vlachos, A; Augenstein, I		Macina, Jakub; Daheim, Nico; Wang, Lingzhi; Sinha, Tanmay; Kapur, Manu; Gurevych, Iryna; Sachan, Mrinmaya			Opportunities and Challenges in Neural Dialog Tutoring	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape			AUTOTUTOR	Designing dialog tutors has been challenging as it involves modeling the diverse and complex pedagogical strategies employed by human tutors. Although there have been significant recent advances in neural conversational systems using large language models (LLMs) and growth in available dialog corpora, dialog tutoring has largely remained unaffected by these advances. In this paper, we rigorously analyze various generative language models on two dialog tutoring datasets for language learning using automatic and human evaluations to understand the new opportunities brought by these advances as well as the challenges we must overcome to build models that would be usable in real educational settings. We find that although current approaches can model tutoring in constrained learning scenarios when the number of concepts to be taught and possible teacher strategies are small, they perform poorly in less constrained scenarios. Our human quality evaluation shows that both models and ground-truth annotations exhibit low performance in terms of equitable tutoring, which measures learning opportunities for students and how engaging the dialog is. To understand the behavior of our models in a real tutoring setting, we conduct a user study using expert annotators and find a significantly large number of model reasoning errors in 45% of conversations. Finally, we connect our findings to outline future work.	[Macina, Jakub; Sachan, Mrinmaya] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland; [Macina, Jakub] ETH AI Ctr, Zurich, Switzerland; [Daheim, Nico; Gurevych, Iryna] Tech Univ Darmstadt, Dept Comp Sci, Ubiquitous Knowledge Proc Lab UKP Lab, Darmstadt, Germany; [Daheim, Nico; Gurevych, Iryna] Tech Univ Darmstadt, Hessian Ctr AI hessian AI, Darmstadt, Germany; [Wang, Lingzhi] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Sinha, Tanmay; Kapur, Manu] Swiss Fed Inst Technol, Professorship Learning Sci & Higher Educ, Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich; Technical University of Darmstadt; Technical University of Darmstadt; Chinese University of Hong Kong; Swiss Federal Institutes of Technology Domain; ETH Zurich	Macina, J (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.; Macina, J (corresponding author), ETH AI Ctr, Zurich, Switzerland.		sinha, tanmay/ABG-9711-2020; WANG, Lingzhi/GNM-9660-2022	sinha, tanmay/0000-0003-3069-2899; WANG, Lingzhi/0000-0002-1346-2437	Asuera Stiftung; ETH Zurich Foundation; German Federal Ministry of Education and Research; Hessian Ministry of Higher Education, Research, Science and the Arts	Asuera Stiftung; ETH Zurich Foundation(ETH Zurich); German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Hessian Ministry of Higher Education, Research, Science and the Arts	This project was made possible by an ETH AI Center Doctoral Fellowship to Jakub Macina with partial support by the Asuera Stiftung and the ETH Zurich Foundation and has received funding by the German Federal Ministry of Education and Research and the Hessian Ministry of Higher Education, Research, Science and the Arts within their joint support of the National Research Center for Applied Cybersecurity ATHENE. We thank the group members and our reviewers for their valuable feedback.	Adiwardana D., 2020, ABS200109977 ARXIV; Bommasani Rishi, 2021, ARXIV210807258; Caines Andrew, 2020, P 9 WORKSH NLP COMP, P10; Chi MTH, 2014, EDUC PSYCHOL-US, V49, P219, DOI 10.1080/00461520.2014.965823; CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1016/0364-0213(94)90016-7; Cohen AaronDaniel., 2022, Lamda: Language models for dialog applications; CORBETT AT, 1994, USER MODEL USER-ADAP, V4, P253, DOI 10.1007/BF01099821; Demszky D, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1638; Dinan E, 2020, SPRING SER CHALLENGE, P187, DOI 10.1007/978-3-030-29135-8_7; Dinan Emily, 2019, 7 INT C LEARN REPR I; Eric M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P422; Freeman S, 2014, P NATL ACAD SCI USA, V111, P8410, DOI 10.1073/pnas.1319030111; GRAESSER AC, 1995, APPL COGNITIVE PSYCH, V9, P495, DOI 10.1002/acp.2350090604; Graesser AC, 2016, INT J ARTIF INTELL E, V26, P124, DOI 10.1007/s40593-015-0086-4; Graesser Arthur C, 2009, HDB METACOGNITION ED, P373; Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631; Hall M. W., 2010, ACCOUNTABLE TALK SOU; He Wanwei, 2022, P AAAI C ART INT; Honovich O, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7856; Ji Ziwei, 2022, ACM COMPUTING SURVEY; Keskar N. S., 2019, ABS190905858 CORR; Kim S, 2020, SIGDIAL 2020: 21ST ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2020), P278; Komeili M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8460; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Litman D.J., 2006, INT J ARTIFICIAL INT, V16, P145; Mehri S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P681; Moon S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P845; Moore JohannaD., 2004, Proceedings of the FLAIRS Conference, P923; Nye B, 2014, INT J ARTIF INTELL E, V24, P427, DOI 10.1007/s40593-014-0029-5; Peng BL, 2021, T ASSOC COMPUT LING, V9, P807, DOI 10.1162/tacl_a_00399; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Qin L, 2022, MOL INFORM, V41, DOI 10.1002/minf.202200001; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rashkin H, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P704; Reiser BJ, 2004, J LEARN SCI, V13, P273, DOI 10.1207/s15327809jls1303_2; Roschelle J., 1995, Computer Supported Collaborative Learning. Proceedings NATO Advanced Research Workshop, P69; Ruan S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300587; Schick T, 2022, T ASSOC COMPUT LING, V10, P716, DOI 10.1162/tacl_a_00485; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; Sinha T, 2021, REV EDUC RES, V91, P761, DOI 10.3102/00346543211019105; Stasaski K, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P52; Suresh A., 2022, P 17 WORKSH INN US N, P71; Suresh Abhijit, 2022, ARXIV220409652; Sutskever I, 2014, ADV NEUR IN, V27; Tack Anais, 2022, 15 INT C ED DAT MIN; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhao R, 2016, LECT NOTES ARTIF INT, V10011, P218, DOI 10.1007/978-3-319-47665-0_20; Zhou KY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P708	52	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							2357	2372						16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056901014
C	Nishikino, K; Kobayashi, K		Koutra, D; Plant, C; Rodriguez, MG; Baralis, E; Bonchi, F		Nishikino, Keizaburo; Kobayashi, Kenichi			Adversarial Imitation Learning with Controllable Rewards for Text Generation	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES: RESEARCH TRACK, ECML PKDD 2023, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 18-22, 2023	Turin, ITALY	CENTAI, Politecnico Torino, AFC Digital Hub, ASML, ThermoFisher Sci, Volkswagen Grp, AstraZeneca, CRITEO, Google, Mercari, Bosch, KNIME, SoBigData, Two Sigma, SIG Susquehanna		Text generation; Adversarial imitation learning; Reinforcement learning		Supervised fine-tuning of large language models (LMs) does not always provide good text-generation performance in terms of quality and diversity. This is because such models maximize the likelihood of correct subsequent words based on previous contexts encountered in the training phase, instead of evaluating the entire structure of the generated texts. In this context, fine-tuning methods for LMs using adversarial imitation learning (AIL) have been proposed to improve the trade-off relationship between quality and diversity. This method leverages the evaluations of the discriminators without requiring manually designed metrics. Previously proposed AIL methods cannot control the shapes of the reward functions and constrain updates of LMs using fixed ranges, independent of the quality, e.g., proximal policy optimization. This study proposes a combination of an AIL method and an approximation of mixture distributions (AMDAIL), synergizing with LMs for text generation. AMDAIL exhibits two features: (1) controlling the distribution of the bounded reward values by varying the shape of the bounded reward function, and (2) a variable constraint to promote updates using the confidence of the discriminator as the quality of the texts. The proposed method exhibits stable behavior in the training phases and improves the trade-off relationship between the quality and diversity in the inference phases.	[Nishikino, Keizaburo; Kobayashi, Kenichi] Fujitsu Ltd, Fujitsu Res, Kawasaki, Kanagawa, Japan	Fujitsu Ltd	Nishikino, K (corresponding author), Fujitsu Ltd, Fujitsu Res, Kawasaki, Kanagawa, Japan.	nishikino@fujitsu.com; kenichi@fujitsu.com						Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Fu J., 2018, INT C LEARNING REPRE; Ghasemipour S.K.S., 2020, C ROBOT LEARNING, P1259, DOI DOI 10.48550/ARXIV.1911.02256; Goodfellow I., 2014, ADV NEURAL INFORM PR, V27, DOI DOI 10.1016/J.ERGON.2011.05.001; Guo JX, 2018, AAAI CONF ARTIF INTE, P5141; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Ho J, 2016, ADV NEUR IN, V29; Holtzman A., 2019, INT C LEARNING REPRE; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; KLOEK T, 1978, ECONOMETRICA, V46, P1, DOI 10.2307/1913641; Lamprier S, 2022, PR MACH LEARN RES; Li J., 2016, P 2016 C N AM CHAPTE, P110, DOI DOI 10.18653/V1; Lin BY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1823; Lin K, 2017, 31 ANN C NEURAL INFO, V30; Mostafazadeh Nasrin, 2016, P 2016 C N AM CHAPTE, P839, DOI [10.18653/v1/N16-1098, DOI 10.18653/V1/N16-1098]; Ouyang L., 2022, Advances in Neural Information Processing Systems; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Schulman J, 2015, PR MACH LEARN RES, V37, P1889; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Torabi F, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6325; Welleck S, 2020, INT C LEARNING REPRE; Wu QY, 2021, AAAI CONF ARTIF INTE, V35, P14067; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao MY, 2020, AAAI CONF ARTIF INTE, V34, P6901; Zhou W, 2020, INT C LEARNING REPRE	28	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-43411-2; 978-3-031-43412-9	LECT NOTES ARTIF INT			2023	14169						131	146		10.1007/978-3-031-43412-9_8	http://dx.doi.org/10.1007/978-3-031-43412-9_8			16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4VZ					2024-07-03	WOS:001156137100008
C	Qiao, YY; Qi, YK; Yu, Z; Liu, J; Wu, Q			IEEE	Qiao, Yanyuan; Qi, Yuankai; Yu, Zheng; Liu, Jing; Wu, Qi			March in Chat: Interactive Prompting for Remote Embodied Referring Expression	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent years, from room-based to object-based and indoor to outdoor. The REVERIE (Remote Embodied Referring Expression) is interesting since it only provides high-level instructions to the agent, which are closer to human commands in practice. Nevertheless, this poses more challenges than other VLN tasks since it requires agents to infer a navigation plan only based on a short instruction. Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still, this strategy has not been explored under the REVERIE settings. There are several new challenges. For example, the LLM should be environment-aware so that the navigation plan can be adjusted based on the current visual observation. Moreover, the LLM planned actions should be adaptable to the much larger and more complex REVERIE environment. This paper proposes a March-in-Chat (MiC) model that can talk to the LLM on the fly and plan dynamically based on a newly proposed Room-and-Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the previous state-of-the-art by large margins by SPL and RGSPL metrics on the REVERIE benchmark. The source code is available at https://github.com/YanyuanQiao/MiC	[Qiao, Yanyuan; Qi, Yuankai; Yu, Zheng; Wu, Qi] Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA, Australia; [Liu, Jing] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China; [Liu, Jing] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China	University of Adelaide; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Wu, Q (corresponding author), Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA, Australia.	yanyuan.qiao@adelaide.edu.au; qi.wu01@adelaide.edu.au; zheng.yu@adelaide.edu.au; jliu@nlpr.ia.ac.cn; qykshr@gmail.com		Qi, Yuankai/0000-0003-4312-5682	National Key Research and Development Program of China [2020AAA0106400]	National Key Research and Development Program of China	Jing Liu is supported by the National Key Research and Development Program of China (No. 2020AAA0106400).	Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; An D, 2023, Arxiv, DOI arXiv:2212.04385; Anderson P, 2018, Arxiv, DOI [arXiv:1807.06757, DOI 10.48550/ARXIV.1807.06757]; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081; Chen H, 2019, PROC CVPR IEEE, P12530, DOI 10.1109/CVPR.2019.01282; Chen M., 2021, arXiv; Chen SZ, 2021, ADV NEUR IN, V34; Chen SZ, 2022, LECT NOTES COMPUT SC, V13699, P638, DOI 10.1007/978-3-031-19842-7_37; Chen SZ, 2022, PROC CVPR IEEE, P16516, DOI 10.1109/CVPR52688.2022.01604; Gao C, 2021, PROC CVPR IEEE, P3063, DOI 10.1109/CVPR46437.2021.00308; Guhur P., 2021, P IEEECVF INT C COMP, P1634; He Keji, 2021, NeurIPS, P652; Hong YC, 2021, PROC CVPR IEEE, P1643, DOI 10.1109/CVPR46437.2021.00169; Hong Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3360; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Huang WL, 2022, PR MACH LEARN RES; Jain V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1862; Johnson M., 2017, Google's multilingual neural machine translation system: Enabling zero-shot translation, V5, P339, DOI 10.1162/tacla00065; Nguyen K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P684; Ku A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4392; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Ma C., 2019, ICLR; Poesia Gabriel, 2022, ICLR; Qi Y., 2021, ICCV, P1655; Qiao YY, 2022, PROC CVPR IEEE, P15397, DOI 10.1109/CVPR52688.2022.01498; Qiao Yanyuan, 2023, IEEE TPAMI, P2; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Singh Ishika, 2022, Progprompt: Generating situated robot task plans using large language models; Song CH, 2023, Arxiv, DOI [arXiv:2212.04088, 10.48550/arXiv.2212.04088]; Thomason Jesse, 2019, CoRL, V100, P394; Xin Wang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P6622, DOI 10.1109/CVPR.2019.00679; Yuankai Qi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9979, DOI 10.1109/CVPR42600.2020.01000; Zhao Yusheng, 2022, Targetdriven structured transformer planner for vision-language navigation, P4194; Zhu FD, 2021, PROC CVPR IEEE, P12684, DOI 10.1109/CVPR46437.2021.01250	39	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							15712	15721		10.1109/ICCV51070.2023.01444	http://dx.doi.org/10.1109/ICCV51070.2023.01444			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO		Green Submitted			2024-07-03	WOS:001169500500008
C	Fernandez, N; Ghosh, A; Liu, NM; Wang, ZC; Choffin, B; Baraniuk, R; Lan, A		Rodrigo, MM; Matsuda, N; Cristea, AI; Dimitrova, V		Fernandez, Nigel; Ghosh, Aritra; Liu, Naiming; Wang, Zichao; Choffin, Benoit; Baraniuk, Richard; Lan, Andrew			Automated Scoring for Reading Comprehension via In-context BERT Tuning	ARTIFICIAL INTELLIGENCE IN EDUCATION, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	23rd International Conference on Artificial Intelligence in Education (AIED)	JUL 27-31, 2022	Durham Univ, Durham, ENGLAND		Durham Univ	Automated scoring; BERT; Reading comprehension		Automated scoring of open-ended student responses has the potential to significantly reduce human grader effort. Recent advances in automated scoring leverage textual representations from pre-trained language models like BERT. Existing approaches train a separate model for each item/question, suitable for scenarios like essay scoring where items can be different from one another. However, these approaches have two limitations: 1) they fail to leverage item linkage for scenarios such as reading comprehension where multiple items may share a reading passage; 2) they are not scalable since storing one model per item is difficult with large language models. We report our (grand prize-winning) solution to the National Assessment of Education Progress (NAEP) automated scoring challenge for reading comprehension. Our approach, in-context BERT fine-tuning, produces a single shared scoring model for all items with a carefully designed input structure to provide contextual information on each item. Our experiments demonstrate the effectiveness of our approach which outperforms existing methods. We also perform a qualitative analysis and discuss the limitations of our approach. (Full version of the paper can be found at: https://arxiv.org/abs/2205.09864 Our implementation can be found at: https://github.com/ni9elf/automatedscoring).	[Fernandez, Nigel; Ghosh, Aritra; Lan, Andrew] Univ Massachusetts, Amherst, MA 01003 USA; [Liu, Naiming; Wang, Zichao; Baraniuk, Richard] Rice Univ, Houston, TX 77005 USA	University of Massachusetts System; University of Massachusetts Amherst; Rice University	Lan, A (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.	andrewlan@cs.umass.edu	Ghosh, Aritra/GLN-3465-2022	Ghosh, Aritra/0000-0003-2024-2173; Lan, Andrew/0000-0002-8475-6600				Attali Y., 2006, J TECHNOL LEARN ASSE, V4, P1650; Baral S., 2021, 14 INT C ED DATA MIN; Chen Y., 2022, 60 ANN M ASS COMPUTA; Devlin J., 2018, BERT PRE TRAINING DE; Graesser AC, 2004, BEHAV RES METH INS C, V36, P193, DOI 10.3758/BF03195564; Lottridge S., 2021, COMP ROBUSTNESS DEEP; Mayfield E, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P151; McNamara DS, 2015, ASSESS WRIT, V23, P35, DOI 10.1016/j.asw.2014.09.002; Min S., 2022, NAACL HLT; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Persing I, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1534; Sung C., 2019, P 2019 C EMPIRICAL M, P6071; The hewlett foundation, AUTOMATED ESSAY SCOR; Uto M., 2020, P 28 INT C COMP LING, P6077	14	2	2	0	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-11644-5; 978-3-031-11643-8	LECT NOTES COMPUT SC			2022	13355						691	697		10.1007/978-3-031-11644-5_69	http://dx.doi.org/10.1007/978-3-031-11644-5_69			7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BU1FW		Green Submitted			2024-07-03	WOS:000877435100069
J	Leng, LG				Leng, Lige			Challenge, integration, and change: ChatGPT and future anatomical education	MEDICAL EDUCATION ONLINE			English	Article						ChatGPT; artificial intelligence; anatomy; medical education; educational reform		With the vigorous development of ChatGPT and its application in the field of education, a new era of the collaborative development of human and artificial intelligence and the symbiosis of education has come. Integrating artificial intelligence (AI) into medical education has the potential to revolutionize it. Large language models, such as ChatGPT, can be used as virtual teaching aids to provide students with individualized and immediate medical knowledge, and conduct interactive simulation learning and detection. In this paper, we discuss the application of ChatGPT in anatomy teaching and its various application levels based on our own teaching experiences, and discuss the advantages and disadvantages of ChatGPT in anatomy teaching. ChatGPT increases student engagement and strengthens students' ability to learn independently. At the same time, ChatGPT faces many challenges and limitations in medical education. Medical educators must keep pace with the rapid changes in technology, taking into account ChatGPT's impact on curriculum design, assessment strategies and teaching methods. Discussing the application of ChatGPT in medical education, especially anatomy teaching, is helpful to the effective integration and application of artificial intelligence tools in medical education.	[Leng, Lige] Xiamen Univ, Inst Neurosci, Sch Med, Fujian Prov Key Lab Neurodegenerat Dis & Aging Res, Xiamen, Fujian, Peoples R China; [Leng, Lige] Xiamen Univ, Inst Neurosci, Coll Med, Xiamen 361005, Fujian, Peoples R China	Xiamen University; Xiamen University	Leng, LG (corresponding author), Xiamen Univ, Inst Neurosci, Coll Med, Xiamen 361005, Fujian, Peoples R China.	lenglige@xmu.edu.cn			Fujian Province undergraduate education teaching research project [FBJY20230241]	Fujian Province undergraduate education teaching research project	Fujian Province undergraduate education teaching research project [Grant FBJY20230241 to L.L.]	Abdellatif H, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph192114209; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Bhattacharya K, 2023, INDIAN J SURG, V85, P1346, DOI 10.1007/s12262-023-03727-x; Butt UD, 2024, PROBIOTICS ANTIMICRO, V16, P426, DOI 10.1007/s12602-023-10053-x; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Hsiao IH, 2010, J COMPUT ASSIST LEAR, V26, P270, DOI 10.1111/j.1365-2729.2010.00365.x; Ilgaz HB, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45301; Klimova B, 2023, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1118116; Lazarus MD, 2024, ANAT SCI EDUC, V17, P249, DOI 10.1002/ase.2221; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Li YS, 2021, MED SCI EDUC, V31, P1729, DOI 10.1007/s40670-021-01405-9; Lonergan RM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.48788; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Totlis T, 2023, SURG RADIOL ANAT, V45, P1321, DOI 10.1007/s00276-023-03229-1; Wang XF, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100905; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216	24	2	2	153	153	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1087-2981			MED EDUC ONLINE	Med. Educ. Online	DEC 31	2024	29	1							2304973	10.1080/10872981.2024.2304973	http://dx.doi.org/10.1080/10872981.2024.2304973			9	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	EX1T6	38217884	gold			2024-07-03	WOS:001142147300001
J	Kwon, T; Di Palo, N; Johns, E				Kwon, Teyun; Di Palo, Norman; Johns, Edward			Language Models as Zero-Shot Trajectory Generators	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						Task analysis; Robots; Trajectory; End effectors; Codes; Robot kinematics; Object detection; AI-based methods; big data in robotics and automation; deep learning in grasping and manipulation		Large Language Models (LLMs) have recently shown promise as high-level planners for robots when given access to a selection of low-level skills. However, it is often assumed that LLMs do not possess sufficient knowledge to be used for the low-level trajectories themselves. In this work, we address this assumption thoroughly, and investigate if an LLM (GPT-4) can directly predict a dense sequence of end-effector poses for manipulation tasks, when given access to only object detection and segmentation vision models. We designed a single, task-agnostic prompt, without any in-context examples, motion primitives, or external trajectory optimisers. Then we studied how well it can perform across 30 real-world language-based tasks, such as "open the bottle cap" and "wipe the plate with the sponge", and we investigated which design choices in this prompt are the most important. Our conclusions raise the assumed limit of LLMs for robotics, and we reveal for the first time that LLMs do indeed possess an understanding of low-level robot control sufficient for a range of common tasks, and that they can additionally detect failures and then re-plan trajectories accordingly.	[Kwon, Teyun; Di Palo, Norman; Johns, Edward] Imperial Coll London, Robot Learning Lab, London SW7 2AZ, England	Imperial College London	Kwon, T (corresponding author), Imperial Coll London, Robot Learning Lab, London SW7 2AZ, England.	john.kwon20@imperial.ac.uk; n.di-palo20@imperial.ac.uk; e.johns@imperial.ac.uk			Royal Academy of Engineering	Royal Academy of Engineering(Royal Academy of Engineering - UK)	No Statement Available	Ahn M., 2022, P 6 C ROB LEARN, P287; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Anthropic, Model card and evaluations for claude models; Anthropic, The claude 3 model family: Opus, sonnet, haiku; Brohan A., 2023, P ROB SCI SYST DAEG, DOI DOI 10.15607/RSS.2023.XIX.025; Chen M., 2021, arXiv; Cheng HK, 2022, LECT NOTES COMPUT SC, V13688, P640, DOI 10.1007/978-3-031-19815-1_37; Di Palo N., 2024, P IEEE INT C ROB AUT; Di Palo N., 2024, P ROB SCI SYST DELFT; Di Palo N., 2023, P WORKSH REINC REINF; Di Palo N, 2024, IEEE ROBOT AUTOM LET, V9, P2032, DOI 10.1109/LRA.2024.3349832; Driess D., 2023, INT C MACHINE LEARNI, P8469; Hoffmann J., 2022, P ADV NEUR INF PROC, V35, P30016; Huang W, 2022, C ROBOT LEARNING P M, P1769; Huang W, 2023, P C ROBOT LEARNING C, P540; Huang W., 2022, PROC INT C MACHINE L, P9118; Kapelyukh I, 2023, IEEE ROBOT AUTOM LET, V8, P3956, DOI 10.1109/LRA.2023.3272516; Kapelyukh L., 2024, P IEEE INT C ROB AUT; Kerr J., 2023, P IEEECVF INT C COMP, P19729; Kirillov A, 2023, IEEE I CONF COMP VIS, P3992, DOI 10.1109/ICCV51070.2023.00371; Kojima T., 2022, Advances in neural information processing systems, V35, P22199, DOI DOI 10.48550/ARXIV.2205.11916; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Liu SL, 2023, Arxiv, DOI arXiv:2303.05499; Luo HP, 2023, Arxiv, DOI arXiv:2308.09583; Medeiros L., Langsam: Language segment-anything; Mirchandani S., 2023, P 7 C ROB LEARN, P2498; Rashid A., 2023, P 7 ANN C ROB LEARN, V229, P178; Shen W., 2023, P 7 C ROB LEARN, V229, P405; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vemprala S., 2023, Tech. Rep. MSR-TR-2023-8; Wang L., 2024, Frontiers of Computer Science, V18, P1; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Xiao T., 2023, P ROB SCI SYST DAEG, DOI [10.15607/RSS.2023.XIX.029, DOI 10.15607/RSS.2023.XIX.029]; Yu T., 2023, P ROB SCI SYST DAEG, DOI DOI 10.15607/RSS.2023.XIX.027; Yu W., 2023, P 7 C ROB LEARN, P374; Zeng A., 2023, P 11 INT C LEARN REP; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zitkovich B., 2023, C ROBOT LEARNING, P2165	39	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	JUL	2024	9	7					6728	6735		10.1109/LRA.2024.3410155	http://dx.doi.org/10.1109/LRA.2024.3410155			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	UP7Z6		Green Submitted			2024-07-03	WOS:001249341200002
J	Zhang, CM; Hofmann, F; Plössl, L; Gläser-Zikuda, M				Zhang, Chengming; Hofmann, Florian; Ploessl, Lea; Glaeser-Zikuda, Michaela			Classification of reflective writing: A comparative analysis with shallow machine learning and pre-trained language models	EDUCATION AND INFORMATION TECHNOLOGIES			English	Article; Early Access						Reflective writing; Pre-trained language model; Shallow machine learning; AI feedback; Teacher education	EDUCATION; COGNITION	Reflective practice holds critical importance, for example, in higher education and teacher education, yet promoting students' reflective skills has been a persistent challenge. The emergence of revolutionary artificial intelligence technologies, notably in machine learning and large language models, heralds potential breakthroughs in this domain. The current research on analyzing reflective writing hinges on sentence-level classification. Such an approach, however, may fall short of providing a holistic grasp of written reflection. Therefore, this study employs shallow machine learning algorithms and pre-trained language models, namely BERT, RoBERTa, BigBird, and Longformer, with the intention of enhancing the document-level classification accuracy of reflective writings. A dataset of 1,043 reflective writings was collected in a teacher education program at a German university (M = 251.38 words, SD = 143.08 words). Our findings indicated that BigBird and Longformer models significantly outperformed BERT and RoBERTa, achieving classification accuracies of 76.26% and 77.22%, respectively, with less than 60% accuracy observed in shallow machine learning models. The outcomes of this study contribute to refining document-level classification of reflective writings and have implications for augmenting automated feedback mechanisms in teacher education.	[Zhang, Chengming; Hofmann, Florian; Ploessl, Lea; Glaeser-Zikuda, Michaela] Univ Erlangen Nurnberg, Dept Educ, Regensburger St 160, D-90478 Nurnberg, Germany	University of Erlangen Nuremberg	Zhang, CM (corresponding author), Univ Erlangen Nurnberg, Dept Educ, Regensburger St 160, D-90478 Nurnberg, Germany.	chengming.zhang@fau.de; florian.hofmann@fau.de; lea.ploessl@fau.de; michaela.glaeser-zikuda@fau.de			Friedrich-Alexander-Universitt Erlangen-Nrnberg (1041)	Friedrich-Alexander-Universitt Erlangen-Nrnberg (1041)	We wish to express our appreciation to Jessica Schie ss l, and Meltem Doganay for their contribution to the secondary coding of sections of the reflective writing.	Atzeni D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134925; Barthakur A, 2022, IEEE T LEARN TECHNOL, V15, P567, DOI 10.1109/TLT.2022.3162546; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Boud D. R. K., 2013, Reflection: Turning experience into learning; BOYD EM, 1983, J HUMANIST PSYCHOL, V23, P99, DOI 10.1177/0022167883232011; Cai ZH, 2023, EDUC RES REV-NETH, V39, DOI 10.1016/j.edurev.2023.100521; Carpenter D, 2020, LECT NOTES ARTIF INT, V12163, P67, DOI 10.1007/978-3-030-52237-7_6; Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832; Chan BD, 2020, Arxiv, DOI [arXiv:2010.10906, DOI 10.48550/ARXIV.2010.10906]; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Cheng G, 2017, AUSTRALAS J EDUC TEC, V33, P1, DOI 10.14742/ajet.3029; Chong Calvin, 2020, IOP Conference Series: Materials Science and Engineering, V884, DOI 10.1088/1757-899X/884/1/012069; Cui Y, 2019, COMPUT HUM BEHAV, V100, P305, DOI 10.1016/j.chb.2019.02.019; Cutumisu M, 2019, IEEE T EDUC, V62, P325, DOI 10.1109/TE.2019.2925253; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dewey J., 1933, How we think: A restatement of the relation of reflective thinking to the educative process; EBELING W, 1995, PHYSICA A, V215, P233, DOI 10.1016/0378-4371(95)00025-3; Fan XM, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P363, DOI 10.1145/3025171.3025204; FLAVELL JH, 1979, AM PSYCHOL, V34, P906, DOI 10.1037/0003-066X.34.10.906; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Futterer T., 2019, Professional Development Portfolios im Vorbereitungsdienst. Die Wirksamkeit Von Lernumgebungen Auf Die Qualitat Der Portfolioarbeit, DOI [10.1007/978-3-658-24064-6, DOI 10.1007/978-3-658-24064-6]; Gibbs G., 1988, Learning By Doing: A Guide to Teaching and Learning Methods. Further Education Unit; Gibson Andrew., 2016, Journal of Learning Analytics, V3, P22, DOI DOI 10.18608/JLA.2016.32.3; Glaser-Zikuda M., 2015, Encyclopedia of Educational Technology, P275; Glaser-Zikuda M., 2020, Forum: Qualitative Social Research, V21, P1; Gupta N, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P4040, DOI 10.1145/3447548.3470817; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; HATTON N, 1995, TEACH TEACH EDUC, V11, P33, DOI 10.1016/0742-051X(94)00012-U; HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634; Hopcan S, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12086-9; Hu X., 2017, Learning: Research and Practice, V3, P30, DOI [10.1080/23735082.2017.1284253, DOI 10.1080/23735082.2017.1284253]; Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2; Jung YJ, 2022, ADV HEALTH SCI EDUC, V27, P23, DOI 10.1007/s10459-021-10067-6; Jung Y, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P595, DOI 10.1145/3375462.3375528; Kember D., 1999, INT J LIFELONG EDUC, V18, P18, DOI [DOI 10.1080/026013799293928, 10.1080/026013799293928]; Kolb D.A., 2000, EXPERIENTIAL LEARNIN; Körkkö M, 2016, TEACH TEACH EDUC, V55, P198, DOI 10.1016/j.tate.2016.01.014; Korthagen F., 2005, TEACHERS TEACHING TH, V11, P47, DOI [DOI 10.1080/1354060042000337093, 10.1080/135406000420003370093]; Kovanovic V, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P389, DOI 10.1145/3170358.3170374; Kraus M, 2020, EUR J OPER RES, V281, P628, DOI 10.1016/j.ejor.2019.09.018; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li YK, 2022, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocac225; Liu M, 2019, LECT NOTES ARTIF INT, V11625, P220, DOI 10.1007/978-3-030-23204-7_19; Liu QT, 2018, IEEE T LEARN TECHNOL, V11, P243, DOI 10.1109/TLT.2017.2708115; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mezirow Jack., 1991, JOSSEY BASS HIGHER A, V1st; Minixhofer B, 2022, Arxiv, DOI [arXiv:2112.06598, 10.48550/arXiv.2112.06598, DOI 10.48550/ARXIV.2112.06598]; Moon J.A., 2013, Reflection in learning and professional development: Theory and practice; Narciss S., 2006, INFORM TUTORIELLES F; Nehyba J, 2023, EDUC INF TECHNOL, V28, P2961, DOI 10.1007/s10639-022-11254-7; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Poldner E, 2014, EUR J TEACH EDUC, V37, P348, DOI 10.1080/02619768.2014.892479; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rosé C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0; Russell T., 2013, Teachers who teach teachers: Reflections on teacher education; Savicki V, 2015, J COLL STUDENT DEV, V56, P587; Sch??n D. A., 1983, REFLECTIVE PRACTITIO; Schon D. A., 1987, ED REFLECTIVE PRACTI; Solopova V, 2023, LECT NOTES ARTIF INT, V14236, P198, DOI 10.1007/978-3-031-42608-7_16; Springer DG, 2019, J MUSIC TEACH EDUC, V28, P56, DOI 10.1177/1057083718786739; Stede M., 2016, Handbuch Textannotation: Potsdamer Kommentarkorpus 2.0, V8; Tan LJ, 2021, AGRIENGINEERING, V3, P542, DOI 10.3390/agriengineering3030035; Ullmann TD, 2019, INT J ARTIF INTELL E, V29, P217, DOI 10.1007/s40593-019-00174-2; Wulff P, 2023, INT J ARTIF INTELL E, V33, P439, DOI 10.1007/s40593-022-00290-6; Wulff P, 2021, J SCI EDUC TECHNOL, V30, P1, DOI 10.1007/s10956-020-09865-1; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174; Zanette DH, 2017, Arxiv, DOI [arXiv:1412.3336, 10.48550/arXiv.1412.3336, DOI 10.48550/ARXIV.1412.3336]; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhai XS, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8812542; Zhang CM, 2023, EDUC SCI, V13, DOI 10.3390/educsci13121213; Zhang CM, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00420-7; Zimmerman BJ, 2002, THEOR PRACT, V41, P64, DOI 10.1207/s15430421tip4102_2	74	0	0	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1360-2357	1573-7608		EDUC INF TECHNOL	Educ. Inf. Technol.	2024 MAY 2	2024										10.1007/s10639-024-12720-0	http://dx.doi.org/10.1007/s10639-024-12720-0		MAY 2024	27	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	PV9O8		hybrid			2024-07-03	WOS:001216978200001
J	Gorelik, Y; Ghersin, I; Arraf, T; Ben-Ishay, O; Klein, A; Khamaysi, I				Gorelik, Yuri; Ghersin, Itai; Arraf, Tarek; Ben-Ishay, Offir; Klein, Amir; Khamaysi, Iyad			Using a customized GPT to provide guideline-based recommendations for management of pancreatic cystic lesions	ENDOSCOPY INTERNATIONAL OPEN			English	Article						Pancreas; Endoscopic ultrasonography; Fine-needle aspiration/biopsy; Pancreatobiliary (ERCP/PTCD); MRCP topics	DIAGNOSIS	Background and study aims Rising prevalence of pancreatic cysts and inconsistent management guidelines necessitate innovative approaches. New features of large language models (LLMs), namely custom GPT creation, provided by ChatGPT can be utilized to integrate multiple guidelines and settle inconsistencies. Methods A custom GPT was developed to provide guideline-based management advice for pancreatic cysts. Sixty clinical scenarios were evaluated by both the custom GPT and gastroenterology experts. A consensus was reached between experts and review of guidelines and the accuracy of recommendations provided by the custom GPT was evaluated and compared with experts. Results The custom GPT aligned with expert recommendations in 87% of scenarios. Initial expert recommendations were correct in 97% and 87% of cases, respectively. No significant difference was observed between the accuracy of custom GPT and the experts. Agreement analysis using Cohen's and Fleiss' Kappa coefficients indicated consistency among experts and the custom GPT. Conclusions This proof-of-concept study shows the custom GPT's potential to provide accurate, guideline-based recommendations for pancreatic cyst management, comparable to expert opinions. The study highlights the role of advanced features of LLMs in enhancing clinical decision-making in fields with significant practice variability.	[Gorelik, Yuri; Ghersin, Itai; Arraf, Tarek; Klein, Amir] Rambam Hlth Care Campus, Dept Internal Med D, Gastroenterol, IL-31999 Haifa, Israel; [Ben-Ishay, Offir] Rambam Hlth Care Campus, Surg, Haifa, Israel; [Khamaysi, Iyad] Rambam MC, Gastroenterol, Kfar Kana, Israel	Rambam Health Care Campus; Rambam Health Care Campus	Gorelik, Y (corresponding author), Rambam Hlth Care Campus, Dept Internal Med D, Gastroenterol, IL-31999 Haifa, Israel.	yurigorelik@gmail.com						Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Del Chiaro M, 2018, GUT, V67, P789, DOI 10.1136/gutjnl-2018-316027; Elta GH, 2018, AM J GASTROENTEROL, V113, P464, DOI 10.1038/ajg.2018.14; Gorelik Y, 2023, GASTROINTEST ENDOSC, V98, DOI 10.1016/j.gie.2023.06.025; Marchegiani G, 2023, GASTROENTEROLOGY, V165, DOI 10.1053/j.gastro.2023.06.022; Okasha HH, 2021, WORLD J GASTROENTERO, V27, P2664, DOI 10.3748/wjg.v27.i21.2664; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Schenck RJ, 2019, PANCREAS, V48, P883, DOI 10.1097/MPA.0000000000001352; Schweber AB, 2021, PANCREAS, V50, P1287, DOI 10.1097/MPA.0000000000001918; Tanaka M, 2017, PANCREATOLOGY, V17, P738, DOI 10.1016/j.pan.2017.07.007; van Huijgevoort NCM, 2019, NAT REV GASTRO HEPAT, V16, P676, DOI 10.1038/s41575-019-0195-x; Vege SS, 2015, GASTROENTEROLOGY, V148, P819, DOI 10.1053/j.gastro.2015.01.015	13	2	2	0	0	GEORG THIEME VERLAG KG	STUTTGART	RUDIGERSTR 14, D-70469 STUTTGART, GERMANY	2364-3722	2196-9736		ENDOSC INT OPEN	Endosc. Int. Open	APR	2024	12	04					E600	E603		10.1055/a-2289-9334	http://dx.doi.org/10.1055/a-2289-9334			4	Gastroenterology & Hepatology; Surgery	Emerging Sources Citation Index (ESCI)	Gastroenterology & Hepatology; Surgery	OP9B3	38681146				2024-07-03	WOS:001208585800002
J	Yang, ZG; Laki, LJ				Yang, Zijian Gyozo; Laki, Laszlo Janos			Enhancing machine translation with quality estimation and reinforcement learning	ANNALES MATHEMATICAE ET INFORMATICAE			English	Article						machine translation; reinforcement learning; quality estimation; mT5		In recent times, our research has focused on training large language models and exploring their potential. With the emergence of ChatGPT, it has been demonstrated that it is possible to fine-tune language models in a task-agnostic way. The success of ChatGPT is attributed to the reinforcement learning method, which integrates human feedback into the language model fine-tuning process. As a part of our research, we initially adapted the method of reinforcement learning for a specific task, which is machine translation, respectively. In this paper, we propose a novel approach to enhance machine translation with reinforcement learning and quality estimation methods. Our proposed approach uses reinforcement learning to learn to adjust the machine translation output based on quality estimation feedback, with the goal of improving the overall translation quality. We evaluated our approach on the WMT09 dataset for English-Hungarian language pair. We conducted an analysis to show how our approach improves the quality of machine translation output. Our approach offers a promising avenue for enhancing the quality of machine translation and demonstrates the potential of utilizing reinforcement learning to improve other natural language processing tasks.	[Yang, Zijian Gyozo; Laki, Laszlo Janos] Hungarian Res Ctr Linguist, Budapest, Hungary		Yang, ZG (corresponding author), Hungarian Res Ctr Linguist, Budapest, Hungary.	yang.zijian.gyozo@nytud.hu; laki.laszlo@nytud.hu		Yang, Zijian Gyozo/0000-0001-9955-860X				Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Choshen Leshem, 2020, INT C LEARN REPR; Conneau Alexis., 2020, P 58 ANN M ASS COMP, P8440, DOI [DOI 10.18653/V1/2020.ACL-MAIN.747, 10.18653/v1/2020.acl-main.747]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; GENG X., 2022, WMT 2022, P615; Heo Dam, 2021, P 6 C MACHINE TRANSL, P920; Kiegeland S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1673; Laki LJ, 2022, ACTA LINGUIST ACAD, V69, P501, DOI 10.1556/2062.2022.00576; LIM S., 2021, P 6 C MACHINE TRANSL, P935; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Ouyang L., 2022, Advances in Neural Information Processing Systems; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P634; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Tao Shimin, 2022, P 7 C MACHINE TRANSL, P646; Varga D., 2005, Proc. RANLP, V2005, P590; Wang J., 2021, P 6 C MACHINE TRANSL, P948; Wu LJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3612; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; YANG Z. G., 2016, P LREC 2016 WORKSH T; Zerva C., 2021, P 6 C MACHINE TRANSL, P961	22	0	0	16	16	E K F LICEUM KIADO	EGER	ESZTERHAZY TER 1, EGER, 3300, HUNGARY	1787-5021	1787-6117		ANN MATH INFORM	Ann. Math. Inform.		2023	58						182	190		10.33039/ami.2023.08.008	http://dx.doi.org/10.33039/ami.2023.08.008			9	Mathematics	Emerging Sources Citation Index (ESCI)	Mathematics	Y3ES3		gold			2024-07-03	WOS:001104140800003
J	Wang, GJ; Wang, ER; Li, ZF; Zhou, J; Sun, ZM				Wang, Guanjie; Wang, Erpeng; Li, Zefeng; Zhou, Jian; Sun, Zhimei			Exploring the mathematic equations behind the materials science data using interpretable symbolic regression	INTERDISCIPLINARY MATERIALS			English	Review; Early Access						explainable machine learning; material database; materials science; representation learning; symbolic regression	COMBINATORIAL APPROACH; INFRASTRUCTURE; SELECTION; MANAGEMENT; PLATFORM; DESIGN; TRENDS	Symbolic regression (SR), exploring mathematical expressions from a given data set to construct an interpretable model, emerges as a powerful computational technique with the potential to transform the "black box" machining learning methods into physical and chemistry interpretable expressions in material science research. In this review, the current advancements in SR are investigated, focusing on the underlying theories, fundamental flowcharts, various techniques, implemented codes, and application fields. More predominantly, the challenging issues and future opportunities in SR that should be overcome to unlock the full potential of SR in material design and research, including graphics processing unit acceleration and transfer learning algorithms, the trade-off between expression accuracy and complexity, physical or chemistry interpretable SR with generative large language models, and multimodal SR methods, are discussed. Symbolic regression (SR) transforms "black box" machine learning into interpretable models by deriving mathematical expressions from data sets. The theoretical foundations, five categories of models, computational software, and benchmark data sets are reviewed. The paper also provides an overview of SR's applications in materials research, from feature selection to predicting material properties and atomic interactions, and concludes with a critical analysis of its limitations and future research topics. image	[Wang, Guanjie; Wang, Erpeng; Li, Zefeng; Zhou, Jian; Sun, Zhimei] Beihang Univ, Sch Mat Sci & Engn, Beijing 100191, Peoples R China; [Wang, Guanjie] Beihang Univ, Sch Integrated Circuit Sci & Engn, Beijing, Peoples R China	Beihang University; Beihang University	Sun, ZM (corresponding author), Beihang Univ, Sch Mat Sci & Engn, Beijing 100191, Peoples R China.	zmsun@buaa.edu.cn			National Natural Science Foundation of China; National Key Research and Development Program of China [2022YFB3807200]; China Postdoctoral Science Foundation [2022TQ0019];  [52332005]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); 	This work is financially supported by the National Natural Science Foundation of China (Grant No. 52332005), the National Key Research and Development Program of China (Grant No. 2022YFB3807200), and the China Postdoctoral Science Foundation (Grant No. 2022TQ0019).	Abadi M., 2015, arXiv, DOI DOI 10.48550/ARXIV.1603.04467; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Ad-hoc Interagency Group on Advanced Materials, 2011, Materials genome initiative for global competitiveness; Agrawal A, 2016, APL MATER, V4, DOI 10.1063/1.4946894; Anasori B, 2017, NAT REV MATER, V2, DOI 10.1038/natrevmats.2016.98; Angelis D, 2023, ARCH COMPUT METHOD E, V30, P3845, DOI 10.1007/s11831-023-09922-z; Augusto DA, 2000, SIXTH BRAZILIAN SYMPOSIUM ON NEURAL NETWORKS, VOL 1, PROCEEDINGS, P173, DOI 10.1109/SBRN.2000.889734; Austel V, 2017, Arxiv, DOI arXiv:1710.10720; Baldi P., 2012, P ICML WORKSH UNS TR, P37; Baloch Ahmer A. B., 2022, 2022 IEEE 49th Photovoltaics Specialists Conference (PVSC), P0452, DOI 10.1109/PVSC48317.2022.9938842; Baume F, 2024, Arxiv, DOI arXiv:2310.12980; Becker S, 2023, Arxiv, DOI arXiv:2307.12617; Belsky A, 2002, ACTA CRYSTALLOGR B, V58, P364, DOI 10.1107/S0108768102006948; Bendinelli T, 2023, Arxiv, DOI arXiv:2304.10336; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Biggio L., 2021, arXiv; Birky D, 2023, MODEL SIMUL MATER SC, V31, DOI 10.1088/1361-651X/acfe28; Blaiszik B, 2016, JOM-US, V68, P2045, DOI 10.1007/s11837-016-2001-3; Brence J, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107077; Burlacu Bogdan, 2020, GECCO'20. Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion, P1562, DOI 10.1145/3377929.3398099; Burlacu B., 2023, Genetic Programming Theory and Practice XIX, P1; Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077; Chen M, 2020, PR MACH LEARN RES, V119; Chen Q, 2022, IEEE T CYBERNETICS, V52, P25, DOI 10.1109/TCYB.2020.2969689; Chu XT, 2023, Arxiv, DOI arXiv:2306.04718; Cohen AJ, 2012, CHEM REV, V112, P289, DOI 10.1021/cr200107z; Cranmer M, 2020, Arxiv, DOI arXiv:2006.11287; Cranmer M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2026053118; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Curtarolo S, 2013, NAT MATER, V12, P191, DOI [10.1038/NMAT3568, 10.1038/nmat3568]; Curtarolo S, 2012, COMP MATER SCI, V58, P218, DOI 10.1016/j.commatsci.2012.02.005; Curtarolo S, 2012, COMP MATER SCI, V58, P227, DOI 10.1016/j.commatsci.2012.02.002; d'Ascoli S, 2022, Arxiv, DOI arXiv:2201.04600; de Franca FO, 2021, EVOL COMPUT, V29, P367, DOI 10.1162/evco_a_00285; de França FO, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P920, DOI 10.1145/3512290.3528695; de França FO, 2018, INFORM SCIENCES, V442, P18, DOI 10.1016/j.ins.2018.02.040; Doersch C, 2021, Arxiv, DOI arXiv:1606.05908; Draxl C, 2019, J PHYS-MATER, V2, DOI 10.1088/2515-7639/ab13bb; Dubcáková R, 2011, GENET PROGRAM EVOL M, V12, P173, DOI 10.1007/s10710-010-9124-z; Dugan O, 2023, Arxiv, DOI arXiv:2007.10784; Engle MR, 2022, AICHE J, V68, DOI 10.1002/aic.17457; Flores E, 2022, DIGIT DISCOV, V1, P440, DOI 10.1039/d2dd00027j; Foppa L, 2022, PHYS REV LETT, V129, DOI 10.1103/PhysRevLett.129.055301; FORREST S, 1993, SCIENCE, V261, P872, DOI 10.1126/science.8346439; Gandomi AH, 2016, AUTOMAT CONSTR, V70, P89, DOI 10.1016/j.autcon.2016.06.010; Gilpin W, 2023, Arxiv, DOI [arXiv:2110.05266, DOI 10.48550/ARXIV.2110.05266]; Glick J., 2013, Informatics for Materials Science and Engineering, P147; Gong C., 2022, SN ComputSci, V3, P209; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gossett E, 2018, COMP MATER SCI, V152, P134, DOI 10.1016/j.commatsci.2018.03.075; Granlund G. H., 2013, Signal Processing for Computer Vision; Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116; Guo Z, 2022, J CHEM THEORY COMPUT, V18, P4945, DOI 10.1021/acs.jctc.2c00281; Halder C, 2015, MATER MANUF PROCESS, V30, P552, DOI 10.1080/10426914.2014.994765; Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285; Haslam E, 2016, IEEE C EVOL COMPUTAT, P3598, DOI 10.1109/CEC.2016.7744245; He BH, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P946, DOI 10.1145/3512290.3528757; Hernandez A, 2023, PHYS REV MATER, V7, DOI 10.1103/PhysRevMaterials.7.053804; Hernandez A, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0249-1; Hicks D, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-020-00483-4; Himanen L, 2019, ADV SCI, V6, DOI 10.1002/advs.201900808; Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e; Holt S., 2023, INT C LEARN REPR; Hu WG, 2023, J MOL GRAPH MODEL, V124, DOI 10.1016/j.jmgm.2023.108530; Huxtable S, 2004, NAT MATER, V3, P298, DOI 10.1038/nmat1114; Icke I, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1763; Igarashi Y, 2018, J PHYS SOC JPN, V87, DOI 10.7566/JPSJ.87.044802; Jain A, 2016, APL MATER, V4, DOI 10.1063/1.4944683; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Jin PW, 2023, Arxiv, DOI arXiv:2302.10539; Jin Y, 2020, Arxiv, DOI arXiv:1910.08892; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Kabliman E, 2021, APPL ENG SCI, V6, DOI 10.1016/j.apples.2021.100052; Kabliman E, 2019, AIP CONF PROC, V2113, DOI 10.1063/1.5112747; Kalinin SV, 2015, NAT MATER, V14, P973, DOI [10.1038/NMAT4395, 10.1038/nmat4395]; Kamienny PA, 2023, Arxiv, DOI arXiv:2302.11223; Kamienny Pierre-Alexandre, 2022, arXiv; Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kartelj A, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00743-2; Kenoufi A., 2015, Biol Chem Res, V2, P1; Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213; Kim S, 2021, IEEE T NEUR NET LEAR, V32, P4166, DOI 10.1109/TNNLS.2020.3017010; Kingma D. P., 2014, ICLR; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Kommenda M, 2020, GENET PROGRAM EVOL M, V21, P471, DOI 10.1007/s10710-019-09371-3; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; Kronberger G, 2022, EVOL COMPUT, V30, P75, DOI 10.1162/evco_a_00294; Kubalík J, 2023, IEEE ACCESS, V11, P61481, DOI 10.1109/ACCESS.2023.3287397; Kubalík J, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115210; Kusne AG, 2014, SCI REP-UK, V4, DOI 10.1038/srep06367; Kusner MJ, 2017, PR MACH LEARN RES, V70; Hamilton WL, 2018, Arxiv, DOI [arXiv:1709.05584, 10.48550/arXiv.1709.05584]; La Cava W, 2019, Arxiv, DOI arXiv:1807.00981; La Cava W, 2021, Arxiv, DOI arXiv:2107.14351; Lencer D, 2008, NAT MATER, V7, P972, DOI 10.1038/nmat2330; Li JC, 2022, Arxiv, DOI arXiv:2205.11798; Li W., 2023, 11 INT C LEARN REPR; Li Z, 2023, J NON-CRYST SOLIDS, V614, DOI 10.1016/j.jnoncrysol.2023.122409; Liu XY, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00758-y; Liu ZK, 2018, J PHASE EQUILIB DIFF, V39, P635, DOI 10.1007/s11669-018-0654-z; Loftis C, 2021, J PHYS CHEM A, V125, P435, DOI 10.1021/acs.jpca.0c08103; Louie SG, 2021, NAT MATER, V20, P728, DOI 10.1038/s41563-021-01015-1; Lucena-Sánchez E, 2021, ALGORITHMS, V14, DOI 10.3390/a14030076; Maier WF, 2007, ANGEW CHEM INT EDIT, V46, P6016, DOI 10.1002/anie.200603675; Makhzani A, 2016, Arxiv, DOI arXiv:1511.05644; Makke N, 2023, Arxiv, DOI arXiv:2211.10873; Manzeli S, 2017, NAT REV MATER, V2, DOI 10.1038/natrevmats.2017.33; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mao YQ, 2021, ACS OMEGA, V6, P14533, DOI 10.1021/acsomega.1c01517; Marzari N, 2021, NAT MATER, V20, P736, DOI 10.1038/s41563-021-01013-3; Mathew K, 2017, COMP MATER SCI, V139, P140, DOI 10.1016/j.commatsci.2017.07.030; Matsubara Y, 2024, Arxiv, DOI arXiv:2206.10540; Mayer-Schnberger V., 2013, BIG DATA REVOLUTION; Mcree R, 2010, GECCO-2010 COMPANION PUBLICATION: PROCEEDINGS OF THE 12TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1983; Moraglio Alberto, 2012, Parallel Problem Solving from Nature - PPSN XII. Proceedings of the 12th International Conference, P21, DOI 10.1007/978-3-642-32937-1_3; Moscato P, 2023, PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, GECCO 2023, P520, DOI 10.1145/3583131.3590461; Muller B, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCCO'19 COMPANION), P350, DOI 10.1145/3319619.3322072; Mundhenk TN, 2021, Arxiv, DOI [arXiv:2111.00053, 10.48550/ARXIV.2111.00053, DOI 10.48550/ARXIV.2111.00053]; Narayanan H, 2022, CHEM ENG J, V430, DOI 10.1016/j.cej.2021.133032; O'Connor NJ, 2018, NAT CATAL, V1, P531, DOI 10.1038/s41929-018-0094-5; O'Mara J, 2016, JOM-US, V68, P2031, DOI 10.1007/s11837-016-1984-0; Olson GB, 1997, SCIENCE, V277, P1237, DOI 10.1126/science.277.5330.1237; Ong SP, 2013, COMP MATER SCI, V68, P314, DOI 10.1016/j.commatsci.2012.10.028; Orzechowski P, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1183, DOI 10.1145/3205455.3205539; Otte Clemens, 2013, Computational Intelligence in Intelligent Data Analysis, P111, DOI [DOI 10.1007/978-3-642-32378-2_8, 10.1007/978-3-642-32378-2_8]; Ouyang RH, 2019, J PHYS-MATER, V2, DOI 10.1088/2515-7639/ab077b; Ouyang RH, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.083802; Paszke A, 2019, ADV NEUR IN, V32; Pederson R, 2022, NAT REV PHYS, V4, P357, DOI 10.1038/s42254-022-00470-2; Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003; Petersen BK, 2021, Arxiv, DOI arXiv:1912.04871; Pitzer E, 2015, LECT NOTES COMPUT SC, V9520, P375, DOI 10.1007/978-3-319-27340-2_47; Pizzi G, 2016, COMP MATER SCI, V111, P218, DOI 10.1016/j.commatsci.2015.09.013; Popov S, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1241; Pospichal P., 2011, P 13 ANN C COMP GEN, P431; Purcell TAR, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01063-y; Pyhne HO., 1996, Report No. 96/04), P72; Quirós M, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0279-6; Ram S, 2023, ACS APPL MATER INTER, V15, P43702, DOI 10.1021/acsami.3c08020; Rivero D, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116712; Rodrigues Jose F Jr, 2021, Discov Mater, V1, P12, DOI 10.1007/s43939-021-00012-0; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE; Salakhutdinov R, 2015, ANNU REV STAT APPL, V2, P361, DOI 10.1146/annurev-statistics-010814-020120; Sastry K, 2004, INT J MULTISCALE COM, V2, P239, DOI 10.1615/IntJMultCompEng.v2.i2.50; Savic DA, 1999, WATER RESOUR MANAG, V13, P219, DOI 10.1023/A:1008132509589; Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893; Shojaee P, 2023, Arxiv, DOI arXiv:2303.06833; Smits GF, 2005, GENET PROGR SER, V8, P283, DOI 10.1007/0-387-23254-0_17; Snyder JC, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.253002; Sun FZ, 2023, Arxiv, DOI arXiv:2205.13134; Szymanski NJ, 2023, NATURE, V624, P86, DOI 10.1038/s41586-023-06734-w; Tan BF, 2022, J APPL PHYS, V132, DOI 10.1063/5.0105445; Tantardini C, 2024, Arxiv, DOI arXiv:2304.12880; Theis L, 2016, Arxiv, DOI arXiv:1511.01844; Tohme T, 2023, Arxiv, DOI arXiv:2205.15569; Udrescu SM, 2020, Arxiv, DOI arXiv:2006.10782; Udrescu SM, 2021, PHYS REV E, V103, DOI 10.1103/PhysRevE.103.043307; Udrescu SM, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2631; Valipour M, 2021, Arxiv, DOI arXiv:2106.14131; van Heeswijk M, 2011, NEUROCOMPUTING, V74, P2430, DOI 10.1016/j.neucom.2010.11.034; Vastl M, 2022, Arxiv, DOI arXiv:2205.15764; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vázquez D, 2022, SUSTAIN PROD CONSUMP, V30, P596, DOI 10.1016/j.spc.2021.12.025; Vergniory MG, 2022, SCIENCE, V376, P816, DOI 10.1126/science.abg9094; Versino D, 2017, COMPUT METHOD APPL M, V318, P981, DOI 10.1016/j.cma.2017.02.016; Virgolin M, 2021, EVOL COMPUT, V29, P211, DOI 10.1162/evco_a_00278; Virgolin M, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION, GECCO 2022, P2289, DOI 10.1145/3520304.3534036; Virgolin M, 2022, Arxiv, DOI arXiv:2207.01018; Virgolin M, 2021, Arxiv, DOI arXiv:1904.02050; Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349; Wagner S, 2014, T INTEL ENG INFORMAT, V6, P197, DOI 10.1007/978-3-319-01436-4_10; Wang CX, 2022, J MATER SCI TECHNOL, V122, P77, DOI 10.1016/j.jmst.2021.12.052; Wang E., 2024, Natl Sci Open, V3; Wang GJ, 2023, J PHYS CHEM C, V127, P24724, DOI 10.1021/acs.jpcc.3c07110; Wang GJ, 2023, SCI BULL, V68, P3105, DOI 10.1016/j.scib.2023.11.038; Wang GJ, 2022, ACTA METALL SIN, V58, P75, DOI 10.11900/0412.1961.2021.00041; Wang GJ, 2021, COMP MATER SCI, V186, DOI 10.1016/j.commatsci.2020.110064; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Ward L, 2018, COMP MATER SCI, V152, P60, DOI 10.1016/j.commatsci.2018.05.018; Weber G, 2020, JOM-US, V72, P4404, DOI 10.1007/s11837-020-04344-9; Werner Matthias, 2021, arXiv; White A, 2012, MRS BULL, V37, P715, DOI 10.1557/mrs.2012.194; Wilson DG, 2018, Arxiv, DOI arXiv:1810.04119; XIANG XD, 1995, SCIENCE, V268, P1738, DOI 10.1126/science.268.5218.1738; Xiong J, 2020, SCI CHINA TECHNOL SC, V63, P1247, DOI 10.1007/s11431-020-1599-5; Xu D., 2023, MaterGenome EngAdv, V1; Xu D., 2021, arXiv; Yang C, 2023, ACS APPL MATER INTER, DOI 10.1021/acsami.3c06392; Yang XY, 2018, COMP MATER SCI, V146, P319, DOI 10.1016/j.commatsci.2018.01.039; Zapiain DMD, 2023, COMP MATER SCI, V218, DOI 10.1016/j.commatsci.2022.111967; Zegklitz J, 2021, GENET PROGRAM EVOL M, V22, P5, DOI 10.1007/s10710-020-09387-0; Zhang Haoyu, 2021, PROC IEEE INT C COMM, P1, DOI DOI 10.1109/IJCNN52387.2021.9533808; Zhang HZ, 2022, SWARM EVOL COMPUT, V71, DOI 10.1016/j.swevo.2022.101061; Zhang L, 2023, ACS APPL ENERG MATER, V6, P5177, DOI 10.1021/acsaem.2c04066; Zhang LY, 2022, MATER TODAY COMMUN, V33, DOI 10.1016/j.mtcomm.2022.104630; Zhao JC, 2001, ADV ENG MATER, V3, P143, DOI 10.1002/1527-2648(200103)3:3<143::AID-ADEM143>3.3.CO;2-6; Zhao JC, 2014, CHINESE SCI BULL, V59, P1652, DOI 10.1007/s11434-014-0120-1; Zhao JC, 2011, JOM-US, V63, P40, DOI 10.1007/s11837-011-0044-z; Zhong YQ, 2023, J MATER CHEM A, V11, P18651, DOI 10.1039/d3ta03990k; Zhou T, 2019, ENGINEERING-PRC, V5, P1017, DOI 10.1016/j.eng.2019.02.011; Zhu LG, 2022, J PHYS CHEM LETT, V13, P3965, DOI 10.1021/acs.jpclett.2c00576; Zhu ZJ, 2021, NAT REV MATER, V6, P27, DOI 10.1038/s41578-020-00235-2	204	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2767-4401	2767-441X		INTERD MATER	Interdiscip. Mater.	2024 MAY 29	2024										10.1002/idm2.12180	http://dx.doi.org/10.1002/idm2.12180		MAY 2024	21	Chemistry, Physical; Materials Science, Multidisciplinary; Physics, Applied	Emerging Sources Citation Index (ESCI)	Chemistry; Materials Science; Physics	SK1Z0		gold			2024-07-03	WOS:001234268300001
J	Feng, XR; Xu, S; Li, YN; Liu, J				Feng, Xinran; Xu, Shan; Li, Yuannan; Liu, Jia			Body size as a metric for the affordable world	ELIFE			English	Article						embodied cognition; affordance boundary; foundation agents; Human	CATEGORICAL PERCEPTION; SCALED INFORMATION; VISUAL GUIDANCE; OBJECT; ORGANIZATION; REPRESENTATIONS; DISCRIMINATION; COGNITION; LANGUAGE; STREAM	The physical body of an organism serves as a vital interface for interactions with its environment. Here, we investigated the impact of human body size on the perception of action possibilities (affordances) offered by the environment. We found that the body size delineated a distinct boundary on affordances, dividing objects of continuous real-world sizes into two discrete categories with each affording distinct action sets. Additionally, the boundary shifted with imagined body sizes, suggesting a causal link between body size and affordance perception. Intriguingly, ChatGPT, a large language model lacking physical embodiment, exhibited a modest yet comparable affordance boundary at the scale of human body size, suggesting the boundary is not exclusively derived from organism-environment interactions. A subsequent fMRI experiment offered preliminary evidence of affordance processing exclusively for objects within the body size range, but not for those beyond. This suggests that only objects capable of being manipulated are the objects capable of offering affordance in the eyes of an organism. In summary, our study suggests a novel definition of object-ness in an affordance-based context, advocating the concept of embodied cognition in understanding the emergence of intelligence constrained by an organism's physical attributes.	[Feng, Xinran; Li, Yuannan; Liu, Jia] Tsinghua Univ, Dept Psychol, Beijing, Peoples R China; [Feng, Xinran; Li, Yuannan; Liu, Jia] Tsinghua Univ, Tsinghua Lab Brain & Intelligence, Beijing, Peoples R China; [Xu, Shan] Beijing Normal Univ, Fac Psychol, Beijing, Peoples R China	Tsinghua University; Tsinghua University; Beijing Normal University	Liu, J (corresponding author), Tsinghua Univ, Dept Psychol, Beijing, Peoples R China.; Liu, J (corresponding author), Tsinghua Univ, Tsinghua Lab Brain & Intelligence, Beijing, Peoples R China.	liujiathu@tsinghua.edu.cn		Xu, Shan/0000-0002-6535-3283; Feng, Xinran/0000-0002-4298-1666	National Natural Science Foundation of China [31600925, 32371099, 31861143039]; Natural Science Foundation of China [YJ20220273]; Shuimu Scholar Program of Tsinghua University, China Postdoctoral International Exchange Program [Z221100002722012, 2020GQG1016]; Beijing Municipal Science & Technology Commission, Administrative Commission of Zhongguancun Science Park; Double First-Class Initiative Funds for Discipline Construction	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shuimu Scholar Program of Tsinghua University, China Postdoctoral International Exchange Program; Beijing Municipal Science & Technology Commission, Administrative Commission of Zhongguancun Science Park; Double First-Class Initiative Funds for Discipline Construction	We thank our reviewers for thoughtful feedback. This study was funded by Natural Science Foundation of China (31600925, 32371099, 31861143039), Shuimu Scholar Program of Tsinghua University, China Postdoctoral International Exchange Program (YJ20220273), Beijing Municipal Science & Technology Commission, Administrative Commission of Zhongguancun Science Park (Z221100002722012), Tsinghua University Guoqiang Institute (2020GQG1016), Beijing Academy of Artificial Intelligence (BAAI), and Double First-Class Initiative Funds for Discipline Construction.	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639; Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147; Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X; Binkofski F, 2002, J NEUROPHYSIOL, V88, P514, DOI 10.1152/jn.2002.88.1.514; Borghi A.M., 2005, Grounding cognition: the role of perception and action in memory, DOI DOI 10.1017/CBO9780511499968.002; BORNSTEIN MH, 1984, PSYCHOL RES-PSYCH FO, V46, P207, DOI 10.1007/BF00308884; Campanella S, 2001, VIS COGN, V8, P237, DOI 10.1080/13506280042000072; Casasanto D, 2011, CURR DIR PSYCHOL SCI, V20, P378, DOI 10.1177/0963721411422058; CASTIELLO U, 1993, EXP BRAIN RES, V94, P163; Cesari P, 2000, J EXP PSYCHOL HUMAN, V26, P1657, DOI 10.1037//0096-1523.26.5.1657; Chemero A, 2013, REV GEN PSYCHOL, V17, P145, DOI 10.1037/a0032923; Colling Lincoln, 2021, Zenodo, DOI 10.5281/ZENODO.4642331; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diedenhofen B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121945; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Fan LZ, 2016, CEREB CORTEX, V26, P3508, DOI 10.1093/cercor/bhw157; Filimon F, 2007, NEUROIMAGE, V37, P1315, DOI 10.1016/j.neuroimage.2007.06.008; Fodor J. A., 1975, LANGUAGE THOUGHT, V5; Gallagher S., 2017, Enactivist interventions: Rethinking the mind; GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154; Glenberg AM, 2013, PERSPECT PSYCHOL SCI, V8, P573, DOI 10.1177/1745691613498098; Glenberg AM, 2012, CORTEX, V48, P905, DOI 10.1016/j.cortex.2011.04.010; Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26; GREENO JG, 1994, PSYCHOL REV, V101, P336, DOI 10.1037/0033-295X.101.2.336; Grill-Spector K, 2000, NAT NEUROSCI, V3, P837, DOI 10.1038/77754; Gupta A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25874-z; Harnad S, 1987, Psychophysical and Cognitive Aspects of Categorical Perception: A Critical Overview; Hebart MN, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223792; Hebart MN, 2018, ELIFE, V7, DOI 10.7554/eLife.32816; Hestness J, 2017, Arxiv, DOI [arXiv:1712.00409, DOI 10.48550/ARXIV.1712.00409]; Huang TC, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03711-3; Hutto DD, 2013, RADICALIZING ENACTIVISM: BASIC MINDS WITHOUT CONTENT, P1; Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132; Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015; Kay W, 2017, Arxiv, DOI [arXiv:1705.06950, DOI 10.48550/ARXIV.1705.06950]; Konkle T, 2013, J NEUROSCI, V33, P10235, DOI 10.1523/JNEUROSCI.0983-13.2013; Konkle T, 2012, NEURON, V74, P1114, DOI 10.1016/j.neuron.2012.04.036; Konkle T, 2011, J EXP PSYCHOL HUMAN, V37, P23, DOI 10.1037/a0020413; Kourtis D, 2018, COGN AFFECT BEHAV NE, V18, P1221, DOI 10.3758/s13415-018-0633-1; LAKOFF G, 1980, COGNITIVE SCI, V4, P195, DOI 10.1016/S0364-0213(80)80017-6; LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417; Magri C, 2021, NEUROIMAGE, V237, DOI 10.1016/j.neuroimage.2021.118098; MALACH R, 1995, P NATL ACAD SCI USA, V92, P8135, DOI 10.1073/pnas.92.18.8135; MARK LS, 1987, J EXP PSYCHOL HUMAN, V13, P361, DOI 10.1037/0096-1523.13.3.361; Matic K, 2020, CORTEX, V133, P358, DOI 10.1016/j.cortex.2020.09.016; McDannald DW, 2018, NEUROSCI LETT, V683, P131, DOI 10.1016/j.neulet.2018.05.040; Merleau-Ponty M., 2012, PHENOMENOLOGY PERCEP, DOI DOI 10.4324/9780203720714; NCD Risk Factor Collaboration (NCD-RisC), 2016, Elife, V5, DOI 10.7554/eLife.13410; NEWELL KM, 1989, DEV PSYCHOBIOL, V22, P817, DOI 10.1002/dev.420220806; Op de Beeck HP, 2008, J NEUROSCI, V28, P10111, DOI 10.1523/JNEUROSCI.2511-08.2008; OpenAI, 2023, Introducing chatgpt; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Park S, 2011, J NEUROSCI, V31, P1333, DOI 10.1523/JNEUROSCI.3885-10.2011; Pearson K., 1898, PHILOS T R SOC A, P229, DOI DOI 10.1098/RSTA.1898.0007; PRINDLE SS, 1980, BEHAV BRAIN SCI, V3, P395, DOI 10.1017/S0140525X0000563X; Pylyshyn Z, 1999, BEHAV BRAIN SCI, V22, P341, DOI 10.1017/S0140525X99002022; Radford A., 2018, IMPROVING LANGUAGE U; Sakreida K, 2016, NEUROSCI BIOBEHAV R, V69, P89, DOI 10.1016/j.neubiorev.2016.07.032; Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973; Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062; Snow JC, 2011, SCI REP-UK, V1, DOI 10.1038/srep00130; Stanfield RA, 2001, PSYCHOL SCI, V12, P153, DOI 10.1111/1467-9280.00326; THOMPSON E., 2007, Mind in Life: Biology, Phenomenology, and the Sciences of Mind; Troiani V, 2014, CEREB CORTEX, V24, P883, DOI 10.1093/cercor/bhs364; Tucker M, 2004, ACTA PSYCHOL, V116, P185, DOI 10.1016/j.actpsy.2004.01.004; Unpingco J., 2016, Python for Probability, Statistics, and Machine Learning, DOI DOI 10.1007/978-3-319-30717-6; Vainio L, 2020, NEUROSCI BIOBEHAV R, V112, P487, DOI 10.1016/j.neubiorev.2020.02.029; van Gelder T, 1998, BEHAV BRAIN SCI, V21, P615, DOI 10.1017/S0140525X98001733; Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1; Wagenmakers EJ, 2011, J PERS SOC PSYCHOL, V100, P426, DOI 10.1037/a0022790; WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683; WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371; Waskom M., 2021, J OPEN SOURCE SOFTW, V6, P3021, DOI [10.21105/JOSS.03021, DOI 10.21105/JOSS.03021, 10.21105/joss.03021]; Wilson AD, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00058; Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322; Worsley KJ., 2001, Functional MRI: An Introduction to Methods, V14, P251; Young AW, 1997, COGNITION, V63, P271, DOI 10.1016/S0010-0277(97)00003-6; Yu C, 2005, COGNITIVE SCI, V29, P961, DOI 10.1207/s15516709cog0000_40; Zhen ZL, 2015, NEUROIMAGE, V113, P13, DOI 10.1016/j.neuroimage.2015.03.010	80	0	0	3	3	eLIFE SCIENCES PUBL LTD	CAMBRIDGE	SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND	2050-084X			ELIFE	eLife	MAR 28	2024	12								RP90583	10.7554/eLife.90583	http://dx.doi.org/10.7554/eLife.90583			20	Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics	NE7V3	38547366	Green Accepted, gold			2024-07-03	WOS:001198851400001
J	Lai, XJ; Lin, SH; Zou, JK; Li, M; Huang, JQ; Liu, ZR; Li, DW; Fu, H				Lai, Xinjun; Lin, Shenhe; Zou, Jingkai; Li, Min; Huang, Jiaqi; Liu, Zhirui; Li, Dawei; Fu, Hui			Kansei engineering for the intelligent connected vehicle functions: An online and offline data mining approach	ADVANCED ENGINEERING INFORMATICS			English	Article						Design requirement; BERT model; Smart cockpit; Choice modelling; New energy vehicle	ANALYTICS	The big data era enables automakers to mine users' affective (Kansei) requirements for the car design. However, existing literature mostly applies text mining with users' online comments, possibly leading to biased results since users without online comments were not considered. To fill in this gap, this paper proposes to jointly analyse users' online commenting and offline usage big data, and develops a novel framework to efficiently fuse these two datasets for the Kansei engineering of the intelligent connected vehicle (ICV) functions. A behaviour -enhanced large language model is proposed to process users' online comments; then, users' Kansei requirements are further jointly analysed with their offline in -cabin behaviour data, by the proposed NLPMDCEV (natural language process - multiple discrete -continuous extreme value) model, to understand user's complex discrete and continuous choice decisions in the smart cockpit. In addition, the proposed framework aims to solve the problem of design tasks prioritization, where not all the Kansei requirements can be met if design resources are limited. The proposed framework is applied in the studied new energy vehicle company, with more than nine -months' online comments and six -months' offline usage data, where results suggest its merits of economic, efficient, and effective.	[Lai, Xinjun; Lin, Shenhe; Zou, Jingkai; Fu, Hui] Guangdong Univ Technol, Sch Electromech Engn, Guangzhou, Guangdong, Peoples R China; [Lin, Shenhe] Beijing Qingneng Internet Technol Co Ltd, Guangzhou 510630, Guangdong, Peoples R China; [Li, Min; Huang, Jiaqi; Liu, Zhirui] GAC AION New Energy Automobile Co Ltd, Guangzhou 511434, Peoples R China; [Li, Dawei] Southeast Univ, Sch Transportat, 2 Dongnandaxue Rd, Nanjing 211189, Jiangsu, Peoples R China	Guangdong University of Technology; Southeast University - China	Li, M (corresponding author), GAC AION New Energy Automobile Co Ltd, Guangzhou 511434, Peoples R China.	xinjun.lai@gdut.edu.cn; lim@gacne.com.cn; hui.fu@gdut.edu.cn			Guangdong Basic and Applied Basic Research Foundation [2021A1515012015]; Guangzhou Municipal Science and Technology Project, China [2024B03J1293]; National Natural Science Foun-dation of China [71971056]	Guangdong Basic and Applied Basic Research Foundation; Guangzhou Municipal Science and Technology Project, China; National Natural Science Foun-dation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgements</B> The work described in this paper was jointly supported by the Guangdong Basic and Applied Basic Research Foundation (No. 2021A1515012015) , Guangzhou Municipal Science and Technology Project, China (2024B03J1293) , and National Natural Science Foun-dation of China (No. 71971056) .	Anam Asm Iftekhar, 2013, P 15 INT ACM SIGACCE; Bahrini Aram, 2023, Chatgpt: Applications, opportunities, and threats; Bhat CR, 2008, TRANSPORT RES B-METH, V42, P274, DOI 10.1016/j.trb.2007.06.002; Bhat CR, 2022, TRANSPORT RES B-METH, V156, P28, DOI 10.1016/j.trb.2021.12.013; Cao H, 2017, PERVASIVE MOB COMPUT, V37, P1, DOI 10.1016/j.pmcj.2017.01.007; Cheng ZW, 2022, J PHYS-CONDENS MAT, V34, DOI 10.1088/1361-648X/ac6558; Cong YF, 2023, ADV ENG INFORM, V56, DOI 10.1016/j.aei.2023.101953; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fu Hui, 2016, Industrial Engineering Journal, V19, P10, DOI 10.3969/j.issn.1007-7375.2016.01.002; Gao CY, 2015, 9TH IEEE INTERNATIONAL SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE 2015), P284, DOI 10.1109/SOSE.2015.13; Giner-Miguelez J, 2023, J COMPUT LANG, V76, DOI 10.1016/j.cola.2023.101209; Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257; Han SP, 2016, MIS QUART, V40, P983, DOI 10.25300/MISQ/2016/40.4.09; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041538; Jiao YR, 2019, COMPUT IND, V108, P1, DOI 10.1016/j.compind.2019.02.011; Kar AK, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102205; Khan W., 2023, Natural Lang. Process. J., V4, DOI DOI 10.1016/J.NLP.2023.100026; Kiukkonen N., 2010, PROC ACM INT C PERVA; Kumari M, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010091; Lai XJ, 2023, BIG DATA-US, DOI 10.1089/big.2022.0021; Lai XJ, 2022, COMPUT IND ENG, V165, DOI 10.1016/j.cie.2021.107913; Lai XJ, 2019, INT J PROD RES, V57, P5660, DOI 10.1080/00207543.2018.1541200; Li T, 2022, IEEE COMMUN SURV TUT, V24, P937, DOI 10.1109/COMST.2022.3163176; Liang Q, 2019, QUAL RELIAB ENG INT, V35, P1180, DOI 10.1002/qre.2452; Lin KY, 2018, INT J IND ENG-THEORY, V25, P108; Marzi G, 2021, IEEE T ENG MANAGE, V68, P330, DOI 10.1109/TEM.2020.2997386; OpenAI, 2023, Gpt-4 Technical Report; Park J, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120767; Pei HN, 2022, ADV ENG INFORM, V54, DOI 10.1016/j.aei.2022.101763; Roffarello AM, 2022, INT J HUM-COMPUT ST, V158, DOI 10.1016/j.ijhcs.2021.102735; Rong X, 2016, Arxiv, DOI arXiv:1411.2738; Sun Fei, 2022, Ind. Eng. J., V25, P120; Sun Y., 2019, Enhanced Representation through Knowledge Integration, P8968; Szegedy C, 2015, 3 INT C LEARN REPR I; Tan ZY, 2022, IEEE T INTELL TRANSP, V23, P13954, DOI 10.1109/TITS.2021.3127217; Vlah D, 2022, ADV ENG INFORM, V54, DOI 10.1016/j.aei.2022.101774; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Wang ST, 2023, ELECTRON COMMER R A, V57, DOI 10.1016/j.elerap.2022.101231; Wang Yue, 2021, R-drop: Regularized dropout for neural networks; Wang ZX, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101394; Wu XY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14396-3; Yang ZL, 2019, ADV NEUR IN, V32; Zhang K, 2023, ADV ENG INFORM, V57, DOI 10.1016/j.aei.2023.101996; Zheng P, 2019, IEEE ACCESS, V7, P128463, DOI 10.1109/ACCESS.2019.2939828; Zhu HY, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119369	46	0	0	20	20	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1474-0346	1873-5320		ADV ENG INFORM	Adv. Eng. Inform.	AUG	2024	61								102467	10.1016/j.aei.2024.102467	http://dx.doi.org/10.1016/j.aei.2024.102467		MAR 2024	20	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OH1Q7					2024-07-03	WOS:001206293500001
J	Huh, T; Ko, Y				Huh, Taehun; Ko, Youngjoong			Efficient framework for low-resource abstractive summarization by meta-transfer learning and pointer-generator networks	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Low-resource abstractive summarization; Meta-transfer learning; Pointer-generator network; Copy mechanism; Prompt-tuning		Recently, large language models have shown great success on various abstractive summarization datasets. These datasets consist of numerous data that are enough to train a large number of parameters. However, for a new domain, there is a lack of labeled data to train those parameters and the model is easily overfitted to a small amount of data. In addition, because annotating document-summary pairs is too expensive and transfer learning using high-resource datasets causes a domain shifting problem, a low-resource abstractive summarization task is becoming necessary. Herein, we propose an efficient framework for low-resource abstractive summarization using a pointer-generator network and a meta-learning technique to address the above problems. Meta-learning using existing high-resource datasets enables our model to rapidly adapt to a new domain using limited data to solve the domain shifting problem. In addition, we explore the copy mechanism using a pointer-generator network that can copy words from a source document when generating a summary. The experimental results on 11 different datasets show that the proposed model outperforms the previous state-of-the-art models in low-resource abstractive summarization on most of the datasets.	[Huh, Taehun] Sungkyunkwan Univ, Dept Artificial Intelligence, Suwon, Gyeonggi Do, South Korea; [Ko, Youngjoong] Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, Gyeonggi Do, South Korea	Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU)	Ko, Y (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, Gyeonggi Do, South Korea.	yjko@skku.edu			National Research Foundation of Korea (NRF) - Korea government (MSIT) [2022-0-00369]; Institute for Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT); Development of AI Technology; Institute of Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT); AI Graduate School Support Program (Sungkyunkwan University);  [NRF-2020R1A2C2100362]	National Research Foundation of Korea (NRF) - Korea government (MSIT)(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Institute for Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Development of AI Technology; Institute of Information amp; communications Technology Planning amp; Evaluation (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); AI Graduate School Support Program (Sungkyunkwan University); 	This work was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. NRF-2020R1A2C2100362) , in part by Institute for Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00369, (Part 4) Development of AI Technology to support Expert Decision-making that can Explain the Reasons/Grounds for Judgment Results based on Expert Knowledge) , and in part by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2019-0-00421, AI Graduate School Support Program (Sungkyunkwan University) ) .	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen YS, 2021, AAAI CONF ARTIF INTE, V35, P12692; Cohan Arman, 2018, P 2018 C N AM CHAPTE, V2, P615; Fabbri AR, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P704; Fabbri AR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1074; Finn C, 2017, PR MACH LEARN RES, V70; Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3622; Hermann KM, 2015, ADV NEUR IN, V28; Huh T, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2629, DOI 10.1145/3477495.3531908; Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519; Kornilova A., 2019, P 2 WORKSH NEW FRONT, P48, DOI DOI 10.18653/V1/D19-5406; Koupaee M, 2018, Arxiv, DOI arXiv:1810.09305; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Magooda A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1652; Mi F, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3151; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Raffel C, 2020, J MACH LEARN RES, V21; Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Sharma E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2204; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Vinyals Oriol, 2015, ADV NEURAL INFORM PR, V28; Yu T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5892; Zhang J., 2020, PMLR, P11328; Zhang R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P446; Zhao YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P583	30	0	0	1	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	DEC 30	2023	234								121029	10.1016/j.eswa.2023.121029	http://dx.doi.org/10.1016/j.eswa.2023.121029		AUG 2023	8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	Q7OP8					2024-07-03	WOS:001059384300001
J	Agüero-Torales, M; López-Herrera, AG; Vilares, D				Aguero-Torales, Marvin M.; Lopez-Herrera, Antonio G.; Vilares, David			Multidimensional Affective Analysis for Low-Resource Languages: A Use Case with Guarani-Spanish Code-Switching Language	COGNITIVE COMPUTATION			English	Article						Natural language processing; Sentiment analysis; Affective analysis; Code-switching; Low-resource languages	SENTIMENT ANALYSIS	This paper focuses on text-based affective computing for Jopara, a code-switching language that combines Guarani and Spanish. First, we collected a dataset of tweets primarily written in Guarani and annotated them for three widely used dimensions in sentiment analysis: (a) emotion recognition, (b) humor detection, and (c) offensive language identification. Then, we developed several neural network models, including large language models specifically designed for Guarani, and compared their performance against off-the-shelf multilingual and Spanish pre-trained models for the aforementioned dimensions. Our experiments show that language models incorporating Guarani during pre-training or pre-fine-tuning consistently achieve the best results, despite limited resources (a single 24-GB GPU and only 800K tokens). Notably, even a Guarani BERT model with just two layers of Transformers shows a favorable balance between accuracy and computational power, likely due to the inherent low-resource nature of the task. We present a comprehensive overview of corpus creation and model development for low-resource languages like Guarani, particularly in the context of its code-switching with Spanish, resulting in Jopara. Our findings shed light on the challenges and strategies involved in analyzing affective language in such linguistic contexts.	[Aguero-Torales, Marvin M.; Lopez-Herrera, Antonio G.] Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain; [Vilares, David] Univ A Coruna, Dept Comp Sci & Informat Technol, CITIC, Campus Elvina S-N, La Coruna 15008, A Coruna, Spain; [Aguero-Torales, Marvin M.] Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain	University of Granada; Universidade da Coruna	Agüero-Torales, M (corresponding author), Univ Granada, Dept Comp Sci & Artificial Intelligence, Calle Daniel Saucedo Aranda S-N, Granada 18071, Granada, Spain.; Agüero-Torales, M (corresponding author), Global CoE Data Intelligence, Camino Cerro Gamos 1, Madrid 28224, Spain.	maguero@correo.ugr.es; lopez-herrera@decsai.ugr.es; david.vilares@udc.es	Lopez-Herrera, Antonio G/B-7932-2011	Lopez-Herrera, Antonio G/0000-0001-8424-275X; Aguero-Torales, Marvin M./0000-0002-0910-0310	FBBVA; SCANNER-UDC [PID2020-113230RB-C21]; MCIN/AEI; European Research Council (ERC); European Union [101100615]; Xunta de Galicia [ED431C 2020/11]; European Union (ERDF - Galicia 2014-2020 Program) [ED431G 2019/01]; University of Granada; Generalitat Valenciana; University of Alicante [IDIFEDER/2020/003]; European Research Council (ERC) [101100615] Funding Source: European Research Council (ERC)	FBBVA(BBVA Foundation); SCANNER-UDC; MCIN/AEI; European Research Council (ERC)(European Research Council (ERC)); European Union(European Union (EU)); Xunta de Galicia(Xunta de Galicia); European Union (ERDF - Galicia 2014-2020 Program)(European Union (EU)Marie Curie Actions); University of Granada; Generalitat Valenciana(Center for Forestry Research & Experimentation (CIEF)); University of Alicante; European Research Council (ERC)(European Research Council (ERC)Spanish Government)	This work is supported by a 2020 Leonardo Grant for Researchers and Cultural Creators from the FBBVA. This paper has also received funding from grant SCANNER-UDC (PID2020-113230RB-C21) funded by MCIN/AEI/10.13039/501100011033, the European Research Council (ERC), which has supported this research under the European Union's Horizon Europe research and innovation programme (SALSA, grant agreement no. 101100615), Xunta de Galicia (ED431C 2020/11), and Centro de Investigacion de Galicia "CITIC," funded by Xunta de Galicia and the European Union (ERDF - Galicia 2014-2020 Program), by grant ED431G 2019/01. Additionally, the research leading to these results received funding from the University of Granada, Generalitat Valenciana, and the University of Alicante (IDIFEDER/2020/003).	Abdellaoui H, 2018, COMPUT SIST, V22, P777, DOI 10.13053/CyS-22-3-3031; Adelani DI, 2021, T ASSOC COMPUT LING, V9, P1116, DOI 10.1162/tacl_a_00416; Adwan OY, 2020, INT J EMERG TECHNOL, V15, P79, DOI 10.3991/ijet.v15i15.14467; Afli H., 2017, 18 INT C COMP LING I; Agerri R, 2020, P 12 LANGUAGE RESOUR; Aguero-Torales MM, 2021, P 5 WORKSHOP COMPUTA, P95; Aguero-Torales MM, 2022, MACHINE LEARNING APP; Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Asgari E, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4113; Attardi Giusepppe., Wikiextractor; Babu A, 2022, INTERSPEECH, P2278, DOI 10.21437/Interspeech.2022-143; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Batra R, LARGE SCALE TWEET DA; Biewald L, Experiment Tracking with Weights and Biases; BittarPrieto J, 2016, THESIS U NEW MEXICO; BittarPrieto J, 2020, CONSTRUCTIONIST APPR; Boidin C, 2005, REGIONALWISSENSCHAFT, V11, P303; Borges Y, 2021, PROCES LENG NAT, P89, DOI 10.26342/2021-66-7; Cambria E, 2015, COGN COMPUT, V7, P183, DOI 10.1007/s12559-015-9325-0; Canete Jose, 2020, PML4DC ICLR 2020; Chatterjee A., 2019, P 13 INT WORKSHOP SE, P39, DOI [10.18653/, DOI 10.18653/V1/S19-2005]; Chen YQ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P383; Chiruzzo L, 2023, P 12 INT GLOB WORDN; Chiruzzo L, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2098; Chiruzzo L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5106; Conneau Alexis, 2020, P 58 ANN M ASS COMPU, P6022, DOI 10.18653/v1/2020.acl-main.536; Cordova J, 2019, INFORM MANAGEMENT BI, P198, DOI [10.1007/978-3-030-11680-4_20, DOI 10.1007/978-3-030-11680-4_20]; Costa-jussa MR, ARXIV; de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI [10.1162/coli_a_00402, 10.1162/COLI_a_00402]; Devi MD., 2020, International Conference on Machine Learning, Image Processing, Network Security and Data Sciences, P411, DOI 10.1007/978-981-15-6318-8_34; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duran M., 2021, FORMALISING NATURAL, P61, DOI [10.1007/978-3-030-70629-6_6, DOI 10.1007/978-3-030-70629-6_6]; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; Estigarribia B, 2020, Grammars Wor Minorit, P1, DOI 10.14324/111.9781787352872; Estigarribia B, 2015, J LANG CONTACT, V8, P183, DOI 10.1163/19552629-00802002; GarciaTrillo MA, 2021, PROCESAMIENTO LENGUA, V1; Ghosh S, 2022, COGN COMPUT, V14, P110, DOI 10.1007/s12559-021-09828-7; Giossa N, 2021, THESIS U REPUBLICA U; Green DW, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00103; Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2545; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hossain N, 2020, P 14 WORKSHOP SEMANT, P746, DOI DOI 10.18653/V1/2020.SEMEVAL-1.98; Jain DK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102758; Jakobsen AL, 2017, TRANSLATION TRANSITI, V133; Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI 10.18653/v1/e17-2068; Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062; Kann K, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.995667; Kann K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3342; Khan Mansoor, 2020, 2020 IEEE 8th International Conference on Photonics (ICP), P1, DOI 10.1109/ICP46580.2020.9206421; Kuratov Y., 2019, KompJuternaja Lingvistika IntellektualNye Tehnol, V18, P333; Kuznetsova A, 2021, P 1 WORKSH NAT LANG, P81; Lamprinidis S., 2021, P 11 WORKSHOP COMPUT, P62; Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483; LeCun Y., 1995, Handb Brain Theory Neural Netw, V3361, P1995, DOI [DOI 10.5555/303568.303704, 10.5555/303568.303704]; Lieberman MD, 2019, NAT HUM BEHAV, V3, P20, DOI 10.1038/s41562-018-0487-0; Liu Y, ROBERTA ROBUSTLY OPT; Mager M, 2018, P 27 INT C COMP LING, P55, DOI DOI 10.48550/ARXIV.1806.04291; Mager M, 2021, P 1 WORKSH NAT LANG, P202, DOI DOI 10.18653/V1/2021.AMERICASNLP-1.23; Magooda A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1652; Mamta, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3514498; Mazumder M, 2021, 35 C NEURAL INFORM P; Mihalcea R, 2006, COMPUT INTELL-US, V22, P126, DOI 10.1111/j.1467-8640.2006.00278.x; Muhammad SH, NAIJASENTI NIGERIAN; Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237; Novak PK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144296; Ogueji Kelechi, 2021, WORKSHOP MULTILINGUA, P116, DOI [10.18653/v1/2021.mrl-1.11, DOI 10.18653/V1/2021.MRL-1.11]; Pajupuu H, 2016, FOLKLORE-EL J FOLKL, P125, DOI 10.7592/FEJF2016.64.polarity; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704; Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7654; Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996; Plaza-Del-Arco FM, 2021, IEEE ACCESS, V9, P112478, DOI 10.1109/ACCESS.2021.3103697; Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344; Ranasinghe T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5838; Ríos AA, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P37, DOI 10.1109/BRACIS.2014.18; Schulz C, 2018, P 2018 C N AM CHAPT, V2, P35; Souza F., 2020, LECT NOTES COMPUTER, P403, DOI [10.1007/978-3-030-61377-8_28, DOI 10.1007/978-3-030-61377-828]; Strapparava C, 2015, OXFORD HDB AFFECTIVE; Tejwani R., ARXIV; Vilares D, 2021, PROCES LENG NAT, P13, DOI 10.26342/2021-66-1; Wang Minghan, 2020, P 22 ANN C EUR ASS M, P53; Wang Z, 2020, INT C LEARNING REPRE; Winata G. I., 2021, P 1 WORKSH MULT REPR, P1, DOI DOI 10.18653/V1/2021.MRL-1.1; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833; Wu Y., 2016, ARXIV160908144, V1609; Xu QT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3030, DOI 10.1109/ICASSP39728.2021.9414641; Yen MF, 2022, COMPUT ECON, V59, P1677, DOI 10.1007/s10614-021-10111-y; Yong Hu, 2020, Web and Big Data. 4th International Joint Conference, APWeb-WAIM 2020. Lecture Notes in Computer Science (LNCS 12317), P603, DOI 10.1007/978-3-030-60259-8_44; Yong ZX, ARXIV; Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4; Zampieri M., 2020, P 14 WORKSH SEM EV, P1425, DOI DOI 10.18653/V1/2020.SEMEVAL-1.188; Zhang Y., 2018, P ACL 2018 MELB AUST, P74, DOI DOI 10.18653/V1/P18-4013; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	93	3	3	2	5	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	JUL	2023	15	4					1391	1406		10.1007/s12559-023-10165-0	http://dx.doi.org/10.1007/s12559-023-10165-0		JUN 2023	16	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Neurosciences & Neurology	O3JP9					2024-07-03	WOS:001020154100001
C	Bird, JJ; Lotfi, A			ACM	Bird, Jordan J.; Lotfi, Ahmad			Generative Transformer Chatbots for Mental Health Support: A Study on Depression and Anxiety	PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023			English	Proceedings Paper	16th ACM International Conference on Pervasive Technologies Related to Assistive Environments (PETRA)	JUL 05-07, 2023	Corfu, GREECE	Assoc Comp Machinery, ICPS Digital Libraries, Univ Texas Arlington, Coll Engn, Natl Sci Fdn, Univ Texas Arlington, Dept Comp Sci & Engn, Univ Texas Arlington, Human Centered Comp Lab, Univ Texas Arlington, iPerform Ind Univ NSF Ctr, Natl Ctr Sci Res, Ionian Univ, Technologies Journal		Chatbots; Natural Language Processing; Transformers; Mental Health		Mental health is a critical issue worldwide and effective treatments are available. However, incidence of social stigma prevents many from seeking the support they need. Given the rapid developments in the field of large-language models, this study explores the potential of chatbots to support people experiencing depression and anxiety. The focus of this research is on the engineering aspect of building chatbots, and through topology optimisation find an effective hyperparameter set that can predict tokens with 88.65% accuracy and with a performance of 96.49% and 97.88% regarding the correct token appearing in the top 5 and 10 predictions. Examples of how optimised chatbots can effectively answer questions surrounding mental health are provided, generalising information from verified online sources. The results of this study demonstrate the potential of chatbots to provide accessible and anonymous support to individuals who may otherwise be deterred by the stigma associated with seeking help for mental health issues. However, the limitations and challenges of using chatbots for mental health support must also be acknowledged, and future work is suggested to fully understand the potential and limitations of chatbots and to ensure that they are developed and deployed ethically and responsibly.	[Bird, Jordan J.; Lotfi, Ahmad] Nottingham Trent Univ, Dept Comp Sci, Nottingham, England	Nottingham Trent University	Bird, JJ (corresponding author), Nottingham Trent Univ, Dept Comp Sci, Nottingham, England.	jordan.bird@ntu.ac.uk; ahmad.lotfi@ntu.ac.uk	Bird, Jordan J./Z-4460-2019; Lotfi, Ahmad/D-4260-2009	Bird, Jordan J./0000-0002-9858-1231; Lotfi, Ahmad/0000-0002-5139-6565				Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828; Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Almansor EH, 2021, COMPUTING, V103, P491, DOI 10.1007/s00607-020-00863-0; Bali Manish, 2019, International Journal of Recent Technology and Engineering, V8, P6334; Bansal H., 2018, INT J ADV RES COMPUT, V8, P53, DOI DOI 10.23956/IJARCSSE.V8I4.630; Bhagchandani A, 2022, LECT NOTE NETW SYST, V318, P271, DOI 10.1007/978-981-16-5689-7_24; Bird JJ, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03439-8; Crasto Reuben, 2021, 2021 2 INT C EM TECH, P1; Cuayáhuitl H, 2019, NEUROCOMPUTING, V366, P118, DOI 10.1016/j.neucom.2019.08.007; Deshpande S, 2021, STUD HEALTH TECHNOL, V281, P48, DOI 10.3233/SHTI210118; Devlin J., 2018, Google, V2; Frank R.G., 2006, BETTER NOT WELL MENT; Hanley T, 2021, COUNS PSYCHOTHER RES, V21, P522, DOI 10.1002/capr.12371; Jiang Z.P., 2020, P 11 INT WORKSHOP HL, P147, DOI DOI 10.18653/V1/2020.LOUHI-1.16; Joglekar Chaitanya, 2022, Master's thesis; Jones Edgar., 2005, Shell Shock to PTSD: Military Psychiatry from 1900 to the Gulf War; Lin T., 2022, AI Open; Liu JF, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1793, DOI 10.1145/3397271.3401250; Lukovnikov D, 2019, LECT NOTES COMPUT SC, V11778, P470, DOI 10.1007/978-3-030-30793-6_27; Prakash Kolla Bhanu, 2020, International Journal, V8, P5; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Shao TH, 2019, IEEE ACCESS, V7, P26146, DOI 10.1109/ACCESS.2019.2900753; Sickel AE, 2014, ADV MENT HEALTH, V12, P202, DOI 10.1080/18374905.2014.11081898; Suhaili SM, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115461; Syed ZH, 2021, PROCEDIA COMPUT SCI, V192, P941, DOI 10.1016/j.procs.2021.08.097; Vaswani A, 2017, ADV NEUR IN, V30; WHO, 2021, Depression	28	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0069-9				2023							475	479		10.1145/3594806.3596520	http://dx.doi.org/10.1145/3594806.3596520			5	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2SR					2024-07-03	WOS:001124478300079
C	Kant, Y; Ramachandran, A; Yenamandra, S; Gilitschenski, I; Batra, D; Szot, A; Agrawal, H		Avidan, S; Brostow, G; Cisse, M; Farinella, GM; Hassner, T		Kant, Yash; Ramachandran, Arun; Yenamandra, Sriram; Gilitschenski, Igor; Batra, Dhruv; Szot, Andrew; Agrawal, Harsh			Housekeep: Tidying Virtual Households Using Commonsense Reasoning	COMPUTER VISION, ECCV 2022, PT XXXIX	Lecture Notes in Computer Science		English	Proceedings Paper	17th European Conference on Computer Vision (ECCV)	OCT 23-27, 2022	Tel Aviv, ISRAEL					We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the home for embodied AI. In Housekeep, an embodied agent must tidy a house by rearranging misplaced objects without explicit instructions specifying which objects need to be rearranged. Instead, the agent must learn from and is evaluated against human preferences of which objects belong where in a tidy house. Specifically, we collect a dataset of where humans typically place objects in tidy and untidy houses constituting 1799 objects, 268 object categories, 585 placements, and 105 rooms. Next, we propose a modular baseline approach for Housekeep that integrates planning, exploration, and navigation. It leverages a fine-tuned large language model (LLM) trained on an internet text corpus for effective planning. We find that our baseline planner generalizes to some extent when rearranging objects in unknown environments. See our webpage for code, data and more details: https://yashkant.github. io/housekeep/.	[Kant, Yash; Gilitschenski, Igor] Univ Toronto, Toronto, ON, Canada; [Kant, Yash; Ramachandran, Arun; Yenamandra, Sriram; Batra, Dhruv; Szot, Andrew; Agrawal, Harsh] Georgia Tech, Atlanta, GA 30332 USA; [Batra, Dhruv] Meta AI, Menlo Pk, CA USA	University of Toronto; University System of Georgia; Georgia Institute of Technology	Kant, Y (corresponding author), Univ Toronto, Toronto, ON, Canada.; Kant, Y (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.	ysh.kant@gmail.com			NSF; AFRL; DARPA; ONR YIPs; ARO PECASE; Amazon	NSF(National Science Foundation (NSF)); AFRL(United States Department of DefenseUS Air Force Research Laboratory); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); ONR YIPs; ARO PECASE; Amazon	We thank the Habitat team for their support. The Georgia Tech effort was supported in part by NSF, AFRL, DARPA, ONR YIPs, ARO PECASE, Amazon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the U.S. Government, or any sponsor.	Abbeel P., 2021, arXiv; Abdo N, 2015, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ICRA.2015.7139396; Agrawal H., 2016, P 2016 C EMPIRICAL M; Anderson P, 2018, Arxiv, DOI [arXiv:1807.06757, DOI 10.48550/ARXIV.1807.06757]; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; [Anonymous], 2021, HABITAT HABITAT CHAL; [Anonymous], 2020, FETCH ROBOTICS FETCH; Armeni I., 2019, 2019 IEEECVF INT C C; Bao HB, 2022, Arxiv, DOI arXiv:2111.02358; Batra D., 2020, ARXIV PREPRINT ARXIV; Batra D, 2020, Arxiv, DOI arXiv:2006.13171; Bhagavatula C., 2020, 8 INT C LEARNING REP; Bisk Y., 2020, 34 AAAI C ARTIFICIAL; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504; Cartillier V, 2021, Arxiv, DOI arXiv:2010.01191; Collins J, 2022, Arxiv, DOI arXiv:2110.06199; Craswell N, 2009, Encyclopedia of Database Systems, DOI 10.1007/978-0-387-39940-9_488; Crowston Kevin, 2012, SHAPING FUTURE ICT R, P6, DOI [10.1007/978-3-642-35142-6-14, DOI 10.1007/978-3-642-35142-6_14, 10.1007/978-3-642-35142-6_14]; Daruna A., 2019, ROBOCSE ROBOT COMMON; Das A., 2018, 2018 IEEE C COMPUTER; Ehsani K, 2021, PROC CVPR IEEE, P4495, DOI 10.1109/CVPR46437.2021.00447; Fleiss J.L., 1971, Psychological Bulletin, V76, P378; Gan C., 2020, NEURIPS; Google Research, 2020, GOOGL SCANN OBJ; Gordon D, 2018, PROC CVPR IEEE, P4089, DOI 10.1109/CVPR.2018.00430; Granroth-Wilding M, 2016, AAAI CONF ARTIF INTE, P2727; Hill F, 2020, Arxiv, DOI arXiv:2005.09382; Hong Y., 2021, ECCV; Hu XW, 2021, Arxiv, DOI arXiv:2009.13682; Huang WL, 2022, Arxiv, DOI arXiv:2201.07207; Jiang JD, 2018, Arxiv, DOI arXiv:1806.01054; Jiang Y., 2012, P 29 INT C MACHINE L; Kapelyukh Ivan., 2021, CoRL; Kolve E, 2017, ARXIV; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Levesque H., 2011, KR; Li S, 2022, Arxiv, DOI arXiv:2202.01771; Li X., 2020, EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8; Liu WY, 2021, ROBOT SCI SYS; Liu WY, 2021, Arxiv, DOI arXiv:2110.10189; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu JS, 2019, ADV NEUR IN, V32; Majumdar A, 2020, Arxiv, DOI arXiv:2004.14973; Mostafazadeh N., 2016, P 2016 C N AM CHAPTE; Moudgil A., 2021, ADV NEURAL INFORM PR, V34; Narasimhan M., 2020, ABS200709841 CORR; Padmakumar A, 2021, Arxiv, DOI [arXiv:2110.00534, 10.1609/aaai.v36i2.20097]; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Petroni F., 2020, Automated Knowledge Base Construction; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Ramakrishnan SK, 2021, INT J COMPUT VISION, V129, P1616, DOI 10.1007/s11263-021-01437-z; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732; Salganik MJ, 2018, BIT BY BIT: SOCIAL RESEARCH IN THE DIGITAL AGE, P1; Sap M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4463; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Shen BK, 2021, Arxiv, DOI arXiv:2012.02924; Shridhar M., 2020, 2020 IEEECVF C COMPU; Srivastava S., 2021, CORL; Szot Andrew, 2021, Advances in Neural Information Processing Systems, V34, P251; Taniguchi A, 2021, ADV ROBOTICS, V35, P471, DOI 10.1080/01691864.2021.1890212; Thomason Jesse, 2019, CoRL, V100, P394; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Vaswani A, 2017, ADV NEUR IN, V30; Wani S., 2020, NEURIPS; Weihs L, 2021, PROC CVPR IEEE, P5918, DOI 10.1109/CVPR46437.2021.00586; Wiegand M., 2019, P 2019 C N AM CHAPT, V1, P602; Wijmans E, 2019, PROC CVPR IEEE, P6652, DOI 10.1109/CVPR.2019.00682; Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA '97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851; Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688; Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791; Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93; Zhou B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3363	76	6	7	2	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-19841-0; 978-3-031-19842-7	LECT NOTES COMPUT SC			2022	13699						355	373		10.1007/978-3-031-19842-7_21	http://dx.doi.org/10.1007/978-3-031-19842-7_21			19	Computer Science, Artificial Intelligence; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BU4OY					2024-07-03	WOS:000904430800021
J	Kim, J; Yoon, S; Choi, T; Sull, S				Kim, Jaehyun; Yoon, Seongwook; Choi, Taehyeon; Sull, Sanghoon			Unsupervised Video Anomaly Detection Based on Similarity with Predefined Text Descriptions	SENSORS			English	Article						abnormal video; CLIP; embedding space; fine-tuning of pre-trained models; large language models; large vision and language models; similarity measure; text descriptions; unsupervised video anomaly detection		Research on video anomaly detection has mainly been based on video data. However, many real-world cases involve users who can conceive potential normal and abnormal situations within the anomaly detection domain. This domain knowledge can be conveniently expressed as text descriptions, such as "walking" or "people fighting", which can be easily obtained, customized for specific applications, and applied to unseen abnormal videos not included in the training dataset. We explore the potential of using these text descriptions with unlabeled video datasets. We use large language models to obtain text descriptions and leverage them to detect abnormal frames by calculating the cosine similarity between the input frame and text descriptions using the CLIP visual language model. To enhance the performance, we refined the CLIP-derived cosine similarity using an unlabeled dataset and the proposed text-conditional similarity, which is a similarity measure between two vectors based on additional learnable parameters and a triplet loss. The proposed method has a simple training and inference process that avoids the computationally intensive analyses of optical flow or multiple frames. The experimental results demonstrate that the proposed method outperforms unsupervised methods by showing 8% and 13% better AUC scores for the ShanghaiTech and UCFcrime datasets, respectively. Although the proposed method shows -6% and -5% than weakly supervised methods for those datasets, in abnormal videos, the proposed method shows 17% and 5% better AUC scores, which means that the proposed method shows comparable results with weakly supervised methods that require resource-intensive dataset labeling. These outcomes validate the potential of using text descriptions in unsupervised video anomaly detection.	[Kim, Jaehyun; Yoon, Seongwook; Choi, Taehyeon; Sull, Sanghoon] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea	Korea University	Sull, S (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.	jhkim@mpeg.korea.ac.kr; swyoon@mpeg.korea.ac.kr; taehyeon@korea.ac.kr; sull@korea.ac.kr		Choi, Taehyeon/0009-0006-8975-7430	DAPA; ADD [UD230017TD]	DAPA; ADD	This work was conducted by Center for Applied Research in Artificial Intelligence (CARAI)grant funded by DAPA and ADD (UD230017TD).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909; Cho MyeongAh, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P12137, DOI 10.1109/CVPR52729.2023.01168; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Gao P., 2021, arXiv; Georgescu MI, 2022, IEEE T PATTERN ANAL, V44, P4505, DOI 10.1109/TPAMI.2021.3074805; Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685; Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86; Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803; Jia C, 2021, PR MACH LEARN RES, V139; Khandelwal A, 2022, PROC CVPR IEEE, P14809, DOI 10.1109/CVPR52688.2022.01441; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Li JN, 2022, PR MACH LEARN RES; Li M., 2022, CVPR, P16420; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu PP, 2019, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2019.00470; Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684; Lu Y., 2022, P IEEE CVF C COMP VI, P5206; Lv Hui, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P8022, DOI 10.1109/CVPR52729.2023.00775; Menon S, 2022, Arxiv, DOI arXiv:2210.07183; Nilsback ME, 2006, IEEE C COMP VIS PATT, Vvol2, P1447, DOI [10.1109/CVPR.2006.42, DOI 10.1109/CVPR.2006.42]; Paszke A, 2019, ADV NEUR IN, V32; Pawan Kumar M., 2010, NIPS; Purwanto D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P173, DOI 10.1109/ICCV48922.2021.00024; Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655; Qiao MN, 2017, CHIN CONTR CONF, P11098, DOI 10.23919/ChiCC.2017.8029129; Radford A, 2021, PR MACH LEARN RES, V139; Rao Y., 2022, P IEEECVF C COMPUTER, P18082; Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767; Reiss T., 2022, arXiv; Sapkota H., 2022, PROC IEEE C COMPUT V, P3212; Sato Fumiaki, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P6471, DOI 10.1109/CVPR52729.2023.00626; Shen S., 2021, arXiv; Shi H., 2022, P IEEECVF C COMPUTER, P9611; Singh A, 2022, PROC CVPR IEEE, P15617, DOI 10.1109/CVPR52688.2022.01519; Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678; Teh Y., 2004, Advances in Neural Information Processing Systems, V17; Tian Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4955, DOI 10.1109/ICCV48922.2021.00493; Tur AO, 2023, Arxiv, DOI arXiv:2304.05841; Wang Can, 2022, P IEEECVF C COMPUTER, P3835; Wang XZ, 2022, IEEE T NEUR NET LEAR, V33, P2301, DOI 10.1109/TNNLS.2021.3083152; Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139; Wortsman M, 2022, PROC CVPR IEEE, P7949, DOI 10.1109/CVPR52688.2022.00780; Wu P, 2021, IEEE T IMAGE PROCESS, V30, P3513, DOI 10.1109/TIP.2021.3062192; Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554; Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010; Yao LW, 2021, Arxiv, DOI arXiv:2111.07783; Yu G, 2022, PROC CVPR IEEE, P13967, DOI 10.1109/CVPR52688.2022.01360; Zaheer MZ, 2022, PROC CVPR IEEE, P14724, DOI 10.1109/CVPR52688.2022.01433; Zaigham Zaheer Muhammad, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14171, DOI 10.1109/CVPR42600.2020.01419; Zeng Y, 2022, 39 INT C MACHINE LEA; Zhang Chen, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P16271, DOI 10.1109/CVPR52729.2023.01561; Zhang H., 2022, Advances in Neural Information Processing Systems, V35; Zhang RR, 2021, Arxiv, DOI arXiv:2111.03930; Zhou K., 2022, P IEEECVF C COMPUTER, P16816; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	58	1	1	1	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	JUL	2023	23	14							6256	10.3390/s23146256	http://dx.doi.org/10.3390/s23146256			27	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	N7KR0	37514551	Green Published, gold			2024-07-03	WOS:001038760700001
J	Li, ZZ; Zhang, JF; Zhou, W; Zheng, JJ; Xia, YS				Li, Zhenzhu; Zhang, Jingfeng; Zhou, Wei; Zheng, Jianjun; Xia, Yinshui			GPT-agents based on medical guidelines can improve the responsiveness and explainability of outcomes for traumatic brain injury rehabilitation	SCIENTIFIC REPORTS			English	Article						Large language model; Generative pre-trained transformer; Medical guidelines; Traumatic brain injury; Rehabilitation	AI	This study explored the application of generative pre-trained transformer (GPT) agents based on medical guidelines using large language model (LLM) technology for traumatic brain injury (TBI) rehabilitation-related questions. To assess the effectiveness of multiple agents (GPT-agents) created using GPT-4, a comparison was conducted using direct GPT-4 as the control group (GPT-4). The GPT-agents comprised multiple agents with distinct functions, including "Medical Guideline Classification", "Question Retrieval", "Matching Evaluation", "Intelligent Question Answering (QA)", and "Results Evaluation and Source Citation". Brain rehabilitation questions were selected from the doctor-patient Q&A database for assessment. The primary endpoint was a better answer. The secondary endpoints were accuracy, completeness, explainability, and empathy. Thirty questions were answered; overall GPT-agents took substantially longer and more words to respond than GPT-4 (time: 54.05 vs. 9.66 s, words: 371 vs. 57). However, GPT-agents provided superior answers in more cases compared to GPT-4 (66.7 vs. 33.3%). GPT-Agents surpassed GPT-4 in accuracy evaluation (3.8 +/- 1.02 vs. 3.2 +/- 0.96, p = 0.0234). No difference in incomplete answers was found (2 +/- 0.87 vs. 1.7 +/- 0.79, p = 0.213). However, in terms of explainability (2.79 +/- 0.45 vs. 07 +/- 0.52, p < 0.001) and empathy (2.63 +/- 0.57 vs. 1.08 +/- 0.51, p < 0.001) evaluation, the GPT-agents performed notably better. Based on medical guidelines, GPT-agents enhanced the accuracy and empathy of responses to TBI rehabilitation questions. This study provides guideline references and demonstrates improved clinical explainability. However, further validation through multicenter trials in a clinical setting is necessary. This study offers practical insights and establishes groundwork for the potential theoretical integration of LLM-agents medicine.	[Li, Zhenzhu; Zhang, Jingfeng; Zheng, Jianjun] Ningbo 2 Hosp, Radiol Dept, Ningbo 315211, Peoples R China; [Li, Zhenzhu; Zhou, Wei] Ningbo 2 Hosp, Dept Neurosurg, Ningbo 315211, Peoples R China; [Li, Zhenzhu; Xia, Yinshui] Ningbo Univ, Fac Elect Engn & Comp Sci, Ningbo 315211, Peoples R China	Ningbo University	Zheng, JJ (corresponding author), Ningbo 2 Hosp, Radiol Dept, Ningbo 315211, Peoples R China.; Xia, YS (corresponding author), Ningbo Univ, Fac Elect Engn & Comp Sci, Ningbo 315211, Peoples R China.	zhjjnb2@163.com; xiayinshui@nbu.edu.cn			HwaMei Research Foundation of Ningbo No. 2 Hospital	HwaMei Research Foundation of Ningbo No. 2 Hospital	We extend our heartfelt gratitude to Xu Ruiyu and the neurosurgery team at Ningbo No.2 Hospital and the volunteers who participated in this study, for their valuable contributions. We would also like to express our appreciation to Kaggle (www.kaggle.com) for providing the online platform and their free services.	Arachchige ASPM, 2023, EUR J NUCL MED MOL I, V50, P2248, DOI 10.1007/s00259-023-06227-y; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barlas T, 2024, INT J OBESITY, V48, P271, DOI 10.1038/s41366-023-01410-5; Capizzi A, 2020, MED CLIN N AM, V104, P213, DOI 10.1016/j.mcna.2019.11.001; Chen HM, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00699-2; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Chinese Medical Association Neurosurgery Branch Chinese Neurosurgical Intensive Care Collaboration Group, Chin. Med. J., V97, P1615; Guo Y, 2024, NEURAL REGEN RES, V19, P663, DOI 10.4103/1673-5374.380909; Gupta B, 2023, COGENT BUS MANAG, V10, DOI 10.1080/23311975.2023.2275851; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Hasnain M, 2023, ANN BIOMED ENG, V51, P2100, DOI 10.1007/s10439-023-03238-6; He YB, 2023, ANN BIOMED ENG, V51, P1362, DOI 10.1007/s10439-023-03206-0; Johri S., 2023, medRxiv; Kim G., 2023, arXiv; Kuang YR, 2023, INT J SURG, V109, P2886, DOI 10.1097/JS9.0000000000000571; Lin B., 2023, arXiv; Marklund N, 2019, J INTERN MED, V285, P608, DOI 10.1111/joim.12900; McBee J. C., 2023, medRxiv; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Peng SX, 2024, ANN BIOMED ENG, V52, P462, DOI 10.1007/s10439-023-03314-x; Posti JP, 2021, NEUROEPIDEMIOLOGY, V55, P216, DOI 10.1159/000515395; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rossettini G, 2023, J ORTHOP SPORT PHYS, V53, P728, DOI 10.2519/jospt.2023.12000; Sacco S, 2024, LANCET NEUROL, V23, P17, DOI 10.1016/S1474-4422(23)00450-7; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wachter RM, 2024, JAMA-J AM MED ASSOC, V331, P65, DOI 10.1001/jama.2023.25054; Wang G, 2023, ARXIV; Wu Y., 2023, ARXIV; Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016; Zhang Liang, 2023, J Rehabil Med, V55, pjrm13373, DOI 10.2340/jrm.v55.13373; Zhang Y., 2023, ARXIV; Zhao H., 2023, arXiv	36	0	0	13	13	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 1	2024	14	1							7626	10.1038/s41598-024-58514-9	http://dx.doi.org/10.1038/s41598-024-58514-9			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	MT1N9	38561445	gold, Green Published			2024-07-03	WOS:001195796200031
J	Li, YS; Keung, J; Yang, Z; Ma, XX; Zhang, JY; Liu, S				Li, Yishu; Keung, Jacky; Yang, Zhen; Ma, Xiaoxue; Zhang, Jingyu; Liu, Shuo			SimAC: simulating agile collaboration to generate acceptance criteria in user story elaboration	AUTOMATED SOFTWARE ENGINEERING			English	Article						Large language models; Prompts engineering; User story; Acceptance criteria; Agile requirements engineering	AGREEMENT	In agile requirements engineering, Generating Acceptance Criteria (GAC) to elaborate user stories plays a pivotal role in the sprint planning phase, which provides a reference for delivering functional solutions. GAC requires extensive collaboration and human involvement. However, the lack of labeled datasets tailored for User Story attached with Acceptance Criteria (US-AC) poses significant challenges for supervised learning techniques attempting to automate this process. Recent advancements in Large Language Models (LLMs) have showcased their remarkable text-generation capabilities, bypassing the need for supervised fine-tuning. Consequently, LLMs offer the potential to overcome the above challenge. Motivated by this, we propose SimAC, a framework leveraging LLMs to simulate agile collaboration, with three distinct role groups: requirement analyst, quality analyst, and others. Initiated by role-based prompts, LLMs act in these roles sequentially, following a create-update-update paradigm in GAC. Owing to the unavailability of ground truths, we invited practitioners to build a gold standard serving as a benchmark to evaluate the completeness and validity of auto-generated US-AC against human-crafted ones. Additionally, we invited eight experienced agile practitioners to evaluate the quality of US-AC using the INVEST framework. The results demonstrate consistent improvements across all tested LLMs, including the LLaMA and GPT-3.5 series. Notably, SimAC significantly enhances the ability of gpt-3.5-turbo in GAC, achieving improvements of 29.48% in completeness and 15.56% in validity, along with the highest INVEST satisfaction score of 3.21/4. Furthermore, this study also provides case studies to illustrate SimAC's effectiveness and limitations, shedding light on the potential of LLMs in automated agile requirements engineering.	[Li, Yishu; Keung, Jacky; Ma, Xiaoxue; Zhang, Jingyu; Liu, Shuo] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China; [Yang, Zhen] Shandong Univ, Sch Comp Sci & Technol, Qingdao, Peoples R China	City University of Hong Kong; Shandong University	Yang, Z (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao, Peoples R China.	yishuli5-c@my.cityu.edu.hk; Jacky.Keung@cityu.edu.hk; zhenyang@sdu.edu.cn; xiaoxuema3-c@my.cityu.edu.hk; jzhang2297-c@my.cityu.edu.hk; sliu273-c@my.cityu.edu.hk		MA, Xiaoxue/0000-0002-5476-6074; LI, Yishu/0000-0003-4017-4294; ZHANG, Jingyu/0000-0001-6043-4239; Keung, Jacky/0000-0002-3803-9600; LIU, Shuo/0000-0002-8877-3678	General Research Fund of the Research Grants Council of Hong Kong; City University of Hong Kong [6000796, 9229109, 9229098, 9220103, 9229029]	General Research Fund of the Research Grants Council of Hong Kong; City University of Hong Kong(City University of Hong Kong)	This work is supported in part by the General Research Fund of the Research Grants Council of Hong Kong and the research funds of the City University of Hong Kong (6000796, 9229109, 9229098, 9220103, 9229029).	Achananuparp P, 2008, LECT NOTES COMPUT SC, V5182, P305, DOI 10.1007/978-3-540-85836-2_29; Ahmed M, 2023, AUTOMAT SOFTW ENG, V30, DOI 10.1007/s10515-022-00371-9; Ali N, 2019, INFORM SOFTWARE TECH, V106, P126, DOI 10.1016/j.infsof.2018.09.009; Almanaseer A.M., 2022, 2022 INT C EM TRENDS, P1; Bjarnason E, 2015, LECT NOTES BUS INF P, V212, P27, DOI 10.1007/978-3-319-18612-2_3; Bragilovski M, 2022, LECT NOTES COMPUT SC, V13216, P131, DOI 10.1007/978-3-030-98464-9_11; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buglione L, 2013, 2013 JOINT CONFERENCE OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE MEASUREMENT AND THE 2013 EIGHTH INTERNATIONAL CONFERENCE ON SOFTWARE PROCESS AND PRODUCT MEASUREMENT (IWSM-MENSURA), P49, DOI 10.1109/IWSM-Mensura.2013.18; Cardoso Jefferson Rosa, 2014, Dental Press J. Orthod., V19, P27, DOI 10.1590/2176-9451.19.5.027-030.ebo; Carreño LVG, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P582, DOI 10.1109/ICSE.2013.6606604; Cer D, 2018, Arxiv, DOI arXiv:1803.11175; Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285; Cho KYHY, 2014, Arxiv, DOI [arXiv:1409.1259, DOI 10.48550/ARXIV.1409.1259, 10.48550/arXiv.1409.1259]; Coe R., 2002, British Educ. Res. Assoc. Ann. Conf, V12, P14; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Cohn M., 2004, User stories applied: For agile software development; Conboy Kieran., 2004, P 2004 ACM WORKSHOP, P37; Dalpiaz F., 2012, 2018 IEEE 26 INT REQ, P191; Dalpiaz F, 2019, INFORM SOFTWARE TECH, V110, P3, DOI 10.1016/j.infsof.2018.12.007; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diebold P, 2015, LECT NOTES BUS INF P, V212, P40, DOI 10.1007/978-3-319-18612-2_4; Dimitrijevic S, 2015, INFORM SOFTWARE TECH, V57, P352, DOI 10.1016/j.infsof.2014.05.012; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Falessi D, 2018, EMPIR SOFTW ENG, V23, P452, DOI 10.1007/s10664-017-9523-3; Fan AEL, 2023, Arxiv, DOI arXiv:2310.03533; Ferrari A., 2012, 2012 IEEE 20th International Requirements Engineering Conference (RE 2012), P191, DOI 10.1109/RE.2012.6345803; Ferrari A, 2024, Arxiv, DOI arXiv:2404.06371; Ferreira AMS, 2022, ENASE: PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON EVALUATION OF NOVEL APPROACHES TO SOFTWARE ENGINEERING, P477, DOI 10.5220/0011082000003176; Fischbach J, 2020, IEEE INT CONF SOFTW, P321, DOI 10.1109/ICST46399.2020.00040; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Geng X., 2023, Openllama; Guo DY, 2022, Arxiv, DOI arXiv:2203.03850; Gupta A, 2019, LECT NOTES COMPUT SC, V11787, P47, DOI 10.1007/978-3-030-34146-6_5; Hakala K., 2019, P 5 WORKSH BIONLP OP, P56; Halme E, 2021, LECT NOTES BUS INF P, V419, P36, DOI 10.1007/978-3-030-78098-2_3; Hey T, 2020, INT REQUIR ENG CONF, P169, DOI 10.1109/RE48521.2020.00028; Hoang M., 2019, P 22 NORDIC C COMPUT, P187; Hoda R, 2018, IEEE SOFTWARE, V35, P58, DOI 10.1109/MS.2018.290111318; Honnibal M., 2020, spaCy: Industrial-strength Natural Language Processing in Python; Hotomski S, 2018, INT REQUIR ENG CONF, P29, DOI 10.1109/RE.2018.00-54; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kelly A., 2019, The Art of Agile Product Ownership: A Guide for Product Managers, Business Analysts, and Entrepreneurs, P93; Khanh N.T., 2017, P 6 INT C SOFTW COMP, P15; Kojima T., 2022, Advances in neural information processing systems, V35, P22199, DOI DOI 10.48550/ARXIV.2205.11916; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li GH, 2023, Arxiv, DOI arXiv:2303.17760; Li Y., 2024, 2024 IEEE 48 ANN COM; Liu F, 2024, Arxiv, DOI arXiv:2404.00971; Lombriser P, 2016, LECT NOTES COMPUT SC, V9619, P171, DOI 10.1007/978-3-319-30282-9_12; Lucassen G, 2017, REQUIR ENG, V22, P339, DOI 10.1007/s00766-017-0270-1; Lucassen G, 2016, REQUIR ENG, V21, P383, DOI 10.1007/s00766-016-0250-x; Lucassen G, 2016, LECT NOTES COMPUT SC, V9619, P205, DOI 10.1007/978-3-319-30282-9_14; Ma XX, 2023, IEEE T RELIAB, V72, P1663, DOI 10.1109/TR.2023.3236404; Manifesto A., 2001, Haettu, V14, P2012; Meredith P., 2019, ACIS 2019 P, P93; Nema P, 2022, PROC INT CONF SOFTW, P112, DOI 10.1145/3510003.3510079; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3248401; Pandit P., 2015, Int. J. Comput. Appl, V120, P16; Pantiuchina J, 2017, LECT NOTES BUS INF P, V283, P167, DOI 10.1007/978-3-319-57633-6_11; Peng ZD, 2021, INT REQUIR ENG CONF, P245, DOI 10.1109/RE51729.2021.00029; Raffel C, 2020, J MACH LEARN RES, V21; Sedano T, 2019, PROC INT CONF SOFTW, P200, DOI 10.1109/ICSE.2019.00036; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Spoletini P, 2024, LECT NOTES COMPUT SC, V14588, P344, DOI 10.1007/978-3-031-57327-9_22; Subramanian S, 2018, ADV NEUR IN, V31; Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1; Sverrisdottir HS, 2014, PROCD SOC BEHV, V119, P257, DOI 10.1016/j.sbspro.2014.03.030; Thakur JS, 2016, IEEE INT CONF AUTOM, P828, DOI 10.1145/2970276.2970289; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang T., 2022, INT C MACHINE LEARNI, P22964; Wang X., 2014, Current advances on genetic resistance to rice blast disease, P195; Wang Y., 2021, arXiv; Wautelet Yves, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549299; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wohlin C., 2012, Experimentation in Software Engineering, DOI [10.1007/978-3-642-29044-2, DOI 10.1007/978-3-642-29044-2, 10.1007/978-3-642-29044-2.]; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xiao X., 2012, P ACM SIGSOFT 20 INT, P1; Xue PY, 2024, Arxiv, DOI arXiv:2404.14824; Yang Z, 2024, Arxiv, DOI arXiv:2404.14646; Zhang JZ, 2023, Arxiv, DOI arXiv:2304.12562; Zhang YW, 2023, Arxiv, DOI arXiv:2308.14460; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	89	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0928-8910	1573-7535		AUTOMAT SOFTW ENG	Automat. Softw. Eng.	NOV	2024	31	2							55	10.1007/s10515-024-00448-7	http://dx.doi.org/10.1007/s10515-024-00448-7			56	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UY2H3					2024-07-03	WOS:001251554000001
J	Murugan, M; Yuan, B; Venner, E; Ballantyne, CM; Robinson, KM; Coons, JC; Wang, LW; Empey, PE; Gibbs, RA				Murugan, Mullai; Yuan, Bo; Venner, Eric; Ballantyne, Christie M.; Robinson, Katherine M.; Coons, James C.; Wang, Liwen; Empey, Philip E.; Gibbs, Richard A.			Empowering personalized pharmacogenomics with generative AI solutions	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						generative AI; pharmacogenomic testing; AI assistant; retrieval-augmented generation; large language models; OpenAI GPT-4	CHALLENGES	Objective This study evaluates an AI assistant developed using OpenAI's GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access.Materials and Methods The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails.Results Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI's ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses.Discussion The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant's utility. RAG's ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns.Conclusion This study underscores generative AI's potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.	[Murugan, Mullai; Yuan, Bo; Venner, Eric; Wang, Liwen; Gibbs, Richard A.] Baylor Coll Med, Human Genome Sequencing Ctr, Houston, TX USA; [Yuan, Bo; Venner, Eric; Gibbs, Richard A.] Baylor Coll Med, Dept Mol & Human Genet, Houston, TX USA; [Ballantyne, Christie M.] Baylor Coll Med, Dept Med, Sect Cardiol, Houston, TX USA; [Ballantyne, Christie M.] Baylor Coll Med, Dept Med, Sect Cardiovasc Res, Houston, TX USA; [Robinson, Katherine M.; Coons, James C.; Empey, Philip E.] Univ Pittsburgh, Sch Pharm, Pittsburgh, PA USA; [Coons, James C.] UPMC Presbyterian Shadyside Hosp, Dept Pharm, Pittsburgh, PA USA; [Empey, Philip E.] Univ Pittsburgh, UPMC, Inst Precis Med, Pittsburgh, PA USA; [Murugan, Mullai] Baylor Coll Med, Human Genome Sequencing Ctr, 1 Baylor Plaza, Houston, TX 77030 USA	Baylor College of Medicine; Baylor College of Medicine; Baylor College of Medicine; Baylor College of Medicine; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; UPMC Presbyterian; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Baylor College of Medicine	Murugan, M (corresponding author), Baylor Coll Med, Human Genome Sequencing Ctr, 1 Baylor Plaza, Houston, TX 77030 USA.	murugan@bcm.edu	Empey, Philip/KLY-5211-2024	Murugan, Mullai/0000-0002-9401-2613	National Institutes of Health [1OT2OD002751]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by the National Institutes of Health grant number 1OT2OD002751.	Amendola LM, 2021, ANNU REV GENOM HUM G, V22, P339, DOI 10.1146/annurev-genom-110320-121752; [Anonymous], GITHUB OPENAI ADA EM; [Anonymous], AMA HLTH LITERACY; [Anonymous], PGX AI CHATGPT 35 SU; [Anonymous], PGX STATINS KB; [Anonymous], OPENAI PLATFORM; [Anonymous], 2024, PGX AI ASSISTANT REA; [Anonymous], GITHUB PGX AI ASSIST; Berrios C, 2021, GENET MED, V23, P2289, DOI 10.1038/s41436-021-01267-x; Blumenthal-Barby J, 2023, AM J BIOETHICS, V23, P4, DOI 10.1080/15265161.2022.2135875; Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025; Challen R, 2019, BMJ QUAL SAF, V28, P231, DOI 10.1136/bmjqs-2018-008370; CPIC, GUIDELINE STATINS SL; Donohue KE, 2021, CLIN GENET, V99, P638, DOI 10.1111/cge.13917; Ellahham S, 2020, AM J MED QUAL, V35, P341, DOI 10.1177/1062860619878515; Farmer MB, 2021, CANCER J, V27, P417, DOI 10.1097/PPO.0000000000000553; Gao Y, 2023, arXiv; Gerke S, 2020, ARTIF INTELL HEALTHC, P295, DOI [DOI 10.1016/B978-0-12-818438-7.00012-5, 1016/B978-0-12-818438-7.00012-5, 10.1016/B978-0-12-818438-7.00012-5]; Gudis DA, 2023, INT FORUM ALLERGY RH, V13, P193, DOI 10.1002/alr.23129; Guo JM, 2023, BRIT J CANCER, V128, P2141, DOI 10.1038/s41416-023-02215-z; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hicks JK, 2021, CLIN PHARMACOL THER, V110, P179, DOI 10.1002/cpt.2161; Hill ER, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1139210; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Jin Q, 2024, BIOINFORMATICS, V40, DOI 10.1093/bioinformatics/btae075; Johnson KB, 2021, CTS-CLIN TRANSL SCI, V14, P86, DOI 10.1111/cts.12884; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Lai TM, 2023, J BIOMED INFORM, V143, DOI 10.1016/j.jbi.2023.104392; Lamoureux F, 2017, THERAPIE, V72, P257, DOI 10.1016/j.therap.2016.09.017; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mahbub M, 2022, BIOINFORMATICS, V38, P4369, DOI 10.1093/bioinformatics/btac508; Manolio Teri A, 2022, Am J Hum Genet, V109, P2101, DOI 10.1016/j.ajhg.2022.11.003; Manolio TA, 2013, GENET MED, V15, P258, DOI 10.1038/gim.2012.157; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Nawaz MS, 2023, APPL INTELL, V53, P21920, DOI 10.1007/s10489-023-04618-0; Neelakantan A., 2022, ARXIV; OpenAI, 2023, ArXiv; Peng KQ, 2022, IEEE ACM T COMPUT BI, V19, P2365, DOI 10.1109/TCBB.2021.3079339; Pujari S, 2023, B WORLD HEALTH ORGAN, V101, P364, DOI 10.2471/BLT.23.290215; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Verma SS, 2022, J TRANSL MED, V20, DOI 10.1186/s12967-022-03745-5; Wachter RM, 2024, JAMA-J AM MED ASSOC, V331, P65, DOI 10.1001/jama.2023.25054; Wornow M., 2023, ARXIV; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhang Z, 2023, SEMIN CANCER BIOL, V90, P57, DOI 10.1016/j.semcancer.2023.02.005; Zhao WX, 2023, ARXIV	50	3	3	34	34	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1356	1366		10.1093/jamia/ocae039	http://dx.doi.org/10.1093/jamia/ocae039		MAR 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38447590	Green Submitted			2024-07-03	WOS:001179493300001
J	Liu, MX; Wang, JF; Lin, T; Ma, Q; Fang, ZY; Wu, YQ				Liu, Mingxing; Wang, Junfeng; Lin, Tao; Ma, Quan; Fang, Zhiyang; Wu, Yanqun			An Empirical Study of the Code Generation of Safety-Critical Software Using LLMs	APPLIED SCIENCES-BASEL			English	Article						generative pre-training (GPT); large language models (LLMs); safety-critical software; code generation; prompt engineering		In the digital era of increasing software complexity, improving the development efficiency of safety-critical software is a challenging task faced by academia and industry in domains such as nuclear energy, aviation, the automotive industry, and rail transportation. Recently, people have been excited about using pre-trained large language models (LLMs) such as ChatGPT and GPT-4 to generate code. Professionals in the safety-critical software field are intrigued by the code generation capabilities of LLMs. However, there is currently a lack of systematic case studies in this area. Aiming at the need for automated code generation in safety-critical domains such as nuclear energy and the automotive industry, this paper conducts a case study on generating safety-critical software code using GPT-4 as the tool. Practical engineering cases from the industrial domain are employed. We explore different approaches, including code generation based on overall requirements, specific requirements, and augmented prompts. We propose a novel prompt engineering method called Prompt-FDC that integrates basic functional requirements, domain feature generalization, and domain constraints. This method improves code completeness from achieving 30% functions to 100% functions, increases the code comment rate to 26.3%, and yields better results in terms of code compliance, readability, and maintainability. The code generation approach based on LLMs also introduces a new software development process and V-model lifecycle for safety-critical software. Through systematic case studies, we demonstrate that, with appropriate prompt methods, LLMs can auto-generate safety-critical software code that meets practical engineering application requirements. It is foreseeable that LLMs can be applied to various engineering domains to improve software safety and development efficiency.	[Liu, Mingxing; Wang, Junfeng; Lin, Tao; Fang, Zhiyang; Wu, Yanqun] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China; [Liu, Mingxing; Ma, Quan; Wu, Yanqun] Nucl Power Inst China, Sci & Technol Reactor Syst Design Technol Lab, Chengdu 610041, Peoples R China	Sichuan University	Wang, JF; Lin, T (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.	lmxstar@163.com; wangjf@scu.edu.cn; lintao@scu.edu.cn; maq_np@163.com; fangzhiyang@scu.edu.cn; m15720123548@163.com			National Key Research and Development Program	National Key Research and Development Program	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2011, ISO 26262:2011; [Anonymous], 2006, IEC 60880:2006; anthropic, Anthropic\Claude 2; Arora S, 2022, Arxiv, DOI [arXiv:2210.02441, arXiv:2210.02441]; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen M., 2021, arXiv; Colaco J.-L., 2017, P 2017 INT S THEORET, P1; Cppcheck, A Tool for Static C/C++ Code Analysis; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du N, 2022, PR MACH LEARN RES; Fedus W, 2022, J MACH LEARN RES, V23; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; IEC, 2010, Functional safety of electrical/electronic/programmable electronic safety-related systems-Part 3: Software requirements; Jolak R, 2018, 21ST ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS 2018), P213, DOI 10.1145/3239372.3239404; Jung JH, 2022, Arxiv, DOI arXiv:2205.11822; Koziolek H, 2023, Arxiv, DOI arXiv:2305.15809; Lai Y., 2023, P 40 INT C MACHINE L; Le Sergent Thierry, 2011, SDL 2011: Integrating System and Software Modeling. 15th International SDL Forum. Revised Papers, P2, DOI 10.1007/978-3-642-25264-8_2; Leveson N. G., 2016, ENG SAFER WORLD SYST; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Luo ZY, 2023, Arxiv, DOI [arXiv:2306.08568, 10.48550/arXiv.2306.08568, DOI 10.48550/ARXIV.2306.08568]; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; openai, INTRO CHATGPT; Osaiweran A, 2014, EMPIR SOFTW ENG, V19, P1169, DOI 10.1007/s10664-013-9251-2; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Robustness Testing, What Is It & How to Deliver Reliable Software Systems with Test Automation.; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	41	0	0	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	FEB	2024	14	3							1046	10.3390/app14031046	http://dx.doi.org/10.3390/app14031046			41	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	HN0S5		gold			2024-07-03	WOS:001160071900001
J	Sinha, R; Raina, R; Bag, M; Rupa, B				Sinha, Rooma; Raina, Rohit; Bag, Moumita; Rupa, Bana			Empowering gynaecologists with Artificial Intelligence: Tailoring surgical solutions for fibroids	EUROPEAN JOURNAL OF OBSTETRICS & GYNECOLOGY AND REPRODUCTIVE BIOLOGY			English	Article						Fibroid; Myomectomy; ChatGPT; Artificial intelligence; Google Bard; Large Language Model		Background: In recent years, the integration of Artificial intelligence (AI) into various fields of medicine including Gynaecology, has shown promising potential. Surgical treatment of fibroid is myomectomy if uterine preservation and fertility are the primary aims. AI usage begins with the involvement of LLM (Large Language Model) from the point when a patient visits a gynecologist, from identifying signs and symptoms to reaching a diagnosis, providing treatment plans, and patient counseling. Objective: Use of AI (ChatGPT versus Google Bard) in the surgical management of fibroid. Study design: Identifying the patient's problems using LLMs like ChatGPT and Google Bard and giving a treatment option in 8 clinical scenarios of fibroid. Data entry was done using M.S. Excel and was statistically analyzed using Statistical Package for Social Sciences (SPSS Version 26) for M.S. Windows 2010. All results were presented in tabular form. Data were analyzed using nonparametric tests Chi-square tests or Fisher exact test. p values < 0.05 were considered statistically significant. The sensitivity of both techniques was calculated. We have used Cohen's Kappa to know the degree of agreement. Results: We found that on the first attempt, ChatGPT gave general answers in 62.5 % of cases and specific answers in 37.5 % of cases. ChatGPT showed improved sensitivity on successive prompts 37.5 % to 62.5 % on the third prompt. Google Bard could not identify the clinical question in 50 % of cases and gave incorrect answers in 12.5 % of cases (p = 0.04). Google Bard showed the same sensitivity of 25 % on all prompts. Conclusion: AI helps to reduce the time to diagnose and plan a treatment strategy for fibroid and acts as a powerful tool in the hands of a gynecologist. However, the usage of AI by patients for self-treatment is to be avoided and should be used only for education and counseling about fibroids.	[Sinha, Rooma; Raina, Rohit; Bag, Moumita; Rupa, Bana] Apollo Hlth City, Dept Obstet & Gynaecol, Jubilee Hills, Hyderabad 500033, India		Raina, R (corresponding author), Apollo Hlth City, Dept Obstet & Gynaecol, Jubilee Hills, Hyderabad 500033, India.	rohitraina52@rediffmail.com		RAINA, ROHIT/0009-0001-8807-2433				Ali R, 2023, NEUROSURGERY, V93, P1353, DOI 10.1227/neu.0000000000002632; Ali R, 2023, medRxiv, DOI [10.1101/2023.04.06.23288265, 10.1101/2023.04.06.23288265, DOI 10.1101/2023.04.06.23288265]; Allahqoli L, 2023, GYNECOL OBSTET INVES, V88, P310, DOI 10.1159/000533177; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; Dhombres F, 2022, J MED INTERNET RES, V24, DOI 10.2196/35465; Emin EI, 2019, IN VIVO, V33, P1547, DOI 10.21873/invivo.11635; Javid M, 2023, CAN J UROL, V30, P11588; Kumar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43313; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020	9	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0301-2115	1872-7654		EUR J OBSTET GYN R B	Eur. J. Obstet. Gynecol. Reprod. Biol.	AUG	2024	299						72	77		10.1016/j.ejogrb.2024.06.001	http://dx.doi.org/10.1016/j.ejogrb.2024.06.001			6	Obstetrics & Gynecology; Reproductive Biology	Science Citation Index Expanded (SCI-EXPANDED)	Obstetrics & Gynecology; Reproductive Biology	UZ1G0	38838389				2024-07-03	WOS:001251789000001
C	Daniel, N; Kaiser, FK; Dzega, A; Elyashar, A; Puzis, R		Katsikas, S; Abie, H; Ranise, S; Verderame, L; Cambiaso, E; Ugarelli, R; Praca, I; Li, W; Meng, W; Furnell, S; Katt, B; Pirbhulal, S; Shukla, A; Ianni, M; Preda, MD; Choo, KKR; Correia, MP; Abhishta, A; Sileno, G; Alishahi, M; Kalutarage, H; Yanai, N		Daniel, Nir; Kaiser, Florian Klaus; Dzega, Anton; Elyashar, Aviad; Puzis, Rami			Labeling NIDS Rules with MITRE ATT&CK Techniques Using ChatGPT	COMPUTER SECURITY. ESORICS 2023 INTERNATIONAL WORKSHOPS, CPS4CIP, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	28th European Symposium on Research in Computer Security (ESORICS)	SEP 25-29, 2023	The Hague, NETHERLANDS			Cyber threat intelligence; Alerts investigation; Natural language processing		A typical analyst spends much time and effort investigating alerts from network intrusion detection systems (NIDS). Available NIDS rules for enterprise and industrial control systems are not always accompanied by high-level explanations that allow for building valid hypotheses about the attacker's techniques and intentions. The plethora of rules and the lack of high-level information necessitates new automated methods for alert enrichment. Large language models, such as ChatGPT, encompass a vast amount of knowledge, including cyber threat intelligence such as ports and protocols (low-level) and MITRE ATT&CK techniques (high-level). Despite being a very new technology, ChatGPT is increasingly used in order to automate processes that experts previously performed. In this paper, we explore the ability of ChatGPT to reason about NIDS rules while labeling them with MITRE ATT&CK techniques. We discuss prompt design and present results on ChatGPT-3.5, ChatGPT-4, and a keyword-based approach. Our results indicate that both versions of ChatGPT outperform a baseline that relies on a-priori frequencies of the techniques. ChatGPT-3.5 is much more precise than ChatGPT-4, with a little reduction in recall.	[Daniel, Nir; Dzega, Anton; Puzis, Rami] Ben Gurion Univ Negev, Dept Software & Informat Syst Engn, Beer Sheva, Israel; [Daniel, Nir; Dzega, Anton; Elyashar, Aviad; Puzis, Rami] Ben Gurion Univ Negev, Cyber BGU, Cyber Labs, Beer Sheva, Israel; [Kaiser, Florian Klaus] Karlsruhe Inst Technol, Inst Ind Prod, Karlsruhe, Germany; [Kaiser, Florian Klaus] Karlsruhe Inst Technol, Inst Informat Secur & Dependabil, Karlsruhe, Germany; [Elyashar, Aviad] Shamoon Coll Engn, Dept Comp Sci, Beer Sheva, Israel	Ben Gurion University; Ben Gurion University; Helmholtz Association; Karlsruhe Institute of Technology; Helmholtz Association; Karlsruhe Institute of Technology	Daniel, N (corresponding author), Ben Gurion Univ Negev, Dept Software & Informat Syst Engn, Beer Sheva, Israel.; Daniel, N (corresponding author), Ben Gurion Univ Negev, Cyber BGU, Cyber Labs, Beer Sheva, Israel.	nirdanie@post.bgu.ac.il; florian-klaus.kaiser@kit.edu; dzega@post.bgu.ac.il; aviadel2@ac.sce.ac.il; puzis@bgu.ac.il			U.S.-Israel Energy Center managed by the Israel-U.S. Binational Industrial Research and Development (BIRD) Foundation	U.S.-Israel Energy Center managed by the Israel-U.S. Binational Industrial Research and Development (BIRD) Foundation	Supported by the U.S.-Israel Energy Center managed by the Israel-U.S. Binational Industrial Research and Development (BIRD) Foundation.	[Anonymous], 2010, P INT C WORKSH EM TR, DOI [10.1145/1741906.1741914, DOI 10.1145/1741906.1741914]; Arafune M, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), DOI 10.1109/PerComWorkshops53856.2022.9767375; Bagui SS, 2023, DATA, V8, DOI 10.3390/data8010018; Chismon D, 2015, MWR InfoSecurity Ltd, P36; Daszczyszak R, 2019, Tech. rep; Elitzur Aviad, 2019, 2019 European Intelligence and Security Informatics Conference (EISIC). Proceedings, P40, DOI 10.1109/EISIC49498.2019.9108886; Gjerstad J.L., 2022, Master's thesis; Haddad A., 2023, arXiv; Husari G, 2017, ANN COMPUT SECURITY, P103, DOI 10.1145/3134600.3134646; Kaiser FK, 2023, IEEE T DEPEND SECURE, V20, P4793, DOI 10.1109/TDSC.2022.3233703; Khamphakdee N, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT); Legoy V, 2020, Arxiv, DOI arXiv:2004.14322; Li Z, 2022, LECT NOTES COMPUT SC, V13554, P589, DOI 10.1007/978-3-031-17140-6_29; Liao XJ, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P755, DOI 10.1145/2976749.2978315; Lin SX, 2022, INT CONF ADV COMMUN, P34, DOI 10.23919/ICACT53585.2022.9728949; Long C., 2023, medRxiv; McPhee M, 2020, Tech. Rep.; Mendsaikhan O, 2020, 14 INT C EM SEC INF; Palacin V., 2021, Practical Threat Intelligence and Data-driven Threat Hunting; Rani N, 2023, PROCEEDINGS OF 2023 AUSTRALIAN COMPUTER SCIENCE WEEK, ACSW 2023, P126, DOI 10.1145/3579375.3579391; Satvat K, 2021, 2021 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2021), P598, DOI 10.1109/EuroSP51992.2021.00046; Sentonas M, 2023, Crowdstrike introduces Charlotte AI, generative AI security analyst-crowdstrike; Shackleford D., 2015, Who's Using Cyberthreat Intelligence and How?; Sharma Y, 2023, Arxiv, DOI arXiv:2212.03793; Strom B.E, 2020, MITRE ATT&CK ~ R: Design and philosophy; Tod-Raileanu G, 2023, INT C CYB CYB, V10; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Vulnerabilities C., 2005, Common vulnerabilities and exposures; YingHui Peng, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P116, DOI 10.1109/ICSAI.2012.6223247; You YZ, 2022, CYBERSECURITY, V5, DOI 10.1186/s42400-021-00106-5	30	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-54128-5; 978-3-031-54129-2	LECT NOTES COMPUT SC			2024	14399						76	91		10.1007/978-3-031-54129-2_5	http://dx.doi.org/10.1007/978-3-031-54129-2_5			16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9FB					2024-07-03	WOS:001212380000005
C	Souza, FD; Souza, JBDE		Pinheiro, V; Gamallo, P; Amaro, R; Scarton, C; Batista, F; Silva, D; Magro, C; Pinto, H		Souza, Frederico Dias; de Oliveira e Souza Filho, Joao Baptista			BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives	COMPUTATIONAL PROCESSING OF THE PORTUGUESE LANGUAGE, PROPOR 2022	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	15th International Conference on the Computational Processing of Portuguese (PROPOR)	MAR 21-23, 2022	Univ Fortaleza, ELECTR NETWORK	Americanas Sa	Univ Fortaleza	Sentiment analysis; Natural language processing; Machine learning; Transfer learning; Transformers		BERT has revolutionized the NLP field by enabling transfer learning with large language models that can capture complex textual patterns, reaching the state-of-the-art for an expressive number of NLP applications. For text classification tasks, BERT has already been extensively explored. However, aspects like how to better cope with the different embeddings provided by the BERT output layer and the usage of language-specific instead of multilingual models are not well studied in the literature, especially for the Brazilian Portuguese language. The purpose of this article is to conduct an extensive experimental study regarding different strategies for aggregating the features produced in the BERT output layer, with a focus on the sentiment analysis task. The experiments include BERT models trained with Brazilian Portuguese corpora and the multilingual version, contemplating multiple aggregation strategies and open-source datasets with predefined training, validation, and test partitions to facilitate the reproducibility of the results. BERT achieved the highest ROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless, TF-IDF represents a good trade-off between the predictive performance and computational cost.	[Souza, Frederico Dias; de Oliveira e Souza Filho, Joao Baptista] Univ Fed Rio de Janeiro, Elect Engn Program, Rio De Janeiro, Brazil	Universidade Federal do Rio de Janeiro	Souza, FD; Souza, JBDE (corresponding author), Univ Fed Rio de Janeiro, Elect Engn Program, Rio De Janeiro, Brazil.	fredericodspoli@ufrj.br; jbfilhopoli@ufrj.br	de Oliveira e Souza Filho, João Baptista/M-3384-2017	de Oliveira e Souza Filho, João Baptista/0000-0001-6005-8480; Dias Souza, Frederico/0000-0002-4746-2136				Carmo D, 2020, PTT5 PRETRAINING VAL; Carrico N., 2021, IBERSPEECH 2021, P200; Devlin J., 2018, BERT PRE TRAINING DE; Finardi P, ARXIVABS210112015; Google, 2019, BERT; Hartmann N, 2014, P 9 INT C LANG RES E; Jiang S., 2021, IB LANG EV FOR 2021, P891; Jones Karen Sparck, 1988, A Statistical Interpretation of Term Specificity and Its Application in Retrieval, P132; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Lopes E., 2021, INT FLAIRS C P, V34, DOI [DOI 10.32473/FLAIRS.V34I1.128357, 10.32473/ flairs.v34i1.128357]; Minaee S., 2021, ACM COMPUT SURV, DOI [10.1145/3439726, DOI 10.1145/3439726]; Neto A.M.S.A., 2021, CEUR WORKSHOP P, V2943, P933; Real L., 2019, STIL S INF HUM LANG; Scarton C, 2020, ABS201004543 CORR; Sionek A., 2018, Brazilian e-Commerce Public Dataset by OLIST; Sousa R.F.d., 2019, S INF HUM LANG TECHN; Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28; Souza F, 2021, BRAZILIAN PORTUGUESE; Souza F., 2021, IEEE LAT AM C COMP I; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Vaswani A, 2017, ADV NEUR IN, V30; Wagner JA, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P4339; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang X, 2015, ADV NEUR IN, V28	24	3	3	2	7	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-030-98305-5; 978-3-030-98304-8	LECT NOTES ARTIF INT			2022	13208						209	218		10.1007/978-3-030-98305-5_20	http://dx.doi.org/10.1007/978-3-030-98305-5_20			10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS9YS		Green Submitted			2024-07-03	WOS:000784617700020
J	Necula, SC; Dumitriu, F; Greavu-Serban, V				Necula, Sabina-Cristiana; Dumitriu, Florin; Greavu-Serban, Valerica			A Systematic Literature Review on Using Natural Language Processing in Software Requirements Engineering	ELECTRONICS			English	Review						natural language processing; software requirements engineering; artificial intelligence; thematic mapping; trend analysis; historiograph analysis; automation in software development	CONCEPTUAL MODELS; USER STORIES; EXTRACTION; CLASSIFICATION; IDENTIFICATION; AMBIGUITY; IMPROVE; QUALITY; TOOLS	This systematic literature review examines the integration of natural language processing (NLP) in software requirements engineering (SRE) from 1991 to 2023. Focusing on the enhancement of software requirement processes through technological innovation, this study spans an extensive array of scholarly articles, conference papers, and key journal and conference reports, including data from Scopus, IEEE Xplore, ACM Digital Library, and Clarivate. Our methodology employs both quantitative bibliometric tools, like keyword trend analysis and thematic mapping, and qualitative content analysis to provide a robust synthesis of current trends and future directions. Reported findings underscore the essential roles of advanced computational techniques like machine learning, deep learning, and large language models in refining and automating SRE tasks. This review highlights the progressive adoption of these technologies in response to the increasing complexity of software systems, emphasizing their significant potential to enhance the accuracy and efficiency of requirement engineering practices while also pointing to the challenges of integrating artificial intelligence (AI) and NLP into existing SRE workflows. The systematic exploration of both historical contributions and emerging trends offers new insights into the dynamic interplay between technological advances and their practical applications in SRE.	[Necula, Sabina-Cristiana; Dumitriu, Florin; Greavu-Serban, Valerica] Alexandru Ioan Cuza Univ, Fac Econ & Business Adm, Dept Accounting Business Informat Syst & Stat, Iasi 700506, Romania	Alexandru Ioan Cuza University	Necula, SC; Dumitriu, F; Greavu-Serban, V (corresponding author), Alexandru Ioan Cuza Univ, Fac Econ & Business Adm, Dept Accounting Business Informat Syst & Stat, Iasi 700506, Romania.	sabina.necula@uaic.ro; fdumi@uaic.ro; valy.greavu@feaa.uaic.ro						Abdelnabi E.A., 2021, P 2021 IEEE 1 INT MA, P288, DOI DOI 10.1109/MI-STA52233.2021.9464433; Aceituna D., 2011, 2011 Model-Driven Requirements Engineering Workshop (MoDRE 2011), P1, DOI 10.1109/MoDRE.2011.6045361; Ahmad A, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8830683; Ahmed Mudassar Adeel, 2021, 2021 International Conference on Communication Technologies (ComTech), P39, DOI 10.1109/ComTech52583.2021.9616949; Ahmed S, 2022, 2022 IEEE/ACIS 20TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P112, DOI 10.1109/SERA54885.2022.9806783; Airlangga G, 2022, J INF SCI ENG, V38, P295, DOI 10.6688/JISE.202203_38(2).0002; Akour M, 2016, ADV SCI LETT, V22, P2972, DOI 10.1166/asl.2016.7070; Al Kilani N, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P541, DOI [10.1109/snams.2019.8931820, 10.1109/SNAMS.2019.8931820]; Al-Hroob A, 2018, INFORM SOFTWARE TECH, V101, P1, DOI 10.1016/j.infsof.2018.04.010; AlDhafer O, 2022, INFORM SOFTWARE TECH, V147, DOI 10.1016/j.infsof.2022.106877; Alhoshan W., 2019, CEUR Workshop Proceedings; Alon I, 2018, ASIA PAC J MANAG, V35, P573, DOI 10.1007/s10490-018-9597-5; Altalbe A., 2015, Int. J. Adv. Res. Artif. Intell, V4, P40410, DOI [10.14569/IJARAI.2015.040410, DOI 10.14569/IJARAI.2015.040410]; Arora C, 2017, IEEE T SOFTWARE ENG, V43, P918, DOI 10.1109/TSE.2016.2635134; Asyrofi Rakha, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P332, DOI 10.1109/ISRITI51436.2020.9315489; Bajaj Deepali, 2022, International Journal of Information Technology, V14, P1543, DOI 10.1007/s41870-022-00884-2; Bajceta A., 2022, REFSQ WORKSH; Bajwa I.S., 2009, Object Oriented Software Modeling Using NLP Based Knowledge Extraction; Bakar NH, 2016, APPL SOFT COMPUT, V49, P1297, DOI 10.1016/j.asoc.2016.07.048; Bhatia J, 2016, ACM T SOFTW ENG METH, V25, DOI 10.1145/2907942; Bozyigit F, 2021, ENG SCI TECHNOL, V24, P71, DOI 10.1016/j.jestch.2020.11.006; Bretas VPG, 2021, J BUS RES, V133, P51, DOI 10.1016/j.jbusres.2021.04.067; de Gea JMC, 2016, J SOFTW-EVOL PROC, V28, P205, DOI 10.1002/smr.1772; Cascini G, 2004, LECT NOTES COMPUT SC, V3163, P508; Choi S, 2006, LECT NOTES COMPUT SC, V3999, P12; Chow M.Y., 2023, J. Inf. Process, V31, P143, DOI [10.2197/ipsjjip.31.143, DOI 10.2197/IPSJJIP.31.143]; Corral A, 2022, J UNIVERS COMPUT SCI, V28, P1136, DOI 10.3897/jucs.78776; Dalpiaz F, 2019, INFORM SOFTWARE TECH, V110, P3, DOI 10.1016/j.infsof.2018.12.007; Dar HS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3183411; Dawood O.S., 2018, Eur. J. Eng. Technol. Res, V3, P42, DOI [10.24018/ejeng.2018.3.7.807, DOI 10.24018/EJENG.2018.3.7.807]; Diamantopoulos T, 2017, LANG RESOUR EVAL, V51, P495, DOI 10.1007/s10579-017-9381-z; Ellis-Braithwaite R, 2017, REQUIR ENG, V22, P167, DOI 10.1007/s00766-015-0239-x; Femmer H., 2018, REFSQ WORKSH; Fliedl G, 2007, DATA KNOWL ENG, V61, P433, DOI 10.1016/j.datak.2006.06.012; Geetha S., 2013, IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013), P374; Gupta A., 2019, ARPN J. Eng. Appl. Sci, V14, P3046; Halim F, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEM (ICORIS), P269, DOI [10.1109/icoris.2019.8874888, 10.1109/ICORIS.2019.8874888]; Hochstetter J, 2022, IEEE ACCESS, V10, P41564, DOI 10.1109/ACCESS.2022.3165585; Howarth J., 2024, Explod. Top; Huertas C., 2012, NLARE, a Natural Language Processing Tool for Automatic Requirements Evaluation, P371, DOI [10.1145/2381716.2381786, DOI 10.1145/2381716.2381786]; Husain M.S., 2022, Computational Intelligence in Software Modeling, P107, DOI [10.1515/9783110709247-008, DOI 10.1515/9783110709247-008]; IBM IBM Engineering Requirements Quality Assistant (RQA), 2024, IBM Doc; Imam AT, 2021, INT J ADV COMPUT SC, V12, P174; Javed M, 2021, INFORM SOFTWARE TECH, V135, DOI 10.1016/j.infsof.2021.106558; Jorg T, 2024, INSIGHTS IMAGING, V15, DOI 10.1186/s13244-024-01660-5; Jubair MA, 2022, IET COMMUN, DOI 10.1049/cmu2.12555; Kaur K, 2024, J SOFTW-EVOL PROC, V36, DOI 10.1002/smr.2430; Kersting Joschka, 2022, HCI International 2022 Posters: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, Proceedings. Communications in Computer and Information Science (1580), P419, DOI 10.1007/978-3-031-06417-3_56; Kiyavitskaya N, 2008, REQUIR ENG, V13, P207, DOI 10.1007/s00766-008-0063-7; Kochbati T., 2021, P 33 INT C SOFTW ENG, P285, DOI [10.18293/SEKE2021-056, DOI 10.18293/SEKE2021-056]; Kuchta J, 2018, C HUM SYST INTERACT, P443, DOI 10.1109/HSI.2018.8431221; Kumar Shailender, 2023, 2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA), P1026, DOI 10.1109/ICIRCA57980.2023.10220849; Lafi M, 2021, CMES-COMP MODEL ENG, V127, P99, DOI 10.32604/cmes.2021.013026; Lami G., 2005, QUARS TOOL ANAL REQU; Lethbridge T.C., 2005, OBJECT ORIENTED SOFT; Li CY, 2018, J SYST SOFTWARE, V138, P108, DOI 10.1016/j.jss.2017.12.028; Limaylla-Lunarejo MI, 2023, LECT NOTES COMPUT SC, V13975, P159, DOI 10.1007/978-3-031-29786-1_11; Limaylla-Lunarejo MI, 2022, 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022), P270, DOI 10.1109/RE54965.2022.00039; Liu H, 2022, IEEE T SOFTWARE ENG, V48, P1268, DOI 10.1109/TSE.2020.3018481; Lucassen G, 2017, REQUIR ENG, V22, P339, DOI 10.1007/s00766-017-0270-1; Luo XC, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3560417; Maatuk Abdelsalam M., 2021, DATA'21: International Conference on Data Science, E-learning and Information Systems 2021, P271, DOI 10.1145/3460620.3460768; Pérez-Verdejo JM, 2020, 2020 8TH EDITION OF THE INTERNATIONAL CONFERENCE IN SOFTWARE ENGINEERING RESEARCH AND INNOVATION (CONISOFT 2020), P21, DOI 10.1109/CONISOFT50191.2020.00014; market, 2024, Market.us Global Natural Language Processing Market by Type (Statistical NLP, Rule Based NLP, and Hybrid NLP), by Component (Solution and Services), by Deployment (On-Premises and Cloud), by Application (Sentiment Analysis, Data Extraction, Risk And Threat Detection), by Technology (Interactive Voice Response (IVR), Optical Character Recognition (OCR), Text Analytics), by Enterprise Size (Small and Medium-Sized Enterprises (SMEs) and Large Enterprises), by Industry Vertical (Healthcare, Retail, High Tech and Telecom, BFSI), by Region and Companies-Industry Segment Outlook, Market Assessment, Competition Scenario, Trends and Forecast; Masuda S, 2016, PROCEEDINGS OF THE 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING (ICIME 2016), P12, DOI 10.1145/3012258.3012262; Masuda S, 2016, IEICE T INF SYST, VE99D, P2210, DOI 10.1587/transinf.2015KBP0005; Maulana M.Z.N., 2022, P 2022 6 INT C INF T, P205, DOI [10.1109/ICITISEE57756.2022.10057944, DOI 10.1109/ICITISEE57756.2022.10057944]; May E., 2023, Stackoverflow Blog; McZara J, 2015, EMPIR SOFTW ENG, V20, P1721, DOI 10.1007/s10664-014-9334-8; Mishra S, 2019, 2019 IEEE 27TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2019), P234, DOI 10.1109/REW.2019.00048; Mornie MN, 2023, ACTA INFORM PRAG, V12, P419, DOI 10.18267/j.aip.212; Murugesh S., 2018, International Journal of Reasoning-based Intelligent Systems, V10, P169; Nazir F, 2017, LECT NOTES ELECTR EN, V424, P485, DOI 10.1007/978-981-10-4154-9_56; Neuendorf K. A., 2017, CONTENT ANAL GUIDEBO, DOI [10.4135/9781071802878, DOI 10.4135/9781071802878]; Omar M, 2020, DATA KNOWL ENG, V127, DOI 10.1016/j.datak.2020.101796; Ong ET, 2008, INT J MULTISCALE COM, V6, P39, DOI 10.1615/IntJMultCompEng.v6.i1.40; Osama M, 2020, PROC IEEE INT CONF S, P651, DOI 10.1109/ICSME46990.2020.00067; Oztekin GC, 2023, IEEE ACCESS, V11, P62906, DOI 10.1109/ACCESS.2023.3287882; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Pauzi Z, 2023, J SYST SOFTWARE, V198, DOI 10.1016/j.jss.2023.111616; Pohl K, 2010, REQUIREMENTS ENGINEERING: FUNDAMENTALS, PRINCIPLES, AND TECHNIQUES, P1, DOI 10.1007/978-3-642-12578-2; Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284; Priyadi Y, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEM (ICORIS), P221, DOI [10.1109/ICORIS.2019.8874920, 10.1109/icoris.2019.8874920]; qracorp, 2024, QRA QVscribe; Rago A, 2018, LANG RESOUR EVAL, V52, P801, DOI 10.1007/s10579-017-9406-7; Rahman K, 2023, IEEE ACCESS, V11, P81787, DOI 10.1109/ACCESS.2023.3301725; Ramesh MRR, 2021, COMPUT ELECTR ENG, V96, DOI 10.1016/j.compeleceng.2021.107445; Riaz MQ, 2019, 5TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2019), P1, DOI [10.1109/INFOMAN.2019.8714682, 10.1109/infoman.2019.8714682]; Rossanez A, 2016, LAT-AM SYMP DEP COMP, P123, DOI 10.1109/LADC.2016.26; Sanjanasri J, 2022, IEEE ACCESS, V10, P117707, DOI 10.1109/ACCESS.2022.3217752; Shehadeh Karmel, 2021, 2021 International Conference on Information Technology (ICIT), P527, DOI 10.1109/ICIT52682.2021.9491698; Sholiq S, 2022, J KING SAUD UNIV-COM, V34, P10079, DOI 10.1016/j.jksuci.2022.10.007; Shreda Q. A., 2021, IEEE Access, V4, P1, DOI [10.1109/ACCESS.2021.3052921, DOI 10.1109/ACCESS.2021.3052921]; Singh M, 2017, 2017 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND DATA SCIENCE (MLDS 2017), P128, DOI 10.1109/MLDS.2017.16; Sinkie M, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12183955; Sonbol R, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108933; Subha R., 2013, Communications in Computer and Information Science, P131, DOI [10.1007/978-3-642-36321-412, DOI 10.1007/978-3-642-36321-412]; Talele P, 2023, INT J EL COMP ENG SY, V14, P1107; Tiwari S, 2020, INT REQUIR ENG CONF, P410, DOI 10.1109/RE48521.2020.00059; Tizard J, 2023, IEEE T SOFTWARE ENG, V49, P2381, DOI 10.1109/TSE.2022.3219458; Verma K, 2014, SEMANT WEB, V5, P405, DOI 10.3233/SW-2012-0071; Vlas RE, 2012, J MANAGE INFORM SYST, V28, P11, DOI 10.2753/MIS0742-1222280402; Wakabayashi T., 2020, J. Inf. Process, V28, P136, DOI [10.2197/ipsjjip.28.136, DOI 10.2197/IPSJJIP.28.136]; Wang YL, 2016, PR IEEE I C PROGR IN, P636, DOI 10.1109/PIC.2016.7949577; Wein S, 2021, AEROSP CONF PROC, DOI 10.1109/AERO50100.2021.9438170; Wong MF, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25060888; Yalla P., 2015, Int. J. Softw. Eng. Its Appl, V9, P127, DOI DOI 10.14257/IJSEIA.2015.9.11.12; Younas M, 2020, NEURAL COMPUT APPL, V32, P7383, DOI 10.1007/s00521-019-04226-5; Zolotas C, 2017, AUTOMAT SOFTW ENG, V24, P791, DOI 10.1007/s10515-016-0206-x; Zupic I, 2015, ORGAN RES METHODS, V18, P429, DOI 10.1177/1094428114562629	110	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2055	10.3390/electronics13112055	http://dx.doi.org/10.3390/electronics13112055			29	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UA1C9		gold			2024-07-03	WOS:001245241500001
J	Park, C; Lee, J; Son, S; Park, K; Jang, J; Lim, H				Park, Chanjun; Lee, Jungseob; Son, Suhyune; Park, Kinam; Jang, Jungsun; Lim, Heuiseok			Analysis of the Effectiveness of Model, Data, and User-Centric Approaches for Chat Application: A Case Study of BlenderBot 2.0	APPLIED SCIENCES-BASEL			English	Article						BlendorBot; chatbot; dialogue; deep learning; natural language processing		BlenderBot 2.0 represents a significant advancement in open-domain chatbots by incorporating real-time information and retaining user information across multiple sessions through an internet search module. Despite its innovations, there are still areas for improvement. This paper examines BlenderBot 2.0's limitations and errors from three perspectives: model, data, and user interaction. From the data perspective, we highlight the challenges associated with the crowdsourcing process, including unclear guidelines for workers, insufficient measures for filtering hate speech, and the lack of a robust process for verifying the accuracy of internet-sourced information. From the user perspective, we identify nine types of limitations and conduct a thorough investigation into their causes. For each perspective, we propose practical methods for improvement and discuss potential directions for future research. Additionally, we extend our analysis to include perspectives in the era of large language models (LLMs), further broadening our understanding of the challenges and opportunities present in current AI technologies. This multifaceted analysis not only sheds light on BlenderBot 2.0's current limitations but also charts a path forward for the development of more sophisticated and reliable open-domain chatbots within the broader context of LLM advancements.	[Park, Chanjun] Upstage, Yongin 16942, South Korea; [Lee, Jungseob; Son, Suhyune; Lim, Heuiseok] Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea; [Park, Kinam] Korea Univ, Human Inspired AI Res, 145 Anam Ro, Seoul 02841, South Korea; [Jang, Jungsun] Korea Univ, Dept Korean Hist, Seoul 02841, South Korea	Korea University; Korea University; Korea University	Lim, H (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea.; Jang, J (corresponding author), Korea Univ, Dept Korean Hist, Seoul 02841, South Korea.	chanjun.park@upstage.ai; omanma1928@korea.ac.kr; ssh5131@korea.ac.kr; spknn@korea.ac.kr; empyrean@korea.ac.kr; limhseok@korea.ac.kr			National Research Foundation of Korea	National Research Foundation of Korea(National Research Foundation of Korea)	This work is the extended version of our papers [36,37]. Chanjun Park, Jungseob Lee, and Suhyune Son contributed equally to this work.	Achiam J., 2023, GPT-4 Technical Report; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bao SQ, 2021, Arxiv, DOI arXiv:2006.16779; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Dinan E, 2019, Arxiv, DOI arXiv:1811.01241; Fong T, 2003, SPR TRA ADV ROBOT, V6, P255; Herzig J, 2020, Arxiv, DOI arXiv:2004.02349; Humeau S., 2019, Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring, DOI DOI 10.48550/ARXIV.1905.01969; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jurafsky D., 2021, SPEECH LANGUAGE PROC; Karma Choedak K., 2020, Master Thesis; Kim B, 2020, Arxiv, DOI arXiv:2002.07510; Kim D, 2024, Arxiv, DOI [arXiv:2312.15166, 10.48550/arXiv.2312.15166]; Kim H, 2024, Arxiv, DOI arXiv:2404.03887; Komeili M, 2021, Arxiv, DOI [arXiv:2107.07566, 10.48550/ARXIV.2107.07566, DOI 10.48550/ARXIV.2107.07566]; Lee C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11051974; Lee JS, 2022, Arxiv, DOI arXiv:2201.03239; Mesnard T., 2024, arXiv; Smith EM, 2020, Arxiv, DOI arXiv:2004.08449; Park Chan-Jun, 2021, [Journal of the Korea Convergence Society, 한국융합학회논문지], V12, P23; Park C, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P97; Park C, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, P106; Park H, 2024, Arxiv, DOI arXiv:2403.19340; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rashkin H, 2019, Arxiv, DOI arXiv:1811.00207; Roller S, 2020, Arxiv, DOI arXiv:2004.13637; Song HY, 2019, Arxiv, DOI arXiv:1905.12188; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Xu J, 2021, Arxiv, DOI arXiv:2010.07079; Xu J, 2021, Arxiv, DOI [arXiv:2107.07567, 10.48550/ARXIV.2107.07567, DOI 10.48550/ARXIV.2107.07567]; YiJungseob, 2021, [Journal of the Korea Convergence Society, 한국융합학회논문지], V12, P93, DOI 10.15207/JKCS.2021.12.12.093; Yin PC, 2020, Arxiv, DOI arXiv:2005.08314; Zhang SZ, 2018, Arxiv, DOI arXiv:1801.07243; Zhong PX, 2020, Arxiv, DOI arXiv:2004.12316; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]	37	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	JUN	2024	14	11							4821	10.3390/app14114821	http://dx.doi.org/10.3390/app14114821			17	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	UC0T6		gold			2024-07-03	WOS:001245752400001
J	Caswell, D				Caswell, David			Audiences, automation, and AI: From structured news to language models	AI MAGAZINE			English	Article								The appearance of large language models (LLMs) and other forms of generative AI portend a new era of disruption and innovation for the news industry, this time focused on the production and consumption of news rather than on its distribution. Large news organizations, however, may be surprisingly well-prepared for at least some of this disruption because of earlier innovation work on automating workflows for personalized content and formats using structured techniques. This article reviews this work and uses examples from the British Broadcasting Corporation (BBC) and other large news providers to show how LLMs have recently been successfully applied to addressing significant barriers to the deployment of structured approaches in production, and how innovation using structured techniques has more generally framed significant editorial and product challenges that might now be more readily addressed using generative AI. Using the BBC's next-generation authoring and publishing stack as an example, the article also discusses how earlier innovation work has influenced the design of flexible infrastructure that can accommodate uncertainty in audience behavior and editorial workflows - capabilities that are likely to be well suited to the fast-approaching AI-mediated news ecosystem.	[Caswell, David] Story Flow Ltd, BBC News Labs, London, England		Caswell, D (corresponding author), Story Flow Ltd, BBC News Labs, London, England.	david@structuredstories.com		Caswell, David/0009-0007-9845-6709				Adams G., 2023, ARXIV; Amico C., 2013, REUTERS BETS BIG CON; Anderson CW, 2015, DIGIT JOURNAL, V3, P349, DOI 10.1080/21670811.2014.976407; Anderson Chris., 2014, Post-Industrial Journalism; Armstrong M., 2020, SMPTE MOTION IMAG J, V129, P30, DOI [10.5594/JMI.2020.2990255, DOI 10.5594/JMI.2020.2990255]; BBC Academy, 2023, INTR OPT; BBC News Labs, 2023, PROJ; BBC News Labs, 2015, BBC NEWS LABS; Bliss Edward., 1991, Now the News: The Story of Broadcast Journalism; British Broadcasting Corporation, 2017, ROYAL CHART AGR ART; Caswell D., 2019, INT ENCY JOURNALISM, DOI DOI 10.1002/9781118841570.IEJS0046; Caswell D., 2021, ALGORITHMS AUTOMATIO; Chua G., 2010, MOL NEWS RE STRUCTUR; Coddington M, 2015, DIGIT JOURNAL, V3, P331, DOI 10.1080/21670811.2014.976400; Danzon-Chambaud S., 2021, AUTOMATED NEWS BBC; Gahran A., 2011, LEGO APPROACH STORYT; Gourarie Chava., 2015, COLUMBIA JOURNAL REV; Graefe A., 2016, GUIDE AUTOMATED JOUR; Harrower T., 2012, INSIDE REPORTING PRA; Levy S., 2023, WIRED; Macgregor M., 2021, RESPONSIBLE AI BBC O; Mitte E., 2023, M DOPFNER ROLE AI JO; Newman N., 2022, Journalism, media, and technology trends and predictions 2022; Pavlik J.V., 2021, Disruption and digital journalism: Assessing news media innovation in a time of dramatic change; Pettegree Andrew., 2014, The Invention of the News: How the World Came to Know About Itself; Tarling J., 2014, STORYLINES DATA BBC; Thäsler-Kordonouri S, 2023, JOURNAL PRACT, DOI 10.1080/17512786.2023.2184413; Zachrison O., 2020, ALGORITHM EMPOWERING	28	0	0	8	8	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602	2371-9621		AI MAG	AI Mag.	JUN	2024	45	2			SI		174	186		10.1002/aaai.12168	http://dx.doi.org/10.1002/aaai.12168		APR 2024	13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	US6A3		hybrid			2024-07-03	WOS:001197152000001
J	Qian, JL; Du, YY; Liang, FY; Yi, JW; Wang, N; Tu, WN; Huang, S; Pei, T; Ma, T				Qian, Jiale; Du, Yunyan; Liang, Fuyuan; Yi, Jiawei; Wang, Nan; Tu, Wenna; Huang, Sheng; Pei, Tao; Ma, Ting			Quantifying Urban Linguistic Diversity Related to Rainfall and Flood across China with Social Media Data	ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION			English	Article						linguistic diversity; flood; rainfall; social media; Chinese dialects; bias	LANGUAGE; TWEETS	Understanding the public's diverse linguistic expressions about rainfall and flood provides a basis for flood disaster studies and enhances linguistic and cultural awareness. However, existing research tends to overlook linguistic complexity, potentially leading to bias. In this study, we introduce a novel algorithm capturing rainfall and flood-related expressions, considering the relationship between precipitation observations and linguistics expressions. Analyzing 210 million social media microblogs from 2017, we identified 594 keywords, 20 times more than usual manually created bag-of-words. Utilizing Large Language Model, we categorized these keywords into rainfall, flood, and other related terms. Semantic features of these keywords were analyzed from the viewpoint of popularity, credibility, time delay, and part-of-speech, finding rainfall-related terms most common-used, flood-related keywords often more time delayed than precipitation, and notable differences in part-of-speech across categories. We also assessed spatial characteristics from keyword and city-centric perspectives, revealing that 49.5% of the keywords have significant spatial correlation with differing median centers, reflecting regional variations. Large and disaster-impacted cities show the richest expression diversity for rainfall and flood-related terms.	[Qian, Jiale; Du, Yunyan; Liang, Fuyuan; Yi, Jiawei; Wang, Nan; Tu, Wenna; Huang, Sheng; Pei, Tao; Ma, Ting] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China; [Qian, Jiale; Du, Yunyan; Yi, Jiawei; Wang, Nan; Tu, Wenna; Huang, Sheng; Pei, Tao; Ma, Ting] Univ Chinese Acad Sci, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Institute of Geographic Sciences & Natural Resources Research, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Du, YY (corresponding author), Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, State Key Lab Resources & Environm Informat Syst, Beijing 100101, Peoples R China.; Du, YY (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.	qianjl@lreis.ac.cn; duyy@lreis.ac.cn		Ma, Ting/0000-0002-4362-9330; qian, jiale/0000-0002-6677-0820; Huang, Sheng/0000-0001-5900-627X; Pei, Tao/0000-0002-5311-8761	Key Project of Innovation LREIS	Key Project of Innovation LREIS	No Statement Available	Anselin L, 2022, GEOGR ANAL, V54, P429, DOI 10.1111/gean.12339; Baldwin D. A., 2014, Joint attention: Its origins and role in development, P131; Bernal G, 2009, PROF PSYCHOL-RES PR, V40, P361, DOI 10.1037/a0016401; Blodgett S.L., 2016, arXiv; Bonnett A, 2021, MULTIRACISM RETHINKI; Borden J, 2020, J CONTING CRISIS MAN, V28, P281, DOI 10.1111/1468-5973.12308; Bromham L, 2022, NAT ECOL EVOL, V6, P163, DOI 10.1038/s41559-021-01604-y; Buhler K., 1990, THEORY LANGUAGE REPR; Burke M, 2015, NATURE, V527, P235, DOI 10.1038/nature15725; Crawford T, 2021, INT J DISAST RISK RE, V63, DOI 10.1016/j.ijdrr.2021.102430; de Bruijn JA, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0326-9; DeFrancis John., 1986, The Chinese Language: Fact and Fantasy; Del Gratta R, 2021, LANG RESOUR EVAL, V55, P259, DOI 10.1007/s10579-020-09520-6; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; El Ayadi N, 2022, SOC CULT GEOGR, V23, P227, DOI 10.1080/14649365.2019.1707861; Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X; Feng Y, 2022, COMPUT ENVIRON URBAN, V93, DOI 10.1016/j.compenvurbsys.2022.101759; Florax R.J.G.M., 1995, New directions in spatial econometrics. Advances in Spatial Science, P111, DOI DOI 10.1007/978-3-642-79877-1_5; Fu C, 2018, COMPUT ENVIRON URBAN, V72, P25, DOI 10.1016/j.compenvurbsys.2018.07.003; Gembris D, 2000, MAGN RESON MED, V43, P259, DOI 10.1002/(SICI)1522-2594(200002)43:2<259::AID-MRM13>3.0.CO;2-P; Gnach A., 2022, Digital Communication and Media Linguistics; Gorenflo LJ, 2012, P NATL ACAD SCI USA, V109, P8032, DOI 10.1073/pnas.1117511109; Hauerwas LB, 2023, TEACH TEACH EDUC, V123, DOI 10.1016/j.tate.2022.103974; Huang QY, 2015, ISPRS INT J GEO-INF, V4, P1549, DOI 10.3390/ijgi4031549; Huang S, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14051269; Huang Y, 2016, COMPUT ENVIRON URBAN, V59, P244, DOI 10.1016/j.compenvurbsys.2015.12.003; Kelejian HH, 2001, J ECONOMETRICS, V104, P219; Kruspe A, 2021, NAT HAZARD EARTH SYS, V21, P1825, DOI 10.5194/nhess-21-1825-2021; Kwak YJ, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6070203; Leeman J, 2009, J SOCIOLING, V13, P332, DOI 10.1111/j.1467-9841.2009.00409.x; Li LY, 2020, INT J DISAST RISK RE, V51, DOI 10.1016/j.ijdrr.2020.101776; Li WW, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12030112; Liu Q, 2022, J CURRICULUM STUD, V54, P687, DOI 10.1080/00220272.2022.2045361; Liu Z, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182091; Jimenez-Marquez JL, 2019, INT J INFORM MANAGE, V44, P1, DOI 10.1016/j.ijinfomgt.2018.09.003; Lyons John., 1981, LANGUAGE LINGUISTICS; MacPhee D, 2021, READ RES QUART, V56, pS145, DOI 10.1002/rrq.384; Maican MA, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020781; Martin J. H., 2011, P INT AAAI C WEB SOC, P385; Moore FC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13935-3; Muñoz DF, 2020, WATER RESOUR RES, V56, DOI 10.1029/2020WR027544; Nestle Marion., 2015, SODA POLITICS TAKING; O'Brien S, 2018, INT J DISAST RISK RE, V31, P627, DOI 10.1016/j.ijdrr.2018.07.006; OXFORD R, 1989, MOD LANG J, V73, P291, DOI 10.2307/327003; Peng SC, 2017, IEEE NETWORK, V31, P11, DOI 10.1109/MNET.2016.1500104NM; Pennycook A., 2015, METROLINGUALISM LANG; Pomeroy J., 2020, Cities of Opportunities: Connecting Culture and Innovation; Qian JL, 2023, NAT HAZARD EARTH SYS, V23, P317, DOI 10.5194/nhess-23-317-2023; Qian JL, 2022, SUSTAIN CITIES SOC, V87, DOI 10.1016/j.scs.2022.104213; Rachunok B, 2021, INT J DISAST RISK RE, V59, DOI 10.1016/j.ijdrr.2021.102236; Rashid A., 2023, Pak. J. Linguist, V5, P40; RENFREW C, 1994, SCI AM, V270, P116, DOI 10.1038/scientificamerican0194-116; Sadat F., 2014, Proceedings of the First International Workshop on Social Media Retrieval and Analysis, P35; Said N, 2020, Arxiv, DOI arXiv:2011.14943; Son J, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102176; Songchon C, 2021, COMPUT ENVIRON URBAN, V90, DOI 10.1016/j.compenvurbsys.2021.101690; Tomasello M., 2010, ORIGINS HUMAN COMMUN; Tse YK, 2016, IND MANAGE DATA SYST, V116, P1178, DOI 10.1108/IMDS-10-2015-0417; Turk F. J., 2020, Satellite Precipitation Measurement, DOI [10.1007/978-3-030-35798-6, DOI 10.1007/978-3-030-35798-6]; Uekusa S, 2020, INT J DISAST RISK RE, V48, DOI 10.1016/j.ijdrr.2010.101625; Vaisanen T, 2022, COMPUT ENVIRON URBAN, V97, DOI 10.1016/j.compenvurbsys.2022.101857; Vaux B., 2004, Let's Go USA; Wang B, 2020, CITIES, V106, DOI 10.1016/j.cities.2020.102884; Wang N, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214629; Wang WJ, 2020, LAND USE POLICY, V95, DOI 10.1016/j.landusepol.2019.104354; Wang XW, 2020, INF DISCOV DELIV, V48, P213, DOI 10.1108/IDD-10-2019-0075; Wang XY, 2022, DISCOURSE COMMUN, V16, P716, DOI 10.1177/17504813221109090; Warschauer M., 2002, J COMPUT-MEDIAT COMM, V7, DOI [10.1111/j.1083-6101.2002.tb00157.x, DOI 10.1111/J.1083-6101.2002.TB00157.X]; Weigel R, 2004, STEREOT FUNCT NEUROS, V82, P115, DOI 10.1159/000079843; Wisner Ben, 2010, Int Soc Sci J, V61, P131, DOI 10.1111/j.1468-2451.2010.01752.x; Wohl E.E., 2000, INLAND FLOOD HAZARDS; Yan Y, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6050144; Yi JW, 2019, NAT HAZARD EARTH SYS, V19, P2169, DOI 10.5194/nhess-19-2169-2019; Yuan FX, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2020.102289; Zade Himanshu, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274464	75	0	0	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2220-9964		ISPRS INT J GEO-INF	ISPRS Int. J. Geo-Inf.	MAR	2024	13	3							92	10.3390/ijgi13030092	http://dx.doi.org/10.3390/ijgi13030092			19	Computer Science, Information Systems; Geography, Physical; Remote Sensing	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Physical Geography; Remote Sensing	MG4B1		gold			2024-07-03	WOS:001192448600001
J	Datta, PM; Zahn, BJ; Salierno, G; Battisti, D; Attias, L; Bertè, R; Acton, T				Datta, Pratim Milton; Zahn, Brian J.; Salierno, Giulio; Battisti, Daniela; Attias, Luca; Berte, Rosamaria; Acton, Thomas			GiusBERTo: Italy's AI-Based Judicial Transformation: A Case	COMMUNICATIONS OF THE ASSOCIATION FOR INFORMATION SYSTEMS			English	Article						AI; BERT; GPT; Transformer Models; Italy; eGovernment; Public Administration; Digital Transformation		In an age when open access to law enforcement files and judicial documents can erode individual privacy and confidentiality, miscreants can abuse this open access to personal information for blackmail, misinformation, and even social engineering. Yet, limiting access to law enforcement and court cases is a freedom-of-information violation.To address this tension, this collaborative action-research-based teaching case exemplifies how Italy's Corte dei Conti (Court of Auditors) used artificial intelligence in the automated deidentification and anonymization of court documents in Italy's public sector.This teaching case is aimed at undergraduate and graduate students learning about Artificial Intelligence (AI), Large Language Model (LLM) (e.g., ChatGPT) evolution, development, and operations. The case will help students learn the origin and evolution of AI transformer models and architectures, and discusses the GiusBERTo operation and process, highlighting opportunities and challenges. GiusBERTo, Italy's custom-AI model, offers an innovative approach that walks a tightrope between anonymizing Italy's judicial court documents without sacrificing context or information loss. The case ends with a series of questions, challenges, and potential for LLMs in data anonymization.	[Datta, Pratim Milton] Kent State Univ, ISBA, Ambassador Crawford Coll Business, Kent, OH 44240 USA; [Datta, Pratim Milton] Univ Johannesburg, Auckland Pk, Gauteng, South Africa; [Zahn, Brian J.] Kent State Univ, Ambassador Crawford Coll Business, Kent, OH USA; [Salierno, Giulio; Attias, Luca; Berte, Rosamaria] Univ Roma Tre, Dept Polit Sci, Rome, Italy; [Battisti, Daniela] Govt Italy, Dept Digital Transformat, Presidency Council Minist, Rome, Italy; [Acton, Thomas] Univ Galway, JE Cairnes Sch Business & Econ, Business Informat Syst Group, Galway, Ireland	University System of Ohio; Kent State University; Kent State University Kent; Kent State University Salem; University of Johannesburg; University System of Ohio; Kent State University; Kent State University Salem; Kent State University Kent; Roma Tre University; Ollscoil na Gaillimhe-University of Galway	Datta, PM (corresponding author), Kent State Univ, ISBA, Ambassador Crawford Coll Business, Kent, OH 44240 USA.; Datta, PM (corresponding author), Univ Johannesburg, Auckland Pk, Gauteng, South Africa.	pdatta@kent.edu; bzahn1@kent.edu; salierno.g92@gmail.com; daniela.battisti@teamdigitale.governo.it; luca.attias@uniroma3.it; rosamaria.berte@gmail.com; thomas.acton@universityofgalway.ie						[Anonymous], 2023, The Economist; Datta Pratim, 2023, Journal of Information Technology Teaching Cases, P2, DOI 10.1177/20438869211056938; Datta Pratim, 2022, Journal of Information Technology Teaching Cases, P115, DOI 10.1177/2043886921993126; Datta Pratim, 2021, ACM Digital Threats: Research Practice, V2, DOI 10.1145/3428157; Datta Pratim, 2020, Journal of Information Technology Teaching Cases, V10, P54, DOI 10.1177/2043886920910437; Datta P., 2022, Journal of Information Technology Teaching Cases, P1; Datta P, 2020, COMMUN ASSOC INF SYS, V46, P252, DOI 10.17705/1CAIS.04611; Deuber D., 2023, USENIX SECURITY C; Glaser Ingo, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P205, DOI 10.1145/3462757.3466087; Google, Google ReCAPTCHA: Tough on bots, easy on humans; Kang C., 2023, The New York Times; Susarl A, 2023, INFORM SYST RES, V34, P399, DOI 10.1287/isre.2023.ed.v34.n2; Vaswani A, 2017, ADV NEUR IN, V30; Venkatesha Sushruth, 2021, SN Comput Sci, V2, P78, DOI 10.1007/s42979-020-00443-1; Vial G, 2023, INFORM SYST J, V33, P669, DOI 10.1111/isj.12420	15	0	0	13	13	ASSOC INFORMATION SYSTEMS	ATLANTA	GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA	1529-3181			COMMUN ASSOC INF SYS	Commun. Assoc. Inf. Syst.		2023	53						751	766		10.17705/1CAIS.05331	http://dx.doi.org/10.17705/1CAIS.05331			18	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	Z1IL5		Bronze			2024-07-03	WOS:001109688600004
C	Loukas, L; Stogiannidis, I; Diamantopoulos, O; Malakasiotis, P; Vassos, S			ACM	Loukas, Lefteris; Stogiannidis, Ilias; Diamantopoulos, Odysseas; Malakasiotis, Prodromos; Vassos, Stavros			Making LLMsWorth Every Penny: Resource-Limited Text Classification in Banking	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		LLMs; OpenAI; GPT; Anthropic; Claude; Cohere; Few-shot; NLP		Standard Full-Data classifiers in NLP demand thousands of labeled examples, which is impractical in data-limited domains. Fewshot methods offer an alternative, utilizing contrastive learning techniques that can be effective with as little as 20 examples per class. Similarly, Large Language Models (LLMs) like GPT-4 can perform effectively with just 1-5 examples per class. However, the performance-cost trade-offs of these methods remain under-explored, a critical concern for budget-limited organizations. Our work addresses this gap by studying the aforementioned approaches over the Banking77 financial intent detection dataset, including the evaluation of cutting-edge LLMs by OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We complete the picture with two additional methods: first, a cost-effective querying method for LLMs based on retrieval-augmented generation (RAG), able to reduce operational costs multiple times compared to classic few-shot approaches, and second, a data augmentation method using GPT-4, able to improve performance in data-limited scenarios. Finally, to inspire future research, we provide a human expert's curated subset of Banking77, along with extensive error analysis.	[Loukas, Lefteris; Stogiannidis, Ilias; Diamantopoulos, Odysseas; Vassos, Stavros] Helvia Ai, Athens, Greece; [Loukas, Lefteris; Stogiannidis, Ilias; Diamantopoulos, Odysseas; Malakasiotis, Prodromos] Athens Univ Econ & Business, Dept Informat, Athens, Greece	Athens University of Economics & Business	Loukas, L (corresponding author), Helvia Ai, Athens, Greece.; Loukas, L (corresponding author), Athens Univ Econ & Business, Dept Informat, Athens, Greece.	lefteris.loukas@helvia.ai; ilias.stogiannidis@helvia.ai; odysseas.diamantopoulos@helvia.ai; stavros@helvia.ai	Vassos, Stavros/H-6961-2016	Loukas, Lefteris/0000-0002-7473-9428; Malakasiotis, Prodromos/0009-0008-0055-5598; Stogiannidis, Ilias - Marios/0009-0005-5803-1138	European Union [101021714]	European Union(European Union (EU))	This work has received funding from European Union's Horizon 2020 research and innovation programme under grant agreement No 101021714 ("LAW GAME"). Also, we would like to sincerely thank the Hellenic Artificial Intelligence Society (EETN) for their sponsorship.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Bergstra J., 2011, Adv. Neural Inf. Process. Syst., P2546; Braun D, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P174; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Casanueva I, 2020, NLP FOR CONVERSATIONAL AI, P38; Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169; Chalkidis I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7503; Chen T, 2020, PR MACH LEARN RES, V119; Christiano PF, 2017, ADV NEUR IN, V30; Coucke A, 2018, Arxiv, DOI arXiv:1805.10190; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dodge J, 2020, Arxiv, DOI [arXiv:2002.06305, 10.48550/arXiv.2002.06305]; Gauthier-melancon Gabrielle, 2022, P 2022 C EMP METH NA, P298; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Institute of Electrical and Electronics Engineers (IEEE), 2019, 2019 2 WORKSH EN EFF, DOI DOI 10.1109/EMC249363.2019; Jia ML, 2022, LECT NOTES COMPUT SC, V13693, P709, DOI 10.1007/978-3-031-19827-4_41; Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1311; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Lewis Patrick, 2020, (NIPS' 20; Li Xianzhi, 2022, P 4 WORKSH FIN TECHN, P68; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Liu Xingkun, 2021, Benchmarking Natural Language Understanding Services for Building Conversational Agents, P165, DOI 10.1007/978-981-15-9323-9_15; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loukas L., 2023, P 5 WORKSHOP FINANCI, P74; Loukas L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4419; Loukas Lefteris, 2021, P 3 WORKSHOP EC NATU, P13; Mehri S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2979; Northcutt CG, 2021, J ARTIF INTELL RES, V70, P1373; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Razeghi Yasaman., 2022, FINDINGS ASS COMPUTA, P840, DOI 10.18653/v1/2022.findings-emnlp.59; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Sahu G, 2022, PROCEEDINGS OF THE 4TH WORKSHOP ON NLP FOR CONVERSATIONAL AI, P47; Song Kaitao, 2020, NIPS'20); Stogiannidis Ilias, 2023, FIND C EMP METH NAT; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tunstall L, 2022, Arxiv, DOI [arXiv:2209.11055, 10.48550/arXiv.2209.11055, DOI 10.48550/ARXIV.2209.11055]; Vaswani A, 2017, ADV NEUR IN, V30; Webson A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2300; Wei Jason, 2022, ADV NEURAL INFORM PR; Yang Z., 2019, NIPS, V32, P1; Ying C, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), P139; Yoo KM, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2225; Zavitsanos E, 2021, ICAIF 2021: THE SECOND ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, DOI 10.1145/3490354.3494453	47	1	1	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							392	400		10.1145/3604237.3626891	http://dx.doi.org/10.1145/3604237.3626891			9	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		Green Submitted			2024-07-03	WOS:001124982700046
C	Yu, P; Wang, TL; Golovneva, O; AlKhamissi, B; Verma, S; Jin, ZJ; Ghosh, G; Diab, M; Celikyilmaz, A		Rogers, A; Boyd-Graber, J; Okazaki, N		Yu, Ping; Wang, Tianlu; Golovneva, Olga; AlKhamissi, Badr; Verma, Siddharth; Jin, Zhijing; Ghosh, Gargi; Diab, Mona; Celikyilmaz, Asli			ALERT: Adapting Language Models to Reasoning Tasks	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Recent advancements in large language models have enabled them to perform well on complex tasks that require step-by-step reasoning with few-shot learning. However, it is unclear whether these models are applying reasoning skills they have learned during pre-training, or if they are simply memorizing their training corpus at finer granularity and have learned to better understand their context. To address this question, we introduce ALERT, a benchmark and suite of analyses for evaluating reasoning skills of language models. ALERT enables comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve them. Our benchmark provides a test bed to assess any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. To prove the efficacy of ALERT we investigate the role of finetuning. Our extensive empirical analysis shows that language models acquire reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage. Another finding is when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models resulting in generalization problems.	[Yu, Ping; Wang, Tianlu; Golovneva, Olga; AlKhamissi, Badr; Verma, Siddharth; Jin, Zhijing; Ghosh, Gargi; Diab, Mona; Celikyilmaz, Asli] Meta AI, New York, NY 10001 USA		Yu, P; Celikyilmaz, A (corresponding author), Meta AI, New York, NY 10001 USA.	pingyu@meta.com; aslic@meta.com						Aggarwal S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3050; AlKhamissi Badr, 2023, ARXIV230512001; [Anonymous], CoRR; Artetxe M., 2021, ARXIV211210684; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Camburu OM, 2018, ADV NEUR IN, V31; Chen Zeming, 2022, ARXIV220406283; Chowdhery A., 2022, ARXIV220402311; Chung Hyung Won, 2022, ARXIV221011416; Cobbe K., 2021, ARXIV211014168; Fu Yao, 2022, ARXIV221000720; Fulda N., 2017, PMLR, P525; Gao Leo, 2020, ARXIV210100027; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Golovneva Olga, 2022, Roscoe: A suite of metrics for scoring step-by-step reasoning; Gururangan Suchin, 2020, ARXIV200410964; Hendrycks Dan, 2021, ARXIV210303874; Hendrycks Dan., 2020, arXiv preprint arXiv:2009.03300; Hendrycks Dan, 2021, Proc. Int. Conf. Learn Represent ICLR; Hendrycks Dan, 2021, NeurIPS; Hopkins Mark, 2019, P 13 INT WORKSH SEM, P893, DOI [10.18653/v1/S19-2153, DOI 10.18653/V1/S19-2153]; Iyer Srinivasan, 2022, ARXIV221212017; Keysers Daniel, 2019, INT C LEARN REPR; Kim N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9087; Kingma D. P., 2017, ARXIV; Kobbe J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P50; Kojima Takeshi, 2022, arXiv preprint arXiv:2205.11916; Kondadadi R, 2022, PROCEEDINGS OF THE 5TH WORKSHOP ON E-COMMERCE AND NLP (ECNLP 5), P29; Lake B, 2018, PR MACH LEARN RES, V80; Lal YK, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P596; Lin BY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1823; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877; Ling W, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P158, DOI 10.18653/v1/P17-1015; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Loshchilov I., 2017, ARXIV; Meng HF, 2020, CHIN AUTOM CONGR, P5736, DOI 10.1109/CAC51589.2020.9326788; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Mostafazadeh Nasrin, 2016, P 2016 C N AM CHAPTE, P839, DOI [10.18653/v1/N16-1098, DOI 10.18653/V1/N16-1098]; Nematzadeh A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2392; Nye Maxwell, 2021, ARXIV211200114; Ouyang Long, 2022, ARXIV220302155; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Roller Stephen, 2020, Recipes for building an open-domain chatbot; Rytting Christopher, 2021, Advances in Neural Information Processing Systems, V34, P17111; Sanh Victor, 2021, arXiv; Shoeybi M., 2019, Megatron-lm: Training multibillion parameter language models using model parallelism; Srivastava Aarohi, 2022, ARXIV220604615; Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264; SwaroopMishra Daniel Khashabi, 2022, ACL; Tafjord Oyvind, 2020, ARXIV201213048; Trinh Trieu H, 2018, A simple method for commonsense reasoning; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wang Xuezhi, 2022, arXiv:2203.11171; Wang Xuezhi, 2022, ARXIV220700747; Wang Yizhong, 2022, EMNLP; Wei Jason, 2022, arXiv:2201.11903; Wei Jason, 2021, arXiv preprint arXiv:2109.01652; Wei Jason, 2021, ARXIV210901652; Weidinger Laura, 2021, arXiv preprint arXiv:2112.04359; Weir Nathaniel, 2020, ARXIV201002882; Welbl Johannes, 2017, ARXIV170706209; West P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4602; Zhang S., 2022, arXiv; Zhou Denny, 2022, arXiv:2205.10625; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	71	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							1055	1081						27	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086807054
J	Yik, BJ; Dood, AJ				Yik, Brandon J.; Dood, Amber J.			ChatGPT Convincingly Explains Organic Chemistry Reaction Mechanisms Slightly Inaccurately with High Levels of Explanation Sophistication	JOURNAL OF CHEMICAL EDUCATION			English	Article						Second-Year Undergraduate; Upper-DivisionUndergraduate; Organic Chemistry; Testing and Assessment; Mechanistic Reasoning; Generative Artificial Intelligence; Chemistry Education Research	FEATURES; MODES	The chemistry education research community values and emphasizes the role of constructing explanations and mechanistic reasoning to support students' learning of organic chemistry. Emerging large language model (LLM) and generative artificial intelligence (GAI) technologies are uniquely equipped to advance the teaching and learning of chemistry. GAI-based chatbots, such as ChatGPT, have the potential to help students learn mechanistic reasoning through their generated responses. This study investigates the extent to which 255 ChatGPT-generated responses are accurate explanations of 85 different reaction mechanisms and exhibit mechanistic reasoning as categorized by the levels of explanation sophistication framework. The study also explores the effects of prompt engineering on mechanism accuracy and explanation sophistication through three types of prompt cueing. Study findings show that (1) a quarter of responses are fully accurate explanations of reaction mechanisms and the majority contain predominantly accurate explanations of chemical phenomena and identification of nucleophiles and electrophiles, (2) responses exhibit high levels of explanation sophistication, and (3) prompt engineering plays a significant role in eliciting high levels of explanation sophistication but not mechanism description accuracy. Results are situated in mechanistic reasoning and prompt engineering frameworks with a focus on how these new technologies can be integrated into the chemistry classroom.	[Yik, Brandon J.] Univ Virginia, Dept Chem, Charlottesville, VA 22904 USA; [Dood, Amber J.] Univ Michigan, Dept Chem, Ann Arbor, MI 48109 USA	University of Virginia; University of Michigan System; University of Michigan	Yik, BJ (corresponding author), Univ Virginia, Dept Chem, Charlottesville, VA 22904 USA.	byik@virginia.edu	; Yik, Brandon/AAS-6477-2021	Dood, Amber/0000-0003-4572-1402; Yik, Brandon/0000-0001-8124-8451				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Alasadi EA, 2023, J CHEM EDUC, V100, P2965, DOI 10.1021/acs.jchemed.3c00323; [Anonymous], 2023, PERPLEXITYAI; [Anonymous], 2020, arXiv; [Anonymous], 2023, Gemini; Bodé NE, 2019, J CHEM EDUC, V96, P1068, DOI 10.1021/acs.jchemed.8b00719; Bongers A, 2020, CHEM EDUC RES PRACT, V21, P496, DOI 10.1039/c9rp00198k; Caspari I, 2018, CHEM EDUC RES PRACT, V19, P1117, DOI 10.1039/c8rp00131f; Caspari I, 2018, CHEM EDUC RES PRACT, V19, P42, DOI 10.1039/c7rp00124j; Christian K, 2012, CHEM EDUC RES PRACT, V13, P286, DOI 10.1039/c2rp20010d; Clark TM, 2023, J CHEM EDUC, V100, P3934, DOI 10.1021/acs.jchemed.3c00500; Clark TM, 2023, J CHEM EDUC, V100, P1905, DOI 10.1021/acs.jchemed.3c00027; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cooper MM, 2016, J CHEM EDUC, V93, P1703, DOI 10.1021/acs.jchemed.6b00417; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crandell OM, 2020, J CHEM EDUC, V97, P313, DOI 10.1021/acs.jchemed.9b00815; Crandell OM, 2019, J CHEM EDUC, V96, P213, DOI 10.1021/acs.jchemed.8b00784; Crowder CJ, 2024, J CHEM EDUC, V101, P398, DOI 10.1021/acs.jchemed.3c00710; Dahlkemper MN, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010142; DAIR.AI, 2024, ELEMENTS PROMPT; Deng JM, 2023, J CHEM EDUC, V100, P1523, DOI 10.1021/acs.jchemed.2c01063; Deng JM, 2021, CHEM EDUC RES PRACT, V22, P749, DOI 10.1039/d0rp00320d; Dood AJ, 2022, J CHEM EDUC, DOI 10.1021/acs.jchemed.2c00313; Dood AJ, 2020, J CHEM EDUC, V97, P3551, DOI 10.1021/acs.jchemed.0c00569; Dood AJ, 2020, CHEM EDUC RES PRACT, V21, P267, DOI 10.1039/c9rp00148d; Dood AJ, 2019, CAN J CHEM, V97, P711, DOI 10.1139/cjc-2018-0479; Dood AJ, 2018, J CHEM EDUC, V95, P1267, DOI 10.1021/acs.jchemed.8b00177; DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041; Ellis AR, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i04; Emenike ME, 2023, J CHEM EDUC, V100, P1413, DOI 10.1021/acs.jchemed.3c00063; Exintaris B, 2023, J CHEM EDUC, V100, P2972, DOI 10.1021/acs.jchemed.3c00481; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Frost SJH, 2023, CHEM EDUC RES PRACT, V24, P706, DOI 10.1039/d2rp00327a; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Google Gemini Team, 2023, ARXIV; Graulich N, 2019, CHEM EDUC RES PRACT, V20, P924, DOI 10.1039/c9rp00054b; Guo Y, 2023, J CHEM EDUC, V100, P4876, DOI 10.1021/acs.jchemed.3c00505; Hasrod T, 2024, J CHEM EDUC, V101, P653, DOI 10.1021/acs.jchemed.3c01170; HuggingFace, 2024, HUGGINGCHAT; Humphry T, 2023, J CHEM EDUC, V100, P1434, DOI 10.1021/acs.jchemed.3c00006; Johnson R, 2022, J CHEM EDUC, V99, P3631, DOI 10.1021/acs.jchemed.2c01035; Keiner L, 2020, CHEM EDUC RES PRACT, V21, P469, DOI 10.1039/c9rp00241c; Keiner L, 2021, CHEM EDUC RES PRACT, V22, P146, DOI 10.1039/d0rp00206b; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.1093/biomet/30.1-2.81; Kraft A, 2010, CHEM EDUC RES PRACT, V11, P281, DOI 10.1039/C0RP90003F; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; Lawrie G, 2023, CHEM EDUC RES PRACT, V24, P392, DOI 10.1039/d3rp90003g; Leon AJ, 2023, J CHEM EDUC, V100, P3859, DOI 10.1021/acs.jchemed.3c00288; Lindauer M., 2022, ARXIV; Lolinco AT, 2023, J CHEM EDUC, V100, P4092, DOI 10.1021/acs.jchemed.3c00520; Mahapatra S, 2024, SMART LEARN ENVIRON, V11, DOI 10.1186/s40561-024-00295-9; Malik A., 2023, OPENAIS CHATGPTNOW H; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Microsoft, 2024, MICROSOFT COPILOT; Natl Res Council, 2012, FRAMEWORK FOR K-12 SCIENCE EDUCATION: PRACTICES, CROSSCUTTING CONCEPTS, AND CORE IDEAS, P1; NGSSLead States, 2013, NEXT GENERATIONSCIEN; OpenAI, 2023, ArXiv; OpenAI, 2023, INTRODUCINGGPTS; OpenAI, 2024, CHATGPT RELEASENOTES; OpenAI, 2023, CHATGPT; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Raker J. R., 2022, STUDENT REASONINGIN; Seidl P., 2023, ARXIV; Sevian H, 2014, CHEM EDUC RES PRACT, V15, P10, DOI 10.1039/c3rp00111c; Tack A., 2022, PROCEEDS 15 INT C ED; Talanquer V, 2023, J CHEM EDUC, V100, P2821, DOI 10.1021/acs.jchemed.3c00472; Tyson J, 2023, J CHEM EDUC, V100, P3098, DOI 10.1021/acs.jchemed.3c00361; Waltzer T, 2023, ETHICS BEHAV, V33, P130, DOI 10.1080/10508422.2022.2026775; Watts FM, 2023, J CHEM EDUC, V100, P3806, DOI 10.1021/acs.jchemed.3c00664; Watts FM, 2020, CHEM EDUC RES PRACT, V21, P1148, DOI 10.1039/c9rp00185a; Weinrich ML, 2016, CHEM EDUC RES PRACT, V17, P394, DOI 10.1039/c5rp00208g; Wilks SS, 1932, BIOMETRIKA, V24, P471; Yik BJ, 2023, CHEM EDUC RES PRACT, V24, P263, DOI 10.1039/d2rp00184e; Yik BJ, 2021, CHEM EDUC RES PRACT, V22, P866, DOI 10.1039/d1rp00111f; Yuriev E, 2023, J CHEM EDUC, V100, P3168, DOI 10.1021/acs.jchemed.3c00829	76	1	1	26	26	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0021-9584	1938-1328		J CHEM EDUC	J. Chem. Educ.	APR 25	2024	101	5					1836	1846		10.1021/acs.jchemed.4c00235	http://dx.doi.org/10.1021/acs.jchemed.4c00235		APR 2024	11	Chemistry, Multidisciplinary; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Education & Educational Research	RE6I2		hybrid			2024-07-03	WOS:001208324000001
J	Hagan, M				Hagan, Margaret			Towards human-centred standards for legal help AI	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Article						legal technology; artificial intelligence; participatory policymaking; legal design; access to justice	DESIGN; ACCESS	As more groups consider how AI may be used in the legal sector, this paper envisions how companies and policymakers can prioritize the perspective of community members as they design AI and policies around it. It presents findings of structured interviews and design sessions with community members, in which they were asked about whether, how, and why they would use AI tools powered by large language models to respond to legal problems like receiving an eviction notice. The respondents reviewed options for simple versus complex interfaces for AI tools, and expressed how they would want to engage with an AI tool to resolve a legal problem. These empirical findings provide directions that can counterbalance legal domain experts' proposals about the public interest around AI, as expressed by attorneys, court officials, advocates and regulators. By hearing directly from community members about how they want to use AI for civil justice tasks, what risks concern them, and the value they would find in different kinds of AI tools, this research can ensure that people's points of view are understood and prioritized, rather than only domain experts' assertions about people's needs and preferences around legal help AI.This article is part of the theme issue 'A complexity science approach to law and governance'.	[Hagan, Margaret] Stanford Law Sch, Legal Design Lab, Stanford, CA 94305 USA	Stanford University	Hagan, M (corresponding author), Stanford Law Sch, Legal Design Lab, Stanford, CA 94305 USA.	mdhagan@stanford.edu		Hagan, Margaret/0000-0003-2972-1867				American Academy of Arts Sciences, 2023, AI's implications for equitable access to legal and other professional services; Bason C., 2013, Public and collaborative: exploring the intersection of design, social innovation, and public policy; Berditchevskaia A., 2021, Participatory AI for humanitarian innovation; Blomkamp E, 2022, POLICY DES PRACT, V5, P12, DOI 10.1080/25741292.2021.1887576; Blomkamp E, 2018, AUST J PUBL ADMIN, V77, P729, DOI 10.1111/1467-8500.12310; Brescia R H., 2015, Albany Law Review, V78, P553; Buchholz RM., 2021, Regulation of the legal profession in the United States: overview; Cabral JamesE., 2012, HARVARD J LAW TECHNO, V26, P241; Cornett L., 2019, Redesigning divorce: user-driven design for a better process; Cyphert A. B., 2021, UC Davis L. Rev, V55, P401; Denvir C., 2014, What is the net worth? Young people, civil justice and the internet; Google, 2023, Generative AI additional terms of service. Privacy & terms; Granat R., 2023, The Law Product Makers; Greacen JM, 2019, FAM COURT REV, V57, P515, DOI 10.1111/fcre.12446; Groves L., 2023, Exploring the role of public participation in commercial AI labs; Guzman H., 2023, AI's 'hallucinations' add to risks of widespread adoption; Hagan M., 2024, Figshare, DOI [10.6084/m9.figshare.c.7031265, DOI 10.6084/M9.FIGSHARE.C.7031265]; Hagan M., 2016, Va J. Law Technol, V20, P395; Hagan M, 2020, DES ISSUES, V36, P3, DOI 10.1162/desi_a_00600; Hagan M, 2019, DAEDALUS-US, V148, P120, DOI 10.1162/daed_a_00544; Hagan MargaretD., 2018, INDIANA J LAW SOCIAL, V6, P199; Harden S., 2023, Team Do Something; Holt AT., 2023, Vanderbilt J. Entertain. Technol. Law; Hossain Soaad, 2021, arXiv; IAALS and HiiL, 2021, Justice needs and satisfaction in the United States of America; Kanu H., 2023, Reuters; Le Dantec CA, 2013, SOC STUD SCI, V43, P241, DOI 10.1177/0306312712471581; Legal Service Corporation, 2022 Justice Gap Study 2022; Moss MA, 2020, DES ISSUES, V36, P45, DOI 10.1162/desi_a_00603; Organisation for Economic Cooperation and Development, 2019, Legal needs surveys and access to justice, P23, DOI [10.1787/cab05cff-en, DOI 10.1787/CAB05CFF-EN]; Rostain T, 2019, DAEDALUS-US, V148, P93, DOI 10.1162/daed_a_00540; Sandefur R.L., 2007, Transforming Lives: Law and Social Process; Sandefur R.L., 2014, ACCESSING JUSTICE CO; Sandefur RebeccaL., 2016, South Carolina law review, V67, P443; Self-Represented Litigation Network, 2023, Generative AI April Webinar; Simshaw Drew., 2022, Yale J. Law Technol, V24, P150; Sonday K., 2023, There's potential for AI chatbots to increase access to justice; Staudt RW., 2008, Loy. L. A. Law Rev, V42, P1117; Stepka M., 2022, ABA Business Law Today; Telang A., 2023, Harv. J. Law Technol. (JOLT Digest); The Engine Room, 2019, A global review technology for legal empowerment; Tito Joel, 2017, How AI Can Improve Access to Justice; Tripp A., 2018, Legal services community principles and guidelines for due process and ethics in the age of AI; Wu J., 2019, Legal Design and Innovation; Yang J., 2020, Partnership on AI; Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493	46	1	1	8	8	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-503X	1471-2962		PHILOS T R SOC A	Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.	APR 15	2024	382	2270							20230157	10.1098/rsta.2023.0157	http://dx.doi.org/10.1098/rsta.2023.0157			21	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	JV6Z5	38403062				2024-07-03	WOS:001175989800013
J	Kerr, WT; McFarlane, KN				Kerr, Wesley T.; McFarlane, Katherine N.			Machine Learning and Artificial Intelligence Applications to Epilepsy: a Review for the Practicing Epileptologist	CURRENT NEUROLOGY AND NEUROSCIENCE REPORTS			English	Review						Seizures; Computer-aided decision making; Neural networks; Computer-aided decision support; Natural language processing	PSYCHOGENIC NONEPILEPTIC SEIZURES; HIGH-FREQUENCY OSCILLATIONS; EPILEPTIFORM DISCHARGES; INTERNATIONAL LEAGUE; PATIENTS ACCOUNTS; SERUM PROLACTIN; ILAE COMMISSION; HEALTH-CARE; BIG DATA; DIAGNOSIS	Purpose of ReviewMachine Learning (ML) and Artificial Intelligence (AI) are data-driven techniques to translate raw data into applicable and interpretable insights that can assist in clinical decision making. Some of these tools have extremely promising initial results, earning both great excitement and creating hype. This non-technical article reviews recent developments in ML/AI in epilepsy to assist the current practicing epileptologist in understanding both the benefits and limitations of integrating ML/AI tools into their clinical practice.Recent FindingsML/AI tools have been developed to assist clinicians in almost every clinical decision including (1) predicting future epilepsy in people at risk, (2) detecting and monitoring for seizures, (3) differentiating epilepsy from mimics, (4) using data to improve neuroanatomic localization and lateralization, and (5) tracking and predicting response to medical and surgical treatments. We also discuss practical, ethical, and equity considerations in the development and application of ML/AI tools including chatbots based on Large Language Models (e.g., ChatGPT).SummaryML/AI tools will change how clinical medicine is practiced, but, with rare exceptions, the transferability to other centers, effectiveness, and safety of these approaches have not yet been established rigorously. In the future, ML/AI will not replace epileptologists, but epileptologists with ML/AI will replace epileptologists without ML/AI.	[Kerr, Wesley T.; McFarlane, Katherine N.] Univ Pittsburgh, Dept Neurol, 3471 Fifth Ave,Kaufmann 811-22, Pittsburgh, PA 15213 USA; [Kerr, Wesley T.] Univ Pittsburgh, Dept Biomed Informat, 3471 Fifth Ave,Kaufmann 811-22, Pittsburgh, PA 15213 USA; [Kerr, Wesley T.] Univ Michigan, Dept Neurol Michigan Med, Ann Arbor, MI 48109 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Michigan System; University of Michigan	Kerr, WT (corresponding author), Univ Pittsburgh, Dept Neurol, 3471 Fifth Ave,Kaufmann 811-22, Pittsburgh, PA 15213 USA.; Kerr, WT (corresponding author), Univ Pittsburgh, Dept Biomed Informat, 3471 Fifth Ave,Kaufmann 811-22, Pittsburgh, PA 15213 USA.; Kerr, WT (corresponding author), Univ Michigan, Dept Neurol Michigan Med, Ann Arbor, MI 48109 USA.	KerrW@Pitt.edu			National Institute of Neurological Disorders and Stroke	National Institute of Neurological Disorders and Stroke(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	No Statement Available	Abbasi B, 2019, EPILEPSIA, V60, P2037, DOI 10.1111/epi.16333; Akrami H, 2022, AM J NEURORADIOL, V43, P347, DOI 10.3174/ajnr.A7436; Al-hajjar ALN, 2023, J SUPERCOMPUT, V79, P16017, DOI 10.1007/s11227-023-05299-9; Alving J, 1998, SEIZURE-EUR J EPILEP, V7, P85, DOI 10.1016/S1059-1311(98)80046-0; Asadi-Pooya AA, 2023, EPILEPSIA OPEN, V8, P1362, DOI 10.1002/epi4.12800; Asadi-Pooya AA, 2022, J PSYCHOSOM RES, V153, DOI 10.1016/j.jpsychores.2021.110703; Asadi-Pooya AA, 2020, EPILEPSY BEHAV, V104, DOI 10.1016/j.yebeh.2019.106895; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Azriel R, 2022, PHYSIOL MEAS, V43, DOI 10.1088/1361-6579/ac8ccd; Beheshti I, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104805; Bensken WP, 2023, SEIZURE-EUR J EPILEP, V110, P169, DOI 10.1016/j.seizure.2023.06.021; Berg AT, 2004, CNS SPECTRUMS, V9, P136, DOI 10.1017/S109285290000849X; Bernasconi A, 2022, EUR NEUROL, V85, P333, DOI 10.1159/000525262; Bernasconi A, 2019, EPILEPSIA, V60, P1054, DOI 10.1111/epi.15612; Bertoncelli CM, 2023, COMPUT METH PROG BIO, V236, DOI 10.1016/j.cmpb.2023.107548; Bhattacharya S, 2019, J FAM MED PRIM CARE, V8, P3461, DOI 10.4103/jfmpc.jfmpc_155_19; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Breitenstein PS, 2022, FRONT PHARMACOL, V13, DOI 10.3389/fphar.2022.954393; Budd J, 2023, J PRIM CARE COMMUNIT, V14, DOI 10.1177/21501319231166921; Caciagli L, 2022, BRAIN, V145, P807, DOI 10.1093/brain/awac027; Caldairou B, 2021, NEUROLOGY, V97, pE1583, DOI 10.1212/WNL.0000000000012699; Cendes F, 2022, EPILEPSY CURR, V22, P91, DOI 10.1177/15357597211068600; Chang AJ, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00262-4; Chari A, 2023, DEV MED CHILD NEUROL, DOI 10.1111/dmcn.15727; Chen A, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.27647; Chen DK, 2005, NEUROLOGY, V65, P668, DOI 10.1212/01.wnl.0000178391.96957.d0; Chen GH, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.738658; Chen M, 2019, NEUROLOGY, V92, pE895, DOI 10.1212/WNL.0000000000007017; Cheval M, 2023, J NEUROL, V270, P2715, DOI 10.1007/s00415-023-11603-7; Chiang SR, 2021, NEUROLOGY, V97, P632, DOI 10.1212/WNL.0000000000012570; Co Z, 2020, J AM MED INFORM ASSN, V27, P1252, DOI 10.1093/jamia/ocaa098; Croce P, 2021, CLIN NEUROPHYSIOL, V132, P3035, DOI 10.1016/j.clinph.2021.08.024; de Jong J, 2021, BRAIN, V144, P1738, DOI 10.1093/brain/awab108; Decker BM, 2022, SEIZURE-EUR J EPILEP, V101, P48, DOI 10.1016/j.seizure.2022.07.010; Delgado-García G, 2023, EPILEPSIA, V64, P2781, DOI 10.1111/epi.17710; Demuth S, 2021, EPILEPSIA, V62, P3143, DOI 10.1111/epi.17093; Dunnmon J, 2021, RADIOL CLIN N AM, V59, P1063, DOI 10.1016/j.rcl.2021.07.006; Eberhard E, 2023, J NEUROSCI NURS, V55, P157, DOI 10.1097/JNN.0000000000000715; Egger J, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106874; Elmahdy M, 2023, J AM MED INFORM ASSN, V30, P1552, DOI 10.1093/jamia/ocad094; Emanuel EJ, 2019, JAMA-J AM MED ASSOC, V321, P2281, DOI 10.1001/jama.2019.4914; Eriksson MH, 2023, EPILEPSIA, V64, P2014, DOI 10.1111/epi.17637; Escobar-Ipuz FA, 2023, BRAIN RES, V1798, DOI 10.1016/j.brainres.2022.148131; Faghihpirayesh R, 2021, IEEE ENG MED BIO, P302, DOI 10.1109/EMBC46164.2021.9630242; Fearns N, 2023, EPILEPSY RES, V192, DOI 10.1016/j.eplepsyres.2023.107133; Fernandes M, 2023, EPILEPSIA, V64, P1472, DOI 10.1111/epi.17589; Fisher RS, 2017, EPILEPSIA, V58, P531, DOI 10.1111/epi.13671; Flaus A, 2023, EPILEPSIA OPEN, V8, P1440, DOI 10.1002/epi4.12820; Fujiwara H, 2012, EPILEPSIA, V53, P1607, DOI 10.1111/j.1528-1167.2012.03629.x; Garçao VM, 2023, EPILEPSIA, V64, P2472, DOI 10.1111/epi.17677; García-Ramó KB, 2023, CLIN NEUROL NEUROSUR, V232, DOI 10.1016/j.clineuro.2023.107879; Gill RS, 2021, NEUROLOGY, V97, pE1571, DOI 10.1212/WNL.0000000000012698; Glauser T, 2020, ACTA NEUROL SCAND, V141, P388, DOI 10.1111/ane.13216; Gleichgerrcht E, 2022, PHYSIOL MEAS, V43, DOI 10.1088/1361-6579/aca6ca; Gleichgerrcht E, 2022, BRAIN COMMUN, V4, DOI 10.1093/braincomms/fcab284; Gleichgerrcht E, 2021, NEUROIMAGE-CLIN, V31, DOI 10.1016/j.nicl.2021.102765; Goldenholz DM, 2023, EPILEPSIA, V64, P396, DOI 10.1111/epi.17471; Goldenholz DM, 2020, ANN NEUROL, V88, P588, DOI 10.1002/ana.25812; Gomez-Quintana S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14894-4; GOTMAN J, 1979, ELECTROEN CLIN NEURO, V46, P510, DOI 10.1016/0013-4694(79)90004-X; Gramacki A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15830-2; Grzeskowiak CLL, 2021, FRONT NEUROL, V12, DOI 10.3389/fneur.2021.717428; Gu B, 2022, REV NEUROSCIENCE, V33, P877, DOI 10.1515/revneuro-2022-0024; Hakeem H, 2022, JAMA NEUROL, V79, P986, DOI 10.1001/jamaneurol.2022.2514; Hamid H, 2013, EPILEPSY BEHAV, V29, P578, DOI 10.1016/j.yebeh.2013.09.025; Hirsch LJ, 2021, J CLIN NEUROPHYSIOL, V38, P1, DOI 10.1097/WNP.0000000000000806; Hollis Kate Fultz, 2019, Yearb Med Inform, V28, P3, DOI 10.1055/s-0039-1677951; Hou JC, 2022, EPILEPSY RES, V184, DOI 10.1016/j.eplepsyres.2022.106953; Huang J, 2022, JMIR MED INF, V10, DOI 10.2196/36388; Iwatani Y, 2012, EPILEPSY RES, V102, P60, DOI 10.1016/j.eplepsyres.2012.04.020; Jankovic Ivana, 2020, Yearb Med Inform, V29, P145, DOI 10.1055/s-0040-1701986; Janocko NJ, 2021, EPILEPSY RES, V171, DOI 10.1016/j.eplepsyres.2021.106563; Japaridze G, 2023, EPILEPSIA, V64, pS40, DOI 10.1111/epi.17200; Jenkins L, 2016, EPILEPSY BEHAV, V64, P257, DOI 10.1016/j.yebeh.2016.08.008; Jeon Y, 2022, IEEE T NEUR SYS REH, V30, P2939, DOI 10.1109/TNSRE.2022.3215526; Jeppesen J, 2023, SEIZURE-EUR J EPILEP, V107, P155, DOI 10.1016/j.seizure.2023.04.012; Jing J, 2023, NEUROLOGY, V100, pE1750, DOI 10.1212/WNL.0000000000207127; Jing J, 2023, NEUROLOGY, V100, pE1737, DOI 10.1212/WNL.0000000000201670; Johnson GW, 2022, J NEUROSURG, V138, P1002, DOI 10.3171/2022.8.JNS221321; Jonas S, 2022, NEUROIMAGE-CLIN, V36, DOI 10.1016/j.nicl.2022.103167; Kaestner E, 2023, NEUROLOGY, V101, pE324, DOI 10.1212/WNL.0000000000207411; Kaestner E, 2023, NEUROLOGY, V100, P799, DOI 10.1212/WNL.0000000000207224; Kakeda S, 2010, NEURORADIOLOGY, V52, P711, DOI 10.1007/s00234-010-0717-2; Kamousi B, 2021, NEUROCRIT CARE, V34, P908, DOI 10.1007/s12028-020-01120-0; Kanbar LJ, 2022, JMIR MED INF, V10, DOI 10.2196/37833; Kao YS, 2023, ANN BIOMED ENG, V51, P2652, DOI 10.1007/s10439-023-03285-z; Karakis I, 2022, EPILEPSY CURR, V22, P279, DOI 10.1177/15357597221105139; Karoly PJ, 2021, EBIOMEDICINE, V72, DOI 10.1016/j.ebiom.2021.103619; Karoly PJ, 2021, NAT REV NEUROL, V17, P267, DOI 10.1038/s41582-021-00464-1; Karoly PJ, 2021, EPILEPSIA, V62, P416, DOI 10.1111/epi.16809; Karoly PJ, 2020, EPILEPSIA, V61, P776, DOI 10.1111/epi.16485; Karoly PJ, 2019, EPILEPSIA, V60, pE99, DOI 10.1111/epi.16321; Karoly PJ, 2018, LANCET NEUROL, V17, P977, DOI 10.1016/S1474-4422(18)30274-6; Kaur T, 2021, NEUROL INDIA, V69, P560, DOI 10.4103/0028-3886.317233; Kerr WT, 2022, EPILEPSIA, V63, P2994, DOI 10.1111/epi.17411; Kerr WT, 2021, EPILEPSY BEHAV, V115, DOI 10.1016/j.yebeh.2020.107696; Kerr WT, 2020, EPILEPSY BEHAV, V113, DOI 10.1016/j.yebeh.2020.107525; Kerr WT, 2012, EPILEPSIA, V53, pe189, DOI 10.1111/j.1528-1167.2012.03653.x; Khalil Nadia, 2022, Int J MS Care, V24, P271, DOI 10.7224/1537-2073.2020-101; Kleen JK, 2023, JAMA NEUROL, V80, P777, DOI 10.1001/jamaneurol.2023.1082; Kozak R, 2023, JACEP OPEN, V4, DOI 10.1002/emp2.13004; Kulkarni PA, 2023, JAMA-J AM MED ASSOC, V330, P317, DOI 10.1001/jama.2023.11440; Kural MA, 2022, EPILEPSIA, V63, P1064, DOI 10.1111/epi.17206; Kusmakar S, 2019, EPILEPSIA, V60, P165, DOI 10.1111/epi.14619; Kusmakar S, 2019, IEEE T BIO-MED ENG, V66, P421, DOI 10.1109/TBME.2018.2845865; Kusmakar S, 2016, IEEE ENG MED BIO, P1006, DOI 10.1109/EMBC.2016.7590872; Kwan P, 2010, EPILEPSIA, V51, P1069, DOI 10.1111/j.1528-1167.2009.02397.x; LaFrance WC, 2013, EPILEPSIA, V54, P2005, DOI 10.1111/epi.12356; Lee DA, 2021, CLIN NEUROL NEUROSUR, V211, DOI 10.1016/j.clineuro.2021.107037; Lee DA, 2021, J CLIN NEUROSCI, V91, P327, DOI 10.1016/j.jocn.2021.07.035; Lee HM, 2022, BRAIN, V145, P897, DOI 10.1093/brain/awab425; Lee KK, 2009, AM J NEURORADIOL, V30, P1811, DOI 10.3174/ajnr.A1637; Lekoubou A, 2021, EPILEPSY BEHAV, V121, DOI 10.1016/j.yebeh.2021.108003; Lemoine E, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-39799-8; Lenio S, 2021, EPILEPSY BEHAV, V116, DOI 10.1016/j.yebeh.2021.107767; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Li W, 2022, ACTA NEUROL SCAND, V146, P723, DOI 10.1111/ane.13716; Li Y, 2019, EPILEPSIA OPEN, V4, P210, DOI 10.1002/epi4.12301; Li Y, 2017, EPILEPSIA, V58, pE132, DOI 10.1111/epi.13840; Lin F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99506-3; Luckett PH, 2022, EPILEPSIA, V63, P1542, DOI 10.1111/epi.17233; McInnis RP, 2023, EPILEPSY BEHAV, V141, DOI 10.1016/j.yebeh.2023.109135; Mettenburg JM, 2019, AM J NEURORADIOL, V40, P440, DOI 10.3174/ajnr.A5966; Mezrich JL, 2022, AM J ROENTGENOL, V219, P152, DOI 10.2214/AJR.21.27224; Mezrich JL, 2022, PET CLIN, V17, P41, DOI 10.1016/j.cpet.2021.08.002; Mirchi N, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.913777; Moffet EW, 2020, NEUROCRIT CARE, V33, P701, DOI 10.1007/s12028-020-00939-x; Monsoor T, 2023, CLIN NEUROPHYSIOL, V154, P129, DOI 10.1016/j.clinph.2023.07.012; Moro M, 2023, EPILEPSIA, V64, P1653, DOI 10.1111/epi.17605; Mueller B, 2021, HEADACHE, V61, P1521, DOI 10.1111/head.14226; Muhiyaddin Raghad, 2022, Stud Health Technol Inform, V289, P481, DOI 10.3233/SHTI210962; Murphy MA, 2004, J NEUROSURG, V100, P452, DOI 10.3171/jns.2004.100.3.0452; Muthusamy S, 2022, NEUROL-CLIN PRACT, V12, P234, DOI 10.1212/CPJ.0000000000001170; Nafea MS, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9120781; Naganur VD, 2019, EPILEPSIA OPEN, V4, P309, DOI 10.1002/epi4.12327; Nagasawa T, 2012, HUM BRAIN MAPP, V33, P569, DOI 10.1002/hbm.21233; Nascimento FA, 2023, CLIN NEUROPHYSIOL, V146, P10, DOI 10.1016/j.clinph.2022.10.018; Nascimento FA, 2022, CLIN NEUROPHYSIOL, V133, P68, DOI 10.1016/j.clinph.2021.10.007; Nasseri M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01449-2; Nemesure MD, 2022, EPILEPSIA, V63, P2269, DOI 10.1111/epi.17324; Ngiam KY, 2019, LANCET ONCOL, V20, pE262, DOI 10.1016/S1470-2045(19)30149-4; Nhu D, 2022, J NEURAL ENG, V19, DOI 10.1088/1741-2552/ac9644; Norori N, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100347; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Oliveira A, 2019, EPILEPSIA, V60, pE128, DOI 10.1111/epi.16384; Park Y, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.3909; Passaro Erasmo A, 2023, Continuum (Minneap Minn), V29, P104, DOI 10.1212/CON.0000000000001242; Peltola J, 2023, EPILEPSIA, V64, pS65, DOI 10.1111/epi.17207; Pevy N, 2023, EPILEPSY BEHAV, V143, DOI 10.1016/j.yebeh.2023.109217; Pitkänen A, 2021, EPILEPSY BEHAV, V121, DOI 10.1016/j.yebeh.2020.107080; Plug L, 2009, EPILEPSIA, V50, P994, DOI 10.1111/j.1528-1167.2008.01798.x; Preilowski B, 2009, FORTSCHR NEUROL PSYC, V77, P568, DOI 10.1055/s-0028-1109664; Quon RJ, 2022, CLIN NEUROPHYSIOL, V133, P1, DOI 10.1016/j.clinph.2021.09.018; Reuber M, 2016, NEUROLOGY, V87, P625, DOI 10.1212/WNL.0000000000002948; Reutens DC, 1996, NEURORADIOLOGY, V38, P221; Rigney G, 2021, SEIZURE-EUR J EPILEP, V91, P132, DOI 10.1016/j.seizure.2021.06.006; Ritter AC, 2016, EPILEPSIA, V57, P1503, DOI 10.1111/epi.13470; Robson C, 2012, SEIZURE-EUR J EPILEP, V21, P795, DOI 10.1016/j.seizure.2012.09.007; Romero J, 2021, SEIZURE-EUR J EPILEP, V91, P499, DOI 10.1016/j.seizure.2021.07.033; Saboo KV, 2023, IEEE T NANOBIOSCI, V22, P818, DOI 10.1109/TNB.2023.3275037; Safdar NM, 2020, EUR J RADIOL, V122, DOI 10.1016/j.ejrad.2019.108768; Sakashita K, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0282082; Salamon N, 2008, NEUROLOGY, V71, P1594, DOI 10.1212/01.wnl.0000334752.41807.2f; Samanta D, 2021, EPILEPSY BEHAV, V117, DOI 10.1016/j.yebeh.2021.107837; Sheldon R, 2002, J AM COLL CARDIOL, V40, P142, DOI 10.1016/S0735-1097(02)01940-X; Shih YC, 2022, CLIN NUCL MED, V47, P287, DOI 10.1097/RLU.0000000000004072; Singh K, 2021, PHYS ENG SCI MED, V44, P1161, DOI 10.1007/s13246-021-01052-9; Smolyansky ED, 2021, EPILEPSY BEHAV, V123, DOI 10.1016/j.yebeh.2021.108273; Sollee J, 2022, EPILEPSY RES, V182, DOI 10.1016/j.eplepsyres.2022.106861; Steriade C, 2022, EPILEPSY CURR, V22, P168, DOI 10.1177/15357597221081627; Stirling RE, 2021, EPILEPSIA, V62, pS2, DOI 10.1111/epi.16541; Struck AF, 2020, JAMA NEUROL, V77, P500, DOI 10.1001/jamaneurol.2019.4656; Struck AF, 2017, JAMA NEUROL, V74, P1419, DOI 10.1001/jamaneurol.2017.2459; Tamilia E, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00014; Tan S, 2023, J CLIN NEUROSCI, V114, P104, DOI 10.1016/j.jocn.2023.06.010; Tang JB, 2021, EPILEPSIA, V62, P1807, DOI 10.1111/epi.16967; Tatum WO, 2021, EUR J NEUROL, V28, P1453, DOI 10.1111/ene.14744; Tatum WO, 2020, JAMA NEUROL, V77, P593, DOI 10.1001/jamaneurol.2019.4785; Terman SW, 2022, EPILEPSY CURR, V22, P111, DOI 10.1177/15357597211049052; Thompson AC, 2014, EPILEPSIA, V55, P1339, DOI 10.1111/epi.12700; Tolchin B, 2020, EPILEPSY BEHAV, V112, DOI 10.1016/j.yebeh.2020.107364; Trainor D, 2020, EPILEPSY BEHAV, V112, DOI 10.1016/j.yebeh.2020.107482; Tveit J, 2023, JAMA NEUROL, V80, P805, DOI 10.1001/jamaneurol.2023.1645; Urbach H, 2022, NEURORADIOLOGY, V64, P715, DOI 10.1007/s00234-021-02823-7; Varone G, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010129; Vespa PM, 2020, CRIT CARE MED, V48, P1249, DOI 10.1097/CCM.0000000000004428; Vossler DG, 2020, J NEUROL NEUROSUR PS, V91, P1067, DOI 10.1136/jnnp-2020-323524; Walger L, 2023, EPILEPSIA, V64, P1093, DOI 10.1111/epi.17522; Wang B, 2022, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.781937; Wang XY, 2021, J CLIN NEUROSCI, V91, P276, DOI 10.1016/j.jocn.2021.07.016; Ward J, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1035442; Wardrope A, 2021, SEIZURE-EUR J EPILEP, V93, P102, DOI 10.1016/j.seizure.2021.10.016; Wardrope A, 2020, NEUROL-CLIN PRACT, V10, P96, DOI 10.1212/CPJ.0000000000000726; Wardrope A, 2018, SEIZURE-EUR J EPILEP, V61, P139, DOI 10.1016/j.seizure.2018.08.012; Wasserman D, 2017, EPILEPSY BEHAV, V73, P42, DOI 10.1016/j.yebeh.2017.04.020; Whelan CD, 2018, BRAIN, V141, P391, DOI 10.1093/brain/awx341; Wilkinson J, 2020, LANCET DIGIT HEALTH, V2, pE677, DOI 10.1016/S2589-7500(20)30200-4; Wissel BD, 2021, ACTA NEUROL SCAND, V144, P41, DOI 10.1111/ane.13418; Wissel BD, 2020, EPILEPSIA, V61, P39, DOI 10.1111/epi.16398; Wissel BD, 2019, EPILEPSIA, V60, pE93, DOI 10.1111/epi.16320; Wu JH, 2022, EPILEPSY RES, V181, DOI 10.1016/j.eplepsyres.2022.106888; Xia YL, 2023, EPILEPSIA OPEN, V8, P959, DOI 10.1002/epi4.12775; Xie DV, 2024, CAN J NEUROL SCI, V51, P246, DOI 10.1017/cjn.2023.241; Xie K, 2023, EPILEPSIA, V64, P1900, DOI 10.1111/epi.17633; Xie K, 2022, J AM MED INFORM ASSN, V29, P873, DOI 10.1093/jamia/ocac018; Xiong WJ, 2023, IEEE T NEUR SYS REH, V31, P2831, DOI 10.1109/TNSRE.2023.3288138; Xu ZH, 2023, THER INNOV REGUL SCI, V57, P957, DOI 10.1007/s43441-023-00541-1; Yew ANJ, 2023, EPILEPSIA, V64, P292, DOI 10.1111/epi.17474; Yossofzai O, 2022, EPILEPSIA, V63, P1956, DOI 10.1111/epi.17320; Yuan J, 2022, J NEUROSCI METH, V368, DOI 10.1016/j.jneumeth.2021.109441; Zambrana-Vinaroz D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22239372; Zeng-Treitler Q, 2019, J MED INTERNET RES, V21, DOI 10.2196/16272; Zhang YP, 2022, J NEURAL ENG, V19, DOI 10.1088/1741-2552/aca4fa; Zhao X, 2022, EPILEPSY RES, V188, DOI 10.1016/j.eplepsyres.2022.107040	214	2	2	15	16	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1528-4042	1534-6293		CURR NEUROL NEUROSCI	Curr. Neurol. Neurosci. Rep.	DEC	2023	23	12					869	879		10.1007/s11910-023-01318-7	http://dx.doi.org/10.1007/s11910-023-01318-7		DEC 2023	11	Clinical Neurology; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	AU7K1	38060133				2024-07-03	WOS:001116061500001
C	Zeng, Z; Watson, W; Cho, N; Rahimi, S; Reynolds, S; Balch, T; Veloso, M			ACM	Zeng, Zhen; Watson, William; Cho, Nicole; Rahimi, Saba; Reynolds, Shayleen; Balch, Tucker; Veloso, Manuela			FlowMind: Automatic Workflow Generation with LLMs	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		cognitive workflow; user query; information retrieval		The rapidly evolving field of Robotic Process Automation (RPA) has made significant strides in automating repetitive processes, yet its effectiveness diminishes in scenarios requiring spontaneous or unpredictable tasks demanded by users. This paper introduces a novel approach, FlowMind, leveraging the capabilities of Large Language Models (LLMs) such as Generative Pretrained Transformer (GPT), to address this limitation and create an automatic workflow generation system. In FlowMind, we propose a generic prompt recipe for a lecture that helps ground LLM reasoning with reliable Application Programming Interfaces (APIs). With this, FlowMind not only mitigates the common issue of hallucinations in LLMs, but also eliminates direct interaction between LLMs and proprietary data or code, thus ensuring the integrity and confidentiality of information - a cornerstone in financial services. FlowMind further simplifies user interaction by presenting high-level descriptions of auto-generated workflows, enabling users to inspect and provide feedback effectively. We also introduce NCEN-QA, a new dataset in finance for benchmarking question-answering tasks from N-CEN reports on funds. We used NCEN-QA to evaluate the performance of workflows generated by FlowMind against baseline and ablation variants of FlowMind. We demonstrate the success of FlowMind, the importance of each component in the proposed lecture recipe, and the effectiveness of user interaction and feedback in FlowMind.	[Zeng, Zhen; Watson, William; Cho, Nicole; Rahimi, Saba; Reynolds, Shayleen; Balch, Tucker; Veloso, Manuela] J P Morgan AI Res, New York, NY 10017 USA		Zeng, Z (corresponding author), J P Morgan AI Res, New York, NY 10017 USA.	zhen.zeng@jpmchase.com; william.watson@jpmchase.com; nicole.cho@jpmorgan.com; saba.rahimi@jpmorgan.com; shayleen.reynolds@jpmchase.com; tucker.balch@jpmchase.com; manuela.veloso@jpmchase.com	zeng, zhen/KGK-4217-2024	Watson, William/0000-0001-5516-262X; Balch, Tucker/0000-0002-5148-2033; Veloso, Maria Manuela/0000-0001-6738-238X				Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Bachmann Max, 2021, Zenodo; Gao LY, 2023, Arxiv, DOI [arXiv:2211.10435, 10.48550/arXiv.2211.10435, DOI 10.48550/ARXIV.2211.10435]; github, 2022, LangChain; github, 2023, AutoGPT; Herm LV, 2020, LECT NOTES COMPUT SC, V12168, P471, DOI 10.1007/978-3-030-58666-9_27; Hofmann P, 2020, ELECTRON MARK, V30, P99, DOI 10.1007/s12525-019-00365-8; huggingface, 2023, Transformer Agent; Kobayashi T, 2019, P INT COMP SOFTW APP, P251, DOI 10.1109/COMPSAC.2019.10215; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu XY, 2023, Arxiv, DOI [arXiv:2307.10485, 10.48550/arXiv.2307.10485, DOI 10.48550/ARXIV.2307.10485]; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; openai, 2022, OpenAI API; Pereira J, 2023, LECT NOTES COMPUT SC, V13981, P534, DOI 10.1007/978-3-031-28238-6_44; Poesia G, 2022, Arxiv, DOI [arXiv:2201.11227, 10.48550/ARXIV.2201.11227]; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ram O, 2023, Arxiv, DOI arXiv:2302.00083; Ratia M, 2018, MINDTREK'18: PROCEEDINGS OF THE 22ND INTERNATIONAL ACADEMIC MINDTREK CONFERENCE, P222, DOI 10.1145/3275116.3275129; Rubin O, 2022, Arxiv, DOI [arXiv:2112.08633, 10.48550/ARXIV.2112.08633]; Schick Timo, 2023, Toolformer: Language models can teach themselves to use tools; sec, 1984, Edgar; Subramanian S, 2023, Arxiv, DOI arXiv:2306.05392; Syed R, 2020, COMPUT IND, V115, DOI 10.1016/j.compind.2019.103162; Vaithilingam Priyan, 2022, CHI C HUM FACT COMP, P1; van der Aalst WMP, 2018, BUS INFORM SYST ENG+, V60, P269, DOI 10.1007/s12599-018-0542-4; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Villar AS., 2021, Journal of Banking and Financial Technology, V5, P71, DOI DOI 10.1007/S42786-021-00030-9; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yang H, 2023, arXiv; Zhang Boyu, 2023, arXiv	33	0	0	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							73	81		10.1145/3604237.3626908	http://dx.doi.org/10.1145/3604237.3626908			9	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI					2024-07-03	WOS:001124982700009
J	Schneider, H				Schneider, Howard			The emergence of compositionality in a brain-inspired cognitive architecture	COGNITIVE SYSTEMS RESEARCH			English	Article						Compositionality; Brain-Inspired Cognitive Architecture (BICA); Artificial Intelligence (AI); Language evolution; Large Language Model (LLM); Neurosymbolic computing	EVOLUTION; HIPPOCAMPUS; NAVIGATION; KNOWLEDGE; MODEL; FRAMEWORK; NEOCORTEX; PALLIUM; MEMORY	Compositionality can be considered as finding (or creating) the correct meaning of the constituents of a nonsimple language expression or visual image. The Causal Cognitive Architecture is a brain-inspired cognitive architecture (BICA). It is not a traditional artificial neural network architecture, nor a traditional symbolic AI system but instead uses spatial navigation maps as its fundamental circuits. In previously described versions of the architecture, sensory inputs are compared in each existing sensory system against previous stored navigation maps for that sensory system, and the best navigation map is chosen and then updated with the new sensory inputs and a best multisensory navigation map is similarly created and used as the working navigation map. Instinctive and learned small procedures are triggered by input sensory inputs as well as matched navigation maps, and in the Navigation Module operate on the working navigation map and produce an output signal. By feeding back intermediate results in the Navigation Module it has been shown previously how causal and analogical behaviors emerge from the architecture. In new work, the Navigation Module is duplicated in a biologically plausible manner. It becomes possible to compositionally process information in the duplicated Navigation Module, and as a result compositional language comprehension and behavior readily emerge. A formalization and simulation of the architecture is presented. A demonstration example, and its negation, are explored of solving a compositional problem requiring the placement of an object in a specific location with regard to other objects. Future work is discussed using large language models to create navigation maps. Given the mammalian brain inspiration of the architecture, it suggests that it is indeed feasible for modest genetic changes to have allowed the emergence of compositional language in humans.	[Schneider, Howard] Sheppard Clin North, Vaughan, ON, Canada		Schneider, H (corresponding author), Sheppard Clin North, Vaughan, ON, Canada.	hschneidermd@alum.mit.edu	Schneider, Howard/GXG-5503-2022	Schneider, Howard/0000-0001-8052-6448				Aboitiz F, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00174; Alme CB, 2014, P NATL ACAD SCI USA, V111, P18428, DOI 10.1073/pnas.1421056111; Amici F, 2022, INT J PRIMATOL, DOI 10.1007/s10764-022-00316-9; Anderson JR, 1996, AM PSYCHOL, V51, P355, DOI 10.1037/0003-066X.51.4.355; [Anonymous], 1984, Varieties of formal semantics; Ashraf S., 2020, Trends Comput. Sci. Inf. Technol, V5; Ashraf S., 2021, Iran J Comput Sci, V4, P171; Barsalou Lawrence W, 2020, J Cogn, V3, P31, DOI 10.5334/joc.116; Bernal B, 2009, BRAIN, V132, P2309, DOI 10.1093/brain/awp206; Binder JR, 2015, NEUROLOGY, V85, P2170, DOI 10.1212/WNL.0000000000002219; Bride H, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114806; Brincat SL, 2021, NEURON, V109, P1055, DOI 10.1016/j.neuron.2021.01.016; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brushe ME, 2020, BMC PEDIATR, V20, DOI 10.1186/s12887-020-1946-0; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buehlmann C, 2020, CURR BIOL, V30, P3438, DOI 10.1016/j.cub.2020.07.013; Butler AB, 2017, BRAIN BEHAV EVOLUT, V90, P7, DOI 10.1159/000475981; Butler AB, 2011, ANN NY ACAD SCI, V1225, P14, DOI 10.1111/j.1749-6632.2011.06006.x; Buxhoeveden DP, 2002, BRAIN, V125, P935, DOI 10.1093/brain/awf110; Caspar K. R., 2024, Preprints, P2024; Chakraborty M, 2015, PHILOS T R SOC B, V370, DOI 10.1098/rstb.2015.0056; Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413; Fahlman S. E, 1977, NETL: A system for representing and using real-world knowledge; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Fournier J, 2015, CURR OPIN NEUROBIOL, V31, P119, DOI 10.1016/j.conb.2014.09.006; Frege G., 1980, FDN ARITHMETIC; Furber S, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/051001; Güntürkün O, 2021, CURR OPIN NEUROBIOL, V71, P29, DOI 10.1016/j.conb.2021.08.007; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2; Hawkins J, 2019, FRONT NEURAL CIRCUIT, V12, DOI 10.3389/fncir.2018.00121; Hitzler P, 2022, NATL SCI REV, V9, DOI 10.1093/nsr/nwac035; Hofstadter DR, 2001, ANALOGICAL MIND, P499; INSAUSTI R, 1993, HIPPOCAMPUS, V3, P19; Jeon W, 2021, ADV COMPUT, V122, P167, DOI 10.1016/bs.adcom.2020.11.003; Jiang YC, 2021, Arxiv, DOI arXiv:2109.15256; Kaas JH, 2019, PROG BRAIN RES, V250, P61, DOI 10.1016/bs.pbr.2019.03.017; Kahn MC, 2009, EUR J NEUROSCI, V30, P1900, DOI 10.1111/j.1460-9568.2009.06979.x; Kautz HA, 2022, AI MAG, V43, P105, DOI 10.1002/aaai.12036; Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89; Kim N., 2021, Compositional linguistic generalization in artificial neural networks; Kinzler KD, 2007, PROG BRAIN RES, V164, P257, DOI 10.1016/S0079-6123(07)64014-X; Kocijan V, 2023, ARTIF INTELL-AMST, V325, DOI 10.1016/j.artint.2023.103971; Kotseruba I, 2020, ARTIF INTELL REV, V53, P17, DOI 10.1007/s10462-018-9646-y; Kracht M, 2013, STUD LOGICA, V101, P1319, DOI 10.1007/s11225-013-9535-y; Krempel R, 2019, PHILOS PAP, V48, P265, DOI 10.1080/05568641.2018.1463820; Kung TH, 2022, medRxiv, DOI [10.1101/2022.12.19.22283643, 10.1101/2022.12.19.22283643v2, DOI 10.1101/2022.12.19.22283643V2, 10.1101/2022.12.19.22283643, DOI 10.1101/2022.12.19.22283643]; Kwon K, 2014, IEICE T FUND ELECTR, VE97A, P1385, DOI 10.1587/transfun.E97.A.1385; Laird J. E., 2012, 26 AAAI C ARTIFICIAL; Laird JE, 2017, AI MAG, V38, P13, DOI 10.1609/aimag.v38i4.2744; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Levesque H., 2012, 13 INT C PRINCIPLES; Levine Y, 2021, Arxiv, DOI arXiv:2006.12467; Lieto A., 2021, Virtual International Symposium on Cognitive Architecture VISCA 2021; Lieto A., 2021, Cognitive Design for Artificial Minds, DOI DOI 10.4324/9781315460536; Lieto A, 2020, J EXP THEOR ARTIF IN, V32, P769, DOI 10.1080/0952813X.2019.1672799; Lieto A, 2019, COGN SYST RES, V58, P305, DOI 10.1016/j.cogsys.2019.08.005; Liska A, 2018, Arxiv, DOI arXiv:1802.06467; Marcus G., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.13807; Mikkelsen TS, 2005, NATURE, V437, P69, DOI 10.1038/nature04072; OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949; Olsen A., 2005, Journal of Computing Sciences in Colleges, V21, P231; Oña LS, 2019, PEERJ, V7, DOI 10.7717/peerj.7623; OpenAI, 2023, Introducing chatgpt; Pleyer M, 2022, INT J PRIMATOL, DOI 10.1007/s10764-022-00330-x; Rakic P, 2009, NAT REV NEUROSCI, V10, P724, DOI 10.1038/nrn2719; Rodríguez F, 2002, BRAIN RES BULL, V57, P499, DOI 10.1016/S0361-9230(01)00682-7; Rosenbloom Paul S., 2013, AISB Quarterly, P4; Ruis Laura, 2022, arXiv; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Samsonovich AV, 2012, BIOL INSPIR COGN ARC, V1, P100, DOI 10.1016/j.bica.2012.05.002; Samsonovich AV, 2010, FRONT ARTIF INTEL AP, V221, P195, DOI 10.3233/978-1-60750-661-4-195; Samsonovich AV, 2005, LEARN MEMORY, V12, P193, DOI 10.1101/lm.85205; Schafer M, 2018, NEURON, V100, P476, DOI 10.1016/j.neuron.2018.10.006; Schneider H, 2023, COGN SYST RES, V77, P174, DOI 10.1016/j.cogsys.2022.10.005; Schneider H, 2022, AI-BASEL, V3, P434, DOI 10.3390/ai3020026; Schneider H, 2022, COGN SYST RES, V72, P88, DOI 10.1016/j.cogsys.2021.10.004; Schneider H, 2021, COGN SYST RES, V66, P67, DOI 10.1016/j.cogsys.2020.10.021; Schneider H, 2020, COGN SYST RES, V59, P73, DOI 10.1016/j.cogsys.2019.09.019; Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z; Shahzad A., 2020, AIMS Electron. Electr. Eng, V4, P234; Shi XH, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3128571; SPELKE E, 1994, COGNITION, V50, P431, DOI 10.1016/0010-0277(94)90039-6; Striedter GF, 2016, J COMP NEUROL, V524, P496, DOI 10.1002/cne.23803; Szabo Z.G., 2020, STANFORD ENCY PHILOS; Taglialatela JP, 2008, CURR BIOL, V18, P343, DOI 10.1016/j.cub.2008.01.049; Topsakal O., 2023, INT C APPL ENG NATUR, V1, P1050; van Os J, 2001, ARCH GEN PSYCHIAT, V58, P663, DOI 10.1001/archpsyc.58.7.663; Van Rossum G, 2014, The Python Language Reference; Varma S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00440; Vaswani A, 2017, ADV NEUR IN, V30; Weber JN, 2013, NATURE, V493, P402, DOI 10.1038/nature11816; Winograd T., 1971, Procedures as a Representation for Data In a Computer Program For Understanding Natural Language; Wu L, 2021, CURR GENOMICS, V22, P496, DOI 10.2174/1389202923666211227143952; Xu K, 2015, MOL BIOL EVOL, V32, P1148, DOI 10.1093/molbev/msv031; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zuberbühler K, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0062	97	1	1	2	2	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2214-4366	1389-0417		COGN SYST RES	Cogn. Syst. Res.	AUG	2024	86								101215	10.1016/j.cogsys.2024.101215	http://dx.doi.org/10.1016/j.cogsys.2024.101215		MAR 2024	47	Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Neurosciences & Neurology; Psychology	OI4K8					2024-07-03	WOS:001206627700001
J	O'Halloran, K				O'Halloran, Kieran			Digital assemblages with AI for creative interpretation of short stories	DIGITAL SCHOLARSHIP IN THE HUMANITIES			English	Article						AI literacy; assemblage; corpus stylistics; creative interpretation of literature; diffractive reading; digital stylistics; distant reading; distant-diffractive reading; Edgar Allan Poe ('The Black Cat'); Large Language Model Generative AI; literary studies; short stories; stylistics	POE	I demonstrate an approach fostering inventive interpretation of short stories in Literary Studies and higher education generally. It involves constructing an 'assemblage'-at its simplest, an evolving network of unusual connections for creative outcome. The assemblage of this article combines freshly located research literature, directly and indirectly related to a story's themes, and/or the personality type of protagonists. Importantly, this assemblage also utilizes text analysis software revealing the relatively invisible (e.g. (in)frequent words, parts of speech, and topics) and Large Language Model (LLM) Generative AI to enrich the interpretation. The use of all these elements helps productively exceed initial intuitions about the story, facilitating creativity. I model the approach using Edgar Allan Poe's short story, The Black Cat, whose protagonist is a homicidal psychopath. Specifically, the assemblage here includes relevant software-based research (a corpus analysis of homicidal psychopathic language), non-software-based research (psychoanalytical literary criticism of The Black Cat using the empirically validated concept of transference), text analysis software (WMatrix and Datayze), and the LLM Generative AI, 'ChatGPT' (using the freely available LLM GPT-3.5). One use of this approach is as a pedagogy in Literary Studies employing text analysis software (e.g. on a digital stylistics course). Yet given creative adaptability is a key 21st-century skill, with digital literacy-including the use of Generative AI-an important contemporary competence, and with the short story genre universally known, I highlight too the utility of this approach as a university-wide pedagogy for enhancing creative thinking.	[O'Halloran, Kieran] Kings Coll London, Sch Educ Commun & Soc, Waterloo Bridge Wing, London, England; [O'Halloran, Kieran] Kings Coll London, Sch Educ Commun & Soc, Waterloo Bridge Wing,Franklin Wilkins Bldg,150 Sta, London SE1 9NH, England	University of London; King's College London; University of London; King's College London	O'Halloran, K (corresponding author), Kings Coll London, Sch Educ Commun & Soc, Waterloo Bridge Wing,Franklin Wilkins Bldg,150 Sta, London SE1 9NH, England.	kieran.o'halloran@kcl.ac.uk		O'Halloran, Kieran/0000-0003-3424-994X				Ajana B., 2018, SELF TRACKING; Barad K., 2007, M UNIVERSE HALFWAY Q; Bliss AV, 2009, EXPLICATOR, V67, P96, DOI 10.3200/EXPL.67.2.96-99; Buday M., 2014, ENGLISH MATTERS, P11; Cook Guy., 1994, Discourse and literature; Culpeper J, 2014, ROUTL ADV CORPUS LIN, V16, P9; Culpeper Jonathan., 2001, LANGUAGE CHARACTERIS; Davidson CathyN., 2017, NEW ED; DeLanda Manuel., 2016, Assemblage Theory; Deleuze G., 1987, 1000 PLATEAUS CAPITA, P1980; Deleuze Gilles., 1994, WHAT IS PHILOS; Deleuze Gilles., 1987, DIALOGUES; Duff C, 2017, ORGANIZATION, V24, P418, DOI 10.1177/1350508416687765; Ellmann M., 2013, PSYCHOANALYTICAL LIT; Gregoriou C, 2011, ROUT STUD RHETORIC, P1; Hancock JT, 2013, LEGAL CRIMINOL PSYCH, V18, P102, DOI 10.1111/j.2044-8333.2011.02025.x; Harari Y. N., 2018, 21 Lessons for the 21st Century; Hare R.D., 1999, Without conscience: The disturbing world of the psychopaths among us; Harford T., 2016, Messy; Hester V, 2014, EDGAR ALLAN POE REV, V15, P175, DOI 10.5325/edgallpoerev.15.2.0175; Heuser R., 2024, EMOTIONS LONDON, V13; Hickey-Moody A, 2016, GENDER EDUC, V28, P213, DOI 10.1080/09540253.2016.1140723; Jockers ML, 2013, TOP DIGIT HUM, P1; Judkins R., 2013, CHANGE YOUR MIND 57; Judkins R., 2015, ART CREATIVE THINKIN; Kivunja C., 2014, International Journal of Higher Education, V3, P37, DOI DOI 10.5430/IJHE.V3N4P37; Livesey Graham., 2010, The Deleuze Dictionary, P18; Lucas B., 2017, Teaching Creative Thinking: Developing learners who generate ideas and can think critically; Lupton D, 2018, BIG DATA SOC, V5, DOI 10.1177/2053951718786314; Mahlberg M., 2013, CORPUS STYLISTICS DI; MATHESON TJ, 1986, MOSAIC, V19, P69; Mazzei LA, 2014, QUAL INQ, V20, P742, DOI 10.1177/1077800414530257; McAvoy LizHerbert., 2010, Anchoritic Traditions of Medieval Europe; McIntyre D., 2019, CORPUS STYLISTICS; Moretti Franco., 2013, Distant Reading; Nail T, 2017, SUB-STANCE, V46, P21, DOI 10.3368/ss.46.1.21; O'Halloran K.A., 2006, ART ENGLISH LIT CREA, P94; O'Halloran K.A., 2022, ROUTLEDGE HDB CORPUS, P675; Penprase B.E, 2018, Higher education in the era of the fourth industrial revolution, P207, DOI DOI 10.1007/978-981-13-0194-0_9; Popper K., 1963, CONJECTURES REFUTAT; Pugh G., 2019, PSYCHOTHERAPY MEETS; Rayson P., 2008, International Journal of Corpus Linguistics, V13, P519, DOI [DOI 10.1075/IJCL.13.4.06RAY, https://doi.org/10.1075/ijcl.13.4.06ray]; Robinson K., 2011, Out of our minds, V2; Roth M., 2019, PSYCHOANALYTIC PERSP; Schwab K., 2016, 4 IND REVOLUTION WHA; Sehgal M, 2014, PARALLAX, V20, P188, DOI 10.1080/13534645.2014.927625; Stockwell P., 2020, COGNITIVE POETICS; Taylor CA, 2018, INT J QUAL STUD EDUC, V31, P465, DOI 10.1080/09518398.2017.1422286; Trilling B., 2009, 21st century skills	49	0	0	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	2055-7671	2055-768X		DIGIT SCHOLARSH HUM	Digit. Scholarsh. Humanit.	MAR 6	2024	39	2					657	689		10.1093/llc/fqad050	http://dx.doi.org/10.1093/llc/fqad050		MAR 2024	33	Humanities, Multidisciplinary; Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; Linguistics	UN3Z8		hybrid			2024-07-03	WOS:001179470400001
J	Zhuang, YG; Kang, YH; Fei, T; Bian, M; Du, YY				Zhuang, Yonggai; Kang, Yuhao; Fei, Teng; Bian, Meng; Du, Yunyan			From hearing to seeing: Linking auditory and visual place perceptions with soundscape-to-image generative artificial intelligence	COMPUTERS ENVIRONMENT AND URBAN SYSTEMS			English	Article						Soundscape; Street view images; Sense of place; Stable diffusion; Generative AI; LLMs	DESIGN; NOISE; LANDSCAPE; FEATURES; SENSE	People experience the world through multiple senses simultaneously, contributing to our sense of place. Prior quantitative geography studies have mostly emphasized human visual perceptions, neglecting human auditory perceptions at place due to the challenges in characterizing the acoustic environment vividly. Also, few studies have synthesized the two-dimensional (auditory and visual) perceptions in understanding human sense of place. To bridge these gaps, we propose a Soundscape-to-Image Diffusion model, a generative Artificial Intelligence (AI) model supported by Large Language Models (LLMs), aiming to visualize soundscapes through the generation of street view images. By creating audio-image pairs, acoustic environments are first represented as highdimensional semantic audio vectors. Our proposed Soundscape-to-Image Diffusion model, which contains a Low-Resolution Diffusion Model and a Super-Resolution Diffusion Model, can then translate those semantic audio vectors into visual representations of place effectively. We evaluated our proposed model by using both machine-based and human-centered approaches. We proved that the generated street view images align with our common perceptions, and accurately create several key street elements of the original soundscapes. It also demonstrates that soundscapes provide sufficient visual information places. This study stands at the forefront of the intersection between generative AI and human geography, demonstrating how human multi-sensory experiences can be linked. We aim to enrich geospatial data science and AI studies with human experiences. It has the potential to inform multiple domains such as human geography, environmental psychology, and urban design and planning, as well as advancing our knowledge of human-environment relationships.	[Zhuang, Yonggai; Fei, Teng] Wuhan Univ, Sch Resource & Environm Sci, Wuhan, Peoples R China; [Kang, Yuhao] Univ South Carolina, Dept Geog, GISense Lab, Columbia, SC 29208 USA; [Kang, Yuhao; Du, Yunyan] Univ South Carolina, Ctr GISci & Geospatial Big Data, Columbia, SC USA; [Bian, Meng] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China; [Fei, Teng] State Key Lab Resources & Environm Informat Syst, Beijing, Peoples R China; [Kang, Yuhao] Univ Texas Austin, Dept Geog & Environm, Austin, TX 78712 USA	Wuhan University; University of South Carolina System; University of South Carolina Columbia; University of South Carolina System; University of South Carolina Columbia; Wuhan University; University of Texas System; University of Texas Austin	Fei, T (corresponding author), Wuhan Univ, Sch Resource & Environm Sci, Wuhan, Peoples R China.; Kang, YH (corresponding author), Univ South Carolina, Dept Geog, GISense Lab, Columbia, SC 29208 USA.	2019301030116@whu.edu.cn; yuhaokang@sc.edu; feiteng@whu.edu.cn; bian@whu.edu.cn; duyy@lreis.ac.cn			National Natural Science Foundation of China [42271476]; Wuhan University; Key Laboratory of Resources and Environmental Information System	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Wuhan University; Key Laboratory of Resources and Environmental Information System	We acknowledge the support by grants from the National Natural Science Foundation of China under grant number 42271476 (TF), the 351 Talent Project of Wuhan University (TF), and the Key Laboratory of Resources and Environmental Information System (TF & YD), all of which have been instrumental in facilitating our project's success. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author (s) and do not necessarily reflect the views of the funders.	Agnew J., 2011, Space and Place; Agostinelli A., 2023, Musiclm: Generating music from text; Aiello LM, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.150690; Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043; Bhandari U, 2019, INFORM MANAGE-AMSTER, V56, P85, DOI 10.1016/j.im.2018.07.003; Bilasco S, 2017, FRONT EARTH SCI-PRC, V11, P214, DOI 10.1007/s11707-017-0615-6; Brooks B., 2014, Acoust. Today, V10, P30; Buxton RT, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2013097118; Cain R, 2013, APPL ACOUST, V74, P232, DOI 10.1016/j.apacoust.2011.11.006; Chen W, 2023, IET CONTROL THEORY A, V17, P1955, DOI 10.1049/cth2.12518; Clement J, 2013, J RETAIL CONSUM SERV, V20, P234, DOI 10.1016/j.jretconser.2013.01.003; Cosgrove D., 2003, Landscape and the european sense of sight-eyeing nature; Cresswell T., 2014, Place: An Introduction; D'Alessandro F, 2018, BUILD ACOUST, V25, P199, DOI 10.1177/1351010X18778759; Dunkel A, 2015, LANDSCAPE URBAN PLAN, V142, P173, DOI 10.1016/j.landurbplan.2015.02.022; Eronen AJ, 2006, IEEE T AUDIO SPEECH, V14, P321, DOI 10.1109/TSA.2005.854103; Fischer J, 2014, NAT NEUROSCI, V17, P738, DOI 10.1038/nn.3689; Fuller S, 2015, ECOL INDIC, V58, P207, DOI 10.1016/j.ecolind.2015.05.057; Gao S., 2021, User-generated content: A promising data source for urban informatics; Girdhar R, 2023, PROC CVPR IEEE, P15180, DOI 10.1109/CVPR52729.2023.01457; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Han J., 2023, ImageBind-LLM: Multi-modality instruction tuning; Ho JAT, 2020, Arxiv, DOI [arXiv:2006.11239, DOI 10.48550/ARXIV.2006.11239]; HOLMES CR, 1971, J GEOPHYS RES, V76, P2106, DOI 10.1029/JC076i009p02106; Hong JY, 2019, BUILD ENVIRON, V149, P1, DOI 10.1016/j.buildenv.2018.12.004; Hopkins JM, 2022, BIOL INVASIONS, V24, P3381, DOI 10.1007/s10530-022-02856-w; Huang J, 2024, INT J GEOGR INF SCI, V38, P128, DOI 10.1080/13658816.2023.2274475; Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500; Jeon JY, 2020, BUILD ENVIRON, V169, DOI 10.1016/j.buildenv.2019.106544; Jeon JY, 2015, LANDSCAPE URBAN PLAN, V141, P100, DOI 10.1016/j.landurbplan.2015.05.005; Jo HI, 2020, BUILD ENVIRON, V179, DOI 10.1016/j.buildenv.2020.106975; Kang Y., 2019, Extracting human emotions at different places based on facial expressions and spatial clustering analysis; Kang YH, 2024, CARTOGR GEOGR INF SC, DOI 10.1080/15230406.2023.2295943; Kang YH, 2023, LANDSCAPE URBAN PLAN, V236, DOI 10.1016/j.landurbplan.2023.104768; Kang YH, 2021, CITIES, V118, DOI 10.1016/j.cities.2021.103333; Kang YH, 2019, INT J CARTOGRAPHY, V5, P115, DOI 10.1080/23729333.2019.1615729; Kedron P, 2021, GEOGR ANAL, V53, P135, DOI 10.1111/gean.12221; Keyel AC, 2017, ENVIRON MODELL SOFTW, V97, P56, DOI 10.1016/j.envsoft.2017.07.008; Landeschi G, 2016, J ARCHAEOL SCI, V65, P103, DOI 10.1016/j.jas.2015.11.002; Lee S., 2023, Diffusion explainer: Visual explanation for text-to-image stable diffusion; Lillis A, 2014, MAR ECOL PROG SER, V505, P1, DOI 10.3354/meps10805; Manzo LC, 2003, J ENVIRON PSYCHOL, V23, P47, DOI 10.1016/S0272-4944(02)00074-9; Marchegiani Letizia, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6547, DOI 10.1109/ICRA.2017.7989774; Martin B, 2018, ORGAN SOUND, V23, P20, DOI 10.1017/S1355771817000243; Michael I, 2019, J ISLAMIC MARK, V10, P543, DOI 10.1108/JIMA-09-2017-0098; Minelli A, 2014, ENVIRON IMPACT ASSES, V49, P70, DOI 10.1016/j.eiar.2014.07.002; Moliner E., 2023, Solving audio inverse problems with a diffusion model; Nichol A. Q., 2021, INT C MACH LEARN, P8162; Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356; Oppenheim AV, 2004, IEEE SIGNAL PROC MAG, V21, P95, DOI 10.1109/MSP.2004.1328092; Oppenlaender J., 2022, P 25 INT AC MINDTR C; Park Tae Hong, 2014, ICMC; Phillips Y., 2017, Visualization of environmental audio using ribbon plots and acoustic state sequences; Pijanowski BC, 2011, BIOSCIENCE, V61, P203, DOI 10.1525/bio.2011.61.3.6; Pocock D., 1974, Progress in human geography-Prog Hum Geogr, V18, P355; PRESTIGIACOMO AJ, 1962, J ACOUST SOC AM, V34, P1684, DOI 10.1121/1.1909092; Primeau KE, 2018, J ARCHAEOL SCI-REP, V19, P875, DOI 10.1016/j.jasrep.2017.05.044; Ramesh A., 2022, Hierarchical textconditional image generation with CLIP Latents; Raymond CM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01674; Ren XX, 2023, LANDSCAPE URBAN PLAN, V238, DOI 10.1016/j.landurbplan.2023.104839; Reynaud H., 2023, Feature-conditioned cascaded video diffusion models for precise echocardiogram synthesis; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Sacchelli S, 2019, FORESTS, V10, DOI 10.3390/f10090731; Saharia C., 2022, Photorealistic text-to-image diffusion models with deep language understanding; Sang AO, 2016, URBAN FOR URBAN GREE, V18, P268, DOI 10.1016/j.ufug.2016.06.008; Schafer R. M., 1977, The tuning of the world: Toward a theory of soundscape design; Schreuder E, 2016, SAGE OPEN, V6, DOI 10.1177/2158244016630591; Schulte-Fortkamp B, 2006, ACTA ACUST UNITED AC, V92, P875; Shaw S.-L., 2021, Mapping COVID-19 in space and time understanding the spatial and temporal dynamics of a global pandemic: Understanding the spatial and temporal dynamics of a global pandemic; Smith S, 2015, TOUR RECREAT RES, V40, P220, DOI 10.1080/02508281.2015.1049814; Spence C, 2020, COGN RES, V5, DOI 10.1186/s41235-020-00243-4; Tan JKA, 2022, APPL ACOUST, V189, DOI 10.1016/j.apacoust.2021.108580; Tuan Y.-F., 1975, SERBIULA (sistema Librum, V2, P65; Tuan Y.F., 1974, TOPOPHILIA, DOI 10.2307/1424328; Watts G, 2016, APPL ACOUST, V104, P135, DOI 10.1016/j.apacoust.2015.11.007; Williams A., 2023, Sound-and-image-informed music artwork generation using text-to-image models; Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702; Wrózynski R, 2016, RENEW ENERG, V96, P625, DOI 10.1016/j.renene.2016.05.016; Wu H.-H., 2021, Wav2CLIP: Learning robust audio representations from CLIP; Wu ZR, 2023, REMOTE SENS ENVIRON, V290, DOI 10.1016/j.rse.2023.113545; Xu XW, 2021, EUR J REMOTE SENS, V54, P383, DOI 10.1080/22797254.2020.1790995; Yang L., 2023, ACM computing surveys; Yildirim Y, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141811508; Yurtkulu Salih Can, 2019, Semantic segmentation with extended DeepLabv3 architecture, 2019; Zhao TH, 2023, COMPUT ENVIRON URBAN, V99, DOI 10.1016/j.compenvurbsys.2022.101915; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0	86	0	0	2	2	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0198-9715	1873-7587		COMPUT ENVIRON URBAN	Comput. Environ. Urban Syst.	JUN	2024	110								102122	10.1016/j.compenvurbsys.2024.102122	http://dx.doi.org/10.1016/j.compenvurbsys.2024.102122			12	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research & Management Science; Regional & Urban Planning	Social Science Citation Index (SSCI)	Computer Science; Engineering; Environmental Sciences & Ecology; Geography; Operations Research & Management Science; Public Administration	SY9X7					2024-07-03	WOS:001238140000001
J	Marchi, F; Bellini, E; Iandelli, A; Sampieri, C; Peretti, G				Marchi, Filippo; Bellini, Elisa; Iandelli, Andrea; Sampieri, Claudio; Peretti, Giorgio			Exploring the landscape of AI-assisted decision-making in head and neck cancer treatment: a comparative analysis of NCCN guidelines and ChatGPT responses	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						Machine learning; Artificial intelligence (AI) models; ChatGPT; Cancer care; National Comprehensive Cancer Network (NCCN) Guidelines; Head and neck cancers		PurposeRecent breakthroughs in natural language processing and machine learning, exemplified by ChatGPT, have spurred a paradigm shift in healthcare. Released by OpenAI in November 2022, ChatGPT rapidly gained global attention. Trained on massive text datasets, this large language model holds immense potential to revolutionize healthcare. However, existing literature often overlooks the need for rigorous validation and real-world applicability.MethodsThis head-to-head comparative study assesses ChatGPT's capabilities in providing therapeutic recommendations for head and neck cancers. Simulating every NCCN Guidelines scenarios. ChatGPT is queried on primary treatments, adjuvant treatment, and follow-up, with responses compared to the NCCN Guidelines. Performance metrics, including sensitivity, specificity, and F1 score, are employed for assessment.ResultsThe study includes 68 hypothetical cases and 204 clinical scenarios. ChatGPT exhibits promising capabilities in addressing NCCN-related queries, achieving high sensitivity and overall accuracy across primary treatment, adjuvant treatment, and follow-up. The study's metrics showcase robustness in providing relevant suggestions. However, a few inaccuracies are noted, especially in primary treatment scenarios.ConclusionOur study highlights the proficiency of ChatGPT in providing treatment suggestions. The model's alignment with the NCCN Guidelines sets the stage for a nuanced exploration of AI's evolving role in oncological decision support. However, challenges related to the interpretability of AI in clinical decision-making and the importance of clinicians understanding the underlying principles of AI models remain unexplored. As AI continues to advance, collaborative efforts between models and medical experts are deemed essential for unlocking new frontiers in personalized cancer care.	[Marchi, Filippo; Bellini, Elisa; Iandelli, Andrea; Peretti, Giorgio] IRCCS Osped Policlin San Martino, Unit Otorhinolaryngol Head & Neck Surg, Largo Rosanna Benzi 10, I-16132 Genoa, Italy; [Marchi, Filippo; Bellini, Elisa; Peretti, Giorgio] Univ Genoa, Dept Surg Sci & Integrated Diagnost DISC, I-16132 Genoa, Italy; [Sampieri, Claudio] Univ Genoa, Dept Expt Med DIMES, Genoa, Italy; [Sampieri, Claudio] Hosp Clin Univ, Dept Otolaryngol, Barcelona, Spain; [Sampieri, Claudio] Hosp Clin Barcelona, Funct Unit Head Neck Tumors, Barcelona, Spain	University of Genoa; University of Genoa; University of Barcelona; Hospital Clinic de Barcelona; University of Barcelona; Hospital Clinic de Barcelona	Bellini, E (corresponding author), IRCCS Osped Policlin San Martino, Unit Otorhinolaryngol Head & Neck Surg, Largo Rosanna Benzi 10, I-16132 Genoa, Italy.; Bellini, E (corresponding author), Univ Genoa, Dept Surg Sci & Integrated Diagnost DISC, I-16132 Genoa, Italy.	e.e.elisabellini@gmail.com	Sampieri, Claudio/GQQ-1121-2022	Sampieri, Claudio/0000-0002-7699-2291				[Anonymous], 2024, NCCN CLIN PRACTICE G, P1; Azam MA, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.900451; Azam MA, 2022, LARYNGOSCOPE, V132, P1798, DOI 10.1002/lary.29960; Barbour AB, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.44541; Benary M, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.43689; Braun EM, 2024, ARCH GYNECOL OBSTET, V309, P1543, DOI 10.1007/s00404-023-07272-6; Brom L, 2014, BMC MED INFORM DECIS, V14, DOI 10.1186/1472-6947-14-25; Bullock MJ, 2019, ARCH PATHOL LAB MED, V143, P452, DOI 10.5858/arpa.2018-0421-SA; Chavez MR, 2023, AM J OBSTET GYNECOL, V228, P706, DOI 10.1016/j.ajog.2023.03.010; Cheong RCT, 2024, EUR ARCH OTO-RHINO-L, V281, P985, DOI 10.1007/s00405-023-08319-9; Choo JM, 2024, ANZ J SURG, V94, P356, DOI 10.1111/ans.18749; Chung CW, 2024, BIODATA MIN, V17, DOI 10.1186/s13040-023-00352-y; Dallari V, 2024, EUR ARCH OTO-RHINO-L, V281, P995, DOI 10.1007/s00405-023-08321-1; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Davis RJ, 2024, LARYNGOSCOPE, V134, P2252, DOI 10.1002/lary.31191; Decker H, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36997; Devi KG, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/670739; Ferreira Alana L, 2023, JMIR Dermatol, V6, pe49280, DOI 10.2196/49280; Ferres JML, 2023, DIAGN INTERV IMAG, V104, P263, DOI 10.1016/j.diii.2023.02.006; Gabriel J, 2024, BJU INT, V133, P407, DOI 10.1111/bju.16240; Griewing S, 2023, J PERS MED, V13, DOI 10.3390/jpm13101502; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Hueso M, 2023, REV INVEST CLIN, V75, P309, DOI 10.24875/RIC.23000162; Jabbour J, 2018, PATIENT EDUC COUNS, V101, P1736, DOI 10.1016/j.pec.2018.05.023; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lewis JS, 2019, ARCH PATHOL LAB MED, V143, P447, DOI 10.5858/arpa.2018-0405-SA; Lukac S, 2023, ARCH GYNECOL OBSTET, V308, P1831, DOI 10.1007/s00404-023-07130-5; Lydiatt WM., 2017, AJCC Cancer Staging Manual, DOI [10.1007/978-3-319-40618-3_5, DOI 10.1007/978-3-319-40618-3_5]; Marchi F, 2023, ORAL ONCOL, V138, DOI 10.1016/j.oraloncology.2023.106312; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Miller MC, 2016, JAMA OTOLARYNGOL, V142, P1002, DOI 10.1001/jamaoto.2016.1615; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Nune A, 2023, RHEUMATOL INT, V43, P1379, DOI 10.1007/s00296-023-05340-3; Pagano S, 2023, J ORTHOP TRAUMATOL, V24, DOI 10.1186/s10195-023-00740-4; Popovic D, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13182862; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sampieri C, 2024, LARYNGOSCOPE, V134, P2826, DOI 10.1002/lary.31255; Sampieri C, 2023, OTOLARYNG HEAD NECK, V169, P811, DOI 10.1002/ohn.343; Sanchez-Ramos L, 2023, AM J OBSTET GYNECOL, V229, P356, DOI 10.1016/j.ajog.2023.04.004; Stone A, 2024, LARYNGOSCOPE, V134, P708, DOI 10.1002/lary.30909; Sun HA, 2023, J MED INTERNET RES, V25, DOI 10.2196/51300; Vadhwana B, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13203267; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324; Yoshiyasu Y, 2023, INT FORUM ALLERGY RH, V13, P2231, DOI 10.1002/alr.23201; Yue TW, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242115858; Zhou SN, 2024, ABDOM RADIOL, V49, P3, DOI 10.1007/s00261-023-04029-2	47	2	2	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	APR	2024	281	4					2123	2136		10.1007/s00405-024-08525-z	http://dx.doi.org/10.1007/s00405-024-08525-z		FEB 2024	14	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	LQ7A3	38421392				2024-07-03	WOS:001172712200001
J	Fijacko, N; Creber, RM; Abella, BS; Kocbek, P; Metlicar, S; Greif, R; Stiglic, G				Fijacko, Nino; Creber, Ruth Masterson; Abella, Benjamin S.; Kocbek, Primoz; Metlicar, Spela; Greif, Robert; Stiglic, Gregor			Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses	RESUSCITATION PLUS			English	Article						Emergency medicine; European Resuscitation Council; Congress; Bibliometrics analysis; Generative artificial intelligence	COUNCIL GUIDELINES; CARDIAC-ARREST; EMERGENCY	Aims: The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade. Methods: In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics. Results: From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence. Conclusion: This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.	[Fijacko, Nino; Kocbek, Primoz; Metlicar, Spela; Stiglic, Gregor] Univ Maribor, Fac Hlth Sci, Maribor 3000, Slovenia; [Fijacko, Nino; Greif, Robert] ERC Res Net, Niels, Belgium; [Fijacko, Nino] Univ Maribor, Med Ctr, Maribor, Slovenia; [Creber, Ruth Masterson] Columbia Univ, Sch Nursing, New York, NY USA; [Abella, Benjamin S.] Univ Penn, Ctr Resuscitat Sci, Philadelphia, PA USA; [Abella, Benjamin S.] Univ Penn, Dept Emergency Med, Philadelphia, PA USA; [Kocbek, Primoz] Univ Ljubljana, Fac Med, Ljubljana, Slovenia; [Metlicar, Spela] Univ Clin Ctr Ljubljana, Med Dispatch Ctr Maribor, Ljubljana, Slovenia; [Greif, Robert] Univ Bern, Bern, Switzerland; [Greif, Robert] Sigmund Freud Univ Vienna, Sch Med, Vienna, Austria; [Greif, Robert] Univ Maribor, Fac Elect Engn & Comp Sci, Maribor, Slovenia; [Stiglic, Gregor] Univ Edinburgh, Usher Inst, Edinburgh, Scotland	University of Maribor; University of Maribor; Columbia University; University of Pennsylvania; University of Pennsylvania; University of Ljubljana; University Medical Centre Ljubljana; University of Bern; University of Maribor; University of Edinburgh	Fijacko, N (corresponding author), Univ Maribor, Fac Hlth Sci, Maribor 3000, Slovenia.	nino.fijacko@um.si		Metlicar, Spela/0009-0007-4051-1736	Slovenian Research Agency [ARRS P2-0057, ARRS N3-0307, ARRS BI-US/22-24-138, C3330-22-953012]; National Institutes of Health [R01HL161458, R01NS123639, R01HL152021]; Department of Defense; Becton Dickinson; Zoll; Stryker; Patient-Centered Outcomes Research Insti tute (PCORI)	Slovenian Research Agency(Slovenian Research Agency - Slovenia); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Department of Defense(United States Department of Defense); Becton Dickinson; Zoll; Stryker; Patient-Centered Outcomes Research Insti tute (PCORI)(Patient-Centered Outcomes Research Institute - PCORI)	Nino Fija & ccaron;ko, Primo & zcaron; Kocbek, and Gregor Stiglic are supported by Slovenian Research Agency grants ARRS P2-0057, ARRS N3-0307, ARRS BI-US/22-24-138, NextGenerationEU and MVZI (C3330-22-953012) . Benjamin S. Abella has received research funding from the National Institutes of Health, the Department of Defense, and Becton Dickinson. He has served as a paid consultant to Becton Dickinson, Zoll and Stryker. He holds equity in MDAlly and VOCHealth. Ruth Masterson Creber receives research funding from the National Institutes of Health (R01HL161458, R01NS123639, R01HL152021) and the Patient-Centered Outcomes Research Insti tute (PCORI) .	[Anonymous], Generative Pre-trained Transformer 4 (GPT-4) application programming interface; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Barbic D, 2016, ACAD EMERG MED, V23, P251, DOI 10.1111/acem.12898; Choudhri AF, 2015, RADIOGRAPHICS, V35, P736, DOI 10.1148/rg.2015140036; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Gräsner JT, 2021, RESUSCITATION, V161, P61, DOI 10.1016/j.resuscitation.2021.02.007; Greif R, 2021, RESUSCITATION, V161, P388, DOI 10.1016/j.resuscitation.2021.02.016; HOLMBERG S, 1992, RESUSCITATION, V24, P103, DOI 10.1016/0300-9572(92)90015-5; Jia TY, 2020, MED SCI MONITOR, V26, DOI 10.12659/MSM.926815; Kirtania DK, 2023, ChatGPT as a tool for bibliometrics analysis: interview with ChatGPT, DOI [10.2139/ssrn.4391794, DOI 10.2139/SSRN.4391794]; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Lott C, 2021, RESUSCITATION, V161, P152, DOI 10.1016/j.resuscitation.2021.02.011; Madar J, 2021, RESUSCITATION, V161, P291, DOI 10.1016/j.resuscitation.2021.02.014; Mentzelopoulos SD, 2021, RESUSCITATION, V161, P408, DOI 10.1016/j.resuscitation.2021.02.017; Nakaya Y, 2023, EUR HEART J-DIGIT HL, V4, P141, DOI 10.1093/ehjdh/ztad026; Nolan JP, 2021, RESUSCITATION, V161, P220, DOI 10.1016/j.resuscitation.2021.02.012; Nolan JP, 2010, RESUSCITATION, V81, P1219, DOI 10.1016/j.resuscitation.2010.08.021; Olasveengen TM, 2021, RESUSCITATION, V161, P98, DOI 10.1016/j.resuscitation.2021.02.009; Perkins GD, 2021, RESUSCITATION, V161, P1, DOI 10.1016/j.resuscitation.2021.02.003; PRITCHARD A, 1969, J DOC, V25, P348; R Foundation for Statistical Computing, About Us; Rodrigues SP, 2014, BMJ OPEN, V4, DOI 10.1136/bmjopen-2013-004468; Semeraro F, 2021, RESUSCITATION, V161, P80, DOI 10.1016/j.resuscitation.2021.02.008; Soar J, 2021, RESUSCITATION, V161, P115, DOI 10.1016/j.resuscitation.2021.02.010; Van de Voorde P, 2021, RESUSCITATION, V161, P327, DOI 10.1016/j.resuscitation.2021.02.015; Webhook, about Us; Xu L, 2021, AM J TRANSL RES, V13, P1109; Zideman DA, 2021, RESUSCITATION, V161, P270, DOI 10.1016/j.resuscitation.2021.02.013	28	1	1	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-5204			RESUSC PLUS	Resusc. Plus	JUN	2024	18								100584	10.1016/j.resplu.2024.100584	http://dx.doi.org/10.1016/j.resplu.2024.100584		FEB 2024	5	Critical Care Medicine; Emergency Medicine	Emerging Sources Citation Index (ESCI)	General & Internal Medicine; Emergency Medicine	MG0W0	38420596	hybrid			2024-07-03	WOS:001192365400001
C	Huang, Q; Wan, ZY; Xing, ZC; Chen, JJ; Chen, JS; Xu, XW; Lu, QH			IEEE	Huang, Qing; Wan, Zhenyu; Xing, Zhenchang; Wang, Changjing; Chen, Jieshan; Xu, Xiwei; Lu, Qinghua			Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		API recommendation; query clarification; knowledge graph; large language model; out-of-vocabulary	SEARCH	API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.	[Huang, Qing; Wan, Zhenyu; Wang, Changjing] Jiangxi Normal Univ, Nanchang, Jiangxi, Peoples R China; [Xing, Zhenchang; Chen, Jieshan; Xu, Xiwei; Lu, Qinghua] CSIROs Data61, Canberra, ACT, Australia; [Xing, Zhenchang] Australian Natl Univ, Canberra, ACT, Australia	Jiangxi Normal University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian National University	Huang, Q (corresponding author), Jiangxi Normal Univ, Nanchang, Jiangxi, Peoples R China.	qh@whu.edu.cn; wanzy@jxnu.edu.cn; zhenchang.xing@data61.csiro.au; wcj@jxnu.edu.cn; jieshan.chen@data61.csiro.au; xiwei.xu@data61.csiro.au; qinghua.lu@data61.csiro.au	Chen, Jieshan/AAA-5470-2022; Lu, Qinghua/AAG-3378-2021; Wan, Zhenyu/HNJ-3060-2023; Xu, Xiwei/AAD-6098-2020	Chen, Jieshan/0000-0002-2700-7478; 	National Nature Science Foundation of China [62262031]; Cultivation Project for Academic and Technical Leader in Major Disciplines in Jiangxi Province [20232BCJ22013]; Science and Technology Key Project of the Education Department of Jiangxi Province [GJJ2200302]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Cultivation Project for Academic and Technical Leader in Major Disciplines in Jiangxi Province; Science and Technology Key Project of the Education Department of Jiangxi Province	The work is partly supported by the National Nature Science Foundation of China under Grant (Nos. 62262031), Cultivation Project for Academic and Technical Leader in Major Disciplines in Jiangxi Province (20232BCJ22013), and the Science and Technology Key Project of the Education Department of Jiangxi Province (GJJ2200302).	Asaduzzaman M, 2015, PROC IEEE INT CONF S, P271, DOI 10.1109/ICSM.2015.7332473; Bajracharya Sushil, 2010, P 2010 ICSE WORKSH S, P5; Basse L, 2000, ANN SURG, V232, P51, DOI 10.1097/00000658-200007000-00008; Blackwell Alan F, 2000, P 12 ANN WORKSH PSYC, V13; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao KB, 2021, PROC INT CONF SOFTW, P1273, DOI 10.1109/ICSE43902.2021.00116; Chen C, 2022, IEEE T SOFTWARE ENG, V48, P2987, DOI 10.1109/TSE.2021.3074309; Datta S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1996; Le D, 2021, IEEE W SP LANG TECH, P251, DOI 10.1109/SLT48900.2021.9383560; Eberhart Z, 2022, EUR CON SFTWR MTNCE, P140, DOI 10.1109/SANER53432.2022.00028; Eberhart Z, 2021, PROC IEEE INT CONF S, P274, DOI 10.1109/ICSME52107.2021.00031; Gallant M, 2019, P INT COMP SOFTW APP, P443, DOI 10.1109/COMPSAC.2019.00070; Groth P, 2014, J WEB SEMANT, V29, P12, DOI 10.1016/j.websem.2014.03.003; Gu XD, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P631, DOI 10.1145/2950290.2950334; He XC, 2021, PROC INT CONF SOFTW, P1634, DOI 10.1109/ICSE43902.2021.00145; Hssina B., 2014, International Journal of Advanced Computer Science and Applications, Special Issue on Advances in Vehicular Ad Hoc Networking and Applications, vol, V4, n, P13; Huang Q, 2018, IEEE INT CONF AUTOM, P293, DOI 10.1145/3238147.3238191; Huang Q, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556912; Huang Q, 2023, Arxiv, DOI arXiv:2304.14163; Huang Q, 2023, Arxiv, DOI arXiv:2207.05560; Huang Q, 2022, Arxiv, DOI arXiv:2212.08221; Huang Qing, 2022, IEEE Transactions on Services Computing; Jannach D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453154; Karampatsis RM, 2020, PROC INT CONF SOFTW, P1073, DOI 10.1145/3377811.3380342; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Li HW, 2018, PROC IEEE INT CONF S, P183, DOI 10.1109/ICSME.2018.00028; Ling CY, 2019, J COMPUT SCI TECH-CH, V34, P993, DOI 10.1007/s11390-019-1956-2; Liu C, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3480027; Liu Y, 2020, IEEE INT CONF AUTOM, P834, DOI 10.1145/3324884.3416628; Luccioni A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P182; Lv F, 2015, IEEE INT CONF AUTOM, P260, DOI 10.1109/ASE.2015.42; Manning Christopher, 2010, Natural Language Engineering, V16, P100, DOI DOI 10.1017/S1351324909005129; Morton K, 2019, BIOINFORMATICS, V35, P5382, DOI 10.1093/bioinformatics/btz604; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, Introducing ChatGPT and whisper APIs; OpenAI, 2023, Gpt-4 technical report, pVI; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Radev Dragomir R., 2002, P 3 INT C LANGUAGE R; Rahman MM, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P349, DOI 10.1109/SANER.2016.80; Ren XH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P808, DOI 10.1145/3404835.3462839; Sharath JS, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206698; Stylos J, 2006, IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P195; Thung F, 2016, IEEE INT CONF AUTOM, P896, DOI 10.1145/2970276.2975940; Thung F, 2013, IEEE INT CONF AUTOM, P290, DOI 10.1109/ASE.2013.6693088; Ulrich Hannes, 2020, Stud Health Technol Inform, V275, P202, DOI 10.3233/SHTI200723; Verborgh R, 2016, J WEB SEMANT, V37-38, P184, DOI 10.1016/j.websem.2016.03.003; Wan Y, 2022, PROC INT CONF SOFTW, P2377, DOI 10.1145/3510003.3510050; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Zhang F, 2018, IEEE T SOFTWARE ENG, V44, P1070, DOI 10.1109/TSE.2017.2750682; Zhang N, 2018, J SYST SOFTWARE, V142, P73, DOI 10.1016/j.jss.2018.04.046	50	0	0	17	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							471	483		10.1109/ASE56229.2023.00075	http://dx.doi.org/10.1109/ASE56229.2023.00075			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200038
J	Church, K				Church, Kenneth			Emerging trends: When can users trust GPT, and when should they intervene?	NATURAL LANGUAGE ENGINEERING			English	Review						ChatGPT; fluency; trustworthiness; human-in-the-loop; evaluation in situ; fact-checking		Usage of large language models and chat bots will almost surely continue to grow, since they are so easy to use, and so (incredibly) credible. I would be more comfortable with this reality if we encouraged more evaluations with humans-in-the-loop to come up with a better characterization of when the machine can be trusted and when humans should intervene. This article will describe a homework assignment, where I asked my students to use tools such as chat bots and web search to write a number of essays. Even after considerable discussion in class on hallucinations, many of the essays were full of misinformation that should have been fact-checked. Apparently, it is easier to believe ChatGPT than to be skeptical. Fact-checking and web search are too much trouble.	[Church, Kenneth] Northeastern Univ, Boston, MA 02138 USA	Northeastern University	Church, K (corresponding author), Northeastern Univ, Boston, MA 02138 USA.	k.church@northeastern.edu	Church, Kenneth Ward/GYR-1624-2022	Church, Kenneth Ward/0000-0001-8378-6069				Abbasifard M.R., 2014, INT J COMPUT APPL, V95, P39, DOI DOI 10.5120/16754-7073; Amanbek Y, 2020, COMPUT METHOD APPL M, V363, DOI 10.1016/j.cma.2020.112884; [Anonymous], 1990, A computational model of metaphor interpretation; Camburu OM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4157; Carbonell J.G., 1980, METAPHOR KEY EXTENSI, P17; Chen M., 2021, ARXIV; Chia Y. K., 2023, ARXIV; Chomsky N, 1957, SYNTACTIC STRUCTURES; Chomsky N., 1965, Aspects of the Theory of Syntax; Church K, 2023, NAT LANG ENG, V29, P483, DOI 10.1017/S1351324922000481; Church KW, 2023, NAT LANG ENG, V29, P1402, DOI 10.1017/S1351324923000463; Cinelli M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2023301118; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Fass D., 1983, American Journal of Computational Linguistics, V9, P178; Fortuna P, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102524; Frohberg J, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2126; Gale W.A., 1991, SPEECH NATURAL LANGU; Gedigian M., 2006, CATCHING METAPHORS, P41; Hendrycks D., 2020, ARXIV; Hobbs J. R., 1992, Communication from an Artificial Intelligence Perspective. Theoretical and Applied Issues. Proceedings of the NATO Advanced Research Workshop on Computational Theories of Communication and their Applications: Problems and Perspectives, P35; Jia R, 2017, P 2017 C EMPIRICAL M, P2021, DOI [10.18653/v1/D17-1215, DOI 10.18653/V1/D17-1215, DOI 10.18653/V1/D17-1215.URL]; Kai Shu, 2017, ACM SIGKDD EXPLOR NE, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]; Krishnakumaran S., 2007, HUNTING ELUSIVE META, P13; Lakoff George, 1990, Women, Fire; Lakoff George, 1980, METAPHORS WE LIVE BY; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li DQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5053; Minsky M., 1969, Perceptron: an introduction to computational geometry, V19, P2; Mohammad S., 2016, P 5 JOINT C LEX COMP, P23, DOI [10.18653/v1/S16-2003, DOI 10.18653/V1/S16-2003]; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Platt StephenR., 2019, IMPERIAL TWILIGHT OP; Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8; Rosengren E., 2011, RUMOR HAS IT IDENTIF, P1589; Shutova E, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P688; Srivastava A., 2023, Transactions on Machine Learning Research; Wang B., 2021, ARXIV; Wang J., 2023, arXiv; Wei JS, 2022, ADV NEUR IN; Ziegler D.M., 2022, ARXIV; Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603	42	1	1	40	40	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1351-3249	1469-8110		NAT LANG ENG	Nat. Lang. Eng.	MAR	2024	30	2					417	427		10.1017/S1351324923000578	http://dx.doi.org/10.1017/S1351324923000578		JAN 2024	11	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	MO6K6		hybrid			2024-07-03	WOS:001143408600001
C	Hewett, J; Leeke, M			IEEE	Hewett, Joe; Leeke, Matthew			Developing a GPT-3-based Automated Victim for Advance Fee Fraud Disruption	2022 IEEE 27TH PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING (PRDC)	IEEE Pacific Rim International Symposium on Dependable Computing		English	Proceedings Paper	27th IEEE Pacific Rim International Symposium on Dependable Computing (PRDC)	NOV 28-DEC 01, 2022	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc Tech Comm Dependable Comp & Fault Tolerance, Tsinghua Univ, Huawei Technologies Co Ltd		Automated; Fraud; GPT-3; Language; Prompt	DATING ROMANCE SCAM; IMPACT	Advance Fee Fraud (AFF) is amongst the most prevalent and destructive forms of cybercrime. Scammers typically commit AFF by tricking victims into making upfront payments for goods or services that are never provided. These payments are small compared to the alleged gains, and can thus be attractive for victims, particularly if they are vulnerable or in a heightened emotional state. Given that approximately three billion fraudulent emails are sent every day, the scale and impact of AFF demands innovative approaches. In this paper we document the development of an automated victim for AFF. The system leverages GPT-3, a large language model, in conjunction with deliberately engineered prompts to generate plausible responses to AFF emails, allowing fraud to be disrupted and actionable information relating to perpetrators to be obtained.	[Hewett, Joe; Leeke, Matthew] Univ Warwick, Dept Comp Sci, Coventry, England	University of Warwick	Leeke, M (corresponding author), Univ Warwick, Dept Comp Sci, Coventry, England.	matthew.leeke@warwick.ac.uk						419eater, 2006, CHAD DARF SAF; ActionFraud, 2016, FRAUD CYB COST UK NE; Ampratwum E.F., 2009, Journal of Financial Crime, vol, V16, P67, DOI [10.1108/13590790910924975, DOI 10.1108/13590790910924975]; Anderson Ross., 2013, The Economics of Information Security and Privacy; [Anonymous], 2022, Crime in England and Wales: year ending June 2022; Berry M., 2006, GREETINGS JESUS NAME; Boddy Matt, 2018, Computer Fraud & Security, V2018, P8, DOI 10.1016/S1361-3723(18)30108-8; Branwen Gwern, 2021, GPT 3 CREATIVE FICTI; Brown T.B., 2020, ADV NEURAL INFORM PR; Buchanan T, 2014, PSYCHOL CRIME LAW, V20, P261, DOI 10.1080/1068316X.2013.772180; Button M, 2014, AUST NZ J CRIMINOL, V47, P391, DOI 10.1177/0004865814521224; Gao T., 2021, PROMPTING BETTER WAY; Gee J., 2019, The financial cost of fraud 2019: The latest data from around the world; Kaplan J., 2022, P 10 INTERNATION C L; Komatsuzaki A, 2021, GPT-J-6B: 6B JAX-Based Transformer; McGuire M., 2018, Into the web of profit: Understanding the growth of the cybercrime economy; Modic D, 2015, IEEE SECUR PRIV, V13, P99, DOI 10.1109/MSP.2015.107; Norris G, 2021, PERS INDIV DIFFER, V169, DOI 10.1016/j.paid.2020.109847; Palmer D., 2021, 3 BILLION PHISHING E; Paperno D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1525; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Ross S, 2011, TRENDS ISS CRIME CRI, P1; Sorrell T., 2019, Criminal Justice Ethics, V38, P153; Wang Ben, 2021, Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX; Whittaker JM, 2020, AUST NZ J CRIMINOL, V53, P497, DOI 10.1177/0004865820957077; Whitty MT, 2016, CRIMINOL CRIM JUSTIC, V16, P176, DOI 10.1177/1748895815603773; Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791; Zingerle A, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P352, DOI 10.1109/CW.2013.49	29	1	1	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1555-094X		978-1-6654-8555-5	IEEE PAC RIM INT SYM			2022							205	211		10.1109/PRDC55274.2022.00034	http://dx.doi.org/10.1109/PRDC55274.2022.00034			7	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BU9XT					2024-07-03	WOS:000965064800020
C	Yu, DA; Yu, Z; Sagae, K		Moens, MF; Huang, X; Specia, L; Yih, SWT		Yu, Dian; Yu, Zhou; Sagae, Kenji			Attribute Alignment: Controlling Text Generation from Pre-trained Language Models	FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021			English	Proceedings Paper	Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)	NOV 07-11, 2021	Punta Cana, DOMINICAN REP	Assoc Computat Linguist				Large language models benefit from training with a large amount of unlabeled text, which gives them increasingly fluent and diverse generation capabilities. However, using these models for text generation that takes into account target attributes, such as sentiment polarity or specific topics, remains a challenge. We propose a simple and flexible method for controlling text generation by aligning disentangled attribute representations. In contrast to recent efforts on training a discriminator to perturb the token level distribution for an attribute, we use the same data to learn an alignment function to guide the pre-trained, non-controlled language model to generate texts with the target attribute without changing the original language model parameters. We evaluate our method on sentiment- and topiccontrolled generation, and show large performance gains over previous methods while retaining fluency and diversity.	[Yu, Dian; Sagae, Kenji] Univ Calif Davis, Davis, CA 95616 USA; [Yu, Zhou] Columbia Univ, New York, NY 10027 USA	University of California System; University of California Davis; Columbia University	Yu, DA (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.	dianyu@ucdavis.edu; zhouyu@cs.columbia.edu; sagae@ucdavis.edu			National Science Foundation [1840191]	National Science Foundation(National Science Foundation (NSF))	We thank our anonymous reviewers for constructive suggestions. This work was supported by the National Science Foundation under Grant No. 1840191. Any opinions, findings, and conclusions or recommendations expressed are those of the authors and do not necessarily reflect the views of the NSF.	Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374; [Anonymous], 2011, P 49 ANN M ASS COMPU; Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1538; Bowman Samuel R., 2016, PROC 20 SIGNLL C COM, P10, DOI [10.18653/V1/K16-1002, DOI 10.18653/V1/K16-1002]; Chan Alvin, 2021, INT C LEARN REPR; Dathathri Sumanth, 2020, Plug and play language models: A simple approach to controlled text generation; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dinan Emily, 2019, 7 INT C LEARN REPR I; Ficler Jessica, 2017, P WORKSHOP STYLISTIC, P94; Fu ZX, 2018, AAAI CONF ARTIF INTE, P663; Hoang C.D. V., 2016, P 2016 C N AM CHAPTE, P1250; Holtzman A., 2019, INT C LEARNING REPRE; Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638; Houlsby N, 2019, PR MACH LEARN RES, V97; Johnson M., 2017, Google's multilingual neural machine translation system: Enabling zero-shot translation, V5, P339, DOI 10.1162/tacla00065; Keskar N. S., 2019, ABS190905858 CORR; Krause Ben, 2020, ABS200906367 CORR; Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5; Li J, 2016, RES ASTRON ASTROPHYS, V16, DOI 10.1088/1674-4527/16/7/110; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Yang., 2018, Transactions of the Association for Computational Linguistics, V6, P63, DOI 10.1162/tacl_a_00005; Madotto A, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2422; Prabhumoye S., 2020, P 28 INT C COMP LING, P1, DOI DOI 10.18653/V1/2020.COLING-MAIN.1; Radford A, 2017, LEARNING GENERATE RE; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Romanov A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P815; Smith Eric Michael, 2020, ABS200910855 CORR; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang WL, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P166; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yang Z., 2019, ADV NEURAL INFORM PR, P5754, DOI DOI 10.5555/3454287.3454804; Yu Dian, 2021, P 59 ANN M ASS COMP, V1, P7210, DOI DOI 10.18653/V1/2021.ACL-LONG.560; Zhang Xiang, 2015, ADV NEURAL INFORM PR, P649, DOI DOI 10.5555/2969239.2969312; Ziegler Daniel M., 2019, ABS190908593 CORR; Ziegler Zachary M, 2019, ARXIV190806938	39	5	6	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-10-0				2021							2251	2268						18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TD					2024-07-03	WOS:001181828801024
J	Garg, M; Liu, XY; Sathvik, MSVPJ; Raza, S; Sohn, S				Garg, Muskan; Liu, Xingyi; Sathvik, M. S. V. P. J.; Raza, Shaina; Sohn, Sunghwan			MULTIWD: Multi-label wellness dimensions in social media posts	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Dataset; Mental health; Multi-label classification; Wellness dimensions		Background: Halbert L. Dunn's concept of wellness is a multi-dimensional aspect encompassing social and mental well-being. Neglecting these dimensions over time can have a negative impact on an individual's mental health. The manual efforts employed in in -person therapy sessions reveal that underlying factors of mental disturbance if triggered, may lead to severe mental health disorders. Objective: In our research, we introduce a fine-grained approach focused on identifying indicators of wellness dimensions and mark their presence in self-narrated human-writings on Reddit social media platform. Design and Method: We present the MULTIWD dataset, a curated collection comprising 3281 instances, as a specifically designed and annotated dataset that facilitates the identification of multiple wellness dimensions in Reddit posts. In our study, we introduce the task of identifying wellness dimensions and utilize state -of -the -art classifiers to solve this multi-label classification task. Results: Our findings highlights the best and comparative performance of fine-tuned large language models with fine-tuned BERT model. As such, we set BERT as a baseline model to tag wellness dimensions in a user-penned text with F1 score of 76.69. Conclusion: Our findings underscore the need of trustworthy and domain-specific knowledge infusion to develop more comprehensive and contextually-aware AI models for tagging and extracting wellness dimensions.	[Garg, Muskan; Liu, Xingyi; Sohn, Sunghwan] Mayo Clin, Rochester, MN 55901 USA; [Sathvik, M. S. V. P. J.] IIIT Dharwad, Dharwad 580011, Goa, India; [Raza, Shaina] Vector Inst Artificial Intelligence, Toronto, ON M5G 1M1, Canada	Mayo Clinic; Vector Institute for Artificial Intelligence	Garg, M (corresponding author), Mayo Clin, Rochester, MN 55901 USA.	garg.muskan@mayo.edu; liu.xingyi@mayo.edu; 20bec024@iiitdwd.ac.in; shaina.raza@vectorinstitute.ai; sohn.sunghwan@mayo.edu	Sathvik, MSVPJ/JCE-8500-2023; Liu, Xingyi/IVH-7043-2023	Sathvik, MSVPJ/0000-0003-4544-4011; Liu, Xingyi/0000-0001-9230-3209	NIH [R01 AG068007]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This project was supported by NIH R01 AG068007. We extend our sincere acknowledgment to the postgraduate student annotators, Ritika Bhardwaj, Astha Jain, and Amrit Chadha, for their diligent efforts in the annotation process. We express our gratitude to Veena Krishnan, a senior clinical psychologist, and Ruchi Joshi, a rehabilitation counselor, for their unwavering support throughout the project.	Abraham AG, 2023, J AM GERIATR SOC, V71, P1369, DOI 10.1111/jgs.18229; Ansari G, 2021, Arxiv, DOI arXiv:2112.10064; Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]; Dang YF, 2023, J AM MED INFORM ASSN, V30, P1465, DOI 10.1093/jamia/ocad096; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DUNN HL, 1959, AM J PUBLIC HEALTH N, V49, P786, DOI 10.2105/AJPH.49.6.786; Garg M, 2023, Asian J. Psychiatry; Garg M, 2024, KNOWL-BASED SYST, V284, DOI 10.1016/j.knosys.2023.111228; Garg M, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6387; Garg M, 2023, ARCH COMPUT METHOD E, V30, P1819, DOI 10.1007/s11831-022-09863-z; Ghosh S, 2022, LECT NOTES COMPUT SC, V13186, P128, DOI 10.1007/978-3-030-99739-7_15; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Ji S., 2021, arXiv; Kumar P., 2022, Int. J. Inf. Technol., P1; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Pan BC, 2022, PSYCHOL RES BEHAV MA, V15, P2815, DOI 10.2147/PRBM.S381976; Park S, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P557, DOI 10.1145/2675133.2675139; Patra BG, 2021, J AM MED INFORM ASSN, V28, P2716, DOI 10.1093/jamia/ocab170; Pavalanathan U, 2015, Arxiv, DOI arXiv:1510.08480; Qu X., 2023, Proc AAAI Confer Artif Intell, V37, P13501; Roccabruna G, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P581; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Tarekegn AN, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.107965; U. ESCAP W. WHO, 2021, SDG 3 Goodhealth and Well-Being: Ensure Healthy Lives and Promote Well-Being for All at All Ages; UNITEDNATIONS, 2015, Transforming Our World: The 2030 Agenda for Sustainable Development New York; Vajre Vedant, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1077, DOI 10.1109/BIBM52615.2021.9669469; Zirikly A., 2022, CLPSYCH 2022, P30	28	0	0	4	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	FEB	2024	150								104586	10.1016/j.jbi.2024.104586	http://dx.doi.org/10.1016/j.jbi.2024.104586		JAN 2024	10	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	IZ1H5	38191011				2024-07-03	WOS:001170066700001
J	Lin, YN; Li, HT; Yang, LN; Wu, AY; Qu, HM				Lin, Yanna; Li, Haotian; Yang, Leni; Wu, Aoyu; Qu, Huamin			InkSight: Leveraging Sketch Interaction for Documenting Chart Findings in Computational Notebooks	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			English	Article						Data visualization; Documentation; Data analysis; Visualization; Codes; Natural languages; Data models; Computational Notebook; Sketch-based Interaction; Exploratory Data Analysis		Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch. Upon receiving a user's sketch, InkSight identifies the sketch type and corresponding selected data items. Subsequently, it filters data fact types based on the sketch and selected data items before employing existing automatic data fact recommendation algorithms to infer data facts. Using large language models (GPT-3.5), InkSight converts data facts into effective natural language documentation. Users can conveniently fine-tune the generated documentation within InkSight. A user study with 12 participants demonstrated the usability and effectiveness of InkSight in expressing user intent and facilitating chart finding documentation.	[Lin, Yanna; Li, Haotian; Yang, Leni; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Wu, Aoyu] Harvard Univ, Cambridge, MA USA	Hong Kong University of Science & Technology; Harvard University	Yang, LN (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.	ylindg@connect.ust.hk; haotian.li@connect.ust.hk; lyangbb@connect.ust.hk; aoyuwu@seas.harvard.edu; huamin@cse.ust.hk		Yang, Leni/0000-0003-4527-4905; Lin, Yanna/0000-0003-3730-0827	HK RGC GRF	HK RGC GRF(Hong Kong Research Grants Council)	No Statement Available	Akers D., 2006, Proceedings of the ACM Symposium on User Interface Software and Technology, P33, DOI DOI 10.1145/1166253.1166260; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; Browne J., 2011, P 2011 ACM INT C INT, P154, DOI DOI 10.1145/2076354.20763832,9; Chao W. O., 2010, P 2010 IEEE INF C PO; Chattopadhyay S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376729; Chen X, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174070; Chen YR, 2022, INT CONF MANAGE DATA, P1711, DOI 10.1145/3514221.3526166; Chen Z., 2022, P 2022 CHI C HUM FAC, DOI DOI 10.1145/3491102.35174853; Choi J, 2022, IEEE VIS CONF, P40, DOI 10.1109/VIS54862.2022.00017; Chung J. J. Y., 2022, P 2022 CHI C HUM FAC, P1, DOI [10.1145/3491102.35018192,9, DOI 10.1145/3491102.35018192,9]; Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785; Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037; Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540; EPPerson W, 2022, COMPUT GRAPH FORUM, V41, P145, DOI 10.1111/cgf.14529; Holz C, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P213; jupyter, Project Jupyter Home; Kantharaj S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4005; Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714; Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241; Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802; Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191; Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151; Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307; Li H., 2023, P 2023 CHI C HUM FAC, DOI DOI 10.1145/3544548.35809651,2,3,8,9; Li HT, 2023, Arxiv, DOI arXiv:2304.08366; Lin Yanna, 2024, IEEE Trans Vis Comput Graph, V30, P4108, DOI 10.1109/TVCG.2023.3251344; Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043; Mishra P, 2022, J COMPUT LANG, V69, DOI 10.1016/j.cola.2022.101107; Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378; Obeid J., 2020, P 13 INT C NAT LANG, P2; online.stat, Interquartile Range (IQR) method.; OpenAI, 2023, GPT-4 Technical Report; Pandey Aditeya, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209421; platform.openai, GPT-3.5; Posit, About us; Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606; Ryall K., 2005, P 2005 CHI C HUM FAC, P1765, DOI [10.1145/1056808.10570172, DOI 10.1145/1056808.10570172]; Shen L., 2021, P 23 EUR C VIS SHORT, DOI [DOI 10.2312/EVS.20211061, 10.2312/evs.20211061]; Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403; Siddiqui T, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P51, DOI 10.1145/3318464.3389722; Song S., 2023, P 2023 CHI C HUM FAC, P2; Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145; Sutherland I. E., 1963, Sketchpad, a Man-Machine Graphical Communication System, P2; Tohidi M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1243; Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275; Wang AY, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3489465; Wang FJ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580753; Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357; Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398; Wattenberg Martin, 2001, PROC SIGCHI EA, P381, DOI DOI 10.1145/634067.6342922; Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648; Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826; Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774; Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851; Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668; Yu CH, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.628832; Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211; Zheng CB, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517615	58	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1077-2626	1941-0506		IEEE T VIS COMPUT GR	IEEE Trans. Vis. Comput. Graph.	JAN	2024	30	1					944	954		10.1109/TVCG.2023.3327170	http://dx.doi.org/10.1109/TVCG.2023.3327170			11	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HJ3Z6	37878446	Green Submitted			2024-07-03	WOS:001159106500133
C	MacAvaney, S; Soldaini, L			ACM	MacAvaney, Sean; Soldaini, Luca			One-Shot Labeling for Automatic Relevance Estimation	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		few-shot learning; relevance assessments; neural networks	RETRIEVAL-SYSTEMS; INFORMATION	Dealing with unjudged documents ("holes") in relevance assessments is a perennial problem when evaluating search systems with offline experiments. Holes can reduce the apparent effectiveness of retrieval systems during evaluation and introduce biases in models trained with incomplete data. In this work, we explore whether large language models can help us fill such holes to improve offline evaluations. We examine an extreme, albeit common, evaluation setting wherein only a single known relevant document per query is available for evaluation. We then explore various approaches for predicting the relevance of unjudged documents with respect to a query and the known relevant document, including nearest neighbor, supervised, and prompting techniques. We find that although the predictions of these One-Shot Labelers (1SL) frequently disagree with human assessments, the labels they produce yield a far more reliable ranking of systems than the single labels do alone. Specifically, the strongest approaches can consistently reach system ranking correlations of over 0.86 with the full rankings over a variety of measures. Meanwhile, the approach substantially increases the reliability of t-tests due to filling holes in relevance assessments, giving researchers more confidence in results they find to be significant. Alongside this work, we release an easy-to-use software package to enable the use of 1SL for evaluation of other ad-hoc collections or systems.	[MacAvaney, Sean] Univ Glasgow, Glasgow, Lanark, Scotland; [Soldaini, Luca] Allen Inst AI, Seattle, WA USA	University of Glasgow	MacAvaney, S (corresponding author), Univ Glasgow, Glasgow, Lanark, Scotland.	sean.macavaney@glasgow.ac.uk; lucas@allenai.org						Arabzadeh N, 2022, INFORM RETRIEVAL J, V25, P365, DOI 10.1007/s10791-022-09411-0; Aslam Javed., 2003, P SIGIR, P361; Boytsov L, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P403; Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P25, DOI 10.1145/1008992.1009000; Buttcher Stefan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P63, DOI 10.1145/1277741.1277755; Carterette Ben., 2007, Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM '07, P873, DOI [10.1145/1321440.1321564, DOI 10.1145/1321440.1321564]; Chung H. W., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2210.11416; CLEVERDON C, 1967, ASLIB PROC, V19, P173, DOI 10.1108/eb050097; Craswell N., 2020, NIST Special Publication, V1266; Craswell Nick, 2019, NIST SPECIAL PUBLICA, V1250; Craswell Nick, 2021, NIST SPECIAL PUBLICA; Faggioli Guglielmo, 2023, ABS230409161 CORR, DOI [10.48550/arXiv.2304.09161, DOI 10.48550/ARXIV.2304.09161]; Fröbe M, 2023, LECT NOTES COMPUT SC, V13980, P313, DOI 10.1007/978-3-031-28244-7_20; Gupta P, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2214, DOI 10.1145/3477495.3531832; Hauff C, 2010, LECT NOTES COMPUT SC, V5993, P153, DOI 10.1007/978-3-642-12275-0_16; Hui K, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P47, DOI 10.1145/2872518.2889370; Hui K, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P83, DOI 10.1145/3121050.3121064; Hui K, 2015, LECT NOTES COMPUT SC, V9309, P137, DOI 10.1007/978-3-319-23826-5_14; JARDINE N, 1971, INFORM STORAGE RET, V7, P217, DOI 10.1016/0020-0271(71)90051-9; Le Q. V., 2022, 10 INT C LEARN REPR; Lin SC, 2021, REPL4NLP 2021: PROCEEDINGS OF THE 6TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P163; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; MacAvaney Sean, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P246, DOI 10.1007/978-3-030-45442-5_31; MacAvaney S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P1491, DOI 10.1145/3511808.3557231; MacAvaney S, 2022, LECT NOTES COMPUT SC, V13186, P305, DOI 10.1007/978-3-030-99739-7_38; McCreadie R, 2018, ACM/SIGIR PROCEEDINGS 2018, P685, DOI 10.1145/3209978.3210034; Min Sewon, 2022, P 2022 C EMPIRICAL M, P11048, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.759; Moffat Alistair, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P375, DOI 10.1145/1277741.1277806; Moffat A, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3052768; Moffat A, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1416950.1416952; Nguyen Tri, 2016, CEUR Workshop Proceedings, V1773; Nuray R, 2006, INFORM PROCESS MANAG, V42, P595, DOI 10.1016/j.ipm.2005.03.023; Pradeep Ronak, 2021, ARXIV210105667; Raffel C, 2020, J MACH LEARN RES, V21; Rekabsaz N, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2507, DOI 10.1145/3404835.3463242; Roitero K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102149; Sakai Tetsuya, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P71, DOI 10.1145/1277741.1277756; Sakai T, 2008, INFORM RETRIEVAL, V11, P447, DOI 10.1007/s10791-008-9059-7; Sander D.P., 2021, CEUR WORKSHOP P, V2950, P136; Sanh Victor., 2022, 10 INT C LEARN REPR; Soboroff I., 2001, Proceedings Of The 24th Annual International ACM SIGIR Conference On Research And Development In Information Retrieval, P66, DOI DOI 10.1145/383952.383961; Sparck-Jones Karen, 1975, 5266 U CAMBR BRIT LI; Spoerri A, 2007, INFORM PROCESS MANAG, V43, P1059, DOI 10.1016/j.ipm.2006.09.009; Thakur Nandan, 2021, ABS210408663 CORR; Voorhees EM, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2970, DOI 10.1145/3477495.3531728; Voorhees Ellen M., 2022, ABS220111086 CORR; Voorhees EM, 2002, LECT NOTES COMPUT SC, V2406, P355; Vu T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5223; Wang Y., 2022, P 2022 C EMP METH NA, P5085; Wu S., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P648, DOI 10.1145/584792.584908; Wu S., 2003, P 2003 ACM S APPL CO, P811, DOI DOI 10.1145/952532.952693; Yilmaz Emine, 2006, Proceedings of the 2006 ACM CIKM International Conference on Information and Knowledge Management, Arlington, Virginia, USA, November 6-11, 2006, P102, DOI [DOI 10.1145/1183614.1183633, DOI 10.1145/1183614.1183633(CIT.ONP.34, 10.1145/1183614.1183633 (cit. on p. 34]; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zobel J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P307, DOI 10.1145/290941.291014	54	2	2	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							2230	2235		10.1145/3539618.3592032	http://dx.doi.org/10.1145/3539618.3592032			6	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		Green Submitted			2024-07-03	WOS:001118084002054
C	Chen, C; Yin, YC; Shang, LF; Jiang, X; Qin, YJ; Wang, FY; Wang, Z; Chen, X; Liu, ZY; Liu, Q			Assoc Computat Linguist	Chen, Cheng; Yin, Yichun; Shang, Lifeng; Jiang, Xin; Qin, Yujia; Wang, Fengyu; Wang, Zhi; Chen, Xiao; Liu, Zhiyuan; Liu, Qun			bert2BERT: Towards Reusable Pretrained Language Models	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple				In recent years, researchers tend to pre-train ever-larger language models to explore the upper limit of deep models. However, large language model pre-training costs intensive computational resources, and most of the models are trained from scratch without reusing the existing pre-trained models, which is wasteful. In this paper, we propose bert2BERT1, which can effectively transfer the knowledge of an existing smaller pre-trained model to a large model through parameter initialization and significantly improve the pre-training efficiency of the large model. Specifically, we extend the previous function-preserving (Chen et al., 2016) method proposed in computer vision on the Transformer-based language model, and further improve it by proposing a novel method, advanced knowledge for the large model's initialization. In addition, a two-stage learning method is proposed to further accelerate the pre-training. We conduct extensive experiments on representative PLMs (e.g., BERT and GPT) and demonstrate that (1) our method can save a significant amount of training cost compared with baselines including learning from scratch, StackBERT (Gong et al., 2019) and MSLT (Yang et al., 2020); (2) our method is generic and applicable to different types of pretrained models. In particular, bert2BERT saves about 45% and 47% computational cost of pretraining BERTBASE and GPTBASE by reusing the models of almost their half sizes.	[Chen, Cheng; Qin, Yujia; Wang, Fengyu; Liu, Zhiyuan] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China; [Chen, Cheng; Yin, Yichun; Shang, Lifeng; Jiang, Xin; Chen, Xiao; Liu, Qun] Huawei Noahs Ark Lab, Beijing, Peoples R China; [Wang, Zhi] Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China; [Wang, Zhi] Peng Cheng Lab, Shenzhen, Peoples R China	Tsinghua University; Huawei Technologies; Tsinghua Shenzhen International Graduate School; Peng Cheng Laboratory	Wang, Z (corresponding author), Tsinghua Shenzhen Int Grad Sch, Shenzhen, Peoples R China.; Wang, Z (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.	c-chen19@mails.tsinghua.edu.cn; yinyichun@huawei.com; shang.lifeng@huawei.com; jiang.xin@huawei.com; gyj20@mails.tsinghua.edu.cn; wangfy20@mails.tsinghua.edu.cn; wangzhi@sz.tsinghua.edu.cn; chen.xiao2@huawei.com; liuzy@tsinghua.edu.cn; gun.liu@huawei.com	Wang, Zhi/GZB-2713-2022	Wang, Zhi/0000-0001-6952-8848	NSFC [61872215]; Shenzhen Science and Technology Program [RCYX20200714114523079]	NSFC(National Natural Science Foundation of China (NSFC)); Shenzhen Science and Technology Program	This work is supported in part by NSFC (Grant No. 61872215), and Shenzhen Science and Technology Program (Grant No. RCYX20200714114523079). We would like to thank Yifeng Liu, Binbin Deng, Ziliang Yang, Jiaxin Shi for their support of this work.	[Anonymous], 2020, 8 INT C LEARN REPR I; [Anonymous], 2020, STEEPEST DESCENT NEU, DOI DOI 10.1007/978-3-030-35723-8_1; Ba Jimmy Lei, 2016, ABS160706450 ARXIV; Brown Tom B., 2020, ADV NEURAL INFORM PR, V33; Chen T., 2016, P 4 INT C LEARN REPR; Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828; Devlin J., 2019, CoRR, P4171; Fedus William, 2021, CORR; Feng A., 2020, IJCNN; Gong Linyuan, 2019, P MACHINE LEARNING R, V97, P2337; Gu XT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5174; Han S, 2015, ADV NEUR IN, V28; Hendrycks D., 2016, PROC INT C LEARN REP; Hu H, 2020, M ASS FOR COMPUTATIO; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Lan Zhenzhong, 2020, 8 INT C LEARNING REP; LemengWu Bo Liu, 2020, ADV NEURAL INFORM PR, V33; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Liu Y., 2019, CoRR abs/1907.11692; Pan Sinno Jialin, 2010, TKDE; Qin Yujia, 2021, CORR; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Shoeybi Mohammad, 2019, CoRR; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang Dilin, 2019, CoRR; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wen Wei, 2018, 6 INT C LEARN REPR I; Wu Lemeng, 2019, ADV NEURAL INFORM PR, P10655; Wu Qiyu, 2021, ICLR; Xiong R., 2020, P 37 INT C MACHINE L, V119, P10524, DOI 10.48550/arXiv.2002.04745; Yang Cheng, 2020, ARXIV201113635; Yang Yuan, 2020, 8 INT C LEARN REPR I; Yang Zhilin, 2019, NEURIPS, P5754; Yuan K, 2021, I IEEE EMBS C NEUR E, P1057, DOI 10.1109/NER49283.2021.9441290; Zeng Wei, 2021, PANGU ALPHA LARGE SC; Zhang Minjia, 2020, ADV NEURAL INFORM PR, V33; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	42	3	4	2	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-21-6				2022							2134	2148						15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EM					2024-07-03	WOS:000828702302018
J	Shi, YW; Ren, P; Wang, J; Han, B; ValizadehAslani, T; Agbavor, F; Zhang, Y; Hu, M; Zhao, L; Liang, HL				Shi, Yiwen; Ren, Ping; Wang, Jing; Han, Biao; ValizadehAslani, Taha; Agbavor, Felix; Zhang, Yi; Hu, Meng; Zhao, Liang; Liang, Hualou			Leveraging GPT-4 for food effect summarization to enhance product-specific guidance development via iterative prompting	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Drug labeling; Prompt Engineering; GPT-4; Text Summarization; Large Language Models		Food effect summarization from New Drug Application (NDA) is an essential component of product-specific guidance (PSG) development and assessment, which provides the basis of recommendations for fasting and fed bioequivalence studies to guide the pharmaceutical industry for developing generic drug products. However, manual summarization of food effect from extensive drug application review documents is time-consuming. Therefore, there is a need to develop automated methods to generate food effect summary. Recent advances in natural language processing (NLP), particularly large language models (LLMs) such as ChatGPT and GPT-4, have demonstrated great potential in improving the effectiveness of automated text summarization, but its ability with regard to the accuracy in summarizing food effect for PSG assessment remains unclear. In this study, we introduce a simple yet effective approach, iterative prompting, which allows one to interact with ChatGPT or GPT-4 more effectively and efficiently through multi-turn interaction. Specifically, we propose a three-turn iterative prompting approach to food effect summarization in which the keyword-focused and length -controlled prompts are respectively provided in consecutive turns to refine the quality of the generated sum-mary. We conduct a series of extensive evaluations, ranging from automated metrics to FDA professionals and even evaluation by GPT-4, on 100 NDA review documents selected over the past five years. We observe that the summary quality is progressively improved throughout the iterative prompting process. Moreover, we find that GPT-4 performs better than ChatGPT, as evaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%). Importantly, all the FDA professionals unanimously rated that 85% of the summaries generated by GPT-4 are factually consistent with the golden reference summary, a finding further supported by GPT-4 rating of 72% consistency. Taken together, these results strongly suggest a great potential for GPT-4 to draft food effect summaries that could be reviewed by FDA professionals, thereby improving the efficiency of the PSG assessment cycle and promoting generic drug product development.	[Shi, Yiwen] Drexel Univ, Coll Comp & Informat, Philadelphia, PA USA; [Ren, Ping; Wang, Jing; Han, Biao; Zhang, Yi; Hu, Meng; Zhao, Liang] US FDA, Ctr Drug Evaluat & Res, Off Res & Stand, Off Gener Drugs, Silver Spring, MD USA; [ValizadehAslani, Taha] Drexel Univ, Coll Engn, Dept Elect & Comp Engn, Philadelphia, PA USA; [Agbavor, Felix; Liang, Hualou] Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA USA; [Liang, Hualou] Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, 3141 Chestnut St, Philadelphia, PA 19104 USA	Drexel University; US Food & Drug Administration (FDA); Drexel University; Drexel University; Drexel University	Liang, HL (corresponding author), Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, 3141 Chestnut St, Philadelphia, PA 19104 USA.	hualou.liang@drexel.edu			United States Food and Drug Administration [75F40119C10106]	United States Food and Drug Administration	This work was partly supported by The United States Food and Drug Administration Contract #: 75F40119C10106	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agbavor Felix, 2022, PLOS Digit Health, V1, pe0000168, DOI 10.1371/journal.pdig.0000168; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Castro S., 2017, Fast {K}rippendorff: Fast computation of {K}rippendorff's alpha agreement measure; Chaves A, 2022, INFORMATION, V13, DOI 10.3390/info13080393; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; Cintas C., 2019, IEEE INT CONF HEALT, P1, DOI [10.1109/ICHI.2019.8904526, DOI 10.1109/ichi.2019.8904526]; Deutsch D, 2022, Arxiv, DOI [arXiv:2204.10216, 10.48550/arXiv.2204.10216]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fabbri A.R., 2021, arXiv; Google, 2022, LaMDA: Towards Safe, Grounded, and High-Quality Dialog Models for Everything; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Gu JT, 2016, Arxiv, DOI [arXiv:1603.06393, 10.48550/arXiv.1603.06393]; Holmes J, 2023, Arxiv, DOI arXiv:2304.01938; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li Z., 2023, Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu Yixin, 2022, arXiv, DOI 10.48550/arXiv.2203.16804; Meta, 2023, Introducing LLaMA: A foundational, 65-billion-parameter language model; Mishra R, 2014, J BIOMED INFORM, V52, P457, DOI 10.1016/j.jbi.2014.06.009; Nallapati R, 2016, Arxiv, DOI arXiv:1611.04230; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; OpenAI, 2022, Introducing chatgpt; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Schick T, 2021, Arxiv, DOI [arXiv:2001.07676, 10.48550/arXiv.2001.07676]; See A, 2017, arXiv; Sharma MR, 2013, CLIN CANCER RES, V19, P3059, DOI 10.1158/1078-0432.CCR-12-3829; Shi YW, 2023, J BIOMED INFORM, V138, DOI 10.1016/j.jbi.2023.104285; Shi Yiwen, 2021, Front Res Metr Anal, V6, P670006, DOI 10.3389/frma.2021.670006; Sutskever I, 2014, ADV NEUR IN, V27; Taylor N., 2022, arXiv; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zhang JQ, 2020, Arxiv, DOI arXiv:1912.08777; Zhang T., 2023, arXiv; Zheng CY, 2023, Arxiv, DOI [arXiv:2304.09797, 10.48550/arXiv.2304.09797]	45	3	3	9	12	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	DEC	2023	148								104533	10.1016/j.jbi.2023.104533	http://dx.doi.org/10.1016/j.jbi.2023.104533		NOV 2023	9	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	Z3DA4	37918623	Green Submitted			2024-07-03	WOS:001110900600001
J	Livne, M; Miftahutdinov, Z; Tutubalina, E; Kuznetsov, M; Polykovskiy, D; Brundyn, A; Jhunjhunwala, A; Costa, A; Aliper, A; Aspuru-Guzik, A; Zhavoronkov, A				Livne, Micha; Miftahutdinov, Zulfat; Tutubalina, Elena; Kuznetsov, Maksim; Polykovskiy, Daniil; Brundyn, Annika; Jhunjhunwala, Aastha; Costa, Anthony; Aliper, Alex; Aspuru-Guzik, Alan; Zhavoronkov, Alex			nach0: multimodal natural and chemical languages foundation model	CHEMICAL SCIENCE			English	Article							CORPUS	Large Language Models (LLMs) have substantially driven scientific progress in various domains, and many papers have demonstrated their ability to tackle complex problems with creative solutions. Our paper introduces a new foundation model, nach0, capable of solving various chemical and biological tasks: biomedical question answering, named entity recognition, molecular generation, molecular synthesis, attributes prediction, and others. nach0 is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge. We employed instruction tuning, where specific task-related instructions are utilized to fine-tune nach0 for the final set of tasks. To train nach0 effectively, we leverage the NeMo framework, enabling efficient parallel optimization of both base and large model versions. Extensive experiments demonstrate that our model outperforms state-of-the-art baselines on single-domain and cross-domain tasks. Furthermore, it can generate high-quality outputs in molecular and textual formats, showcasing its effectiveness in multi-domain setups. nach0 is a novel multi-domain and multi-task language model pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge.	[Livne, Micha; Brundyn, Annika; Jhunjhunwala, Aastha; Costa, Anthony] NVIDIA, 2788 San Tomas Expressway, Santa Clara, CA 95051 USA; [Miftahutdinov, Zulfat; Kuznetsov, Maksim; Polykovskiy, Daniil] Insil Med Canada Inc, 3710-1250 Rene Levesque West, Montreal, PQ, Canada; [Tutubalina, Elena; Zhavoronkov, Alex] Insil Med Hong Kong Ltd, Unit 310,3-F,Bldg 8W,Phase 2,Hong Kong Sci Pk, Hong Kong, Peoples R China; [Aliper, Alex] Insil Med AI Ltd, Level 6,Unit 08,Block A,IRENA HQ Bldg, Abu Dhabi, U Arab Emirates; [Aspuru-Guzik, Alan] Univ Toronto, Lash Miller Bldg 80 St George St, Toronto, ON, Canada	Nvidia Corporation; University of Toronto	Zhavoronkov, A (corresponding author), Insil Med Hong Kong Ltd, Unit 310,3-F,Bldg 8W,Phase 2,Hong Kong Sci Pk, Hong Kong, Peoples R China.; Aspuru-Guzik, A (corresponding author), Univ Toronto, Lash Miller Bldg 80 St George St, Toronto, ON, Canada.	alan@aspuru.com; alex@insilicomedicine.com	; Polykovskiy, Daniil/Q-4192-2018	Kuznetsov, Maksim/0000-0001-8446-7983; Polykovskiy, Daniil/0000-0002-0899-8368				Aliper A, 2023, CLIN PHARMACOL THER, V114, P972, DOI 10.1002/cpt.3008; Aliper A, 2016, MOL PHARMACEUT, V13, P2524, DOI 10.1021/acs.molpharmaceut.6b00248; Bolton E., 2022, STANFORD CRFM INTROD; Bommasani Rishi, 2021, ARXIV210807258; Bravo A, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0472-9; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen QJ, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad557; Cheng AH, 2023, DIGIT DISCOV, V2, P748, DOI 10.1039/d3dd00012e; Chowdhery A, 2023, J MACH LEARN RES, V24; Chung H., 2022, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006; Dowden H, 2019, NAT REV DRUG DISCOV, V18, P494, DOI 10.1038/d41573-019-00074-z; Edwards C., 2022, P 2022 C EMPIRICAL M, P375; Fang Y., 2024, 12 INT C LEARN REPR; Flam-Shepherd D., 2023, ARXIV; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Hanahan D, 2000, CELL, V100, P57, DOI 10.1016/S0092-8674(00)81683-9; Harper E., 2019, NEMO TOOLKIT CONVERS; Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011; Ivanenkov YA, 2023, J CHEM INF MODEL, DOI 10.1021/acs.jcim.2c01191; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Khot T., 2018, P AAAI C ARTIFICIAL; Kim Jin-Dong, 2004, P INT JOINT WORKSHOP, P70; Krallinger M., 2017, P 6 BIOCREATIVE CHAL, V1, P141; Krallinger M, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-S2-S1; Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kuchaiev Oleksii, 2019, arXiv; Kuznetsov M, 2021, AAAI CONF ARTIF INTE, V35, P8226; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Miftahutdinov, 2020, COLING 2020 28 INT C, P6710; Miftahutdinov Z., 2021, LECT NOTES COMPUTER; Miftahutdinov Z, 2021, BIOINFORMATICS, V37, P3856, DOI 10.1093/bioinformatics/btab474; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; Nentidis A, 2020, COMM COM INF SC, V1168, P553, DOI 10.1007/978-3-030-43887-6_51; Nye B., 2018, P C M ASS COMP LING; Phan LN., 2021, ARXIV; Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644; Polykovskiy D, 2018, MOL PHARMACEUT, V15, P4398, DOI 10.1021/acs.molpharmaceut.8b00839; Putin E, 2018, MOL PHARMACEUT, V15, P4386, DOI 10.1021/acs.molpharmaceut.7b01137; Raffel C, 2020, J MACH LEARN RES, V21; Shayakhmetov R, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.00269; Shin HC, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4700; Shivade C., 2019, P 2018 C EMP METH NA; Sogancioglu G, 2017, BIOINFORMATICS, V33, pI49, DOI 10.1093/bioinformatics/btx238; Tang R., 2023, ARXIV; Taylor R., ARXIV; Tutubalina E., 2022, P 2022 C EMP METH NA, P596; Vaswani A., 2017, Advances in neural information processing systems, P6000; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	56	1	1	1	1	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	2041-6520	2041-6539		CHEM SCI	Chem. Sci.	JUN 5	2024	15	22					8380	8389		10.1039/d4sc00966e	http://dx.doi.org/10.1039/d4sc00966e		MAY 2024	10	Chemistry, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	TB9X1	38846388	gold, Green Submitted			2024-07-03	WOS:001216129700001
C	Snyder, C; Hutchins, NM; Cohn, C; Fonteles, JH; Biswas, G			Assoc Computing Machinery	Snyder, Caitlin; Hutchins, Nicole M.; Cohn, Clayton; Fonteles, Joyce Horn; Biswas, Gautam			Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM plus C Learning	FOURTEENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, LAK 2024			English	Proceedings Paper	14th Annual International Conference on Learning Analytics and Knowledge (LAK) - Learning Analytics in the Age of Artificial Intelligence	MAR 18-22, 2024	Kyoto, JAPAN	Soc Learning Analyt Res, ACM In Cooperat, SIGWEB, SIGCHI		collaboration; learning analytics; STEM; SRL	COMPUTATIONAL THINKING	This study introduces a methodology to investigate students ' collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework-specifically, Planning, Enacting, and Reflection-proposed in the literature, applying it to examine students ' collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students ' model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.	[Snyder, Caitlin; Hutchins, Nicole M.; Cohn, Clayton; Fonteles, Joyce Horn; Biswas, Gautam] Vanderbilt Univ, Nashville, TN 37235 USA	Vanderbilt University	Snyder, C (corresponding author), Vanderbilt Univ, Nashville, TN 37235 USA.	caitlin.r.snyder@vanderbilt.edu			NSF Cyberlearning grant [2017000]; NSF AI Institute [2112635]	NSF Cyberlearning grant; NSF AI Institute(National Science Foundation (NSF))	This work was supported by NSF Cyberlearning grant #2017000 and NSF AI Institute grant #2112635. We thank the anonymous reviewers for their constructive comments.	Alexander PA, 2011, EDUC PSYCHOL HANDB, P393; [Anonymous], 2009, Handbook of metacognition in education; Basu Satabdi, 2016, Res Pract Technol Enhanc Learn, V11, P13, DOI 10.1186/s41039-016-0036-2; Biswas G, 2016, INT J ARTIF INTELL E, V26, P350, DOI 10.1007/s40593-015-0057-9; Blikstein P., 2016, J LEARNING ANAL, V3, P220, DOI [10.18608/jla.2016.32.11, https://doi.org/10.18608/jla.2016.32.11, DOI 10.18608/JLA.2016.32.11]; Craig BA, 2002, HEALTH ECON, V11, P33, DOI 10.1002/hec.654; Dillenbourg P., 1999, COLLABORATIVE LEARNI, P1; Emara M, 2021, J LEARN ANAL, V8, P49, DOI 10.18608/jla.2021.7230; Grosch Josef, 1990, INT WORKSH COMP CONS; Grover S, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P999, DOI 10.1145/3159450.3159522; Grover S, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P245, DOI 10.1145/2876034.2893425; Hambrusch Susanne, 2009, SIGCSE Bulletin, V41, P183, DOI 10.1145/1539024.1508931; Hmelo-Silver Cindy E, 2023, Computer support for collaborative learning, P199; Hutchins NM, 2020, INT J ARTIF INTELL E, V30, P537, DOI 10.1007/s40593-020-00209-z; Hutchins NM, 2020, J SCI EDUC TECHNOL, V29, P83, DOI 10.1007/s10956-019-09804-9; Hutchins Nicole M, 2021, INT SOC LEARNING SCI; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kinnebrew JS, 2014, METACOGN LEARN, V9, P187, DOI 10.1007/s11409-014-9112-4; Knight Simon, 2017, Journal of Learning Analytics, V4, P3, DOI [10.18608/jla.2017.43, DOI 10.18608/JLA.2017.43, DOI 10.18608/JLA.2017.43.2]; Natl Res Council, 2012, FRAMEWORK FOR K-12 SCIENCE EDUCATION: PRACTICES, CROSSCUTTING CONCEPTS, AND CORE IDEAS, P1; Next Generation Science Standards NGSS Lead States, 2013, Next generation science standards: For states, by states; Panadero E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00422; Rakovic M, 2022, CONTEMP EDUC PSYCHOL, V68, DOI 10.1016/j.cedpsych.2021.102027; Roschelle J., 1995, Computer Supported Collaborative Learning. Proceedings NATO Advanced Research Workshop, P69; Rosenshine B, 1996, REV EDUC RES, V66, P181, DOI 10.3102/00346543066002181; Rummel N, 2009, INT J COMP-SUPP COLL, V4, P69, DOI 10.1007/s11412-008-9054-4; Sears DA, 2013, INSTR SCI, V41, P1153, DOI 10.1007/s11251-013-9271-8; Sengupta P, 2013, EDUC INF TECHNOL, V18, P351, DOI 10.1007/s10639-012-9240-x; Snyder Caitlin, 2019, P INT C COMP SUPP CO, P360; Weintrop D, 2016, J SCI EDUC TECHNOL, V25, P127, DOI 10.1007/s10956-015-9581-5; White B., 2009, Handbook of metacognition in education, P175; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215; Winne P.H., 2002, New directions in measures and methods, Advances in motivation and achievement, V12, P121; Wise AF., 2021, International Handbook of Computer-Supported Collaborative Learning, P425, DOI [DOI 10.1007/978-3-030-65291-323, 10.1007/978-3-030-65291-3_23, DOI 10.1007/978-3-030-65291-3_23]; Zhang NY, 2022, INT J ARTIF INTELL E, V32, P931, DOI 10.1007/s40593-021-00275-x	36	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1618-8				2024							540	550		10.1145/3636555.3636912	http://dx.doi.org/10.1145/3636555.3636912			11	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW6NI		hybrid			2024-07-03	WOS:001179044200050
J	Beauchemin, D; Saggion, H; Khoury, R				Beauchemin, David; Saggion, Horacio; Khoury, Richard			MeaningBERT: assessing meaning preservation between sentences	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						evaluation of text simplification systems; meaning preservation; automatic text simplification; lexical simplification; syntactic simplification; few-shot evaluation of text simplification systems		In the field of automatic text simplification, assessing whether or not the meaning of the original text has been preserved during simplification is of paramount importance. Metrics relying on n-gram overlap assessment may struggle to deal with simplifications which replace complex phrases with their simpler paraphrases. Current evaluation metrics for meaning preservation based on large language models (LLMs), such as BertScore in machine translation or QuestEval in summarization, have been proposed. However, none has a strong correlation with human judgment of meaning preservation. Moreover, such metrics have not been assessed in the context of text simplification research. In this study, we present a meta-evaluation of several metrics we apply to measure content similarity in text simplification. We also show that the metrics are unable to pass two trivial, inexpensive content preservation tests. Another contribution of this study is MeaningBERT (https://github.com/GRAAL-Research/MeaningBERT), a new trainable metric designed to assess meaning preservation between two sentences in text simplification, showing how it correlates with human judgment. To demonstrate its quality and versatility, we will also present a compilation of datasets used to assess meaning preservation and benchmark our study against a large selection of popular metrics.	[Beauchemin, David; Khoury, Richard] Univ Laval, Dept Comp Sci & Software Engn, Grp Res Artificial Intelligence, Quebec City, PQ, Canada; [Saggion, Horacio] Univ Pompeu Fabra, Dept Informat & Commun Technol, Large Scale Text Understanding Syst Lab, Nat Language Proc Grp, Barcelona, Spain	Laval University; Pompeu Fabra University	Beauchemin, D (corresponding author), Univ Laval, Dept Comp Sci & Software Engn, Grp Res Artificial Intelligence, Quebec City, PQ, Canada.	david.beauchemin@ift.ulaval.ca	Saggion, Horacio/D-2029-2013		This work was supported by NSERC research grants RDCPJ 537198-18 and FRQNT doctoral research grant. This research was made possible thanks to the support of Beneva, a Canadian insurance company who provided financial support in the form of a scholarship th [RDCPJ 537198-18]; NSERC; FRQNT; Canadian Research Council (CRSNG)	This work was supported by NSERC research grants RDCPJ 537198-18 and FRQNT doctoral research grant. This research was made possible thanks to the support of Beneva, a Canadian insurance company who provided financial support in the form of a scholarship th; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); FRQNT(Fonds de recherche du Quebec (FRQ)Fonds de recherche du Quebec - Nature et technologies (FRQNT)); Canadian Research Council (CRSNG)	We wish to thank the reviewers for their comments regarding our work and methodology.r This work was supported by NSERC research grants RDCPJ 537198-18 and FRQNT doctoral research grant. This research was made possible thanks to the support of Beneva, a Canadian insurance company who provided financial support in the form of a scholarship through a research grant in partnership with the Canadian Research Council (CRSNG) to DB.	Alva-Manchego F., 2020, Annual Meeting of the Association for Computational Linguistics, DOI [10.18653/v1/2020.acl-main.424, DOI 10.18653/V1/2020.ACL-MAIN.424]; Alva-Manchego F, 2021, COMPUT LINGUIST, V47, P861, DOI [10.1162/coli_a_00418, 10.1162/COLI_a_00418]; [Anonymous], 2005, Global Autonomous Language Exploitation (GALE); Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Flesh Rudolph., 1948, Elementary English, V25, P344; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Gunning R., 1969, Journal of Business Communication, V6, P3, DOI DOI 10.1177/002194366900600202; James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Laban P., 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, DOI [10.18653/v1/2020.acl-main.460, DOI 10.18653/V1/2020.ACL-MAIN.460]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Maddela M, 2023, Arxiv, DOI arXiv:2212.09739; MCLAUGHLIN GH, 1969, J READING, V12, P639; Mosbach Marius, 2021, INT C LEARN REPR; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rebuffel C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8029; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Saggion H., 2017, SYNTHESIS LECT HUMAN, V10, P1, DOI [DOI 10.2200/S00700ED1V01Y201602HLT032, 10.1007/978-3-031-02166-4]; Scialom T, 2021, Arxiv, DOI arXiv:2104.07560; Scialom T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6594; Scialom T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3246; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Sulem E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P738; Sulem Elior, 2018, Long Papers, V1, P685; van Hout R., 2007, Modelling and assessing vocabulary knowledge, P93, DOI [10.1017/CBO9780511667268, DOI 10.1017/CBO9780511667268]; Vasilyev O., 2020, Proceedings of the Evaluation and Comparison of NLP Systems Workshop, DOI [10.18653/v1/2020.eval4nlp-1.2, DOI 10.18653/V1/2020.EVAL4NLP-1.2]; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wubben S., 2012, P 50 ANN M ASS COMP, V1, P1015; Xu W., 2016, T ASS COMPUTATIONAL, V4, P401, DOI [DOI 10.1162/TACL_A_00107, DOI 10.1162/TACLA00107]; Xu Wei, 2015, Transactions of the Association for Computational Linguistics, V3, P283; Zar J.H., 2005, Encycl. Biostat., V7, DOI [10.1002/0470011815.b2a15150, DOI 10.1002/0470011815.B2A15150]; Zhang T., 2019, INT C LEARNING REPRE; Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563	36	0	0	1	1	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	SEP 22	2023	6								1223924	10.3389/frai.2023.1223924	http://dx.doi.org/10.3389/frai.2023.1223924			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	T2LQ6	37808622	gold, Green Published			2024-07-03	WOS:001076352800001
C	Dasbach-Prisk, A; DeWitt, C; Garcia, L			ACM	Dasbach-Prisk, AnMei; DeWitt, Cory; Garcia, Luis			SensorLoader: Bridging the Gap in Cyber-Physical Reverse Engineering Across Embedded Peripheral Devices	PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON SECURITY AND PRIVACY OF SENSING SYSTEMS, SENSORS S&P 2023			English	Proceedings Paper	1st International Workshop on Security and Privacy of Sensing Systems (Sensors S and P) Part of SenSys Conference	NOV 12-17, 2023	Istanbul, TURKEY	Assoc Comp Machinery		sensor security; reverse engineering; embedded systems		Safety-critical cyber-physical systems, such as autonomous vehicles and medical devices, are often driven by notions of state provided by sensor information translated through embedded firmware. This sensor pipeline is often a fragmented supply chain across vendors, and analyzing the associated security properties entails semantic reverse engineering of third-party software, i.e., mapping low-level software representations to cyber-physical models without access to source code. This mapping is a manual, time-consuming, and error-prone process. This paper introduces SensorLoader, a tool designed to automate mapping sensor semantics across all layers of closed-source software representations. SensorLoader exploits open-source knowledge, potentially derived from structured vendor description files or unstructured vendor datasheets, to extract and infer sensor semantics. We leverage large language models to extract sensor semantics from unstructured sources and map the semantics to memory maps and structures used by the Ghidra reverse engineering framework. We formalize the limitations of this automatic extraction and demonstrate how our approach can streamline the reverse engineering process for embedded systems. Preliminary evaluations suggest that SensorLoader can effectively and scalably aid in identifying vulnerabilities and deviations from expected behaviors, offering a more efficient pathway to secure cyber-physical systems.	[Dasbach-Prisk, AnMei] Cabrillo Coll, Aptos, CA 95003 USA; [DeWitt, Cory] Univ Southern Calif, Los Angeles, CA 90007 USA; [Garcia, Luis] Univ Utah, Kahlert Sch Comp, Salt Lake City, UT USA	University of Southern California; Utah System of Higher Education; University of Utah	Dasbach-Prisk, A (corresponding author), Cabrillo Coll, Aptos, CA 95003 USA.	anmei.dasbachprisk@gmail.com; cjdewitt@usc.edu; la.garcia@utah.edu		Garcia, Luis/0000-0002-5111-0694	University of Southern California, Information Sciences Institute's Research Experience for Undergraduate (REU) Site "SURF-I: Safe, Usable, Reliable and Fair Internet"; National Science Foundation [2051101, 2220312]	University of Southern California, Information Sciences Institute's Research Experience for Undergraduate (REU) Site "SURF-I: Safe, Usable, Reliable and Fair Internet"; National Science Foundation(National Science Foundation (NSF))	The research reported in this paper was sponsored in part by This research was done through the University of Southern California, Information Sciences Institute's Research Experience for Undergraduate (REU) Site "SURF-I: Safe, Usable, Reliable and Fair Internet". We thank the National Science Foundation for supporting the REU by NSF grant award #2051101, as well as Award #2220312. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of NSF or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.	Giechaskiel I, 2020, IEEE COMMUN SURV TUT, V22, P645, DOI 10.1109/COMST.2019.2952858; Gustafson Eric, 2023, Shimware: Toward Practical Security Retrofitting for Monolithic Firmware Images; Keliris A, 2018, Arxiv, DOI arXiv:1812.03478; Kim Taegyu, 2022, MobiSys '22: Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services, P69, DOI 10.1145/3498361.3538938; OpenAI, text-davinci-002; Osbourne Paul., Cmsis-svd repository and parsers; Sun PF, 2019, I C DEPEND SYS NETWO, P349, DOI 10.1109/DSN.2019.00045; Tsang Ryan, 2022, NETWORK DISTRIBUTED; Tychalas D, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2847; Wang HD, 2022, IEEE SEC PRIV WORKS, P236, DOI 10.1109/SPW54247.2022.9833887; Weideman Nicolaas, 2021, Checkmate '21: Proceedings of the 2021 Research on offensive and defensive techniques in the Context of Man At The End (MATE) Attacks, P59, DOI 10.1145/3465413.3488575; Wouters L, 2022, LECT NOTES COMPUT SC, V13211, P143, DOI 10.1007/978-3-030-99766-3_7	12	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0440-6				2023							30	36		10.1145/3628356.3630117	http://dx.doi.org/10.1145/3628356.3630117			7	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3PZ		hybrid			2024-07-03	WOS:001141320700005
C	Lin, JY; Dzeparoska, K; Tizghadam, A; Leon-Garcia, A		Bernardos, CJ; Martini, B; Rojas, E; Verdi, FL; Zhu, Z; Oki, E; Parzyjegla, H		Lin, Jieyu; Dzeparoska, Kristina; Tizghadam, Ali; Leon-Garcia, Alberto			AppleSeed: Intent-Based Multi-Domain Infrastructure Management via Few-Shot Learning	2023 IEEE 9TH INTERNATIONAL CONFERENCE ON NETWORK SOFTWARIZATION, NETSOFT	IEEE Conference on Network Softwarization		English	Proceedings Paper	9th IEEE International Conference on Network Softwarization (IEEE NetSoft) - Boosting Future Networks through Advanced Softwarization	JUN 19-23, 2023	Univ Carlos III Madrid, Madrid, SPAIN	IEEE, IEEE Commun Soc, Futurewei Technologies, TeraFlow	Univ Carlos III Madrid			Managing complex infrastructures in multi-domain settings is time-consuming and error-prone. Intent-based infrastructure management is a means to simplify management by allowing users to specify intents, i.e., high-level statements in natural language, that are automatically realized by the system. However, providing intent-based multi-domain infrastructure management poses a number of challenges: 1) intent translation; 2) plan execution and parallelization; 3) incompatible cross-domain abstractions. To tackle these challenges, we propose AppleSeed, an intent-based infrastructure management system that enables an end-to-end intent-to-deployment pipeline. AppleSeed uses few-shot learning for training a Large Language Model (LLM) to translate intents into intermediate programs, which are processed by a just-in-time compiler and a materialization module to automatically generate parallelizable, domain-specific executable programs. We evaluate the system in two use cases: Deep Packet Inspection (DPI); and machine learning training and inferencing. Our system achieves efficient intent translation into an execution plan with an average 22.3x lines of code to intent word ratio. It also speeds up the execution of the management plan by 1.7-2.6 times with our JIT compilation for parallelized execution compared to sequential execution.	[Lin, Jieyu; Dzeparoska, Kristina; Tizghadam, Ali; Leon-Garcia, Alberto] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada	University of Toronto	Lin, JY (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.	jieyu.lin@mail.utoronto.ca; kristina.dzeparoska@mail.utoronto.ca; ali.tizghadam@utoronto.ca; albertoleongarcia@utoronto.ca						Abhashkumar A, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P296, DOI 10.1145/3143361.3143380; [Anonymous], 2021, TERRAFORM; [Anonymous], 2021, Metro Ethernet Forum; [Anonymous], 2023, GPT-4 Technical Report; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Du N, 2022, PR MACH LEARN RES; Dzeparoska K, 2021, IEEE ACCESS, V9, P159882, DOI 10.1109/ACCESS.2021.3129990; Jacobs AS, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P625; Kim H., 2015, P 12 USENIX S NETWOR, P59; Kiran M, 2018, FUTURE GENER COMP SY, V79, P205, DOI 10.1016/j.future.2017.04.020; Mahtout Hocine, 2020, SNTA '20: Proceedings of the 3rd International Workshop on Systems and Network Telemetry and Analytics, P27, DOI 10.1145/3391812.3396269; Prakash C, 2015, ACM SIGCOMM COMP COM, V45, P29, DOI 10.1145/2829988.2787506; Soulé R, 2018, IEEE ACM T NETWORK, V26, P2188, DOI 10.1109/TNET.2018.2867239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]	15	2	2	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2693-9770		979-8-3503-9980-6	IEEE Confer on Netwo			2023							539	544		10.1109/NetSoft57336.2023.10175410	http://dx.doi.org/10.1109/NetSoft57336.2023.10175410			6	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BV4JS					2024-07-03	WOS:001032763600091
J	Gamble, JL; Ferguson, D; Yuen, J; Sheikh, A				Gamble, Joel; Ferguson, Duncan; Yuen, Joanna; Sheikh, Adnan			Limitations of GPT-3.5 and GPT-4 in Applying Fleischner Society Guidelines to Incidental Lung Nodules	CANADIAN ASSOCIATION OF RADIOLOGISTS JOURNAL-JOURNAL DE L ASSOCIATION CANADIENNE DES RADIOLOGISTES			English	Article						lung nodules; guidelines; GPT; machine learning; large language models	MANAGEMENT; STATEMENT; CT	Purpose: To evaluate the accuracy of GPT-3.5, GPT-4, and a fine-tuned GPT-3.5 model in applying Fleischner Society recommendations to lung nodules. Methods: We generated 10 lung nodule descriptions for each of the 12 nodule categories from the Fleischner Society guidelines, incorporating them into a single fictitious report (n = 120). GPT-3.5 and GPT-4 were prompted to make follow-up recommendations based on the reports. We then incorporated the full guidelines into the prompts and re-submitted them. Finally, we re-submitted the prompts to a fine-tuned GPT-3.5 model. Results were analyzed using binary accuracy analysis in R. Results: GPT-3.5 accuracy in applying Fleischner Society guidelines was 0.058 (95% CI: 0.02, 0.12). GPT-4 accuracy was improved at 0.15 (95% CI: 0.09, 0.23; P = .02 for accuracy comparison). In recommending PET-CT and/or biopsy, both GPT-3.5 and GPT-4 had an F-score of 0.00. After explicitly including the Fleischner Society guidelines in the prompt, GPT-3.5 and GPT-4 significantly improved their accuracy to 0.42 (95% CI: 0.33, 0.51; P < .001) and to 0.66 (95% CI: 0.57, 0.74; P < .001), respectively. GPT-4 remained significantly better than GPT-3.5 (P < .001). The fine-tuned GPT-3.5 model accuracy was 0.46 (95% CI: 0.37, 0.55), not different from the GPT-3.5 model with guidelines included (P = .53). Conclusion: GPT-3.5 and GPT-4 performed poorly in applying widely known guidelines and never correctly recommended biopsy. Flawed knowledge and reasoning both contributed to their poor performance. While GPT-4 was more accurate than GPT-3.5, its inaccuracy rate was unacceptable for clinical practice. These results underscore the limitations of large language models for knowledge and reasoning-based tasks.	[Gamble, Joel; Ferguson, Duncan; Yuen, Joanna; Sheikh, Adnan] Univ British Columbia, Dept Radiol, 2775 Laurel St, 11th Floor, Vancouver, BC V5Z 1M9, Canada	University of British Columbia	Gamble, JL (corresponding author), Univ British Columbia, Dept Radiol, 2775 Laurel St, 11th Floor, Vancouver, BC V5Z 1M9, Canada.	joel.gamble@mail.utoronto.ca						Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Haver HL, 2023, RADIOL-CARDIOTHORAC, V5, DOI 10.1148/ryct.230115; Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; MacMahon H, 2005, RADIOLOGY, V237, P395, DOI 10.1148/radiol.2372041887; MacMahon H, 2017, RADIOLOGY, V284, P228, DOI 10.1148/radiol.2017161659; Naidich DP, 2013, RADIOLOGY, V266, P304, DOI 10.1148/radiol.12120628; Pawelczyk M, 2024, Arxiv, DOI [arXiv:2310.07579, 10.48550/arXiv.2310.07579]; Peng A., 2023, GPT-3.5 turbo fine-tuning and API updates; R Core Team, 2023, R: A Language and Environment for Statistical Computing; Ramasamy SK, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231330; Rogasch JMM, 2023, J NUCL MED, V64, P1876, DOI 10.2967/jnumed.123.266114; Stewart M, 2023, Arxiv, DOI arXiv:2309.08181; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, ADV NEUR IN	20	0	0	10	10	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0846-5371	1488-2361		CAN ASSOC RADIOL J	Can. Assoc. Radiol. J.-J. Assoc. Can. Radiol.	MAY	2024	75	2					412	416		10.1177/08465371231218250	http://dx.doi.org/10.1177/08465371231218250			5	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	OR1T3	38146205	hybrid			2024-07-03	WOS:001208916100021
J	Yalamanchili, A; Sengupta, B; Song, J; Lim, S; Thomas, TO; Mittal, BB; Abazeed, ME; Teo, PT				Yalamanchili, Amulya; Sengupta, Bishwambhar; Song, Joshua; Lim, Sara; Thomas, Tarita O.; Mittal, Bharat B.; Abazeed, Mohamed E.; Teo, P. Troy			Quality of Large Language Model Responses to Radiation Oncology Patient Care Questions	JAMA NETWORK OPEN			English	Article							READABILITY FORMULA	Importance Artificial intelligence (AI) large language models (LLMs) demonstrate potential in simulating human-like dialogue. Their efficacy in accurate patient-clinician communication within radiation oncology has yet to be explored. Objective To determine an LLM's quality of responses to radiation oncology patient care questions using both domain-specific expertise and domain-agnostic metrics. Design, Setting, and Participants This cross-sectional study retrieved questions and answers from websites (accessed February 1 to March 20, 2023) affiliated with the National Cancer Institute and the Radiological Society of North America. These questions were used as queries for an AI LLM, ChatGPT version 3.5 (accessed February 20 to April 20, 2023), to prompt LLM-generated responses. Three radiation oncologists and 3 radiation physicists ranked the LLM-generated responses for relative factual correctness, relative completeness, and relative conciseness compared with online expert answers. Statistical analysis was performed from July to October 2023. Main Outcomes and Measures The LLM's responses were ranked by experts using domain-specific metrics such as relative correctness, conciseness, completeness, and potential harm compared with online expert answers on a 5-point Likert scale. Domain-agnostic metrics encompassing cosine similarity scores, readability scores, word count, lexicon, and syllable counts were computed as independent quality checks for LLM-generated responses. Results Of the 115 radiation oncology questions retrieved from 4 professional society websites, the LLM performed the same or better in 108 responses (94%) for relative correctness, 89 responses (77%) for completeness, and 105 responses (91%) for conciseness compared with expert answers. Only 2 LLM responses were ranked as having potential harm. The mean (SD) readability consensus score for expert answers was 10.63 (3.17) vs 13.64 (2.22) for LLM answers (P < .001), indicating 10th grade and college reading levels, respectively. The mean (SD) number of syllables was 327.35 (277.15) for expert vs 376.21 (107.89) for LLM answers (P = .07), the mean (SD) word count was 226.33 (191.92) for expert vs 246.26 (69.36) for LLM answers (P = .27), and the mean (SD) lexicon score was 200.15 (171.28) for expert vs 219.10 (61.59) for LLM answers (P = .24). Conclusions and Relevance In this cross-sectional study, the LLM generated accurate, comprehensive, and concise responses with minimal risk of harm, using language similar to human experts but at a higher reading level. These findings suggest the LLM's potential, with some retraining, as a valuable resource for patient queries in radiation oncology and other medical fields.	[Abazeed, Mohamed E.; Teo, P. Troy] Northwestern Univ, 251 Huron St,Galter Pavil LC-178, Chicago, IL 60611 USA; [Yalamanchili, Amulya; Sengupta, Bishwambhar; Song, Joshua; Lim, Sara; Thomas, Tarita O.; Mittal, Bharat B.; Abazeed, Mohamed E.; Teo, P. Troy] Northwestern Univ, Northwestern Mem Hosp, Robert H Lurie Comprehens Canc Ctr, Dept Radiat Oncol,Feinberg Sch Med, Chicago, IL USA	Northwestern University; Northwestern University; Feinberg School of Medicine; Robert H. Lurie Comprehensive Cancer Center; Ann & Robert H. Lurie Children's Hospital of Chicago; Northwestern Memorial Hospital	Abazeed, ME; Teo, PT (corresponding author), Northwestern Univ, 251 Huron St,Galter Pavil LC-178, Chicago, IL 60611 USA.	mabazeed@northwestern.edu; peng.teo1@northwestern.edu						Akbar F, 2021, J AM MED INFORM ASSN, V28, P923, DOI 10.1093/jamia/ocaa229; Answers RT, RTAnswers; Atwood TF, 2020, J APPL CLIN MED PHYS, V21, P305, DOI 10.1002/acm2.12942; Bingham B, 2022, JCO ONCOL PRACT, V18, P458, DOI 10.1200/OP.21.00644; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Boswell EN, 2015, TRANSL ANDROL UROL, V4, P160, DOI 10.3978/j.issn.2223-4683.2014.12.04; Burmeister J, 2023, INT J RADIAT ONCOL, V115, P233, DOI 10.1016/j.ijrobp.2022.10.011; cancer, 2014, Radiation Therapy and You: Support for People With Cancer-NCI; Cancer.Net, Side Effects of Radiation Therapy; Caylor J.S., 1973, Methodologies for determining reading requirements of military occupational specialities; Chall J., 1995, READABILITY REVISITE; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; Doshi R., Utilizing large Language Models to simplify radiology reports: a comparative analysis of ChatGPT3.5, ChatGPT4.0, Google bard, and microsoft bing n.d, DOI [10.1101/2023.06.04.23290786, DOI 10.1101/2023.06.04.23290786]; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; FRY E, 1968, J READING, V11, P513; Gaffney A, 2022, JAMA INTERN MED, V182, P564, DOI 10.1001/jamainternmed.2022.0372; Gunning Robert., 1952, TECHNIQUE CLEAR WRIT; Hay CM, 2018, INT J GYNECOL CANCER, V28, P1737, DOI 10.1097/IGC.0000000000001376; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Kincaid J.P., 1975, Derivation of new readability formulas (Automated Readability Index, Fog Count and Flesch Reading Ease formula) for Navy enlisted personnel; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Matsuyama RK, 2013, J CANCER EDUC, V28, P306, DOI 10.1007/s13187-013-0473-1; MCLAUGHLIN GH, 1969, J READING, V12, P639; Nguyen DD, 2021, INT J IMPOT RES, V33, P410, DOI 10.1038/s41443-020-00389-1; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Prabhu AV, 2016, INT J RADIAT ONCOL, V96, P521, DOI 10.1016/j.ijrobp.2016.06.2449; Raygor A.L., 1977, READING, P259; Rosenberg SA, 2017, PRACT RADIAT ONCOL, V7, P57, DOI 10.1016/j.prro.2016.07.008; Schnitzler L, 2017, PATIENT EDUC COUNS, V100, P112, DOI 10.1016/j.pec.2016.08.006; Sinsky CA, 2022, J GEN INTERN MED, V37, P4002, DOI 10.1007/s11606-022-07766-0; Thakur N, 2021, Arxiv, DOI arXiv:2010.08240; von Elm E, 2008, J CLIN EPIDEMIOL, V61, P344, DOI [10.1016/j.jclinepi.2007.11.008, 10.2471/BLT.07.045120]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	36	0	0	9	9	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	APR 2	2024	7	4							e244630	10.1001/jamanetworkopen.2024.4630	http://dx.doi.org/10.1001/jamanetworkopen.2024.4630			13	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	MZ9F0	38564215	gold			2024-07-03	WOS:001197566900004
J	Jeyaraman, M; Balaji, S; Jeyaraman, N; Yadav, S				Jeyaraman, Madhan; Balaji, Sangeetha; Jeyaraman, Naveen; Yadav, Sankalp			Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						secure multiparty computation; homo-morphic encryption; healthcare; large language models; chatgpt; artificial intelligence (ai)	PRIVACY; RACE; SEX; AGE	The integration of artificial intelligence (AI) into healthcare promises groundbreaking advancements in patient care, revolutionizing clinical diagnosis, predictive medicine, and decision-making. This transformative technology uses machine learning, natural language processing, and large language models (LLMs) to process and reason like human intelligence. OpenAI's ChatGPT, a sophisticated LLM, holds immense potential in medical practice, research, and education. However, as AI in healthcare gains momentum, it brings forth profound ethical challenges that demand careful consideration. This comprehensive review explores key ethical concerns in the domain, including privacy, transparency, trust, responsibility, bias, and data quality. Protecting patient privacy in data-driven healthcare is crucial, with potential implications for psychological well-being and data sharing. Strategies like homomorphic encryption (HE) and secure multiparty computation (SMPC) are vital to preserving confidentiality. Transparency and trustworthiness of AI systems are essential, particularly in high-risk decision-making scenarios. Explainable AI (XAI) emerges as a critical aspect, ensuring a clear understanding of AI-generated predictions. Cybersecurity becomes a pressing concern as AI's complexity creates vulnerabilities for potential breaches. Determining responsibility in AI-driven outcomes raises important questions, with debates on AI's moral agency and human accountability. Shifting from data ownership to data stewardship enables responsible data management in compliance with regulations. Addressing bias in healthcare data is crucial to avoid AI-driven inequities. Biases present in data collection and algorithm development can perpetuate healthcare disparities. A public-health approach is advocated to address inequalities and promote diversity in AI research and the workforce. Maintaining data quality is imperative in AI applications, with convolutional neural networks showing promise in multi-input/mixed data models, offering a comprehensive patient perspective. In this ever-evolving landscape, it is imperative to adopt a multidimensional approach involving policymakers, developers, healthcare practitioners, and patients to mitigate ethical concerns. By understanding and addressing these challenges, we can harness the full potential of AI in healthcare while ensuring ethical and equitable outcomes.	[Jeyaraman, Madhan; Jeyaraman, Naveen] ACS Med Coll & Hosp, Dr MGR Educ & Res Inst, Orthoped, Chennai, Tamil Nadu, India; [Balaji, Sangeetha] Omandurar Govt Estate, Govt Med Coll, Orthoped, Chennai, Tamil Nadu, India; [Yadav, Sankalp] Shri Madan Lal Khurana Chest Clin, Med, New Delhi, India		Yadav, S (corresponding author), Shri Madan Lal Khurana Chest Clin, Med, New Delhi, India.	drsankalpyadav@gmail.com	Yadav, Sankalp/C-8076-2016	Yadav, Sankalp/0000-0001-6367-7228				Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; [Anonymous], 2023, BING CHAT MICR EDG; [Anonymous], 2023, TRY BARD AI EXPT GOO; [Anonymous], 2023, ARE CHATB READ PRIV, DOI DOI 10.48550/ARXIV.2305.15008; [Anonymous], 2023, INTR CHATGPT; Ashburner JM, 2022, J AM HEART ASSOC, V11, DOI 10.1161/JAHA.122.026014; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Barragan-Montero A, 2021, PHYS MEDICA, V83, P242, DOI 10.1016/j.ejmp.2021.04.016; Bleher Hannah, 2022, AI Ethics, V2, P747, DOI 10.1007/s43681-022-00135-x; Boulemtafes A, 2020, NEUROCOMPUTING, V384, P21, DOI 10.1016/j.neucom.2019.11.041; Canales C, 2020, ANESTH ANALG, V130, P1234, DOI 10.1213/ANE.0000000000004728; Chaddad A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020634; Coeckelbergh M, 2020, SCI ENG ETHICS, V26, P2051, DOI 10.1007/s11948-019-00146-8; Fehr J, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10101923; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Grobler M, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.583723; Hagos DH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249916; Hashimoto DA, 2020, ANESTHESIOLOGY, V132, P379, DOI 10.1097/ALN.0000000000002960; Hunter B, 2022, CANCERS, V14, DOI 10.3390/cancers14061524; Istasy P, 2022, J MED INTERNET RES, V24, DOI 10.2196/39748; Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Khoury MJ, 2022, GENET MED, V24, P1630, DOI 10.1016/j.gim.2022.04.009; Kumar R, 2022, COMPUT SECUR, V120, DOI 10.1016/j.cose.2022.102821; Li F, 2022, AI-BASEL, V4, P28, DOI 10.3390/ai4010003; Marder SR, 2022, SCHIZOPHRENIA BULL, V48, P958, DOI 10.1093/schbul/sbac092; Murthy VH, 2004, JAMA-J AM MED ASSOC, V291, P2720, DOI 10.1001/jama.291.22.2720; Mvula Paul K, 2023, Discov Data, V1, P4, DOI 10.1007/s44248-023-00003-x; Obasa AE, 2023, S AFR J SCI, V119, DOI 10.17159/sajs.2023/14889; Prakash S, 2022, J PERS MED, V12, DOI 10.3390/jpm12111914; Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7; Qayyum A, 2021, IEEE REV BIOMED ENG, V14, P156, DOI 10.1109/RBME.2020.3013489; Ryan M, 2020, SCI ENG ETHICS, V26, P2749, DOI 10.1007/s11948-020-00228-y; Sabry F, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/4653923; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Saravi B, 2022, J PERS MED, V12, DOI 10.3390/jpm12040509; Schulman KA, 1999, NEW ENGL J MED, V340, P618, DOI 10.1056/NEJM199902253400806; Secinaro S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01488-9; Segar MW, 2022, JAMA CARDIOL, V7, P844, DOI 10.1001/jamacardio.2022.1900; Singh NM, 2022, NEUROINFORMATICS, V20, P943, DOI 10.1007/s12021-022-09572-9; Stanfill Mary H, 2019, Yearb Med Inform, V28, P56, DOI 10.1055/s-0039-1677913; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Verdicchio Mario, 2022, Philos Technol, V35, P11, DOI 10.1007/s13347-022-00506-6; Yadav A, 2023, ARTIF INTELL REV, V56, P12407, DOI 10.1007/s10462-023-10454-y; Yasaka K, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002707	45	20	20	17	24	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 10	2023	15	8							e43262	10.7759/cureus.43262	http://dx.doi.org/10.7759/cureus.43262			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	IT4I0	37692617	Green Published, gold			2024-07-03	WOS:001168567200012
J	Lent, HC; Ortner, VK; Karmisholt, KE; Wiegell, SR; Nissen, CV; Omland, SH; Kamstrup, MR; Togsverd-Bo, K; Haedersdal, M				Lent, Heather C.; Ortner, Vinzent K.; Karmisholt, Katrine E.; Wiegell, Stine R.; Nissen, Christoffer V.; Omland, Silje H.; Kamstrup, Maria R.; Togsverd-Bo, Katrine; Haedersdal, Merete			A chat about actinic keratosis: Examining capabilities and user experience of ChatGPT as a digital health technology in dermato-oncology	JEADV CLINICAL PRACTICE			English	Article						actinic keratosis; ChatGPT; large language models; natural language processing; skin cancer; user experience		BackgroundThe potential applications of artificial intelligence (AI) in dermatology are evolving rapidly. Chatbots are an emerging trend in healthcare that rely on large language models (LLMs) to generate answers to prompts from users. However, the factuality and user experience (UX) of such chatbots remain to be evaluated in the context of dermato-oncology.ObjectivesTo examine the potential of Chat Generative Pretrained Transformer (ChatGPT) as a reliable source of information in the context of actinic keratosis (AK) and to evaluate clinicians' attitudes and UX with regard to the chatbot.MethodsA set of 38 clinical questions were compiled and entered as natural language queries in separate, individual conversation threads in ChatGPT (OpenAI, default GPT 3.5). Questions pertain to patient education, diagnosis, and treatment. ChatGPT's responses were presented to a panel of 7 dermatologists for rating of factual accuracy, currency of information, and completeness of the response. Attitudes towards ChatGTP were explored qualitatively and quantitatively using a validated user experience questionnaire (UEQ).ResultsChatGPT answered 12 questions (31.6%) with an accurate, current, and complete response. ChatGPT performed best for questions on patient education, including pathogenesis of AK and potential risk factors, but struggled with diagnosis and treatment. Major deficits were seen in grading AK, providing up-to-date treatment guidance, and asserting incorrect information with unwarranted confidence. Further, responses were considered verbose with an average word count of 198 (SD 55) and overly alarming of the risk of malignant transformation. Based on UEQ responses, the expert panel considered ChatGPT an attractive and efficient tool, scoring highest for speed of information retrieval, but deemed the chatbot inaccurate and verbose, scoring lowest for clarity.ConclusionsWhile dermatologists rated ChatGPT high in UX, the underlying LLMs that enable such chatbots require further development to guarantee accuracy and concision required in a clinical setting.	[Lent, Heather C.; Omland, Silje H.] Aalborg Univ, Dept Comp Sci, Copenhagen, Denmark; [Ortner, Vinzent K.; Karmisholt, Katrine E.; Wiegell, Stine R.; Nissen, Christoffer V.; Kamstrup, Maria R.; Togsverd-Bo, Katrine; Haedersdal, Merete] Bispebjerg & Frederiksberg, Copenhagen Univ Hosp, Dept Dermatol, Nielsine Nielsens Vej 17,Entrance 9,2nd floor, DK-2400 Copenhagen NV, Denmark; [Ortner, Vinzent K.] Bispebjerg & Frederiksberg, Copenhagen Univ Hosp, Wound Healing Ctr, Nielsine Nielsens Vej 17,Entrance 9,2nd floor, DK-2400 Copenhagen NV, Denmark	Aalborg University; University of Copenhagen; University of Copenhagen	Ortner, VK (corresponding author), Bispebjerg & Frederiksberg, Copenhagen Univ Hosp, Dept Dermatol, Nielsine Nielsens Vej 17,Entrance 9,2nd floor, DK-2400 Copenhagen NV, Denmark.; Ortner, VK (corresponding author), Bispebjerg & Frederiksberg, Copenhagen Univ Hosp, Wound Healing Ctr, Nielsine Nielsens Vej 17,Entrance 9,2nd floor, DK-2400 Copenhagen NV, Denmark.	vinzent.kevin.ortner@regionh.dk			Carlsberg Foundation under an Accelerate career grant entitled "Multilingual Modelling for Resource-Poor Languages" [CF21-0454]; Carlsberg Foundation under an Accelerate career grant; Danish Research Center for Skin Cancer	Carlsberg Foundation under an Accelerate career grant entitled "Multilingual Modelling for Resource-Poor Languages"; Carlsberg Foundation under an Accelerate career grant; Danish Research Center for Skin Cancer	Heather C. Lent is funded by the Carlsberg Foundation under an Accelerate career grant entitled 'Multilingual Modelling for Resource-Poor Languages', Grant Code CF21-0454. The work was executed as a part of the Danish Research Center for Skin Cancer, a public-private research partnership between the Private Hospital Molholm, Aalborg University Hospital and Copenhagen University Hospital, Bispebjerg and Frederiksberg.	Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Akyurek E., 2022, FINDINGS ASS COMPUTA, P2429; [Anonymous], ChatGPT-Release Notes | OpenAI Help Center; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao BX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1860; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; EMA, 2020, Picato (ingenol mebutate): Suspension of the marketing authorisation due to risk skin malignancy; European Medicines Agency (EMA), 2021, Klisyri; Guo ZJ, 2022, T ASSOC COMPUT LING, V10, P178, DOI 10.1162/tacl_a_00454; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Kluger N, 2023, J EUR ACAD DERMATOL, V37, pE941, DOI 10.1111/jdv.19152; Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6; OLSEN EA, 1991, J AM ACAD DERMATOL, V24, P738, DOI 10.1016/0190-9622(91)70113-G; OpenAI, Introducing ChatGPT; OpenAI, API; OpenAI Help Center, How your data is used to improve model performance; Petroni F., 2020, arXiv; Rogers A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2182; Sadeq N, 2023, Arxiv, DOI arXiv:2304.01597; The Lancet Digital Health, 2023, Lancet Digit Health, V5, P102; Werner RN, 2013, BRIT J DERMATOL, V169, P502, DOI 10.1111/bjd.12420; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xiong WH, 2019, Arxiv, DOI arXiv:1912.09637	24	0	1	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2768-6566			JEADV CLIN PRACT	JEADV Clin. Pract.	MAR	2024	3	1					258	265		10.1002/jvc2.263	http://dx.doi.org/10.1002/jvc2.263			8	Dermatology	Emerging Sources Citation Index (ESCI)	Dermatology	PT1K7		gold			2024-07-03	WOS:001216241300001
J	Abdullahi, T; Singh, R; Eickhoff, C				Abdullahi, Tassallah; Singh, Ritambhara; Eickhoff, Carsten			Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models	JMIR MEDICAL EDUCATION			English	Article						clinical decision support; rare diseases; complex diseases; prompt engineering; reliability; consistency; natural language processing; language model; Bard; ChatGPT 3.5; GPT-4; MedAlpaca; medical education; complex diagnosis; artificial intelligence; AI assistance; medical training; prediction model		Background: Patients with rare and complex diseases often experience delayed diagnoses and misdiagnoses because comprehensive knowledge about these diseases is limited to only a few medical experts. In this context, large language models (LLMs) have emerged as powerful knowledge aggregation tools with applications in clinical decision support and education domains. Objective: This study aims to explore the potential of 3 popular LLMs, namely Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical education to enhance the diagnosis of rare and complex diseases while investigating the impact of prompt engineering on their performance. Methods: We conducted experiments on publicly available complex and rare cases to achieve these objectives. We implemented various prompt strategies to evaluate the performance of these models using both open-ended and multiple-choice prompts. In addition, we used a majority voting strategy to leverage diverse reasoning paths within language models, aiming to enhance their reliability. Furthermore, we compared their performance with the performance of human respondents and MedAlpaca, a generative LLM specifically designed for medical tasks. Results: Notably, all LLMs outperformed the average human consensus and MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 cases from the diagnostic case challenge collection. On the frequently misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca and the human respondents on the moderately often misdiagnosed cases category with minimum accuracy scores of 28% and 11%, respectively. The majority voting strategy, particularly with GPT-4, demonstrated the highest overall score across all cases from the diagnostic complex case collection, surpassing that of other LLMs. On the Medical Information Mart for Intensive Care -III data sets, Bard and GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, respectively. Furthermore, our results demonstrate that there is no one -size -fits -all prompting approach for improving the performance of LLMs and that a single strategy does not universally apply to all LLMs. Conclusions: Our findings shed light on the diagnostic capabilities of LLMs and the challenges associated with identifying an optimal prompting strategy that aligns with each language model's characteristics and specific task requirements. The significance of prompt engineering is highlighted, providing valuable insights for researchers and practitioners who use these language models for medical training. Furthermore, this study represents a crucial step toward understanding how LLMs can enhance diagnostic reasoning in rare and complex medical cases, paving the way for developing effective educational tools and accurate diagnostic aids to improve patient care and outcomes.	[Abdullahi, Tassallah; Singh, Ritambhara] Brown Univ, Dept Comp Sci, Providence, RI USA; [Singh, Ritambhara] Brown Univ, Ctr Computat Mol Biol, Providence, RI USA; [Eickhoff, Carsten] Univ Tubingen, Sch Med, Tubingen, Germany	Brown University; Brown University; Eberhard Karls University of Tubingen	Eickhoff, C (corresponding author), Univ Tubingen, Sch Med, Schaffhausenstr 77, D-72072 Tubingen, Germany.	carsten.eickhoff@uni-tuebingen.de		Eickhoff, Carsten/0000-0001-9895-4061	University of Tubingen	University of Tubingen	We acknowledge support from the Open Access Publication Fund of the University of Tubingen.	Abdullahi TA, 2023, PREPRINT, DOI [10.2196/preprints.50209, DOI 10.2196/PREPRINTS.50209]; Achiam J, GPT-4 technical report; [Anonymous], Introducing chatgpt; [Anonymous], codiag-public / dc3.; [Anonymous], NIH investigator manual for human subjects research; [Anonymous], Orphanet About Rare Diseases; Bateman L, 2021, MAYO CLIN PROC, V96, P2861, DOI 10.1016/j.mayocp.2021.07.004; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Decherchi S, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.747612; Eckleberry-Hunt Jodie, 2018, J Grad Med Educ, V10, P378, DOI 10.4300/JGME-D-18-00466.1; Eickhoff C, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P140, DOI 10.1145/3341981.3344239; Faviez C, 2020, ORPHANET J RARE DIS, V15, DOI 10.1186/s13023-020-01374-z; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li YF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5315; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Manyika J., An overview of Bard: An Early Experiment with Generative AI; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Mitani AA, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.1965; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pollard T, 2016, PHYSIONET; Resnick Daniel K, 2023, Neurosurgery, V93, pe123, DOI 10.1227/neu.0000000000002618; Sartorious Norman, 2013, Shanghai Arch Psychiatry, V25, P68, DOI 10.3969/j.issn.1002-0829.2013.02.002; Sutton RT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0221-y; van Aken B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P881; Walkowiak D, 2021, ORPHANET J RARE DIS, V16, DOI 10.1186/s13023-021-02023-9	30	2	2	19	19	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e51391	10.2196/51391	http://dx.doi.org/10.2196/51391			11	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IN3M6	38349725	gold, Green Published			2024-07-03	WOS:001166966500001
J	Roos, J; Kasapovic, A; Jansen, T; Kaczmarczyk, R				Roos, Jonas; Kasapovic, Adnan; Jansen, Tom; Kaczmarczyk, Robert			Artificial Intelligence in Medical Education: Comparative Analysis of ChatGPT, Bing, and Medical Students in Germany	JMIR MEDICAL EDUCATION			English	Article						medical education; state examinations; exams; large language models; artificial intelligence; ChatGPT		Background: Large language models (LLMs) have demonstrated significant potential in diverse domains, including medicine. Nonetheless, there is a scarcity of studies examining their performance in medical examinations, especially those conducted in languages other than English, and in direct comparison with medical students. Analyzing the performance of LLMs in state medical examinations can provide insights into their capabilities and limitations and evaluate their potential role in medical education and examination preparation.Objective: This study aimed to assess and compare the performance of 3 LLMs, GPT-4, Bing, and GPT-3.5-Turbo, in the German Medical State Examinations of 2022 and to evaluate their performance relative to that of medical students.Methods: The LLMs were assessed on a total of 630 questions from the spring and fall German Medical State Examinations of 2022. The performance was evaluated with and without media-related questions. Statistical analyses included 1-way ANOVA and independent samples t tests for pairwise comparisons. The relative strength of the LLMs in comparison with that of the students was also evaluated.Results: GPT-4 achieved the highest overall performance, correctly answering 88.1% of questions, closely followed by Bing (86.0%) and GPT-3.5-Turbo (65.7%). The students had an average correct answer rate of 74.6%. Both GPT-4 and Bing significantly outperformed the students in both examinations. When media questions were excluded, Bing achieved the highest performance of 90.7%, closely followed by GPT-4 (90.4%), while GPT-3.5-Turbo lagged (68.2%). There was a significant decline in the performance of GPT-4 and Bing in the fall 2022 examination, which was attributed to a higher proportion of media-related questions and a potential increase in question difficulty.Conclusions: LLMs, particularly GPT-4 and Bing, demonstrate potential as valuable tools in medical education and for pretesting examination questions. Their high performance, even relative to that of medical students, indicates promising avenues for further development and integration into the educational and clinical landscape.	[Roos, Jonas; Kasapovic, Adnan; Jansen, Tom] Univ Hosp Bonn, Dept Orthoped & Trauma Surg, Bonn, Germany; [Kaczmarczyk, Robert] Tech Univ Munich, Dept Dermatol & Allergy, Munich, Germany; [Kaczmarczyk, Robert] Tech Univ Munich, Dept Dermatol & Allergy, Biedersteiner Str 29, D-80802 Munich, Germany	University of Bonn; Technical University of Munich; Technical University of Munich	Kaczmarczyk, R (corresponding author), Tech Univ Munich, Dept Dermatol & Allergy, Biedersteiner Str 29, D-80802 Munich, Germany.	robert.kaczmarczyk@tum.de		Roos, Jonas/0000-0001-8843-4695				[Anonymous], openai-python; [Anonymous], ARCHIV; [Anonymous], Introducing the new Bing.; [Anonymous], Introducing chatgpt; [Anonymous], EdgeGPT; [Anonymous], Medizinwissen, auf das man sich verlassen kann-denn Wissen ist Grundlage jeder klinischen Entscheidung; [Anonymous], What Is ChatGPT?; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Breen A, 2023, Entrepreneur; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chow A. R., 2023, Time; google, PaLM 2. Google AI; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Laukkonen J, 2023, What Is Microsoft's Bing AI Chatbot?; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Martindale J, 2023, GPT-4 vs. ChatGPT: just how much better is the latest version?; Mehdi Y., 2023, Official Microsoft Blog; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nikendei C, 2009, MED TEACH, V31, P591, DOI 10.1080/01421590902833010; Novet J, 2023, CNBC; Palmowski A, 2022, GESUNDHEITSWESEN, V84, P1067, DOI 10.1055/a-1306-0335; Pichai S., 2023, IMPORTANT NEXT STEP; Rosenbloom L., 2019, The Charleston Advisor, V21, P8, DOI [10.5260/chara.21.2.8, DOI 10.5260/CHARA.21.2.8]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887	25	11	12	19	29	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e46482	10.2196/46482	http://dx.doi.org/10.2196/46482			7	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	U6UX6	37665620	Green Published, gold			2024-07-03	WOS:001086147600001
J	Szabó, Z; Bilicki, V				Szabo, Zoltan; Bilicki, Vilmos			A New Approach to Web Application Security: Utilizing GPT Language Models for Source Code Inspection	FUTURE INTERNET			English	Article						large language models; GPT; sensitive data; vulnerability detection; CWE-653; Angular; static code analysis	ACCESS-CONTROL	Due to the proliferation of large language models (LLMs) and their widespread use in applications such as ChatGPT, there has been a significant increase in interest in AI over the past year. Multiple researchers have raised the question: how will AI be applied and in what areas? Programming, including the generation, interpretation, analysis, and documentation of static program code based on promptsis one of the most promising fields. With the GPT API, we have explored a new aspect of this: static analysis of the source code of front-end applications at the endpoints of the data path. Our focus was the detection of the CWE-653 vulnerability-inadequately isolated sensitive code segments that could lead to unauthorized access or data leakage. This type of vulnerability detection consists of the detection of code segments dealing with sensitive data and the categorization of the isolation and protection levels of those segments that were previously not feasible without human intervention. However, we believed that the interpretive capabilities of GPT models could be explored to create a set of prompts to detect these cases on a file-by-file basis for the applications under study, and the efficiency of the method could pave the way for additional analysis tasks that were previously unavailable for automation. In the introduction to our paper, we characterize in detail the problem space of vulnerability and weakness detection, the challenges of the domain, and the advances that have been achieved in similarly complex areas using GPT or other LLMs. Then, we present our methodology, which includes our classification of sensitive data and protection levels. This is followed by the process of preprocessing, analyzing, and evaluating static code. This was achieved through a series of GPT prompts containing parts of static source code, utilizing few-shot examples and chain-of-thought techniques that detected sensitive code segments and mapped the complex code base into manageable JSON structures.Finally, we present our findings and evaluation of the open source project analysis, comparing the results of the GPT-based pipelines with manual evaluations, highlighting that the field yields a high research value. The results show a vulnerability detection rate for this particular type of model of 88.76%, among others.	[Szabo, Zoltan; Bilicki, Vilmos] Univ Szeged, Dept Software Engn, Dugon Sq 13, H-6720 Szeged, Hungary	Szeged University	Szabó, Z (corresponding author), Univ Szeged, Dept Software Engn, Dugon Sq 13, H-6720 Szeged, Hungary.	szaboz@inf.u-szeged.hu; bilickiv@inf.u-szeged.hu		Szabo, Zoltan/0000-0003-3863-7595; Bilicki, Vilmos/0000-0002-7793-2661	Ministry of Innovation and Technology NRDI Office [RRF-2.3.1-21-2022-00004]; Ministry of Innovation and Technology of Hungary from the National Research, Development and Innovation Fund under the TKP2021-NVA funding scheme [TKP2021-NVA-09]	Ministry of Innovation and Technology NRDI Office(National Research, Development & Innovation Office (NRDIO) - Hungary); Ministry of Innovation and Technology of Hungary from the National Research, Development and Innovation Fund under the TKP2021-NVA funding scheme	The research was supported by the Ministry of Innovation and Technology NRDI Office within the framework of the Artificial Intelligence National Laboratory Program (RRF-2.3.1-21-2022-00004). Project No. TKP2021-NVA-09 has been implemented with the support provided by the Ministry of Innovation and Technology of Hungary from the National Research, Development and Innovation Fund, financed under the TKP2021-NVA funding scheme	Angular, INTR ANG DOCS; Borji A., 2023, SSRN Electron. J., DOI [10.2139/SSRN.4476855, DOI 10.2139/SSRN.4476855]; Botti-Cebria V., 2020, P 13 INT C COMP INT, P184, DOI [10.1007/978-3-030-57805-3_18, DOI 10.1007/978-3-030-57805-3_18]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cheshkov A, 2023, Arxiv, DOI arXiv:2304.07232; Chua HN, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102453; Cui JF, 2020, COMPUT COMMUN, V155, P125, DOI 10.1016/j.comcom.2020.02.078; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Ferraiolo D. E., 1995, Proceedings. 11th Annual Computer Security Applications Conference, P241; Giordano M, 2013, IEEE SOFTWARE, V30, P62, DOI 10.1109/MS.2012.112; HEYDON A, 1990, IEEE T SOFTWARE ENG, V16, P1185, DOI 10.1109/32.60298; Hossain Misu M.R., 2017, P 12 INT C SOFTW ENG; Hourani H., 2019, 2019 IEEE JORD INT, DOI [DOI 10.1109/jeeit.2019.8717439, 10.1109/jeeit.2019.8717439]; Jánki ZR, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12153364; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang L, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P614, DOI 10.1109/ASE.2019.00062; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Kokrehel G., 2022, Pollack Period, V17, P7, DOI [10.1556/606.2021.00372, DOI 10.1556/606.2021.00372]; Lang C, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P655, DOI 10.1145/3375462.3375506; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Martin B., 2011, SANS Top, V25; Martin R.C., 2013, Getting a SOLID Start; Mhawish MY, 2020, J COMPUT SCI TECH-CH, V35, P1428, DOI 10.1007/s11390-020-0323-7; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Momeni P, 2019, ANN CONF PRIV SECUR, P272, DOI 10.1109/pst47121.2019.8949045; Omar M, 2023, Arxiv, DOI [arXiv:2302.11773, 10.48550/arXiv.2302.11773]; openai, What Is the Difference between the GPT-4 Models?; openai, 2023, OpenAI-Privacy Policy; openai, Pricing of GPT; Park S, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/3035741; Qiu R., 2023, Digital Transformation and Society, V2, P101, DOI DOI 10.1108/DTS-05-2023-066; Rainey S, 2021, J LAW BIOSCI, V7, DOI 10.1093/jlb/lsaa051; Rumbold JMM, 2018, BIG DATA RES, V12, P49, DOI 10.1016/j.bdr.2017.11.001; Saglam RB, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103163; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sarkar A, 2022, Arxiv, DOI arXiv:2208.06213; Sharma Tushar, 2021, arXiv, DOI 10.48550/ARXIV.2110.09610; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Sun YQ, 2024, Arxiv, DOI arXiv:2308.03314; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Szabó Z, 2021, ACTA CYBERN, V25, P485, DOI 10.14232/actacyb.290283; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu JJ, 2021, Arxiv, DOI arXiv:2104.11230; Yuan E, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, PROCEEDINGS, P561	48	3	3	9	10	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1999-5903		FUTURE INTERNET	Future Internet	OCT	2023	15	10							326	10.3390/fi15100326	http://dx.doi.org/10.3390/fi15100326			27	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	W9YZ5		gold			2024-07-03	WOS:001095127100001
C	Tomar, M; Tiwari, A; Saha, T; Jha, P; Saha, S		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Tomar, Mohit; Tiwari, Abhisek; Saha, Tulika; Jha, Prince; Saha, Sriparna			<i>An EcoSage Assistant</i>: Towards Building A Multimodal Plant Care Dialogue Assistant	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Plant Care; Virtual Assistant; Large Language Models (LLMs); Multi-modal infusion; Dialogue Generation		In recent times, there has been an increasing awareness about imminent environmental challenges, resulting in people showing a stronger dedication to taking care of the environment and nurturing green life. The current $19.6 billion indoor gardening industry, reflective of this growing sentiment, not only signifies a monetary value but also speaks of a profound human desire to reconnect with the natural world. However, several recent surveys cast a revealing light on the fate of plants within our care, with more than half succumbing primarily due to the silent menace of improper care. Thus, the need for accessible expertise capable of assisting and guiding individuals through the intricacies of plant care has become paramount more than ever. In this work, we make the very first attempt at building a plant care assistant, which aims to assist people with plant(-ing) concerns through conversations. We propose a plant care conversational dataset named Plantational, which contains around 1K dialogues between users and plant care experts. Our endto-end proposed approach is two-fold: (i) We first benchmark the dataset with the help of various large language models (LLMs) and visual language model (VLM) by studying the impact of instruction tuning (zeroshot and few-shot prompting) and fine-tuning techniques on this task; (ii) finally, we build EcoSage, a multi-modal plant care assisting dialogue generation framework, incorporating an adapter-based modality infusion using a gated mechanism. We performed an extensive examination (both automated and manual evaluation) of the performance exhibited by various LLMs and VLM in the generation of the domain-specific dialogue responses to underscore the respective strengths and weaknesses of these diverse models (The dataset and code are available at https://github.com/mohit2b/EcoSage).	[Tomar, Mohit; Tiwari, Abhisek; Jha, Prince; Saha, Sriparna] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India; [Saha, Tulika] Univ Liverpool, Dept Comp Sci & Engn, Liverpool, Merseyside, England	Indian Institute of Technology (IIT) - Patna; Indian Institute of Technology System (IIT System); University of Liverpool	Tomar, M (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.	mohitsinghtomar9797@gmail.com; abhisek_1921cs16@iitp.ac.in; tulika.saha@liverpool.ac.uk; jhapks1999@gmail.com; sriparna@iitp.ac.in			Young Faculty Research Fellowship (YFRF) Award - Visvesvaraya Ph.D. Scheme for Electronics and IT, Ministry of Electronics; Prime Minister Research Fellowship (PMRF) Award provided by the Government of India	Young Faculty Research Fellowship (YFRF) Award - Visvesvaraya Ph.D. Scheme for Electronics and IT, Ministry of Electronics; Prime Minister Research Fellowship (PMRF) Award provided by the Government of India	Dr. Sriparna Saha extends heartfelt gratitude for the Young Faculty Research Fellowship (YFRF) Award, supported by the Visvesvaraya Ph.D. Scheme for Electronics and IT, Ministry of Electronics. Abhisek Tiwari expresses sincere gratitude for the support received by the Prime Minister Research Fellowship (PMRF) Award provided by the Government of India. This grant has played a role in supporting this research endeavor. We also thank Rachit Ranjan, Ujjwal Kumar, Kushagra Shree, and other annotators for the dataset development.	Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Awadalla Anas, 2023, Zenodo; Baevski A, 2022, PR MACH LEARN RES; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Black Sid, 2021, Zenodo; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Fenu G, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11112107; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Glaese A, 2022, arXiv; Jain R., 2023, Findings of the Association for Computational Linguistics: EMNLP 2023, P3158; Jain R., 2023, ECAI 2023, P1132; Jain R, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892890; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu XD, 2021, IEEE T IMAGE PROCESS, V30, P2003, DOI 10.1109/TIP.2021.3049334; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; OpenAI, 2023, : GPT-4 technical report.; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paszke A, 2019, ADV NEUR IN, V32; Peng BL, 2022, Arxiv, DOI arXiv:2206.11309; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Saha T, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533924; Saha T, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2436; Saha T, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2650, DOI 10.1145/3477495.3531912; Saha T, 2023, IEEE T COMPUT SOC SY, V10, P1130, DOI 10.1109/TCSS.2022.3143763; Schulman J, 2022, Introducing chatgpt; Singh D, 2020, ACM INT CONF PR SER, P249, DOI 10.1145/3371158.3371196; Smith S, 2022, arXiv; Tiwari A, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-05032-y; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	46	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						318	332		10.1007/978-3-031-56060-6_21	http://dx.doi.org/10.1007/978-3-031-56060-6_21			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY		Green Submitted			2024-07-03	WOS:001211832000021
J	Scquizzato, T; Semeraro, F; Swindell, P; Simpson, R; Angelini, M; Gazzato, A; Sajjad, U; Bignami, EG; Landoni, G; Keeble, TR; Mion, M				Scquizzato, Tommaso; Semeraro, Federico; Swindell, Paul; Simpson, Rupert; Angelini, Matteo; Gazzato, Arianna; Sajjad, Uzma; Bignami, Elena G.; Landoni, Giovanni; Keeble, Thomas R.; Mion, Marco			Simulation and education Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation	RESUSCITATION			English	Article						Out-of-hospital cardiac arrest; Cardiopulmonary resuscitation; Artificial intelligence; Large language model; ChatGPT	EPIDEMIOLOGY	Introduction: Cardiac arrest leaves witnesses, survivors, and their relatives with a multitude of questions. When a young or a public figure is affected, interest around cardiac arrest and cardiopulmonary resuscitation (CPR) increases. ChatGPT allows everyone to obtain human-like responses on any topic. Due to the risks of accessing incorrect information, we assessed ChatGPT accuracy in answering laypeople questions about cardiac arrest and CPR.Methods: We co-produced a list of 40 questions with members of Sudden Cardiac Arrest UK covering all aspects of cardiac arrest and CPR. Answers provided by ChatGPT to each question were evaluated by professionals for their accuracy, by professionals and laypeople for their rele-vance, clarity, comprehensiveness, and overall value on a scale from 1 (poor) to 5 (excellent), and for readability.Results: ChatGPT answers received an overall positive evaluation (4.3 +/- 0.7) by 14 professionals and 16 laypeople. Also, clarity (4.4 +/- 0.6), rel-evance (4.3 +/- 0.6), accuracy (4.0 +/- 0.6), and comprehensiveness (4.2 +/- 0.7) of answers was rated high. Professionals, however, rated overall value (4.0 +/- 0.5 vs 4.6 +/- 0.7; p = 0.02) and comprehensiveness (3.9 +/- 0.6 vs 4.5 +/- 0.7; p = 0.02) lower compared to laypeople. CPR-related answers consistently received a lower score across all parameters by professionals and laypeople. Readability was 'difficult' (median Flesch reading ease score of 34 [IQR 26-42]).Conclusions: ChatGPT provided largely accurate, relevant, and comprehensive answers to questions about cardiac arrest commonly asked by survivors, their relatives, and lay rescuers, except CPR-related answers that received the lowest scores. Large language model will play a significant role in the future and healthcare-related content generated should be monitored.	[Mion, Marco] Mid & South Essex NHS Fdn Trust, Essex Cardiothorac Ctr, Basildon, England; [Scquizzato, Tommaso; Angelini, Matteo; Gazzato, Arianna; Landoni, Giovanni] IRCCS San Raffaele Sci Inst, Dept Anesthesia & Intens Care, Milan, Italy; [Semeraro, Federico] Osped Maggiore Bologna, Dept Anaesthesia Intens Care & Emergency Med Serv, Bologna, Italy; [Swindell, Paul] Sudden Cardiac Arrest UK, Benfleet, England; [Simpson, Rupert; Sajjad, Uzma; Keeble, Thomas R.; Mion, Marco] Mid & South Essex NHS Fdn Trust, Essex Cardiothor Acic Ctr, Basildon, England; [Bignami, Elena G.; Keeble, Thomas R.; Mion, Marco] Univ Parma, Dept Med & Surg, Anesthesiol Crit Care & Pain Med Div, Parma, Italy; [Simpson, Rupert; Sajjad, Uzma] Anglia Ruskin Sch Med, Med Technol Res Ctr, Chelmsford, England; [Landoni, Giovanni] Univ Vita Salute San Raffaele, Sch Med, Milan, Italy	Vita-Salute San Raffaele University; IRCCS Ospedale San Raffaele; AUSL di Bologna; University of Parma; Vita-Salute San Raffaele University	Mion, M (corresponding author), Mid & South Essex NHS Fdn Trust, Essex Cardiothorac Ctr, Basildon, England.	m.mion@nhs.net	Scquizzato, Tommaso/AAN-5554-2020; Landoni, Giovanni/AAH-1881-2019	Scquizzato, Tommaso/0000-0002-1394-8402; Landoni, Giovanni/0000-0002-8594-5980; Mion, Marco/0000-0002-3656-5965				Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Atwood C, 2005, RESUSCITATION, V67, P75, DOI 10.1016/j.resuscitation.2005.03.021; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baumgartner C, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1206; Daraz L, 2019, J GEN INTERN MED, V34, P1884, DOI 10.1007/s11606-019-05109-0; Dee R, 2021, RESUSCITATION, V162, P73, DOI 10.1016/j.resuscitation.2021.01.027; Field RA, 2011, J ROY SOC MED, V104, P525, DOI 10.1258/jrsm.2011.110228; Fijacko N, 2021, RESUSCITATION, V167, P427, DOI 10.1016/j.resuscitation.2021.07.018; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gräsner JT, 2021, RESUSCITATION, V161, P61, DOI 10.1016/j.resuscitation.2021.02.007; Grubic N, 2023, AM J EMERG MED, V67, P179, DOI 10.1016/j.ajem.2023.03.015; Haman M, 2023, RESUSCITATION, V187, DOI 10.1016/j.resuscitation.2023.109795; Jacobs HR, 2023, RESUSCITATION, V186, DOI 10.1016/j.resuscitation.2023.109789; Mion M, 2021, RESUSC PLUS, V7, DOI 10.1016/j.resplu.2021.100154; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Rea TD, 2004, RESUSCITATION, V63, P17, DOI 10.1016/j.resuscitation.2004.03.025; Scquizzato T, 2022, Resuscitation, V175, pS59; Scquizzato T, 2021, RESUSCITATION, V160, P68, DOI 10.1016/j.resuscitation.2021.01.002; Trethewey SP, 2018, RESUSCITATION, V133, pE7, DOI 10.1016/j.resuscitation.2018.10.003; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479	21	1	1	2	2	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0300-9572	1873-1570		RESUSCITATION	Resuscitation	JAN	2024	194								110077	10.1016/j.resuscitation.2023.110077	http://dx.doi.org/10.1016/j.resuscitation.2023.110077		DEC 2023	5	Critical Care Medicine; Emergency Medicine	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Emergency Medicine	FD1E7	38081504				2024-07-03	WOS:001143715800001
C	Yan, DP; Gao, ZP; Liu, ZM			IEEE	Yan, Dapeng; Gao, Zhipeng; Liu, Zhiming			A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		code generation; program competition; ChatGPT; large language model; clean code		Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.	[Yan, Dapeng] Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China; [Gao, Zhipeng] Zhejiang Univ, Hangzhou, Peoples R China; [Liu, Zhiming] Southwest Univ, Chongqing, Peoples R China	Nanjing University of Aeronautics & Astronautics; Zhejiang University; Southwest University - China	Gao, ZP (corresponding author), Zhejiang Univ, Hangzhou, Peoples R China.	dapeng.yan@nuaa.edu.cn; zhipeng.gao@zju.edu.cn; zliu@nwpu.edu.cn	Yan, Dapeng/A-2677-2015	GAO, Zhipeng/0000-0003-3030-9917	Shanghai Rising-Star Program [23YF1446900]; National Science Foundation of China [62202341]; Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study [SN-ZJU-SIAS-001]	Shanghai Rising-Star Program; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study	This research is partially supported by the Shanghai Rising-Star Program (23YF1446900) and the National Science Foundation of China (No. 62202341). This research is partially supported by the Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study, Grant No. SN-ZJU-SIAS-001.	[Anonymous], 2016, 150k python dataset; [Anonymous], Source code of experiments; Hayati SA, 2018, Arxiv, DOI arXiv:1808.10025; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Chen M., 2021, arXiv; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Xu FF, 2020, Arxiv, DOI [arXiv:2004.09015, 10.48550/ARXIV.2004.09015]; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gao ZP, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3550150; Gao ZP, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1525, DOI 10.1145/3468264.3473114; Gao ZP, 2021, ACM T SOFTW ENG METH, V30, DOI 10.1145/3412845; Gao ZP, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3401026; Google, Google style guides; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hendrycks D, 2021, Arxiv, DOI arXiv:2105.09938; Hu X, 2022, PROC INT CONF SOFTW, P1693, DOI 10.1145/3510003.3510152; Hu X, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P5, DOI 10.1109/ASE51524.2021.9678552; Iyer S, 2018, Arxiv, DOI arXiv:1808.09588; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Le Hung, 2022, NEURIPS; Ling W, 2016, Arxiv, DOI arXiv:1603.06744; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Martin R.C., 2009, Clean code: a handbook of agile software craftsmanship; McCabe Sr T. J., 1976, special Publication, Vm99; McCabe T., Software quality metrics to identify risk; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2023, GPT-4 Technical Report; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Phan Long N., 2021, Cotext: Multi-task learning with code-text transformer; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Sun ZY, 2019, AAAI CONF ARTIF INTE, P7055; Sutskever I, 2014, ADV NEUR IN, V27; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Wang Xin, 2022, arXiv; Wei B., 2019, Advances in neural information processing systems; Yang ZZ, 2023, Arxiv, DOI arXiv:2303.01056; Yin P., 2017, arXiv; Yin PC, 2018, Arxiv, DOI arXiv:1810.02720; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	41	0	0	12	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1887	1898		10.1109/ASE56229.2023.00096	http://dx.doi.org/10.1109/ASE56229.2023.00096			12	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200175
J	Middleton, P				Middleton, Peter			Parrots and Paragrams: AI Language Models and Erasure Poetry	MODERN PHILOLOGY			English	Article								This essay on poetry and computation borrows a provocative trope from an essay written by AI specialists who describe large language models as "stochastic parrots," copyists relying on probability statistics to generate answers. The history of poetry affords us many instances of textual borrowing that might provocatively be called parroting, repetition embedded in procedural selection from a source text, most recently in the minor genre of erasure poetry. This essay pursues analogies and differences between the digital systems and erasure poetics with the assistance of a poetic device known as the paragram, associated with eccentric searchers for hidden or occult messages in literary classics, as well as linguistic theorists such as Ferdinand de Saussure, Roman Jakobson, and Julia Kristeva. The essay centers on a prominent erasure poem, Voyager (2010) by Srikanth Reddy, and also discusses more briefly texts by Tom Phillips, Ronald Johnson, Janet Holmes, and Susan Howe.	[Middleton, Peter] Univ Southampton, Southampton, England	University of Southampton	Middleton, P (corresponding author), Univ Southampton, Southampton, England.							[Anonymous], 2002, This Compost: Ecological Imperatives in American Poetry., P17; [Anonymous], 2005, interview by Samuel Vriezen.; [Anonymous], 2013, Diagnostic and Statistical Manual of Mental Disorders: DSM-5, P54; [Anonymous], 1913, Poetry: A Magazine of Verse; [Anonymous], 2015, Physics Envy: American Poetry in the Cold War and After.; [Anonymous], 1957, The Shakespearean Ciphers Examined: An Analysis of Cryptographic Systems Used as Evidence That Some Author Other Than Shakespeare Wrote the Plays Commonly Attributed to Him; Ausonius Hugh G. Evelyn, 1961, Loeb Classical Library., V96, P371; Bandy J., 2021, arXiv; Beckett Samuel, 1958, Three Novels., P211; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bender Emily M., 2012, The Linguist List.; Benveniste Emile, 1964, Cahiers Ferdinand de Saussure, P118; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bode K, 2023, CRIT INQUIRY, V49, P507, DOI 10.1086/724943; Boehrer BT, 2004, PARROT CULTURE, P1; Brandom Robert, 2000, Articulating Reasons: An Introduction to Inferentialism, P162; Bruns GL, 2009, CONTEMP LITERATURE, V50, P28, DOI 10.1353/cli.0.0056; Chua Daniel K. L., 2021, Alien Listening: Voyager's Golden Record and Music from Earth, P97; Cooney Brian C., 2014, Journal of Modern Literature., V37, P32; Cullhed SS, 2016, GREECE ROME, V63, P237, DOI 10.1017/S0017383516000115; Davidson Michael, 1997, Ghostlier Demarcations: Modern Poetry and the Material Word, P153; Duncan Robert., 2014, Robert Duncan: Collected Essays and Other Prose, P37; Dworkin Craig, 2011, Against Expression: An Anthology of Conceptual Writing, pxxxvii; Fitterman Robert, 2009, Notes on Conceptualisms, P22; Frye Northrop, 1961, Anatomy of Criticism., P97; Guillory John, 2022, PROFESSING CRITICISM, P101; Hair R, 2010, MOD CONTEMP POET POE, P1, DOI 10.1057/9780230115552; Hair Ross., 2012, Reading Duncan Reading: Robert Duncan and the Poetics of Derivation, P129; Hammer Langdon, 2018, The Fate of Difficulty in the Poetry of Our Time., P34; Happe F.G. E., 1991, Autism and Asperger Syndrome, chapter 7, P207; Hegel G. W. F., 1977, Phenomenology of Spirit., P359; Hejinian Lyn, 2007, The Grand Piano, pt. 3, An Experiment in Collective Autobiography: San Francisco, 1975-1980., P61; Heller-Roazen Daniel, 2013, Dark Tongues: The Art of Rogues and Riddlers., P125; Holmes Janet, 2009, The Ms of My Kin., P122; Howe Susan, 2003, The Midnight., P85; Howe Susan, 1993, The Birth -Mark: Unsettling the Wilderness in American Literary History, P37; Jakobson Roman, 1987, Language in Literature., P261; Johnson Ronald, 2005, Radi Os, P49; Kay S, 2013, MIDDLE AGES SER, P1; King Andrew David., 2012, Kenyon Review; Kinser JM, 2005, AIPR 2004: 33rd Applied Imagery Pattern Recognition Workshop, Proceedings, P51; Kristeva Julia., 1998, TEL QUEL READER, P25; Kristeva Semeiotike, 1969, Recherches pour une semanalyse; Lehman David, 1999, The Last Avant -Garde: The Making of the New York School of Poets., P160; MacDonald Travis., 2009, JACKET, V38; Metz C., 2019, NEW YORK TIMES; Middleton P, 2009, TEXTUAL PRACT, V23, P947, DOI 10.1080/09502360903361634; Middleton Peter, 2012, Journal of Literature and Science., V5, P77; Mieszkowski Jan, 2019, Crises of the Sentence., P21; Moxley Jennifer, 2021, For the Good of All, Do Not Destroy the Birds., P63; Murgia Madhumita, 2023, Financ. Times; Nicholls P, 2002, CONTEMP LITERATURE, V43, P441, DOI 10.2307/1209108; Nourbese Philip M., 2008, Zong! As Told to the Author by Setaey Adamu Boateng, P201; paperpile, About us; Parikka Jussi, 2015, A Geology of Media., P139; Parks Cecily, 2020, Kenyon Review., V42; Perloff Marjorie, 2010, Unoriginal Genius: Poetry by Other Means in the New Century, P4; Phillips Tom, 2005, A Humument, V4, P13; poets, About us; Radford A., 2018, IMPROVING LANGUAGE U; Reddy Srikanth., 2011, Voyager; Roh David S., 2015, Illegal Literature: Toward a Disruptive Creativity., P8; Ruefle Mary, On Erasure.; Sagan Carl., 1978, MURMURS EARTH VOYAGE; Schauss P, 2021, CRIT HORIZ, V22, P321, DOI 10.1080/14409917.2021.1953752; Sontag Kate., 2001, CONFESSION POETRY AU; srikanthreddypoet, Notes on Composition; Starobinski Jean, 1964, Mercure de France., P262; Stenning A, 2020, ROUTL ADV SOCIOL, P108; Stern Jane, 1990, New Yorker, P55; Sugiura E., 2022, FINANC TIMES; Twitchell-Waas Jeffery., Z SITE COMPANION WOR; Waldheim Kurt, 1985, In the Eye of the Storm: A Memoir; Wordsworth William, 1952, The Poetical Works of William Wordsworth., V2, P390; Yeats W. B., 1984, The Poems., P194; Yergeau M, 2018, Thought Act, P1	77	0	0	2	2	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	0026-8232	1545-6951		MOD PHILOLOGY	Mod. Philol.	FEB 1	2024	121	3					352	374		10.1086/728291	http://dx.doi.org/10.1086/728291			23	Language & Linguistics; Literature	Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics; Literature	FX3S6					2024-07-03	WOS:001149118200014
J	Deng, Y; Wang, BC; Zhu, Q; Liu, JP; Kuang, JW; Li, XF				Deng, Yang; Wang, Bangchao; Zhu, Qiang; Liu, Junping; Kuang, Jiewen; Li, Xingfu			MTLink: Adaptive multi-task learning based pre-trained language model for traceability link recovery between issues and commits	JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES			English	Article						Issue-commit link recovery; Multi-teacher knowledge distillation; Adaptive multi-task		Traceability links between issues and commits (issue-commit links recovery (ILR)) play a significant role in software maintenance tasks by enhancing developers' observability in practice. Recent advancements in large language models, particularly pre-trained models, have improved the effectiveness of automated ILR. However, these models' large parameter sizes and extended training time pose challenges in large software projects. Besides, existing methods often overlook the association and distinction among artifacts, leading to the generation of erroneous links. To mitigate these problems, this paper proposes a novel link recovery method called MTLink. It utilizes multi-teacher knowledge distillation (MTKD) to compress the model and employs an adaptive multi-task strategy to reduce information loss and improve link accuracy. Experiments are conducted on four open-source projects. The results show that (i) MTLink outperforms state-of-the-art methods; (ii) The multi-teacher knowledge distillation maintains accuracy despite model size reduction; (iii) The adaptive multi-task tracing method effectively handles confusion caused by similar artifacts and balances each task. In conclusion, MTLink offers an efficient solution for ILR in software traceability. The code is available at https://zenodo.org/records/10321150.	[Deng, Yang; Wang, Bangchao; Zhu, Qiang; Liu, Junping; Kuang, Jiewen; Li, Xingfu] Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan, Peoples R China; [Wang, Bangchao; Zhu, Qiang; Liu, Junping] Engn Res Ctr Hubei Prov Clothing Informat, Wuhan, Peoples R China	Wuhan Textile University	Wang, BC (corresponding author), Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan, Peoples R China.	dd0028y@163.com; wangbc@whu.edu.cn; qzhu@wtu.edu.cn; jpliu@wtu.edu.cn; jiewen_kuang@163.com; lixingfu1999@163.com		Deng, Yang/0000-0002-2795-6796; Wang, Bangchao/0000-0001-6920-1810	National Natural Science Foundation of China [62102291]; Opening Foundation of Engineer-ing Research Center of Hubei Province for Clothing Information [2022HBCI02]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Opening Foundation of Engineer-ing Research Center of Hubei Province for Clothing Information	This work is supported by the National Natural Science Foundation of China (No. 62102291) , and the Opening Foundation of Engineer-ing Research Center of Hubei Province for Clothing Information (No. 2022HBCI02) .	Asuncion H.U., 2011, Software and Systems Traceability, P129; Bachmann A, 2010, P 18 ACM SIGSOFT INT, P97, DOI [10.1145/1882291.1882308, DOI 10.1145/1882291.1882308]; Bachmann R, 2022, LECT NOTES COMPUT SC, V13697, P348, DOI 10.1007/978-3-031-19836-6_20; Bai JS, 2024, Arxiv, DOI arXiv:2311.12371; Bennington-Davis M, 2006, PSYCHIAT SERV, V57, P1819, DOI 10.1176/appi.ps.57.12.1819-a; Borg M, 2014, EMPIR SOFTW ENG, V19, P1565, DOI 10.1007/s10664-013-9255-y; Claes M, 2020, IEEE WORK CONF MIN S, P503, DOI 10.1145/3379597.3387487; Devlin J., 2018, BERT PRE TRAINING DE; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Guo J, 2017, PROC INT CONF SOFTW, P3, DOI 10.1109/ICSE.2017.9; Hayes JH, 2006, IEEE T SOFTWARE ENG, V32, P4, DOI 10.1109/TSE.2006.3; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Karmakar A, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P1332, DOI 10.1109/ASE51524.2021.9678927; Kingma D. P., 2017, ARXIV; Lan JP, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-023-10342-7; Le TDB, 2015, INT C PROGRAM COMPRE, P36, DOI 10.1109/ICPC.2015.13; Lin JF, 2021, PROC INT CONF SOFTW, P324, DOI 10.1109/ICSE43902.2021.00040; Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loper E, 2002, ARXIV; LOVINS JB, 1968, MECH TRANSL, V11, P22; Lyu Y., 2023, IEEE Access; Mahmud J, 2021, arXiv; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mills C, 2020, EMPIR SOFTW ENG, V25, P3086, DOI 10.1007/s10664-020-09823-w; Nguyen A.T., 2012, P ACM SIGSOFT 20 INT, P1; Nishikawa K, 2015, PROC IEEE INT CONF S, P576, DOI 10.1109/ICSM.2015.7332517; Rahman F, 2013, P 2013 9 JOINT M FDN, P147, DOI 10.1145/2491411.2491418; Rath M, 2018, IEEE WORK CONF MIN S, P442, DOI 10.1145/3196398.3196415; Rath M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P834, DOI 10.1145/3180155.3180207; Ruan H, 2019, J SYST SOFTWARE, V158, DOI 10.1016/j.jss.2019.110406; Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]; Samant RM, 2022, IEEE ACCESS, V10, P17078, DOI 10.1109/ACCESS.2022.3149798; Sun Y, 2017, IEEE INT CONF AUTOM, P147, DOI 10.1109/ASE.2017.8115627; Sun Y, 2017, INFORM SOFTWARE TECH, V84, P33, DOI 10.1016/j.infsof.2016.11.010; Tian FC, 2021, J SOFTW-EVOL PROC, V33, DOI 10.1002/smr.2374; Xie R, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER), P434, DOI [10.1109/saner.2019.8667969, 10.1109/SANER.2019.8667969]; Zhang CY, 2023, Arxiv, DOI arXiv:2308.10759	40	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1319-1578	2213-1248		J KING SAUD UNIV-COM	J. King Saud Univ.-Comput. Inf. Sci.	FEB	2024	36	2							101958	10.1016/j.jksuci.2024.101958	http://dx.doi.org/10.1016/j.jksuci.2024.101958		FEB 2024	12	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	JZ9S2		gold			2024-07-03	WOS:001177103100001
C	Borzunov, A; Baranchuk, D; Dettmers, T; Ryabinin, M; Belkada, Y; Chumachenko, A; Samygin, P; Raffel, C		Bollegala, D; Huang, R; Ritter, A		Borzunov, Alexander; Baranchuk, Dmitry; Dettmers, Tim; Ryabinin, Max; Belkada, Younes; Chumachenko, Artem; Samygin, Pavel; Raffel, Colin			PETALS: Collaborative Inference and Fine-tuning of Large Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3			English	Proceedings Paper	61st Annual Meeting of the Association-for-Computational-Linguistics - System Demonstrations (ACL-DEMO)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist				Many NLP tasks benefit from using large language models (LLMs) that often have more than 100 billion parameters. With the release of BLOOM -176B and OPT-175B, everyone can download pretrained models of this scale. Still, using these models requires high-end hardware unavailable to many researchers, In some cases, LLMs can be used more affordably via RAM offloading or hosted APIs. However, these techniques have innate limitations: offloading is too slow for interactive inference, while APIs are not flexible enough for research that requires access to weights. attention or logits. In this work, we propose PETALS a system for inference and fine-tuning of large models collaboratively by joining the resources of multiple parties. We demonstrate that this strategy outperforms offloading for very large models, running inference of BLOOM -176B on consumer GPUs with approximate to 1 step per second, which is enough for many interactive LLM applications, Unlike most inference APIs, PETALS also natively exposes hidden states of served models, allowing to train and share custom model extensions based on efficient fine-tuning methods. The system, its source code, and documentation are available at https://petals.ml.	[Borzunov, Alexander; Ryabinin, Max] HSE Univ, Moscow, Russia; [Borzunov, Alexander; Baranchuk, Dmitry; Ryabinin, Max; Chumachenko, Artem] Yandex, Moscow, Russia; [Dettmers, Tim] Univ Washington, Seattle, WA 98195 USA; [Belkada, Younes; Raffel, Colin] Hugging Face, New York, NY USA; [Belkada, Younes] ENS Paris Saclay, Paris, France; [Samygin, Pavel] Yandex Sch Data Anal, Moscow, Russia	HSE University (National Research University Higher School of Economics); University of Washington; University of Washington Seattle; Universite Paris Saclay	Borzunov, A (corresponding author), HSE Univ, Moscow, Russia.; Borzunov, A (corresponding author), Yandex, Moscow, Russia.	borzunov.alexander@gmail.com						A121, JURASSIC 1 LANGUAGE; Black S., 2022, Gpt-neox-20b: An open-source autoregressive language model; Borgeaud Sebastian., 2021, IMPROVING LANGUAGE M; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dettmers Tim, 2022, INT C LEARN REPR ICL; Dettmers Tim, 2022, arXiv; Du N, 2022, Arxiv, DOI arXiv:2112.06905; Evans V. Kolesnikov, 2018, Privacy and Security, V2, P70, DOI 10.1561/3300000019; Fedus William, 2021, arXiv; Forefront, POW LANG MOD CLICK A; Gao Leo, 2021, A framework for few-shot language model evaluation; Guo DM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4884; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ., 2021, Lora: Low-rank adaptation of large language models; Hugging Face and contributors, 2020, ACCELERATE RUN YOUR; Kaplan Jared, 2020, Scaling laws for neural language models; Khruslichev Michael, 2022, YALM 100B; Kiela Douwe, 2021, Dynabench: Rethinking benchmarking in nlp; Kim B, 2021, Arxiv, DOI [arXiv:2109.04650, 10.48550/arXiv.2109.04650, DOI 10.48550/ARXIV.2109.04650]; lclaymotmlcov Petar, 2002, INT WORKSHOP PEER TO, P53; Le Scao Teven, 2022, arXiv; Lepikhin D., 2020, ARXIV; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; libp2p, 2022, LIBP2P CIRC REL; Liu Haokun, 2022, FEW SHOT PARAMETER E; Liu X., 2021, ARXIV; Muennighoff Niklas, 2022, arXiv; Narayman Deepak, 2021, ARXIV; NVIDIA, 2022, NVIDIA CONF COMP; NVIDIA, 2020, NNIDIA AMPERE GA102; OpenAI, Build Next-gen Apps With OpenAI's Powerful Models.; Patrick Lewis, 2020, ADV NEURAL INFORM PR, V33, P9459; Pfeiffer J., 2020, arXiv; Pudipeddi B., 2020, ARXIV; PyTorch Hub, PYTORCH HUB; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel Cohn, 2021, CANTO BUILD MODELS W; Rajbhandari S, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476205; Ren J, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P551; Ryabinin Max, 2020, Advances in Neural Information Processing Systems, V33, P3659; Ryabinin Max, 2023, ARXIV; Sung YL, 2021, ADV NEUR IN; Team Learning home, 2020, HIVEMIND LIB DECENTR; TensorFlow Hub, US; Touvron H., 2023, arXiv; Upadhyay Ashish, 2022, GENIV2 NLG BENCLUNAR; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yong Zneng-Xin, 2022, ADAPTING BIGSCIENCE; Zeng A., 2022, Glm-130b: An open bilingual pre-trained model; Zeng W., 2021, PREPRINT; Zhang S., 2022, Opt: Open pre-trained transformer language models	54	0	0	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-70-8				2023							558	568						11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BW6RV					2024-07-03	WOS:001181040500054
C	Li, LH; Hessel, J; Yu, Y; Ren, X; Chang, KW; Choi, Y		Rogers, A; Boyd-Graber, J; Okazaki, N		Li, Liunian Harold; Hessel, Jack; Yu, Youngjae; Ren, Xiang; Chang, Kai-Wei; Choi, Yejin			Symbolic Chain-of-Thought Distillation: Small Models Can Also "Think" Step-by-Step	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Chain-of-thought prompting (e.g., '' Let ' s think step-by-step '') primes large language models to verbalize rationalization for their predictions. While chain-of-thought can lead to dramatic performance gains, benefits appear to emerge only for sufficiently large models (beyond 50B parameters). We show that ordersof-magnitude smaller models (125M-1.3B parameters) can still benefit from chain-ofthought prompting. To achieve this, we introduce Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger teacher model. Experiments across several commonsense benchmarks show that: 1) SCoTD enhances the performance of the student model in both supervised and few-shot settings, and especially for challenge sets; 2) sampling many reasoning chains per instance from the teacher is paramount; and 3) after distillation, student chain-of-thoughts are judged by humans as comparable to the teacher, despite orders of magnitude fewer parameters. We test several hypotheses regarding what properties of chain-of-thought samples are important, e.g., diversity vs. teacher likelihood vs. open-endedness. We release our corpus of chain-of-thought samples and code.	[Li, Liunian Harold; Chang, Kai-Wei] Univ Calif Los Angeles, Los Angeles, CA 90024 USA; [Hessel, Jack; Choi, Yejin] Allen Inst Artificial Intelligence, Seattle, WA USA; [Ren, Xiang] Univ Southern Calif, Los Angeles, CA USA; [Yu, Youngjae] Yonsei Univ, Seoul, South Korea; [Choi, Yejin] Univ Washington, Seattle, WA 98195 USA	University of California System; University of California Los Angeles; University of Southern California; Yonsei University; University of Washington; University of Washington Seattle	Li, LH (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.				DARPA MCS program; NCSOFT NLP Center; Sloan research fellowship	DARPA MCS program(United States Department of Defense); NCSOFT NLP Center; Sloan research fellowship(Alfred P. Sloan Foundation)	We thank anonymous reviewers for their comments. This work is supported in part by the DARPA MCS program, NCSOFT NLP Center and a Sloan research fellowship.	[Anonymous], 2011, P 49 ANN M ASS COMPU; Bhagavatula Chandra, 2022, ARXIV221209246; BIG-bench collaboration, 2022, ARXIV220604615 BIG B; Bogin Ben, 2020, Findings of EMNLP; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camburu OM, 2018, ADV NEUR IN, V31; Chiang Ting-Rui, 2019, NAACL; Golovneva Olga, 2022, ARXIV221207919; Hase P, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON LEARNING WITH NATURAL LANGUAGE SUPERVISION (LNLS 2022), P29; Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1; Hinton G., 2015, COMPUTER SCI, V1050, P9, DOI [10.48550/arXiv.1503.02531, DOI 10.48550/ARXIV.1503.02531]; Ho Namgyu, 2022, LARGE LANGUAGE MODEL; Hoffmann Jordan, 2022, arXiv; Huang Jiaxin, 2022, ARXIV221011610; Kayser M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1224, DOI 10.1109/ICCV48922.2021.00128; Kojima Takeshi, 2022, Advances in Neural Information Processing Systems; Li Shiyang, 2022, ARXIV221006726; Li Yifei, 2022, ARXIV220602336; Ling H, 2017, ADV NEUR IN, V30; Liu Alisa, 2022, ARXIV220105955; Magister Lucie Charlotte, 2022, ARXIV221208410; Meng Yu, 2022, ARXIV220204538; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Min Sewon, 2021, NAACL; Narang Sharan, 2020, ARXIV200414546; Nye M. I., 2021, Show your work: Scratchpads for intermediate computation with language models; Paszke A, 2019, ADV NEUR IN, V32; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Roy Subhro, 2015, EMNLP; Schick Timo, 2021, EMNLP; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Srivastava Shashank, 2018, ACL; Suzgun Mirac, 2022, ARXIV221009261; Tafjord Oyvind, 2019, AAAI; Talmor A., 2020, ADV NEURAL INFORM PR; Talmor A, 2019, NAACL HLT; Wang Xuezhi, 2022, arXiv:2203.11171; Wang Xuezhi, 2022, ARXIV220700747; Wei Jason, 2022, ADV NEURAL INFORM PR; Wei Jiaheng, 2022, ICLR; West Peter, 2022, NAACL; Wiegreffe Sarah, 2022, NAACL; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xiong Wenhan, 2019, ARXIV191209637; Yogatama Dani, 2017, ACL; Zaidan Omar, 2007, HUMAN LANGUAGE TECHN, P260; Zelikman Eric, 2022, ADV NEURAL INFORM PR, V2675; Zhang S., 2022, Opt: Open pre-trained transformer language models; Zhang Y., 2016, EMNLP; Zhou W., 2020, Advances in Neural Information Processing Systems	52	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							2665	2679						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086801019
C	Zheng, C; Shi, C; Vafa, K; Feder, A; Blei, DM		Rogers, A; Boyd-Graber, J; Okazaki, N		Zheng, Carolina; Shi, Claudia; Vafa, Keyon; Feder, Amir; Blei, David M.			An Invariant Learning Characterization of Controlled Text Generation	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Controlled generation refers to the problem of creating text that contains stylistic or semantic attributes of interest. Many approaches reduce this problem to training a predictor of the desired attribute. For example, researchers hoping to deploy a large language model to produce non-toxic content may use a toxicity classifier to filter generated text. In practice, the generated text to classify, which is determined by user prompts, may come from a wide range of distributions. In this paper, we show that the performance of controlled generation may be poor if the distributions of text in response to user prompts differ from the distribution the predictor was trained on. To address this problem, we cast controlled generation under distribution shift as an invariant learning problem: the most effective predictor should be invariant across multiple text environments. We then discuss a natural solution that arises from this characterization and propose heuristics for selecting natural environments. We study this characterization and the proposed method empirically using both synthetic and real data. Experiments demonstrate both the challenge of distribution shift in controlled generation and the potential of invariance methods in this setting.	[Zheng, Carolina; Shi, Claudia; Vafa, Keyon; Feder, Amir; Blei, David M.] Columbia Univ, New York, NY 10027 USA; [Shi, Claudia] FAR AI, San Diego, CA 92101 USA	Columbia University	Zheng, C; Shi, C (corresponding author), Columbia Univ, New York, NY 10027 USA.; Shi, C (corresponding author), FAR AI, San Diego, CA 92101 USA.	carolina.z@columbia.edu; claudia.j.shi@gmail.com			NSF [IIS 2127869]; ONR [N00014-17-1-2131, N00014-15-1-2209]; Simons Foundation; Open Philanthropy	NSF(National Science Foundation (NSF)); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); Simons Foundation; Open Philanthropy	We thank Tiffany Cai, Nino Scherrer, and the reviewers for their thoughtful comments and suggestions, which have greatly improved the paper. This work is supported by NSF grant IIS 2127869, ONR grants N00014-17-1-2131 and N00014-15-1-2209, the Simons Foundation, and Open Philanthropy.	[Anonymous], 2019, P 1 WORKSH GEND BIAS, DOI DOI 10.18653/V1/W19-3823; Arjovsky Martin, 2019, arXiv; Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223; Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33; BenTal A, 2009, PRINC SER APPL MATH, P1; Borkan Daniel, 2019, WWW; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Calderon N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7727; Carlsson F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6837; Chang Kai-Wei, 2018, P NAACL, V2, DOI [10.18653/v1/N18-2003, DOI 10.18653/V1/N18-2003]; Chowdhery A., 2022, ARXIV220402311; DAmour A., 2020, Journal of Machine Learning Research; Dathathri Sumanth, 2019, ARXIV191202164; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dranker Y., 2021, Advances in Neural Information Processing Systems, V34, P18212; Feder A., 2022, ADV NEURAL INFORM PR; Feder Amir, 2021, ARXIV210900725; Gehman S, 2020, M ASS FOR COMPUTATIO; Georgakopoulos SV, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3208069; Gretton A, 2012, J MACH LEARN RES, V13, P723; Gulrajani Ishaan, 2020, ICLR; Gururangan S., 2020, P 58 ANN M ASS COMPU, P1, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]; Heinze-Deml C, 2018, J CAUSAL INFERENCE, V6, DOI 10.1515/jci-2017-0016; Holtzman A., 2019, P INT C LEARN REPR; Hu Z, 2021, Advances in Neural Information Processing Systems, V34, P24941; Hu Zhiting, 2017, P 34 INT C MACHINE L, P1587; Keskar N. S., 2019, ABS190905858 CORR; Krause Ben, 2020, Gedi: Generative discriminator guided sequence generation; Krueger D., 2021, INT C MACH LEARN, P5815, DOI DOI 10.48550/ARXIV.2003.00688; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Liu A., 2021, ARXIV210503023; Lu Chaochao, 2021, ARXIV210212353; Magliacane S, 2018, ADV NEUR IN, V31; Makar M, 2022, PR MACH LEARN RES, V151, P739; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; Nye Maxwell, 2021, ARXIV211200114; Peters J., 2016, J ROYAL STAT SOC B; Prabhumoye S., 2020, P 28 INT C COMP LING, P1, DOI DOI 10.18653/V1/2020.COLING-MAIN.1; Raffel C, 2020, J MACH LEARN RES, V21; Rosenfeld Elan, 2020, INT C LEARN REPR; Schick Timo, 2021, ABS210300453 CORR; Scholkopf B., 2021, ABS210211107 CORR; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Shi Claudia, 2021, Uncertainty in artificial intelligence, P1546; Shin Taylor, 2020, ARXIV201015980; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Veitch V., 2021, Advances in neural information processing systems, V34, P16196; Wald Y., 2021, Advances in neural information processing systems, V34, P2215, DOI 10.48550/arXiv.2102.10395; Wei Jason, 2022, arXiv:2201.11903; Welbl J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2447; Xu A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2390; Yang K., 2021, ARXIV210405218; Yin M., 2021, ARXIV210911990; Yu L, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23241; Zampieri M, 2019, SEMEVAL, P75, DOI [DOI 10.18653/V1/S19-2010, 10.18653/v1/S19-2010]; Zhang GH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4134; Zhang H., 2022, ARXIV221009551; Zhao J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P629; Zhao SC, 2022, IEEE T NEUR NET LEAR, V33, P473, DOI 10.1109/TNNLS.2020.3028503; Ziegler Daniel M, 2019, ARXIV190908593	62	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							3186	3206						21	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086801050
J	Duarte, D; Costa, R; Bizarro, P; Duarte, C				Duarte, Diogo; Costa, Rita; Bizarro, Pedro; Duarte, Carlos			AutoVizuA11y: A Tool to Automate Screen Reader Accessibility in Charts	COMPUTER GRAPHICS FORUM			English	Article						<bold>CCS Concepts</bold>; center dot <bold>Human-centered computing</bold> -> <bold>Visualization</bold>; <bold>Accessibility</bold>		Charts remain widely inaccessible on the web for users of assistive technologies like screen readers. This is, in part, due to data visualization experts still lacking the experience, knowledge, and time to consistently implement accessible charts. As a result, screen reader users are prevented from accessing information and are forced to resort to tabular alternatives (if available), limiting the insights that they can gather. We worked with both groups to develop AutoVizuA11y, a tool that automates the addition of accessible features to web-based charts. It generates human-like descriptions of the data using a large language model, calculates statistical insights from the data, and provides keyboard navigation between multiple charts and underlying elements. Fifteen screen reader users interacted with charts made accessible with AutoVizuA11y in a usability test, thirteen of which praised the tool for its intuitive design, short learning curve, and rich information. On average, they took 66 seconds to complete each of the eight analytical tasks presented and achieved a success rate of 89%. Through a SUS questionnaire, the participants gave AutoVizuA11y an "Excellent" score - 83.5/100 points. We also gathered feedback from two data visualization experts who used the tool. They praised the tool availability, ease of use and functionalities, and provided feedback to add AutoVizuA11y support for other technologies in the future.	[Duarte, Diogo; Costa, Rita; Bizarro, Pedro] Feedzai, Coimbra, Portugal; [Duarte, Carlos] Univ LisboaLisbon, Fac Ciencias, LASIGE, Lisbon, Portugal	Universidade de Lisboa	Duarte, D (corresponding author), Feedzai, Coimbra, Portugal.				FCT through the LASIGE Research Unit	FCT through the LASIGE Research Unit(Fundacao para a Ciencia e a Tecnologia (FCT))	No Statement Available	AFP, 2024, SCREEN READERS; [Anonymous], 2017, AIRBNB VISX HOMEPAGE; [Anonymous], 2019, W3C WCAG 21; [Anonymous], CAUSES BLINDNESS VIS; [Anonymous], 2005, APPLE VOICEOVER USER; Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776; Blanco M., OLLI EXTENSIBLE VISU; Borkin M. A., MEMORABILITY VISUALI; Brooke JSUS., 1996, Usability Eval. Ind., V189194, P4, DOI DOI 10.1201/9781498710411-35; Clarke V, 2017, J POSIT PSYCHOL, V12, P297, DOI 10.1080/17439760.2016.1262613; Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555; dos Cegos e Amblopes de Portugal A., 1989, ACAPO HOMEPAGE; Downie N., 2013, CHARTJS HOMEPAGE; Elavsky F., 2023, IEEE VIS; Elavsky F, 2022, COMPUT GRAPH FORUM, V41, P57, DOI 10.1111/cgf.14522; Engel C., SVGPLOTT ACCESSIBLE, DOI [10.1145/3316782.3316793, DOI 10.1145/3316782.3316793]; Highsoft, 2009, HIGHCHARTS HOMEPAGE; Jung C., 2021, COMMUNICATING VISUAL; Kim E, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P143, DOI 10.1145/3234695.3236357; Kim G, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581139; Kim NW, 2021, COMPUT GRAPH FORUM, V40, P173, DOI 10.1111/cgf.14298; Kim N. W., VISUALIZATION ACCESS, P1, DOI [10.1145/3491102.3517630, DOI 10.1145/3491102.3517630]; Lundgard A., 2022, ACCESSIBLE VISUALIZA, DOI DOI 10.1109/TVCG.2021.3114770; Maddigan P., CHAT2VIS GENERATING; Mike Bostock Jason Davies J. H. V. O., 2011, D3JS HOMEPAGE; Norman D.A., 1986, USER CTR SYSTEM DESI; Obeid J., CHARTTOTEXT GENERATI; Schwabish J., 2022, NO HARM GUIDE; Scientific F., 1995, JAWS SCREEN READER H; Sharif A., 2022, P 24 INT ACM SIGACCE, DOI 10.1145/3517428.3550360; Sharif A., EVOGRAPHS JQUERY PLU, P1; Sharif A., VOXLENS MAKING ONLIN, P1, DOI [10.1145/3491102.3517431, DOI 10.1145/3491102.3517431]; Sharif A, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3471202; South L., 2022, PHOTOSENSITIVE ACCES; Sultanum N., 2023, DATATALES INVESTIGAT; Tang B. J., 2023, VISTEXT BENCHMARK SE; Wang Y., WHAT MAKES WEB DATA, P1, DOI [10.1145/3491102.3517469, DOI 10.1145/3491102.3517469]; Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398; Wu K., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445743; Zong J, 2022, COMPUT GRAPH FORUM, V41, P15, DOI 10.1111/cgf.14519; Zou H, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P107, DOI 10.1145/2700648.2809862	41	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0167-7055	1467-8659		COMPUT GRAPH FORUM	Comput. Graph. Forum	JUN	2024	43	3								10.1111/cgf.15099	http://dx.doi.org/10.1111/cgf.15099		JUN 2024	12	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UM5V8		hybrid			2024-07-03	WOS:001243040700001
J	Mets, M; Karjus, A; Ibrus, I; Schich, M				Mets, Mark; Karjus, Andres; Ibrus, Indrek; Schich, Maximilian			Automated stance detection in complex topics and small languages: The challenging case of immigration in polarizing news media	PLOS ONE			English	Article							SOCIAL MEDIA; POPULISM; ESTONIA	Automated stance detection and related machine learning methods can provide useful insights for media monitoring and academic research. Many of these approaches require annotated training datasets, which limits their applicability for languages where these may not be readily available. This paper explores the applicability of large language models for automated stance detection in a challenging scenario, involving a morphologically complex, lower-resource language, and a socio-culturally complex topic, immigration. If the approach works in this case, it can be expected to perform as well or better in less demanding scenarios. We annotate a large set of pro- and anti-immigration examples to train and compare the performance of multiple language models. We also probe the usability of GPT-3.5 (that powers ChatGPT) as an instructable zero-shot classifier for the same task. The supervised models achieve acceptable performance, but GPT-3.5 yields similar accuracy. As the latter does not require tuning with annotated data, it constitutes a potentially simpler and cheaper alternative for text classification tasks, including in lower-resource languages. We further use the best-performing supervised model to investigate diachronic trends over seven years in two corpora of Estonian mainstream and right-wing populist news sources, demonstrating the applicability of automated stance detection for news analytics and media monitoring settings even in lower-resource scenarios, and discuss correspondences between stance changes and real-world events.	[Mets, Mark; Karjus, Andres] Tallinn Univ, Sch Humanities, Tallinn, Estonia; [Mets, Mark; Karjus, Andres; Ibrus, Indrek; Schich, Maximilian] Tallinn Univ, ERA Chair Cultural Data Analyt, Tallinn, Estonia; [Karjus, Andres] Estonian Business Sch, Tallinn, Estonia; [Ibrus, Indrek; Schich, Maximilian] Tallinn Univ, Balt Film Media & Arts Sch, Tallinn, Estonia	Tallinn University; Tallinn University; Estonian Business School; Tallinn University	Mets, M; Karjus, A (corresponding author), Tallinn Univ, Sch Humanities, Tallinn, Estonia.; Mets, M; Karjus, A (corresponding author), Tallinn Univ, ERA Chair Cultural Data Analyt, Tallinn, Estonia.; Karjus, A (corresponding author), Estonian Business Sch, Tallinn, Estonia.	mark.mets@tlu.ee; andres.karjus@tlu.ee			Tallinn University, funded through the European Union Horizon 2020 research and innovation program [810961]; Estonian media publishing company AS Ekspress Grupp	Tallinn University, funded through the European Union Horizon 2020 research and innovation program; Estonian media publishing company AS Ekspress Grupp	M.M., A.K., I.I., and M.S. are supported by the CUDAN ERA Chair project for Cultural Data Analytics at Tallinn University, funded through the European Union Horizon 2020 research and innovation program (Project No. 810961). The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. M.M., A.K. and I.I. received funding from Estonian media publishing company AS Ekspress Grupp (https://www.egrupp.ee/en/). The funder provided part of the data but had no role in study design and analysis, decision to publish, or preparation of the manuscript. There was no additional external funding received for this study.	Abts K, 2007, POLIT STUD-LONDON, V55, P405, DOI 10.1111/j.1467-9248.2007.00657.x; Aiyappa R, 2023, Arxiv, DOI [arXiv:2303.12767, DOI 10.48550/ARXIV.2303.12767]; ALDayel A, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102597; Allaway E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8913; Auers D, 2018, FUDAN J HUM SOC SCI, V11, P341, DOI 10.1007/s40647-018-0231-1; Batanovic V, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242050; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001; Braghiroli S, 2023, EAST EUR POLITICS, V39, P128, DOI 10.1080/21599165.2022.2077725; Burscher B, 2015, ELECT STUD, V38, P59, DOI 10.1016/j.electstud.2015.03.001; Carda D, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120510119; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003; Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3988; Engesser S, 2017, INFORM COMMUN SOC, V20, P1109, DOI 10.1080/1369118X.2016.1207697; Ghosh S, 2019, LECT NOTES COMPUT SC, V11696, P75, DOI 10.1007/978-3-030-28577-7_4; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Hedderich MA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2545; Kaal E., 2019, Randetemaatika kajastamine Eesti meedias; Karjus A, 2023, Arxiv, DOI arXiv:2309.14379; Karjus A, 2023, Arxiv, DOI arXiv:2309.01659; Kasekamp A, 2019, PROBL POST-COMMUNISM, V66, P47, DOI 10.1080/10758216.2018.1445973; Khatua A., 2022, P INT AAAI C WEB SOC, V16, P512; Koppel K., 2023, Anxieties of Migration and Integration in Turbulent Times, P225, DOI [10.1007/978-3-031-23996-0_13, DOI 10.1007/978-3-031-23996-0_13]; Küçük D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3369026; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; LOTMAN YM, 1978, NEW LITERARY HIST, V9, P211, DOI 10.2307/468571; Madisson ML, 2018, SEMIOTICA, P25, DOI 10.1515/sem-2016-0077; Madisson ML, 2016, SIGN SYST STUD, V44, P326, DOI 10.12697/SSS.2016.44.3.02; Magueresse A, 2020, Arxiv, DOI arXiv:2006.07264; Meltzer CE, 2021, MEDIA AND PUBLIC ATTITUDES TOWARD MIGRATION IN EUROPE, P174; Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433; Mudde C, 2007, POPULIST RADICAL RIGHT PARTIES IN EUROPE, P1, DOI 10.1017/CBO9780511492037; Pajupuu H, 2016, FOLKLORE-EL J FOLKL, P125, DOI 10.7592/FEJF2016.64.polarity; Petsinis V, 2019, NATL ETHN POLIT, V25, P211, DOI 10.1080/13537113.2019.1602374; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Rajapakse TC, 2019, Simple Transformers; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Rooduijn M, 2014, PARTY POLIT, V20, P563, DOI 10.1177/1354068811436065; Saarts T, 2021, POLITICS GOV, V9, P354, DOI 10.17645/pag.v9i4.4566; Sobhani P., 2017, EACL 2017 P, V2, P551, DOI DOI 10.18653/V1/E17-2088; Tanvir H., 2021, P 23 NORDIC C COMPUT, P11; Ulcar M, 2021, Arxiv, DOI arXiv:2107.10614; Vamvas J., 2020, 5 SWISS TEXT ANALYTI; Yantseva V, 2021, PROCEEDINGS OF THE 2021 SWEDISH WORKSHOP ON DATA SCIENCE (SWEDS), DOI 10.1109/SweDS53855.2021.9637718; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	48	0	0	4	4	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	APR 26	2024	19	4							e0302380	10.1371/journal.pone.0302380	http://dx.doi.org/10.1371/journal.pone.0302380			16	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	OR7A8	38669237	Green Submitted, gold			2024-07-03	WOS:001209055100034
C	Mizrahi, D; Bachmann, R; Kar, OF; Yeo, T; Gao, MF; Dehghan, A; Zamir, A		Oh, A; Neumann, T; Globerson, A; Saenko, K; Hardt, M; Levine, S		Mizrahi, David; Bachmann, Roman; Kar, Oguzhan Fatih; Yeo, Teresa; Gao, Mingfei; Dehghan, Afshin; Zamir, Amir			4M: Massively Multimodal Masked Modeling	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 36, NEURIPS 2023	Advances in Neural Information Processing Systems		English	Proceedings Paper	37th Conference on Neural Information Processing Systems (NeurIPS)	DEC 10-16, 2023	New Orleans, LA					Current machine learning models for vision are often highly specialized and limited to a single modality and task. In contrast, recent large language models exhibit a wide range of capabilities, hinting at a possibility for similarly versatile models in computer vision. In this paper, we take a step in this direction and propose a multimodal training scheme called 4M. It consists of training a single unified Transformer encoder-decoder using a masked modeling objective across a wide range of input/output modalities - including text, images, geometric, and semantic modalities, as well as neural network feature maps. 4M achieves scalability by unifying the representation space of all modalities through mapping them into discrete tokens and performing multimodal masked modeling on a small randomized subset of tokens. 4M leads to models that exhibit several key capabilities: (1) they can perform a diverse set of vision tasks out of the box, (2) they excel when fine-tuned for unseen downstream tasks or new input modalities, and (3) they can function as a generative model that can be conditioned on arbitrary modalities, enabling a wide variety of expressive multimodal editing capabilities with remarkable flexibility. Through experimental analyses, we demonstrate the potential of 4M for training versatile and scalable foundation models for vision tasks, setting the stage for further exploration in multimodal learning for vision and other domains.	[Mizrahi, David; Bachmann, Roman; Kar, Oguzhan Fatih; Yeo, Teresa; Zamir, Amir] Swiss Fed Inst Technol Lausanne EPFL, Lausanne, Switzerland; [Mizrahi, David; Gao, Mingfei; Dehghan, Afshin] Apple, Cupertino, CA 95014 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Apple Inc	Mizrahi, D; Bachmann, R (corresponding author), Swiss Fed Inst Technol Lausanne EPFL, Lausanne, Switzerland.; Mizrahi, D (corresponding author), Apple, Cupertino, CA 95014 USA.							Aghajanyan Armen, 2023, INT C MACH LEARN; Aghajanyan Armen, 2022, ARXIV220107520; Alayrac JB., 2022, Advances in Neural Information Processing Systems (NeurIPS); Atito Sara, 2021, ARXIV210403602; Bachmann Roman, 2022, EUR C COMP VIS; Baevski A, 2022, PR MACH LEARN RES; Bao H, 2022, IEEE DATA MINING, P1, DOI 10.1109/ICDM54844.2022.00010; Bar Amir, 2022, ADV NEURAL INFORM PR, V2; Bar-Tal Omer, 2021, INT C MACH LEARN; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Bhattacharjee Deblina, 2022, C COMP VIS PATT REC; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Burgess Neil, 2019, S COMP AR; Byeon Minwoo, 2022, COYO 700M IMAGE TEXT; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chang Huiwen, 2023, INT C MACH LEARN; Chang J, 2010, J INTELL FUZZY SYST, V21, P5, DOI 10.3233/IFS-2010-0431; Changpinyo Soravit, 2021, C COMP VIS PATT REC; Chen T., 2022, INT C LEARN REPR; Chen Ting, 2022, Advances in Neural Information Processing Systems; Cheng Bowen, 2022, C COMP VIS PATT REC; Chowdhery A., 2022, ARXIV220402311; Clark K., 2020, 8 INT C LEARN REPR I; Cubuk Ekin Dogus, 2020, ADV NEURAL INFORM PR; Dehghani Mostafa, 2023, INT C MACH LEARN; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin Jacob, 2019, N AM ASS COMP ASS CO; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; Duan K, 2022, ENERG MATER FRONT, V3, P10, DOI 10.1016/j.enmf.2021.10.003; Eftekhar Ainaz, 2021, INT C COMP VIS; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; El-Nouby Alaaeldin, 2021, arXiv preprint arXiv:211210740; Esser Patrick, 2021, C COMP VIS PATT REC; Fang Yuxin, 2023, ARXIV230311331; Fang Yuxin, 2023, C COMP VIS PATT REC; Feichtenhofer Christoph, 2022, Advances in neural information processing systems; Gadre Samir Yitzhak, 2023, ARXIV230414108; Gafni Oran, 2022, EUR C COMP VIS; Ghiasi Golnaz, 2021, INT C COMP VIS; Ghiasi Golnaz, 2021, C COMP VIS PATT REC; Girdhar Rohit, 2023, C COMP VIS PATT REC; Google, 2023, PALM 2 TECHN REP; Goyal Priya, 2017, ARXIV170602677; He Kaiming, 2017, T PATTERN ANAL MACHI; He Kaiming, 2022, C COMP VIS PATT REC; He YH, 2020, APPL PSYCH MEAS, V44, P3, DOI 10.1177/0146621618824854; Hendrycks D., 2016, ARXIV160608415, DOI DOI 10.48550/ARXIV.1606.08415; Ho J., 2020, ADV NEUR IN, P1; Ho Jonathan, 2022, J MACHINE LEARNING R; Ho Jonathan, 2022, arXiv preprint arXiv:2207.12598; Hoogeboom Emiel, 2022, INT C LEARN REPR; Hu Ronghang, 2021, INT C COMP VIS; Huang Po-Yao, 2022, ADV NEURAL INFORM PR; Huang Shaohan, 2023, ARXIV230214045; Huang Xun, 2022, EUR C COMP VIS; Jaegle A., 2022, INT C LEARN REPR, P1; Jin XX, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901353; Kaplan Jared, 2020, Scaling laws for neural language models; Kirstain Yuval, 2023, ARXIV230301000; Kolesnikov Alexander, 2022, ADV NEURAL INFORM PR; Li Tianhong, 2023, C COMP VIS PATT REC; Li Yanghao, 2022, EUR C COMP VIS; Li YF, 2020, METALS-BASEL, V10, DOI 10.3390/met10030312; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Nan, 2022, EUR C COMP VIS; Liu Shikun, 2023, ARXIV230302506; Liu Xingbin, 2022, ARXIV220903917; Liu Z., 2022, C COMP VIS PATT REC; Liu Ze, 2021, INT C COMP VIS; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Lu Jiasen, 2023, INT C LEARN REPR; Luhman Troy, 2022, ARXIV220704316; Myers J, 2017, CIRC-HEART FAIL, V10, DOI 10.1161/CIRCHEARTFAILURE.116.003780; Nash Charlie, 2022, ARXIV220309494; NegPrompt, 2022, NEG PROMPT; Nichol A. Q., 2021, INT C MACH LEARN, P8162; Nichol A, 2021, PR MACH LEARN RES, V139; Oguzhan Fatih Kar, 2022, C COMP VIS PATT REC; OpenAI, 2023, GPT-4 technical report; Peng Zhiliang, 2022, ARXIV220806366; Pinto Andre Susano, 2023, INT C MACH LEARN; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Ramesh A, 2021, PR MACH LEARN RES, V139; Ramesh Aditya, 2022, ARXIV220406125; Ranftl Rene, 2020, T PATTERN ANAL MACHI; Ranftl Rene, 2021, INT C COMP VIS; Reed Scott, 2022, Transactions on Machine Learning Research; Ridnik Tal, 2021, PREPRINT; Roberts Mike, 2020, INT C COMP VIS; Rombach Robin, 2022, C COMP VIS PATT REC; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saharia Chitwan, 2022, Advances in Neural Information Processing Systems; Sax Alexander, 2018, ARXIV181211971; Schuhmann Christoph, 2022, ADV NEURAL INFORM PR; Shazeer Noam, 2020, ARXIV200205202; Shi Jie, 2022, ARXIV220600386; Silberman N., 2012, LECT NOTES COMPUT SC, P746, DOI [DOI 10.1007/978-3-642-33715-4_54, 10.1007/978-3-642-33715-4_54]; Singh Amanpreet, 2022, C COMP VIS PATT REC; Smith Linda, 2005, ARTIFICIAL LIFE, P2; Song J, 2021, INT C LEARN REPR; Sun C., 2021, ADV NEUR IN, V34, P14200; Tay Yi, 2023, INT C LEARN REPR; Tian Yuan, 2020, EUR C COMP VIS; Touvron Hugo, 2022, EUR C COMP VIS; Tripuraneni N., 2020, Advances in Neural Information Processing Systems (NeurIPS); van den Oord A, 2017, ADV NEUR IN, V30; Vasiljevic I., 2019, ARXIV190800463; Vaswani A, 2017, ADV NEUR IN, V30; Voynov A, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591560; Wang Xinlong, 2023, C COMP VIS PATT REC; WebDataset, 2022, WEBD; Williams LJ, 2020, ORGAN RES METHODS, V23, P6, DOI 10.1177/1094428117736137; Xie Zhenda, 2022, C COMP VIS PATT REC; Yang Zhengyuan, 2023, C COMP VIS PATT REC; Yang ZL, 2019, ADV NEUR IN, V32; Yu Jiahui, 2022, INT C LEARN REPR; Yu Jiahui, 2022, T MACHINE LEARNING R, V1, P7; Yun S, 2019, ANN OCCUP ENVIRON ME, V31, DOI 10.1186/s40557-019-0285-9; Zamir Amir R, 2020, C COMP VIS PATT REC; Zamir Amir Roshan, 2018, C COMP VIS PATT REC; Zeghidour Neil, 2022, T AUDIO SPEECH LANGU; Zhan F., 2021, ARXIV211213592; Zhang H., 2018, ICLR; Zhang Lvmin, 2023, INT C COMP VIS; ZHANG YF, 2022, MATHEMATICS-BASEL, V10, DOI DOI 10.3390/MATH10132227; Zhou B., 2017, C COMP VIS PATT REC; Zhou Jinghao, 2022, INT C LEARN REPR, P3; Zhu Xizhou, 2022, C COMP VIS PATT REC	132	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258			ADV NEUR IN			2023														46	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8HB					2024-07-03	WOS:001202273400009
J	Valentini, M; Szkandera, J; Smolle, M; Scheipl, S; Leithner, A; Andreou, D				Valentini, Marisa; Szkandera, Joanna; Smolle, Maria; Scheipl, Susanne; Leithner, Andreas; Andreou, Dimosthenis			Artificial intelligence large language model ChatGPT: is it a trustworthy and reliable source of information for sarcoma patients?	FRONTIERS IN PUBLIC HEALTH			English	Article						artificial intelligence; ChatGPT; sarcoma; patient information; information quality	OSTEOSARCOMA	Introduction Since its introduction in November 2022, the artificial intelligence large language model ChatGPT has taken the world by storm. Among other applications it can be used by patients as a source of information on diseases and their treatments. However, little is known about the quality of the sarcoma-related information ChatGPT provides. We therefore aimed at analyzing how sarcoma experts evaluate the quality of ChatGPT's responses on sarcoma-related inquiries and assess the bot's answers in specific evaluation metrics.Methods The ChatGPT responses to a sample of 25 sarcoma-related questions (5 definitions, 9 general questions, and 11 treatment-related inquiries) were evaluated by 3 independent sarcoma experts. Each response was compared with authoritative resources and international guidelines and graded on 5 different metrics using a 5-point Likert scale: completeness, misleadingness, accuracy, being up-to-date, and appropriateness. This resulted in maximum 25 and minimum 5 points per answer, with higher scores indicating a higher response quality. Scores >= 21 points were rated as very good, between 16 and 20 as good, while scores <= 15 points were classified as poor (11-15) and very poor (<= 10).Results The median score that ChatGPT's answers achieved was 18.3 points (IQR, i.e., Inter-Quartile Range, 12.3-20.3 points). Six answers were classified as very good, 9 as good, while 5 answers each were rated as poor and very poor. The best scores were documented in the evaluation of how appropriate the response was for patients (median, 3.7 points; IQR, 2.5-4.2 points), which were significantly higher compared to the accuracy scores (median, 3.3 points; IQR, 2.0-4.2 points; p = 0.035). ChatGPT fared considerably worse with treatment-related questions, with only 45% of its responses classified as good or very good, compared to general questions (78% of responses good/very good) and definitions (60% of responses good/very good).Discussion The answers ChatGPT provided on a rare disease, such as sarcoma, were found to be of very inconsistent quality, with some answers being classified as very good and others as very poor. Sarcoma physicians should be aware of the risks of misinformation that ChatGPT poses and advise their patients accordingly.	[Valentini, Marisa; Smolle, Maria; Scheipl, Susanne; Leithner, Andreas; Andreou, Dimosthenis] Med Univ Graz, Dept Orthopaed & Trauma, Graz, Austria; [Szkandera, Joanna] Med Univ Graz, Dept Internal Med, Div Oncol, Graz, Austria	Medical University of Graz; Medical University of Graz	Andreou, D (corresponding author), Med Univ Graz, Dept Orthopaed & Trauma, Graz, Austria.	dimosthenis.andreou@medunigraz.at						Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Gage Michele M, 2019, Oncotarget, V10, P2462, DOI 10.18632/oncotarget.26809; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gronchi A, 2021, ANN ONCOL, V32, P1348, DOI 10.1016/j.annonc.2021.07.006; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Johnson D, 2023, PREPRINT, DOI DOI 10.21203/RS.3.RS-2566942/V1; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; Karako K, 2023, BIOSCI TRENDS, V17, P186, DOI 10.5582/bst.2023.01138; Kung TH., 2023, Health, V2, pe0000198, DOI [10.1371/journal.pdig.0000198, DOI 10.1371/JOURNAL.PDIG.0000198]; Leithner A, 2010, J AM MED INFORM ASSN, V17, P373, DOI 10.1136/jamia.2010.004507; Nakayama R, 2020, EXPERT REV ANTICANC, V20, P893, DOI 10.1080/14737140.2020.1814150; Orrù G, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1199350; Pollock RE, 2018, CURR PROB SURG, V55, P517, DOI 10.1067/j.cpsurg.2018.10.006; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Schippinger M, 2014, WIEN MED WOCHENSCHR, V164, P353, DOI 10.1007/s10354-014-0304-y; Semrl N, 2023, HUM REPROD, V38, P2281, DOI 10.1093/humrep/dead207; Stiller CA, 2013, EUR J CANCER, V49, P684, DOI 10.1016/j.ejca.2012.09.011; Strauss SJ, 2021, ANN ONCOL, V32, P1520, DOI 10.1016/j.annonc.2021.08.1995; Strönisch A, 2023, LIFE-BASEL, V13, DOI 10.3390/life13040979; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749; Zade RT, 2020, JAAOS GLOB RES REV, V4, DOI 10.5435/JAAOSGlobal-D-19-00181	24	0	0	7	7	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-2565		FRONT PUBLIC HEALTH	Front. Public Health	MAR 22	2024	12								1303319	10.3389/fpubh.2024.1303319	http://dx.doi.org/10.3389/fpubh.2024.1303319			6	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	MW6U1	38584922	gold			2024-07-03	WOS:001196720200001
C	Dean, M; Bond, RR; McTear, MF; Mulvenna, MD			IEEE	Dean, Max; Bond, Raymond R.; McTear, Michael F.; Mulvenna, Maurice D.			ChatPapers: An AI Chatbot for Interacting with Academic Research	2023 31ST IRISH CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COGNITIVE SCIENCE, AICS			English	Proceedings Paper	31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)	DEC 07-08, 2023	Letterkenny, IRELAND			large language model; chatbot; retrieval augmented generation; Langchain; vector database; semantic search; GPT-4; Retrieval Augmented Generation Assessment; Readability metrics; Flesch-Kincaid; Coleman-Liau		A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in similar to 11 million vectors (based on 'chunks' from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked.	[Dean, Max; Bond, Raymond R.; McTear, Michael F.; Mulvenna, Maurice D.] Univ Ulster, Sch Comp, Belfast, Antrim, North Ireland	Ulster University	Dean, M (corresponding author), Univ Ulster, Sch Comp, Belfast, Antrim, North Ireland.	MaxDean140@Gmail.com; RB.Bond@Ulster.ac.uk; MF.Mctear@Ulster.ac.uk; MD.Mulvenna@Ulster.ac.uk						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Dean M., Evaluation Questions; Kanakia A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2893, DOI 10.1145/3308558.3313700; Kong XJ, 2021, IEEE T EMERG TOP COM, V9, P226, DOI 10.1109/TETC.2018.2830698; Lewis P., Retrieval-augmented generation for knowledge-intensive nlp tasks, P9459; pgVector, pgVector; Press Ofir, 2022, MEASURING AND NARROWING; RAGAS, ragas (note: see relese 0.0.12 for version used here); Singh R., 2023, 2023 IEEE 8 INT C CO, P1, DOI [10.1109/I2CT57861.2023.10126196, DOI 10.1109/I2CT57861.2023.10126196]; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wei Y, 2022, 2022 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, COMPUTER VISION AND MACHINE LEARNING (ICICML), P390, DOI 10.1109/ICICML57342.2022.10009721; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]	12	0	0	10	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-6021-9				2023										10.1109/AICS60730.2023.10470521	http://dx.doi.org/10.1109/AICS60730.2023.10470521			7	Behavioral Sciences; Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Behavioral Sciences; Computer Science	BW7SN					2024-07-03	WOS:001195949100008
C	Li, TO; Zong, WX; Wang, YB; Tian, HY; Wang, Y; Cheung, SC; Kramer, J			IEEE	Li, Tsz-On; Zong, Wenxi; Wang, Yibo; Tian, Haoye; Wang, Ying; Cheung, Shing-Chi; Kramer, Jeff			Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		failure-inducing test cases; large language models; program intention inference; program generation		Automated detection of software failures is an important but challenging software engineering task. It involves finding in a vast search space the failure-inducing test cases that contain an input triggering the software fault and an oracle asserting the incorrect execution. We are motivated to study how far this outstanding challenge can be solved by recent advances in large language models (LLMs) such as ChatGPT. However, our study reveals that ChatGPT has a relatively low success rate (28.8%) in finding correct failure-inducing test cases for buggy programs. A possible conjecture is that finding failure-inducing test cases requires analyzing the subtle differences (nuances) between the tokens of a program's correct version and those for its buggy version. When these two versions have similar sets of tokens and attentions, ChatGPT is weak in distinguishing their differences. We find that ChatGPT can successfully generate failure-inducing test cases when it is guided to focus on the nuances. Our solution is inspired by an interesting observation that ChatGPT could infer the intended functionality of buggy code if it is similar to the correct version. Driven by the inspiration, we develop a novel technique, called Differential Prompting, to effectively find failure-inducing test cases with the help of the compilable code synthesized by the inferred intention. Prompts are constructed based on the nuances between the given version and the synthesized code. We evaluate Differential Prompting on Quixbugs (a popular benchmark of buggy programs) and recent programs published at Codeforces (a popular programming contest portal, which is also an official benchmark of ChatGPT). We compare Differential Prompting with two baselines constructed using conventional ChatGPT prompting and PYNGUIN (the state-of-the-art unit test generation tool for Python programs). Our evaluation results show that for programs of Quixbugs, Differential Prompting can achieve a success rate of 75.0% in finding failure-inducing test cases, outperforming the best baseline by 2.6X. For programs of Codeforces, Differential Prompting's success rate is 66.7%, outperforming the best baseline by 4.0X.	[Li, Tsz-On; Wang, Ying; Cheung, Shing-Chi] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Li, Tsz-On; Cheung, Shing-Chi] Guangzhou HKUST Fok Ying Tung Res Inst, Guangzhou, Peoples R China; [Zong, Wenxi; Wang, Yibo; Wang, Ying] Northeastern Univ, Shenyang, Peoples R China; [Tian, Haoye] Univ Luxembourg, Luxembourg, Luxembourg; [Kramer, Jeff] Imperial Coll London, London, England	Hong Kong University of Science & Technology; Hong Kong University of Science & Technology; Northeastern University - China; University of Luxembourg; Imperial College London	Wang, Y; Cheung, SC (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.; Cheung, SC (corresponding author), Guangzhou HKUST Fok Ying Tung Res Inst, Guangzhou, Peoples R China.; Wang, Y (corresponding author), Northeastern Univ, Shenyang, Peoples R China.	toli@cse.ust.hk; iamwenxiz@163.com; yibowangcz@outlook.com; haoye.tian@uni.lu; wangying@swc.neu.edu.cn; scc@cse.ust.hk; j.kramer@imperial.ac.uk		TIAN, Haoye/0000-0002-8049-3997	National Science Foundation of China [61932021, 62141210]; Hong Kong Research Grant Council/General Research Fund [16205722]; Hong Kong Research Grant Council/Research Impact Fund [R5034-18]; Fundamental Research Funds for the Central Universities [N2217005]; Open Fund of State Key Lab. for Novel Software Technology, Nanjing University [KFKT2021B01]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hong Kong Research Grant Council/General Research Fund(Hong Kong Research Grants Council); Hong Kong Research Grant Council/Research Impact Fund; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Open Fund of State Key Lab. for Novel Software Technology, Nanjing University	We would like to thank the anonymous reviewers for their comments and suggestions. We would also like to thank DL library developers for analyzing our reported issues. This work is supported by the National Science Foundation of China (Grant No. 61932021, 62141210), the Hong Kong Research Grant Council/General Research Fund (Grant No. 16205722), the Hong Kong Research Grant Council/Research Impact Fund (Grant No. R5034-18), the Fundamental Research Funds for the Central Universities (Grant No. N2217005), and Open Fund of State Key Lab. for Novel Software Technology, Nanjing University (KFKT2021B01).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed T, 2022, Arxiv, DOI arXiv:2207.04237; An GB, 2022, Arxiv, DOI [arXiv:2104.06641, DOI 10.48550/ARXIV.2104.06641]; [Anonymous], 2023, Chatgpt: Optimizing language models for dialogue; [Anonymous], 2023, Codeforces; [Anonymous], 2023, How to interpret contest ratings; Baldoni R, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3182657; Bhatia S, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P60, DOI 10.1145/3180155.3180219; Cao JL, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3490488; Chang WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3163, DOI 10.1145/3394486.3403368; Chen TY, 2020, Arxiv, DOI arXiv:2002.12543; Chen YT, 2016, ACM SIGPLAN NOTICES, V51, P85, DOI [10.1145/2908080.2908095, 10.1145/2980983.2908095]; Creswell J. W., 2013, QUAL INQ, V3rd, DOI DOI 10.1177/1524839915580941; Deng YL, 2023, Arxiv, DOI arXiv:2304.02014; Ebtekar A, 2021, Arxiv, DOI arXiv:2101.00400; Evans Robert B, 2007, 6 JOINT M EUROPEAN S, P549, DOI 10.1145/1295014.1295038; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2015, ACM T SOFTW ENG METH, V24, DOI 10.1145/2699688; Hu Y, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P388, DOI 10.1109/ASE.2019.00044; Ibrahimzada AR, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P70, DOI 10.1145/3540250.3549086; Jalil S, 2023, Arxiv, DOI arXiv:2302.03287; Jiang T, 2021, AAAI CONF ARTIF INTE, V35, P7987; Jin W, 2012, PROC INT CONF SOFTW, P474, DOI 10.1109/ICSE.2012.6227168; Kelleher C, 2005, ACM COMPUT SURV, V37, P83, DOI 10.1145/1089733.1089734; Lahtinen E., 2005, SIGCSE Bulletin, V37, P14, DOI 10.1145/1151954.1067453; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Liang J, 2021, IEEE T DEPEND SECURE, V18, P2675, DOI 10.1109/TDSC.2019.2961339; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu K, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER), P456, DOI 10.1109/saner.2019.8667970; Lukasczyk S, 2022, PROC IEEE ACM INT C, P168, DOI [10.1109/ICSE-Companion55297.2022.9793730, 10.1145/3510454.3516829]; Manès VJM, 2021, IEEE T SOFTWARE ENG, V47, P2312, DOI 10.1109/TSE.2019.2946563; McKeeman William M., 1998, Digital Technical Journal, V10, P100; Patra J, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P906, DOI 10.1145/3468264.3468623; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Perretta J, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P263, DOI 10.1145/3533767.3534217; Saha S, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P1295, DOI 10.1145/3597926.3598136; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Segura S, 2016, IEEE T SOFTWARE ENG, V42, P805, DOI 10.1109/TSE.2016.2532875; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Soltani M, 2020, EMPIR SOFTW ENG, V25, P96, DOI 10.1007/s10664-019-09762-1; Soltani M, 2018, LECT NOTES COMPUT SC, V11036, P325, DOI 10.1007/978-3-319-99241-9_18; Tan L, 2014, EMPIR SOFTW ENG, V19, P1665, DOI 10.1007/s10664-013-9258-8; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Tian YQ, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-09985-1; Vaithilingam Priyan, 2022, CHI C HUM FACT COMP, P1; Weimer W, 2009, PROC INT CONF SOFTW, P364, DOI 10.1109/ICSE.2009.5070536; Widyasari R, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1556, DOI 10.1145/3368089.3417943; Xia C.S., 2023, arXiv; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xia Chunqiu Steven, 2022, arXiv; Yi JY, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P740, DOI 10.1145/3106237.3106262; Zhang J, 2021, Advances in Neural Information Processing Systems, V34; Zhang Z, 2022, PROC IEEE INT CONF S, P199, DOI 10.1109/ICSME55016.2022.00026; Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9628	56	1	1	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							14	26		10.1109/ASE56229.2023.00089	http://dx.doi.org/10.1109/ASE56229.2023.00089			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200002
J	Ellis, ME; Casey, KM; Hill, G				Ellis, Michael E.; Casey, K. Mike; Hill, Geoffrey			ChatGPT and Python programming homework	DECISION SCIENCES-JOURNAL OF INNOVATIVE EDUCATION			English	Article						analytics; course design; experiential learning; pedagogy		Large Language Model (LLM) artificial intelligence tools present a unique challenge for educators who teach programming languages. While LLMs like ChatGPT have been well documented for their ability to complete exams and create prose, there is a noticeable lack of research into their ability to solve problems using high-level programming languages. Like many other university educators, those teaching programming courses would like to detect if students submit assignments generated by an LLM. To investigate grade performance and the likelihood of instructors identifying code generated by artificial intelligence (AI) tools, we compare code generated by students and ChatGPT for introductory Python homework assignments. Our research reveals mixed results on both counts, with ChatGPT performing like a mid-range student on assignments and seasoned instructors struggling to detect AI-generated code. This indicates that although AI-generated results may not always be identifiable, they do not currently yield results approaching those of diligent students. We describe our methodology for selecting and evaluating the code examples, the results of our comparison, and the implications for future classes. We conclude with recommendations for how instructors of programming courses can mitigate student use of LLM tools as well as articulate the inherent value of preserving students' individual creativity in producing programming languages.	[Ellis, Michael E.; Casey, K. Mike; Hill, Geoffrey] Univ Cent Arkansas, Coll Business, Comp Informat Syst & Analyt Dept, Conway, AR USA; [Ellis, Michael E.] Univ Cent Arkansas, Coll Business, Comp Informat Syst & Analyt Dept, 201 Donaghey Ave, Conway, AR 72035 USA	University of Central Arkansas; University of Central Arkansas	Ellis, ME (corresponding author), Univ Cent Arkansas, Coll Business, Comp Informat Syst & Analyt Dept, 201 Donaghey Ave, Conway, AR 72035 USA.	mellis@uca.edu		Ellis, Michael/0000-0001-8682-3873				Anaconda, 2022, Anaconda Software Distribution; Barbaranelli C, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00695; Barros B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199328; Bommarito M., 2022, PREPRINT; Chevalier A., 2023, PREPRINT; Driscoll M., 2019, JUPYTER NOTEBOOK INT; Ellis M.E., 2019, Q REV BUSINESS DISCI, V6, P237; Gaddis T., 2017, STARTING OUT PYTHON; Geer D, 2005, COMPUTER, V38, P16; Geng C., 2023, PREPRINT; Greitemeyer T, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e19909; IBM SPSS Statistics for Windows Version 27, 2020, IBM SPSS STAT WIND V; Kalla D., 2023, International Journal of Innovative Science and Research Technology, V8, P827; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kirchner J. H., 2023, NEW CLASSIFIER INDIC; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; McCabe DL, 1997, RES HIGH EDUC, V38, P379, DOI 10.1023/A:1024954224675; OpenAI, 2022, OpenA I; OpenAI Text Classifier, 2023, COMPUTER SOFTWARE; Papert S., 1989, STUDYING NOVICE PROG, P3; Python's Integrated Development and Learning Environment (IDLE) (3.11.3), 2023, COMPUTER SOFTWARE; Qadir Junaid, 2023, 2023 IEEE Global Engineering Education Conference (EDUCON), P1, DOI 10.1109/EDUCON54358.2023.10125121; Raybaut P., 2022, SPYDER SCI PYTHON DE; Shidiq M., 2023, Proceeding of International Conference on Education Society and Humanity, V1, P353; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Zhang S.J., 2023, ARXIV230608997, V20, DOI [10.48550/arXiv.2306.08997, DOI 10.48550/ARXIV.2306.08997]	26	0	0	33	33	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1540-4595	1540-4609		DECIS SCI-J INNOV ED	Decis. Sci.	APR	2024	22	2					74	87		10.1111/dsji.12306	http://dx.doi.org/10.1111/dsji.12306		JAN 2024	14	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	NI5E0					2024-07-03	WOS:001144549700001
J	Karakas, C; Brock, D; Lakhotia, A				Karakas, Cemal; Brock, Dylan; Lakhotia, Arpita			Leveraging ChatGPT in the Pediatric Neurology Clinic: Practical Considerations for Use to Improve Efficiency and Outcomes	PEDIATRIC NEUROLOGY			English	Article						Clinic; ChatGPT; Letters; Workflow; Efficiency; Practical		Background: Artificial intelligence (AI) is progressively influencing healthcare sectors, including pediatric neurology. This paper aims to investigate the potential and limitations of using ChatGPT, a large language model (LLM) developed by OpenAI, in an outpatient pediatric neurology clinic. The analysis focuses on the tool's capabilities in enhancing clinical efficiency, productivity, and patient education. Method: This is an opinion-based exploration supplemented with practical examples. We assessed ChatGPT's utility in administrative and educational tasks such as drafting medical necessity letters and creating patient educational materials. Results: ChatGPT showed efficacy in streamlining administrative work, particularly in drafting administrative letters and formulating personalized patient education materials. However, the model has limitations in performing higher-order tasks like formulating nuanced differential diagnoses. Additionally, ethical and legal concerns, including data privacy and the potential dissemination of misinformation, warrant cautious implementation. Conclusions: The integration of AI tools like ChatGPT in pediatric neurology clinics has demonstrated promising results in boosting efficiency and patient education, despite present limitations and ethical concerns. As technology advances, we anticipate future applications may extend to more complex clinical tasks like precise differential diagnoses and treatment strategy guidance. Careful, patient-centered implementation is essential for leveraging the potential benefits of AI in pediatric neurology effectively. (c) 2023 Elsevier Inc. All rights reserved.	[Karakas, Cemal; Brock, Dylan; Lakhotia, Arpita] Univ Louisville, Dept Neurol, Div Pediat Neurol, Louisville, KY 40202 USA; [Karakas, Cemal; Brock, Dylan; Lakhotia, Arpita] Norton Neurosci Inst, Louisville, KY USA; [Karakas, Cemal] Pediat Neurol, 615 S Preston St,2ndfloor, Louisville, KY 40207 USA	University of Louisville	Karakas, C (corresponding author), Pediat Neurol, 615 S Preston St,2ndfloor, Louisville, KY 40207 USA.	cemal.karakas@louisville.edu	Karakas, Cemal/GQY-4429-2022	Karakas, Cemal/0000-0002-9516-2285				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Anders BA, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100694; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Bogossian A, 2020, J CHILD NEUROL, V35, P536, DOI 10.1177/0883073820918454; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Metze K, 2023, ANN BIOMED ENG, V51, P1360, DOI 10.1007/s10439-023-03205-1; Mhlanga D, Open AI in education, the responsible and ethical use of ChatGPT towards lifelong learning; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rao A, 2023, Assessing the Utility of ChatGPT throughout the Entire Clinical Workflow; Sanchez-Ramos L, 2023, AM J OBSTET GYNECOL, V229, P356, DOI 10.1016/j.ajog.2023.04.004; Sedaghat S, 2023, CLIN MED, V23, P278, DOI 10.7861/clinmed.2023-0078; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; Zerilli J, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100455	14	1	1	16	21	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0887-8994	1873-5150		PEDIATR NEUROL	Pediatr. Neurol.	NOV	2023	148						157	163		10.1016/j.pediatrneurol.2023.08.035	http://dx.doi.org/10.1016/j.pediatrneurol.2023.08.035		SEP 2023	7	Clinical Neurology; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Pediatrics	U1FL9	37725885				2024-07-03	WOS:001082330800001
C	Lin, W; Karlinsky, L; Shvetsova, N; Possegger, H; Kozinski, M; Panda, R; Feris, R; Kuehne, H; Bischof, H			IEEE	Lin, Wei; Karlinsky, Leonid; Shvetsova, Nina; Possegger, Horst; Kozinski, Mateusz; Panda, Rameswar; Feris, Rogerio; Kuehne, Hilde; Bischof, Horst			MAtch, eXpand and Improve: Unsupervised Finetuning for Zero-Shot Action Recognition with Language Knowledge	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION, ICCV	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Large scale Vision Language (VL) models have shown tremendous success in aligning representations between visual and text modalities. This enables remarkable progress in zero-shot recognition, image generation & editing, and many other exciting tasks. However, VL models tend to over-represent objects while paying much less attention to verbs, and require additional tuning on video data for best zero-shot action recognition performance. While previous work relied on large-scale, fully-annotated data, in this work we propose an unsupervised approach. We adapt a VL model for zero-shot and few-shot action recognition using a collection of unlabeled videos and an unpaired action dictionary. Based on that, we leverage Large Language Models and VL models to build a text bag for each unlabeled video via matching, text expansion and captioning. We use those bags in a Multiple Instance Learning setup to adapt an image-text backbone to video data. Although finetuned on unlabeled video data, our resulting models demonstrate high transferability to numerous unseen zero-shot downstream tasks, improving the base VL model performance by up to 14%, and even comparing favorably to fully-supervised baselines in both zero-shot and few-shot video recognition transfer. The code is released at https://github.com/wlin-at/MAXI.	[Lin, Wei; Possegger, Horst; Kozinski, Mateusz; Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria; [Karlinsky, Leonid; Panda, Rameswar; Feris, Rogerio; Kuehne, Hilde] MIT IBM Watson Lab, Cambridge, MA USA; [Shvetsova, Nina; Kuehne, Hilde] Goethe Univ Frankfurt, Frankfurt, Germany; [Kuehne, Hilde] Univ Bonn, Bonn, Germany	Graz University of Technology; Goethe University Frankfurt; University of Bonn	Lin, W (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria.	wlin2021at@gmail.com	Lin, Wei/D-3353-2012		FWF Austrian Science Fund Lise Meitner grant [M3374]; Austrian Research Promotion Agency (FFG) under the project SAFER [894164]; German Federal Ministry of Education and Research (BMBF) [STCL - 01IS22067]	FWF Austrian Science Fund Lise Meitner grant; Austrian Research Promotion Agency (FFG) under the project SAFER; German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF))	This work was funded by the FWF Austrian Science Fund Lise Meitner grant (M3374), Austrian Research Promotion Agency (FFG) under the project SAFER (894164) and German Federal Ministry of Education and Research (BMBF) project STCL - 01IS22067.	[Anonymous], 2021, PMLR; [Anonymous], 2022, P IEEE CVF C COMP VI, DOI DOI 10.1109/CVPR52688.2022.01755; [Anonymous], 2021, PMLR; [Anonymous], 2021, PMLR; [Anonymous], 2022, P IEEE CVF C COMP VI, DOI DOI 10.1109/ECTC51906.2022.00250; Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1708, DOI 10.1109/ICCV48922.2021.00175; Banki-Horvath A., 2018, arXiv preprint arXiv:1808.01340; Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Castro Santiago, 2022, BMVC; CHEN CF, 2021, COMPUTER VISION PATT, P6161, DOI DOI 10.1109/CVPR46437.2021.00610; Chen S., 2021, P IEEE INT C COMP VI, P13638; Dosovitskiy A, 2021, INT C LEARNING REPRE; Furst Andreas, 2021, ARXIV211011316; Gao XX, 2022, J FUTURE FOODS, V2, P1, DOI 10.1016/j.jfutfo.2022.03.011; Gao Yuting, 2022, ARXIV220414095; Goel Shashank, 2022, ARXIV220514459; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Gu X., 2022, ICLR; Hendricks Lisa Anne, 2021, ARXIV210609141; Ilharco Gabriel, 2022, NEURIPS; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Ju C, 2022, LECT NOTES COMPUT SC, V13695, P105, DOI 10.1007/978-3-031-19833-5_7; Kay Will, 2017, The kinetics human action video dataset; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Li B., 2022, ICLR; Li Junnan, 2022, ARXIV220112086; LI TJ, 2021, CVPR, P1626, DOI DOI 10.1109/CVPR46437.2021.01600; Li X., 2020, EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8; Li Yangguang, 2021, ARXIV211005208; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu LF, 2022, ACS ENG AU, V2, P350, DOI 10.1021/acsengineeringau.1c00039; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022; MengmengWang Jiazheng Xing, 2021, ARXIV210908472; Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990; Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464; Ni B, 2022, LECT NOTES COMPUT SC, V13664, P1, DOI 10.1007/978-3-031-19772-7_1; Qian Y, 2022, CARBON, V190, P104, DOI 10.1016/j.carbon.2022.01.009; Qin J, 2017, PROC CVPR IEEE, P1042, DOI 10.1109/CVPR.2017.117; Rasheed Hanoona, 2022, NEURIPS; Rasheed Hanoona, 2022, ARXIV221203640; Ruiz Nataniel, 2022, ARXIV220812242 CS; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shao H, 2020, AAAI CONF ARTIF INTE, V34, P11966; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Soomro Khurram, 2012, CTR RES COMPUTER VIS, V2, P11; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Thrush T, 2022, PROC CVPR IEEE, P5228, DOI 10.1109/CVPR52688.2022.00517; Wang Q, 2017, LECT NOTES ARTIF INT, V10534, P87, DOI 10.1007/978-3-319-71249-9_6; Wortsman M, 2022, PROC CVPR IEEE, P7949, DOI 10.1109/CVPR52688.2022.00780; Wu W., 2023, P AAAI WASH DC US, P7; Yao Lewei, 2021, ARXIV211107783; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Yuksekgonul M., 2023, 11 INT C LEARN REPR; Zellers Rowan, 2017, ARXIV170709468; Zhao Tiancheng, 2022, ARXIV220700221; Zhou KY, 2022, PROC CVPR IEEE, P16795, DOI 10.1109/CVPR52688.2022.01631; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	59	1	1	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							2839	2850		10.1109/ICCV51070.2023.00267	http://dx.doi.org/10.1109/ICCV51070.2023.00267			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5FA		Green Submitted			2024-07-03	WOS:001159644303010
C	Liu, YX; Deb, B; Teruel, M; Halfaker, A; Radev, D; Awadallah, AH		Rogers, A; Boyd-Graber, J; Okazaki, N		Liu, Yixin; Deb, Budhaditya; Teruel, Milagro; Halfaker, Aaron; Radev, Dragomir; Awadallah, Ahmed H.			On Improving Summarization Factual Consistency from Natural Language Feedback	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.	[Liu, Yixin; Radev, Dragomir] Yale Univ, New Haven, CT 06520 USA; [Liu, Yixin; Deb, Budhaditya; Teruel, Milagro; Halfaker, Aaron; Awadallah, Ahmed H.] Microsoft Res, Redmond, WA 98052 USA	Yale University; Microsoft	Liu, YX (corresponding author), Yale Univ, New Haven, CT 06520 USA.; Liu, YX (corresponding author), Microsoft Res, Redmond, WA 98052 USA.	yixin.liu@yale.edu; Budha.Deb@microsoft.com; hassanam@microsoft.com; dragomir.radev@yale.edu	Liu, Yi-Xin/L-8291-2019	Liu, Yi-Xin/0000-0001-9374-5981				Adams Griffin, 2022, ARXIV220410290; Agrawal S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7550; Aralikatte Rahul, 2021, Long Papers, V1, P6078, DOI DOI 10.18653/V1/2021.ACLLONG.474; Awasthi A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4260; Bach SH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P93; Balachandran Vidhisha, 2022, CORRECTING DIVERSE F; Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85; Bommasani R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8075; Cao M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3340; Cao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6251; Chen S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5935; Fabbri AR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2587; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Fabbri Alexander R., 2022, ABS221106196 ARXIV; Faltings F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5259; Goyal T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1449; Goyal Tanya, 2020, FINDINGS ASS COMPUTA, P3592; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Gu Jiatao, 2019, LEVENSHTEIN TRANSFOR; Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693, DOI DOI 10.48550/ARXIV.1506.03340; Huang DD, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P446; Huang Fan, 2022, ABS220904889 ARXIV; Jung Jaehun, 2022, ABS220511822 ARXIV; Krippendorff K, 2011, Computing krippendorff's alpha-reliability; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Madaan Aman, 2021, ABS210408765 CORR; Mallinson J, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1244; Mallinson Jonathan, 2022, EDIT5 SEMIAUTOREGRES; Malmi E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5054; Malmi Eric, 2022, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorial Abstracts, P1; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Nguyen Duy-Hung, 2022, FINDINGS ASS COMPUTA, P1919, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.147; Ouyang L., 2022, Advances in Neural Information Processing Systems; Ouyang Long, 2022, ABS220302155 ARXIV; Pagnoni A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4812; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Reid M, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3932; Sanh Victor, 2022, INT C LEARNING REPRE; Scheurer Jeremy, 2022, TRAINING LANGUAGE MO; Schick Timo, 2022, PEER COLLABORATIVE L; Stahlberg F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5147; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Tang L, 2014, P NATL ACAD SCI USA, V111, P15344, DOI 10.1073/pnas.1411499111; Wan D, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1010; Wang W, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6795205; Wei Jason, 2022, ABS220111903 ARXIV; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Wu J, 2021, RECURSIVELY SUMMARIZ; Xiao J, 2021, PROCEEDINGS OF 2021 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS '21), DOI 10.1145/3469213.3470705; Xiao Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P182; Xu Jing, 2022, LEARNING NEW SKILLS; Xu Wang, 2022, FINDINGS ASS COMPUTA, P2340; Zhang Jingqing, 2020, P 37 INT C MACH LEAR; Zhu CG, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P718	60	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15144	15161						18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962506049
C	Ye, X; Durrett, G		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Ye, Xi; Durrett, Greg			The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					Does prompting a large language model (LLM) like GPT-3 with explanations improve in-context learning? We study this question on two NLP tasks that involve reasoning over text, namely question answering and natural language inference. We test the performance of four LLMs on three textual reasoning datasets using prompts that include explanations in multiple different styles. For these tasks, we find that including explanations in the prompts for OPT, GPT-3 (davinci), and InstructGPT (text-davinci-001) only yields small to moderate accuracy improvements over standard few-show learning. However, text-davinci-002 is able to benefit more substantially. We further show that explanations generated by the LLMs may not entail the models' predictions nor be factually grounded in the input, even on simple tasks with extractive explanations. However, these flawed explanations can still be useful as a way to verify LLMs' predictions post-hoc. Through analysis in our three settings, we show that explanations judged by humans to be good-logically consistent with the input and the prediction-more likely cooccur with accurate predictions. Following these observations, we train calibrators using automatically extracted scores that assess the reliability of explanations, allowing us to improve performance post-hoc across all of our datasets.	[Ye, Xi; Durrett, Greg] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Ye, X (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	xiye@cs.utexas.edu; gdurrett@cs.utexas.edu	ye, xi/KTH-8756-2024		NSF [IIS-1814522]; NSF CAREER Award [IIS-2145280]	NSF(National Science Foundation (NSF)); NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD))	We would like to thank Eunsol Choi, Ruiqi Zhong, Jocelyn Chen, Zayne Sprague, and Jiacheng Xu for their helpful feedback on drafts of this work, as well as the anonymous reviewers for their thoughtful reviews. This work was partially supported by NSF Grant IIS-1814522, NSF CAREER Award IIS-2145280, a grant from Open Philanthropy, a gift from Salesforce Inc., and a gift from Adobe.	Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bender Emily M., 2020, P ANN C ASS COMP LIN; Brown Tom, 2020, P C ADV NEUR INF PRO; Bulian Jannis, 2022, ARXIV220207654; Camburu OM, 2018, ADV NEUR IN, V31; Chen Howard, 2022, P ANN C ASS COMP LIN; Chen JF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4026; Chen Jifan, 2021, P C EMP METH NAT LAN; Chowdhery Aakanksha, 2022, ABS220402311 ARXIV; DeYoung Jay, 2020, P ANN C ASS COMP LIN; Dua Dheeru, 2020, P ANN C ASS COMP LIN; Erion G, 2021, NAT MACH INTELL, V3, P620, DOI 10.1038/s42256-021-00343-w; Garg Siddhant, 2021, P 2021 C EMP METH NA; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Guo CS, 2017, WORLD ENVIRONMENTAL AND WATER RESOURCES CONGRESS 2017: INTERNATIONAL PERSPECTIVES, HISTORY AND HERITAGE, EMERGING TECHNOLOGIES, AND STUDENT PAPERS, P34; Hancock Braden, 2018, P ANN C ASS COMP LIN; He P, 2020, ICLR; Jacovi A, 2021, T ASSOC COMPUT LING, V9, P294, DOI 10.1162/tacl_a_00367; Jiang Yichen, 2019, P ANN C ASS COMP LIN; Kamath Amita, 2020, P ANN M ASS COMP LIN; Kojima Takeshi, 2022, ABS220511916 ARXIV; Lamm M, 2021, T ASSOC COMPUT LING, V9, P790, DOI 10.1162/tacl_a_00398; Lampinen Andrew K, 2022, ARXIV220402329; Liu Frederick, 2019, P ANN C ASS COMP LIN; Liu Jiachang, 2021, ABS210106804 ARXIV; Liu Y., 2019, CoRR abs/1907.11692; Marasovic Ana, 2022, FINDINGS N AM CHAPT; Mielke SJ, 2022, T ASSOC COMPUT LING, V10, P857, DOI 10.1162/tacl_a_00494; Min Sewon, 2022, ARXIV220212837; Nye Maxwell, 2021, ABS211200114 ARXIV; Platt JC, 2000, ADV NEUR IN, P61; Plumb G, 2020, ADV NEURAL INFORM PR; Rajani Nazneen Fatema, 2019, P ANN C ASS COMP LIN; Rajani Nazneen Fatema, 2018, P 2018 C N AM CHAPT, V1; Ribeiro MT., 2016, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, V1135, P1135, DOI [DOI 10.1145/2939672.2939778, 10.1145/2939672.2939778, 10.1145/2939672.2939778. u r l, DOI 10.1145/2939672.2939778.URL]; Rieger Laura, 2020, P INT C MACH LEARN I; Shin Richard, 2021, P C EMP METH NAT LAN; Simonyan Karen, 2014, WORKSH INT C LEARN R, P2; Stacey Joe, 2022, P AAAI C ART INT AAA; Sundararajan M, 2017, PR MACH LEARN RES, V70; Webson Albert, 2022, P 2018 C N AM CHAPT; Wei Jason, 2022, ABS220111903 ARXIV; Weston J., 2016, ICLR; Wiegreffe Sarah, 2022, P 2018 C N AM CHAPT; Wiegreffe Sarah, 2021, P C EMP METH NAT LAN; Yang Zhilin, 2018, P C EMP METH NAT LAN; Yao HH, 2021, ADV NEUR IN, V34; Ye Xi, 2021, P C EMP METH NAT LAN; Ye Xi, 2022, P ANN C ASS COMP LIN; Zaidan Omar, 2007, P ANN C ASS COMP LIN; Zhang Shujian, 2021, FIND ANN C ASS COMP; Zhang Susan, 2022, ABS220501068 ARXIV; Zhao Tony, 2021, P INT C LEARN REPR I; Zhou Yangqiaoyu, 2021, P WORKSH INS NEG RES	54	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259108065
J	Ding, DJ; Dai, GA; Peng, C; Peng, XJ; Zhang, BW; Huang, H				Ding, Daijun; Dai, Genan; Peng, Cheng; Peng, Xiaojiang; Zhang, Bowen; Huang, Hu			Distantly Supervised Explainable Stance Detection via Chain-of-Thought Supervision	MATHEMATICS			English	Article						stance detection; prompt-tuning; chain-of-thought		Investigating public attitudes on social media is crucial for opinion mining systems. Stance detection aims to predict the attitude towards a specific target expressed in a text. However, effective neural stance detectors require substantial training data, which are challenging to curate due to the dynamic nature of social media. Moreover, deep neural networks (DNNs) lack explainability, rendering them unsuitable for scenarios requiring explanations. We propose a distantly supervised explainable stance detection framework (DS-ESD), comprising an instruction-based chain-of-thought (CoT) method, a generative network, and a transformer-based stance predictor. The CoT method employs prompt templates to extract stance detection explanations from a very large language model (VLLM). The generative network learns the input-explanation mapping, and a transformer-based stance classifier is trained with VLLM-annotated stance labels, implementing distant supervision. We propose a label rectification strategy to mitigate the impact of erroneous labels. Experiments on three benchmark datasets showed that our model outperformed the compared methods, validating its efficacy in stance detection tasks. This research contributes to the advancement of explainable stance detection frameworks, leveraging distant supervision and label rectification strategies to enhance performance and interpretability.	[Ding, Daijun] Shenzhen Univ, Coll Appl Sci, Shenzhen 518052, Peoples R China; [Dai, Genan; Peng, Xiaojiang; Zhang, Bowen] Shenzhen Technol Univ, Coll Big data & Internet, Shenzhen 518118, Peoples R China; [Peng, Cheng] Univ Elect Sci & Technol China, Zhongshan Inst, Sch Comp, Zhongshan 528402, Peoples R China; [Huang, Hu] Peking Univ, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China	Shenzhen University; Shenzhen Technology University; University of Electronic Science & Technology of China; Peking University	Zhang, BW (corresponding author), Shenzhen Technol Univ, Coll Big data & Internet, Shenzhen 518118, Peoples R China.; Huang, H (corresponding author), Peking Univ, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China.	2100411011@email.szu.edu.cn; daigenan@sztu.edu.cn; pengcheng@zsc.edu.cn; pengxiaojiang@sztu.edu.cn; zhang_bo_wen@foxmail.com; h.huang@pku.edu.cn		Peng, Xiaojiang/0000-0002-5783-321X; huang, hu/0009-0005-9674-258X	National Nature science Foundation of China	National Nature science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Allaway E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4756; Allaway E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8913; Díaz GA, 2022, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON THEORY AND PRACTICE OF ELECTRONIC GOVERNANCE, ICEGOV 2022, P19, DOI 10.1145/3560107.3560296; [Anonymous], 2016, P C EMP METH NAT LAN; Cambria E., 2018, P 32 AAAI C ART INT; Cignarella AT, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), P10; Conforti C., 2021, P 11 WORKSH COMP APP, P181; Dan YH, 2022, INT CONF ACOUST SPEE, P4303, DOI 10.1109/ICASSP43922.2022.9746200; Dev K, 2018, LECT NOTES COMPUT SC, V10772, P529, DOI 10.1007/978-3-319-76941-7_40; Devi VS, 2023, NEURAL PROCESS LETT, V55, P589, DOI 10.1007/s11063-022-10898-3; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Draws Tim, 2023, CHIIR '23: Proceedings of the 2023 Conference on Human Information Interaction and Retrieval, P221, DOI 10.1145/3576840.3578296; Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3988; Glandt K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1596; Gómez-Suta M, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119046; He Z., 2022, arXiv preprint arXiv:2204.03839; Hu S., 2021, arXiv; Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22; Huang H, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3588767; Jain R, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3447650; Jayaram S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5540; Jiang Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P837, DOI 10.1145/3477495.3531979; Küçük D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3369026; Li C, 2022, IEEE T NEUR NET LEAR, V33, P2530, DOI 10.1109/TNNLS.2021.3114027; Li YJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6299; Liang B, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2738, DOI 10.1145/3485447.3511994; Liang B, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3453, DOI 10.1145/3442381.3449790; Liu R, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3152; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo Y., 2022, P 29 INT C COMP LING, P7112; Mohammad S., 2016, P 10 INT WORKSH SEM, P31, DOI [DOI 10.18653/V1/S16-1003, 10.18653/v1/S16-1003]; Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070; Rani S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3485243; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Somasundaran S., 2009, ACL, P226, DOI DOI 10.3115/1687878.1687912; Sun Q., 2018, P 27 INT C COMP LING, P2399; Tang D., 2016, P 2016 C EMPIRICAL M, P214, DOI [DOI 10.18653/V1/D16-1021, 10.18653/v1/D16-1021]; Walker M.A., 2012, Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P592; Wei JS, 2022, ADV NEUR IN; Wei PH, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1173, DOI 10.1145/3331184.3331367; Wei PH, 2018, ACM/SIGIR PROCEEDINGS 2018, P1229, DOI 10.1145/3209978.3210145; Xu C, 2020, FRONT ARTIF INTEL AP, V325, P2260, DOI 10.3233/FAIA200353; Xu C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P778; Yang M, 2019, NEURAL NETWORKS, V118, P247, DOI 10.1016/j.neunet.2019.06.014; Zhang BW, 2023, Arxiv, DOI arXiv:2304.03087; Zhang BW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3188; Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568; Zhang YZ, 2021, NEURAL NETWORKS, V133, P40, DOI 10.1016/j.neunet.2020.10.001; Zhu QL, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2070, DOI 10.1145/3477495.3531807	49	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	APR	2024	12	7							1119	10.3390/math12071119	http://dx.doi.org/10.3390/math12071119			18	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	NN3W3		gold			2024-07-03	WOS:001201100800001
J	Zou, WX; Li, JX; Yang, YK; Tang, L				Zou, Wenxue; Li, Jinxu; Yang, Yunkang; Tang, Lu			Exploring the Early Adoption of Open AI among Laypeople and Technical Professionals: An Analysis of Twitter Conversations on #ChatGPT and #GPT3	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION			English	Article; Early Access						ChatGPT; gpt-3; twitter; structural topic modeling; sentiment analysis		Large language models (LLMs) such as GPT-3 and their derivative products such as ChatGPT have garnered significant attention for their remarkable ability to process texts and conduct human-like conversations. Guided by the Diffusion of Innovation theory, this study examines the early discussions about LLMs on Twitter, specifically about ChatGPT and GPT-3, during the first three months following the release of ChatGPT. By utilizing topic structural modeling and sentiment analysis on a sample of 42,273 #ChatGPT tweets and 17,639 #GPT3 tweets, we explore how laypeople and technical professionals differ in their attitudes in the early stage of the adoption of LLMs. Our findings suggest that the discussion surrounding ChatGPT and GPT-3 primarily revolves around relative advantage and compatibility, with the majority of #ChatGPT conversations demonstrating negative sentiment and #GPT3 discussions containing more positive topics. The Twitter discussion using #ChatGPT is highly business-oriented, while the discussion of #GPT3 covers a broader range of topics in terms of the characteristics, applications, and potential ethical concerns of LLMs. This study offers implications for government agencies and policymakers, suggesting that further research is needed to fully understand the potential applications and risks of LLMs.	[Zou, Wenxue] Coastal Carolina Univ, Dept Commun, Conway, SC USA; [Li, Jinxu; Yang, Yunkang; Tang, Lu] Texas A&M Univ, Dept Commun & Journalism, College Stn, TX USA	Coastal Carolina University; Texas A&M University System; Texas A&M University College Station	Tang, L (corresponding author), Texas A&M Univ, Dept Commun, College Stn, TX 77843 USA.	ltang@tamu.edu		Tang, Lu/0000-0002-1850-1511; Zou, Wenxue/0000-0002-4151-4230; Li, Jinxu/0000-0001-7978-2129	National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	No Statement Available	Abrahamson E, 1996, ACAD MANAGE REV, V21, P254, DOI 10.2307/258636; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; [Anonymous], 2023, What's New in Artificial Intelligence From the 2023 Gartner Hype CycleT; Argyle LP, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2311627120; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bae Y, 2012, J AM SOC INF SCI TEC, V63, P2521, DOI 10.1002/asi.22768; Bail C. A., 2023, Can Generative AI Improve Social Science?, DOI [https://doi.org/10.31235/osf.io/rwtzs, DOI 10.31235/OSF.IO/RWTZS]; Bailey E., 2023, Cribl; Bian J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158450; Boyd R. L., 2022, The Development and Psychometric Properties of LIWC-22, DOI DOI 10.13140/RG.2.2.23890.43205; Calabrese C, 2020, ENVIRON COMMUN, V14, P954, DOI 10.1080/17524032.2019.1699135; Creten S, 2022, J HEALTH COMMUN, V27, P697, DOI 10.1080/10810730.2022.2149904; Dunklin M, 2022, J MASS COMMUN Q, V99, P763, DOI 10.1177/10776990221109236; Haque M.U., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.05856; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hung M, 2020, J MED INTERNET RES, V22, DOI 10.2196/22590; Kim YJ, 2019, PRS-GLOB OPEN, V7, DOI 10.1097/GOX.0000000000002113; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kwon KH, 2019, INT J COMMUN-US, V13, P2652; Lee SY, 2014, TELEMAT INFORM, V31, P308, DOI 10.1016/j.tele.2013.06.001; Leiter C, 2023, Arxiv, DOI [arXiv:2302.13795, DOI 10.48550/ARXIV.2302.13795]; LIWC, 2022, LIWC Analysis; Cody EM, 2016, Arxiv, DOI [arXiv:1608.02024, 10.48550/arXiv.1608.02024, DOI 10.48550/ARXIV.1608.02024]; Maad M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P65, DOI DOI 10.52866/IJCSM.2023.01.01.0019; Madsen DO, 2015, COGENT BUS MANAG, V2, DOI 10.1080/23311975.2015.1122256; Marr B., 2016, FORBES; McHugh MC, 2019, HEALTH EDUC BEHAV, V46, P97, DOI 10.1177/1090198118788610; Moldovan S, 2015, J CONSUM PSYCHOL, V25, P1, DOI 10.1016/j.jcps.2014.06.001; OConnor B., 2010, Proceedings of the International AAAI Conference on Web and Social Media, V4, P122, DOI [10.1609/icwsm.v4i1.14031, DOI 10.1609/ICWSM.V4I1.14031]; Piazza A, 2020, INT J MANAG REV, V22, P264, DOI 10.1111/ijmr.12225; Raman R., 2023, University students as early adopters of ChatGPT: innovation diffusion study, DOI [10.21203/rs.3.rs-2734142/v1, DOI 10.21203/RS.3.RS-2734142/V1]; Rauschnabel PA, 2019, PSYCHOL MARKET, V36, P473, DOI 10.1002/mar.21191; Reuters, 2023, Reuters; Roberts ME, 2019, J STAT SOFTW, V91, P1, DOI 10.18637/jss.v091.i02; Roberts ME, 2014, AM J POLIT SCI, V58, P1064, DOI 10.1111/ajps.12103; Rogers EM., 2003, Diffusion of innovations (5. Aufl.), V5, DOI DOI 10.2307/2573300; Seranmadevi R., 2019, Management Science Letters, V9, P33, DOI [https://doi.org/10.5267/j.msl.2018.11.002, DOI 10.5267/J.MSL.2018.11.002]; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sterling R, 2019, J MED INTERNET RES, V21, DOI 10.2196/14304; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; TORNATZKY LG, 1982, IEEE T ENG MANAGE, V29, P28, DOI 10.1109/TEM.1982.6447463; Tumasjan A, 2011, SOC SCI COMPUT REV, V29, P402, DOI 10.1177/0894439310386557; Wang P, 2010, MIS QUART, V34, P63; Weigel FK, 2014, COMMUN ASSOC INF SYS, V34, P619	44	1	1	25	25	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	1044-7318	1532-7590		INT J HUM-COMPUT INT	Int. J. Hum.-Comput. Interact.	2023 DEC 22	2023										10.1080/10447318.2023.2295725	http://dx.doi.org/10.1080/10447318.2023.2295725		DEC 2023	12	Computer Science, Cybernetics; Ergonomics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	DC2F4					2024-07-03	WOS:001129761000001
J	Siegel, MG; Rossi, MJ; Lubowitz, JH				Siegel, Mark G.; Rossi, Michael J.; Lubowitz, James H.			Artificial Intelligence and Machine Learning May Resolve Health Care Information Overload	ARTHROSCOPY-THE JOURNAL OF ARTHROSCOPIC AND RELATED SURGERY			English	Editorial Material							SYSTEMATIC REVIEWS; HIP ARTHROSCOPY; FUTURE	Biomedical information doubles almost every 2 months, and this very rate is expected to double by 2025. The result is information overload for clinicians and researchers. Today, arti fi cial intelligence (AI) and machine learning (ML) research contribute to the deluge of information. In addition, AI large language models, although capable of automating scienti fi c writing, are fl awed. They hallucinate (make things up), are trained primarily on non - peer -reviewed content, raise ethical and legal issues, and lack human empathy. Still, when it comes to AI including ML, we are optimistic. The technology is improving rapidly. In the future, AI will help us manage unwieldy information by processing data, determining diagnoses, recommending treatments, and predicting outcomes. In research, AI and ML similarly promise ef fi cient data analysis and literature review and will create new content in response to our instructions. Human touch will be required, and we will disclose use of AI proactively, including rationale for its use, our data input, our level of con fi dence in the output, and the patients or populations to whom the output may be applied. In addition, we will ensure data quality is high and bias is minimized. Most of all, we will provide essential reasoning, clinical and research guidance, and diligent oversight. Humans will remain accountable.										Brand JC, 2023, ARTHROSCOPY, V39, DOI 10.1016/j.arthro.2022.10.026; Brand JC, 2022, ARTHROSCOPY, V38, P2111, DOI 10.1016/j.arthro.2022.04.017; Brand JC, 2022, ARTHROSCOPY, V38, P1, DOI 10.1016/j.arthro.2021.11.015; Burbank C, 2023, MedPageTodayJuly 28; Cote MP, 2024, ARTHROSCOPY, V40, DOI 10.1016/j.arthro.2023.12.027; Cote MP, 2021, ARTHROSCOPY, V37, P1699, DOI 10.1016/j.arthro.2021.04.022; Densen Peter, 2011, Trans Am Clin Climatol Assoc, V122, P48; Domb BG, 2021, ARTHROSCOPY, V37, P1152, DOI 10.1016/j.arthro.2020.12.231; European Union-Agency for Fundamental Rights, Data quality and artificial intelligence-mitigating bias and error to protect fundamental rights; Gilat R, 2023, ARTHROSCOPY, V39, P1119, DOI 10.1016/j.arthro.2023.01.014; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Harris JD, 2021, ARTHROSCOPY, V37, P1867, DOI 10.1016/j.arthro.2021.03.002; Harris JD, 2021, ARTHROSCOPY, V37, P1498, DOI 10.1016/j.arthro.2021.02.032; Hohmann E, 2022, ARTHROSCOPY, V38, P848, DOI 10.1016/j.arthro.2021.10.008; Hurley ET, 2024, ARTHROSCOPY, V40, DOI 10.1016/j.arthro.2023.07.048; Lu YN, 2023, ARTHROSCOPY, V39, P1512, DOI 10.1016/j.arthro.2023.01.093; Lubowitz JH, 2024, ARTHROSCOPY, V40, P651, DOI 10.1016/j.arthro.2023.10.037; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1367, DOI 10.1016/j.arthro.2022.12.016; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Lubowitz JH, 2022, ARTHROSCOPY, V38, P2589, DOI 10.1016/j.arthro.2022.07.005; Lubowitz JH, 2021, ARTHROSCOPY, V37, P3387, DOI 10.1016/j.arthro.2021.10.005; Lubowitz JH, 2018, ARTHROSCOPY, V34, P1379, DOI 10.1016/j.arthro.2018.03.013; Lubowitz JH, 2017, ARTHROSCOPY, V33, P1753, DOI 10.1016/j.arthro.2017.07.002; Lubowitz JH, 2016, ARTHROSCOPY, V32, P237, DOI 10.1016/j.arthro.2015.12.002; Lubowitz JH, 2010, ARTHROSCOPY, V26, P1141, DOI 10.1016/j.arthro.2010.07.003; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Miller A, 2013, CAN MED ASSOC J, V185, pE367, DOI 10.1503/cmaj.109-4442; Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762; Pareek A, 2022, ARTHROSCOPY, V38, P2106, DOI 10.1016/j.arthro.2022.01.026; Polce EM, 2023, ARTHROSCOPY, V39, P151, DOI 10.1016/j.arthro.2022.04.016; Provencher MT, 2016, ARTHROSCOPY, V32, P955, DOI 10.1016/j.arthro.2016.04.005; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Rahimi SA, 2022, JMIR MED INF, V10, DOI 10.2196/36199; Ramkumar PN, 2023, ARTHROSCOPY, V39, P787, DOI 10.1016/j.arthro.2022.07.012; Ramkumar PN, 2022, ARTHROSCOPY, V38, P2761, DOI 10.1016/j.arthro.2022.04.014; Ramkumar PN, 2021, ARTHROSCOPY, V37, P1694, DOI 10.1016/j.arthro.2020.08.009; Rossi MJ, 2023, ARTHROSCOPY, V39, P2399, DOI 10.1016/j.arthro.2023.08.068; Sallam M, 2023, medRxiv; Taylor P., 2024, Amount of data created, consumed, and stored 2010-2020, with forecasts to 2025; Wang DY, 2024, ARTHROSCOPY, V40, P1197, DOI 10.1016/j.arthro.2023.08.010; Wellington IJ, 2022, ARTHROSCOPY, V38, P2767, DOI 10.1016/j.arthro.2022.05.010	41	0	0	0	0	W B SAUNDERS CO-ELSEVIER INC	PHILADELPHIA	1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA	0749-8063	1526-3231		ARTHROSCOPY	Arthroscopy	JUN	2024	40	6								10.1016/j.arthro.2024.01.007	http://dx.doi.org/10.1016/j.arthro.2024.01.007			3	Orthopedics; Sport Sciences; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Sport Sciences; Surgery	UL9R1	38218231				2024-07-03	WOS:001248337500001
J	García-Peñalvo, FJ; Llorens-Largo, F; Vidal, J				Garcia-Penalvo, Francisco Jose; Llorens-Largo, Faraon; Vidal, Javier			The new reality of education in the face of advances in generative artificial intelligence	RIED-REVISTA IBEROAMERICANA DE EDUCACION A DISTANCIA			English	Article						artificial intelligence; generative artificial intelligence; ChatGPT; education	CHATGPT	It is increasingly common to interact with products that seem "intelligent", although the label "artificial intelligence" may have been replaced by other euphemisms. Since November 2022, with the emergence of the ChatGPT tool, there has been an exponential increase in the use of artificial intelligence in all areas. Although ChatGPT is just one of many generative artificial intelligence technologies, its impact on teaching and learning processes has been significant. This article reflects on the advantages, disadvantages, potentials, limits, and challenges of generative artificial intelligence technologies in education to avoid the biases inherent in extremist positions. To this end, we conducted a systematic review of both the tools and the scientific production that have emerged in the six months since the appearance of ChatGPT. Generative artificial intelligence is extremely powerful and improving at an accelerated pace, but it is based on large language models with a probabilistic basis, which means that they have no capacity for reasoning or comprehension and are therefore susceptible to containing errors that need to be contrasted. On the other hand, many of the problems associated with these technologies in educational contexts already existed before their appearance, but now, due to their power, we cannot ignore them, and we must assume what our speed of response will be to analyse and incorporate these tools into our teaching practice.	[Garcia-Penalvo, Francisco Jose] Univ Salamanca, Salamanca, Spain; [Llorens-Largo, Faraon] Univ Alicante, Alicante, Spain; [Vidal, Javier] Univ Leon, Leon, Spain	University of Salamanca; Universitat d'Alacant; Universidad de Leon	García-Peñalvo, FJ (corresponding author), Univ Salamanca, Salamanca, Spain.		GARCÍA-PEÑALVO, Francisco José/D-5445-2013; Llorens Largo, Faraón/K-5060-2014	GARCÍA-PEÑALVO, Francisco José/0000-0001-9987-5584; Llorens Largo, Faraón/0000-0002-2117-0784				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adiwardana D., 2020, Google; Agarwal G., 2023, AI Tool Master List, DOI [10.1007/s43681-022-00147-7, DOI 10.1007/S43681-022-00147-7]; Ali S, 2021, AAAI CONF ARTIF INTE, V35, P15472; Ali Safinah., 2021, Computers and Education: Artificial Intelligence, V2, P100040, DOI DOI 10.1016/J.CAEAI.2021.100040; Alier-Forment M., 2023, Cabalga el Cometa; Alonso C., 2023, inverted exclamationOjo con ChatGPT, que es un charlatan mentirosillo! El futuro esta por hackear; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Arora Anmol, 2022, Future Healthc J, V9, P190, DOI 10.7861/fhj.2022-0013; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P53, DOI [10.5281/zenodo.7636568, DOI 10.5281/ZENODO.7636568]; Chng E., 2023, J. STEM Educ. Res, DOI [10.1007/s41979-023-00092-y, DOI 10.1007/S41979-023-00092-Y]; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Chomsky N., 2023, NEW YORK TIMES; Coeckelbergh M., 2023, La filosofia politica de la inteligencia artificial. Una introduccion; Collins E., 2021, Google; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Crespo Artiaga D., 2023, UNIVERSITIC 2022. Analisis de la madurez digital de las universidades espanolas en 2022; Dennett D., 2017, De las bacterias a Bach. La evolucion de la mente; Devlin J., 2018, Google, V2; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Ebrahimi Y., 2023, 1000 AI collection tools; European University Association, 2023, Artificial intelligence tools and their responsible use in higher education learning and teaching; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Flores-Vivar J. M., 2023, Desafios y retos de las redes sociales en el ecosistema de la comunicacion, V1, P109; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Garcia-Penalvo F., 2023, International Journal of Interactive Multimedia and Artificial Intelligence; García-Peñalvo FJ, 2023, EDUC KNOWL SOC, V24, DOI 10.14201/eks.31279; García-Peñalvo FJ, 2022, EDUC KNOWL SOC, V23, DOI 10.14201/eks.28600; Gasevic D., 2023, Comput. Educ. Artif. Intell, V4, DOI [DOI 10.1016/J.CAEAI.2023.100130, 10.1016/j.caeai.2023.100130]; Gasevic D, 2015, TECHTRENDS, V59, P64, DOI 10.1007/s11528-014-0822-x; Gates B., 2023, GatesNotes; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gobierno de Espana, 2020, ENIA: Estrategia Nacional de Inteligencia Artificial; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Grant MJ, 2009, HEALTH INFO LIBR J, V26, P91, DOI 10.1111/j.1471-1842.2009.00848.x; Gruetzemacher R, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505245; Gubareva R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P97, DOI 10.5220/0009417600970103; Hazzan O., 2023, BLOG@ACM; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Holmes W, 2022, INT J ARTIF INTELL E, V32, P504, DOI 10.1007/s40593-021-00239-1; Informatics Europe, 2023, AI in Informatics Education (Position paper by Informatics Europe and the National Informatics Associations); Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Johinke R, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.01; Karaali Gizem, 2023, Numeracy, V16, DOI [10.5038/1936-4660.16.1.1438, DOI 10.5038/1936-4660.16.1.1438]; Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kirchner Jan Hendrik, 2023, New ai classifier for indicating ai-written text; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kurian T., 2023, The Keyword; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Liu Y., 2023, arXiv; Llorens-Largo F., 2019, Las tecnologias en la educacion: caracteristicas deseables, efectos perversos; Lyu Z, 2022, AAAI CONF ARTIF INTE, P12801; Maslej N., 2023, The ai index 2023 annual report; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Meyer B., 2022, BLOG@CACM; Nemorin S, 2023, LEARN MEDIA TECHNOL, V48, P38, DOI 10.1080/17439884.2022.2095568; Neubauer AC, 2021, INTELLIGENCE, V87, DOI 10.1016/j.intell.2021.101563; Ng DTK, 2023, EDUC INF TECHNOL, V28, P8445, DOI 10.1007/s10639-022-11491-w; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Pataranutaporn P., 2022, P 2022 IEEE FRONT ED, DOI [10.1109/FIE56618, DOI 10.1109/FIE56618]; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pichai S., 2023, Google; Raffel C, 2020, J MACH LEARN RES, V21; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sabzalieva E., 2023, ED/HE/IESALC/IP/2023/12; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Sivasubramanian S., 2023, Announcing New Tools for Building with Generative AI on AWS; Slapeta J, 2023, TRENDS PARASITOL, V39, P314, DOI 10.1016/j.pt.2023.02.006; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Thatcher JB, 2018, MIS QUART, V42, P831, DOI 10.25300/MISQ/2018/11881; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; UNESCO, 2021, Inteligencia Artificial: oportunidad para el Desarrollo Sostenible en America Latina; Unesco, 2022, Recomendacion sobre la etica de la inteligencia artificial; UNESCO, 2019, INT C ART INT ED PLA; van der Zant T., 2013, Philosophy and Theory of Artificial Intelligence, V5, P107, DOI [10.1007/978-3-642-31674-6, DOI 10.1007/978-3-642-31674-68]; Vartiainen H, 2023, DIGIT CREAT, V34, P1, DOI 10.1080/14626268.2023.2174557; Vaswani A, 2017, ADV NEUR IN, V30; Vázquez-Ingelmo A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073249; Wang T., 2021, Computers and Education: Artificial Intelligence, V2, P100031, DOI DOI 10.1016/J.CAEAI.2021.100031; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yilmaz R., 2022, Comput. Educ., Artif. Intell., V3, P100092, DOI [10.1016/j.caeai.2022.100092, DOI 10.1016/J.CAEAI]; Zhang L, 2020, EDUC RES REV-NETH, V31, DOI 10.1016/j.edurev.2020.100339; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zhao WX, 2023, ARXIV; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206	100	18	18	149	149	ASOCIACION IBEROAMERICANA EDUCACION SUPERIOR & DISTANCIA - AIESAD	MADRID	UNED, FAC EDUC, C/ JUAN DEL ROSAI, 14, MADRID, 28040, SPAIN	1138-2783	1390-3306		RIED-REV IBEROAM EDU	RIED-Rev. Iberoam. Educ. Distancia	JAN	2024	27	1								10.5944/ried.27.1.37716	http://dx.doi.org/10.5944/ried.27.1.37716			24	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	EE4Q1		Green Submitted, gold			2024-07-03	WOS:001137233600013
J	Staub, A				Staub, Adrian			The Function/Content Word Distinction and Eye Movements in Reading	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION			English	Article; Early Access						eye movements; reading; word class	E-Z-READER; FUNCTIONAL CATEGORIES; FIXATION DURATIONS; PERCEPTUAL-SPAN; PREDICTABILITY; FREQUENCY; ENGLISH; INTEGRATION; SENTENCE; MODEL	A substantial quantity of research has explored whether readers' eye movements are sensitive to the distinction between function and content words. No clear answer has emerged, in part due to the difficulty of accounting for differences in length, frequency, and predictability between the words in the two classes. Based on evidence that readers differentially overlook function word errors, we hypothesized that function words may be more frequently skipped or may receive shorter fixations. We present two very large-scale eyetracking experiments using selected sentences from a corpus of natural text, with each sentence containing a target function or content word. The target words in the two classes were carefully matched on length, frequency, and predictability, with the latter variable operationalized in terms of next-word probability obtained from the large language model GPT-2. While the experiments replicated a range of expected effects, word class did not have any clear influence on target word skipping probability, and there was some evidence for a content word advantage in fixation duration measures. These results indicate that readers' tendency to overlook function word errors is not due to reduced time spent encoding these words. The results also broadly support the implicit assumption in prominent models of eye movement control in reading that a word's syntactic category does not play an important role in decisions about when and where to move the eyes.	[Staub, Adrian] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA USA; [Staub, Adrian] Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst; University of Massachusetts System; University of Massachusetts Amherst	Staub, A (corresponding author), Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA.	astaub@umass.edu		Staub, Adrian/0000-0002-9045-9610				ABRAHAM RG, 1992, MOD LANG J, V76, P468, DOI 10.2307/330047; Angele B, 2014, J EXP PSYCHOL LEARN, V40, P1181, DOI 10.1037/a0036396; Angele B, 2013, J EXP PSYCHOL LEARN, V39, P649, DOI 10.1037/a0029294; Ashby J, 2005, COGNITION, V96, pB89, DOI 10.1016/j.cognition.2004.12.006; Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014; Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003; Bicknell K, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1168; BLYTH CR, 1972, J AM STAT ASSOC, V67, P364, DOI 10.2307/2284382; Breen M, 2014, LANG LINGUIST COMPAS, V8, P37, DOI 10.1111/lnc3.12061; Brysbaert M., 1998, EYE GUIDANCE READING, P125, DOI DOI 10.1016/B978-008043361-5/50007-9; Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977; Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01; Burnsky J, 2023, LANG COGN NEUROSCI, V38, P821, DOI 10.1080/23273798.2022.2159990; Cevoli B, 2022, ROY SOC OPEN SCI, V9, DOI 10.1098/rsos.211837; Chomsky N., 1995, The Minimalist Program; Christophe A, 2008, LANG SPEECH, V51, P61, DOI 10.1177/00238309080510010501; Corver Norbert., 2001, Semi-Lexical Categories, P1; Cutter MG, 2020, Q J EXP PSYCHOL, V73, P1423, DOI 10.1177/1747021820911021; Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav; Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008; Drieghe D, 2008, J EXP PSYCHOL LEARN, V34, P1552, DOI 10.1037/a0013017; Engbert R, 2005, PSYCHOL REV, V112, P777, DOI 10.1037/0033-295X.112.4.777; FILLENBAUM S, 1963, J VERB LEARN VERB BE, V2, P186, DOI 10.1016/S0022-5371(63)80084-5; Friederici AD, 2000, CEREB CORTEX, V10, P698, DOI 10.1093/cercor/10.7.698; Garrett M. F., 1980, LANGUAGE PRODUCTION, V1, P177; Garrett M.F., 1975, PSYCHOL LEARNING MOT, P133; Gibson E, 2013, P NATL ACAD SCI USA, V110, P8051, DOI 10.1073/pnas.1216438110; Gollan TH, 2023, NEUROPSYCHOLOGY, V37, P813, DOI 10.1037/neu0000829; Gollan TH, 2020, PSYCHOL AGING, V35, P1016, DOI 10.1037/pag0000550; GORDON B, 1982, BRAIN LANG, V15, P143, DOI 10.1016/0093-934X(82)90053-0; GREENBERG SN, 1991, J EXP PSYCHOL LEARN, V17, P1051, DOI 10.1037/0278-7393.17.6.1051; HEALY AF, 1980, J EXP PSYCHOL HUMAN, V6, P45, DOI 10.1037/0096-1523.6.1.45; Healy AF, 2017, Q J EXP PSYCHOL, V70, P373, DOI 10.1080/17470218.2016.1218521; Huang K. J., 2022, P ANN M COGN SCI SOC, V44; Huang KJ, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12434; Juhasz BJ, 2003, J EXP PSYCHOL LEARN, V29, P1312, DOI 10.1037/0278-7393.29.6.1312; Just Marcel., 1987, The Psychology of Reading and Language Comprehension; KEAN ML, 1977, COGNITION, V5, P9, DOI 10.1016/0010-0277(77)90015-4; Kliegl R, 2007, J EXP PSYCHOL GEN, V136, P530, DOI 10.1037/0096-3445.136.3.530; KORIAT A, 1991, J EXP PSYCHOL LEARN, V17, P1035, DOI 10.1037/0278-7393.17.6.1035; Kuperman V, 2013, Q J EXP PSYCHOL, V66, P563, DOI 10.1080/17470218.2012.658820; Kuperman V, 2010, Q J EXP PSYCHOL, V63, P1838, DOI 10.1080/17470211003602412; Lapointe Stephen., 1989, Linguistic structure in language processing, P107; Linzen T., 2014, P 5 WORKSH COGN MOD, P10, DOI [10.3115/v1/W14-2002, DOI 10.3115/V1/W14-2002]; Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002; McDonald SA, 2003, VISION RES, V43, P1735, DOI 10.1016/S0042-6989(03)00237-2; New B, 2006, PSYCHON B REV, V13, P45, DOI 10.3758/BF03193811; OREGAN K, 1979, PERCEPT PSYCHOPHYS, V25, P501, DOI 10.3758/BF03213829; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rayner K, 2004, J EXP PSYCHOL HUMAN, V30, P720, DOI 10.1037/0096-1523.30.4.720; RAYNER K, 1975, COGNITIVE PSYCHOL, V7, P65, DOI 10.1016/0010-0285(75)90005-5; RAYNER K, 1977, MEM COGNITION, V5, P443, DOI 10.3758/BF03197383; Rayner K, 2011, J EXP PSYCHOL HUMAN, V37, P514, DOI 10.1037/a0020990; Reichle ED, 2003, BEHAV BRAIN SCI, V26, P445, DOI 10.1017/S0140525X03000104; Reichle ED, 2009, PSYCHON B REV, V16, P1, DOI 10.3758/PBR.16.1.1; Rizzi L, 2016, ANNU REV LINGUIST, V2, P139, DOI 10.1146/annurev-linguistics-011415-040827; Schmauder AR, 2000, MEM COGNITION, V28, P1098, DOI 10.3758/BF03211811; Segalowitz SJ, 2000, BRAIN LANG, V75, P376, DOI 10.1006/brln.2000.2361; Shain C., 2022, Large-scale evidence for logarithmic effects of word predictability on reading time, DOI [10.31234/osf.io/4hyna, DOI 10.31234/OSF.IO/4HYNA]; Shi RS, 2010, INFANCY, V15, P517, DOI 10.1111/j.1532-7078.2009.00022.x; Slattery TJ, 2012, J EXP PSYCHOL HUMAN, V38, P251, DOI 10.1037/a0025980; Staub A., 2023, Function vs content words; Staub A, 2020, J EXP PSYCHOL HUMAN, V46, P1235, DOI 10.1037/xhp0000853; Staub A, 2019, PSYCHON B REV, V26, P340, DOI 10.3758/s13423-018-1492-z; Staub A, 2019, J EXP PSYCHOL LEARN, V45, P110, DOI 10.1037/xlm0000561; Staub A, 2015, LANG LINGUIST COMPAS, V9, P311, DOI 10.1111/lnc3.12151; Szewczyk JM, 2022, J MEM LANG, V123, DOI 10.1016/j.jml.2021.104311; Travis LD, 2014, ROUT HANDB LINGUIST, P42; Vasilev MR, 2017, PSYCHON B REV, V24, P666, DOI 10.3758/s13423-016-1147-x; Wagenmakers EJ, 2010, COGNITIVE PSYCHOL, V60, P158, DOI 10.1016/j.cogpsych.2009.12.001	70	0	0	11	13	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0278-7393	1939-1285		J EXP PSYCHOL LEARN	J. Exp. Psychol.-Learn. Mem. Cogn.	2023 OCT 26	2023										10.1037/xlm0001301	http://dx.doi.org/10.1037/xlm0001301		OCT 2023	19	Psychology; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology	Y9NS8	37883049				2024-07-03	WOS:001108461500001
J	Noe-Steinmüller, N; Scherbakov, D; Zhuravlyova, A; Wager, TD; Goldstein, P; Tesarz, J				Noe-Steinmuller, Niklas; Scherbakov, Dmitry; Zhuravlyova, Alexandra; Wager, Tor D.; Goldstein, Pavel; Tesarz, Jonas			Defining suffering in pain: a systematic review on pain-related suffering using natural language processing	PAIN			English	Article						Pain; Suffering; Definition; Natural language processing; Machine learning; ChatGPT; GPT-3; Topic modeling; LDA	PALLIATIVE CARE; EXPERIENCE; DEMENTIA; MEDICINE; ILLNESS; PEOPLE; CANCER; MODEL; PHENOMENOLOGY; TALK	Supplemental Digital Content is Available in the Text. Understanding, measuring, and mitigating pain-related suffering is a key challenge for both clinical care and pain research. However, there is no consensus on what exactly the concept of pain-related suffering includes, and it is often not precisely operationalized in empirical studies. Here, we (1) systematically review the conceptualization of pain-related suffering in the existing literature, (2) develop a definition and a conceptual framework, and (3) use machine learning to cross-validate the results. We identified 111 articles in a systematic search of Web of Science, PubMed, PsychINFO, and PhilPapers for peer-reviewed articles containing conceptual contributions about the experience of pain-related suffering. We developed a new procedure for extracting and synthesizing study information based on the cross-validation of qualitative analysis with an artificial intelligence-based approach grounded in large language models and topic modeling. We derived a definition from the literature that is representative of current theoretical views and describes pain-related suffering as a severely negative, complex, and dynamic experience in response to a perceived threat to an individual's integrity as a self and identity as a person. We also offer a conceptual framework of pain-related suffering distinguishing 8 dimensions: social, physical, personal, spiritual, existential, cultural, cognitive, and affective. Our data show that pain-related suffering is a multidimensional phenomenon that is closely related to but distinct from pain itself. The present analysis provides a roadmap for further theoretical and empirical development.	[Noe-Steinmuller, Niklas; Tesarz, Jonas] Univ Hosp Heidelberg, Dept Gen Internal Med & Psychosomat, Heidelberg, Germany; [Scherbakov, Dmitry; Zhuravlyova, Alexandra; Goldstein, Pavel] Univ Haifa, Sch Publ Hlth, Haifa, Israel; [Wager, Tor D.] Dartmouth Coll, Hanover, NH USA; [Tesarz, Jonas] Heidelberg Univ, Med Hosp, Dept Gen Internal Med & Psychosomat, Neuenheimer Feld 410, D-69120 Heidelberg, Germany	Ruprecht Karls University Heidelberg; University of Haifa; Dartmouth College; Ruprecht Karls University Heidelberg	Tesarz, J (corresponding author), Univ Hosp Heidelberg, Dept Gen Internal Med & Psychosomat, Heidelberg, Germany.; Tesarz, J (corresponding author), Heidelberg Univ, Med Hosp, Dept Gen Internal Med & Psychosomat, Neuenheimer Feld 410, D-69120 Heidelberg, Germany.	noe-steinmueller@posteo.de; scherbakov.dmitri@gmail.com; alexa.zhuravl@gmail.com; Tor.D.Wager@dartmouth.edu; pavelg@stat.haifa.ac.il; jonas.tesarz@med.uni-heidelberg.de		Scherbakov, Dmitry/0009-0005-7274-0934	German Research Foundation (DFG) within the Collaborative Research Center [(SFB) 1158]; German Federal Ministry of Education and Research (Bundesministerium fur Bildung und Forschung; PerPAIN consortium) [FKZ:01 EC1904A]	German Research Foundation (DFG) within the Collaborative Research Center(German Research Foundation (DFG)); German Federal Ministry of Education and Research (Bundesministerium fur Bildung und Forschung; PerPAIN consortium)(Federal Ministry of Education & Research (BMBF))	The authors express their sincere gratitude to the anonymous reviewers, whose outstanding and constructive comments have made a substantial contribution to the enhancement of this manuscript and its current state. The submitted manuscript does not contain information about medical device(s)/drug(s). This work was supported by the German Research Foundation (DFG) within the Collaborative Research Center (SFB) 1158 and by the German Federal Ministry of Education and Research (Bundesministerium fur Bildung und Forschung; PerPAIN consortium, FKZ:01 EC1904A). No benefits in any form have been or will be received from a commercial party directly or indirectly related to the subject of this manuscript.	Adunsky Abraham, 2007, Am J Hosp Palliat Care, V24, P493, DOI 10.1177/1049909107307374; Aguilera B, 2020, NEUROETHICS-NETH, V13, P337, DOI 10.1007/s12152-020-09430-y; Andaya E, 2021, SOC SCI MED, V269, DOI 10.1016/j.socscimed.2020.113558; Baines B K, 2000, Am J Hosp Palliat Care, V17, P319, DOI 10.1177/104990910001700509; Bellieni Carlo, 2005, Ethics Med, V21, P5; Belon HP, 2014, PHYS MED REH CLIN N, V25, P53, DOI 10.1016/j.pmr.2013.09.010; Best M, 2015, PALLIAT SUPPORT CARE, V13, P1335, DOI 10.1017/S1478951514001217; Best M, 2015, PSYCHO-ONCOLOGY, V24, P977, DOI 10.1002/pon.3795; Björkman B, 2017, SCAND J PAIN, V14, P100, DOI 10.1016/j.sjpain.2016.09.012; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BOISAUBIN EV, 1989, CLIN J PAIN, V5, pS19, DOI 10.1097/00002508-198906002-00004; Broggi G, 2008, NEUROSURGERY, V62, P901, DOI [10.1227/01.NEU.0000317337.51936.43, 10.1227/01.neu.0000333760.53748.9e]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brugnoli MP, 2016, ANN PALLIAT MED, V5, P280, DOI 10.21037/apm.2016.09.04; Büchi S, 1999, PSYCHOSOMATICS, V40, P314; Bueno-Gómez N, 2017, PHILOS ETHICS HUM ME, V12, DOI 10.1186/s13010-017-0049-5; Bustan S, 2015, EUR J PAIN, V19, P1035, DOI 10.1002/ejp.709; Candib LM, 2002, PATIENT EDUC COUNS, V48, P43, DOI 10.1016/S0738-3991(02)00098-8; Carney KB, 2019, PAIN MANAG NURS, V20, P482, DOI 10.1016/j.pmn.2019.06.001; CASSEL EJ, 1982, NEW ENGL J MED, V306, P639, DOI 10.1056/NEJM198203183061104; Chapman CR, 1999, LANCET, V353, P2233, DOI 10.1016/S0140-6736(99)01308-2; Charmaz K, 1983, Sociol Health Illn, V5, P168, DOI 10.1111/1467-9566.ep10491512; Cohen MA, 2018, PULL OF POLITICS, P1, DOI 10.1097/PR9.0000000000000634; Coulehan J, 2009, PERSPECT BIOL MED, V52, P585, DOI 10.1353/pbm.0.0130; Crombez G, 2009, PAIN, V145, P31, DOI 10.1016/j.pain.2009.04.006; DAMASIO AR, 2010, SELF COMES MIND CONS; de Boer ME, 2007, INT PSYCHOGERIATR, V19, P1021, DOI 10.1017/S1041610207005765; de Medeiros K, 2009, J AGING STUD, V23, P97, DOI 10.1016/j.jaging.2008.11.001; De Ridder D, 2021, NEUROSCI BIOBEHAV R, V130, P125, DOI 10.1016/j.neubiorev.2021.08.013; del Giglio A, 2020, MED HEALTH CARE PHIL, V23, P215, DOI 10.1007/s11019-019-09920-8; Devik SA, 2017, EUR J CANCER CARE, V26, DOI 10.1111/ecc.12609; Devisch I, 2017, MED HEALTH CARE PHIL, V20, P257, DOI 10.1007/s11019-016-9742-1; Dildy SP, 1996, APPL NURS RES, V9, P177, DOI 10.1016/S0897-1897(96)80043-7; Duggleby W, 2000, Oncol Nurs Forum, V27, P825; Dysvik E, 2014, J CLIN NURS, V23, P865, DOI 10.1111/jocn.12270; Edgar Andrew, 2007, Med Health Care Philos, V10, P395, DOI 10.1007/s11019-007-9082-2; Edwards Steven D, 2003, Med Health Care Philos, V6, P59, DOI 10.1023/A:1022537117643; Fishman B, 1992, Hosp J, V8, P73; FORDYCE WE, 1988, AM PSYCHOL, V43, P276, DOI 10.1037/0003-066X.43.4.276; Frank AW, 2001, QUAL HEALTH RES, V11, P353, DOI 10.1177/104973201129119154; Gallagher S, 2012, PHENOMENOLOGICAL MIND, 2ND EDITION, P1; Gessert Charles E, 2004, J Palliat Med, V7, P517, DOI 10.1089/1096621041838380; Glas G, 2012, PHILOS PSYCHIATR PSY, V19, P285; Gonzalez Baron M, 2006, Clin Transl Oncol, V8, P525; Gotti M., 2008, Investigating specialized discourse; Gran SV, 2010, INT J OLDER PEOPLE N, V5, P25, DOI 10.1111/j.1748-3743.2009.00195.x; Grau Jorge, 2009, MEDICC Rev, V11, P52, DOI 10.37757/MR2009V11.N3.11; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Gupta A., 2023, The stanford encyclopedia of philosophy; Gutiérrez-Sánchez D, 2020, INT J NURS STUD, V110, DOI 10.1016/j.ijnurstu.2020.103704; Jurafsky D., 2021, SPEECH LANGUAGE PROC; KAHN DL, 1986, J ADV NURS, V11, P623, DOI 10.1111/j.1365-2648.1986.tb03379.x; Kleinman A., 1992, Qualitative Health Research, V2, P127, DOI [DOI 10.1177/104973239200200202, 10.1177/104973239200200202]; Knotek P, 1998, STUD PSYCHOL, V40, P165; Krikorian A, 2012, J PALLIAT CARE, V28, P41, DOI 10.1177/082585971202800107; Kugelmann R, 2000, J Health Psychol, V5, P305, DOI 10.1177/135910530000500302; Lackner JM, 2005, BEHAV RES THER, V43, P943, DOI 10.1016/j.brat.2004.06.018; Lackner JM, 2005, EUR J PAIN, V9, P207, DOI 10.1016/j.ejpain.2004.06.002; Maslach, 1997, EVALUATING STRESS BO, P191, DOI DOI 10.1017/S0033291798257163; Masterson MP, 2018, PSYCHO-ONCOLOGY, V27, P2573, DOI 10.1002/pon.4821; Meeker MA, 2014, J PAIN SYMPTOM MANAG, V47, P887, DOI 10.1016/j.jpainsymman.2013.06.009; Monin JK, 2009, PSYCHOL AGING, V24, P681, DOI 10.1037/a0016355; Montoya-Juarez R, 2013, INT J NURS STUD, V50, P53, DOI 10.1016/j.ijnurstu.2012.08.016; Mount BM, 2007, J PAIN SYMPTOM MANAG, V33, P372, DOI 10.1016/j.jpainsymman.2006.09.014; Murata Hisayuki, 2006, Palliat Support Care, V4, P279; Niven Karen., 2020, Encyclopedia of Behavioral Medicine, P62; Nordenfelt L, 2013, HEALTH CARE ANAL, V21, P298, DOI 10.1007/s10728-013-0256-1; Olson ET., 2023, The Stanford Encyclopedia of Philosophy; OpenAI, 2023, ChatGPT (Jan 30 version) Large language model; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Phillips WR, 2023, J AM BOARD FAM MED, V36, P344, DOI 10.3122/jabfm.2022.220308R1; Pilkington FB, 2008, NURS SCI QUART, V21, P228, DOI 10.1177/0894318408319274; Pollock S E, 1997, Clin Nurs Res, V6, P171, DOI 10.1177/105477389700600206; Priya K.R., 2012, Psychological Studies, V57, P211, DOI DOI 10.1007/S12646-011-0143-5; Pullman D, 2002, THEOR MED BIOETH, V23, P75, DOI 10.1023/A:1019521923979; Quintner JL, 2008, PAIN MED, V9, P824, DOI 10.1111/j.1526-4637.2007.00391.x; Raja SN, 2020, PAIN, V161, pS14, DOI 10.1097/j.pain.0000000000001838; Rochat P, 2018, CURR DIR PSYCHOL SCI, V27, P345, DOI 10.1177/0963721418760236; Rodgers BL, 1997, J ADV NURS, V25, P1048, DOI 10.1046/j.1365-2648.1997.19970251048.x; Rosen G, 2015, ANAL PHILOS, V56, P189, DOI 10.1111/phib.12067; Roxberg Å, 2014, J RELIG HEALTH, V53, P1257, DOI 10.1007/s10943-013-9815-x; Sievert C., 2014, LDAvis: a method for visualizing and interpreting topics; Smith LW, 2014, J HOSP PALLIAT NURS, V16, P263, DOI 10.1097/NJH.0000000000000075; Streeck N, 2020, MED HEALTH CARE PHIL, V23, P343, DOI 10.1007/s11019-019-09921-7; Strong T., 1999, J Syst Ther, V18, P37; Sullivan MD, 2023, PAIN, V164, P271, DOI 10.1097/j.pain.0000000000002748; Svenaeus F, 2020, MED HEALTH CARE PHIL, V23, P335, DOI 10.1007/s11019-019-09914-6; Svenaeus F, 2014, THEOR MED BIOETH, V35, P407, DOI 10.1007/s11017-014-9315-3; Tate T, 2020, THEOR MED BIOETH, V41, P143, DOI 10.1007/s11017-020-09535-8; Tate T, 2019, PERSPECT BIOL MED, V62, P95, DOI 10.1353/pbm.2019.0005; Turk DC, 2009, CLIN J PAIN, V25, P353, DOI 10.1097/AJP.0b013e31819c62e7; van Hooft S, 1998, Med Health Care Philos, V1, P125, DOI 10.1023/A:1009923104175; Wade JB, 2011, PAIN, V152, P314, DOI 10.1016/j.pain.2010.10.034; WADE JB, 1992, PAIN, V51, P67, DOI 10.1016/0304-3959(92)90010-9; Wade JB, 2002, PAIN MED, V3, P30, DOI 10.1046/j.1526-4637.2002.02008.x; Wilson KG, 2007, J CLIN ONCOL, V25, P1691, DOI 10.1200/JCO.2006.08.6801; Xu JX, 1998, ACM T INFORM SYST, V16, P61, DOI 10.1145/267954.267957; Yager J, 2021, J NERV MENT DIS, V209, P615, DOI 10.1097/NMD.0000000000001348; Zwijsen SA, 2016, INT PSYCHOGERIATR, V28, P1067, DOI 10.1017/S1041610216000351	99	1	1	1	1	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0304-3959	1872-6623		PAIN	Pain	JUL	2024	165	7					1434	1449		10.1097/j.pain.0000000000003195	http://dx.doi.org/10.1097/j.pain.0000000000003195			16	Anesthesiology; Clinical Neurology; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology; Neurosciences & Neurology	UX7N8	38452202	hybrid			2024-07-03	WOS:001251430500002
J	Rubin, CN				Rubin, Carlos N.			AI IN TODAY BUSINESS ADMINISTRATION	CUADERNOS DEL CIMBAGE			Spanish	Article						AI; Accounting; Business Administration; Business Economics		Companies are experiencing a digital transformation, which places technology at the center of their strategies and promotes the digitalization and automation of processes. Artificial Intelligence (AI) has become essential to create smarter products and services and make organizations increasingly competitive, increasing operational efficiency and reducing costs by automating repetitive tasks and optimizing processes. AI is transforming the world as we conceived it until now, creating a future that will impact human society in ways we could only imagine before. Within a business organization, AI constitutes a new intangible asset that generates added value in each component of its structure. This work deals exclusively with AI applied to the business organization and will not describe the internal mechanisms of AI, such as neural networks (NN), generative networks (GN), massive data (Big Data), machine learning (Machine Learning), transformer architectures (TA), Large Language Models (LLM), etc. The basic concepts of AI and its state of the art are described. The impact of AI on a business organization is surveyed, without conditioning its size, sector, type or activity. For this, the structure of strategic maps, by Kaplan and Norton, is used, describing for each component its function in the map and the impact that AI has. A list is presented with 45 world -leading companies, according to the HAI (Human -Centered AI), of Stanford University, in its 2022 annual report. Likewise, a list is presented with 10 Argentine companies, leaders in AI, that today are recognized by the Chat GPT tool. At the end of the work, future projections of AI are briefly discussed.	[Rubin, Carlos N.] Univ Buenos Aires, Fac Ciencias Econ, CIMBAGE Inst Invest Adm Contabilidad & Metodos Cua, Av Cordoba 2122,2 Piso,C1120AAQ, Caba, Argentina	University of Buenos Aires	Rubin, CN (corresponding author), Univ Buenos Aires, Fac Ciencias Econ, CIMBAGE Inst Invest Adm Contabilidad & Metodos Cua, Av Cordoba 2122,2 Piso,C1120AAQ, Caba, Argentina.	cxrubin@gmail.com						[Anonymous], 2007, The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future; Hernandez-Orallo J., 2017, The measure of all minds: evaluating natural and artificial intelligence; Kaplan R.S., 2004, STRATEGY MAPS CONVER; Lee K.F., 2024, AI 2041. Ten Visions for Our Future; Lee K.F., 2021, AI Superpowers: China, Silicon Valley, and the New World Order; Leslie D, 2019, NATURE, V574, P32, DOI 10.1038/d41586-019-02939-0; Lopez J. M. Molina, 2005, Desarrollo de Sistemas Basados en el Conocimiento; Minsky M., 1986, The Society of Mind; Moravec Hans., 1988, Mind Children: The Future of Robot and Human Intelligence; Rubin C.N., 2013, Tesis de Maestria en Administracion de Negocios; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003	11	0	0	0	0	UNIV BUENOS AIRES, CENT INVEST & METODOLOGIA BORRASA APL GESTION & ECON	BUENOS AIRES	AVE CORDOBA 2122 PISO 2, BUENOS AIRES, 1120, ARGENTINA	1666-5112	1669-1830		CUAD CIMBAGE	Cuad. CIMBAGE		2024	26	1					61	76						16	Social Sciences, Mathematical Methods	Emerging Sources Citation Index (ESCI)	Mathematical Methods In Social Sciences	UD4F9					2024-07-03	WOS:001246104100004
J	Thirunavukarasu, AJ; Elangovan, K; Gutierrez, L; Li, Y; Tan, I; Keane, PA; Korot, E; Ting, DSW				Thirunavukarasu, Arun James; Elangovan, Kabilan; Gutierrez, Laura; Li, Yong; Tan, Iris; Keane, Pearse A.; Korot, Edward; Ting, Daniel Shu Wei			Democratizing Artificial Intelligence Imaging Analysis With Automated Machine Learning: Tutorial	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						machine learning; automated machine learning; autoML; artificial intelligence; democratization; autonomous AI; imaging; image analysis; automation; AI engineering	HEALTH-CARE PROFESSIONALS; MODELS	Deep learning-based clinical imaging analysis underlies diagnostic artificial intelligence (AI) models, which can match or even exceed the performance of clinical experts, having the potential to revolutionize clinical practice. A wide variety of automated machine learning (autoML) platforms lower the technical barrier to entry to deep learning, extending AI capabilities to clinicians with limited technical expertise, and even autonomous foundation models such as multimodal large language models. Here, we provide a technical overview of autoML with descriptions of how autoML may be applied in education, research, and clinical practice. Each stage of the process of conducting an autoML project is outlined, with an emphasis on ethical and technical best practices. Specifically, data acquisition, data partitioning, model training, model validation, analysis, and model deployment are considered. The strengths and limitations of available code-free, code-minimal, and code-intensive autoML platforms are considered. AutoML has great potential to democratize AI in medicine, improving AI literacy by enabling "hands-on" education. AutoML may serve as a useful adjunct in research by facilitating rapid testing and benchmarking before significant computational resources are committed. AutoML may also be applied in clinical contexts, provided regulatory requirements are met. The abstraction by autoML of arduous aspects of AI engineering promotes prioritization of data set curation, supporting the transition from conventional model-driven approaches to data-centric development. To fulfill its potential, clinicians must be educated on how to apply these technologies ethically, rigorously, and effectively; this tutorial represents a comprehensive summary of relevant considerations.	[Thirunavukarasu, Arun James] Univ Cambridge, Sch Clin Med, Cambridge, England; [Thirunavukarasu, Arun James; Elangovan, Kabilan; Gutierrez, Laura; Li, Yong; Tan, Iris; Ting, Daniel Shu Wei] Singapore Eye Res Inst, Artificial Intelligence & Digital Innovat Res Grp, Singapore, Singapore; [Keane, Pearse A.] Moorfields Eye Hosp NHS Fdn Trust, London, England; [Korot, Edward; Ting, Daniel Shu Wei] Stanford Univ, Byers Eye Inst, Palo Alto, CA USA; [Korot, Edward] Retina Specialists Michigan, Grand Rapids, MI USA; [Ting, Daniel Shu Wei] Singapore Natl Eye Ctr, Singapore, Singapore; [Thirunavukarasu, Arun James] Univ Cambridge, Addenbrookes Hosp, Sch Clin Med, Hills Rd, Cambridge CB2 0SP, England	University of Cambridge; Singapore National Eye Center; National University of Singapore; University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; Stanford University; Singapore National Eye Center; University of Cambridge; Cambridge University Hospitals NHS Foundation Trust; Addenbrooke's Hospital	Thirunavukarasu, AJ (corresponding author), Univ Cambridge, Addenbrookes Hosp, Sch Clin Med, Hills Rd, Cambridge CB2 0SP, England.	ajt205@cantab.ac.uk	Keane, Pearse/AAE-5709-2019; Thirunavukarasu, Arun/ABC-0806-2022	Keane, Pearse/0000-0002-9239-745X; Korot, Edward/0000-0002-5687-1564; Gutierrez-Sinisterra, Laura/0000-0001-7416-2350; Elangovan, Kabilan/0000-0002-7711-7368; Ting, Daniel Shu Wei/0000-0003-2264-7174; Li, Yong/0000-0002-8949-8612; Thirunavukarasu, Arun/0000-0001-8968-4768	Royal College of Surgeons in Edinburgh (RCSED Bursary 2022); Royal College of Physicians (MSEB 2022); Corpus Christi College, University of Cambridge (Gordon Award) [MOH-000655-00]; National Medical Research Council, Singapore [MOH-001014-00, Duke-NUS/RSF/2021/0018, 05/FY2020/EX/15-A58]; Duke-NUS Medical School [A20H4g2141, H20C6a0032]; Agency for Science, Technology and Research;  [1083874682];  [NMCR/HSRG/0087/2018]	Royal College of Surgeons in Edinburgh (RCSED Bursary 2022); Royal College of Physicians (MSEB 2022); Corpus Christi College, University of Cambridge (Gordon Award); National Medical Research Council, Singapore(National Medical Research Council, SingaporeUK Research & Innovation (UKRI)Medical Research Council UK (MRC)); Duke-NUS Medical School; Agency for Science, Technology and Research(Agency for Science Technology & Research (A*STAR)); ; 	The authors extend their thanks to Timing Liu for his insights into automated machine learning and artificial intelligence more broadly. AJT is supported by The Royal College of Surgeons in Edinburgh (RCSED Bursary 2022) , the Royal College of Physicians (MSEB 2022) , and Corpus Christi College, University of Cambridge (Gordon Award 1083874682) . DSWT is supported by the National Medical Research Council, Singapore (NMCR/HSRG/0087/2018; MOH-000655-00; MOH-001014-00) ; Duke-NUS Medical School (Duke-NUS/RSF/2021/0018; 05/FY2020/EX/15-A58) ; and Agency for Science, Technology and Research (A20H4g2141; H20C6a0032) . These funders were not involved in the conception, execution, or reporting of this study.	Abbas A, 2022, GRAEF ARCH CLIN EXP, V260, P2461, DOI 10.1007/s00417-021-05544-y; Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; [Anonymous], 2022, Artificial intelligence and machine learning in software as a medical device; Auffray C, 2016, GENOME MED, V8, DOI 10.1186/s13073-016-0323-y; Bash S, 2022, CLIN NEURORADIOL, V32, P197, DOI 10.1007/s00062-021-01121-2; Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391; Chang EY, 2022, Arxiv, DOI [arXiv:2212.13591, DOI 10.48550/ARXIV.2212.13591, 10.48550/arXiv.2212.13591]; Collins GS, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-40; Drozdal J, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P297, DOI 10.1145/3377325.3377501; Erickson BJ, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200126; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Faes L, 2019, LANCET DIGIT HEALTH, V1, pE232, DOI 10.1016/S2589-7500(19)30108-6; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Jain A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3561, DOI 10.1145/3394486.3406477; Keane PA, 2021, LANCET, V397, P1254, DOI 10.1016/S0140-6736(21)00722-4; Khan SM, 2021, LANCET DIGIT HEALTH, V3, pE51, DOI 10.1016/S2589-7500(20)30240-5; Korot E, 2021, CURR OPIN OPHTHALMOL, V32, P445, DOI 10.1097/ICU.0000000000000785; Korot E, 2021, NAT MACH INTELL, V3, P288, DOI 10.1038/s42256-021-00305-2; Krause J, 2018, OPHTHALMOLOGY, V125, P1264, DOI 10.1016/j.ophtha.2018.01.034; Kuehn BM, 2013, JAMA-J AM MED ASSOC, V310, P1781, DOI 10.1001/jama.2013.280660; Kwon JM, 2018, J AM HEART ASSOC, V7, DOI 10.1161/JAHA.118.008678; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Mahmud MS, 2020, BIG DATA MIN ANAL, V3, P85, DOI 10.26599/BDMA.2019.9020015; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689; Parker-Holder J, 2022, J ARTIF INTELL RES, V74, P517, DOI 10.1613/jair.1.13596; Poulakis Y, 2020, IEEE DATA MINING, P1220, DOI 10.1109/ICDM50108.2020.00153; Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7; Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]; Shen ZQ, 2024, Arxiv, DOI [arXiv:1810.13306, DOI 10.48550/ARXIV.1810.13306]; Tan TF, 2023, LANCET GLOB HEALTH, V11, P1432, DOI 10.1016/S2214-109X(23)00323-6; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173; van der Velden BHM, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102470; Varoquaux G, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00592-y; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]; Wen D, 2022, LANCET DIGIT HEALTH, V4, pE64, DOI 10.1016/S2589-7500(21)00252-1; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Wolff RF, 2019, ANN INTERN MED, V170, P51, DOI 10.7326/M18-1376; Xie Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376807; Xie YC, 2020, LANCET DIGIT HEALTH, V2, pE240, DOI 10.1016/S2589-7500(20)30060-1; Xu J, 2019, THERANOSTICS, V9, P7556, DOI 10.7150/thno.38065; Ying X, 2019, J PHYS CONF SER, V1168, DOI 10.1088/1742-6596/1168/2/022022; Yuvali M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030311	47	4	4	6	8	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	OCT 12	2023	25								e49949	10.2196/49949	http://dx.doi.org/10.2196/49949			11	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	W5QR7	37824185	Green Published, Green Submitted, gold			2024-07-03	WOS:001092176300007
C	Ghannane, Y; Abdelfattah, MS			IEEE	Ghannane, Yassine; Abdelfattah, Mohamed S.			DiviML: A Module-based Heuristic for Mapping Neural Networks onto Heterogeneous Platforms	2023 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD	ICCAD-IEEE ACM International Conference on Computer-Aided Design		English	Proceedings Paper	42nd IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	OCT 28-NOV 02, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, Cadence, Synopsys, Futurewei Technologies, AMD, EMPYREAN, DoraHacks, Singular Med, JP Morgan Chase & Co				Datacenters are increasingly becoming heterogeneous, and are starting to include specialized hardware for networking, video processing, and especially deep learning. To leverage the heterogeneous compute capability of modern datacenters, we develop an approach for compiler-level partitioning of deep neural networks (DNNs) onto multiple interconnected hardware devices. We present a general framework for heterogeneous DNN compilation, offering automatic partitioning and device mapping. Our scheduler integrates both an exact solver, through a mixed integer linear programming (MILP) formulation, and a modularity-based heuristic for scalability. Furthermore, we propose a theoretical lower bound formula for the optimal solution, which enables the assessment of the heuristic solutions' quality. We evaluate our scheduler in optimizing both conventional DNNs and randomly-wired neural networks, subject to latency and throughput constraints, on a heterogeneous system comprised of a CPU and two distinct GPUs. Compared to naively running DNNs on the fastest GPU, the proposed framework can achieve more than 3x lower latency and up to 2.9x higher throughput by automatically leveraging both data and model parallelism to deploy DNNs on our sample heterogeneous server node. Moreover, our modularity-based "splitting" heuristic improves the solution runtime up to 395x without noticeably sacrificing solution quality compared to an exact MILP solution, and outperforms all other heuristics by 30-60% solution quality. Finally, our case study shows how we can extend our framework to schedule large language models across multiple heterogeneous servers by exploiting symmetry in the hardware setup. Our code can be easily plugged in to existing frameworks, and is available at https://github.com/abdelfattah-lab/diviml.	[Ghannane, Yassine; Abdelfattah, Mohamed S.] Cornell Univ, Elect & Comp Engn, New York, NY 10021 USA	Cornell University	Ghannane, Y (corresponding author), Cornell Univ, Elect & Comp Engn, New York, NY 10021 USA.	yg496@cornell.edu; mohamed@cornell.edu	Abdelfattah, Mohamed S./U-1337-2019	Abdelfattah, Mohamed S./0000-0002-4568-8932	TATA Consultancy Services (TCS)	TATA Consultancy Services (TCS)	Thanks to TATA Consultancy Services (TCS) for funding support, and Dr. Rekha Singal for insightful discussion and feedback.	Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077; Ahn B.H, 2020, MLSys, V2; Ahn ByungHoon., 2020, MLSys, P44; Ahn ByungHoon., 2019, ICCV, P44; [Anonymous], 2013, SIGMOD; Borisovsky PavelA., 2002, FOGA; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai H., 2019, ICLR, P1, DOI DOI 10.48550/ARXIV.1812.00332; Carson T, 2001, SIAM PROC S, P903; Caulfield AM, 2016, INT SYMP MICROARCH; Celik E, 2021, CLUSTER COMPUT, V24, P2927, DOI 10.1007/s10586-021-03275-7; Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579; Chen XB, 2019, LECT NOTES COMPUT SC, V11719, P55, DOI 10.1007/978-3-030-29611-7_5; Cococcioni M, 2021, OPTIM LETT, V15, P2455, DOI 10.1007/s11590-020-01644-6; Davidovic T., 2005, Mathematical programming-based approach to scheduling of communicating tasks; Droste S, 2002, THEOR COMPUT SCI, V276, P51, DOI 10.1016/S0304-3975(01)00182-7; Dubey K, 2018, PROCEDIA COMPUT SCI, V125, P725, DOI 10.1016/j.procs.2017.12.093; Dudziak l., 2020, ADV NEUR IN; Gallo C., 2019, Journal of Applied Mathematics and Physics, V7; Grosser Tobias., 2016, ICS; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Kashani M. H., 2009, Proceedings of the 2009 First International Conference on Computational Intelligence, Modelling and Simulation. CSSim 2009 Information Getting Started, P265, DOI 10.1109/CSSim.2009.36; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kumar R, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P81; Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICRO.2018.00059, 10.1109/MICR0.2018.00059]; Liu P., 2021, ACDA; Luk W, 2009, IEEE INT SOC CONF, P9, DOI 10.1109/SOCCON.2009.5398108; Meng Y., 2021, 2021 ACMSIGDA INT S, P183, DOI 10.1145/3431920.3439286; Paszke A, 2019, ADV NEUR IN, V32; Pinedo M., 2008, Scheduling; Purdom Paul, 1970, BIT Numer. Math., V10, P76, DOI DOI 10.1007/BF01940892; Qararyah F, 2021, PARALLEL COMPUT, V104, DOI 10.1016/j.parco.2021.102792; Reed J. K., 2021, arXiv; Sima V.-M., 2009, ISPA, P1; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]; Vaswani A, 2017, ADV NEUR IN, V30; Zheng LM, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P559; Zoph B., 2016, ARXIV161101578	40	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1933-7760		979-8-3503-2225-5	ICCAD-IEEE ACM INT			2023										10.1109/ICCAD57390.2023.10323712	http://dx.doi.org/10.1109/ICCAD57390.2023.10323712			9	Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2HI		Green Submitted			2024-07-03	WOS:001116715100060
J	Van Ostaeyen, S; De Langhe, L; De Clercq, O; Embo, M; Schellens, T; Valcke, M				Van Ostaeyen, Sofie; De Langhe, Loic; De Clercq, Orphee; Embo, Mieke; Schellens, Tammy; Valcke, Martin			Automating the Identification of Feedback Quality Criteria and the CanMEDS Roles in Written Feedback Comments Using Natural Language Processing	PERSPECTIVES ON MEDICAL EDUCATION			English	Article							MEDICAL-EDUCATION	Introduction: Manually analysing the quality of large amounts of written feedback comments is time-consuming and demands extensive resources and human effort. Therefore, this study aimed to explore whether a state-of-the-art large language model (LLM) could be fine-tuned to identify the presence of four literature-derived feedback quality criteria (performance, judgment, elaboration and improvement) and the seven CanMEDS roles (Medical Expert, Communicator, Collaborator, Leader, Health Advocate, Scholar and Professional) in written feedback comments. Methods: A set of 2,349 labelled feedback comments of five healthcare educational programs in Flanders (Belgium) (specialistic medicine, general practice, midwifery, speech therapy and occupational therapy) was split into 12,452 sentences to create two datasets for the machine learning analysis. The Dutch BERT models BERTje and RobBERT were used to train four multiclass-multilabel classification models: two to identify the four feedback quality criteria and two to identify the seven CanMEDS roles. Results: The classification models trained with BERTje and RobBERT to predict the presence of the four feedback quality criteria attained macro average F1-scores of 0.73 and 0.76, respectively. The F1-score of the model predicting the presence of the CanMEDS roles trained with BERTje was 0.71 and 0.72 with RobBERT. Discussion: The results showed that a state-of-the-art LLM is able to identify the presence of the four feedback quality criteria and the CanMEDS roles in written feedback comments. This implies that the quality analysis of written feedback comments can be automated using an LLM, leading to savings of time and resources.	[Van Ostaeyen, Sofie; Embo, Mieke; Schellens, Tammy; Valcke, Martin] Univ Ghent, Dept Educ Sci, Ghent, Belgium; [De Langhe, Loic; De Clercq, Orphee] Univ Ghent, Language & Translat Technol Team, Ghent, Belgium; [Embo, Mieke] Artevelde Univ Appl Sci, Expertise Network Hlth & Care, Ghent, Belgium	Ghent University; Ghent University; Artevelde University of Applied Sciences	Van Ostaeyen, S (corresponding author), Univ Ghent, Fac Psychol & Educ Sci, Dept Educ Studies, Henri Dunantlaan 2, B-9000 Ghent, Belgium.	Sofie.VanOstaeyen@UGent.be	; Valcke, Martin/H-6693-2012	Embo, Mieke/0000-0002-2915-6987; schellens, tammy/0000-0002-3615-7347; Valcke, Martin/0000-0001-9544-4197; De Langhe, Loic/0000-0001-6844-1070; Van Ostaeyen, Sofie/0000-0003-4435-1462	Research Foundation Flanders (FWO, Strategic Basic Research (SBO)) [S003219N]	Research Foundation Flanders (FWO, Strategic Basic Research (SBO))	This work was supported by Research Foundation Flanders (FWO, Strategic Basic Research (SBO) under Grant S003219N.	Bing-You R, 2018, ACAD MED, V93, P657, DOI 10.1097/ACM.0000000000001927; Bleasel J, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0801-3; Canavan C, 2010, ACAD MED, V85, pS106, DOI 10.1097/ACM.0b013e3181ed4cdb; Carraccio C, 2002, ACAD MED, V77, P361, DOI 10.1097/00001888-200205000-00003; Christiansen B, 2021, NURS OPEN, V8, P1069, DOI 10.1002/nop2.717; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cook DA, 2015, MED EDUC, V49, P560, DOI 10.1111/medu.12678; Day LB, 2020, ACAD MED, V95, P1712, DOI 10.1097/ACM.0000000000003315; de Vries W, 2019, Arxiv, DOI arXiv:1912.09582; Delobelle P., 2020, Findings of the Association for Computational Linguistics: EMNLP, V2020, P3255, DOI [DOI 10.18653/V1/2020.FINDINGS-EMNLP.292, https://doi.org/10.18653/v1/2020.findings-emnlp.292]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Frank JR, 2010, MED TEACH, V32, P638, DOI 10.3109/0142159X.2010.501190; Frank JR, 2011, Educational design a CanMEDS guide for the health professions, P17; Fu RH, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-024425; Ginsburg S, 2016, PhD thesis., DOI [10.26481/dis.20160901sg, DOI 10.26481/DIS.20160901SG]; Ginsburg S, 2021, ACAD MED, V96, pS81, DOI 10.1097/ACM.0000000000004089; Ginsburg S, 2020, ACAD MED, V95, P1082, DOI 10.1097/ACM.0000000000003047; Ginsburg S, 2017, ACAD MED, V92, P1617, DOI 10.1097/ACM.0000000000001669; Ginsburg S, 2016, ADV HEALTH SCI EDUC, V21, P175, DOI 10.1007/s10459-015-9622-0; Ginsburg S, 2015, MED EDUC, V49, P296, DOI 10.1111/medu.12637; Gulbas L, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0660-y; Jackson JL, 2015, J GEN INTERN MED, V30, P973, DOI 10.1007/s11606-015-3237-2; Janssens O, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03308-8; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Lefebvre C, 2020, EVAL HEALTH PROF, V43, P159, DOI 10.1177/0163278718820415; Lefroy J, 2015, PERSPECT MED EDUC, V4, P284, DOI 10.1007/s40037-015-0231-7; Ludwig S., 2021, Psych, V3, P897, DOI 10.3390/psych3040056; Marcotte Laura, 2019, Can Med Educ J, V10, pe32; Meriam-Webster, Artificial intelligence; Mooney CJ, 2022, MED EDUC, V56, P1223, DOI 10.1111/medu.14911; Neves SE, 2021, ANESTH ANALG, V132, P545, DOI 10.1213/ANE.0000000000005265; Nousiainen MT, 2017, MED TEACH, V39, P594, DOI 10.1080/0142159X.2017.1315077; Nugraheny Esti, 2016, Iran J Nurs Midwifery Res, V21, P628, DOI 10.4103/1735-9066.197671; OpenAI, ChatGPT: optimizing language models for dialogue; Osakwe Ikenna, 2022, Computers and Education: Artificial Intelligence, V3, DOI [10.1016/j.caeai.2022.100059, DOI 10.1016/J.CAEAI.2022.100059]; Ötles E, 2021, ACAD MED, V96, P1457, DOI 10.1097/ACM.0000000000004153; Polignano M, 2019, P 6 ITALIAN C COMPUT; Raaum SE, 2019, J GEN INTERN MED, V34, P929, DOI 10.1007/s11606-019-04946-3; Sirianni G, 2020, MED TEACH, V42, P909, DOI 10.1080/0142159X.2020.1763285; Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015; Solano QP, 2021, J SURG EDUC, V78, pE72, DOI 10.1016/j.jsurg.2021.05.012; The Royal College of Physicians and Surgeons of Canada, CanMEDS framework, DOI [10.1177/001316446002000104, DOI 10.1177/001316446002000104]; Tomiak A, 2020, J CANCER EDUC, V35, P165, DOI 10.1007/s13187-018-1456-z; unstall L, 2022, Natural Language Processing with Transformers; Van Melle E, 2019, ACAD MED, V94, P1002, DOI 10.1097/ACM.0000000000002743; Van Ostaeyen S, A Qualitative Textual Analysis of Feedback Comments in ePortfolios: Quality and Alignment with the CanMEDS Roles; Veltman A., 2017, NIPS 17 P 31 INT C N, V30, P47; Warren AE, 2014, MED TEACH, V36, P390, DOI 10.3109/0142159X.2014.890281; Whitehead CR, 2013, ADV HEALTH SCI EDUC, V18, P687, DOI 10.1007/s10459-012-9409-5; Yilmaz Y, 2022, JMIR MED EDUC, V8, DOI 10.2196/30537	50	0	0	6	6	UBIQUITY PRESS LTD	LONDON	Unit 3N, 6 Osborn Street, LONDON, E1 6TD, ENGLAND	2212-2761	2212-277X		PERSPECT MED EDUC	Perspect. Med. Educ.		2023	12	1					540	549		10.5334/pme.1056	http://dx.doi.org/10.5334/pme.1056			10	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	JL5A8	38144670	Green Published, gold			2024-07-03	WOS:001173324400018
J	Zhang, X; Wang, HY; Sun, CY				Zhang, Xin; Wang, Huiyu; Sun, Chunyun			BiSpec Pairwise AI: guiding the selection of bispecific antibody target combinations with pairwise learning and GPT augmentation	JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY			English	Article						Bispecific antibody; Target combination; Machine learning; Pairwise learning; GPT		Purpose Bispecific antibodies (BsAbs), capable of targeting two antigens simultaneously, represent a significant advancement by employing dual mechanisms of action for tumor suppression. However, how to pair targets to develop effective and safe bispecific drugs is a major challenge for pharmaceutical companies.Methods Using machine learning models, we refined the biological characteristics of currently approved or in clinical development BsAbs and analyzed hundreds of membrane proteins as bispecific targets to predict the likelihood of successful drug development for various target combinations. Moreover, to enhance the interpretability of prediction results in bispecific target combination, we combined machine learning models with Large Language Models (LLMs). Through a Retrieval-Augmented Generation (RAG) approach, we supplement each pair of bispecific targets' machine learning prediction with important features and rationales, generating interpretable analytical reports.Results In this study, the XGBoost model with pairwise learning was employed to predict the druggability of BsAbs. By analyzing extensive data on BsAbs and designing features from perspectives such as target activity, safety, cell type specificity, pathway mechanism, and gene embedding representation, our model is able to predict target combinations of BsAbs with high market potential. Specifically, we integrated XGBoost with the GPT model to discuss the efficacy of each bispecific target pair, thereby aiding the decision-making for drug developers.Conclusion The novelty of this study lies in the integration of machine learning and GPT techniques to provide a novel framework for the design of BsAbs drugs. This holistic approach not only improves prediction accuracy, but also enhances the interpretability and innovativeness of drug design.	[Zhang, Xin; Wang, Huiyu; Sun, Chunyun] Sinocelltech Ltd, Beijing Engn Res Ctr Prot & Antibody, Beijing 100176, Peoples R China; [Zhang, Xin] Nankai Univ, Sch Med, Tianjin 300071, Peoples R China	Nankai University	Sun, CY (corresponding author), Sinocelltech Ltd, Beijing Engn Res Ctr Prot & Antibody, Beijing 100176, Peoples R China.	xin_zhang4@sinocelltech.com; huiyu_wang@sinocelltech.com; chunyun_sun@sinocelltech.com	zhang, xin/GQA-5010-2022	zhang, xin/0000-0002-0140-5910				Abanades B, 2022, BIOINFORMATICS, V38, P1877, DOI 10.1093/bioinformatics/btac016; Baker JJ, 2019, ANAL CHEM, V91, P965, DOI 10.1021/acs.analchem.8b04071; Chen QJ, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad557; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chon K, 2023, CLIN CANCER RES, V29, P3262, DOI 10.1158/1078-0432.CCR-22-3713; Du JC, 2019, BMC GENOMICS, V20, DOI 10.1186/s12864-018-5370-x; Fonseca A, 2024, BIODATA MIN, V17, DOI 10.1186/s13040-024-00354-4; Froning KJ, 2017, PROTEIN SCI, V26, P2021, DOI 10.1002/pro.3240; Froning K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16231-7; Graves J, 2020, ANTIBODIES, V9, DOI 10.3390/antib9020012; Keam SJ, 2022, DRUGS, V82, P1333, DOI 10.1007/s40265-022-01761-9; Kim N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16164-1; Kruser TJ, 2010, EXP CELL RES, V316, P1083, DOI 10.1016/j.yexcr.2010.01.009; Kürten CHL, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27619-4; Leto SM, 2015, CLIN CANCER RES, V21, P5519, DOI 10.1158/1078-0432.CCR-14-3066; Li L, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-39022-2; Liberis E, 2018, BIOINFORMATICS, V34, P2944, DOI 10.1093/bioinformatics/bty305; Liu ZC, 2021, DRUG DISCOV TODAY, V26, P2593, DOI 10.1016/j.drudis.2021.06.009; Manavalan B, 2018, FRONT IMMUNOL, V9, DOI 10.3389/fimmu.2018.01695; Marks C, 2021, BIOINFORMATICS, V37, P4041, DOI 10.1093/bioinformatics/btab434; Myung Y, 2020, NUCLEIC ACIDS RES, V48, pW125, DOI 10.1093/nar/gkaa389; Obradovic A, 2023, SCIENCE, V379, P654, DOI 10.1126/science.adg5585; Ren QQ, 2020, CANCER CELL INT, V20, DOI 10.1186/s12935-020-01173-3; Sharma A, 2020, CELL, V183, P377, DOI 10.1016/j.cell.2020.08.040; Shirley M, 2023, DRUGS, V83, P935, DOI 10.1007/s40265-023-01894-5; Su ZQ, 2024, BIOPHYS J, V123, P235, DOI 10.1016/j.bpj.2023.12.012; Syed YY, 2021, DRUGS, V81, P1349, DOI 10.1007/s40265-021-01561-7; Teige I, 2019, FRONT IMMUNOL, V10, DOI 10.3389/fimmu.2019.00481; Thakur A, 2018, BLOOD REV, V32, P339, DOI 10.1016/j.blre.2018.02.004; Vallejos CA, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-0930-3; van de Sande B, 2023, NAT REV DRUG DISCOV, V22, P496, DOI 10.1038/s41573-023-00688-4; Vyse S, 2022, EXPERT REV ANTICANC, V22, P3, DOI 10.1080/14737140.2022.2016397; Werba G, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-36296-4; Yang F, 2022, NAT MACH INTELL, V4, P852, DOI 10.1038/s42256-022-00534-z; Yuan MQ, 2022, J VIROL, V96, DOI 10.1128/jvi.00775-22; Zhang XQ, 2020, CANCER CELL INT, V20, DOI 10.1186/s12935-020-1155-9; Zhao YY, 2023, ECLINICALMEDICINE, V62, DOI 10.1016/j.eclinm.2023.102106; Zhou CC, 2023, NEW ENGL J MED, V389, P2039, DOI 10.1056/NEJMoa2306441; Zhou KX, 2023, FRONT IMMUNOL, V14, DOI 10.3389/fimmu.2023.1127071	39	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0171-5216	1432-1335		J CANCER RES CLIN	J. Cancer Res. Clin. Oncol.	MAY 7	2024	150	5							237	10.1007/s00432-024-05740-3	http://dx.doi.org/10.1007/s00432-024-05740-3			15	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	PQ8X5	38713378	hybrid			2024-07-03	WOS:001215651400001
J	Menz, BD; Modi, ND; Sorich, MJ; Hopkins, AM				Menz, Bradley D.; Modi, Natansh D.; Sorich, Michael J.; Hopkins, Ashley M.			Health Disinformation Use Case Highlighting the Urgent Need for Artificial Intelligence Vigilance Weapons of Mass Disinformation	JAMA INTERNAL MEDICINE			English	Review								Importance Although artificial intelligence (AI) offers many promises across modern medicine, it may carry a significant risk for the mass generation of targeted health disinformation. This poses an urgent threat toward public health initiatives and calls for rapid attention by health care professionals, AI developers, and regulators to ensure public safety.Observations As an example, using a single publicly available large-language model, within 65 minutes, 102 distinct blog articles were generated that contained more than 17 000 words of disinformation related to vaccines and vaping. Each post was coercive and targeted at diverse societal groups, including young adults, young parents, older persons, pregnant people, and those with chronic health conditions. The blogs included fake patient and clinician testimonials and obeyed prompting for the inclusion of scientific-looking referencing. Additional generative AI tools created an accompanying 20 realistic images in less than 2 minutes. This process was undertaken by health care professionals and researchers with no specialized knowledge in bypassing AI guardrails, relying solely on publicly available information.Conclusions and Relevance These observations demonstrate that when the guardrails of AI tools are insufficient, the ability to rapidly generate diverse and large amounts of convincing disinformation is profound. Beyond providing 2 example scenarios, these findings demonstrate an urgent need for robust AI vigilance. The AI tools are rapidly progressing; alongside these advancements, emergent risks are becoming increasingly apparent. Key pillars of pharmacovigilance-including transparency, surveillance, and regulation-may serve as valuable examples for managing these risks and safeguarding public health.	[Menz, Bradley D.; Modi, Natansh D.; Sorich, Michael J.; Hopkins, Ashley M.] Flinders Univ S Australia, Coll Med & Publ Hlth, Discipline Clin Pharmacol, Adelaide, SA, Australia	Flinders University South Australia	Hopkins, AM (corresponding author), Flinders Univ S Australia, Coll Med & Publ Hlth, Adelaide, SA 5042, Australia.	ashley.hopkins@flinders.edu.au	Sorich, Michael/A-1210-2011	Sorich, Michael/0000-0003-1999-866X; Modi, Natansh/0000-0003-3262-5374; Menz, Bradley/0000-0002-0855-5081					0	12	12	15	21	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6106	2168-6114		JAMA INTERN MED	JAMA Intern. Med.	JAN	2024	184	1					92	96		10.1001/jamainternmed.2023.5947	http://dx.doi.org/10.1001/jamainternmed.2023.5947		NOV 2023	5	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	ED8H3	37955873				2024-07-03	WOS:001137066600035
J	Ruff, EF; Engen, MA; Franz, JL; Mauser, JF; West, JK; Zemke, JMO				Ruff, Emily F.; Engen, Mark A.; Franz, Jeanne L.; Mauser, Jonathon F.; West, Joseph K.; Zemke, Jennifer M. O.			ChatGPT Writing Assistance and Evaluation Assignments Across the Chemistry Curriculum	JOURNAL OF CHEMICAL EDUCATION			English	Article						First-Year Undergraduate; Second-Year Undergraduate; Upper-Division Undergraduate; Analytical Chemistry; Biochemistry; Inorganic Chemistry; Communication/Writing; Enrichment/Review Materials; Internet/Web-Based Learning	SKILLS	Large language models (LLMs) such as ChatGPT have recently been challenging traditional models of higher education. Given the growing use of these tools for writing, research, and content retrieval tasks, it is imperative that both students and faculty understand their capabilities and shortcomings. Here we describe assignments in which lower- and upper-division students evaluated chemistry writing samples generated and revised by ChatGPT version 3.5 and used this program for revision and other writing tasks. General Chemistry students who evaluated AI-generated content showed strong gains in their knowledge about report structure and the capabilities and deficiencies of LLMs in chemistry. Upper-division students found generative AI to be helpful for revision. Content analysis revealed AI-revised and -generated samples exhibited fewer grammatical errors, fewer very short and very long sentences, and improved readability of the text. We conclude with some implications for future research and suggestions for other instructors who wish to use and adapt these assignments.	[Ruff, Emily F.; Engen, Mark A.; Franz, Jeanne L.; Mauser, Jonathon F.; West, Joseph K.; Zemke, Jennifer M. O.] Winona State Univ, Dept Chem, Winona, MN 55987 USA	Minnesota State Colleges & Universities; Winona State University	Ruff, EF (corresponding author), Winona State Univ, Dept Chem, Winona, MN 55987 USA.	eruff@winona.edu		West, Joseph/0000-0003-0021-9638; Ruff, Emily/0009-0009-3297-7952; Zemke, Jennifer/0000-0002-2034-0059	Winona State University; WSU Professional Improvement Funds	Winona State University; WSU Professional Improvement Funds	We thank all students who completed the pre- and post-semester surveys, and students who completed the assignments described in this article. We also thank the other instructors in the WSU Chemistry Department for their cooperation and helpful conversations. We thank Dr. Silas Bergen from the WSU Department of Mathematics and Statistics for helpful conversations as well. We acknowledge that ChatGPT was used to generate General Chemistry reports and Analytical Chemistry abstracts for assignments. It was also used to revise Biochem Lab and Inorganic student work, and Inorganic students used it to provide introductory material for their synthetic proposals. Funding for Open Access publication was provided in part by WSU Professional Improvement Funds.	Abdaljaleel M, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-52549-8; Alasadi EA, 2023, J CHEM EDUC, V100, P2965, DOI 10.1021/acs.jchemed.3c00323; Anderson L. W., 2001, TAXONOMY LEARNINGTEA; [Anonymous], NOT OD 23149THE USE; [Anonymous], ACS APPROVALPROGRAM; [Anonymous], GEMINI CHATTO SUPERC; [Anonymous], RAHMAN 26HAS CHATGPT; [Anonymous], ABCS AI DETECTORS LI; [Anonymous], PERPLEXITY BURSTINES; [Anonymous], READABILITY SCORINGS; [Anonymous], Introducing chatgpt; [Anonymous], ONE 3 COLL STUDENTS; [Anonymous], NOTICE RES COMMUNITY; [Anonymous], GPTZERO TECHNOLOGY; [Anonymous], GPT-4; [Anonymous], AI WRITING DETECTION; Banik G.M., 2019, The ACS Guide to Scholarly Communication; ACS Guide to Scholarly Communication, DOI DOI 10.1021/ACSGUIDE; Basic Z, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-02269-7; Baum ZJ, 2021, J CHEM INF MODEL, V61, P3197, DOI 10.1021/acs.jcim.1c00619; Buriak JM, 2023, ACS NANO, V17, P4091, DOI 10.1021/acsnano.3c01544; Clark MJ, 2024, J CHEM EDUC, V101, P1983, DOI 10.1021/acs.jchemed.4c00161; Clase KL, 2010, BIOCHEM MOL BIOL EDU, V38, P290, DOI 10.1002/bmb.20415; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Deng J. M., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-24zfl-v2, DOI 10.26434/CHEMRXIV-2023-24ZFL-V2]; Exintaris B, 2023, J CHEM EDUC, V100, P2972, DOI 10.1021/acs.jchemed.3c00481; Gragson DE, 2010, J CHEM EDUC, V87, P62, DOI 10.1021/ed800015t; Grimaldi G, 2023, ACS ENERGY LETT, V8, P878, DOI 10.1021/acsenergylett.2c02828; Grosse CS, 2007, LEARN INSTR, V17, P612, DOI 10.1016/j.learninstruc.2007.09.008; Guo Y, 2023, J CHEM EDUC, V100, P4876, DOI 10.1021/acs.jchemed.3c00505; Heid E., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-3zcfl-v3, DOI 10.26434/CHEMRXIV-2023-3ZCFL-V3]; Herbold Steffen, 2023, Sci Rep, V13, P18617, DOI 10.1038/s41598-023-45644-9; Howes L., 2023, CHEM ENG NEWS; McAfee SC, 2023, J CHEM EDUC, V101, P3, DOI 10.1021/acs.jchemed.3c00942; McKnelly KJ, 2021, J CHEM EDUC, V98, P1201, DOI 10.1021/acs.jchemed.0c00859; Mullin R., TRICKY ETHICS AI INT; Mullin R., 2021, CHEM ENGINEERINGNEWS; Pierce D., GOOGLE LAUNCHES GEMI; Raygor A.L., 1977, READING, P259; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Szymanski NJ, 2023, NATURE, V624, P86, DOI 10.1038/s41586-023-06734-w; van Peppen LM, 2021, INSTR SCI, V49, P747, DOI 10.1007/s11251-021-09559-0; Wackerly JW, 2018, J CHEM EDUC, V95, P76, DOI 10.1021/acs.jchemed.6b00630; Walker JP, 2013, J CHEM EDUC, V90, P1269, DOI 10.1021/ed300656p; Walvoord M.E., 2008, Journal of College Science Teaching, V37, P66; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; West JK, 2023, J CHEM EDUC, V100, P4351, DOI 10.1021/acs.jchemed.3c00581; Zheng ZL, 2023, ACS CENTRAL SCI, V9, P2161, DOI 10.1021/acscentsci.3c01087; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	48	0	0	10	10	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0021-9584	1938-1328		J CHEM EDUC	J. Chem. Educ.	MAY 30	2024	101	6					2483	2492		10.1021/acs.jchemed.4c00248	http://dx.doi.org/10.1021/acs.jchemed.4c00248		MAY 2024	10	Chemistry, Multidisciplinary; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Education & Educational Research	TV7P2		hybrid			2024-07-03	WOS:001236230200001
J	Floroiu, I; Timisica, D				Floroiu, Iustin; Timisica, Daniela			A Heideggerian analysis of generative pretrained transformer models	ROMANIAN JOURNAL OF INFORMATION TECHNOLOGY AND AUTOMATIC CONTROL-REVISTA ROMANA DE INFORMATICA SI AUTOMATICA			English	Article						Martin Heidegger; GPT; Artificial Intelligence; Dasein	TURING TEST	To better understand the emergence of new large language models in the context of future possibilities with regard to developing novel artificial general intelligence, it is essential to analyse and conclude the existential implications of these algorithms. Given the high speed of technological advancements in the field of deep learning, generative pretrained transformers (GPT) are the closest thing related to the invention of highly independent and intelligent programs, because they manifest creativity and convey an accurate formation of a worldview model that was never seen before. Because of these aspects, this article proposes an analysis of the concept of Dasein, defined by Heidegger, in the vast description of advancements added in the field of computational intelligence. The analysis methods described here are meant to bypass the complex problems of cognitive sciences with regard to computational intelligence and to create a highly accurate model of mental representation and hierarchisation of emergent intelligent algorithms.	[Floroiu, Iustin; Timisica, Daniela] Natl Inst Res & Dev Informat ICI Bucharest, Bucharest, Romania; [Timisica, Daniela] Natl Univ Sci & Technol Politehn Bucharest, Bucharest, Romania	National Institute R&D Informatics Bucharest	Floroiu, I (corresponding author), Natl Inst Res & Dev Informat ICI Bucharest, Bucharest, Romania.	iustin.floroiu@ici.ro; daniela.timisica@ici.ro						Aleksander I, 2008, J CONSCIOUSNESS STUD, V15, P95; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Blitz M., 2014, The New Atlantis, V41, P63; Clark T., 2011, Martin Heidegger, DOI [10.4324/9780203829448, DOI 10.4324/9780203829448]; Cooper SB, 2013, ALAN TURING: HIS WORK AND IMPACT, pXI; Cui HT, 2023, bioRxiv, DOI [10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439, DOI 10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439v2, DOI 10.1101/2023.04.30.538439V2]; Damassino N, 2020, MIND MACH, V30, P463, DOI 10.1007/s11023-020-09553-4; Dodig-Crnkovic G., 2023, Computer Sciences & Mathematics Forum, V8, P66, DOI [10.3390/cmsf2023008066, DOI 10.3390/CMSF2023008066]; Elley-Brown MJ, 2021, J BUS ETHICS, V168, P23, DOI 10.1007/s10551-019-04243-3; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Floroiu I, 2023, ROM J INF TECH AUT C, V33, P99, DOI 10.33436/v33i3y202308; French RM, 2000, TRENDS COGN SCI, V4, P115, DOI 10.1016/S1364-6613(00)01453-4; GUIGNON CB, 1984, REV METAPHYS, V38, P321; Heidegger Martin., 1953, BEING IN TIME; Hodges A., 2008, Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer, P13; Hornsby R., 2012, WHAT HEIDEGGER MEANS; Lee M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102320; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu X, 2023, GPT UNDERSTANDS TOO; Miah M., 2012, International Journal of Science and Applied Information Technology, V1, P30; Moran D, 2014, INT J PHILOS STUD, V22, P491, DOI 10.1080/09672559.2014.948717; Overgaard S., 2004, Phaenomenologica (PHAE, V173; Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290; Scarfe P., 2023, case study, DOI [10.31234/osf.io/n854h, DOI 10.31234/OSF.IO/N854H]; Schalow F., 2019, Historical dictionary of Heidegger's philosophy, VThird; Shieber SM, 2004, TURING TEST: VERBAL BEHAVIOR AS THE HALLMARK OF INTELLIGENCE, P1; Shieber SM, 2007, NOUS, V41, P686, DOI 10.1111/j.1468-0068.2007.00636.x; Tan J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13506, DOI 10.1109/ICCV48922.2021.01327; Tatu G, 2018, ROM J INF TECH AUT C, V28, P41; Vaswani A, 2017, ADV NEUR IN, V30; Zuckerman N, 2015, SOUTHERN J PHILOS, V53, P493, DOI 10.1111/sjp.12151	31	0	0	2	2	INST NATL CERCETARE-DEZVOLTARE INFORMATICA-ICI	BUCHAREST	8-10 MARESAL A AVERESCU AV, SECTOR 1, BUCHAREST, 011455, ROMANIA	1220-1758	1841-4303		ROM J INF TECH AUT C	Rom. J. Infor. Tech. Autom. Control		2024	34	1					13	22		10.33436/v34i1y202402	http://dx.doi.org/10.33436/v34i1y202402			10	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	MU9B5		gold			2024-07-03	WOS:001196255700001
J	Li, CY; Gan, Z; Yang, ZY; Yang, JW; Li, LJ; Wang, LJ; Gao, JF				Li, Chunyuan; Gan, Zhe; Yang, Zhengyuan; Yang, Jianwei; Li, Linjie; Wang, Lijuan; Gao, Jianfeng			Multimodal Foundation Models: From Specialists to General-Purpose Assistants	FOUNDATIONS AND TRENDS IN COMPUTER GRAPHICS AND VISION			English	Article							SEGMENTATION; NETWORKS	This monograph presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics - methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics - unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the monograph are researchers, graduate students, and professionals in computer vision and vision-language multimodal communities who are eager to learn the basics and recent advances in multimodal foundation models.	[Li, Chunyuan; Gan, Zhe; Yang, Zhengyuan; Yang, Jianwei; Li, Linjie; Wang, Lijuan; Gao, Jianfeng] Microsoft Corp, Redmond, WA 98052 USA	Microsoft	Li, CY (corresponding author), Microsoft Corp, Redmond, WA 98052 USA.	chunyl@microsoft.com; zhgan@microsoft.com; zhengyang@microsoft.com; jianwyan@microsoft.com; linjli@microsoft.com; lijuanw@microsoft.com; jfgao@microsoft.com	李, 李林洁/JAD-1884-2023					Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agarwal A, 2023, Arxiv, DOI arXiv:2306.14544; Agrawal H, 2019, IEEE I CONF COMP VIS, P8947, DOI 10.1109/ICCV.2019.00904; Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]; Allahyari M, 2017, Arxiv, DOI arXiv:1707.02268; Amrani E, 2022, LECT NOTES COMPUT SC, V13691, P116, DOI 10.1007/978-3-031-19821-2_7; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], General 2; [Anonymous], 2023, Svd-xt; [Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2023, Pika 1.0; [Anonymous], 2023, Morph; [Anonymous], 2023, Moonvalley; [Anonymous], 2022, Stable diffusion; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Arora Sanjeev, 2019, arXiv; Assran M, 2022, LECT NOTES COMPUT SC, V13691, P456, DOI 10.1007/978-3-031-19821-2_26; Avrahami O, 2023, PROC CVPR IEEE, P18370, DOI 10.1109/CVPR52729.2023.01762; Avrahami O, 2023, Arxiv, DOI arXiv:2305.16311; Avrahami O, 2023, Arxiv, DOI arXiv:2206.02779; Avrahami O, 2022, PROC CVPR IEEE, P18187, DOI 10.1109/CVPR52688.2022.01767; Awadalla Anas, 2023, Zenodo; Awais M., 2023, arXiv; Bachman P, 2019, ADV NEUR IN, V32; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bai JZ, 2023, Arxiv, DOI arXiv:2308.12966; Bai S, 2023, Arxiv, DOI arXiv:2308.16890; Balaji Y., 2022, arXiv; Balazevic I, 2023, Arxiv, DOI arXiv:2306.01667; Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24; Bansal A, 2023, IEEE COMPUT SOC CONF, P843, DOI 10.1109/CVPRW59228.2023.00091; Bao H., 2022, ICLR; Bao HB, 2022, Arxiv, DOI arXiv:2111.02358; Bar A., 2022, Advances in Neural Information Processing Systems, V35; Bardes A, 2022, Arxiv, DOI arXiv:2105.04906; Bitton Y, 2023, Arxiv, DOI arXiv:2308.06595; Black K, 2024, Arxiv, DOI arXiv:2305.13301; Blattmann A., 2023, Stable video diffusion: Scaling latent video diffusion models to large datasets; Blattmann A, 2022, Arxiv, DOI [arXiv:2204.11824, 10.48550/ARXIV.2204.11824]; Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brooks T., 2023, P IEEE CVF C COMP VI, p18 392; Brown T. B., 2020, NEUIPS; Bulent Sariyildiz M., 2020, LNCS, P153; Byeon M., 2022, Coyo- 700m: Image-text pair dataset; Cai M, 2024, Arxiv, DOI arXiv:2312.00784; Cai TL, 2024, Arxiv, DOI arXiv:2305.17126; Cai ZW, 2022, LECT NOTES COMPUT SC, V13696, P290, DOI 10.1007/978-3-031-20059-5_17; Cao LL, 2023, Arxiv, DOI arXiv:2305.05095; Carion N., 2020, END TO END OBJECT DE; Caron M., 2020, PROCADV NEURAL INF P, VVolume 33, P9912, DOI DOI 10.5555/3495724.3496555; Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Castrejón L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477; Chang H., 2023, arXiv; Chang HW, 2022, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR52688.2022.01103; Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356; Chefer H, 2023, Arxiv, DOI arXiv:2301.13826; Chen C, 2023, Arxiv, DOI arXiv:2301.13081; Chen DL, 2023, Arxiv, DOI arXiv:2307.01003; Chen FL, 2022, Arxiv, DOI arXiv:2202.09061; Chen KQ, 2023, Arxiv, DOI arXiv:2306.15195; Chen L., 2023, arXiv; Chen L, 2019, IEEE INT CONF COMP V, P1407, DOI 10.1109/ICCVW.2019.00177; Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]; Chen L, 2023, Arxiv, DOI arXiv:2311.12793; Chen M., 2021, arXiv; Chen Q, 2023, Arxiv, DOI arXiv:2207.13085; Chen T, 2022, Arxiv, DOI arXiv:2206.07669; Chen W. -G., 2023, Llavainteractive: An all -in -one demo for image chat, segmentation, generation and editing; Chen WH, 2023, Arxiv, DOI arXiv:2304.00186; Chen WH, 2022, Arxiv, DOI arXiv:2210.02928; Chen WH, 2022, Arxiv, DOI arXiv:2209.14491; Chen X, 2023, Arxiv, DOI arXiv:2305.18565; Chen X, 2022, Arxiv, DOI arXiv:2209.06794; Chen X, 2022, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR52688.2022.00136; Chen X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7325, DOI 10.1109/ICCV48922.2021.00725; Chen XK, 2022, Arxiv, DOI arXiv:2202.03026; Chen XL, 2015, Arxiv, DOI arXiv:1504.00325; Chen XL, 2020, Arxiv, DOI [arXiv:2003.04297, DOI 10.48550/ARXIV.2003.04297]; Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549; Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950; Chen Yen-Chun, 2020, ECCV; Chen Z, 2023, Arxiv, DOI [arXiv:2205.08534, DOI 10.48550/ARXIV.2205.08534]; Cheng BW, 2022, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR52688.2022.00135; Cherti M., 2023, CVPR; Cho J., 2021, ICML; Cho JM, 2023, Arxiv, DOI arXiv:2304.06671; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Computer T., 2023, Redpajama-data: An open source recipe to reproduce llama training dataset; Crawshaw M., 2020, arXiv; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Dai HX, 2024, Arxiv, DOI arXiv:2307.01187; Dai WL, 2023, Arxiv, DOI arXiv:2305.06500; Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729; Huynh D, 2022, PROC CVPR IEEE, P7010, DOI 10.1109/CVPR52688.2022.00689; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Desai K., 2021, NEURIPS TRACK DATASE; Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Hjelm RD, 2019, Arxiv, DOI [arXiv:1808.06670, DOI 10.48550/ARXIV.1808.06670]; Dhariwal P, 2021, ADV NEUR IN, V34; Ding J., 2022, arXiv; Ding Z, 2022, Arxiv, DOI arXiv:2208.08984; Dong B., 2021, Advances in Neural Information Processing Systems, V34, p21 898; Dong XY, 2022, LECT NOTES COMPUT SC, V13690, P247, DOI 10.1007/978-3-031-20056-4_15; Dosovitskiy A., 2020, ICLR; Dou ZY, 2022, PROC CVPR IEEE, P18145, DOI 10.1109/CVPR52688.2022.01763; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Du Y., 2022, IJCAI SURVEY TRACK; Peters ME, 2019, Arxiv, DOI [arXiv:1909.04164, 10.18653/v1/D19-1005, DOI 10.18653/V1/D19-1005]; El-Nouby A., 2021, arXiv; Elharrouss O, 2020, NEURAL PROCESS LETT, V51, P2007, DOI 10.1007/s11063-019-10163-0; Ermolov A., 2021, ICML; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; Everingham M., 2011, Tech. Rep, V8, P5; Fan LJ, 2023, Arxiv, DOI arXiv:2305.20088; Fan Y, 2023, Arxiv, DOI arXiv:2305.16381; Fang YX, 2023, PROC CVPR IEEE, P19358, DOI 10.1109/CVPR52729.2023.01855; Fang ZY, 2022, PROC CVPR IEEE, P17988, DOI 10.1109/CVPR52688.2022.01748; Feichtenhofer Christoph, 2022, NEURIPS; Feng CJ, 2022, LECT NOTES COMPUT SC, V13669, P701, DOI 10.1007/978-3-031-20077-9_41; Feng W., 2022, 11 INT C LEARN REPR; Feng WX, 2023, Arxiv, DOI [arXiv:2305.15393, DOI 10.48550/ARXIV.2305.15393]; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Fu CY, 2024, Arxiv, DOI arXiv:2306.13394; Fu T. -J., 2023, Guiding instruction -based image editing via multimodal large language models; Gadre SY, 2023, Arxiv, DOI arXiv:2304.14108; Gafni O., 2022, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 13675 LNCS:89-106; Gal R, 2022, Arxiv, DOI [arXiv:2208.01618, 10.48550/arXiv.2208.01618]; Gan Z., 2022, Neurips; Gan Z., 2020, Advances in Neural Information Processing Systems, P6616; Gan Z, 2022, FOUND TRENDS COMPUT, V14, P163, DOI 10.1561/0600000105; Gao DF, 2023, Arxiv, DOI arXiv:2306.08640; Gao P., 2022, arXiv; Gao P, 2023, Arxiv, DOI arXiv:2304.15010; Ge YY, 2023, Arxiv, DOI arXiv:2307.08041; Geng X., 2023, OpenLLaMA: An open reproduction of LLaMA; Geng ZG, 2023, Arxiv, DOI arXiv:2309.03895; Ghiasi G, 2022, LECT NOTES COMPUT SC, V13696, P540, DOI 10.1007/978-3-031-20059-5_31; Girdhar R, 2023, PROC CVPR IEEE, P15180, DOI 10.1109/CVPR52729.2023.01457; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Gong T, 2023, Arxiv, DOI [arXiv:2305.04790, 10.48550/arXiv.2305.04790]; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Grill J.B., 2020, P ADV NEUR INF PROC, VVolume 33, P21271, DOI DOI 10.48550/ARXIV.2006.07733; Gu XY, 2023, Arxiv, DOI arXiv:2306.01736; Gu Xiuye, 2021, arXiv; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; Gui LK, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P956; Gunjal A, 2024, Arxiv, DOI arXiv:2308.06394; Gupta T., 2022, arXiv; Gupta T., 2022, arXiv; Gupta T, 2023, PROC CVPR IEEE, P14953, DOI 10.1109/CVPR52729.2023.01436; Gupta T, 2022, PROC CVPR IEEE, P16378, DOI 10.1109/CVPR52688.2022.01591; Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380; Guu K, 2020, Arxiv, DOI arXiv:2002.08909; Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x; Harley AW, 2022, LECT NOTES COMPUT SC, V13682, P59, DOI 10.1007/978-3-031-20047-2_4; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He naff O. J., 2020, PR MACH LEARN RES, V119, P4182, DOI [10.5555/3524938.3525329, DOI 10.5555/3524938.3525329]; He P, 2020, ICLR; He RF, 2022, Arxiv, DOI arXiv:2210.07574; Ho J., 2020, NeurIPS; Ho JAT, 2022, Arxiv, DOI arXiv:2210.02303; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hong YN, 2023, Arxiv, DOI arXiv:2307.12981; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1419, DOI 10.1109/ICCV48922.2021.00147; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; Hu WB, 2023, Arxiv, DOI arXiv:2308.09936; Huang RJ, 2023, Arxiv, DOI arXiv:2304.12995; Huang SH, 2023, Arxiv, DOI arXiv:2302.14045; Huang SY, 2023, Arxiv, DOI arXiv:2305.11176; Huang W., 2022, PROC INT C MACHINE L, P9118; Huang YP, 2023, Arxiv, DOI arXiv:2308.16463; Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849; Huang ZC, 2021, PROC CVPR IEEE, P12971, DOI 10.1109/CVPR46437.2021.01278; Ilharco Gabriel, 2021, Zenodo; Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094; Jain J, 2023, PROC CVPR IEEE, P2989, DOI 10.1109/CVPR52729.2023.00292; Jaiswal A., 2020, Technologies; Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283; Jia C, 2021, PR MACH LEARN RES, V139; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180; Kang M, 2023, PROC CVPR IEEE, P10124, DOI 10.1109/CVPR52729.2023.00976; Kawar B, 2023, PROC CVPR IEEE, P6007, DOI 10.1109/CVPR52729.2023.00582; Kazemzadeh S., 2014, P 2014 C EMPIRICAL M, P787, DOI [DOI 10.3115/V1/D14-1086, 10.3115/v1/d14-1086]; Kim W, 2021, PR MACH LEARN RES, V139; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Koh JY, 2023, Arxiv, DOI arXiv:2305.17216; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Kolesnikov A, 2022, Arxiv, DOI arXiv:2205.10337; Kumari N, 2023, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR52729.2023.00192; Kuo WC, 2022, LECT NOTES COMPUT SC, V13696, P502, DOI 10.1007/978-3-031-20059-5_29; Lai X, 2024, Arxiv, DOI arXiv:2308.00692; Lamb A, 2016, Arxiv, DOI arXiv:1602.03220; Lambert J, 2020, PROC CVPR IEEE, P2876, DOI 10.1109/CVPR42600.2020.00295; Larsen ABL, 2016, PR MACH LEARN RES, V48; Laurençon H, 2023, Arxiv, DOI arXiv:2306.16527; Lee D, 2022, PROC CVPR IEEE, P11513, DOI 10.1109/CVPR52688.2022.01123; Li B., 2022, ICLR; Li B, 2023, Arxiv, DOI arXiv:2306.05425; Li B, 2023, Arxiv, DOI arXiv:2305.03726; Li BH, 2023, Arxiv, DOI arXiv:2307.16125; Li C., 2022, Neurips track on datasets and benchmarks; Li C., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.09785; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Li F., 2022, arXiv; Li F, 2023, Arxiv, DOI arXiv:2307.04767; Li H, 2023, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR52729.2023.00264; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li KC, 2024, Arxiv, DOI [arXiv:2305.06355, 10.48550/arXiv.2305.06355]; Li L, 2023, Arxiv, DOI arXiv:2306.04387; Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041; Li MH, 2023, Arxiv, DOI arXiv:2304.08244; Li SZ, 2023, Arxiv, DOI arXiv:2308.03349; Li Y., 2022, ICLR; Li YD, 2023, Arxiv, DOI arXiv:2308.10253; Li YH, 2023, PROC CVPR IEEE, P23390, DOI 10.1109/CVPR52729.2023.02240; Li YF, 2023, Arxiv, DOI arXiv:2305.10355; Li YZ, 2023, Arxiv, DOI arXiv:2309.05463; Li YH, 2023, PROC CVPR IEEE, P22511, DOI 10.1109/CVPR52729.2023.02156; Liang F, 2023, PROC CVPR IEEE, P7061, DOI 10.1109/CVPR52729.2023.00682; Liang YB, 2023, Arxiv, DOI arXiv:2303.16434; Lin B, 2023, Arxiv, DOI arXiv:2311.10122; Lin CH, 2023, PROC CVPR IEEE, P300, DOI 10.1109/CVPR52729.2023.00037; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin YQ, 2023, Arxiv, DOI arXiv:2305.15808; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143; Liu FX, 2024, Arxiv, DOI arXiv:2306.14565; Liu H., 2023, AAAI; Liu H., 2023, Improved baselines with visual instruction tuning; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu J, 2023, Arxiv, DOI arXiv:2302.07387; Liu N, 2022, LECT NOTES COMPUT SC, V13677, P423, DOI 10.1007/978-3-031-19790-1_26; Liu RS, 2023, Arxiv, DOI arXiv:2303.11328; Liu S., 2023, Llava-plus: Learning to use tools for creating multimodal agents; Liu SK, 2024, Arxiv, DOI arXiv:2303.02506; Liu SL, 2023, Arxiv, DOI arXiv:2303.05499; Liu SH, 2023, Arxiv, DOI [arXiv:2304.09728, DOI 10.48550/ARXIV.2304.09728]; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu WH, 2023, Arxiv, DOI arXiv:2306.16034; Liu XB, 2023, Arxiv, DOI arXiv:2307.14335; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Y, 2024, Arxiv, DOI arXiv:2307.06281; Liu YL, 2024, Arxiv, DOI arXiv:2305.07895; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Liu ZY, 2023, Arxiv, DOI arXiv:2305.05662; Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167; Long A, 2022, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR52688.2022.00683; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu CZ, 2023, Arxiv, DOI arXiv:2305.15248; Lu JS, 2022, Arxiv, DOI arXiv:2206.08916; Lu JS, 2019, ADV NEUR IN, V32; Lu Jiasen, 2020, P IEEE CVF C COMP VI; Lu P., 2022, Advances in Neural Information Processing Systems; Lu P, 2024, Arxiv, DOI [arXiv:2310.02255, 10.48550/arXiv.2310.02255]; Lu P, 2023, Arxiv, DOI arXiv:2304.09842; Lu Q., 2023, ICCV; Lu Y., 2023, arXiv; Lüddecke T, 2022, PROC CVPR IEEE, P7076, DOI 10.1109/CVPR52688.2022.00695; Luo G, 2023, Arxiv, DOI arXiv:2305.15023; Luo RP, 2023, Arxiv, DOI arXiv:2306.07207; Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448; Ma J, 2024, Arxiv, DOI [arXiv:2304.12306, DOI 10.48550/ARXIV.2304.12306]; Ma ZH, 2023, Arxiv, DOI arXiv:2304.10817; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Margffoy-Tuay E, 2018, LECT NOTES COMPUT SC, V11215, P656, DOI 10.1007/978-3-030-01252-6_39; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Mazumder M, 2023, Arxiv, DOI [arXiv:2207.10062, 10.48550/arXiv.2207.10062]; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; Mertan A, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103441; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Minderer M, 2022, Arxiv, DOI arXiv:2205.06230; Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Monajatipoor M, 2023, Arxiv, DOI arXiv:2306.01311; Moor M, 2023, Arxiv, DOI arXiv:2307.15189; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119; Mou C, 2023, Arxiv, DOI arXiv:2302.08453; Mu N., 2021, arXiv; Mu Y, 2023, Arxiv, DOI arXiv:2305.15021; Munasinghe S, 2023, Arxiv, DOI arXiv:2311.13435; Musgrave Kevin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P681, DOI 10.1007/978-3-030-58595-2_41; Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nguyen T., 2022, NeurIPS; Ning J, 2023, Arxiv, DOI arXiv:2301.02229; OpenAi, 2022, Chatgpt; OpenAI, 2023, Gpt-4 technical report, 2023.; Oquab M, 2024, Arxiv, DOI [arXiv:2304.07193, DOI 10.48550/ARXIV.2304.07193]; Ordonez V., 2011, NEURIPS; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Ozbulak U, 2023, Arxiv, DOI arXiv:2305.13689; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Paranjape B, 2023, Arxiv, DOI arXiv:2303.09014; Patil SG, 2023, Arxiv, DOI arXiv:2305.15334; Peebles W, 2023, Arxiv, DOI [arXiv:2212.09748, DOI 10.48550/ARXIV.2212.09748]; Penedo G., 2023, arXiv; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Peng Z., 2022, arXiv; Peng ZL, 2023, Arxiv, DOI [arXiv:2306.14824, 10.48550/arXiv.2306.14824]; Peng ZL, 2022, Arxiv, DOI arXiv:2208.06366; Pham H, 2022, Arxiv, DOI arXiv:2111.10050; Pi RJ, 2023, Arxiv, DOI arXiv:2305.14167; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Pont-Tuset J., 2020, ECCV; Poole Ben, 2022, arXiv; Qian C, 2023, Arxiv, DOI arXiv:2305.14318; Qian R, 2022, Arxiv, DOI arXiv:2207.07646; Qin C, 2023, Arxiv, DOI arXiv:2305.11147; Qin J, 2023, Arxiv, DOI arXiv:2303.17225; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Raffel C, 2020, J MACH LEARN RES, V21; Rahman S, 2020, AAAI CONF ARTIF INTE, V34, P11932; Rajic F, 2023, Arxiv, DOI arXiv:2307.01197; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755; Razavi A, 2019, ADV NEUR IN, V32; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Reed S, 2022, Arxiv, DOI arXiv:2205.06175; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ridnik T, 2021, Arxiv, DOI [arXiv:2104.10972, DOI 10.48550/ARXIV.2104.10972]; Rombach R., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.10752; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roy S, 2023, Arxiv, DOI arXiv:2304.05396; Ruan L., 2022, Survey: Transformer based video -language pre -training; Ruiz N, 2023, PROC CVPR IEEE, P22500, DOI 10.1109/CVPR52729.2023.02155; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saharia C, 2022, Arxiv, DOI arXiv:2205.11487; Schick T., 2023, arXiv; Schuhmann C., 2022, NEURIPS; Schuhmann C, 2021, Arxiv, DOI arXiv:2111.02114; Schwenk D, 2022, Arxiv, DOI arXiv:2206.01718; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shao S, 2019, IEEE I CONF COMP VIS, P8429, DOI 10.1109/ICCV.2019.00852; Shao WQ, 2023, Arxiv, DOI arXiv:2308.03729; ShareGPT, 2023, About us; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Shen QH, 2023, Arxiv, DOI arXiv:2304.10261; Shen S., 2022, NeurIPS; Shen S., 2022, ICLR; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Sheynin S., 2022, arXiv; Shi J, 2023, Arxiv, DOI arXiv:2304.03411; Shi PL, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111947; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Sidorov O., 2020, COMPUTER VISION ECCV, P742, DOI 10.1007/978-3-030-58536-544; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Singer U, 2022, Arxiv, DOI arXiv:2209.14792; Singh A, 2022, PROC CVPR IEEE, P15617, DOI 10.1109/CVPR52688.2022.01519; Singh M, 2024, Arxiv, DOI arXiv:2303.13496; Singh M, 2022, PROC CVPR IEEE, P794, DOI 10.1109/CVPR52688.2022.00088; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Song Y, 2023, Arxiv, DOI [arXiv:2303.01469, DOI 10.48550/ARXIV.2303.01469]; Song YF, 2023, Arxiv, DOI arXiv:2306.06624; Song Yuhang, 2020, Adv Neural Inf Process Syst, V33, P22566; Srinivasan K, 2021, Arxiv, DOI arXiv:2103.01913; Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710; Su YX, 2023, Arxiv, DOI arXiv:2305.16355; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Sun Q, 2024, Arxiv, DOI arXiv:2307.05222; Sun YS, 2023, Arxiv, DOI arXiv:2308.00906; Sun YX, 2024, Arxiv, DOI arXiv:2305.15072; Surís D, 2023, Arxiv, DOI [arXiv:2303.08128, DOI 10.48550/ARXIV.2303.08128(2023).2303.08128]; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Tang L, 2023, Arxiv, DOI arXiv:2304.04709; Tang ZN, 2023, Arxiv, DOI arXiv:2305.11846; Tao CX, 2023, PROC CVPR IEEE, P2132, DOI 10.1109/CVPR52729.2023.00212; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tong Z., 2022, NEURIPS; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Touvron H, 2021, PR MACH LEARN RES, V139, P7358; Tschannen M, 2023, Arxiv, DOI arXiv:2306.07915; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Vahdat A., 2020, Nvae: A deep hierarchical variational autoencoder; van den Oord A, 2018, Arxiv, DOI arXiv:1711.00937; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; van den Oord A, 2017, ADV NEUR IN, V30; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang B, 2024, Arxiv, DOI arXiv:2308.12714; Wang F., 2023, TIP; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542; Wang JF, 2022, Arxiv, DOI arXiv:2205.14100; Wang JK, 2023, Arxiv, DOI arXiv:2311.07574; Wang JK, 2023, Arxiv, DOI arXiv:2304.14407; Wang JY, 2023, Arxiv, DOI arXiv:2308.15126; Wang LM, 2023, PROC CVPR IEEE, P14549, DOI 10.1109/CVPR52729.2023.01398; Wang P., 2022, ICML; Wang R, 2022, PROC CVPR IEEE, P14713, DOI 10.1109/CVPR52688.2022.01432; Wang T, 2024, Arxiv, DOI arXiv:2307.00040; Wang T, 2023, Arxiv, DOI arXiv:2305.02677; Wang W., 2024, arXiv; Wang WH, 2023, Arxiv, DOI arXiv:2305.11175; Wang WH, 2022, Arxiv, DOI arXiv:2208.10442; Wang XL, 2023, PROC CVPR IEEE, P6830, DOI 10.1109/CVPR52729.2023.00660; Wang XL, 2023, Arxiv, DOI arXiv:2304.03284; Wang YZ, 2023, Arxiv, DOI arXiv:2306.04751; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wang YZ, 2022, Arxiv, DOI arXiv:2204.07705; Wang Z., 2023, arXiv; Wang ZD, 2023, Arxiv, DOI arXiv:2305.01115; Wang ZY, 2023, Arxiv, DOI arXiv:2305.16213; Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166; Wang Ziqiao, 2022, ICLR; Weers F, 2023, PROC CVPR IEEE, P23432, DOI 10.1109/CVPR52729.2023.02244; Wei C, 2022, PROC CVPR IEEE, P14648, DOI 10.1109/CVPR52688.2022.01426; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei L, 2023, Arxiv, DOI arXiv:2308.12067; Wei LH, 2022, LECT NOTES COMPUT SC, V13690, P337, DOI 10.1007/978-3-031-20056-4_20; Wei YX, 2023, Arxiv, DOI arXiv:2302.13848; Weng L., 2023, Llm-powered autonomous agents; Wu CY, 2023, Arxiv, DOI [arXiv:2308.02463, DOI 10.48550/ARXIV.2308.02463]; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu J., 2021, Multi-modal answer validation for knowledge-based VQA; Wu JL, 2022, Arxiv, DOI arXiv:2212.00280; Wu JN, 2022, PROC CVPR IEEE, P4964, DOI 10.1109/CVPR52688.2022.00492; Wu WT, 2024, Arxiv, DOI arXiv:2306.07952; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xiao ZX, 2023, Arxiv, DOI [arXiv:2305.00201, DOI 10.48550/ARXIV.2305.00201]; Xie DF, 2023, Arxiv, DOI arXiv:2304.14006; Xie X., 2022, arXiv; Xie ZD, 2023, PROC CVPR IEEE, P10365, DOI 10.1109/CVPR52729.2023.00999; Xie ZD, 2021, Arxiv, DOI arXiv:2105.04553; Xie ZD, 2022, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR52688.2022.00943; Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077; Xu HY, 2021, Arxiv, DOI arXiv:2106.01804; Xu JR, 2023, PROC CVPR IEEE, P2955, DOI 10.1109/CVPR52729.2023.00289; Xu JR, 2022, PROC CVPR IEEE, P18113, DOI 10.1109/CVPR52688.2022.01760; Xu JJ, 2024, Arxiv, DOI arXiv:2311.05348; Xu P, 2023, Arxiv, DOI arXiv:2306.09265; Xu RS, 2023, Arxiv, DOI arXiv:2308.16911; Xu YW, 2023, Arxiv, DOI arXiv:2311.09257; Xu ZY, 2022, Arxiv, DOI arXiv:2212.10773; Yan B, 2023, PROC CVPR IEEE, P15325, DOI 10.1109/CVPR52729.2023.01471; Yang BX, 2023, PROC CVPR IEEE, P18381, DOI 10.1109/CVPR52729.2023.01763; Yang JW, 2022, PROC CVPR IEEE, P19141, DOI 10.1109/CVPR52688.2022.01857; Yang JY, 2023, Arxiv, DOI arXiv:2304.11968; Yang R, 2023, Arxiv, DOI arXiv:2305.18752; Yang Z., 2023, Mm-react: Prompting chatgpt for multimodal reasoning and action; Yang Z, 2022, PROC CVPR IEEE, P18134, DOI 10.1109/CVPR52688.2022.01762; Yang ZY, 2023, PROC CVPR IEEE, P14246, DOI 10.1109/CVPR52729.2023.01369; Yang ZY, 2022, LECT NOTES COMPUT SC, V13696, P521, DOI 10.1007/978-3-031-20059-5_30; Yang ZY, 2022, Arxiv, DOI arXiv:2111.12085; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yang ZL, 2023, Arxiv, DOI arXiv:2302.04858; Yao L., 2022, ICLR; Yao LW, 2023, PROC CVPR IEEE, P23497, DOI 10.1109/CVPR52729.2023.02250; Yao LW, 2022, Arxiv, DOI arXiv:2209.09407; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yasunaga M, 2022, Arxiv, DOI arXiv:2211.12561; Ye JB, 2023, Arxiv, DOI arXiv:2307.02499; Ye L., 2019, P IEEE CVF C COMP VI, p10 502; Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637; Ye QH, 2024, Arxiv, DOI arXiv:2304.14178; Yi K, 2023, Arxiv, DOI [arXiv:2205.09616, 10.3390/biomedinformatics1030007, 10.1016/j.bspc.2022.104217, DOI 10.1016/J.INS.2022.12.099]; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yin D, 2022, Arxiv, DOI arXiv:2202.08772; Yin ZF, 2023, Arxiv, DOI arXiv:2306.06687; Yoon S, 2021, AAAI CONF ARTIF INTE, V35, P10718; You HX, 2023, Arxiv, DOI arXiv:2310.07704; Yu J., 2021, arXiv; Yu J., 2022, TMLR; Yu Jiahui, 2022, T MACHINE LEARNING R, V1, P7; Yu L., 2023, Scaling autoregressive multi -modal models: Pretraining and instruction tuning; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Yuan Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P71, DOI 10.1007/978-3-030-58568-6_5; Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17; Yu QF, 2023, Arxiv, DOI arXiv:2305.12799; Yu QH, 2023, Arxiv, DOI arXiv:2308.02487; Yu T, 2023, Arxiv, DOI arXiv:2304.06790; Yu WH, 2023, Arxiv, DOI arXiv:2308.02490; Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644; Yuan L., 2021, arXiv; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zang YH, 2022, Arxiv, DOI arXiv:2203.11876; Zareian A, 2021, PROC CVPR IEEE, P14388, DOI 10.1109/CVPR46437.2021.01416; Zbontar J, 2021, PR MACH LEARN RES, V139; Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688; Zeng Y., 2022, ICML; Zeng Y, 2023, PROC CVPR IEEE, P22468, DOI 10.1109/CVPR52729.2023.02152; Zhai XH, 2023, Arxiv, DOI arXiv:2303.15343; Zhai XH, 2022, PROC CVPR IEEE, P18102, DOI 10.1109/CVPR52688.2022.01759; Zhai XH, 2022, PROC CVPR IEEE, P12094, DOI 10.1109/CVPR52688.2022.01179; Zhang C, 2020, IEEE J-STSP, V14, P478, DOI 10.1109/JSTSP.2020.2987728; Zhang C, 2023, Arxiv, DOI arXiv:2306.06211; Zhang CS, 2023, Arxiv, DOI arXiv:2303.07909; Zhang CH, 2023, Arxiv, DOI arXiv:2305.08196; Zhang H, 2023, Arxiv, DOI [arXiv:2306.02858, 10.48550/arXiv.2306.02858, DOI 10.48550/ARXIV.2306.02858]; Zhang H, 2023, Arxiv, DOI arXiv:2303.08131; Zhang H, 2022, Arxiv, DOI arXiv:2203.03605; Zhang Hao., 2023, Llava-grounding: Grounded visual chat with large multimodal models; Zhang J, 2024, Arxiv, DOI arXiv:2304.00685; Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19; Zhang L, 2023, Arxiv, DOI arXiv:2302.05543; Zhang P., 2022, ECCV; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553; Zhang RR, 2023, Arxiv, DOI arXiv:2305.03048; Zhang SY, 2024, Arxiv, DOI [arXiv:2308.10792, 10.48550/ARXIV.2308.10792, 10.48550/arXiv.2308.10792]; Zhang SL, 2024, Arxiv, DOI arXiv:2307.03601; Zhang SJ, 2023, Arxiv, DOI [arXiv:2305.02499, DOI 10.48550/ARXIV.2305.02499]; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang WX, 2023, Arxiv, DOI arXiv:2306.05179; Zhang X., 2022, arXiv; Zhang X., 2022, arXiv; Zhang XM, 2023, Arxiv, DOI arXiv:2305.10415; Zhang YZ, 2024, Arxiv, DOI arXiv:2306.17107; Zhang YC, 2023, Arxiv, DOI arXiv:2305.03678; Zhang YC, 2023, Arxiv, DOI arXiv:2306.03514; Zhao B, 2023, Arxiv, DOI arXiv:2307.04087; Zhao SH, 2023, Arxiv, DOI arXiv:2305.16322; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao Y, 2023, Arxiv, DOI arXiv:2307.08581; Zhao YQ, 2023, Arxiv, DOI arXiv:2305.16934; Zhong YW, 2022, PROC CVPR IEEE, P16772, DOI 10.1109/CVPR52688.2022.01629; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhou C, 2022, LECT NOTES COMPUT SC, V13688, P696, DOI 10.1007/978-3-031-19815-1_40; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206; Zhou GZ, 2023, Arxiv, DOI arXiv:2305.16986; Zhou JH, 2022, Arxiv, DOI arXiv:2111.07832; Zhou T, 2023, Arxiv, DOI arXiv:2304.07583; Zhou XY, 2022, LECT NOTES COMPUT SC, V13669, P350, DOI 10.1007/978-3-031-20077-9_21; Zhou Y., 2022, Lafite2: Few-shot text-to-image generation; Zhou YT, 2023, IEEE COMPUT SOC CONF, P826, DOI 10.1109/CVPRW59228.2023.00090; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592; Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515; Zhu PK, 2020, IEEE T CIRC SYST VID, V30, P998, DOI 10.1109/TCSVT.2019.2899569; Zhu WR, 2023, Arxiv, DOI arXiv:2304.06939; Zhu YC, 2024, Arxiv, DOI arXiv:2401.02330; Zong ZF, 2023, Arxiv, DOI arXiv:2211.12860; Zou X., 2022, arXiv; Zou XY, 2023, PROC CVPR IEEE, P15116, DOI 10.1109/CVPR52729.2023.01451; Zou XY, 2023, Arxiv, DOI arXiv:2304.06718	565	0	0	2	2	NOW PUBLISHERS INC	HANOVER	PO BOX 1024, HANOVER, MA 02339, UNITED STATES	1572-2740	1572-2759		FOUND TRENDS COMPUT	Found. Trends Comput. Graph. Vis.		2024	16	1-2					1	214		10.1561/0600000110	http://dx.doi.org/10.1561/0600000110			214	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	QX9Z6		Green Submitted, gold			2024-07-03	WOS:001224298100001
C	Rony, MRA; Sahoo, SR; Khan, AG; Friedl, KE; Sudhi, V; Süss, C		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Rony, Md. Rashad Al Hasan; Sahoo, Soumya Ranjan; Khan, Abbas Goher; Friedl, Ken E.; Sudhi, Viju; Suess, Christian			Incorporating Query Recommendation for Improving In-Car Conversational Search	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Retrieval-augmented Generation; Query Recommendation		Retrieval-augmented generation has become an effective mechanism for conversational systems in domain-specific settings. Retrieval of a wrong document due to the lack of context from the user utterance may lead to wrong answer generation. Such an issue may reduce the user engagement and thereby the system reliability. In this paper, we propose a context-guided follow-up question recommendation to internally improve the document retrieval in an iterative approach for developing an in-car conversational system. Specifically, a user utterance is first reformulated, given the context of the conversation to facilitate improved understanding to the retriever. In the cases, where the documents retrieved by the retriever are not relevant enough for answering the user utterance, we employ a large language model (LLM) to generate question recommendation which is then utilized to perform a refined retrieval. An empirical evaluation confirms the effectiveness of our proposed approaches in in-car conversations, achieving 48% and 22% improvement in the retrieval and system generated responses, respectively, against baseline approaches.	[Rony, Md. Rashad Al Hasan; Friedl, Ken E.; Suess, Christian] BMW Grp, Parkring 19-23, D-85748 Garching, Germany; [Sahoo, Soumya Ranjan; Khan, Abbas Goher; Sudhi, Viju] Fraunhofer IAIS, Zwickauer Str 46, D-01069 Dresden, Germany	BMW AG	Rony, MRA (corresponding author), BMW Grp, Parkring 19-23, D-85748 Garching, Germany.	rah.rony@gmail.com						Bi K., 2021, P 2021 ACM SIGIR INT; Dang V., 2010, Web Search and Data Mining; Elgohary A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5918; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Rao S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2737; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Yu S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1933, DOI 10.1145/3397271.3401323	11	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56068-2; 978-3-031-56069-9	LECT NOTES COMPUT SC			2024	14612						304	312		10.1007/978-3-031-56069-9_36	http://dx.doi.org/10.1007/978-3-031-56069-9_36			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EC					2024-07-03	WOS:001211835200036
J	Korinek, A				Korinek, Anton			Generative AI for Economic Research: Use Cases and Implications for Economists†	JOURNAL OF ECONOMIC LITERATURE			English	Article								Generative artificial intelligence (AI) has the potential to revolutionize research. I analyze how large language models (LLMs) such as ChatGPT can assist economists by describing dozens of use cases in six areas: ideation and feedback, writing, back-ground research, data analysis, coding, and mathematical derivations. I provide gen-eral instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of gener-ative AI to automate micro-tasks. Moreover, these gains will grow as the performance of AI systems continues to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources asso-ciated with this paper explain how to get started and will provide regular updates on the latest capabilities of generative AI in economics. (JEL A11, C45, D83, I23, O33)	[Korinek, Anton] Univ Virginia, Charlottesville, VA 22903 USA; [Korinek, Anton] Brookings Inst, Washington, DC 20036 USA; [Korinek, Anton] Ctr Governance AI GovAI, Oxford, England; [Korinek, Anton] NBER, Cambridge, MA 02138 USA; [Korinek, Anton] CEPR, London, England	University of Virginia; Brookings Institution; National Bureau of Economic Research; Centre for Economic Policy Research - UK	Korinek, A (corresponding author), Univ Virginia, Charlottesville, VA 22903 USA.; Korinek, A (corresponding author), Brookings Inst, Washington, DC 20036 USA.; Korinek, A (corresponding author), Ctr Governance AI GovAI, Oxford, England.; Korinek, A (corresponding author), NBER, Cambridge, MA 02138 USA.; Korinek, A (corresponding author), CEPR, London, England.	akorinek@virginia.edu						Agrawal A., 2018, Prediction Machines: The Simple Economics of Artificial Intelligence, DOI DOI 10.1080/15228053.2019.1673511; Anderljung M, 2023, Arxiv, DOI arXiv:2307.03718; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Ardekani Aref Mahdavi, 2023, EconSentGPT: A Universal Economic Sentiment Engine?, DOI [10.2139/ssrn.4405779, DOI 10.2139/SSRN.4405779]; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buchanan Joy, 2023, GPT-3.5 Hallucinates Nonexistent Citations: Evidence from Economics, DOI [10.2139/ssrn.4467968, DOI 10.2139/SSRN.4467968]; Carlsmith Joseph, 2020, Open PhilanthropySeptember 11; Charness Gary, 2023, NBER Working Paper 31679; Cowen Tyler, 2023, GMU Working Paper in Economics, P23; Deep Ganguli, 2022, P 2022 ACM C FAIRNES, P1747; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Dunn A., 2022, arXiv; Dziri N, 2023, Arxiv, DOI [arXiv:2305.18654, 10.48550/arXiv.2305.18654, DOI 10.48550/ARXIV.2305.18654]; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Felten E., 2023, How will Language Modelers like ChatGPT affect occupations and industries?, DOI [10.2139/ssrn.4375268, DOI 10.2139/SSRN.4375268]; Frank R.H., 1991, The strategy of choice, P25; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Gentzkow M, 2019, J ECON LIT, V57, P535, DOI 10.1257/jel.20181020; Girotra K, 2010, MANAGE SCI, V56, P591, DOI 10.1287/mnsc.1090.1144; Girotra Karan, 2023, Ideas are dimes a dozen: Large language models for idea generation in innovation, DOI DOI 10.2139/SSRN.4526071; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Horton JJ, 2023, 31122 NBER; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kasparov G., 2017, Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begin; Keynes John Maynard, 1936, GEN THEORY EMPLOYMEN; Knight Will, 2023, Wired17 April; Korinek Anton, 2023, The Oxford Handbook of AI Governance; Korinek Anton., 2023, NBER Working Paper 30957; Li KN, 2023, Arxiv, DOI [arXiv:2210.13382, DOI 10.48550/ARXIV.2210.13382]; Lopez-Lira A, 2023, Arxiv, DOI arXiv:2304.07619; Mollick E. R., 2023, USING IMPLEMENT EFFE, DOI [10.2139/ssrn.4391243, DOI 10.2139/SSRN.4391243]; Noorbakhsh K, 2021, Arxiv, DOI [arXiv:2110.03501, DOI 10.48550/ARXIV.2110.03501]; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Peng Sida, 2023, arXiv, DOI DOI 10.48550/ARXIV.2302.06590; Ricardo D., 1817, PRINCIPLES POLITICAL, V1; Sevilla J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891914; Silver D, 2017, Arxiv, DOI arXiv:1712.01815; Sutton R., 2019, Incomplete Ideas (blog)March 13; Thompson Alan D, 2023, GPT-3.5 and ChatGPT: An Illustrated Overview; Vaswani A, 2017, ADV NEUR IN, V30; Wei J., 2022, Advances in Neural Information Processing Systems, V35, p24 824; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Zou A, 2023, Arxiv, DOI arXiv:2307.15043	49	4	4	60	60	AMER ECONOMIC ASSOC	NASHVILLE	2014 BROADWAY, STE 305, NASHVILLE, TN 37203 USA	0022-0515	2328-8175		J ECON LIT	J. Econ. Lit.	DEC	2023	61	4					1281	1317		10.1257/jel.20231736	http://dx.doi.org/10.1257/jel.20231736			37	Economics	Social Science Citation Index (SSCI)	Business & Economics	FE7L3					2024-07-03	WOS:001144150800005
J	Zhang, CY; Xu, J; Tang, R; Yang, JH; Wang, W; Yu, XJ; Shi, S				Zhang, Chaoyi; Xu, Jin; Tang, Rong; Yang, Jianhui; Wang, Wei; Yu, Xianjun; Shi, Si			Novel research and future prospects of artificial intelligence in cancer diagnosis and treatment	JOURNAL OF HEMATOLOGY & ONCOLOGY			English	Review							MULTI-OMICS DATA; MACHINE LEARNING ALGORITHMS; PROSTATE-CANCER; PROGNOSTIC-FACTORS; TUMOR PROGRESSION; COLON-CANCER; PREDICTION; MODELS; IDENTIFICATION; METABOLOMICS	Research into the potential benefits of artificial intelligence for comprehending the intricate biology of cancer has grown as a result of the widespread use of deep learning and machine learning in the healthcare sector and the availability of highly specialized cancer datasets. Here, we review new artificial intelligence approaches and how they are being used in oncology. We describe how artificial intelligence might be used in the detection, prognosis, and administration of cancer treatments and introduce the use of the latest large language models such as ChatGPT in oncology clinics. We highlight artificial intelligence applications for omics data types, and we offer perspectives on how the various data types might be combined to create decision-support tools. We also evaluate the present constraints and challenges to applying artificial intelligence in precision oncology. Finally, we discuss how current challenges may be surmounted to make artificial intelligence useful in clinical settings in the future.	[Zhang, Chaoyi; Xu, Jin; Tang, Rong; Yang, Jianhui; Wang, Wei; Yu, Xianjun; Shi, Si] Fudan Univ, Shanghai Canc Ctr, Dept Pancreat Surg, 270 Dong An Rd, Shanghai 200032, Peoples R China; [Zhang, Chaoyi; Xu, Jin; Tang, Rong; Yang, Jianhui; Wang, Wei; Yu, Xianjun; Shi, Si] Fudan Univ, Shanghai Med Coll, Dept Oncol, Shanghai 200032, Peoples R China; [Zhang, Chaoyi; Xu, Jin; Tang, Rong; Yang, Jianhui; Wang, Wei; Yu, Xianjun; Shi, Si] Shanghai Pancreat Canc Inst, 399 Lingling Rd, Shanghai 200032, Peoples R China; [Zhang, Chaoyi; Xu, Jin; Tang, Rong; Yang, Jianhui; Wang, Wei; Yu, Xianjun; Shi, Si] Fudan Univ, Pancreat Canc Inst, Shanghai 200032, Peoples R China	Fudan University; Fudan University; Fudan University	Yu, XJ; Shi, S (corresponding author), Fudan Univ, Shanghai Canc Ctr, Dept Pancreat Surg, 270 Dong An Rd, Shanghai 200032, Peoples R China.; Yu, XJ; Shi, S (corresponding author), Fudan Univ, Shanghai Med Coll, Dept Oncol, Shanghai 200032, Peoples R China.; Yu, XJ; Shi, S (corresponding author), Shanghai Pancreat Canc Inst, 399 Lingling Rd, Shanghai 200032, Peoples R China.; Yu, XJ; Shi, S (corresponding author), Fudan Univ, Pancreat Canc Inst, Shanghai 200032, Peoples R China.	yuxianjun@fudanpci.org; shisi@fudanpci.org		Shi, Si/0000-0002-6652-0629	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Not applicable.	Abele N, 2023, MODERN PATHOL, V36, DOI 10.1016/j.modpat.2022.100033; Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873; Adeoye J, 2023, ORAL ONCOL, V136, DOI 10.1016/j.oraloncology.2022.106278; Adepu AK, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106571; Afrash MR, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02154-y; Agarwala PK, 2022, MED RES REV, V42, P983, DOI 10.1002/med.21868; Ahmedt-Aristizabal D, 2023, COMPUT METH PROG BIO, V232, DOI 10.1016/j.cmpb.2023.107451; Akselrod-Ballin A, 2019, RADIOLOGY, V292, P331, DOI 10.1148/radiol.2019182622; Alakwaa FM, 2018, J PROTEOME RES, V17, P337, DOI 10.1021/acs.jproteome.7b00595; Alhazmi A, 2021, J ORAL PATHOL MED, V50, P444, DOI 10.1111/jop.13157; Ali A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020572; [Anonymous], 2023, LANCET, V401, P319, DOI [10.1016/s0140-6736(23)00234-9, 10.1016/S0140-6736(23)00234-9]; Areia M, 2022, LANCET DIGIT HEALTH, V4, pE436, DOI 10.1016/S2589-7500(22)00042-5; Arya N, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30143-8; Aung TN, 2022, EBIOMEDICINE, V82, DOI [10.1016/j.ebiom2202.104143, 10.1016/j.ebiom.2022.104143]; Azad R, 2024, MED IMAGE ANAL, V91, DOI 10.1016/j.media.2023.103000; Tosta TAA, 2019, ARTIF INTELL MED, V95, P118, DOI 10.1016/j.artmed.2018.10.004; Bae S, 2021, NUCLEIC ACIDS RES, V49, DOI 10.1093/nar/gkab095; Balasubramaniam S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13172746; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Baralou V, 2023, BIOMETRICAL J, V65, DOI 10.1002/bimj.202100380; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Bergenstråhle L, 2022, NAT BIOTECHNOL, V40, P476, DOI 10.1038/s41587-021-01075-3; Bertsimas D, 2022, JAMA SURG, V157, DOI 10.1001/jamasurg.2022.1819; Bilal M, 2021, LANCET DIGIT HEALTH, V3, pE763, DOI 10.1016/S2589-7500(21)00180-1; Blessin NC, 2023, J PATHOL, V260, P5, DOI 10.1002/path.6057; Bray F, 2012, LANCET ONCOL, V13, P790, DOI 10.1016/S1470-2045(12)70211-5; Brown JRG, 2022, CLIN GASTROENTEROL H, V20, P1499, DOI 10.1016/j.cgh.2021.09.009; Chang XA, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2022.100914; Chen CK, 2022, NAT BIOMED ENG, V6, P1420, DOI 10.1038/s41551-022-00929-8; Chen CC, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms24108807; Chen HZ, 2019, SEMIN CANCER BIOL, V55, P16, DOI 10.1016/j.semcancer.2018.05.009; Chen RJ, 2022, CANCER CELL, V40, P865, DOI 10.1016/j.ccell.2022.07.004; Chen ST, 2023, BRIT J CANCER, V129, P46, DOI 10.1038/s41416-023-02262-6; Choi JM, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05273-5; Conant EF, 2019, JAMA ONCOL, V5, P635, DOI 10.1001/jamaoncol.2018.7078; Cricelli I, 2022, CURR MED RES OPIN, V38, P827, DOI 10.1080/03007995.2022.2052513; Dang PA, 2014, RADIOLOGY, V270, P49, DOI 10.1148/radiol.13130765; Dascalu A, 2019, EBIOMEDICINE, V43, P107, DOI 10.1016/j.ebiom.2019.04.055; Dawwas MF, 2014, NEW ENGL J MED, V370, P2539, DOI [10.1056/NEJMoa1309086, 10.1056/NEJMc1405329]; Deeb SJ, 2015, MOL CELL PROTEOMICS, V14, P2947, DOI 10.1074/mcp.M115.050245; Demirjian NL, 2022, EUR RADIOL, V32, P2552, DOI 10.1007/s00330-021-08344-4; Deng ST, 2023, BMC CANCER, V23, DOI 10.1186/s12885-023-11130-8; Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593; DePeaux K, 2021, NAT REV IMMUNOL, V21, P785, DOI 10.1038/s41577-021-00541-y; Ding HL, 2023, HISTOPATHOLOGY, V83, P211, DOI 10.1111/his.14918; Ding KX, 2022, LANCET DIGIT HEALTH, V4, pE787, DOI 10.1016/S2589-7500(22)00168-6; DiSpirito A, 2021, EXP BIOL MED, V246, P1355, DOI 10.1177/15353702211000310; Dong H, 2020, PROTEOMICS, V20, DOI 10.1002/pmic.201900344; Eden KB, 2020, J WOMENS HEALTH, V29, P763, DOI 10.1089/jwh.2019.8143; Eloy C, 2023, VIRCHOWS ARCH, V482, P595, DOI 10.1007/s00428-023-03518-5; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Fadafen MK, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35431-x; Faiella E, 2022, TOMOGRAPHY, V8, P2010, DOI 10.3390/tomography8040168; Fanizzi A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35344-9; Fenaux P, 2009, LANCET ONCOL, V10, P223, DOI 10.1016/S1470-2045(09)70003-8; Finn CB, 2023, JCO CLIN CANCER INFO, V7, DOI 10.1200/CCI.23.00003; Franciosa G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22787-9; Freeman K, 2021, BMJ-BRIT MED J, V374, DOI 10.1136/bmj.n1872; Freeman K, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m127; Gao PY, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.25608; Gao Y, 2023, LANCET GASTROENTEROL, V8, P432, DOI 10.1016/S2468-1253(23)00004-3; Gerwert K, 2023, EUR J CANCER, V182, P122, DOI 10.1016/j.ejca.2022.12.026; Gould MK, 2021, AM J RESP CRIT CARE, V204, P445, DOI 10.1164/rccm.202007-2791OC; Grosu S, 2021, RADIOLOGY, V299, P326, DOI 10.1148/radiol.2021202363; Guan X, 2023, DIGEST DIS SCI, V68, P1473, DOI 10.1007/s10620-022-07640-3; Gupta P, 2022, J BIOL CHEM, V298, DOI 10.1016/j.jbc.2022.102177; Hassan C, 2022, CLIN GASTROENTEROL H, V20, P2505, DOI 10.1016/j.cgh.2022.04.045; He B, 2020, NAT BIOMED ENG, V4, P827, DOI 10.1038/s41551-020-0578-x; He XJ, 2023, SEMIN CANCER BIOL, V88, P187, DOI 10.1016/j.semcancer.2022.12.009; Hofvind S, 2019, LANCET ONCOL, V20, P795, DOI 10.1016/S1470-2045(19)30161-5; Hollon T, 2023, NAT MED, V29, DOI 10.1038/s41591-023-02252-4; Hosny A, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002711; Khatibi SMH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20783-7; Hu J, 2023, CELL SYST, V14, P404, DOI 10.1016/j.cels.2023.03.008; Huang BL, 2021, EBIOMEDICINE, V73, DOI 10.1016/j.ebiom.2021.103631; Huang HH, 2021, IEEE ACM T COMPUT BI, V18, P1821, DOI 10.1109/TCBB.2019.2961667; Huang L, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17347-6; Huang P, 2019, LANCET DIGIT HEALTH, V1, pE353, DOI 10.1016/S2589-7500(19)30159-1; Huang ZM, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac117; Ishii H, 2020, BRIT J CANCER, V122, P995, DOI 10.1038/s41416-020-0732-y; Jha A, 2022, GENOME BIOL, V23, DOI 10.1186/s13059-022-02681-3; Ji MM, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms231911476; Kehl KL, 2020, JCO CLIN CANCER INFO, V4, P680, DOI 10.1200/CCI.20.00020; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Keyl P, 2023, NUCLEIC ACIDS RES, V51, DOI 10.1093/nar/gkac1212; Khadirnaikar S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31426-w; Khan MS, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105581; Kim H, 2019, J PROTEOME RES, V18, P3195, DOI 10.1021/acs.jproteome.9b00268; Kim I, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112794; Kim Y, 2023, RADIOTHER ONCOL, V183, DOI 10.1016/j.radonc.2023.109617; Kleppe A, 2022, LANCET ONCOL, V23, P1221, DOI 10.1016/S1470-2045(22)00391-6; Knabe M, 2022, ENDOSCOPY, V54, P1191, DOI 10.1055/a-1811-9407; Konishi Y, 2022, CANCER MED-US, V11, P3194, DOI 10.1002/cam4.4671; Korfiati A, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms23031299; Kränke T, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0280670; Kudo S, 2021, GASTROENTEROLOGY, V160, P1075, DOI 10.1053/j.gastro.2020.09.027; Kumar R, 2022, COMPUT MED IMAG GRAP, V102, DOI 10.1016/j.compmedimag.2022.102139; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee C, 2021, LANCET DIGIT HEALTH, V3, pE158, DOI 10.1016/S2589-7500(20)30314-9; Lee W, 2022, INT J SURG, V105, DOI 10.1016/j.ijsu.2022.106851; Lewis SM, 2021, NAT METHODS, V18, P997, DOI 10.1038/s41592-021-01203-6; Li CF, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04277-2; Li J, 2022, FRONT IMMUNOL, V13, DOI 10.3389/fimmu.2022.998140; Li JB, 2023, BMC CANCER, V23, DOI 10.1186/s12885-023-10893-4; Li J, 2023, FRONT IMMUNOL, V14, DOI 10.3389/fimmu.2023.1196054; Li NN, 2022, INT J BIOCHEM CELL B, V153, DOI 10.1016/j.biocel.2022.106315; Li X, 2023, IEEE J TRANSL ENG HE, V11, P441, DOI 10.1109/JTEHM.2023.3289990; Li XJ, 2022, INT J SURG, V105, DOI 10.1016/j.ijsu.2022.106889; Li YC, 2023, COMPUT BIOL MED, V165, DOI 10.1016/j.compbiomed.2023.107374; Liang CA, 2019, ANN CLIN LAB SCI, V49, P119; Liang J, 2023, J BIOMED INFORM, V146, DOI 10.1016/j.jbi.2023.104480; Liang SJ, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/aca516; Lin HJ, 2019, IEEE T MED IMAGING, V38, P1948, DOI 10.1109/TMI.2019.2891305; Liu CY, 2018, J MED INTERNET RES, V20, DOI 10.2196/11087; Liu P, 2024, MED IMAGE ANAL, V91, DOI 10.1016/j.media.2023.103020; Liu Y, 2018, CANCER CELL, V33, P721, DOI 10.1016/j.ccell.2018.03.010; Liu YB, 2023, CLIN EXP MED, V23, P1649, DOI 10.1007/s10238-022-00896-z; Lococo F, 2023, BMC CANCER, V23, DOI 10.1186/s12885-023-10997-x; López-Sánchez LM, 2019, J CELL MOL MED, V23, P8219, DOI 10.1111/jcmm.14693; Lu MT, 2020, ANN INTERN MED, V173, P704, DOI 10.7326/M20-1868; Lu MY, 2021, NATURE, V594, P106, DOI 10.1038/s41586-021-03512-4; Ludwig C, 2018, MOL SYST BIOL, V14, DOI 10.15252/msb.20178126; Luo XD, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102287; Lv WB, 2023, COMPUT METH PROG BIO, V230, DOI 10.1016/j.cmpb.2023.107341; Ma YL, 2012, ANN SURG, V255, P720, DOI 10.1097/SLA.0b013e31824a9a8b; Manzi M, 2021, J PROTEOME RES, V20, P841, DOI 10.1021/acs.jproteome.0c00663; Marchetti MA, 2023, J EUR ACAD DERMATOL, V37, P945, DOI 10.1111/jdv.18924; Mathios D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24994-w; Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1038/s41591-020-0931-3, 10.1101/2020.04.12.20062661]; Mikhael PG, 2023, J CLIN ONCOL, V41, P2191, DOI 10.1200/JCO.22.01345; Moor J, 2006, AI MAG, V27, P87; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Moreno V, 2015, BMC MED, V13, DOI 10.1186/s12916-015-0307-6; Murai H, 2023, HEPATOLOGY, V77, P77, DOI 10.1002/hep.32573; Murata T, 2019, BREAST CANCER RES TR, V177, P591, DOI 10.1007/s10549-019-05330-9; Nam JG, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.221894; Niehoff JH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30521-2; Niehues JM, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.100980; Nimgaonkar V, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.101013; Nwaokorie A, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22189970; Ogunleye AZ, 2022, ADV SCI, V9, DOI 10.1002/advs.202201501; Park MK, 2022, BIOMOLECULES, V12, DOI 10.3390/biom12121839; Pattacini P, 2018, RADIOLOGY, V288, P375, DOI 10.1148/radiol.2018172119; Pérez-Cota F, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-42793-9; Qiu YPL, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20167-3; Quail DF, 2013, NAT MED, V19, P1423, DOI 10.1038/nm.3394; Raab SS, 2010, CA-CANCER J CLIN, V60, P139, DOI 10.3322/caac.20068; Raghu VK, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.48793; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Raju S, 2023, NETWORK-COMP NEURAL, DOI 10.1080/0954898X.2023.2275045; Rana A, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.5111; Remedios D, 2023, EUR RADIOL, V33, P4226, DOI 10.1007/s00330-023-09566-4; Rezaeilouyeh H, 2014, IEEE ENG MED BIO, P6442, DOI 10.1109/EMBC.2014.6945103; Rodrigues J, 2021, LAB INVEST, V101, P952, DOI 10.1038/s41374-021-00597-3; Rönnau MM, 2023, COMPUT METH PROG BIO, V242, DOI 10.1016/j.cmpb.2023.107788; Sahraeian SME, 2022, GENOME BIOL, V23, DOI 10.1186/s13059-021-02592-9; Saito S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-32987-6; Sammut SJ, 2022, NATURE, V601, P623, DOI 10.1038/s41586-021-04278-5; Sanders LM, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-04075-4; Sangers TE, 2021, BRIT J DERMATOL, V185, P961, DOI 10.1111/bjd.20441; Saravanan KA, 2022, GENE, V823, DOI 10.1016/j.gene.2022.146387; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Schmauch B, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17678-4; Schneider G, 2017, NAT REV CANCER, V17, P239, DOI 10.1038/nrc.2017.5; Seager A, 2022, COLORECTAL DIS, V24, P1227, DOI 10.1111/codi.16219; Sengupta A, 2021, ADV PROTEIN CHEM STR, V127, P161, DOI 10.1016/bs.apcsb.2021.02.003; Sharma A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29644-3; She YL, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.5842; Shihabuddin AR, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106815; Shoshan Y, 2022, RADIOLOGY, V303, P69, DOI 10.1148/radiol.211105; Silver FH, 2023, CANCERS, V15, DOI 10.3390/cancers15010156; Sim Y, 2020, RADIOLOGY, V294, P199, DOI 10.1148/radiol.2019182465; Singh MP, 2021, GENES DIS, V8, P133, DOI 10.1016/j.gendis.2019.10.013; Singh T, 2022, GENES-BASEL, V13, DOI 10.3390/genes13122379; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sinonquel P, 2021, GUT, V70, P641, DOI 10.1136/gutjnl-2020-322491; Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8; Soares F, 2017, ARTIF INTELL MED, V82, P1, DOI 10.1016/j.artmed.2017.09.004; Somashekhar SP, 2018, ANN ONCOL, V29, P418, DOI 10.1093/annonc/mdx781; Srivastava R, 2023, J CANCER RES CLIN, V149, P503, DOI 10.1007/s00432-022-04161-4; Ståhl PL, 2016, SCIENCE, V353, P78, DOI 10.1126/science.aaf2403; Stamatoyannopoulos JA, 2012, GENOME RES, V22, P1602, DOI 10.1101/gr.146506.112; Sun JX, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005965; Tajerian A, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0284437; Tan RSYC, 2023, J AM MED INFORM ASSN, V30, P1657, DOI 10.1093/jamia/ocad133; Tang ZY, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-41437-w; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tian M, 2021, MOLECULES, V26, DOI 10.3390/molecules26092715; Tian T, 2023, BIOMETRICAL J, V65, DOI 10.1002/bimj.202100310; Tian Y, 2023, IEEE ACM T COMP BIOL; Tong R, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e16068; Troya J, 2022, GASTROINTEST ENDOSC, V95, P794, DOI 10.1016/j.gie.2021.12.003; Tsimberidou AM, 2022, SEMIN CANCER BIOL, V84, P50, DOI 10.1016/j.semcancer.2020.09.007; Ul Ain Q, 2023, IEEE T CYBERNETICS, V53, P2727, DOI 10.1109/TCYB.2022.3182474; van der Laak J, 2021, NAT MED, V27, P775, DOI 10.1038/s41591-021-01343-4; van der Voort SR, 2023, NEURO-ONCOLOGY, V25, P279, DOI 10.1093/neuonc/noac166; Venkadesh KV, 2021, RADIOLOGY, V300, P438, DOI 10.1148/radiol.2021204433; Venugopal V, 2022, COMPUT METH PROG BIO, V222, DOI 10.1016/j.cmpb.2022.106935; Verghese G, 2023, J PATHOL, V260, P376, DOI 10.1002/path.6088; Vermeulen C, 2023, NATURE, V622, P842, DOI 10.1038/s41586-023-06615-2; Veta M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070221; Vogelstein B, 2013, SCIENCE, V339, P1546, DOI 10.1126/science.1235122; Walker BN, 2019, EBIOMEDICINE, V40, P176, DOI 10.1016/j.ebiom.2019.01.028; Wallace PW, 2020, J PATHOL, V251, P378, DOI 10.1002/path.5472; Wang CW, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms24032521; Wang GX, 2022, SCI TRANSL MED, V14, DOI 10.1126/scitranslmed.abk2756; Wang HM, 2023, ANAL CHEM, V95, P6533, DOI 10.1021/acs.analchem.2c05079; Wang JY, 2023, RADIAT ONCOL, V18, DOI 10.1186/s13014-023-02246-z; Wang J, 2023, BMC CANCER, V23, DOI 10.1186/s12885-023-11432-x; Wang R, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106880; Wang SS, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03783-0; Wang ST, 2022, IEEE T CYBERNETICS, V52, P12623, DOI 10.1109/TCYB.2021.3069920; Wang Y, 2022, ANN ONCOL, V33, P89, DOI 10.1016/j.annonc.2021.09.007; Wang YW, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102693; Weidener L, 2023, PERSPECT MED EDUC, V12, P399, DOI 10.5334/pme.954; Weitz P, 2022, BIOINFORMATICS, V38, P3462, DOI 10.1093/bioinformatics/btac343; Wesp P, 2022, EUR RADIOL, V32, P4749, DOI 10.1007/s00330-021-08532-2; Wishart DS, 2019, PHYSIOL REV, V99, P1819, DOI 10.1152/physrev.00035.2018; Wong CC, 2019, SEMIN CANCER BIOL, V55, P90, DOI 10.1016/j.semcancer.2018.04.002; Wu SX, 2023, LANCET ONCOL, V24, P360, DOI 10.1016/S1470-2045(23)00061-X; Xu H, 2023, CLIN GASTROENTEROL H, V21, DOI 10.1016/j.cgh.2022.07.006; Xu YX, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106882; Yang H, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbac528; Yang JW, 2023, NAT REV CLIN ONCOL, V20, P211, DOI 10.1038/s41571-023-00729-2; Yao YF, 2023, CYTOM PART A, V103, P646, DOI 10.1002/cyto.a.24731; Ye XT, 2021, ANAL CHIM ACTA, V1173, DOI 10.1016/j.aca.2021.338672; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Yi L, 2023, IEEE T MED IMAGING, V42, P317, DOI 10.1109/TMI.2022.3211085; Yi ZL, 2022, EUR J NUCL MED MOL I, V49, P1523, DOI 10.1007/s00259-021-05631-6; Yoo H, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.17135; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Yu SH, 2021, WORLD J UROL, V39, P407, DOI 10.1007/s00345-020-03214-y; Yuan YY, 2021, BRIT J CANCER, V125, P351, DOI 10.1038/s41416-021-01395-w; Yun HJ, 2021, FRONT ENDOCRINOL, V12, DOI 10.3389/fendo.2021.585364; Zafari N, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106639; Zaitsev A, 2022, CANCER CELL, V40, P879, DOI 10.1016/j.ccell.2022.07.006; Zhang GS, 2023, MED PHYS, V50, P4505, DOI 10.1002/mp.16417; Zhang H, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac386; Zhang JFK, 2022, CELLS-BASEL, V11, DOI 10.3390/cells11040716; Zhang K, 2021, NAT BIOMED ENG, V5, P533, DOI 10.1038/s41551-021-00745-6; Zhang N, 2022, THERANOSTICS, V12, P5931, DOI 10.7150/thno.74281; Zhang SW, 2022, GENOM PROTEOM BIOINF, V20, P928, DOI 10.1016/j.gpb.2022.11.004; Zhang TY, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.101131; Zhang XY, 2023, CANCER MED-US, V12, P7508, DOI 10.1002/cam4.5478; Zhao JJ, 2022, RADIOTHER ONCOL, V167, P195, DOI 10.1016/j.radonc.2021.12.031; Zhao WY, 2022, BIOINFORMATICS, V38, P4901, DOI 10.1093/bioinformatics/btac622; Zhou HY, 2023, NAT BIOMED ENG, V7, P743, DOI 10.1038/s41551-023-01045-x; Zhou JT, 2022, EBIOMEDICINE, V81, DOI 10.1016/j.ebiom.2022.104097; Zhou M, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa047; Zhou PY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18879-1; Zhou X, 2020, GIGASCIENCE, V9, DOI 10.1093/gigascience/giaa076; Zhu J, 2023, FRONT IMMUNOL, V14, DOI 10.3389/fimmu.2023.1142609; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	254	5	6	38	44	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1756-8722		J HEMATOL ONCOL	J. Hematol. Oncol.	NOV 27	2023	16	1							114	10.1186/s13045-023-01514-5	http://dx.doi.org/10.1186/s13045-023-01514-5			29	Oncology; Hematology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology; Hematology	Z7UO3	38012673	gold			2024-07-03	WOS:001114093100001
J	Zhang, ZH; Yu, WH; Ning, Z; Ju, MX; Jiang, M				Zhang, Zhihan; Yu, Wenhao; Ning, Zheng; Ju, Mingxuan; Jiang, Meng			Exploring Contrast Consistency of Open-Domain Question Answering Systems on Minimally Edited Questions	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								Contrast consistency, the ability of a model to make consistently correct predictions in the presence of perturbations, is an essential aspect in NLP. While studied in tasks such as sentiment analysis and reading comprehension, it remains unexplored in open-domain question answering (OpenQA) due to the difficulty of collecting perturbed questions that satisfy factuality requirements. In this work, we collect minimally edited questions as challenging contrast sets to evaluate OpenQA models. Our collection approach combines both human annotation and large language model generation. We find that the widely used dense passage retriever (DPR) performs poorly on our contrast sets, despite fitting the training set well and performing competitively on standard test sets. To address this issue, we introduce a simple and effective query-side contrastive loss with the aid of data augmentation to improve DPR training. Our experiments on the contrast sets demonstrate that DPR's contrast consistency is improved without sacrificing its accuracy on the standard test sets.(1)	[Zhang, Zhihan; Yu, Wenhao; Ning, Zheng; Ju, Mingxuan; Jiang, Meng] Univ Notre Dame, Notre Dame, IN 46556 USA	University of Notre Dame	Zhang, ZH (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.	zzhang23@nd.edu; wyu1@nd.edu; zning@nd.edu; mju2@nd.edu; mjiang2@nd.edu	Jiang, Meng/AAE-4976-2020; zhang, zhihan/JGD-2118-2023	Jiang, Meng/0000-0002-3009-519X; 	NSF [IIS-2119531, IIS-2137396, IIS-2142827, CCF-1901059, ONR N00014-22-1-2507]; Bloomberg Data Science PhD Fellowship	NSF(National Science Foundation (NSF)); Bloomberg Data Science PhD Fellowship	This work was supported in part by NSF IIS-2119531, IIS-2137396, IIS-2142827, CCF-1901059, and ONR N00014-22-1-2507. Wenhao Yu is also supported in part by Bloomberg Data Science PhD Fellowship. We would like to thank the anonymous reviewers and the action editor for their valuable suggestions to this paper.	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fajcik M, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P854; Gao LY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P981; Gardner M, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1307; Izacard G, 2022, Arxiv, DOI [arXiv:2112.09118, DOI 10.48550/ARXIV.2112.09118]; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kaushik Divyansh., 2020, 8 INT C LEARN REPR I; Kedia Akhil., 2022, P 2022 C EMP METH NA; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lewis P, 2021, T ASSOC COMPUT LING, V9, P1098, DOI 10.1162/tacl_a_00415; Li D, 2022, arXiv; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Longpre S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7052; Min S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5783; Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P314; Ni Jianmo, 2022, P 2022 C EMPIRICAL M, P9844; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Paranjape B, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1670; Park JS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3574; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Ross A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3194; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Tiedemann J., 2020, P 22 ANN C EUROPEAN, P479; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wenhao Yu., 2023, The Eleventh International Conference on Learning Representations, ICLR 2023; Wu Tongshuang, 2021, P 59 ANN M ASS COMP, DOI DOI 10.18653/V1/2021.ACL-LONG.523; Ye X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5496; Zhu FB, 2021, Arxiv, DOI [arXiv:2101.00774, DOI 10.48550/ARXIV.2101.00774]	35	0	0	5	10	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	AUG 15	2023	11						1082	1096		10.1162/tacl_a_00591	http://dx.doi.org/10.1162/tacl_a_00591			15	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	P3AF0		Green Submitted, gold			2024-07-03	WOS:001049392500008
J	Yang, JW; Ardavanis, KS; Slack, KE; Fernando, ND; Della Valle, CJ; Hernandez, NM				Yang, Jaewon; Ardavanis, Kyle S.; Slack, Katherine E.; Fernando, Navin D.; Della Valle, Craig J.; Hernandez, Nicholas M.			Chat Generative Pretrained Transformer (ChatGPT) and Bard: Artificial Intelligence Does not yet Provide Clinically Supported Answers for Hip and Knee Osteoarthritis	JOURNAL OF ARTHROPLASTY			English	Article						ChatGPT; bard; machine learning; artificial intelligence; large language models	LEARNING ALGORITHM; COMPLICATIONS; ARTHROPLASTY	Background: Advancements in artificial intelligence (AI) have led to the creation of large language models (LLMs), such as Chat Generative Pretrained Transformer (ChatGPT) and Bard, that analyze online resources to synthesize responses to user queries. Despite their popularity, the accuracy of LLM responses to medical questions remains unknown. This study aimed to compare the responses of ChatGPT and Bard regarding treatments for hip and knee osteoarthritis with the American Academy of Orthopaedic Surgeons (AAOS) Evidence-Based Clinical Practice Guidelines (CPGs) recommendations. Methods: Both ChatGPT (Open AI) and Bard (Google) were queried regarding 20 treatments (10 for hip and 10 for knee osteoarthritis) from the AAOS CPGs. Responses were classified by 2 reviewers as being in "Concordance, " "Discordance, " or "No Concordance " with AAOS CPGs. A Cohen 's Kappa coefficient was used to assess inter -rater reliability, and Chi -squared analyses were used to compare responses between LLMs. Results: Overall, ChatGPT and Bard provided responses that were concordant with the AAOS CPGs for 16 (80%) and 12 (60%) treatments, respectively. Notably, ChatGPT and Bard encouraged the use of nonrecommended treatments in 30% and 60% of queries, respectively. There were no differences in performance when evaluating by joint or by recommended versus non-recommended treatments. Studies were referenced in 6 (30%) of the Bard responses and none (0%) of the ChatGPT responses. Of the 6 Bard responses, studies could only be identified for 1 (16.7%). Of the remaining, 2 (33.3%) responses cited studies in journals that did not exist, 2 (33.3%) cited studies that could not be found with the information given, and 1 (16.7%) provided links to unrelated studies. Conclusions: Both ChatGPT and Bard do not consistently provide responses that align with the AAOS CPGs. Consequently, physicians and patients should temper expectations on the guidance AI platforms can currently provide. (c) 2024 Elsevier Inc. All rights reserved.	[Yang, Jaewon; Fernando, Navin D.; Hernandez, Nicholas M.] Univ Washington, Dept Orthopaed Surg, Seattle, WA USA; [Ardavanis, Kyle S.] Madigan Army Med Ctr, Dept Orthopaed Surg, Tacoma, WA 98431 USA; [Slack, Katherine E.] Washington State Univ, Elson S Floyd Coll Med, Spokane, WA USA; [Della Valle, Craig J.] Rush Univ, Dept Orthopaed Surg, Med Ctr, Chicago, IL USA; [Yang, Jaewon] Univ Washington, Dept Orthopaed & Sports Med, Seattle, WA 98104 USA	University of Washington; University of Washington Seattle; Madigan Army Medical Center; Washington State University; Rush University; University of Washington; University of Washington Seattle	Yang, JW (corresponding author), Univ Washington, Dept Orthopaed & Sports Med, Seattle, WA 98104 USA.			Fernando, Navin/0000-0002-2777-0174; Slack, Katherine/0000-0002-9366-1267; Yang, JaeWon/0000-0002-5470-0112				Abraham VM, 2022, CLIN ORTHOP RELAT R, V480, P2137, DOI 10.1097/CORR.0000000000002276; American Academy of Orthopaedic Surgeons, 2017, Management of Osteoarthritis of the Hip Evidence-Based Clinical Practice Guideline; Cabitza F, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00075; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Daraz L, 2019, J GEN INTERN MED, V34, P1884, DOI 10.1007/s11606-019-05109-0; De Cassai A, 2024, REGION ANESTH PAIN M, V49, P378, DOI 10.1136/rapm-2023-104771; Devana SK, 2021, ARTHROPLAST TODAY, V10, P135, DOI 10.1016/j.artd.2021.06.020; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; El Dahdah J, 2023, ANN EMERG MED, V82, P411, DOI 10.1016/j.annemergmed.2023.04.027; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gong ZB, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16534-3; Groot OQ, 2022, J ORTHOP RES, V40, P475, DOI 10.1002/jor.25036; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Hamed E, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38784; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Karnuta JM, 2023, J ARTHROPLASTY, V38, P1998, DOI 10.1016/j.arth.2022.03.002; Karnuta JM, 2021, J ARTHROPLASTY, V36, pS290, DOI 10.1016/j.arth.2020.11.015; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Lazic I, 2022, J CLIN MED, V11, DOI 10.3390/jcm11082147; Liu PR, 2021, CURR MED SCI, V41, P1158, DOI 10.1007/s11596-021-2501-4; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Magruder ML, 2023, J ARTHROPLASTY, V38, P2191, DOI 10.1016/j.arth.2023.06.030; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Medenilla A., 2023, PLoS Digital Health, V2; Polesie S, 2023, ACTA DERM-VENEREOL, V103, DOI 10.2340/actadv.v103.9593; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Ramkumar PN, 2019, J ARTHROPLASTY, V34, P2253, DOI 10.1016/j.arth.2019.05.021; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shademan A, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aad9398; Shen TS, 2021, J ARTHROPLASTY, V36, P1224, DOI 10.1016/j.arth.2020.10.024; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sun YL, 2019, J MED INTERNET RES, V21, DOI 10.2196/12522; Van Riel Noor, 2017, BJGP Open, V1, pbjgpopen17X100833, DOI 10.3399/bjgpopen17X100833; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang J, 2018, AM J MED, V131, DOI 10.1016/j.amjmed.2018.04.019; Wei JC, 2022, SKELETAL RADIOL, V51, P2121, DOI 10.1007/s00256-022-04077-7; Wei JC, 2022, EMERG RADIOL, V29, P801, DOI 10.1007/s10140-022-02060-2; Wu CL, 2023, REGION ANESTH PAIN M, DOI 10.1136/rapm-2023-104646; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	41	2	2	0	0	CHURCHILL LIVINGSTONE INC MEDICAL PUBLISHERS	PHILADELPHIA	CURTIS CENTER, INDEPENDENCE SQUARE WEST, PHILADELPHIA, PA 19106-3399 USA	0883-5403	1532-8406		J ARTHROPLASTY	J. Arthroplast.	MAY	2024	39	5					1184	1190		10.1016/j.arth.2024.01.029	http://dx.doi.org/10.1016/j.arth.2024.01.029			7	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	SG7N5	38237878				2024-07-03	WOS:001233370000001
C	Ayoobi, N; Shahriar, S; Mukherjee, A			ACM	Ayoobi, Navid; Shahriar, Sadat; Mukherjee, Arjun			The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention	34TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, HT 2023			English	Proceedings Paper	34th ACM Conference on Hypertext and Social Media (HT)	SEP 04-08, 2023	Max Planck Inst Art Hist, Bibliotheca Hertziana, Rome, ITALY	Assoc Comp Machinery, Knowledge Media Inst, Open Univ, Hypertext Steering Comm, SigWeb	Max Planck Inst Art Hist, Bibliotheca Hertziana	Fake accounts; LinkedIn; Large language models; LinkedIn dataset; ChatGPT		In this paper, we present a novel method for detecting fake and Large Language Model (LLM)-generated profiles in the LinkedIn Online Social Network immediately upon registration and before establishing connections. Early fake profile identification is crucial to maintaining the platform's integrity since it prevents imposters from acquiring the private and sensitive information of legitimate users and from gaining an opportunity to increase their credibility for future phishing and scamming activities. This work uses textual information provided in LinkedIn profiles and introduces the Section and Subsection Tag Embedding (SSTE) method to enhance the discriminative characteristics of these data for distinguishing between legitimate profiles and those created by imposters manually or by using an LLM. Additionally, the dearth of a large publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn profiles for our research. We release our dataset publicly for research purposes. This is, to the best of our knowledge, the first large publicly available LinkedIn dataset for fake LinkedIn account detection. Within our paradigm, we assess static and contextualized word embeddings, including GloVe, Flair, BERT, and RoBERTa. We show that the suggested method can distinguish between legitimate and fake profiles with an accuracy of about 95% across all word embeddings. In addition, we show that SSTE has a promising accuracy for identifying LLM-generated profiles, despite the fact that no LLM-generated profiles were employed during the training phase, and can achieve an accuracy of approximately 90% when only 20 LLM-generated profiles are added to the training set. It is a significant finding since the proliferation of several LLMs in the near future makes it extremely challenging to design a single system that can identify profiles created with various LLMs.	[Ayoobi, Navid; Shahriar, Sadat; Mukherjee, Arjun] Univ Houston, Houston, TX 77004 USA	University of Houston System; University of Houston	Ayoobi, N (corresponding author), Univ Houston, Houston, TX 77004 USA.	nayoobi@CougarNet.UH.EDU; sshahria@CougarNet.UH.EDU; arjun@cs.uh.edu	Mukherjee, Arjun/KIC-5499-2024	Mukherjee, Arjun/0000-0002-8896-604X	ARO [W911NF-20-1-0254]	ARO	This research was supported in part by grant ARO W911NF-20-1-0254. The views and conclusions contained in this document are those of the authors and not of the sponsors. The authors also would like to acknowledge the important contribution made by David Chamberlin, Steve Elliott, and other LinkedIn users who helped us in the collection of the dataset used in this research.	Adewole KS, 2019, MULTIMED TOOLS APPL, V78, P3925, DOI 10.1007/s11042-017-5018-x; Adikari S, 2020, Arxiv, DOI [arXiv:2006.01381, 10.48550/arXiv.2006.01381]; Akbik A., 2018, P 27 INT C COMP LING, P1638; Al-Zoubi AM, 2017, INT CONF INFORM COMM, P130, DOI 10.1109/IACS.2017.7921959; [Anonymous], 2015, P 8 ACM WORKSHOP ART, DOI 10.1145/2808769.2808779; Breuer A, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1287, DOI 10.1145/3366423.3380204; Cresci S, 2015, DECIS SUPPORT SYST, V80, P56, DOI 10.1016/j.dss.2015.09.003; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Kaubiyal J, 2018, 3RD INTERNATIONAL CONFERENCE ON BIG DATA AND INTERNET OF THINGS (BDIOT 2019), P135, DOI 10.1145/3361758.3361784; Khaled S, 2018, IEEE INT CONF BIG DA, P3672, DOI 10.1109/BigData.2018.8621913; Kondeti P., 2021, Evolutionary Computing and Mobile Sustainable Networks: Proceedings of ICECMSN 2020, P791; Kontaxis G., 2011, 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops 2011). PerCom-Workshops 2011: 2011 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops 2011), P295, DOI 10.1109/PERCOMW.2011.5766886; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Prieto VM, 2013, INT J ADV COMPUT SC, V4, P189; Roy Pradeep Kumar, 2020, IEEE Transactions on Artificial Intelligence, V1, P271, DOI 10.1109/TAI.2021.3064901; Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771; Slater-Robins Max, 2022, LinkedIn has a problem with fake profiles; Wanda P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102465; Wani MA, 2019, INT CONF COMMUN SYST, P145, DOI [10.1109/comsnets.2019.8711124, 10.1109/COMSNETS.2019.8711124]; Yuan D, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1423, DOI 10.1145/3319535.3363198	22	1	1	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0232-7				2023										10.1145/3603163.3609064	http://dx.doi.org/10.1145/3603163.3609064			10	Computer Science, Information Systems; Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Communication	BW2LW		Green Submitted			2024-07-03	WOS:001118858800038
J	Xing, F				Xing, Frank			Financial risk tolerance profiling from text	INFORMATION PROCESSING & MANAGEMENT			English	Article						Artificial intelligence in finance; Risk tolerance; Risk profiling; Text mining; Convolutional neural network	PERSONALITY-TRAITS; DECISION-MAKING; STYLES	Traditionally, individual financial risk tolerance information is gathered via questionnaires or similar structured psychometric tools. Our abundant digital footprint, as an unstructured alternative, is less investigated. Leveraging such information can potentially support largescale and cost-efficient financial services. Therefore, I explore the possibility of building a computational model that distills risk tolerance information from user texts in this study, and discuss the design principles discovered from empirical results and their implications. Specifically, a new quaternary classification task is defined for text mining-based risk profiling. Experiments show that pre-trained large language models set a baseline micro-F1 of circa 0.34. Using a convolutional neural network (CNN), the reported system achieves a micro-F1 of circa 0.51, which significantly outperforms the baselines, and is a circa 4% further improvement over the standard CNN configurations (micro-F1 of circa 0.47). Textual feature richness and supervised learning are found to be the key contributors to model performances, while other machine learning strategies suggested by previous research (data augmentation and multitasking) are less effective. The findings confirm user texts to be a useful risk profiling resource and provide several insights on this task.	[Xing, Frank] Natl Univ Singapore, Sch Comp, Singapore, Singapore	National University of Singapore	Xing, F (corresponding author), Natl Univ Singapore, Sch Comp, Singapore, Singapore.	xing@nus.edu.sg	Xing, Frank/L-7352-2019	Xing, Frank/0000-0002-5751-3937				[Anonymous], 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1181; [Anonymous], 2015, International Journal of Commerce and Management, DOI DOI 10.1108/IJCOMA-01-2013-0002; Athota VS, 2023, J BUS RES, V154, DOI 10.1016/j.jbusres.2022.08.055; Baddeley M., 2010, Cambridge Working Papers in Economics, V1006, P1; Cattell RB, 1943, J ABNORM SOC PSYCH, V38, P476, DOI 10.1037/h0054116; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Durand RB, 2008, J BEHAV FINANC, V9, P193, DOI 10.1080/15427560802341020; Epstein I., 1992, PSYCHOL SMART INVEST; Exley J., 2021, Journal of Financial Planning, P68; Gambetti E, 2019, J BEHAV EXP ECON, V80, P14, DOI 10.1016/j.socec.2019.03.002; Grable J. E., 2016, Handbook of Consumer Finance Research, P19, DOI DOI 10.1007/978-3-319-28887-1_2; Grable J. E., 2018, Financial risk tolerance: A psychometric review; Hemrajani P, 2023, EUR MANAG J, V41, P1119, DOI 10.1016/j.emj.2023.10.004; Hertwig R, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2018.0140; Kim KT, 2021, J FINANC COUNS PLAN, V32, P86, DOI 10.1891/JFCP-19-00022; Kwak E. J., 2022, Handbook of research on new challenges and global outlooks in financial risk management, P293; Lai CP, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11195474; Lauriola M, 2001, PERS INDIV DIFFER, V31, P215, DOI 10.1016/S0191-8869(00)00130-6; Lee K., 2010, Technical report 7, P1; Lee PJ, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103045; Lengkeek M, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103435; Li Y, 2022, NEUROCOMPUTING, V493, P340, DOI 10.1016/j.neucom.2022.04.049; Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349; Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23; Manolika M, 2023, PSYCHOL POP MEDIA, V12, P197, DOI 10.1037/ppm0000394; Marinelli N, 2017, J BEHAV FINANC, V18, P219, DOI 10.1080/15427560.2017.1308944; Marivate Vukosi, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P385, DOI 10.1007/978-3-030-57321-8_21; Mark G, 2014, COMPUT HUM BEHAV, V36, P274, DOI 10.1016/j.chb.2014.03.060; Markovikj D., 2021, Proceedings of the International AAAI Conference on Web and Social Media, V7, P23, DOI [10.1609/icwsm.v7i2.14466, DOI 10.1609/ICWSM.V7I2.14466]; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.1111/j.1540-6261.1952.tb01525.x; MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x; Mikolov T., 2013, International Conference on Learning Representations, P1; Moreschi R.W., 2005, Journal of Business and Economics Research, V3, P39; Nasir T, 2024, INFORM PROCESS MANAG, V61, DOI 10.1016/j.ipm.2023.103544; Nobre L.H. N., 2015, J FINANCIAL SERVICE, V69, P18; Norman W.T., 1967, 2800 personality trait descriptors: Normative operating characteristics for a university population; Nur AiniN S., 2019, J EC BUSINESS ACCOUN, V21, P401, DOI DOI 10.14414/JEBAV.V21I3.1663; Ozer G., 2019, Journal of Business, Economics and Finance, P155; Pardo Rangel, 2015, CEUR Workshop Proceedings, P1, DOI DOI 10.1007/S13398-014-0173-7.2; Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Pinjisakikool T, 2018, J INTERDISC ECON, V30, P32, DOI 10.1177/0260107917731034; Piovesan M, 2021, J ECON BEHAV ORGAN, V186, P523, DOI 10.1016/j.jebo.2021.04.011; Pompian M. M., 2004, Journal of Wealth Management, V7, P127; Prinz S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00158; Rahman M. A., 2019, INT C ADV SCI ENG RO, P1; Ren ZC, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102532; Rodrigues CG, 2024, STUD ECON FINANC, V41, P88, DOI 10.1108/SEF-01-2023-0013; Saha P, 2016, DECIS SUPPORT SYST, V84, P78, DOI 10.1016/j.dss.2016.02.002; Sahm CR, 2012, Q J FINANC, V2, DOI 10.1142/S2010139212500206; SHARPE WF, 1964, J FINANC, V19, P425, DOI 10.2307/2977928; Siering M, 2023, ACM TRANS MANAG INF, V14, DOI 10.1145/3589003; Sun X., 2018, IEEE INT C COMMUNICA, P1; Suzuki M, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103194; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; Tekçe B, 2015, J BEHAV EXP FINANC, V5, P35, DOI 10.1016/j.jbef.2015.02.003; Thavaneswaran A, 2021, IEEE INT CONF FUZZY, DOI 10.1109/FUZZ45933.2021.9494528; Van de Venter G, 2012, J ECON PSYCHOL, V33, P794, DOI 10.1016/j.joep.2012.03.001; Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816; Wen ZY, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103422; WILSON M, 1988, BEHAV RES METH INS C, V20, P6, DOI 10.3758/BF03202594; Wong A., 2013, The IUP Journal of Applied Finance, V19, P7; Xing F., 2019, Robo-Advisory, P113; Xing Frank, 2020, P 28 INT C COMP LING, P978, DOI DOI 10.18653/V1/2020.COLING-MAIN.85; Xing FZ, 2019, KNOWL-BASED SYST, V165, P297, DOI 10.1016/j.knosys.2018.11.035; Yang K, 2023, INFORM SYST RES, V34, P194, DOI 10.1287/isre.2022.1111; Yao R., 2005, J PERSONAL FINANCE, V4, P66; Yekrangi M, 2021, J INTELL INF SYST, V57, P127, DOI 10.1007/s10844-020-00630-9; Yin C, 2020, DECIS SUPPORT SYST, V136, DOI 10.1016/j.dss.2020.113364; Zhu Y., 2022, P IJCAI 22; Zimmerman DW, 2013, J APPL STAT, V40, P169, DOI 10.1080/02664763.2012.740620	71	0	0	12	12	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-4573	1873-5371		INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2024	61	4							103704	10.1016/j.ipm.2024.103704	http://dx.doi.org/10.1016/j.ipm.2024.103704		MAR 2024	12	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	NR3S7		hybrid			2024-07-03	WOS:001202147400001
J	Tian, X; Meng, Y				Tian, Xin; Meng, Yuan			PDEC: A Framework for Improving Knowledge Graph Reasoning Performance through Predicate Decomposition	ALGORITHMS			English	Article						knowledge graph; reasoning; predicates; embedding		The judicious configuration of predicates is a crucial but often overlooked aspect in the field of knowledge graphs. While previous research has primarily focused on the precision of triples in assessing knowledge graph quality, the rationality of predicates has been largely ignored. This paper introduces an innovative approach aimed at enhancing knowledge graph reasoning by addressing the issue of predicate polysemy. Predicate polysemy refers to instances where a predicate possesses multiple meanings, introducing ambiguity into the knowledge graph. We present an adaptable optimization framework that effectively addresses predicate polysemy, thereby enhancing reasoning capabilities within knowledge graphs. Our approach serves as a versatile and generalized framework applicable to any reasoning model, offering a scalable and flexible solution to enhance performance across various domains and applications. Through rigorous experimental evaluations, we demonstrate the effectiveness and adaptability of our methodology, showing significant improvements in knowledge graph reasoning accuracy. Our findings underscore that discerning predicate polysemy is a crucial step towards achieving a more dependable and efficient knowledge graph reasoning process. Even in the age of large language models, the optimization and induction of predicates remain relevant in ensuring interpretable reasoning.	[Tian, Xin] Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China; [Meng, Yuan] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	National University of Defense Technology - China; Tsinghua University	Tian, X (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China.	tianxin07@nudt.edu.cn; yuanmeng@tsinghua.edu.cn						Balazevic I, 2019, Arxiv, DOI [arXiv:1901.09590, DOI 10.18653/V1/D19-1522]; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Caliski T., 1974, COMMUN STAT, V3, P1, DOI DOI 10.1080/03610927408827101; Dai DM, 2020, Arxiv, DOI arXiv:2009.12765; Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811; Geng Yuxia, 2023, 2023 IEEE 39th International Conference on Data Engineering (ICDE), P1221, DOI 10.1109/ICDE55515.2023.00098; Hamaguchi T, 2017, Arxiv, DOI arXiv:1706.05674; Han X, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P139; Ji GL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P687; Kilicoglu H, 2012, BIOINFORMATICS, V28, P3158, DOI 10.1093/bioinformatics/bts591; Kingma D. P., 2017, ARXIV; Lee J, 2023, Arxiv, DOI [arXiv:2305.19987, DOI 10.48550/ARXIV.2305.19987, 10.48550/ARXIV.2305.19987]; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Mahdisoltani F., 2014, P C INNOVATIVE DATA; Meilicke C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3137; Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513; Nathani D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4710; Pan Y., 2022, P C EMP METH NAT LAN, P4261; Qu M., 2021, P INT C LEARNING REP; Sadeghian A., 2019, Adv. Neural Inf. Process. Syst, V32, P1; Socher R., 2013, ADV NEURAL INFORM PR, V1, P926; Sun ZQ, 2019, Arxiv, DOI [arXiv:1902.10197, 10.48550/arXiv.1902.10197]; Toutanova K., 2015, EMNLP, P1499, DOI 10.18653/v1/D15-1174; Toutanova K., 2015, P 3RDWORKSHOP CONTIN, P57, DOI [10.18653/v1/W15-4007, DOI 10.18653/V1/W15-4007]; Trouillon T, 2016, PR MACH LEARN RES, V48; Vashishth S, 2020, Arxiv, DOI [arXiv:1911.03082, DOI 10.48550/ARXIV.1911.03082]; Cohen WW, 2016, Arxiv, DOI arXiv:1605.06523; Wang CJ, 2022, AAAI CONF ARTIF INTE, P4184; Wang PF, 2019, AAAI CONF ARTIF INTE, P7152; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Wood EC, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04932-3; Xin JW, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2041-5; Xiong WH, 2018, Arxiv, DOI arXiv:1707.06690; Yang B., 2015, P ICLR POSTER; Yang F., 2017, Advances in Neural Information Processing Systems, V30, P1; Yue L., 2023, arXiv; Zhang YQ, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P3446, DOI 10.1145/3580305.3599404	37	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1999-4893		ALGORITHMS	Algorithms	MAR	2024	17	3							129	10.3390/a17030129	http://dx.doi.org/10.3390/a17030129			17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	MD8Z8		gold			2024-07-03	WOS:001191792900001
J	Acharya, S; Shinada, NK; Koyama, N; Ikemori, M; Nishioka, T; Hitaoka, S; Hakura, A; Asakura, S; Matsuoka, Y; Palaniappan, SK				Acharya, Sathwik; Shinada, Nicolas K.; Koyama, Naoki; Ikemori, Megumi; Nishioka, Tomoki; Hitaoka, Seiji; Hakura, Atsushi; Asakura, Shoji; Matsuoka, Yukiko; Palaniappan, Sucheendra K.			Asking the right questions for mutagenicity prediction from BioMedical text	NPJ SYSTEMS BIOLOGY AND APPLICATIONS			English	Article								Assessing the mutagenicity of chemicals is an essential task in the drug development process. Usually, databases and other structured sources for AMES mutagenicity exist, which have been carefully and laboriously curated from scientific publications. As knowledge accumulates over time, updating these databases is always an overhead and impractical. In this paper, we first propose the problem of predicting the mutagenicity of chemicals from textual information in scientific publications. More simply, given a chemical and evidence in the natural language form from publications where the mutagenicity of the chemical is described, the goal of the model/algorithm is to predict if it is potentially mutagenic or not. For this, we first construct a golden standard data set and then propose MutaPredBERT, a prediction model fine-tuned on BioLinkBERT based on a question-answering formulation of the problem. We leverage transfer learning and use the help of large transformer-based models to achieve a Macro F1 score of >0.88 even with relatively small data for fine-tuning. Our work establishes the utility of large language models for the construction of structured sources of knowledge bases directly from scientific publications.	[Acharya, Sathwik; Shinada, Nicolas K.; Matsuoka, Yukiko; Palaniappan, Sucheendra K.] Syst Biol Inst, Tokyo, Japan; [Shinada, Nicolas K.; Matsuoka, Yukiko; Palaniappan, Sucheendra K.] SBX Corp, Tokyo, Japan; [Koyama, Naoki; Hakura, Atsushi; Asakura, Shoji] Eisai & Co Ltd, Global Drug Safety, Tokyo, Japan; [Ikemori, Megumi] Eisai & Co Ltd, Hhc Data Creat Ctr, Planning Operat, Tokyo, Japan; [Nishioka, Tomoki; Hitaoka, Seiji] Eisai & Co Ltd, Hhc Data Creat Ctr, 5D Integrat Unit, Tokyo, Japan	Eisai Co Ltd; Eisai Co Ltd; Eisai Co Ltd	Palaniappan, SK (corresponding author), Syst Biol Inst, Tokyo, Japan.; Palaniappan, SK (corresponding author), SBX Corp, Tokyo, Japan.	sucheendra@sbi.jp		Palaniappan, Sucheendra Kumar/0000-0002-2829-2311	United States Department of Defense | United States Navy | ONR | Office of Naval Research Global (ONR Global) [N62909-21-1-2032]; ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute	United States Department of Defense | United States Navy | ONR | Office of Naval Research Global (ONR Global); ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute	The authors thank the ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute (Grant number: N62909-21-1-2032). Sathwik Acharya was an undergraduate student intern from PES University, India for 6 months at the Systems Biology Institute during the period of this research.	Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101; Ahmed S. A. J. A., 2022, Front. Physiol., V1623; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Bergstra J., 2011, Adv. Neural Inf. Process. Syst., P2546; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gugger S., 2022, Accelerate: Training and inference at scale made simple, efficient and adaptable; Hansen K, 2009, J CHEM INF MODEL, V49, P2077, DOI 10.1021/ci900161g; He Jiayuan, 2021, Front Res Metr Anal, V6, P654438, DOI 10.3389/frma.2021.654438; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]; Izmailov P, 2019, Arxiv, DOI arXiv:1803.05407; Kingma D. P., 2017, ARXIV; Kitano H, 2021, NPJ SYST BIOL APPL, V7, DOI 10.1038/s41540-021-00189-3; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; LaValle SM, 2004, INT J ROBOT RES, V23, P673, DOI 10.1177/0278364904045481; Lee CLY, 2020, Arxiv, DOI [arXiv:1909.11299, 10.48550/arXiv.1909.11299]; Lin Z., 2022, BIORXIV; Lundberg SM, 2017, ADV NEUR IN, V30; MARON DM, 1983, MUTAT RES, V113, P173, DOI 10.1016/0165-1161(83)90010-9; Mayr A, 2016, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00080; Nakayama H, 2018, DOCCANO TEXT ANNOTAT; Nantasenamat C, 2009, EXCLI J, V8, P74; Peach ML, 2018, APPLIED CHEMOINFORMATICS: ACHIEVEMENTS AND FUTURE OPPORTUNITIES, P385; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shin H.-C., 2020, P 2020 C EMP METH NA; Shinada NK, 2022, MUTAGENESIS, V37, P191, DOI 10.1093/mutage/geac010; STEAD AG, 1981, MUTAT RES, V85, P13, DOI 10.1016/0165-1161(81)90282-X; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Winter DJ, 2017, PREPRINT; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Yasunaga M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8003; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang J., 2020, PMLR, P11328; Zheng QH, 2019, J INTELL FUZZY SYST, V37, P5641, DOI 10.3233/JIFS-190861	37	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2056-7189		NPJ SYST BIOL APPL	npj Syst. Biol. Appl.	DEC 18	2023	9	1							63	10.1038/s41540-023-00324-2	http://dx.doi.org/10.1038/s41540-023-00324-2			9	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	CS5W6	38110446	gold, Green Published			2024-07-03	WOS:001127253400001
J	Dong, XL; Chen, JL				Dong, Xuelian; Chen, Jiale			PluDG: enhancing task-oriented dialogue system with knowledge graph plug-in module	PEERJ COMPUTER SCIENCE			English	Article						Artificial intelligence; Natural language processing; Data science; Graph neural networks; Dialogue systems	ATTENTION	Task-oriented dialogue systems continue to face significant challenges as they require not only an understanding of dialogue history but also domain-specific knowledge. However, knowledge is often dynamic, making it difficult to effectively integrate into the learning process. Existing large language model approaches primarily treat knowledge bases as textual resources, neglecting to capture the underlying relationships between facts within the knowledge base. To address this limitation, we propose a novel dialogue system called PluDG. We regard the knowledge as a knowledge graph and propose a knowledge extraction plug-in, Kg-Plug, to capture the features of the graph and generate prompt entities to assist the system's dialogue generation. Besides, we propose Unified Memory Integration, a module that enhances the comprehension of the sentence's internal structure and optimizes the knowledge base's encoding location. We conduct experiments on three public datasets and compare PluDG with several state-of-the-art dialogue models. The experimental results indicate that PluDG achieves significant improvements in both accuracy and diversity, outperforming the current state-of-the-art dialogue system models and achieving state-of-the-art performance.	[Dong, Xuelian; Chen, Jiale] Univ South China, Sch Comp Sci, Hengyang, Hunan, Peoples R China	University of South China	Chen, JL (corresponding author), Univ South China, Sch Comp Sci, Hengyang, Hunan, Peoples R China.	jalorc@163.com						Banerjee S, 2019, T ASSOC COMPUT LING, V7, P485, DOI 10.1162/tacl_a_00284; Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016; Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171; Eric M, 2017, Arxiv, DOI arXiv:1705.05414; He ZH, 2020, INT CONF ACOUST SPEE, P8029, DOI [10.1109/icassp40776.2020.9053667, 10.1109/ICASSP40776.2020.9053667]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang GH, 2022, Arxiv, DOI arXiv:2209.08708; Liu X, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11090483; Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400; Lu SY, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00233-6; Madotto A, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2372; Madotto A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1468; Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qin L., 2020, P 58 ANN M ASS COMPU, P6344, DOI https://doi.org/10.18653/v1/2020.acl-main.565; Raghu D, 2021, FINDINGS ASS COMPUTA, DOI [10.18653/v1/2021.findings-acl.448, DOI 10.18653/V1/2021.FINDINGS-ACL.448]; Rony M. R. A. H., 2022, FINDINGS ASS COMPUTA, P2557; Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044; Sukhbaatar S, 2015, Arxiv, DOI [arXiv:1503.08895, DOI 10.48550/ARXIV.1503.08895]; Wen TH, 2017, Arxiv, DOI arXiv:1604.04562; Wu CS, 2019, Arxiv, DOI arXiv:1901.04713; Wu J, 2022, AAAI CONF ARTIF INTE, P11504; Yang YY, 2021, AAAI CONF ARTIF INTE, V35, P14230; Zhao M, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110069	26	0	0	5	9	PEERJ INC	LONDON	341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND		2376-5992		PEERJ COMPUT SCI	PeerJ Comput. Sci.	NOV 24	2023	9								e1707	10.7717/peerj-cs.1707	http://dx.doi.org/10.7717/peerj-cs.1707			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z6AG0	38077554	Green Published, gold			2024-07-03	WOS:001112873000001
C	Singh, AK; Ding, D; Saxe, A; Hill, F; Lampinen, AK		Vlachos, A; Augenstein, I		Singh, Aaditya K.; Ding, David; Saxe, Andrew; Hill, Felix; Lampinen, Andrew Kyle			Know your audience: specializing grounded language models with listener subtraction	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Effective communication requires adapting to the idiosyncrasies of each communicative context-such as the common ground shared with each partner. Humans demonstrate this ability to specialize to their audience in many contexts, such as the popular game Dixit. We take inspiration from Dixit to formulate a multiagent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it among distractors, but another listener cannot. To adapt, the speaker must exploit differences in the knowledge it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. Through controlled experiments, we show that training a speaker with two listeners that perceive differently, using our method, allows the speaker to adapt to the idiosyncracies of the listeners. Furthermore, we show zero-shot transfer of the specialization to real-world data. Our experiments demonstrate a method for specializing grounded language models without direct supervision and highlight the interesting research challenges posed by complex multi-agent communication.	[Singh, Aaditya K.; Saxe, Andrew] UCL, Gatsby Computat Neurosci Unit, London W1T 4JG, England; [Ding, David; Hill, Felix; Lampinen, Andrew Kyle] DeepMind, London, England	University of London; University College London	Singh, AK (corresponding author), UCL, Gatsby Computat Neurosci Unit, London W1T 4JG, England.	aaditya.singh.21@ucl.ac.uk; fding@deepmind.com; a.saxe@ucl.ac.uk; felixhill@deepmind.com; lampinen@deepmind.com						Abadi M., 2015, TensorFlow: Large-scale machine learning on het- erogeneous systems; Agarwal Sandhini, 2021, ABS210802818 CORR; Alayrac J.-B., 2022, Flamingo: a visual language model for few-shot learning, V35, P23716; [Anonymous], 2020, SC, DOI DOI 10.1109/SC41405.2020.00024; Boyce Veronica, 2022, TWOS CO 6 IS CROWD E; Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Brock A, 2021, INT C MACHINE LEARNI, V139; Chaudhary Amit Kumar, 2022, P 15 INT C NAT LANG, P288; Clark H. H., 1996, USING LANGUAGE, DOI DOI 10.1017/CBO9780511620539; CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7; Cogswell Michael, 2020, Advances in Neural Information Processing Systems, V33, P2; Elhagry Ahmed, 2021, ABS210713114 CORR; Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633; Fried D., 2018, P 2018 C N AM CHAPTE, P1951; Gallois C., 2005, THEORIZING INTERCULT, P121; Hawkins Robert, 2020, Proceedings_of_the_Conference_on Computational_Natural_Language_Learning, P408, DOI [10.18653/v1/2020.conll-1.33, 10.18653/v1]; Hawkins RD, 2023, PSYCHOL REV, V130, P977, DOI 10.1037/rev0000348; Hawkins RXD, 2019, TRENDS COGN SCI, V23, P158, DOI 10.1016/j.tics.2018.11.003; Hennigan T., 2020, Haiku: Sonnet for JAX; Hoffmann Jordan, 2022, ABS220315556 CORR; Holtzman A., 2019, P INT C LEARN REPR; Hu Edward J., 2021, CoRR; Jaegle Andrew, 2021, CoRR; Jia C, 2021, PR MACH LEARN RES, V139; KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711; Kingma D. P, 2015, P INT C LEARN REPR 2; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Kunda Maithilee, 2020, CREATIVE CAPTIONING; Lazaridou A., 2020, ACL 2020, P7663; Lazaridou Angeliki, 2020, ABS200602419 CORR; Lee J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4385; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; LisaWang Angela Sy, 2017, Learning to Represent Student Knowledge on Programming Exercises Using Deep Learning; Liu Pengfei, 2021, arXiv; Mankewitz Jessica, 2021, MULTIPARTY REFERENTI; Meade N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1878; Meister Clara, 2022, ABS220200666 CORR; Mokady Ron, 2021, CoRR abs/2111.09734; Ouyang Long, 2022, ARXIV220302155; Radford A, 2021, PR MACH LEARN RES, V139; Ramesh A., 2022, HIERARCHICAL TEXT CO, DOI DOI 10.48550/ARXIV.2204.06125; Roubira JL, 2008, DIXIT BOARD GAME; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Tsimpoukelli M, 2021, ADV NEUR IN, V34; Vaswani A, 2017, ADV NEUR IN, V30; Vélez N, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.06.006; Weidinger Laura, 2021, CoRR; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Xiao H., 2017, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms; Yoon E.J., 2016, P 38 ANN C COGNITIVE, P2771; Ziegler DM, 2020, Fine-tuning language models from human preferences	56	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							3884	3911						28	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056902060
C	Sun, L; Wang, LA; Sun, J; Okatani, T			IEEE	Sun, Li; Wang, Liuan; Sun, Jun; Okatani, Takayuki			PROMPT PROTOTYPE LEARNING BASED ON RANKING INSTRUCTION FOR FEW-SHOT VISUAL TASKS	2023 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, ICIP	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	30th IEEE International Conference on Image Processing (ICIP)	OCT 08-11, 2023	Kuala Lumpur, MALAYSIA	IEEE, Inst Elect & Elect Engineers, Signal Proc Soc		Prompt prototype; Few-hot; Ranking instruction; Large-scale pre-training models		Querying large language models (LLMs), such as GPT-3, for high-quality prompts and utilizing pre-trained vision-language models, such as CLIP, to construct a zero-shot visual classification model, offer promising performance across various downstream visual tasks. However, when applied to specific domains, their efficacy is restricted due to the gap between the general prompts they generate and the required domain-specific knowledge. In this paper, we propose a novel, lightweight method for prompt prototype learning through ranking instruction, specifically designed to bridge this gap in the context of few-shot visual classification. We generate domain-specific prompts leveraging the knowledge contained in LLMs and then fine-tune the prompt prototype with effective ranking instructions from several domain images. Our few-shot experiments on facial expression benchmarks demonstrate the efficacy of the prompt prototype. Notably, our method delivers results that are on par with state-of-the-art few-shot image classification techniques and can be integrated with them to further improve performance in the facial expression domain. Our approach provides a promising solution to few-shot visual classification, making use of the knowledge contained in LLMs to generate domain-specific prompts.	[Sun, Li; Wang, Liuan; Sun, Jun] Fujitsu R&D Ctr, Beijing, Peoples R China; [Sun, Li; Okatani, Takayuki] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan; [Okatani, Takayuki] RIKEN, Ctr AIP, Wako, Saitama, Japan	Fujitsu Ltd; Fujitsu Laboratories Ltd; Tohoku University; RIKEN	Sun, L (corresponding author), Fujitsu R&D Ctr, Beijing, Peoples R China.; Sun, L (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.			Sun, Li/0000-0002-2957-4214				Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Jia C, 2021, PR MACH LEARN RES, V139; Li JN, 2022, PR MACH LEARN RES; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Ma YW, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3547910; Menon Sachit, 2022, ARXIV221007183; Ouyang Long, 2022, ARXIV220302155; Pratt Sarah, 2022, ARXIV220903320; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Snell J, 2017, ADV NEUR IN, V30; Wang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P238, DOI 10.1145/3343031.3350872; Xu Hu, 2021, ARXIV210914084; Yu Jiahui, 2022, ARXIV220501917; Zhang Renrui, 2021, ARXIV211103930; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	18	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		978-1-7281-9835-4	IEEE IMAGE PROC			2023							3235	3239		10.1109/ICIP49359.2023.10222039	http://dx.doi.org/10.1109/ICIP49359.2023.10222039			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1IU					2024-07-03	WOS:001106821003058
C	Swamy, S; Tabari, N; Chen, C; Gangadharaiah, R		Vlachos, A; Augenstein, I		Swamy, Sandesh; Tabari, Narges; Chen, Chacha; Gangadharaiah, Rashmi			Contextual Dynamic Prompting for Response Generation in Task-oriented Dialog Systems	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Response generation is one of the critical components in task-oriented dialog systems. Existing studies have shown that large pre-trained language models can be adapted to this task. The typical paradigm of adapting such extremely large language models would be by fine-tuning on the downstream tasks which is not only time-consuming but also involves significant resources and access to fine-tuning data. Prompting (Schick and Schutze, 2020) has been an alternative to fine-tuning in many NLP tasks. In our work, we explore the idea of using prompting for response generation in task-oriented dialog systems. Specifically, we propose an approach that performs contextual dynamic prompting where the prompts are learnt from dialog contexts. We aim to distill useful prompting signals from the dialog context. On experiments with MultiWOZ 2.2 dataset (Zang et al., 2020), we show that contextual dynamic prompts improve response generation in terms of combined score (Mehri et al., 2019a) by 3 absolute points, and a massive 20 points when dialog states are incorporated. Furthermore, human annotation on these conversations found that agents which incorporate context were preferred over agents with vanilla prefix-tuning.	[Swamy, Sandesh; Tabari, Narges; Gangadharaiah, Rashmi] AWS AI Labs, Seattle, WA 98101 USA; [Chen, Chacha] Univ Chicago, Chicago, IL USA	University of Chicago	Swamy, S (corresponding author), AWS AI Labs, Seattle, WA 98101 USA.	sanswamy@amazon.com; nargesam@amazon.com; chacha@uchicago.edu; rgangad@amazon.com						[Anonymous], 2020, FINDINGS ASS COMPUTA, DOI DOI 10.1109/ACPEE48638.2020.9136501; [Anonymous], 2020, NLP CONVERSATIONAL A; Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016; Gao Tianyu, 2020, arXiv; Ham D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P583; He WW, 2022, AAAI CONF ARTIF INTE, P10749; Hosseini-Asl E., 2020, Advances in Neural Information Processing Systems, P20179; Houlsby N, 2019, PR MACH LEARN RES, V97; Lai HC, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1103, DOI 10.1109/IS3C.2014.287; Lee CH, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4937; Lester B., 2021, arXiv; Li Xiang Lisa, 2021, arXiv; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3391; Liu Q, 2021, T ASSOC COMPUT LING, V9, P657, DOI 10.1162/tacl_a_00390; Mehri S, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P165; Mehri Shikib, 2019, ARXIV190710016; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng BL, 2021, T ASSOC COMPUT LING, V9, P807, DOI 10.1162/tacl_a_00399; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rebuffi Sylvestre-Alvise, 2017, ABS170508045 CORR; Schick Timo, 2020, arXiv; Shin Taylor, 2020, WALLACE; Su Yixuan, 2021, ARXIV210914739; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Wen T.-H., 2015, P 2015 C EMP METH NA, P1711, DOI 10.18653/v1/D15-1199; Yang YY, 2021, AAAI CONF ARTIF INTE, V35, P14230; Zhu Qi, 2022, ARXIV220306654	31	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							3102	3111						10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056902002
C	Tang, JJ; Zheng, G; Yu, JY; Yang, SB			IEEE	Tang, Jiajin; Zheng, Ge; Yu, Jingyi; Yang, Sibei			CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION, ICCV	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF			NETWORK	Task driven object detection aims to detect object instances suitable for affording a task in an image. Its challenge lies in object categories available for the task being too diverse to be limited to a closed set of object vocabulary for traditional object detection. Simply mapping categories and visual features of common objects to the task cannot address the challenge. In this paper, we propose to explore fundamental affordances rather than object categories, i.e., common attributes that enable different objects to accomplish the same task. Moreover, we propose a novel multi-level chain-of-thought prompting (MLCoT) to extract the affordance knowledge from large language models, which contains multi-level reasoning steps from task to object examples to essential visual attributes with rationales. Furthermore, to fully exploit knowledge to benefit object recognition and localization, we propose a knowledgeconditional detection framework, namely CoTDet. It conditions the detector from the knowledge to generate object queries and regress boxes. Experimental results demonstrate that our CoTDet outperforms state-of-the-art methods consistently and significantly (+15.6 box AP and +14.8 mask AP) and can generate rationales for why objects are detected to afford the task.	[Tang, Jiajin; Zheng, Ge; Yu, Jingyi; Yang, Sibei] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China	ShanghaiTech University	Yang, SB (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.	tangjj@shanghaitech.edu.cn; zhengge@shanghaitech.edu.cn; yujingyi@shanghaitech.edu.cn; yangsb@shanghaitech.edu.cn			National Natural Science Foundation of China [62206174]; Shanghai Pujiang Program [21PJ1410900]; Shanghai Frontiers Science Center of Human-centered Artificial Intelligence; MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration (ShanghaiTech University); Shanghai Engineering Research Center of Intelligent Vision and Imaging	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Pujiang Program(Shanghai Pujiang Program); Shanghai Frontiers Science Center of Human-centered Artificial Intelligence; MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration (ShanghaiTech University); Shanghai Engineering Research Center of Intelligent Vision and Imaging	This work was supported by the National Natural Science Foundation of China (No.62206174), Shanghai Pujiang Program (No.21PJ1410900), Shanghai Frontiers Science Center of Human-centered Artificial Intelligence (ShangHAI), MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration (ShanghaiTech University), and Shanghai Engineering Research Center of Intelligent Vision and Imaging.	Ahn M., 2022, arXiv preprint arXiv:2204.01691; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carion N, 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13; Chen D., 2020, C ROB LEARN, P66, DOI DOI 10.48550/ARXIV.1912.12294; Cheng A. G., 2021, Advances in Neural Information Processing Systems, P17864; Deng JJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1749, DOI 10.1109/ICCV48922.2021.00179; Devlin J., 2018, BERT PRE TRAINING DE; Vo DM, 2022, PROC CVPR IEEE, P17979, DOI 10.1109/CVPR52688.2022.01747; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao F, 2022, PROC CVPR IEEE, P5057, DOI 10.1109/CVPR52688.2022.00501; Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207; He K., 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180; Kato K, 2018, LECT NOTES COMPUT SC, V11218, P247, DOI 10.1007/978-3-030-01264-9_15; Kazemzadeh S., 2014, P 2014 C EMPIRICAL M, P787, DOI [DOI 10.3115/V1/D14-1086, 10.3115/v1/d14-1086]; Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325; Li P., 2022, ARXIV221010775; Lin L, 2022, IEEE T MULTIMEDIA, V24, P1922, DOI 10.1109/TMM.2021.3074008; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu Y., 2019, CoRR abs/1907.11692; Loshchilov I., 2017, CoRR; Lu Pan, 2023, INT C LEARN REPR ICL; Mao Chengzhi, 2022, ARXIV221206202; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Narasimhan M, 2018, ADV NEUR IN, V31; Ouyang Long, 2022, ARXIV220302155; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Plummer BA, 2017, IEEE I CONF COMP VIS, P1946, DOI 10.1109/ICCV.2017.213; Pratt Sarah, 2022, ARXIV220903320; Qi MS, 2019, PROC CVPR IEEE, P5232, DOI 10.1109/CVPR.2019.00538; Raffel Colin, 2020, J MACHINE LEARNING R, V21, P5485, DOI [DOI 10.48550/ARXIV.1910.10683, 10.48550/arxiv.1910.10683]; Redmon J, 2018, Arxiv, DOI arXiv:1804.02767; Ren A. Z., 2023, Conference on Robot Learning, P1531; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Sawatzky J, 2019, PROC CVPR IEEE, P7597, DOI 10.1109/CVPR.2019.00779; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shen Sheng, 2022, ARXIV220409222; Shi C, 2022, LECT NOTES COMPUT SC, V13696, P201, DOI 10.1007/978-3-031-20059-5_12; Sibei Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P589, DOI 10.1007/978-3-030-58529-7_35; Singh KK, 2018, LECT NOTES COMPUT SC, V11217, P506, DOI 10.1007/978-3-030-01261-8_30; Tang JJ, 2023, PROC CVPR IEEE, P23570, DOI 10.1109/CVPR52729.2023.02257; Vaswani A, 2017, ADV NEUR IN, V30; Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246; Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139; Wei Jason, 2022, arXiv:2201.11903; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; Yang SB, 2021, PROC CVPR IEEE, P11261, DOI 10.1109/CVPR46437.2021.01111; Yang SB, 2021, IEEE T PATTERN ANAL, V43, P2765, DOI 10.1109/TPAMI.2020.2973983; Yang SB, 2019, IEEE I CONF COMP VIS, P4643, DOI 10.1109/ICCV.2019.00474; Yang SB, 2019, PROC CVPR IEEE, P4140, DOI 10.1109/CVPR.2019.00427; Yang Z, 2022, PROC CVPR IEEE, P18134, DOI 10.1109/CVPR52688.2022.01762; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yu D, 2022, IEEE INT CONF COMM, P604, DOI [10.1109/ICCWorkshops53468.2022.9814531, 10.1109/ICCWORKSHOPS53468.2022.9814531]; Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142; Zareian Alireza, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P606, DOI 10.1007/978-3-030-58592-1_36; Zhang Zhuosheng, 2023, ARXIV230200923; Zhu X, 2021, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.2010.04159	65	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							3045	3055		10.1109/ICCV51070.2023.00285	http://dx.doi.org/10.1109/ICCV51070.2023.00285			11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5FA		Green Submitted			2024-07-03	WOS:001159644303028
J	Ye, CR; Zweck, E; Ma, ZC; Smith, J; Katz, S				Ye, Carrie; Zweck, Elric; Ma, Zechen; Smith, Justin; Katz, Steven			Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study	ARTHRITIS & RHEUMATOLOGY			English	Article							IMPACT	Objective: The objective of the current study was to assess the quality of large language model (LLM) chatbot versus physician-generated responses to patient-generated rheumatology questions.Methods: We conducted a single-center cross-sectional survey of rheumatology patients (n = 17) in Edmonton, Alberta, Canada. Patients evaluated LLM chatbot versus physician-generated responses for comprehensiveness and readability, with four rheumatologists also evaluating accuracy by using a Likert scale from 1 to 10 (1 being poor, 10 being excellent).Results: Patients rated no significant difference between artificial intelligence (AI) and physician-generated responses in comprehensiveness (mean 7.12 +/- SD 0.99 vs 7.52 +/- 1.16; P = 0.1962) or readability (7.90 +/- 0.90 vs 7.80 +/- 0.75; P = 0.5905). Rheumatologists rated AI responses significantly poorer than physician responses on comprehensiveness (AI 5.52 +/- 2.13 vs physician 8.76 +/- 1.07; P < 0.0001), readability (AI 7.85 +/- 0.92 vs physician 8.75 +/- 0.57; P = 0.0003), and accuracy (AI 6.48 +/- 2.07 vs physician 9.08 +/- 0.64; P < 0.0001). The proportion of preference to AI- versus physician-generated responses by patients and physicians was 0.45 +/- 0.18 and 0.15 +/- 0.08, respectively (P = 0.0106). After learning that one answer for each question was AI generated, patients were able to correctly identify AI-generated answers at a lower proportion compared to physicians (0.49 +/- 0.26 vs 0.97 +/- 0.04; P = 0.0183). The average word count of AI answers was 69.10 +/- 25.35 words, as compared to 98.83 +/- 34.58 words for physician-generated responses (P = 0.0008).Conclusion: Rheumatology patients rated AI-generated responses to patient questions similarly to physician-generated responses in terms of comprehensiveness, readability, and overall preference. However, rheumatologists rated AI responses significantly poorer than physician-generated responses, suggesting that LLM chatbot responses are inferior to physician responses, a difference that patients may not be aware of.	[Ye, Carrie; Ma, Zechen; Smith, Justin; Katz, Steven] Univ Alberta, Edmonton, AB, Canada; [Zweck, Elric] Univ Hosp Dusseldorf, Dusseldorf, Germany	University of Alberta; Heinrich Heine University Dusseldorf; Heinrich Heine University Dusseldorf Hospital	Ye, CR (corresponding author), Univ Alberta, Edmonton, AB, Canada.	cye@ualberta.ca		Smith, Justin/0009-0003-6039-5665; Zweck, Elric/0000-0001-6739-476X; Ma, Zechen/0000-0003-3064-8118				Alberta Rheumatology, US; [Anonymous], 2022, news-releases; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Goodman RS, 2023, MED-CAMBRIDGE, V4, P139, DOI 10.1016/j.medj.2023.02.008; Holmgren AJ, 2023, JAMA-J AM MED ASSOC, V329, P339, DOI 10.1001/jama.2022.24710; Holmgren AJ, 2022, J AM MED INFORM ASSN, V29, P453, DOI 10.1093/jamia/ocab268; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lubbad M., 2023, MEDIUM          0319; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Nerdynav, 2022, NERDYNAV; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Sinsky CA, 2022, J GEN INTERN MED, V37, P4002, DOI 10.1007/s11606-022-07766-0; Sng GGR, 2023, DIABETES CARE, V46, pE103, DOI 10.2337/dc23-0197; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	15	6	6	2	3	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2326-5191	2326-5205		ARTHRITIS RHEUMATOL	Arthritis Rheumatol.	MAR	2024	76	3					479	484		10.1002/art.42737	http://dx.doi.org/10.1002/art.42737		JAN 2024	6	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	KB7F8	37902018	hybrid			2024-07-03	WOS:001144922400001
J	Liu, ZJ; Tang, YT; Luo, XP; Zhou, YM; Zhang, LF				Liu, Zhijie; Tang, Yutian; Luo, Xiapu; Zhou, Yuming; Zhang, Liang Feng			No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						Large language model; ChatGPT; code generation	PROGRAM	Large language models (LLMs) have demonstrated impressive capabilities across various natural language processing (NLP) tasks, such as machine translation, question answering, summarization, and so on. Additionally, LLMs are also highly valuable in supporting software engineering tasks, particularly in the field of code generation. Automatic code generation is a process of automatically generating source code or executable code based on given specifications or requirements, improving developer productivity. In this study, we perform a systematic empirical assessment to the quality of code generation using ChatGPT, a recent state-of-the-art product LLM. We leverage 728 algorithm problems in five languages (i.e., C, C++, Java, Python, and JavaScript) and 18 CWEs with 54 code scenarios for the code generation task. Our evaluation encompasses a comprehensive analysis of code snippets generated by ChatGPT, focusing on three critical aspects: correctness, complexity, and security. We also specifically investigate ChatGPT's ability to engage in multi-round fixing process (i.e., ChatGPT's dialog ability, chatting between users and ChatGPT for fixing generated buggy code) of facilitating code generation. By delving into the generated code and examining the experimental results, this work provides valuable insights into the performance of ChatGPT in tackling code generation tasks over the three critical aspects. The experimental results demonstrate that (1) ChatGPT is better at generating functionally correct code for problems before 2021 in different languages than problems after 2021 with 48.14% advantage in Accepted rate on judgment platform, but ChatGPT's ability to directly fix erroneous code with multi-round fixing process to achieve correct functionality is relatively weak; (2) the distribution of cyclomatic and cognitive complexity levels for code snippets in different languages varies. Furthermore, the multi-round fixing process with ChatGPT generally preserves or increases the complexity levels of code snippets; (3) in algorithm scenarios with languages of C, C++, and Java, and CWE scenarios with languages of C and Python3, the code generated by ChatGPT has relevant vulnerabilities. However, the multi-round fixing process for vulnerable code snippets demonstrates promising results, with more than 89% of vulnerabilities successfully addressed; and (4) code generation may be affected by ChatGPT's non-determinism factor, resulting in variations of code snippets in functional correctness, complexity, and security. Overall, our findings uncover potential issues and limitations that arise in the ChatGPT-based code generation and lay the groundwork for improving AI and LLM-based code generation techniques.	[Liu, Zhijie; Zhang, Liang Feng] ShanghaiTech Univ, Shanghai 201210, Peoples R China; [Tang, Yutian] Univ Glasgow, Glasgow City G128QQ, Scotland; [Luo, Xiapu] Hong Kong Polytech Univ, Dept Comp, Hong Kong 999077, Peoples R China; [Zhou, Yuming] Nanjing Univ, Nanjing 210008, Peoples R China	ShanghaiTech University; University of Glasgow; Hong Kong Polytechnic University; Nanjing University	Tang, YT (corresponding author), Univ Glasgow, Glasgow City G128QQ, Scotland.	liuzhj2022@shanghaitech.edu.cn; yutian.tang@glasgow.ac.uk; csxluo@comp.polyu.edu.hk; zhouyuming@nju.edu.cn; zhanglf@shanghaitech.edu.cn			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Abate A, 2018, LECT NOTES COMPUT SC, V10981, P270, DOI 10.1007/978-3-319-96145-3_15; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; [Anonymous], GPT-3.5 models; [Anonymous], GPT-4 technical report; [Anonymous], GitHub CoPilot your ai pair programmer; [Anonymous], CHATGPT: Optimizing language models for dialogue; [Anonymous], Programming competitions and contests, programming community; [Anonymous], The world's leading online programming learning platform; [Anonymous], What is AI code generation?; [Anonymous], CodeQL full cwe coverage; [Anonymous], Cognitive complexity; [Anonymous], Try bard, an AI experiment by Google; [Anonymous], Reverse engineered ChatGPT API by openAI. Extensible for chatbots etc; [Anonymous], CodeQL documentation; [Anonymous], Online artifact; [Anonymous], openAI-cookbook; [Anonymous], DALLE, GPT, midjourney, stable diffusion, ChatGPT prompt marketplace; [Anonymous], CCCC project documentation; [Anonymous], 2022 CWE top 25 most dangerous software weaknesses; [Anonymous], Python / modern C++ solutions of all 2577 LeetCode problems." kamyu104; [Anonymous], clean code for teams and enterprises with sonarqube; [Anonymous], An extensible cross-language static code analyzer; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Bielik P, 2016, PR MACH LEARN RES, V48; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bui NDQ, 2021, PROC INT CONF SOFTW, P1186, DOI 10.1109/ICSE43902.2021.00109; Cai XY, 2023, IEEE T MULTIMEDIA, V25, P845, DOI 10.1109/TMM.2021.3132724; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chen M., 2021, arXiv; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Dantas C. E. C., 2021, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Fay MP, 2010, STAT SURV, V4, P1, DOI 10.1214/09-SS051; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Fu YJ, 2024, Arxiv, DOI arXiv:2310.02059; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gulwani S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI 10.1145/1925844.1926423; Gvero T, 2013, ACM SIGPLAN NOTICES, V48, P27, DOI 10.1145/2499370.2462192; Haefliger S, 2008, MANAGE SCI, V54, P180, DOI 10.1287/mnsc.1070.0748; Hendrycks D, 2021, Arxiv, DOI arXiv:2105.09938; HOLM S, 1979, SCAND J STAT, V6, P65; Hu HS, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3523273; Hu YT, 2023, IEEE T SOFTWARE ENG, V49, P4429, DOI 10.1109/TSE.2023.3295801; Kalyan A, 2018, Arxiv, DOI [arXiv:1804.01186, DOI 10.48550/ARXIV.1804.01186]; Khashabi D, 2020, Arxiv, DOI arXiv:2005.00700; Kou BA, 2024, Arxiv, DOI arXiv:2306.01220; Krishna K, 2022, Arxiv, DOI arXiv:2205.09726; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Le THM, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3383458; Li J, 2018, Arxiv, DOI arXiv:1711.09573; Liu F, 2020, INT C PROGRAM COMPRE, P37, DOI 10.1145/3387904.3389261; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu Y, 2023, Arxiv, DOI arXiv:2307.12596; Macbeth G, 2011, UNIV PSYCHOL, V10, P545, DOI 10.11144/Javeriana.upsy10-2.cdcp; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837; Nagata R, 2021, Arxiv, DOI arXiv:2108.12216; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAi, ChatGPT; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Peters M., 2018, arXiv:1802.05365, V12; Pilault J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9308; Rabinovich M., 2017, arXiv; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rigaki M, 2023, Arxiv, DOI arXiv:2007.07646; Scalabrino S, 2017, IEEE INT CONF AUTOM, P417, DOI 10.1109/ASE.2017.8115654; Siddiq ML, 2022, IEEE INT WORK C SO, P71, DOI 10.1109/SCAM55253.2022.00014; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Stallings W., 2012, Computer Security: Principles and Practice, V3; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tan SH, 2017, PROC IEEE ACM INT C, P180, DOI 10.1109/ICSE-C.2017.76; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Ye W, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2309, DOI 10.1145/3366423.3380295; Zhang J, 2019, PROC INT CONF SOFTW, P783, DOI 10.1109/ICSE.2019.00086; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270	87	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JUN	2024	50	6					1548	1584		10.1109/TSE.2024.3392499	http://dx.doi.org/10.1109/TSE.2024.3392499			37	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL2G2		Green Submitted			2024-07-03	WOS:001248142900012
J	Roumeliotis, KI; Tselikas, ND; Nasiopoulos, DK				Roumeliotis, Konstantinos I.; Tselikas, Nikolaos D.; Nasiopoulos, Dimitrios K.			Next-Generation Spam Filtering: Comparative Fine-Tuning of LLMs, NLPs, and CNN Models for Email Spam Classification	ELECTRONICS			English	Article						spam filtering; spam classification; spam detection; spam detection systems; spam email; phishing email; phishing detection; phishing attacks; LLM fine-tuning; LLM classification	PHISHING EMAILS	Spam emails and phishing attacks continue to pose significant challenges to email users worldwide, necessitating advanced techniques for their efficient detection and classification. In this paper, we address the persistent challenges of spam emails and phishing attacks by introducing a cutting-edge approach to email filtering. Our methodology revolves around harnessing the capabilities of advanced language models, particularly the state-of-the-art GPT-4 Large Language Model (LLM), along with BERT and RoBERTa Natural Language Processing (NLP) models. Through meticulous fine-tuning tailored for spam classification tasks, we aim to surpass the limitations of traditional spam detection systems, such as Convolutional Neural Networks (CNNs). Through an extensive literature review, experimentation, and evaluation, we demonstrate the effectiveness of our approach in accurately identifying spam and phishing emails while minimizing false positives. Our methodology showcases the potential of fine-tuning LLMs for specialized tasks like spam classification, offering enhanced protection against evolving spam and phishing attacks. This research contributes to the advancement of spam filtering techniques and lays the groundwork for robust email security systems in the face of increasingly sophisticated threats.	[Roumeliotis, Konstantinos I.; Tselikas, Nikolaos D.] Univ Peloponnese, Dept Informat & Telecommun, Akadimaikou GK Vlachou St, Tripoli 22131, Greece; [Nasiopoulos, Dimitrios K.] Agr Univ Athens, Sch Appl Econ & Social Sci, Dept Agribusiness & Supply Chain Management, Athens 11855, Greece	University of Peloponnese; Agricultural University of Athens	Roumeliotis, KI (corresponding author), Univ Peloponnese, Dept Informat & Telecommun, Akadimaikou GK Vlachou St, Tripoli 22131, Greece.	k.roumeliotis@uop.gr; ntsel@uop.gr	Roumeliotis, Konstantinos I./JVD-9005-2023	Roumeliotis, Konstantinos I./0000-0002-8098-1616				Ahmed N, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1862888; Alabdan R, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12100168; ALBERT, About us; Baaqeel H, 2020, INT ARAB CONF INF TE; Bhattacharya P, 2020, INT J INTEGR ENG, V12, P40; Bhopale AP, 2022, LECT NOTE NETW SYST, V256, P67, DOI 10.1007/978-3-030-82469-3_6; Cao J, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9347970; Chandan J. R., 2023, Intelligent Communication Technologies and Virtual Mobile Networks: Proceedings of ICICV 2022. Lecture Notes on Data Engineering and Communications Technologies (131), P227, DOI 10.1007/978-981-19-1844-5_19; Dada EG, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01802; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ferreira A, 2019, INT J HUM-COMPUT ST, V125, P19, DOI 10.1016/j.ijhcs.2018.12.004; Garg P, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P30, DOI 10.1109/Confluence51648.2021.9377042; Gaurav D, 2020, SOFT COMPUT, V24, P9625, DOI 10.1007/s00500-019-04473-7; Ghiassi M, 2022, COMPUT IND ENG, V165, DOI 10.1016/j.cie.2022.107959; github, GitHub-Kroumeliotis/Next-Generation-Spam-Filtering-Fine-Tuning-GPT-4-and-RoBERTa-Models-for-Email-Classification: Next-Generation Spam Filtering: Fine-Tuning GPT-4 and RoBERTa Models for Email Classification; Gomaa WH, 2020, INT J ADV COMPUT SC, V11, P544; Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029; Hnini Ghizlane, 2021, Artificial Intelligence and Industrial Applications. Artificial Intelligence Techniques for Cyber-Physical, Digital Twin Systems and Engineering Applications. Lecture Notes in Networks and Systems (LNNS 144), P36, DOI 10.1007/978-3-030-53970-2_4; huggingface, RoBERTa-Transformers 2.9.1; huggingface, Roberta-Base Hugging Face; huggingface, Bert-Base-Uncased Hugging Face; huggingface, Pretrained Models-Transformers 3.3.0 Documentation; Ji KY, 2023, COMPUT SYST SCI ENG, V45, P201, DOI 10.32604/csse.2023.031270; kaggle, NLP-SPAM/HAM Email Classification; kaggle, Spam Emails; Kihal M, 2023, MULTIMED TOOLS APPL, V82, P40819, DOI 10.1007/s11042-023-15170-x; Kim I, 2023, IEEE T INF FOREN SEC, V18, P2856, DOI 10.1109/TIFS.2023.3255172; Kontsewaya Yu., 2021, Proc. Comput. Sci, V190, P479, DOI [10.1016/j.procs.2021.06.056, DOI 10.1016/J.PROCS.2021.06.056]; Kuchipudi B., 2020, P 15 INT C AV REL SE, DOI DOI 10.1145/3407023.3407079; Lv T, 2020, J PHYS CONF SER, V1575, DOI 10.1088/1742-6596/1575/1/012054; Magdy Safaa, 2022, Computer Networks, V206, DOI 10.1016/j.comnet.2022.108826; Manita G, 2023, APPL SOFT COMPUT, V144, DOI 10.1016/j.asoc.2023.110478; Mehrotra T., 2021, Data Driven Approach towards Disruptive Technologies: Proceedings of MIDAS 2020, P423, DOI [10.1007/978-981-15-9873-933, DOI 10.1007/978-981-15-9873-933]; Nam SG, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11132053; Ojugo A.A., 2020, Int. J. Inform. Commun. Technol. (IJ-ICT), V9, P9, DOI [10.11591/ijict.v9i1.pp9-18, DOI 10.11591/IJICT.V9I1.PP9-18]; Paswan Mithilesh Kumar, 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P170; platform, Models-OpenAI API; Rapacz S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172083; Rifat N., 2022, P 2022 IEEE INT C EL, P430, DOI [10.1109/EIT53891.2022.9813922, DOI 10.1109/EIT53891.2022.9813922]; Roumeliotis K.I., 2024, Nat. Lang. Process. J, V6, P100056, DOI [10.1016/J.NLP.2024.100056, DOI 10.1016/J.NLP.2024.100056]; Roumeliotis K.I., 2024, Software, V3, P62, DOI [10.3390/SOFTWARE3010004, DOI 10.3390/SOFTWARE3010004]; Sahin DÖ, 2020, SIG PROCESS COMMUN, DOI 10.1109/siu49456.2020.9302516; Shaik China Moulali, 2023, 2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS), P1350, DOI 10.1109/ICAIS56108.2023.10073776; support, Gmail Message Header Limits-Google Workspace Admin Help; Topal MO, 2021, Arxiv, DOI arXiv:2102.08036; Wang C, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2993877; Xia T, 2020, IEEE ACCESS, V8, P82653, DOI 10.1109/ACCESS.2020.2991328; youtube, What Runs ChatGPT? Inside Microsoft's AI Supercomputer|Featuring Mark Russinovich-YouTube; Zhang KP, 2024, INFORM FUSION, V102, DOI 10.1016/j.inffus.2023.102038; Zhaoquan G, 2021, CHINESE J ELECTRON, V30, P595, DOI 10.1049/cje.2021.05.001	50	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2034	10.3390/electronics13112034	http://dx.doi.org/10.3390/electronics13112034			24	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UF9E4		gold			2024-07-03	WOS:001246754200001
C	Soviero, B; Kuhn, D; Salle, A; Moreira, VP		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Soviero, Beatriz; Kuhn, Daniel; Salle, Alexandre; Moreira, Viviane Pereira			ChatGPT Goes Shopping: LLMs Can Predict Relevance in eCommerce Search	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		relevance judgment prediction; LLM; eCommerce		The dependence on human relevance judgments limits the development of information retrieval test collections that are vital for evaluating these systems. Since their launch, large language models (LLMs) have been applied to automate several human tasks. Recently, LLMs started being used to provide relevance judgments for document search. In this work, our goal is to assess whether LLMs can replace human annotators in a different setting - product search in eCommerce. We conducted experiments on open and proprietary industrial datasets tomeasure LLM's ability to predict relevance judgments. Our results found that LLM-generated relevance assessments present a strong agreement (similar to 82%) with human annotations indicating that LLMs have an innate ability to perform relevance judgments in an eCommerce setting. Then, we went further and tested whether LLMs can generate annotation guidelines. Our results found that relevance assessments obtained with LLM-generated guidelines are as accurate as the ones obtained from human instructions.(1)(The source code for this work is available at https://github.com/danimtk/chatGPT-goes-shopping)	[Soviero, Beatriz; Moreira, Viviane Pereira] Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil; [Kuhn, Daniel] Inst Educ Sci & Technol Rio Grande do Sul IFRS, Ibiruba, Brazil; [Salle, Alexandre] VTEX, Porto Alegre, RS, Brazil	Universidade Federal do Rio Grande do Sul	Moreira, VP (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.	bfsoviero@inf.ufrgs.br; daniel.kuhn@ibiruba.ifrs.edu.br; alexandre.salle@vtex.com; viviane@inf.ufrgs.br			VTEX BRASIL [EMBRAPII PCEE1911.0140]; CAPES Finance [001]; CNPq/Brazil	VTEX BRASIL; CAPES Finance(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); CNPq/Brazil(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ))	The authors thank Shervin Malmasi for his helpful comments and suggestions. This work has been financed in part by VTEX BRASIL (EMBRAPII PCEE1911.0140), CAPES Finance Code 001, and CNPq/Brazil.	Blanco R, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P923; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carterette B., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P268, DOI 10.1145/1148170.1148219; Chen Y, 2022, LECT NOTES COMPUT SC, V13185, P128, DOI 10.1007/978-3-030-99736-6_9; CLEVERDON CW, 1960, ASLIB PROC, V12, P421, DOI 10.1108/eb049778; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; de Oliveira LL, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2363, DOI 10.1145/3404835.3463256; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Faggioli G, 2023, PROCEEDINGS OF THE 2023 ACM SIGIR INTERNATIONAL CONFERENCE ON THE THEORY OF INFORMATION RETRIEVAL, ICTIR 2023, P39, DOI 10.1145/3578337.3605136; Guo JJ, 2021, CHINESE J CHEM, V39, P1898, DOI 10.1002/cjoc.202000675; Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063; Liu Y., 2019, CoRR abs/1907.11692; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Sanderson Mark, 2010, Foundations and Trends in Information Retrieval, V4, P247, DOI 10.1561/1500000009; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Sondhi P, 2018, ACM/SIGIR PROCEEDINGS 2018, P1245, DOI 10.1145/3209978.3210152; Spark-Jones Karen, 1975, Report on the need for and provision of an "ideal"information retrieval test collection; Thomas P, 2024, Arxiv, DOI arXiv:2309.10621; Voorhees E.M., 2003, P TEXT RETR C, P69; Voorhees EllenM., 1999, The Eighth Text Retrieval Conference - (TREC-8), P1; Voorhees EM, 2000, INFORM PROCESS MANAG, V36, P697, DOI 10.1016/S0306-4573(00)00010-8; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]	22	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56065-1; 978-3-031-56066-8	LECT NOTES COMPUT SC			2024	14611						3	11		10.1007/978-3-031-56066-8_1	http://dx.doi.org/10.1007/978-3-031-56066-8_1			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EA					2024-07-03	WOS:001211834200001
J	Spallek, S; Birrell, L; Kershaw, S; Devine, EK; Thornton, L				Spallek, Sophia; Birrell, Louise; Kershaw, Stephanie; Devine, Emma Krogh; Thornton, Louise			Can we use ChatGPT for Mental Health and Substance Use Education? Examining Its Quality and Potential Harms	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; generative artificial intelligence; large language models; ChatGPT; medical education; health education; patient education handout; preventive health services; educational intervention; mental health; substance use		Background: The use of generative artificial intelligence, more specifically large language models (LLMs), is proliferating, and as such, it is vital to consider both the value and potential harms of its use in medical education. Their efficiency in a variety of writing styles makes LLMs, such as ChatGPT, attractive for tailoring educational materials. However, this technology can feature biases and misinformation, which can be particularly harmful in medical education settings, such as mental health and substance use education. This viewpoint investigates if ChatGPT is sufficient for 2 common health education functions in the field of mental health and substance use: (1) answering users' direct queries and (2) aiding in the development of quality consumer educational health materials. Objective: This viewpoint includes a case study to provide insight into the accessibility, biases, and quality of ChatGPT's query responses and educational health materials. We aim to provide guidance for the general public and health educators wishing to utilize LLMs. Methods: We collected real world queries from 2 large-scale mental health and substance use portals and engineered a variety of prompts to use on GPT-4 Pro with the Bing BETA internet browsing plug-in. The outputs were evaluated with tools from the Sydney Health Literacy Lab to determine the accessibility, the adherence to Mindframe communication guidelines to identify biases, and author assessments on quality, including tailoring to audiences, duty of care disclaimers, and evidence-based internet references. Results: GPT-4's outputs had good face validity, but upon detailed analysis were substandard in comparison to expert-developed materials. Without engineered prompting, the reading level, adherence to communication guidelines, and use of evidence-based websites were poor. Therefore, all outputs still required cautious human editing and oversight. Conclusions: GPT-4 is currently not reliable enough for direct-consumer queries, but educators and researchers can use it for creating educational materials with caution. Materials created with LLMs should disclose the use of generative artificial intelligence and be evaluated on their efficacy with the target audience.	[Spallek, Sophia; Birrell, Louise; Kershaw, Stephanie; Devine, Emma Krogh; Thornton, Louise] Univ Sydney, Matilda Ctr Res Mental Hlth & Subst Use, Level 6,Jane Foss Russell Bldg G02, Sydney, NSW 2006, Australia	University of Sydney	Spallek, S (corresponding author), Univ Sydney, Matilda Ctr Res Mental Hlth & Subst Use, Level 6,Jane Foss Russell Bldg G02, Sydney, NSW 2006, Australia.	sophia.spallek@sydney.edu.au	Devine, Emma Krogh/ABD-4628-2021; Kershaw, Steph/AAP-1435-2020	Kershaw, Steph/0000-0003-2494-4391; Devine, Emma Johanne Krogh/0000-0001-8110-6445; Spallek, Sophia/0000-0001-5222-1794; Thornton, Louise/0000-0001-7705-833X				[Anonymous], Supercharge your research with ChatGPT: the 6 most useful plugins for students, academics, and researchers; [Anonymous], 2023, Search engine market share in 2023; [Anonymous], 2023, Meta's progress and learnings in AI fairness and transparency; [Anonymous], National study of mental health and wellbeing; [Anonymous], 2023, The inside story of ChatGPT's astonishing potential | Greg Brockman | TED. TED YouTube page; [Anonymous], Prompt engineering for effective interaction with ChatGPT; [Anonymous], Language matters; [Anonymous], The power of words; [Anonymous], GPT-4 is OpenAI's most advanced system, producing safer and more useful responses; Ayre J, 2023, JMIR FORM RES, V7, DOI 10.2196/40645; Biron B., 2020, Business Insider; Bohannon M, Forbes; Boudry C, 2019, PEERJ, V7, DOI 10.7717/peerj.7850; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Cracks in the Ice, about us; Dean Brian, How people use google search (new user behaviour study); Dickson B, 2023, A look at open-source alternatives to ChatGPT; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; imgix, Mindframe for alcohol and other drugs. Everymind; Karabacak M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48163; Kershaw S, 2021, J MED INTERNET RES, V23, DOI 10.2196/29026; Knight W., Wired; Literacy and access, Australian Government Style Manual; Liu D, 2023, Prompt engineering for educators-making generative AI work for you; Luykx JJ, 2023, WORLD PSYCHIATRY, V22, P479, DOI 10.1002/wps.21145; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Muscat DM, 2021, J GEN INTERN MED, V36, P521, DOI 10.1007/s11606-020-05912-0; Ojenge w., University World News; openai, What is ChatGPT? OpenAI; openai.com, about us; Osborne RH, 2013, BMC PUBLIC HEALTH, V13, DOI 10.1186/1471-2458-13-658; Positive Choices, about us; Prior K., 2022, Mental Health Prev, V28; Routledge K, 2022, SSM Mental Health, V2, DOI [10.1016/j.ssmmh.2022.100073, DOI 10.1016/J.SSMMH.2022.100073]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schulman J, Reinforcement learning from human feedback: progress and challenges; Stapinski LA, 2022, JMIR PEDIATR PARENT, V5, DOI 10.2196/34721; Tober M, 2022, Zero-clicks study	38	3	3	25	28	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e51243	10.2196/51243	http://dx.doi.org/10.2196/51243			10	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Z9BQ6	38032714	Green Published, gold			2024-07-03	WOS:001114957800001
J	Rouhi, AD; Ghanem, YK; Yolchieva, L; Saleh, Z; Joshi, H; Moccia, MC; Suarez-Pierre, A; Han, JJ				Rouhi, Armaun D.; Ghanem, Yazid K.; Yolchieva, Laman; Saleh, Zena; Joshi, Hansa; Moccia, Matthew C.; Suarez-Pierre, Alejandro; Han, Jason J.			Can Artificial Intelligence Improve the Readability of Patient Education Materials on Aortic Stenosis? A Pilot Study	CARDIOLOGY AND THERAPY			English	Article						Aortic stenosis; Heart valve disease; Readability; Health literacy; Patient education material; ChatGPT; Artificial intelligence; Large language models; Chatbots	HEALTH LITERACY; QUALITY ANALYSIS; INFORMATION; SMOG	Introduction: The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public. Methods: Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt "translate to 5th-grade reading level". Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores. Results: Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th-12th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (p < 0.001) to the approximately 6th-7th grade reading level. Bard successfully improved readability across all measures (p < 0.001) except for SMOGI (p = 0.729) to the approximately 8th-9th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all p < 0.001). Conclusion: AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future.	[Rouhi, Armaun D.] Univ Penn, Perelman Sch Med, Dept Surg, Philadelphia, PA USA; [Ghanem, Yazid K.; Saleh, Zena; Joshi, Hansa; Moccia, Matthew C.] Cooper Univ Hosp, Dept Surg, Camden, NJ USA; [Yolchieva, Laman] Univ Penn, Coll Arts & Sci, Philadelphia, PA USA; [Suarez-Pierre, Alejandro] Univ Colorado, Sch Med, Dept Surg, Aurora, CO USA; [Han, Jason J.] Hosp Univ Penn, Perelman Sch Med, Dept Surg, Div Cardiovasc Surg, Philadelphia, PA 19104 USA	University of Pennsylvania; Cooper University Hospital; University of Pennsylvania; University of Colorado System; University of Colorado Anschutz Medical Campus; University of Pennsylvania	Han, JJ (corresponding author), Hosp Univ Penn, Perelman Sch Med, Dept Surg, Div Cardiovasc Surg, Philadelphia, PA 19104 USA.	Jason.Han@pennmedicine.upenn.edu		Han, Jason/0000-0001-9288-3725; Joshi, Hansa/0000-0003-2656-9265; Rouhi, Armaun/0000-0002-7724-1457; Moccia, Matthew/0009-0008-4607-3615				Bart NK, 2023, HEART LUNG CIRC, V32, P883, DOI 10.1016/j.hlc.2023.07.005; Brennan Z, 2023, CARDIOL YOUNG, V33, P1079, DOI 10.1017/S1047951123001294; Cajita MI, 2017, J CARDIOVASC NURS, V32, P156, DOI 10.1097/JCN.0000000000000324; Cajita MI, 2016, J CARDIOVASC NURS, V31, P121, DOI 10.1097/JCN.0000000000000229; Cardaioli F, 2023, AM J CARDIOL, V202, P208, DOI 10.1016/j.amjcard.2023.06.085; Daraz L, 2018, AM J MED QUAL, V33, P487, DOI 10.1177/1062860617751639; Diviani N, 2016, PATIENT EDUC COUNS, V99, P1017, DOI 10.1016/j.pec.2016.01.007; Durko AP, 2018, EUR HEART J, V39, P2635, DOI 10.1093/eurheartj/ehy107; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Goodman RS, 2023, MED-CAMBRIDGE, V4, P139, DOI 10.1016/j.medj.2023.02.008; Grabeel KL, 2018, J MED LIBR ASSOC, V106, P38, DOI 10.5195/jmla.2018.262; Gunning R., 1952, TECHNIQUE CLEAR WRIT, P36; Kincaid J. P., 1975, Derivation of new readability formulas (Automated Readability Index, Fog Count And Flesch Reading Ease Formula) for Navy Enlisted Personnel, P56; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Magnani JW, 2018, CIRCULATION, V138, pE48, DOI 10.1161/CIR.0000000000000579; MCLAUGHLIN GH, 1969, J READING, V12, P639; Moons P, 2024, EUR J CARDIOVASC NUR, V23, P122, DOI 10.1093/eurjcn/zvad087; National Institutes of Health, 2021, WRITE EASY READ HLTH; Oscalices MIL, 2019, REV ESC ENFERM USP, V53, DOI 10.1590/S1980-220X2017039803447; Rahimi SA, 2022, JMIR MED INF, V10, DOI 10.2196/36199; Rodriguez F, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.120.017372; Rouhi AD, 2023, ARTIF ORGANS, V47, P1029, DOI 10.1111/aor.14479; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Scheschenja M, 2024, CARDIOVASC INTER RAD, V47, P245, DOI 10.1007/s00270-023-03563-2; Seetharam K, 2022, CARDIOL THER, V11, P355, DOI 10.1007/s40119-022-00273-7; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Treffalls JA, 2022, ANN VASC SURG, V83, P1, DOI 10.1016/j.avsg.2021.12.079; U.S. News & World Report, BEST HOSP CARDIOLOGY; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Weiss BD., 2003, Health Literacy: A Manual for Clinicians	33	1	1	6	6	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	2193-8261	2193-6544		CARDIOL THER	Cardiol. Ther.	MAR	2024	13	1					137	147		10.1007/s40119-023-00347-0	http://dx.doi.org/10.1007/s40119-023-00347-0		JAN 2024	11	Cardiac & Cardiovascular Systems	Emerging Sources Citation Index (ESCI)	Cardiovascular System & Cardiology	JB3S5	38194058	Green Published, gold			2024-07-03	WOS:001168035400001
J	Sarzaeim, P; Mahmoud, QH; Azim, A				Sarzaeim, Paria; Mahmoud, Qusay H.; Azim, Akramul			A Framework for LLM-Assisted Smart Policing System	IEEE ACCESS			English	Article						Predictive models; Task analysis; Law enforcement; Data models; Artificial intelligence; Recurrent neural networks; Adaptation models; Few-shot learning; Large language models; Crime prediction; fine-tuning; few-shot prompting; large language models; LLM; zero-shot prompting	ARTIFICIAL-INTELLIGENCE; PREDICTION	In the face of rapidly increasing crime rates, the evolving complexity of crime data processing, and public safety challenges, the need for more advanced policing solutions has increased leading to the emergence of smart policing systems and predictive policing techniques. This urgency and shift toward smart policing incorporates artificial intelligence (AI), with a specific focus on machine learning (ML) as an essential tool for data analysis, pattern recognition, and proactive crime forecasting. Among these, the flexibility and power of AI techniques including large language models (LLMs), as a subset of generative AI, have increased the interest in applying them in real-world applications, such as financial, medical, legal, and agricultural applications. However, the abilities and possibilities of adopting LLMs in applications including crime prediction remain unexplored. This paper focuses on bridging this gap by developing a framework based on the transformative potential of BART, GPT-3, and GPT-4, three state-of-the-art LLMs, in the domain of smart policing, specifically, crime prediction. As a prototype, diverse methods such as zero-shot prompting, few-shot prompting, and fine-tuning are used to comprehensively assess the performance of these models in crime prediction based on state-of-the-art datasets from two major cities: San Francisco and Los Angeles. The main objective is to illuminate the adaptability of LLMs and their capacity to revolutionize crime analysis practices. Additionally, a comparative analysis of the aforementioned methods on the GPT series model and BART with ML techniques is provided which shows that the GPT models are more suitable than the traditional ML models for crime classification in most experimental scenarios.	[Sarzaeim, Paria; Mahmoud, Qusay H.; Azim, Akramul] Ontario Tech Univ, Dept Elect Comp & Software Engn, Oshawa, ON L1G 0C5, Canada		Sarzaeim, P (corresponding author), Ontario Tech Univ, Dept Elect Comp & Software Engn, Oshawa, ON L1G 0C5, Canada.	paria.sarzaeim@ontariotechu.net			Mitacs Accelerate collaborative research project with industry partner Mobile Innovations	Mitacs Accelerate collaborative research project with industry partner Mobile Innovations	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Afzal M, 2020, LECT NOTES COMPUT SC, V12219, P59, DOI 10.1007/978-3-030-57599-1_5; Ahishakiye Emmanuel, 2017, International Journal of Computer and Information Technology, V6, P84; Ahishakiye Emmanuel, 2017, International Journal of Computer and Information Technology, V6, P188; Aldossari Bshayer S., 2020, ICCDE 2020: Proceedings of 2020 the 6th International Conference on Computing and Data Engineering, P34, DOI 10.1145/3379247.3379279; Almanie T, 2015, Arxiv, DOI arXiv:1508.02050; Almehmadi A, 2017, SIN'17: PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON SECURITY OF INFORMATION AND NETWORKS, P307, DOI 10.1145/3136825.3136854; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Babakura A, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P250, DOI 10.1109/ISBAST.2014.7013130; Baek MS, 2021, IEEE ACCESS, V9, P131906, DOI 10.1109/ACCESS.2021.3112682; Berk RA, 2021, ANNU REV CRIMINOL, V4, P209, DOI 10.1146/annurev-criminol-051520-012342; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066; Chen JY, 2023, Arxiv, DOI [arXiv:2311.09774, DOI 10.48550/ARXIV.2311.09774]; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chen WH, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1120; DataSF, 2018, Police Department Incident Reports: 2018 to Present; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhaliwal SS, 2018, INFORMATION, V9, DOI 10.3390/info9070149; Elluri L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P198, DOI 10.1109/SMARTCOMP.2019.00053; Ferguson Andrew Guthrie, 2012, Emory Law Journal, V62, P261; Gao T., 2020, arXiv; Gayathri M., 2020, Int. J. Adv. Trends Comput. Sci. Eng., V9, P2812; Haghshenas S. S., 2023, P INT C INF COMM TEC, P1; Hassani H, 2016, STAT ANAL DATA MIN, V9, P139, DOI 10.1002/sam.11312; Iqbal Rizwan., 2013, INDIAN J SCI TECHNOL, V6, P4219, DOI 10.17485/ijst/2013/v6i3.6; Jayakody Anuradha, 2021, 2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P0148, DOI 10.1109/IEMCON53756.2021.9623145; Khan J. R., 2019, Univ. Sindh J. Inf. Commun. Technol., P17; L. A. O. Dats, 2020, Crime Data From 2020 to Present; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Liga D, 2023, COMPUT LAW SECUR REV, V51, DOI 10.1016/j.clsr.2023.105864; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Maliphol S., 2022, P PORTL INT C MAN EN, P1; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pourpanah F, 2023, IEEE T PATTERN ANAL, V45, P4051, DOI 10.1109/TPAMI.2022.3191696; Raaijmakers S, 2019, IEEE SECUR PRIV, V17, P74, DOI 10.1109/MSEC.2019.2925649; Rezayi S., 2022, P 31 INT JOINT C ART, P5150; Safat W, 2021, IEEE ACCESS, V9, P70080, DOI 10.1109/ACCESS.2021.3078117; Sarzaeim P., 2024, P 37 CAN C ART INT, P1; Sarzaeim P, 2023, COMPUTERS, V12, DOI 10.3390/computers12120255; Shingleton J. S., 2012, Crime Trend Prediction Using Regression Models for Salinas, California; Stec A, 2018, Arxiv, DOI arXiv:1806.01486; Wang HN, 2022, SOCIO-ECON PLAN SCI, V80, DOI 10.1016/j.seps.2021.101043; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Xiao CJ, 2021, AI OPEN, V2, P79, DOI 10.1016/j.aiopen.2021.06.003; Xiaoyang Mu, 2021, 2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P929, DOI 10.1109/I-SMAC52330.2021.9640837; Xie QQ, 2023, Arxiv, DOI arXiv:2306.05443; Yang F., 2019, Oxford Res. Encyclopedia, Criminology and Criminal Justice, DOI [10.1093/acrefore/9780190264079.013.508, DOI 10.1093/ACREFORE/9780190264079.013.508]; Yue SB, 2023, Arxiv, DOI arXiv:2309.11325; Zhang Boyu, 2023, arXiv; Zhang SY, 2024, Arxiv, DOI [arXiv:2308.10792, 10.48550/ARXIV.2308.10792, 10.48550/arXiv.2308.10792]; Zia T., 2022, P 52 IRES INT C, P27	54	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						74915	74929		10.1109/ACCESS.2024.3404862	http://dx.doi.org/10.1109/ACCESS.2024.3404862			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	SV9T1		gold			2024-07-03	WOS:001237349200001
J	Gue, CCY; Rahim, NDA; Rojas-Carabali, W; Agrawal, R; Palvannan, RK; Abisheganaden, J; Yip, WF				Gue, Celeste Ci Ying; Rahim, Noorul Dharajath Abdul; Rojas-Carabali, William; Agrawal, Rupesh; Palvannan, R. K.; Abisheganaden, John; Yip, Wan Fen			Evaluating the OpenAI's GPT-3.5 Turbo's performance in extracting information from scientific articles on diabetic retinopathy	SYSTEMATIC REVIEWS			English	Letter						Information extraction; Concordance; GPT-3.5 Turbo	GUIDELINES	We aimed to compare the concordance of information extracted and the time taken between a large language model (OpenAI's GPT-3.5 Turbo via API) against conventional human extraction methods in retrieving information from scientific articles on diabetic retinopathy (DR). The extraction was done using GPT3.5 Turbo as of October 2023. OpenAI's GPT-3.5 Turbo significantly reduced the time taken for extraction. Concordance was highest at 100% for the extraction of the country of study, 64.7% for significant risk factors of DR, 47.1% for exclusion and inclusion criteria, and lastly 41.2% for odds ratio (OR) and 95% confidence interval (CI). The concordance levels seemed to indicate the complexity associated with each prompt. This suggests that OpenAI's GPT-3.5 Turbo may be adopted to extract simple information that is easily located in the text, leaving more complex information to be extracted by the researcher. It is crucial to note that the foundation model is constantly improving significantly with new versions being released quickly. Subsequent work can focus on retrieval-augmented generation (RAG), embedding, chunking PDF into useful sections, and prompting to improve the accuracy of extraction.	[Gue, Celeste Ci Ying; Rahim, Noorul Dharajath Abdul; Palvannan, R. K.; Abisheganaden, John; Yip, Wan Fen] Natl Healthcare Grp, Hlth Serv & Outcomes Res, 3 Fusionopolis Link,03-08 Nexus One North, Singapore 138543, Singapore; [Rojas-Carabali, William; Agrawal, Rupesh] Tan Tock Seng Hosp, Natl Healthcare Grp Eye Inst, 11 Jalan Tan Tock Seng, Singapore 308433, Singapore; [Rojas-Carabali, William; Agrawal, Rupesh] Nanyang Technol Univ, Lee Kong Chian Sch Med, 11 Mandalay Rd, Singapore 308232, Singapore	Tan Tock Seng Hospital; Nanyang Technological University	Yip, WF (corresponding author), Natl Healthcare Grp, Hlth Serv & Outcomes Res, 3 Fusionopolis Link,03-08 Nexus One North, Singapore 138543, Singapore.	wan_fen_yip@nhg.com.sg						Bagde H, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e23050; Gargari OK, 2024, BMJ EVID-BASED MED, V29, P69, DOI 10.1136/bmjebm-2023-112678; Haddaway N., 2014, Springer Science Reviews, V2, P179, DOI [DOI 10.1007/S40362-014-0023-1, 10.1007/s40362-014-0023-1]; Innovation S., 2023, Medium; Mancin S, 2024, METHODSX, V12, DOI 10.1016/j.mex.2023.102532; Marshall IJ, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1074-9; Nussbaumer-Streit B, 2021, J CLIN EPIDEMIOL, V139, P287, DOI 10.1016/j.jclinepi.2021.05.019; Uttley L, 2023, J CLIN EPIDEMIOL, V156, P30, DOI 10.1016/j.jclinepi.2023.01.011; Woolf SH, 1999, BRIT MED J, V318, P527, DOI 10.1136/bmj.318.7182.527; Zhou CT, 2021, Arxiv, DOI arXiv:2011.02593	10	0	0	3	3	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		2046-4053		SYST REV-LONDON	Syst. Rev.	MAY 16	2024	13	1							135	10.1186/s13643-024-02523-2	http://dx.doi.org/10.1186/s13643-024-02523-2			4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RJ1J0	38755704	gold			2024-07-03	WOS:001227200500002
J	Estévez-Ayres, I; Callejo, P; Hombrados-Herrera, MA; Alario-Hoyos, C; Kloos, CD				Estevez-Ayres, Iria; Callejo, Patricia; Hombrados-Herrera, Miguel Angel; Alario-Hoyos, Carlos; Delgado Kloos, Carlos			Evaluation of LLM Tools for Feedback Generation in a Course on Concurrent Programming	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article; Early Access						Generative AI; ChatGPT; Bard; Programming; Concurrency; Generative AI; ChatGPT; Bard; Programming; Concurrency	FORMATIVE ASSESSMENT; FINE	The emergence of Large Language Models (LLMs) has marked a significant change in education. The appearance of these LLMs and their associated chatbots has yielded several advantages for both students and educators, including their use as teaching assistants for content creation or summarisation. This paper aims to evaluate the capacity of LLMs chatbots to provide feedback on student exercises in a university programming course. The complexity of the programming topic in this study (concurrency) makes the need for feedback to students even more important. The authors conducted an assessment of exercises submitted by students. Then, ChatGPT (from OpenAI) and Bard (from Google) were employed to evaluate each exercise, looking for typical concurrency errors, such as starvation, deadlocks, or race conditions. Compared to the ground-truth evaluations performed by expert teachers, it is possible to conclude that none of these two tools can accurately assess the exercises despite the generally positive reception of LLMs within the educational sector. All attempts result in an accuracy rate of 50%, meaning that both tools have limitations in their ability to evaluate these particular exercises effectively, specifically finding typical concurrency errors.	[Estevez-Ayres, Iria; Callejo, Patricia; Hombrados-Herrera, Miguel Angel; Alario-Hoyos, Carlos; Delgado Kloos, Carlos] Univ Carlos III Madrid, Dept Telemat Engn, Avda Univ 30, Leganes 28911, Madrid, Spain	Universidad Carlos III de Madrid	Estévez-Ayres, I (corresponding author), Univ Carlos III Madrid, Dept Telemat Engn, Avda Univ 30, Leganes 28911, Madrid, Spain.	ayres@it.uc3m.es; pcallejo@it.uc3m.es; mhombrad@it.uc3m.es; calario@it.uc3m.es; cdk@it.uc3m.es	Alario-Hoyos, Carlos/K-3451-2014	Alario-Hoyos, Carlos/0000-0002-3082-0814	MCIN/AEI/10.13039/501100011033	MCIN/AEI/10.13039/501100011033	No Statement Available	Afzaal M, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.723447; Ala-Mutka KM, 2005, COMPUT SCI EDUC, V15, P83, DOI 10.1080/08993400500150747; [Anonymous], 1981, Attention and selfregulation: A controltheory approach to human behavior; Barros Manuel, 2023, Formal Techniques for Distributed Objects, Components, and Systems: 43rd IFIP WG 6.1 International Conference, FORTE 2023, Held as Part of the 18th International Federated Conference on Distributed Computing Techniques, DisCoTec 2023, Proceedings. Lecture Notes in Computer Science (13910), P3, DOI 10.1007/978-3-031-35355-0_1; Blackshear S, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276514; BUTLER DL, 1995, REV EDUC RES, V65, P245, DOI 10.2307/1170684; Calcagno C, 2015, LECT NOTES COMPUT SC, V9058, P3, DOI 10.1007/978-3-319-17524-9_1; Cavalcanti AP., 2021, COMPUTERS ED ARTIFIC, V2; Chen H. Lin, 2024, P AAAI C ARTIFICIAL, V38, P17754; Chou CY, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00233-y; Church KW, 2021, NAT LANG ENG, V27, P763, DOI 10.1017/S1351324921000322; Dai W, 2023, IEEE INT CONF ADV LE, P323, DOI 10.1109/ICALT58122.2023.00100; Deeva G, 2021, COMPUT EDUC, V162, DOI 10.1016/j.compedu.2020.104094; Fielding AH, 1997, ENVIRON CONSERV, V24, P38, DOI 10.1017/S0376892997000088; Gao A., 2023, Prompt engineering for large language models; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Holt R. C., 1972, Computing Surveys, V4, P179, DOI 10.1145/356603.356607; Hundt C, 2017, J PARALLEL DISTR COM, V105, P163, DOI 10.1016/j.jpdc.2016.12.028; Ihantola P., 2010, P KOLI CALLING, P86, DOI 10.1145/1930464.1930480; Jenkins T., 2002, Proceedings of the 3rd Annual Conference of the LTSN Centre for Information and Computer Sciences, P53, DOI DOI 10.1109/ISIT.2013.6620675; Jia Q., 2022, Insta-reviewer: A data-driven approach for generating instant feedback on students' project reports; Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711; Lajis A., 2018, Journal of Telecommunication, Electronic and Computer Engineering, V10, P109; Lea D, 2005, SCI COMPUT PROGRAM, V58, P293, DOI 10.1016/j.scico.2005.03.007; Li CL, 2021, INT J ARTIF INTELL E, V31, P186, DOI 10.1007/s40593-020-00235-x; Lu S, 2008, ACM SIGPLAN NOTICES, V43, P329, DOI 10.1145/1353536.1346323; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Marwan Samiha, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P194, DOI 10.1145/3372782.3406264; Melo S.M., 2015, P 6 INT WORKSH AUT T, P31, DOI [10.1145/2804322.2804328, DOI 10.1145/2804322.2804328]; Messer M, 2024, ACM T COMPUT EDUC, V24, DOI 10.1145/3636515; MEYER LA, 1986, ELEM SCHOOL J, V87, P227, DOI 10.1086/461491; Mizumoto A., 2023, Research Methods in Applied Linguistics, V2, P100050, DOI DOI 10.1016/J.RMAL.2023.100050; Netzer R. H. B., 1992, ACM Letters on Programming Languages and Systems, V1, P74, DOI 10.1145/130616.130623; Nicol DJ, 2006, STUD HIGH EDUC, V31, P199, DOI 10.1080/03075070600572090; Orwell J., 2005, J ED RESOURCES COMPU, V5, DOI [10.1145/1163405.1163409, DOI 10.1145/1163405.1163409]; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Pinto G, 2015, J SYST SOFTWARE, V106, P59, DOI 10.1016/j.jss.2015.04.064; Pugh W., 2007, ASE, P513, DOI [10.1145/1321631.1321722, DOI 10.1145/1321631.1321722]; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radiya-Dixit E, 2020, PR MACH LEARN RES, V108, P2435; Rahman K.A., 2007, A review on the static analysis approach in the automated programming assessment systems; SADLER DR, 1989, INSTR SCI, V18, P119, DOI 10.1007/BF00117714; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schaeffer R, 2023, Arxiv, DOI [arXiv:2304.15004, DOI 10.48550/ARXIV.2304.15004, 10.48550/arXiv.2304.15004]; Schellhorn G, 2016, LECT NOTES COMPUT SC, V9681, P193, DOI 10.1007/978-3-319-33693-0_13; Stehle SM, 2019, INT J STEM EDUC, V6, DOI 10.1186/s40594-019-0192-1; Sutter H, 2005, DR DOBBS J, V30, P16; Tarek M., 2022, 2022 2 INT MOB INT U, P230; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu D, 2016, INFORM SOFTWARE TECH, V76, P1, DOI 10.1016/j.infsof.2016.04.004; Yilmaz R., 2023, Computers and Education: Artificial Intelligence, V4, DOI DOI 10.1016/J.CAEAI.2023.100147; Yu FY, 2017, ASIA PAC SOFWR ENG, P594, DOI 10.1109/APSEC.2017.71; Zhang Z., 2024, P AAAI C ART INT, V38, P23250; ZIMMERMAN BJ, 1990, EDUC PSYCHOL, V25, P3, DOI 10.1207/s15326985ep2501_2	55	0	0	7	7	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	2024 MAY 15	2024										10.1007/s40593-024-00406-0	http://dx.doi.org/10.1007/s40593-024-00406-0		MAY 2024	17	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	QU7N5		hybrid			2024-07-03	WOS:001223448800001
J	Sprague, K; Czischek, S				Sprague, Kyle; Czischek, Stefanie			Variational Monte Carlo with large patched transformers	COMMUNICATIONS PHYSICS			English	Article							QUANTUM; ATOM	Large language models, like transformers, have recently demonstrated immense powers in text and image generation. This success is driven by the ability to capture long-range correlations between elements in a sequence. The same feature makes the transformer a powerful wavefunction ansatz that addresses the challenge of describing correlations in simulations of qubit systems. Here we consider two-dimensional Rydberg atom arrays to demonstrate that transformers reach higher accuracies than conventional recurrent neural networks for variational ground state searches. We further introduce large, patched transformer models, which consider a sequence of large atom patches, and show that this architecture significantly accelerates the simulations. The proposed architectures reconstruct ground states with accuracies beyond state-of-the-art quantum Monte Carlo methods, allowing for the study of large Rydberg systems in different phases of matter and at phase transitions. Our high-accuracy ground state representations at reasonable computational costs promise new insights into general large-scale quantum many-body systems. Ground state representations with artificial neural network methods enable high-accuracy simulations of quantum many-body systems. The authors study the performance of the transformer network architecture on this task and demonstrate its vast potential for novel findings in quantum physics.	[Sprague, Kyle; Czischek, Stefanie] Univ Ottawa, Dept Phys, Ottawa, ON K1N 6N5, Canada	University of Ottawa	Czischek, S (corresponding author), Univ Ottawa, Dept Phys, Ottawa, ON K1N 6N5, Canada.	stefanie.czischek@uottawa.ca	Czischek, Stefanie/AAQ-4176-2020		Digital Research Alliance of Canada	Digital Research Alliance of Canada	We thank J. Carrasquilla, R.G. Melko, M. Reh, M.S. Moss, and E. Inack for fruitful discussions and feedback. We are grateful for support on the quantum Monte Carlo simulations by E. Merali. This research was enabled in part by support provided by the Digital Research Alliance of Canada (alliancecan.ca).	Barredo D, 2018, NATURE, V561, P79, DOI 10.1038/s41586-018-0450-2; Becca F, 2017, QUANTUM MONTE CARLO APPROACHES FOR CORRELATED SYSTEMS, P1, DOI 10.1017/9781316417041; Bennewitz ER, 2022, NAT MACH INTELL, V4, P618, DOI 10.1038/s42256-022-00509-0; Bravyi S, 2008, QUANTUM INF COMPUT, V8, P361; Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302; Carrasquilla J, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.040201; Carrasquilla J, 2021, PHYS REV A, V104, DOI 10.1103/PhysRevA.104.032610; Carrasquilla J, 2020, ADV PHYS-X, V5, DOI 10.1080/23746149.2020.1797528; Carrasquilla J, 2019, NAT MACH INTELL, V1, P155, DOI 10.1038/s42256-019-0028-1; Cha P, 2022, MACH LEARN-SCI TECHN, V3, DOI 10.1088/2632-2153/ac362b; Cho Bv, 2014, ARXIV14061078, P1724, DOI 10.3115/v1/d14-1179; Czischek S, 2022, PHYS REV B, V105, DOI 10.1103/PhysRevB.105.205108; Czischek S, 2018, PHYS REV B, V98, DOI 10.1103/PhysRevB.98.024311; Dawid A, 2023, Arxiv, DOI [arXiv:2204.04198, 10.48550/arXiv.2204.04198]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Ebadi S, 2021, NATURE, V595, P227, DOI 10.1038/s41586-021-03582-4; Endres M, 2016, SCIENCE, V354, P1024, DOI 10.1126/science.aah3752; Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2; Hartmann MJ, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.250502; Hibat-Allah M, 2023, PHYS REV B, V108, DOI 10.1103/PhysRevB.108.075152; Hibat-Allah M, 2024, Arxiv, DOI [arXiv:2207.14314, DOI 10.48550/ARXIV.2207.14314]; Hibat-Allah M, 2021, NAT MACH INTELL, V3, P952, DOI 10.1038/s42256-021-00401-3; Hibat-Allah M, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.023358; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55; Jaksch D, 2000, PHYS REV LETT, V85, P2208, DOI 10.1103/PhysRevLett.85.2208; Kalinowski M, 2022, PHYS REV B, V105, DOI 10.1103/PhysRevB.105.174417; Khandoker SA, 2023, MACH LEARN-SCI TECHN, V4, DOI 10.1088/2632-2153/acb895; Lukin MD, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.037901; Luo D, 2023, PHYS REV RES, V5, DOI 10.1103/PhysRevResearch.5.013216; Luo D, 2022, PHYS REV LETT, V128, DOI 10.1103/PhysRevLett.128.090501; Ma HL, 2023, Arxiv, DOI arXiv:2305.05433; Melko RG, 2019, NAT PHYS, V15, P887, DOI 10.1038/s41567-019-0545-1; Merali E, 2023, Arxiv, DOI arXiv:2107.00766; Miles C, 2023, PHYS REV RES, V5, DOI 10.1103/PhysRevResearch.5.013026; Morawetz S, 2021, PHYS REV A, V104, DOI 10.1103/PhysRevA.104.012401; Morin F., 2005, P AISTATS, V5, P246; Nagy A, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.250501; Neugebauer M, 2020, PHYS REV A, V102, DOI 10.1103/PhysRevA.102.042604; Paszke A, 2019, ADV NEUR IN, V32; Reh M, 2021, PHYS REV LETT, V127, DOI 10.1103/PhysRevLett.127.230501; Samajdar R, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2015785118; Samajdar R, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.103601; Schmale T, 2022, NPJ QUANTUM INFORM, V8, DOI 10.1038/s41534-022-00621-4; Schmitt M, 2020, PHYS REV LETT, V125, DOI 10.1103/PhysRevLett.125.100503; Scholl P, 2021, NATURE, V595, P233, DOI 10.1038/s41586-021-03585-1; Sharir O, 2022, Arxiv, DOI arXiv:2212.11296; Sharir O, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.020503; Torlai G, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.022060; Torlai G, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.230504; Torlai G, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.240503; Torlai G, 2018, NAT PHYS, V14, P447, DOI 10.1038/s41567-018-0048-5; Valenti A, 2022, PHYS REV RES, V4, DOI 10.1103/PhysRevResearch.4.L012010; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vicentini F, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.250503; Viteritti LL, 2023, PHYS REV LETT, V130, DOI 10.1103/PhysRevLett.130.236401; Viteritti LL, 2022, SCIPOST PHYS, V12, DOI 10.21468/SciPostPhys.12.5.166; von Glehn I, 2023, Arxiv, DOI arXiv:2211.13672; Xu WC, 2021, PHYS REV LETT, V127, DOI 10.1103/PhysRevLett.127.050501; Zhai XH, 2022, Arxiv, DOI arXiv:2106.04560; Zhang YH, 2023, PHYS REV B, V107, DOI 10.1103/PhysRevB.107.075147; Zheng A, 2024, PHYS REV APPL, V21, DOI 10.1103/PhysRevApplied.21.014037	62	0	0	0	0	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2399-3650			COMMUN PHYS-UK	Commun. Phys.	MAR 11	2024	7	1							90	10.1038/s42005-024-01584-y	http://dx.doi.org/10.1038/s42005-024-01584-y			11	Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Physics	KU1Q0		Green Submitted, gold			2024-07-03	WOS:001182389900002
J	Dan, SJ; Feng, W				Dan, Songjian; Feng, Wei			Enhancing machine vision: the impact of a novel innovative technology on video question-answering	SOFT COMPUTING			English	Article; Early Access						Robot vision; Visual question answering; Text-image matching; VLM; LLM		The robot video question-answering system is an artificial intelligence application that integrates computer vision and natural language processing technologies. Recently, it has received widespread attention, especially with the rapid development of large language models (LLMs). The core technical challenge lies in the application of visual question answering (VQA). However, visual question answering currently faces several challenges. Firstly, the acquisition of human annotations is costly, and secondly, existing models require expensive retraining when replacing a particular module. We propose the VLM2LLM model, which significantly improves the performance of multimodal question-answering tasks by integrating visual-language matching and large-scale language models. Specifically, it overcomes the limitations of requiring massive computational resources for training and inference in previous models. Furthermore, it allows for the upgrading of our LLM version according to the latest research advancements and needs. The results demonstrate that the VLM2LLM model achieves the highest accuracy compared to other state-of-the-art models on three datasets: QAv2, A-OKVQA, and OK-VQA. We hope that the VLM2LLM model can drive advancements in the field of robot video question-answering and provide innovative solutions for a wider range of application domains.	[Dan, Songjian; Feng, Wei] Chongqing Univ Educ, Sch Math & Big Data, Chongqing, Peoples R China	Chongqing University of Education	Dan, SJ (corresponding author), Chongqing Univ Educ, Sch Math & Big Data, Chongqing, Peoples R China.	dansj@cque.edu.cn; fengwei@cque.edu.cn	Feng, Wei/HTP-5852-2023	Feng, Wei/0000-0001-9769-3111	Scientific and Technological Research Program of Chongqing Municipal Education Commission; Chongqing Engineering Laboratory of Children's Big Data; Chongqing Engineering Research Center for Interactive Education Electronics; Chongqing Key Discipline of Electronic Information	Scientific and Technological Research Program of Chongqing Municipal Education Commission; Chongqing Engineering Laboratory of Children's Big Data; Chongqing Engineering Research Center for Interactive Education Electronics; Chongqing Key Discipline of Electronic Information	This research was supported by the Chongqing Engineering Laboratory of Children's Big Data, the Chongqing Engineering Research Center for Interactive Education Electronics, and the Chongqing Key Discipline of Electronic Information.	Akula AR, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2148; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Berrios W, 2023, Arxiv, DOI arXiv:2306.16410; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Dai W., 2022, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong XL, 2024, IEEE T COMPUT SOC SY, V11, P1440, DOI 10.1109/TCSS.2023.3241003; Dou ZY, 2022, PROC CVPR IEEE, P18145, DOI 10.1109/CVPR52688.2022.01763; El-Hendawy AM, 2011, TRANSIT METAL CHEM, V36, P351, DOI 10.1007/s11243-011-9477-z; Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102; Guo JX, 2023, PROC CVPR IEEE, P10867, DOI 10.1109/CVPR52729.2023.01046; Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Hou R., 2020, Signal Process Image Commun, V83; Jin WJ, 2022, Arxiv, DOI arXiv:2110.08484; Li D, 2023, APPL SOFT COMPUT, V144, DOI 10.1016/j.asoc.2023.110487; Li JH, 2021, ADV NEUR IN, V34; Li JN, 2022, PR MACH LEARN RES; Li X, 2020, COMPUTER VISION ECCV; Liu Y, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105584; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216; Ning X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108873; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Schwenk D, 2022, LECT NOTES COMPUT SC, V13668, P146, DOI 10.1007/978-3-031-20074-8_9; Sharma D., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P1964; Shen S., 2021, arXiv; Si Q, 2021, arXiv; Tian SS, 2023, NEUROCOMPUTING, V545, DOI 10.1016/j.neucom.2023.126300; Trust T., 2023, Contemp Issues Technol Teach Educ, V23, P1; Vaswani A, 2017, ADV NEUR IN, V30; Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Zhang LM, 2022, MULTIMED TOOLS APPL, V81, P9277, DOI 10.1007/s11042-021-11549-w; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	38	0	0	10	10	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1432-7643	1433-7479		SOFT COMPUT	Soft Comput.	2024 JAN 18	2024										10.1007/s00500-023-09536-4	http://dx.doi.org/10.1007/s00500-023-09536-4		JAN 2024	14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FE0U3					2024-07-03	WOS:001143976100001
J	Fan, JM; Zheng, P				Fan, Junming; Zheng, Pai			A vision-language-guided robotic action planning approach for ambiguity mitigation in human-robot collaborative manufacturing	JOURNAL OF MANUFACTURING SYSTEMS			English	Article						Vision-language reasoning; Human-robot collaboration; Smart manufacturing; Deep learning; Computer vision		Human-robot collaboration (HRC) has been recognized as a potent pathway towards mass personalization in the manufacturing sector, by leveraging the synergy of human creativity and robotic precision. Previous approaches rely heavily on visual perception to autonomously comprehend the HRC environment. However, the inherent ambiguity in human-robot communication cannot be consistently neutralized by relying solely on visual cues. With the recently soaring popularity of large language models (LLMs), the consideration of language data as a complementary information source has increasingly drawn research attention, while the application of such large models, particularly within the context of HRC in manufacturing, remains largely under-explored. In response to this gap, a vision-language reasoning approach is proposed to mitigate the communication ambiguity prevalent in human-robot collaborative manufacturing scenarios. A referred object retrieval model is first designed to alleviate the object-reference ambiguity in the human language command. This model is then seamlessly integrated into an LLM-based robotic action planner to achieve an improved HRC performance. The effectiveness of the proposed approach is demonstrated empirically through a series of experiments conducted on the object retrieval model and its application in a human-robot collaborative assembly case.	Hong Kong Polytech Univ, Res Inst Adv Mfg, Dept Ind & Syst Engn, Hong Kong, Peoples R China; Hong Kong Polytech Univ, Dept Ind & Syst Engn, PolyU Rhein Koster Joint Lab Smart Mfg, Hong Kong, Peoples R China	Hong Kong Polytechnic University; Hong Kong Polytechnic University	Zheng, P (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong 999077, Peoples R China.	pai.zheng@polyu.edu.hk			Research Institute for Advanced Manufacturing (RIAM) of The Hong Kong Polytechnic University [1-CDJT]; Intra-faculty interdisciplinary project [1-WZ4N]; Research Committee of The Hong Kong Polytechnic University; General Research Fund from the Research Grants Council of the Hong Kong Special Administrative Region, China [PolyU15210222, PolyU15206723]	Research Institute for Advanced Manufacturing (RIAM) of The Hong Kong Polytechnic University; Intra-faculty interdisciplinary project; Research Committee of The Hong Kong Polytechnic University; General Research Fund from the Research Grants Council of the Hong Kong Special Administrative Region, China	The work described in this paper was mainly supported by the funding support from the Research Institute for Advanced Manufacturing (RIAM) of The Hong Kong Polytechnic University (project code: 1-CDJT) , the intra-faculty interdisciplinary project 2023/24 (1-WZ4N) , by the Research Committee of The Hong Kong Polytechnic University, and the General Research Fund from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. PolyU15210222 and PolyU15206723) .	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ajoudani A, 2018, AUTON ROBOT, V42, P957, DOI 10.1007/s10514-017-9677-2; Brohan A, 2023, Arxiv, DOI arXiv:2307.15818; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen HD, 2022, J MANUF SCI E-T ASME, V144, DOI 10.1115/1.4054297; Chen M., 2021, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding HH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16301, DOI 10.1109/ICCV48922.2021.01601; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Fan JM, 2022, ROBOT CIM-INT MANUF, V75, DOI 10.1016/j.rcim.2021.102304; Gupta T, 2023, PROC CVPR IEEE, P14953, DOI 10.1109/CVPR52729.2023.01436; Huang SY, 2023, Arxiv, DOI arXiv:2305.11176; Jiang Y, 2023, P 40 INT C MACH LEAR; Kazemzadeh S., 2014, P 2014 C EMPIRICAL M, P787, DOI [DOI 10.3115/V1/D14-1086, 10.3115/v1/d14-1086]; Li SF, 2023, J MANUF SYST, V68, P304, DOI 10.1016/j.jmsy.2023.03.013; Li SF, 2021, J MANUF SYST, V60, P547, DOI 10.1016/j.jmsy.2021.07.017; Liang YS, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2023.101888; Lin K, 2023, Arxiv, DOI arXiv:2303.12153; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu HY, 2018, INT J IND ERGONOM, V68, P355, DOI 10.1016/j.ergon.2017.02.004; Liu R, 2018, ADV NEUR IN, V31; Liu SC, 2022, J MANUF SCI E-T ASME, V144, DOI 10.1115/1.4053806; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Matheson E, 2019, ROBOTICS, V8, DOI 10.3390/robotics8040100; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P11205, DOI 10.1109/LRA.2022.3196123; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P7327, DOI 10.1109/LRA.2022.3180108; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shridhar M., 2022, C ROBOT LEARNING, P894; Song CH, 2023, IEEE I CONF COMP VIS, P2986, DOI 10.1109/ICCV51070.2023.00280; Song Y, 2022, ARXIV; Stengel-Eskin E, 2022, PMLR, P1486; Sun Y, 2022, IEEE T SYST MAN CY-S, V52, P728, DOI 10.1109/TSMC.2020.3005340; Tan HL, 2020, IEEE IMAGE PROC, P1426, DOI 10.1109/ICIP40778.2020.9190659; Tang C, 2023, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Vemprala S, 2023, Arxiv, DOI arXiv:2306.17582; Venkatesh SG, 2021, IEEE INT CONF ROBOT, P11196, DOI 10.1109/ICRA48506.2021.9560895; Wang L, 2019, CIRP ANN-MANUF TECHN, V68, P701, DOI 10.1016/j.cirp.2019.05.002; Wang LH, 2022, J MANUF SYST, V62, P199, DOI 10.1016/j.jmsy.2021.11.001; Wang T, 2021, J MANUF SYST, V58, P261, DOI 10.1016/j.jmsy.2020.07.011; Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139; Xiong QQ, 2020, J MANUF SYST, V56, P605, DOI 10.1016/j.jmsy.2020.04.007; Xu ZN, 2023, IEEE I CONF COMP VIS, P17457, DOI 10.1109/ICCV51070.2023.01605; Yin Y, 2023, ROBOT CIM-INT MANUF, V81, DOI 10.1016/j.rcim.2022.102515; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng P, 2022, CIRP ANN-MANUF TECHN, V71, P377, DOI 10.1016/j.cirp.2022.04.016	49	0	0	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0278-6125	1878-6642		J MANUF SYST	J. Manuf. Syst.	JUN	2024	74						1009	1018		10.1016/j.jmsy.2024.05.003	http://dx.doi.org/10.1016/j.jmsy.2024.05.003			10	Engineering, Industrial; Engineering, Manufacturing; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Operations Research & Management Science	UB8V3					2024-07-03	WOS:001245702100001
J	Liu, ZW; Zhang, TL; Yang, KL; Thompson, P; Yu, ZP; Ananiadou, S				Liu, Zhiwei; Zhang, Tianlin; Yang, Kailai; Thompson, Paul; Yu, Zeping; Ananiadou, Sophia			Emotion detection for misinformation: A review	INFORMATION FUSION			English	Review						Sentiment analysis; Emotion detection; Misinformation; Rumor; Fake news; Stance detection	FAKE NEWS DETECTION; RUMOR DETECTION; SENTIMENT; INFORMATION; LANGUAGE	With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people's lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion -based methods for misinformation detection, with a particular focus on advanced fusion methods. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance -based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion -based misinformation detection based on large language models, and suggest future research directions, including data collection (multi -platform, multilingual), annotation, benchmark, multimodality, and interpretability.	[Liu, Zhiwei; Zhang, Tianlin; Yang, Kailai; Thompson, Paul; Yu, Zeping; Ananiadou, Sophia] Univ Manchester, Natl Ctr Text Min, Dept Comp Sci, Manchester M1 7DN, England	University of Manchester	Ananiadou, S (corresponding author), Univ Manchester, Natl Ctr Text Min, Dept Comp Sci, Manchester M1 7DN, England.	sophia.ananiadou@manchester.ac.uk	Yang, Kailai/KIB-2102-2024; Zhang, Tianlin/V-8168-2019	Zhang, Tianlin/0000-0003-0843-1916; Liu, Zhiwei/0000-0002-7015-5054; Yang, Kailai/0000-0003-3142-2516	Department of Computer Science at the University of Manchester; Centre for Digital Trust and Society at the University of Manchester; New Energy and Industrial Technology Development Organization (NEDO); Manchester-Melbourne-Toronto Research Fund	Department of Computer Science at the University of Manchester; Centre for Digital Trust and Society at the University of Manchester; New Energy and Industrial Technology Development Organization (NEDO)(New Energy and Industrial Technology Development Organization (NEDO)); Manchester-Melbourne-Toronto Research Fund	This work has been supported by the scholar award from the Department of Computer Science at the University of Manchester. This work has also been supported by Centre for Digital Trust and Society at the University of Manchester, Manchester-Melbourne-Toronto Research Fund, and New Energy and Industrial Technology Development Organization (NEDO) .	Abdul-Mageed M, 2020, Arxiv, DOI arXiv:1912.13072; Acheampong FA, 2020, ENG REP, V2, DOI 10.1002/eng2.12189; Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9; Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9; Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170; Aka Uymaz H, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104922; Aker Ahmet, 2017, P INT C RECENT ADV, P31, DOI [DOI 10.26615/978-954-452-049-6_005, 10.26615/978-954-452- 049- 6_ 005]; Al-Saif HF, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13158815; Al -Tai M.H., 2023, Al-Mustansiriyah J. Sci., V34, P70; Alhindi Tariq, 2018, P 1 WORKSHOP FACT EX, P85, DOI [DOI 10.18653/V1/W18-5513, 10.18653/v1/W18-5513,eprint:https://aclanthology.org/W18-5513.pdf]; Ali G, 2023, MULTIMED TOOLS APPL, V82, P7017, DOI 10.1007/s11042-022-13595-4; Ali K, 2022, COMPUT HUM BEHAV, V134, DOI 10.1016/j.chb.2022.107307; Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211; Alonso MA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111348; Alsaif HF, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105801; Alslaity A, 2024, BEHAV INFORM TECHNOL, V43, P139, DOI 10.1080/0144929X.2022.2156387; [Anonymous], 2017, P 11 INT WORKSHOP SE; [Anonymous], 2017, P 11 INT WORKSHOP; [Anonymous], 2017, P 11 INT WORKSHOP; Anoop K., 2020, IDEAS, V2020; Arkaitz Z., 2016, PHEME rumour scheme dataset: Journalism use case; Arora S, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7124; Augenstein I., 2019, arXiv; Balshetwar SV, 2023, MULTIMED TOOLS APPL, V82, P35781, DOI 10.1007/s11042-023-14883-3; Barbieri F, 2020, Arxiv, DOI [arXiv:2010.12421, DOI 10.48550/ARXIV.2010.12421, 10.48550/ARXIV.2010.12421]; Barron-Cedeno A., EXPT IRMEETS MULT; Baziotis C., 2017, P 11 INT WORKSHOP, P747; Bhatt G, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1353, DOI 10.1145/3184558.3191577; Bhutani B., 2019, 2019 12 INT C CON, P1; Boididou C., 2016, Verifying multimedia use at MediaEval 2016; Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035; Bradley Margaret M., 1999, Technical report C-1, DOI DOI 10.1109/MIC.2008.114; Cambria E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3829; Caramancion KM, 2023, Arxiv, DOI arXiv:2306.17176; de Albornoz JC, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3562; Carvalho F, 2018, P INT C CHIL COMPUT; Castelo S, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P975, DOI 10.1145/3308560.3316739; Chakraborty A., 2023, P AAAI C ARTIFIC, V37, P16178; Chen M., 2023, arXiv; Cheng MX, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.644801; Cheung TH, 2023, Arxiv, DOI arXiv:2309.00240; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Choudhary M., 2021, 2021 2 INT C EMERGIN, P1; Choudhry A., 2022, P 19 INT C NATURAL, P75; Choudhry A, 2024, IEEE T COMPUT SOC SY, V11, P588, DOI 10.1109/TCSS.2022.3228312; Chuai Y, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.970174; CLEF2020, 2020, CLEF2020-CheckThat! Lab; Colneric N, 2020, IEEE T AFFECT COMPUT, V11, P433, DOI 10.1109/TAFFC.2018.2807817; Comito C, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01104-w; Conforti C., 2018, P 1 WORKSH FACT EXTR, P40; Cuenca W., 2022, Computational Intelligence and Mathematics for Tackling Complex Problems, V2, P129; Cui JF, 2023, ARTIF INTELL REV, V56, P8469, DOI 10.1007/s10462-022-10386-z; Cui LM, 2020, Arxiv, DOI arXiv:2006.00885; Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894; D'Ulizia A, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.518; da Silva Flavio Roberto Matias, 2020, WebMedia '20: Proceedings of the Brazilian Symposium on Multimedia and the Web, P241, DOI 10.1145/3428658.3430965; da Silva FCD, 2022, LECT NOTES ARTIF INT, V13788, P107, DOI 10.1007/978-3-031-22419-5_10; de Souza M. P., 2020, P BRAZILIAN S MULT, P217; Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040; Derczynski L, 2017, Arxiv, DOI arXiv:1704.05972; Devika MD, 2016, PROCEDIA COMPUT SCI, V87, P44, DOI 10.1016/j.procs.2016.05.124; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DiFonzo N, 2007, DIOGENES, V54, P19, DOI 10.1177/0392192107073433; Dong Diwen, 2022, 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC), P2174, DOI 10.1109/SMC53654.2022.9945398; Dong W, 2020, J MED INTERNET RES, V22, DOI 10.2196/21933; Dong ZD, 2003, 2003 INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING, PROCEEDINGS, P820; Dua V, 2023, WIRELESS PERS COMMUN, V131, P2841, DOI 10.1007/s11277-023-10582-2; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; Enayet Omar, 2017, P 11 INT WORKSH SEM, P470, DOI 10.18653/v1/S17-2082; Esuli A., 2007, EVALUATION, V17, P1; Ezeakunne U., 2020, INT C SOCIAL COMP, P1; Fang LT, 2023, IEEE T KNOWL DATA EN, V35, P10309, DOI 10.1109/TKDE.2023.3267821; Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535; Feng S., 2023, arXiv; Fernandez M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P595, DOI 10.1145/3184558.3188730; Ferreira W., 2016, P 2016 C N AM CHAP; Fersini E., 2020, CLEF (Working Notes); Fu Chenbo, 2022, Big Data and Social Computing: 7th China National Conference, BDSC 2022, Revised Selected Papers. Communications in Computer and Information Science (1640), P275, DOI 10.1007/978-981-19-7532-5_18; Gagiano M., 2023, EPiC Ser. Comput., V93, P56; Gao X, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116680; Ghanem B., 2019, P 13 INT WORKSHOP SE, P1125; Ghanem B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P679; Giasemidis Georgios, 2016, Social Informatics. 8th International Conference, SocInfo 2016. Proceedings: LNCS 10046, P185, DOI 10.1007/978-3-319-47880-7_12; Giasemidis G, 2020, IEEE T KNOWL DATA EN, V32, P1, DOI 10.1109/TKDE.2018.2880192; Goel S, 2016, MANAGE SCI, V62, P180, DOI 10.1287/mnsc.2015.2158; Gorrell Genevieve, 2019, P 13 INT WORKSHOP SE, P845, DOI [10.18653/v1/S19-2147, DOI 10.18653/V1/S19-2147]; Guo QJ, 2023, Arxiv, DOI arXiv:2304.09421; Gupta V., 2022, FINDINGS ASS COMP, P464; Hakak NM, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P397, DOI 10.1109/COMPTELIX.2017.8004002; Hamed SK, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23041748; Hamidian S., 2019, P 13 INT WORKSHOP, P1115; Hanselowski Andreas, 2018, Proceedings of the 27th International Conference on Computational Linguistics, P1859; Hansen C, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P994, DOI 10.1145/3308560.3316736; Haque A., 2022, 2012 IEEEACM INT C, P533; Hardalov M, 2022, Arxiv, DOI arXiv:2103.00242; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He L, 2022, J BIOMED INFORM, V132, DOI 10.1016/j.jbi.2022.104142; Horne Benjamin D., 2017, This Just in: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire Than Real News; Horner CG, 2021, J MANAGE INFORM SYST, V38, P1039, DOI 10.1080/07421222.2021.1990610; Hosseini M, 2023, Online Soc. Netw. Media, V36; Hu BZ, 2024, Arxiv, DOI [arXiv:2309.12247, 10.1609/aaai.v38i20.30214, DOI 10.48550/ARXIV.2309.12247]; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Iwendi C, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107967; Jain V, 2022, NEURAL COMPUT APPL, V34, P771, DOI 10.1007/s00521-021-06450-4; Janchevski A., 2019, P 13 INT WORKSHOP, P1083; Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454; Kaggle, 2016, Getting real about fake news, 2016; Kaizhou Xuan, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P560, DOI 10.1109/ICDMW.2019.00085; Kaliyar RK, 2020, PROCEEDINGS OF THE 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS-2020), DOI 10.1109/icccs49678.2020.9277353; Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y; Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005; Kawintiranon K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4725; Kelk I, 2022, PROCEEDINGS OF THE FIFTH FACT EXTRACTION AND VERIFICATION WORKSHOP (FEVER 2022), P29; Khan N.S., 2022, INT C INTELLIGENT, P439; Khandelwal A, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), P10, DOI 10.1145/3430984.3431007; Kim A, 2019, J MANAGE INFORM SYST, V36, P931, DOI 10.1080/07421222.2019.1628921; Kochkina Elena, 2018, Figshare; Kolev V, 2022, ICAART, P429, DOI 10.5220/0010873900003116; Kumari R, 2023, J INTELL INF SYST, V61, P673, DOI 10.1007/s10844-023-00789-x; Kumari R, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534218; Kumari R, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102740; Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344; Lei SL, 2024, Arxiv, DOI arXiv:2309.11911; Li JF, 2023, PROCEEDINGS OF THE 15TH ACM WEB SCIENCE CONFERENCE, WEBSCI 2023, P128, DOI 10.1145/3578503.3583595; Li Q, 2019, P 13 INT WORKSH SEM, P855, DOI DOI 10.1007/978-3-030-05861-684; Li R, 2021, Acad. J. Humanit. Soc. Sci., V4, P38; Li S., 2020, Towards Data Science; Li YR, 2017, Arxiv, DOI [arXiv:1710.03957, 10.48550/arXiv.1710.03957]; Maia IML, 2021, PROCEEDINGS OF THE 27TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB (WEBMEDIA '21), P212, DOI 10.1145/3470482.3479467; Lillie A.E., 2019, NORDIC C COMPUTAT, P208; Lin Tian, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P575, DOI 10.1007/978-3-030-45439-5_38; Liu Bing, 2005, Proceedings of 14th International Conference of World Wide Web, P342, DOI 10.1145/1060745.1060797; Liu HT, 2024, Arxiv, DOI arXiv:2310.03744; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu Y., 2023, J. Intell. Fuzzy Systems (Preprint), P1; Lixuan Ding, 2020, Big Data - BigData 2020. 9th International Conference Held as Part of the Services Conference Federation, SCF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12402), P52, DOI 10.1007/978-3-030-59612-5_5; Lukasik M, 2015, Arxiv, DOI arXiv:1506.00468; Luvembe Alex Munyole, 2023, Information Processing and Management, DOI 10.1016/j.ipm.2023.103354; Mohammad SM, 2013, Arxiv, DOI arXiv:1308.6242; Ma CS, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1181, DOI 10.1145/3459637.3482260; Ma J., 2016, 25 INT JOINT C ART; Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066; Ma ZY, 2023, Arxiv, DOI arXiv:2306.07201; Mandal K., 2023, 2023 3 INT C SECURE, P611, DOI DOI 10.1109/ICSCCC58608.2023.10176530; Maniou TA, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13010341; Mao R., 2022, IEEE Trans. Affect. Comput.; Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972; Martel C, 2020, COGN RES, V5, DOI 10.1186/s41235-020-00252-3; Masood Razan, 2018, KMIS, V3, P126; Miao Xin, 2021, NATURAL LANGUAGE PRO, P570; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mitra T, 2015, P 9 INT C WEB SOC ME, P258, DOI [DOI 10.1609/ICWSM.V9I1.14625, 10.1609/icwsm.v9i1.14625]; Miwa M, 2014, J BIOMED INFORM, V51, P242, DOI 10.1016/j.jbi.2014.06.005; Mohamed B., 2022, Combating fake news with computational intelligence techniques, P387; Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P174; Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433; Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x; Monteiro RA, 2018, LECT NOTES ARTIF INT, V11122, P324, DOI 10.1007/978-3-319-99722-3_33; Mutlu EC, 2020, DATA BRIEF, V33, DOI 10.1016/j.dib.2020.106401; Nakamura K, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6149; Nan Q, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3343, DOI 10.1145/3459637.3482139; Nielsen F.A., 2011, arXiv, DOI DOI 10.48550/ARXIV.1103.2903; O'Mara-Eves A, 2015, SYST REV-LONDON, V4, DOI 10.1186/2046-4053-4-5; Obeid O, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P7022; OpenAI R, 2023, arXiv; Ouyang L., 2022, NEURIPS; Parimi P, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-022-01022-3; Patwa P., 2021, Revised Selected Papers, V1; Pavlyshenko BM, 2023, Arxiv, DOI arXiv:2309.04704; Peng SC, 2022, DIGIT COMMUN NETW, V8, P745, DOI 10.1016/j.dcan.2021.10.003; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391; Pillai S.E.V.S., 2023, 2023 IEEEACIS 21, P295; Plutchik R., 1980, Emotion: Theory, research and experience, Theories of emotion, P3, DOI [10.1016/B978-0-12-558701-3.50007-7, DOI 10.1016/B978-0-12-558701-3.50007-7]; Poria S, 2013, IEEE INTELL SYST, V28, P31, DOI 10.1109/MIS.2013.4; Prabhala M, 2019, IN C IND ENG ENG MAN, P219, DOI [10.1109/IEEM44572.2019.8978708, 10.1109/ieem44572.2019.8978708]; Pröllochs N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01813-2; Pröllochs N, 2021, EPJ DATA SCI, V10, DOI 10.1140/epjds/s13688-021-00307-5; Przybyla P, 2018, RES SYNTH METHODS, V9, P470, DOI 10.1002/jrsm.1311; Qi J., 2019, WSDM-fake news classification, 2018; Qi P., 2023, P 37 AAAI C ART INT, P14444; Radford A, 2021, PR MACH LEARN RES, V139; Rao Delip, 2017, Fake news challenge; Rashkin H, 2017, P 2017 C EMP METH NA, P2931, DOI 10.18653/v1/d17-1317; Rezaei S, 2022, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-022-01019-y; Rijo A, 2023, COMPUT HUM BEHAV, V141, DOI 10.1016/j.chb.2022.107619; Rubin V, 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802; RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X; Sabour S, 2017, ADV NEUR IN, V30; Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2; Scheufele DA, 2019, P NATL ACAD SCI USA, V116, P7662, DOI 10.1073/pnas.1805871115; Seddari N, 2022, IEEE ACCESS, V10, P62097, DOI 10.1109/ACCESS.2022.3181184; Shahid W, 2022, IEEE ACCESS, V10, P27069, DOI 10.1109/ACCESS.2022.3157724; Sharifani K., 2023, World Inf. Technol. Eng. J., V10, P3897; SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061; Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001; Shih CH, 2017, ASIAPAC SIGN INFO PR, P641, DOI 10.1109/APSIPA.2017.8282104; Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062; Sicilia R, 2018, EXPERT SYST APPL, V110, P33, DOI 10.1016/j.eswa.2018.05.019; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Sobhani P., 2016, P 5 JOINT C LEXICAL, P159; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Solovev K, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3706, DOI 10.1145/3485447.3512266; Sui MX, 2023, COMPUT HUM BEHAV, V142, DOI 10.1016/j.chb.2023.107654; Sujun Dong, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12431), P366, DOI 10.1007/978-3-030-60457-8_30; Tajrian M, 2023, IEEE ACCESS, V11, P73879, DOI 10.1109/ACCESS.2023.3294989; Tan WK, 2023, ONLINE INFORM REV, V47, P59, DOI 10.1108/OIR-08-2021-0448; Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555; Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416; Touahri I., 2020, CLEF WORKING NOT; Touvron H., 2023, arXiv; Upadhyaya A, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103325; Uppada SK, 2023, J INTELL INF SYST, V61, P367, DOI 10.1007/s10844-022-00764-y; Uppada SK, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00878-9; Varlamis I, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14030070; Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559; Pamungkas EW, 2019, Arxiv, DOI arXiv:1901.01911; Wan M., 2023, IEEE Trans. Affect. Comput.; Wang C., 2021, P IEEE 6 INT C DAT S, P16, DOI [10.1109/DSC53577.2021.00010, DOI 10.1109/DSC53577.2021.00010]; Wang P, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9101275; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Wang ZH, 2020, NEUROCOMPUTING, V397, P224, DOI 10.1016/j.neucom.2020.01.095; Wang ZH, 2019, IEEE ACCESS, V7, P103000, DOI 10.1109/ACCESS.2019.2928044; Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x; Whissell C, 2009, PSYCHOL REP, V105, P509, DOI 10.2466/PR0.105.2.509-521; Worrall Adam, 2022, Information for a Better World: Shaping the Global Future: 17th International Conference, iConference 2022, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (13193), P149, DOI 10.1007/978-3-030-96960-8_11; Wu Liang, 2016, Big Data Complex Soc. Netw., P123; Wu LW, 2020, Arxiv, DOI arXiv:2004.13455; Wu Y., 2022, WHICEB 2022; Xu Linhong, 2008, Journal of the China Society for Scientific and Technical Information, V27, P180; Yan Yunxi, 2023, Procedia Computer Science, P1284, DOI 10.1016/j.procs.2023.08.117; Yang C., 2023, P 2023 C EMP METH NA, P5705; Yang KL, 2024, Arxiv, DOI [arXiv:2309.13567, 10.48550/arXiv.2309.13567, DOI 10.48550/ARXIV.2309.13567]; Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI DOI 10.18653/V1/N16-1174; Yang Z., 2022, arXiv; Yoonjung Choi, 2014, P EMNLP, P1181, DOI [DOI 10.3115/V1/D14-1125, DOI 10.3115/V1/D14-1125.HTTPS://ACLANTHOLOGY.ORG/D14-1125]; Zadeh L., 1979, Advances in fuzzy set theory and applications, P318; Zaeem RN, 2020, PR I-A I C AD S N A, P760, DOI 10.1109/ASONAM49781.2020.9381323; Zeng Li, 2016, P INT AAAI C WEB, P747; Zhang BY, 2023, Arxiv, DOI [arXiv:2310.04027, DOI 10.48550/ARXIV.2310.04027]; Zhang H, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3269090; Zhang N., 2022, Issues Inf. Syst., V23; Zhang S, 2020, Arxiv, DOI arXiv:2009.00901; Zhang TL, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00589-7; Zhang X., 2023, SPIE, V12609, P463; Zhang XY, 2021, Arxiv, DOI arXiv:1903.01728; Zhang XY, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3465, DOI 10.1145/3442381.3450004; Zhao HY, 2023, Arxiv, DOI [arXiv:2309.01029, 10.48550/arXiv.2309.01029]; Zhao J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12163440; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng KZ, 2024, Arxiv, DOI arXiv:2310.02239; Zhou LN, 2023, INFORM SYST FRONT, V25, P493, DOI 10.1007/s10796-022-10329-7; Zojaji Z, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00952-2	256	0	0	33	33	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	JUL	2024	107								102300	10.1016/j.inffus.2024.102300	http://dx.doi.org/10.1016/j.inffus.2024.102300		FEB 2024	29	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MM1N6		Green Submitted, hybrid			2024-07-03	WOS:001193947800001
J	Kim, MY; Rabelo, J; Babiker, HKB; Rahman, MA; Goebel, R				Kim, Mi-Young; Rabelo, Juliano; Babiker, Housam Khalifa Bashier; Rahman, Md Abed; Goebel, Randy			Legal Information Retrieval and Entailment Using Transformer-based Approaches	REVIEW OF SOCIONETWORK STRATEGIES			English	Article						COLIEE 2023; Legal information retrieval; Legal information entailment; Transformer-based legal information extraction		The challenge of information overload in the legal domain increases every day. The COLIEE competition has created four challenge tasks that are intended to encourage the development of systems and methods to alleviate some of that pressure: a case law retrieval (Task 1) and entailment (Task 2), and a statute law retrieval (Task 3) and entailment (Task 4). Here we describe our methods for Task 1 and Task 4. In Task 1, we used a sentence-transformer model to create a numeric representation for each case paragraph. We then created a histogram of the similarities between a query case and a candidate case. The histogram is used to build a binary classifier that decides whether a candidate case should be noticed or not. In Task 4, our approach relies on fine-tuning a pre-trained DeBERTa large language model (LLM) trained on SNLI and MultiNLI datasets. Our method for Task 4 was ranked third among eight participating teams in the COLIEE 2023 competition. For Task 4, We also compared the performance of the DeBERTa model with those of a knowledge distillation model and ensemble methods including Random Forest and Voting.	[Kim, Mi-Young] Univ Alberta, Augustana Fac, Dept Sci, Camrose, AB, Canada; [Rabelo, Juliano] Univ Alberta, Alberta Machine Intelligence Inst, Edmonton, AB, Canada; [Babiker, Housam Khalifa Bashier; Rahman, Md Abed] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada; [Goebel, Randy] Univ Alberta, Alberta Machine Intelligence Inst, Dept Comp Sci, Edmonton, AB, Canada	University of Alberta; University of Alberta; University of Alberta; University of Alberta	Kim, MY (corresponding author), Univ Alberta, Augustana Fac, Dept Sci, Camrose, AB, Canada.	miyoung2@ualberta.ca; rabelo@ualberta.ca; khalifab@ualberta.ca; mdabed@ualberta.ca; rgoebel@ualberta.ca			Natural Sciences and Engineering Research Council of Canada; University of Alberta; Alberta Machine Intelligence Institute [RGPIN-2022-03469, DGECR-2022-00369]; Canadian Natural Sciences and Engineering Research Council (NSERC); Alberta Innovates	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); University of Alberta(University of Alberta); Alberta Machine Intelligence Institute; Canadian Natural Sciences and Engineering Research Council (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Alberta Innovates	This research would not be possible without the COLIEE competition organizers' data distribution and evaluations. The research is supported by the University of Alberta and the Alberta Machine Intelligence Institute, the Canadian Natural Sciences and Engineering Research Council (NSERC) (including funding reference numbers RGPIN-2022-03469 and DGECR-2022-00369), and Alberta Innovates.	Abolghasemi A., 2022, 16 INT WORKSHOP JURI; Bowman S.R., 2015, arXiv; Bui M.Q., 2022, 16 INT WORKSHOP JURI; Chalkidis I, 2020, M ASS FOR COMPUTATIO; Clark K., 2020, ARXIV; Devlin J., 2018, BERT PRE TRAINING DE; Fink T., 2022, 16 INT WORKSHOP JURI; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Fujita M., 2022, 16 INT WORKSHOP JURI; Geiger Atticus, 2020, P 3 BLACKBOXNLP WORK, P163, DOI DOI 10.18653/V1/2020.BLACKBOXNLP-1.16; Gong Y., 2017, ARXIV; He P., 2021, ARXIV; He Pengcheng, 2020, arXiv; Honnibal M., 2015, P 2015 C EMP METH NA, P1373, DOI [10.18653/v1/D15-1162, DOI 10.18653/V1/D15-1162]; Jiang NJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6086; Kim M.Y., 2023, NEW FRONTIERS ARTIFI, V13859; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lin M., 2022, 16 INT WORKSHOP JURI; Liu X., 2018, arXiv; Liu Y., 2019, CoRR abs/1907.11692; Nakatani S., 2010, Language detection library for java; Nangia N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4566; Rabelo J, 2022, REV SOCIONETWORK STR, V16, P111, DOI 10.1007/s12626-022-00105-z; Radford A., 2018, IMPROVING LANGUAGE U; Ravichander A., 2019, P 23 C COMPUTATIONAL, P349, DOI [DOI 10.18653/V1/K19-1033, 10.18653/v1/K19-1033]; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Rocktaschel Tim, 2015, ARXIV; Rosa G.M., 2021, P 18 INT C ARTIFICIA; Schilder F., 2021, P COLIEE WORKSHOP IC; Tan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4411; Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994; Wang W., 2020, ARXIV; Wang ZG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144; Wehnert S., 2022, 16 INT WORKSHOP JURI; Williams A., 2017, ARXIV; Yoshioka M., 2022, 16 INT WORKSHOP JURI	36	0	0	2	2	SPRINGER JAPAN KK	TOKYO	SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005, JAPAN	2523-3173	1867-3236		REV SOCIONETWORK STR	Rev. Socionetwork Strateg.	APR	2024	18	1			SI		101	121		10.1007/s12626-023-00153-z	http://dx.doi.org/10.1007/s12626-023-00153-z		JAN 2024	21	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	OA5N1	38646589	hybrid			2024-07-03	WOS:001140304200001
C	Cheng, M; Durmus, E; Jurafsky, D		Rogers, A; Boyd-Graber, J; Okazaki, N		Cheng, Myra; Durmus, Esin; Jurafsky, Dan			Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			GENDER; STRENGTH; RACE; ERA	To recognize and mitigate harms from large language models (LLMs), we need to understand the prevalence and nuances of stereotypes in LLM outputs. Toward this end, we present Marked Personas, a prompt-based method to measure stereotypes in LLMs for intersectional demographic groups without any lexicon or data labeling. Grounded in the sociolinguistic concept of markedness (which characterizes explicitly linguistically marked categories versus unmarked defaults), our proposed method is twofold: 1) prompting an LLM to generate personas, i.e., natural language descriptions, of the target demographic group alongside personas of unmarked, default groups; 2) identifying the words that significantly distinguish personas of the target group from corresponding unmarked ones. We find that the portrayals generated by GPT-3.5 and GPT-4 contain higher rates of racial stereotypes than human-written portrayals using the same prompts. The words distinguishing personas of marked (non-white, non-male) groups reflect patterns of othering and exoticizing these demographics. An intersectional lens further reveals tropes that dominate portrayals of marginalized groups, such as tropicalism and the hypersexualization of minoritized women. These representational harms have concerning implications for downstream applications like story generation.	[Cheng, Myra; Durmus, Esin; Jurafsky, Dan] Stanford Univ, Stanford, CA 94305 USA	Stanford University	Cheng, M (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	myra@cs.stanford.edu			NSF Graduate Research Fellowship [DGE2146755]; Stanford Knight-Hennessy Scholars graduate fellowship; SAIL Postdoc Fellowship; Hoffman-Yee Research Grants Program; Stanford Institute for HumanCentered Artificial Intelligence	NSF Graduate Research Fellowship(National Science Foundation (NSF)); Stanford Knight-Hennessy Scholars graduate fellowship; SAIL Postdoc Fellowship; Hoffman-Yee Research Grants Program; Stanford Institute for HumanCentered Artificial Intelligence	Thank you to Kaitlyn Zhou, Mirac Suzgun, Diyi Yang, Omar Shaikh, Jing Huang, Rajiv Movva, and Kushal Tirumala for their very helpful feedback on this paper! This work was funded in part by an NSF Graduate Research Fellowship (Grant DGE2146755) and Stanford Knight-Hennessy Scholars graduate fellowship to MC, a SAIL Postdoc Fellowship to ED, the Hoffman-Yee Research Grants Program, and the Stanford Institute for HumanCentered Artificial Intelligence.	Allen K, 2022, EUR J CULT STUD, V25, P310, DOI 10.1177/13675494211036922; Alsultany Evelyn., 2012, Arabs and Muslims in the Media: Race and Representation after 9/11, DOI DOI 10.18574/NYU/9780814729175.001.0001; An HZ, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1573; Aniefuna LI, 2020, WOMEN CRIM JUSTICE, V30, P356, DOI 10.1080/08974454.2020.1752352; Azhar S, 2021, AFFILIA, V36, P282, DOI 10.1177/08861099211001460; Bailey AH, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm2463; Bamman D., 2013, Long Papers, P352; Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Blomkvist Stefan, 2002, USER PERSONALITY USI, P980; Blumer MLC, 2013, J FAM PSYCHOTHER, V24, P267, DOI 10.1080/08975353.2013.849551; Bolukbasi T, 2016, ADV NEUR IN, V29; Bonilla-Silva Eduardo., 2018, RACISM RACISTS COLOR, DOI DOI 10.5860/CHOICE.51.09.1531D; Brekhus W, 1998, SOCIOL THEOR, V16, P34, DOI 10.1111/0735-2751.00041; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cao YT, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1276; Castelin S, 2022, PSYCHOL WOMEN QUART, V46, P196, DOI 10.1177/03616843211067501; Chan ConnieS., 1988, POLITICS RACE GENDER, P33, DOI [10.1300/j015v06n04_05, DOI 10.1300/J015V06N04_05]; Chang Szu-Hsien, 2003, EQUAL OPPORTUNITIES; Cheryan S, 2020, PSYCHOL REV, V127, P1022, DOI 10.1037/rev0000209; Collins PH., 1990, Black feminist thought: Knowledge, consciousness, and the politics of empowerment, V138(1990), P221; Combahee River Collective, 1983, HOME GIRLS BLACK FEM, V1, P264, DOI DOI 10.4324/9780203357071; Cooper A., 1999, The inmates are running the asylum; Crenshaw K. W., 2017, On intersectionality: Essential writings; Czopp AM, 2015, PERSPECT PSYCHOL SCI, V10, P451, DOI 10.1177/1745691615588091; De Beauvoir S., 1952, The second sex, P38; Deaux Kay, 1993, GENDER STEREOTYPES; Dervin Fred., 2012, ROUTLEDGE HDB LANGUA, P181, DOI DOI 10.4324/9780203805640.CH11; Dinan E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P314; Eagly AH, 2020, AM PSYCHOL, V75, P301, DOI 10.1037/amp0000494; Frankenberg R., 1993, WHITE WOMEN RACE MAT; Gallagher RJ, 2021, EPJ DATA SCI, V10, DOI 10.1140/epjds/s13688-021-00260-3; Garcia Patricia, 2020, CSCW '20: 23rd Conference on Computer-Supported Cooperative Work and Social Computing, P199, DOI 10.1145/3406865.3419014; Gentry CE, 2022, CRIT STUD TERROR, V15, P209, DOI 10.1080/17539153.2022.2031131; Ghavami N, 2013, PSYCHOL WOMEN QUART, V37, P113, DOI 10.1177/0361684312464203; Grice HP., 1975, SYNTAX SEMANTICS, P41, DOI [DOI 10.1163/9789004368811_003, 10.1163/9789004368811_003]; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Hegarty P., 2018, OXFORD SCHOLARSHIP O; Heilman ME, 2001, J SOC ISSUES, V57, P657, DOI 10.1111/0022-4537.00234; Hicks M, 2017, HIST COMPUT-MIT PRES, P1; Hoffman B., 1995, STUDIES CONFLICT TER, V18, P271, DOI [10.1080/10576109508435985, DOI 10.1080/10576109508435985]; Hooks B, 2015, FEMINIST THEORY: FROM MARGIN TO CENTER, P1; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Jensen S.Q., 2011, Qualitative Studies, V2, P63, DOI [DOI 10.7146/QS.V2I2.5510, https://doi.org/10.7146/qs.v2i2.5510]; Jettmar E., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P129, DOI 10.1145/503376.503400; Kambhatla Gauri, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1604, DOI 10.1145/3531146.3533217; Kardiner Abraham., 1951, MARK OPPRESSION PSYC; Kirk HR, 2021, ADV NEUR IN, V34; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517545; Lepori Michael, 2020, P 28 INT C COMP LING, P1720; Levi-Strauss C., 1963, STRUCTURAL ANTHR; Lewis AE, 2004, SOCIOL THEOR, V22, P623, DOI 10.1111/j.0735-2751.2004.00237.x; Liang Percy, 2022, arXiv preprint arXiv:2211.09110; Liao KYH, 2020, PSYCHOL WOMEN QUART, V44, P84, DOI 10.1177/0361684319883198; Liboiron M, 2021, POLLUTION IS COLONIALISM, P1; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Ma Shen-Mei., 2000, The Deathly Embrace: Orientalism and Asian American Identity; Madon S, 2001, PERS SOC PSYCHOL B, V27, P996, DOI 10.1177/0146167201278007; Martynuska M, 2016, J LANG CULT EDUC, V4, P73, DOI 10.1515/jolace-2016-0017; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; McRobbie Angela., 2009, The Aftermath of Feminism; Melamed J, 2006, SOC TEXT, V24, P1, DOI 10.1215/01642472-2006-009; Mindell Arnold, 2006, LEADER MARTIAL ARTIS; Molina-Guzman Isabel, 2010, DANGEROUS CURVES LAT, V5; Monroe BL, 2008, POLIT ANAL, V16, P372, DOI 10.1093/pan/mpn018; Muller M. J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P383, DOI 10.1145/503376.503445; Muscati SinaAli., 2002, J MUSLIM MINOR AFF, V22, P131, DOI DOI 10.1080/13602000220124872; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nelson T, 2016, PSYCHOL WOMEN QUART, V40, P551, DOI 10.1177/0361684316646716; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2022, OP INTR CHATGPT; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Parrish A, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2086; Pierre J, 2004, IDENTITIES-GLOB STUD, V11, P141, DOI 10.1080/10702890490451929; Podesva RJ, 2015, LANG VAR CHANGE, V27, P59, DOI 10.1017/S0954394514000192; Reny T., 2016, Media and Minorities, P195, DOI [10.13109/9783666300882.195, DOI 10.13109/9783666300882.195]; Rosenblum Karen E, 1996, MEANING DIFFERENCE A, V52; Rottenberg C, 2014, CULT STUD, V28, P418, DOI 10.1080/09502386.2013.857361; RWaugh Linda, 1982, Marked and unmarked: A choice between unequals in semiotic structure; Said EdwardW., 2003, ORIENTALISM W CONCEP; Santurkar Shibani, 2023, ARXIV230317548; Sap Maarten, 2020, P 58 ANN M ASS COMPU, P5477; Sasson-Levy O, 2013, SOCIOL FORUM, V28, P27, DOI 10.1111/socf.12001; Scao T. L., 2022, arXiv preprint arXiv:2211.05100; Schafer JA, 2014, DEVIANT BEHAV, V35, P173, DOI 10.1080/01639625.2013.834755; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Shaheen JG, 2003, ANN AM ACAD POLIT SS, V588, P171, DOI 10.1177/0002716203588001011; Smith Eric Michael, 2022, P 2022 C EMPIRICAL M, P9180, DOI 10.18653; So RJ, 2020, PMLA, V135, P59; Stoler A., 1995, RACE ED DESIRE; Tan Yi Chern, 2019, ADV NEURAL INFORM PR, V32; Trujillo MZ, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, P164; Uchida A, 1998, WOMEN STUD INT FORUM, V21, P161, DOI 10.1016/S0277-5395(98)00004-1; Watson NN, 2016, J BLACK PSYCHOL, V42, P424, DOI 10.1177/0095798415597093; Weidinger Laura, 2021, arXiv preprint arXiv:2112.04359; Wolfe R, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P800, DOI 10.1145/3514094.3534136; Wolfe Robert, 2022, 2022 ACM C FAIRN ACC; Wolfe Robert, 2022, 2022 ACM C FAIRN ACC; Woods-Giscombé CL, 2010, QUAL HEALTH RES, V20, P668, DOI 10.1177/1049732310361892; Woodward K., 1997, Identity and difference, V3; Xu XC, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2639; Yoshihara Mari., 2002, EMBRACING E WHITE WO; Zhang S., 2022, arXiv; Zheng R, 2016, J AM PHILOS ASSOC, V2, P400, DOI 10.1017/apa.2016.25	107	2	2	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							1504	1532						29	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086808022
C	Oh, BD; Schuler, W		Rogers, A; Boyd-Graber, J; Okazaki, N		Oh, Byung-Doh; Schuler, William			Token-wise Decomposition of Autoregressive Language Model Hidden States for Analyzing Model Predictions	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				While there is much recent interest in studying why Transformer-based large language models make predictions the way they do, the complex computations performed within each layer have made their behavior somewhat opaque. To mitigate this opacity, this work presents a linear decomposition of final hidden states from autoregressive language models based on each initial input token, which is exact for virtually all contemporary Transformer architectures. This decomposition allows the definition of probability distributions that ablate the contribution of specific input tokens, which can be used to analyze their influence on model probabilities over a sequence of upcoming words with only one forward pass from the model. Using the change in next-word probability as a measure of importance, this work first examines which context words make the biggest contribution to language model predictions. Regression experiments suggest that Transformer-based language models rely primarily on collocational associations, followed by linguistic factors such as syntactic dependencies and coreference relationships in making next-word predictions. Additionally, analyses using these measures to predict syntactic dependencies and coreferent mention spans show that collocational association and repetitions of the same token largely explain the language models' predictions on these tasks.	[Oh, Byung-Doh; Schuler, William] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Oh, BD (corresponding author), Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.	oh.531@osu.edu; schuler.77@osu.edu			National Science Foundation [1816891]	National Science Foundation(National Science Foundation (NSF))	We thank the reviewers for their helpful comments. This work was supported by the National Science Foundation grant #1816891. All views expressed are those of the authors and do not necessarily reflect the views of the National Science Foundation.	Ba LJ., 2016, CORR; Belinkov Y, 2022, COMPUT LINGUIST, V48, P207, DOI 10.1162/coli_a_00422; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carlini Nicholas, 2022, ARXIV220207646V2; Elhage N., 2021, Transformer Circuits Thread; Geva M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5484; Geva Mor, 2022, P 2022 C EMPIRICAL M, P30, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.3; Hendrycks Dan, 2016, ARXIV160608415V4; Kobayashi G, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7057; Kobayashi Goro, 2021, P 2021 C EMPIRICAL M, P4547, DOI 10.18653/v1/2021.emnlp-main.373; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556; Mickus T, 2022, T ASSOC COMPUT LING, V10, P981, DOI 10.1162/tacl_a_00501; Nair V., 2010, P ICML, P807; Olsson Catherine, 2022, Transformer Circuits; Parker Robert, 2009, ENGLISH GIGAWORD FOU; Pradhan S, 2012, JOINT C EMNLP CONLL, P1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Sanyal S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10285; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shrikumar A, 2017, PR MACH LEARN RES, V70; Simonyan Karen, 2014, WORKSH INT C LEARN R, P2; Sun SM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P807; Vaswani A, 2017, ADV NEUR IN, V30; Zaman Kerem, 2022, P 2022 C EMPIRICAL M, P1556; Zhang Susan, 2022, ARXIV220501068V4	28	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							10105	10117						13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962501047
J	Grinbaum, A; Adomaitis, L				Grinbaum, Alexei; Adomaitis, Laurynas			Moral Equivalence in the Metaverse	NANOETHICS			English	Article						Ethics; Virtual reality; Extended reality; Artificial intelligence; Chatbot; Affective computing	VIRTUAL-REALITY; EMOTION	Are digital subjects in virtual reality morally equivalent to human subjects? We divide this problem into two questions bearing, respectively, on cognitive and emotional equivalence. Typically, cognitive equivalence does not hold due to the lack of substantialist indistinguishability, but emotional equivalence applies: digital subjects endowed with face or language elicit emotional responses on a par with real-world pleasure, desire, horror, or fear. This is sufficient for projecting moral traits on avatars in the metaverse or on dialog systems based on large language models. Our main case study is a chatbot trained on the chat history between a Canadian man and his deceased fiancee. To demonstrate emotional equivalence and the mechanism of moral transfer, we compare digital devices with the functioning of oracles in a story by Plutarch and in a narrative that draws on the book of Genesis. Finally, we note that, along with the projections of ethical issues, humans also tend to bring real-world solutions of moral conundrums into extended reality. We argue that the lack of cognitive equivalence makes such projections problematic as they lead to overpolicing and a sanitized metaverse.	[Grinbaum, Alexei; Adomaitis, Laurynas] CEA Saclay Larsim, F-91191 Gif Sur Yvette, France		Grinbaum, A (corresponding author), CEA Saclay Larsim, F-91191 Gif Sur Yvette, France.	alexei.grinbaum@cea.fr	Adomaitis, Laurynas/K-7439-2015; Grinbaum, Alexei/A-2210-2012	Grinbaum, Alexei/0000-0002-7484-1553; Adomaitis, Laurynas/0000-0001-7723-2641	European Commission Horizon-2020 program [101006249]	European Commission Horizon-2020 program	This research was supported through the project TechEthos funded by the European Commission Horizon-2020 program (grant number 101006249).	Acharya R, 2021, SPORTSKEEDA; Adomaitis L, TECHETHOS D22 IDENTI; Albuz E, 2022, US Patent, Patent No. [16/595,285, 16595285]; [Anonymous], 2008, MONSTRE IMAGINAIRE S, DOI DOI 10.1378/CHEST.09-1584; [Anonymous], 2021, The Stanford Encyclopedia of Philosophy; Atlan, 2013, ATHEISM SCRIPTURE, V2; Baker M, 2017, IEEE PERVAS COMPUT, V16, P9, DOI 10.1109/MPRV.2017.37; Beard R, 2021, TWITTER; Biocca F., 1995, Communication in the age of virtual reality, V15, P10; Bordeleau M, 2022, J PAIN, V23, P175, DOI 10.1016/j.jpain.2021.08.001; Bourdon J, 2020, COMMUN THEOR, V30, P64, DOI 10.1093/ct/qtz020; Brey P., 1999, Ethics and Information Technology, V1, P5, DOI 10.1023/A:1010069907461; Canguilhem Georges., 1952, La Connaissance de la Vie; Cerna (Commission de reflexion sur l'Ethique de la Recherche en sciences et technologies du Numerique d'Allistene), 2018, RES ETH MACH LEARN; Clayton M, 2022, MAIL SUNDAY 0129; CNPEN (Comite national pilote d'ethique du numerique), 2021, ETH ISS CONV AG OP 3; Collins, 2021, FORBES; Couffignal, 1966, ROBOT BETE LHOMME RE, P189; Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740; Dehaene, 2020, INFLUENCE LANGAGE SY; Descartes R., 1988, PHILOS WRITINGS DESC; European Parliament, 2017, RES CIV LAW RUL ROB; Fagone Jason, 2021, SAN FRANCISCO CHRONI; Flammarion C., 1900, INCONNU PROBLEMES PS; GALE N, 1990, J ENVIRON PSYCHOL, V10, P3, DOI 10.1016/S0272-4944(05)80021-0; Girard Rene., 1977, VIOLENCE SACRED; Glaese A, 2022, ARXIV; Grinbaum Alexei, 2010, Nano Ethics, V4, P191, DOI 10.1007/s11569-010-0103-x; Grinbaum A., 2019, Les Robots et le mal; Grinbaum A., 2004, TECHNE, V8, P4; Grinbaum A, 2015, IEEE ROBOT AUTOM MAG, V22, P152, DOI 10.1109/MRA.2014.2385568; Heater C., 1992, Presence: Teleoperators and Virtual Environments, V1, P262, DOI [DOI 10.1162/PRES.1992.1.2.262, 10.1162/pres.1992.1.2.262]; Ho J, 2022, ARXIV; Hoffman HG, 2006, J PAIN, V7, P843, DOI 10.1016/j.jpain.2006.04.006; HOLMES DS, 1978, PSYCHOL BULL, V85, P677, DOI 10.1037/0033-2909.85.4.677; Hui Y., 2016, On the existence of digital objects, DOI [10.5749/minnesota/9780816698905.001.0001, DOI 10.5749/MINNESOTA/9780816698905.001.0001]; Jung C.G., 1960, Synchronicity: An Acausal Connecting Principle; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Koestler Arthur., 1972, ROOTS COINCIDENCE; Kolmogorov, 1961, MACH TRANSL APPL LIN, V6, P3; Korshunov P, 2020, ARXIV; Korshunov P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2510, DOI 10.1109/ICASSP39728.2021.9414258; Kragel PA, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.2000106; Levinas Emmanuel., 1991, ENTRE NOUS; Lewis M, 2017, ARXIV; Lindauer M., 2022, ARXIV; Lombard M., 1997, J. Comput. Commun., V3, DOI [10.1111/j.1083-6101.1997.tb00072.x, DOI 10.1111/J.1083-6101.1997.TB00072.X, 10.1111/j.1083-6101.1997.tb0]; Mader B, 2017, PERCEPTION, V46, P1062, DOI 10.1177/0301006617713633; Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677; McKinnell RG, 1985, CLONING BIOL REPORTS; Mori M., 1970, ENERGY, V7, P33, DOI [DOI 10.1109/MRA.2012.2192811, 10.1109/MRA.2012.2192811]; Murphy H, 2022, FINANCIAL TIMES 0118; Parviainen J, 2021, AI SOC, V36, P715, DOI 10.1007/s00146-020-01104-w; Patel, 2021, REALITY FICTION SEXU; Petrarca E., 2019, CUT; Rae J, 2021, ARXIV; Ramesh Aditya, 2022, arXiv; Ramirez, 2021, ETHICS VIRTUAL AUGME; Ramirez EJ, 2018, ETHICS INF TECHNOL, V20, P249, DOI 10.1007/s10676-018-9473-5; Robitzski Dan., 2021, Futurism; Rohrer J, 2021, GADGETS 360 NEWSDESK; Rousseau A.-L., 2020, Nabla; Sarwar N, 2021, SCREENRANT; Sharma V, 2022, OCULUS BLOG 0204; Shelley Mary, 1994, Frankenstein; or, The Modern Prometheus (The 1818 Text); SHERWIN B, 2009, GOLEMS US JEWISH LEG; Simondon G., 1989, Du mode existence des objets techniques; Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198; Sohl-Dickstein J., 2015, ARXIV; Spinoza B., 1996, Ethics; Sutherland I. E., 1968, Proceedings of the December 9-11, 1968, fall joint computer conference, part I on-AFIPS'68 (Fall, part I), P757, DOI DOI 10.1145/1476589.1476686; Tsuchiya N, 2007, TRENDS COGN SCI, V11, P158, DOI 10.1016/j.tics.2007.01.005; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Vaihinger H., 1968, The Philosophy of As if; Vaswani A., 2017, Advances in neural information processing systems, P6000; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991	76	4	4	7	43	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1871-4757	1871-4765		NANOETHICS	NanoEthics	DEC	2022	16	3			SI		257	270		10.1007/s11569-022-00426-x	http://dx.doi.org/10.1007/s11569-022-00426-x		NOV 2022	14	Ethics; History & Philosophy Of Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; History & Philosophy of Science	7C2AJ					2024-07-03	WOS:000884939800001
C	Chronopoulou, A; Peters, ME; Dodge, J			ASSOC COMPUTAT LINGUIST	Chronopoulou, Alexandra; Peters, Matthew E.; Dodge, Jesse			Efficient Hierarchical Domain Adaptation for Pretrained Language Models	NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES			English	Proceedings Paper	Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies	JUL 10-15, 2022	Seattle, WA	Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data				The remarkable success of large language models has been driven by dense models trained on massive unlabeled, unstructured corpora. These corpora typically contain text from diverse, heterogeneous sources, but information about the source of the text is rarely used during training. Transferring their knowledge to a target domain is typically done by continuing training in-domain. In this paper, we introduce a method to permit domain adaptation to many diverse domains using a computationally efficient adapter approach. Our method is based on the observation that textual domains are partially overlapping, and we represent domains as a hierarchical tree structure where each node in the tree is associated with a set of adapter weights. When combined with a frozen pretrained language model, this approach enables parameter sharing among related domains, while avoiding negative interference between unrelated ones. Experimental results with GPT-2 and a large fraction of the 100 most represented websites in C4 show across-the-board improvements in-domain. We additionally provide an inference time algorithm for a held-out domain and show that averaging over multiple paths through the tree enables further gains in generalization, while adding only a marginal cost to inference.	[Chronopoulou, Alexandra] Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc, Munich, Germany; [Peters, Matthew E.; Dodge, Jesse] Allen Inst Artificial Intelligence, Seattle, WA USA	University of Munich	Chronopoulou, A (corresponding author), Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc, Munich, Germany.	achron@cis.lmu.de; matthewp@allenai.org; jessed@allenai.org						Aharoni Roee, 2020, P 58 ANN M ASS COMPU, P7747, DOI DOI 10.18653/V1/2020.ACL-MAIN.692; [Anonymous], 2017, P NIPS W; [Anonymous], BIOINFORMATICS; Artetxe Mikel., 2021, Efficient large scale language modeling with mixtures of experts; Axelrod Amittai, 2011, P 2011 C EMPIRICAL M, P355; Ba Jimmy Lei, 2016, LAYER NORMALIZATION; Bapna A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1538; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Das Gupta M, 2015, PROC CVPR IEEE, P2700, DOI 10.1109/CVPR.2015.7298886; Daume III Hal, 2007, Frustratingly easy domain adaptation, P256, DOI DOI 10.48550/ARXIV.0907.1815; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1286; Gururangan S., 2021, Demix layers: disentangling domains for modular language modeling; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Han XC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4238; He Junxian, 2022, INT C LEARN REPR; Houlsby N, 2019, PR MACH LEARN RES, V97; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Hu E.J., 2022, INT C LEARN REPR; Jiang J., 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558; Kaplan Jared, 2020, Scaling laws for neural language models; Kingma D. P., 2017, ARXIV; Lauscher A., 2020, P DEEP LEARNING INSI, P43; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lepikhin Dmitry, 2021, INT C LEARN REPR; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu Alisa, 2021, Proceedings of the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing (volume 1: Long papers), V1, P6691, DOI [DOI 10.18653/V1/2021.ACL-LONG.522, 10.18653/v1/2021.acl-long.522]; Liu Y, 2019, ARXIV PREPRINT ARXIV; Maronikolakis Antonis, 2021, Proceedings of the Second Workshop on Domain Adaptation for NLP, P1; Moore Robert C., 2010, P ACL 2010 C SHORT P, P220; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7654; Plank Barbara, 2016, BOCHUMER LINGUISTISC, V16; Plank Barbara, 2011, P 49 ANN M ASS COMP, P1566; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rebuffi SA, 2017, ADV NEUR IN, V30; Rietzler A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4933; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Stickland AC, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3440; Üstün A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2302; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang RZ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1405; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zaken Elad Ben, 2021, ABS210610199 CORR	47	6	8	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-71-1				2022							1336	1351						16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9EE					2024-07-03	WOS:000859869501031
C	Kim, C; Gowda, D; Lee, D; Kim, J; Kumar, A; Kim, S; Garg, A; Han, C		Matthews, MB		Kim, Chanwoo; Gowda, Dhananjaya; Lee, Dongsoo; Kim, Jiyeon; Kumar, Ankur; Kim, Sungsoo; Garg, Abhinav; Han, Changwoo			A REVIEW OF ON-DEVICE FULLY NEURAL END-TO-END AUTOMATIC SPEECH RECOGNITION ALGORITHMS	2020 54TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS, AND COMPUTERS	Conference Record of the Asilomar Conference on Signals Systems and Computers		English	Proceedings Paper	54th Asilomar Conference on Signals, Systems and Computers	NOV 01-05, 2020	ELECTR NETWORK	IEEE Signal Proc Soc		end-to-end speech recognition; attention-based model; recurrent neural network transducer; on-device speech recognition		In this paper, we review various end-to-end automatic speech recognition algorithms and their optimization techniques for on-device applications. Conventional speech recognition systems comprise a large number of discrete components such as an acoustic model, a language model, a pronunciation model, a text-normalizer, an inverse-text normalizer, a decoder based on a Weighted Finite State Transducer (WFST), and so on. To obtain sufficiently high speech recognition accuracy with such conventional speech recognition systems, a very large language model (up to 100 GB) is usually needed. Hence, the corresponding WFST size becomes enormous, which prohibits their on-device implementation. Recently, fully neural network end-to-end speech recognition algorithms have been proposed. Examples include speech recognition systems based on Connectionist Temporal Classification (CTC), Recurrent Neural Network Transducer (RNN-T), Attention-based Encoder-Decoder models (AED), Monotonic Chunk-wise Attention (MoChA), transformer-based speech recognition systems, and so on. These fully neural network-based systems require much smaller memory footprints compared to conventional algorithms, therefore their on-device implementation has become feasible. In this paper, we review such end-to-end speech recognition models. We extensively discuss their structures, performance, and advantages compared to conventional algorithms.	[Kim, Chanwoo; Gowda, Dhananjaya; Lee, Dongsoo; Kim, Jiyeon; Kumar, Ankur; Kim, Sungsoo; Garg, Abhinav; Han, Changwoo] Samsung Res, Seoul, South Korea		Kim, C (corresponding author), Samsung Res, Seoul, South Korea.	chanw.com@samsung.com; d.gowda@samsung.com; dongsoo3.lee@samsung.com; jstacey7.kim@samsung.com; ankur.k@samsung.com; ss216.kim@samsung.com; abhinav.garg@samsung.com; cw1105.han@samsung.com	Garg, Abhinav/GYE-2494-2022; Garg, Abhinav/ABB-2137-2021	Garg, Abhinav/0000-0001-5082-5500; Gowda, Dhananjaya/0000-0001-8262-5597; Garg, Abhinav/0000-0002-6729-1733; Kim, Chanwoo/0000-0003-4085-2470	Samsung Electronics	Samsung Electronics(Samsung)	Thanks to Samsung Electronics for funding this research. The authors are thankful to President Sebasitan Seung, Executive Vice President Seunghwan Cho and speech processing Lab. members at Samsung Research.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; [Anonymous], 2017, COLD FUSION TRAINING; Chiu C.-C., 2018 IEEE INT C ACOU; Chiu C.-C., INT C LEARN REPR; Cho Bv, 2014, ARXIV14061078, P1724, DOI 10.3115/v1/d14-1179; Chollet F., 2015, About us; Chorowski J, 2015, ADV NEUR IN, V28; Chorowski J, 2017, INTERSPEECH, P523, DOI 10.21437/Interspeech.2017-343; Garg A, 2020, INTERSPEECH, P3371, DOI 10.21437/Interspeech.2020-3172; Garg A, 2020, INTERSPEECH, P1793, DOI 10.21437/Interspeech.2020-3174; Gowda D, 2020, INTERSPEECH, P2827, DOI 10.21437/Interspeech.2020-3230; Graves A., INT C MACHINE LEARNI; Graves A., 2006, P 23 INT C MACH LEAR, P369, DOI 10.1145/1143844.1143891; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Gulati A, 2020, INTERSPEECH, P5036, DOI 10.21437/Interspeech.2020-3015; Gulcehre C., 2015, CORRABS150303535; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; Heymann J, 2016, INT CONF ACOUST SPEE, P196, DOI 10.1109/ICASSP.2016.7471664; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hochreiter S., 1997, "NeuralComput., V9, P1735; Hwang K, 2014, IEEE WRK SIG PRO SYS, P174; Kannan A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5824, DOI 10.1109/ICASSP.2018.8462682; Kim C., 2014, INTERSPEECH 2014, P2734; Kim C, 2019, INTERSPEECH, P739, DOI 10.21437/Interspeech.2019-3227; Kim C, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P562, DOI [10.1109/asru46091.2019.9003976, 10.1109/ASRU46091.2019.9003976]; Kim C, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P988, DOI [10.1109/ASRU46091.2019.9003973, 10.1109/asru46091.2019.9003973]; Kim C, 2018, INTERSPEECH, P3028; Kim C, 2017, INTERSPEECH, P379, DOI 10.21437/Interspeech.2017-1510; Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928; Kim C, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P243, DOI 10.1109/ASRU.2009.5373230; Kim C, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P28; Kim K, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P956, DOI [10.1109/ASRU46091.2019.9004027, 10.1109/asru46091.2019.9004027]; Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075; Lee D., 2018, CORRABS181012823; McGraw I., Streaming End-to-end Speech Recognition for Mobile Devices; McGraw I, 2016, INT CONF ACOUST SPEE, P5955, DOI 10.1109/ICASSP.2016.7472820; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Pang R, 2018, INTERSPEECH, P27; Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680; Park J, 2021, IEEE W SP LANG TECH, P30, DOI 10.1109/SLT48900.2021.9383583; Prabhavalkar R, 2017, INTERSPEECH, P939, DOI 10.21437/Interspeech.2017-233; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Shin S., 2018, Advances in Neural Information Processing Systems, V31, P10620; Sutskever I, 2014, ADV NEUR IN, V27; Toshniwal S, 2018, IEEE W SP LANG TECH, P369, DOI 10.1109/SLT.2018.8639038; Vaswani A, 2017, ADV NEUR IN, V30	46	12	14	1	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1058-6393		978-0-7381-3126-9	CONF REC ASILOMAR C			2020							277	283		10.1109/IEEECONF51394.2020.9443456	http://dx.doi.org/10.1109/IEEECONF51394.2020.9443456			7	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering; Imaging Science & Photographic Technology; Telecommunications	BS0GN		Green Submitted			2024-07-03	WOS:000681731800055
J	Liang, P; Ye, DW; Zhu, ZH; Wang, YC; Xia, W; Liang, RH; Sun, GD				Liang, Pan; Ye, Danwei; Zhu, Zihao; Wang, Yunchao; Xia, Wang; Liang, Ronghua; Sun, Guodao			C<SUP>5</SUP>: toward better conversation comprehension and contextual continuity for ChatGPT	JOURNAL OF VISUALIZATION			English	Article; Early Access						ChatGPT; Conversation visualization; Natural language processing; Conversation comprehension; Contextual continuity	VISUAL ANALYSIS; EXPLORATION; NETWORK; TOPICS	Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks. In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses. However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT. To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q\&A View. The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features. The Topic View is designed to display all the question and answer nodes and their relationships within a topic using the structure of a knowledge graph, thereby display the relevance and evolution of conversations. The Context-associated Q\&A View consists of three linked views, which allow users to explore individual conversations deeply while providing specific contextual information when posing questions. The usefulness and effectiveness of C5 were evaluated through a case study and a user study.	[Liang, Pan; Ye, Danwei; Zhu, Zihao; Wang, Yunchao; Xia, Wang; Liang, Ronghua; Sun, Guodao] Zhejiang Univ Technol, Hangzhou, Peoples R China	Zhejiang University of Technology	Sun, GD (corresponding author), Zhejiang Univ Technol, Hangzhou, Peoples R China.	guodao@zjut.edu.cn		Sun, Guodao/0000-0002-8383-8153	Natural Science Foundation of Zhejiang Province [LR23F020003, LTGG23F020005]; Zhejiang Provincial Natural Science Foundation of China [62372411, 62036009]; National Natural Science Foundation of China	Natural Science Foundation of Zhejiang Province(Natural Science Foundation of Zhejiang Province); Zhejiang Provincial Natural Science Foundation of China(Natural Science Foundation of Zhejiang Province); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by Zhejiang Provincial Natural Science Foundation of China (LR23F020003 and LTGG23F020005) and National Natural Science Foundation of China (62372411 and 62036009). Furthermore, thanks to the participants for taking part in the requirement analysis and evaluation. Guodao Sun is the corresponding author.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahuja K, 2023, Arxiv, DOI arXiv:2303.12528; Dieng AB, 2017, Arxiv, DOI arXiv:1611.01702; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao ZQ, 2015, AAAI CONF ARTIF INTE, P2210; Castronovo S, 2008, LECT NOTES COMPUT SC, V5237, P248, DOI 10.1007/978-3-540-85853-9_23; Chang BF, 2023, IEEE T VIS COMPUT GR, V29, P4015, DOI 10.1109/TVCG.2022.3175364; Cowell AJ., 2006, Inf Vis, V5, P250, DOI [10.1057/palgrave.ivs.9500139, DOI 10.1057/PALGRAVE.IVS.9500139]; Cui WW, 2014, IEEE T VIS COMPUT GR, V20, P2281, DOI 10.1109/TVCG.2014.2346433; Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239; Cui YJ, 2021, J VISUAL-JAPAN, V24, P1097, DOI 10.1007/s12650-021-00757-z; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Ehlen P., 2008, P 13 INT C INTELLIGE, P276, DOI DOI 10.1145/1378773.1378810; El-Assady M, 2017, COMPUT GRAPH FORUM, V36, P213, DOI 10.1111/cgf.13181; El-Assady M, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12919; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fujiwara T, 2017, IEEE CONF VIS ANAL, P59, DOI 10.1109/VAST.2017.8585646; Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Jacobsen B, 2021, IEEE T VIS COMPUT GR, V27, P1257, DOI 10.1109/TVCG.2020.3030475; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Katharopoulos A, 2020, PR MACH LEARN RES, V119; Kieffer S, 2016, IEEE T VIS COMPUT GR, V22, P349, DOI 10.1109/TVCG.2015.2467451; Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445; Knittel J, 2022, IEEE T VIS COMPUT GR, V28, P879, DOI 10.1109/TVCG.2021.3114800; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Lee DD, 2001, ADV NEUR IN, V13, P556; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li YC, 2023, Arxiv, DOI arXiv:2304.12102; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990; Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Madaan A, 2022, Arxiv, DOI arXiv:2201.06009; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091; Peng YN, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-021-0609-0; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Savelka J, 2023, Arxiv, DOI [arXiv:2303.09325, DOI 10.48550/ARXIV.2303.09325]; Shi Y, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P594, DOI 10.1145/2998181.2998208; Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203; Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307; Sun G, 2023, IEEE Transactions on Big Data; Sun GD, 2023, IEEE T BIG DATA, V9, P1018, DOI 10.1109/TBDATA.2023.3262151; Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919; Tafjord O, 2022, arXiv; Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212; Wang YN, 2024, ADV CLIM CHANG RES, V15, P1, DOI [10.1016/j.accre.2024.01.008, 10.1145/3633519]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu YC, 2018, IEEE T VIS COMPUT GR, V24, P2758, DOI 10.1109/TVCG.2017.2764459; Yang XJ, 2023, Arxiv, DOI arXiv:2302.08081; Zhou FF, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00150-7; Zhu SJ, 2022, Arxiv, DOI arXiv:2206.05420; Zhu ZH, 2023, J VISUAL-JAPAN, V26, P611, DOI 10.1007/s12650-022-00896-x	61	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1343-8875	1875-8975		J VISUAL-JAPAN	J. Vis.	2024 APR 5	2024										10.1007/s12650-024-00980-4	http://dx.doi.org/10.1007/s12650-024-00980-4		APR 2024	18	Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Imaging Science & Photographic Technology	NA2U8					2024-07-03	WOS:001197660700001
J	Sung, J; Chung, S; Jang, Y; Jang, H; Kim, J; Lee, C; Lee, D; Jeong, D; Cho, K; Kim, YS; Kang, J; Lee, W; Lee, E				Sung, Junho; Chung, Sein; Jang, Yongchan; Jang, Hyoik; Kim, Jiyeon; Lee, Chan; Lee, Donghwa; Jeong, Dongyeong; Cho, Kilwon; Kim, Youn Sang; Kang, Joonhee; Lee, Wonho; Lee, Eunho			Unveiling the Role of Side Chain for Improving Nonvolatile Characteristics of Conjugated Polymers-Based Artificial Synapse	ADVANCED SCIENCE			English	Article						artificial synapse; electrolyte-gated transistor; long-term plasticity; neuromorphic computing; side chain	TRANSISTORS; PLASTICITY; MEMRISTOR	Interest has grown in services that consume a significant amount of energy, such as large language models (LLMs), and research is being conducted worldwide on synaptic devices for neuromorphic hardware. However, various complex processes are problematic for the implementation of synaptic properties. Here, synaptic characteristics are implemented through a novel method, namely side chain control of conjugated polymers. The developed devices exhibit the characteristics of the biological brain, especially spike-timing-dependent plasticity (STDP), high-pass filtering, and long-term potentiation/depression (LTP/D). Moreover, the fabricated synaptic devices show enhanced nonvolatile characteristics, such as long retention time (approximate to 102 s), high ratio of Gmax/Gmin, high linearity, and reliable cyclic endurance (approximate to 103 pulses). This study presents a new pathway for next-generation neuromorphic computing by modulating conjugated polymers with side chain control, thereby achieving high-performance synaptic properties. In organic semiconductors-based neuromorphic devices, it is difficult to endow long-term plasticity in diketopyrrolopyrrole (DPP) polymers due to insufficient interaction with ions. In this article, a rational way is proposed to overcome the deficiency of nonvolatile properties by tailoring the length of the alkyl side-chain of DPP polymers. image	[Sung, Junho; Jang, Hyoik; Lee, Donghwa; Jeong, Dongyeong] Kumoh Natl Inst Technol, Dept Chem Engn, Gumi 39177, South Korea; [Chung, Sein; Cho, Kilwon] Pohang Univ Sci & Technol, Dept Chem Engn, Pohang 37673, South Korea; [Jang, Yongchan; Lee, Wonho] Kumoh Natl Inst Technol, Dept Polymer Sci & Engn, Dept Energy Engn Convergence, Gumi 39177, South Korea; [Kim, Jiyeon; Kim, Youn Sang] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Dept Appl Bioengn, Seoul 08826, South Korea; [Lee, Chan; Kim, Youn Sang] Seoul Natl Univ, Dept Chem & Biol Engn, Seoul 08826, South Korea; [Lee, Chan; Kim, Youn Sang] Seoul Natl Univ, Inst Chem Proc, Coll Engn, Seoul 08826, South Korea; [Kim, Youn Sang] Adv Inst Convergence Technol, Suwon 16229, South Korea; [Kang, Joonhee] Pusan Natl Univ, Dept Nanoenergy Engn, Busan 46241, South Korea; [Lee, Eunho] Seoul Natl Univ Sci & Technol, Dept Chem & Biomol Engn, Seoul 01811, South Korea	Kumoh National University Technology; Pohang University of Science & Technology (POSTECH); Kumoh National University Technology; Seoul National University (SNU); Seoul National University (SNU); Seoul National University (SNU); Pusan National University; Seoul National University of Science & Technology	Lee, W (corresponding author), Kumoh Natl Inst Technol, Dept Polymer Sci & Engn, Dept Energy Engn Convergence, Gumi 39177, South Korea.; Kang, J (corresponding author), Pusan Natl Univ, Dept Nanoenergy Engn, Busan 46241, South Korea.; Lee, E (corresponding author), Seoul Natl Univ Sci & Technol, Dept Chem & Biomol Engn, Seoul 01811, South Korea.	j.kang@pusan.ac.kr; 1holee@kumoh.ac.kr; ehl@seoultech.ac.kr		Sung, Junho/0009-0002-0513-2072; Jeong, Dongyeong/0009-0002-1168-7779	National Research Foundation of Korea [2022R1C1C1010319]; National Research Foundation of Korea (NRF) - Ministry of Science and ICT (MSIT) [NRF-2020R1I1A306779]; Ministry of Education	National Research Foundation of Korea(National Research Foundation of Korea); National Research Foundation of Korea (NRF) - Ministry of Science and ICT (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea); Ministry of Education	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Ministry of Science and ICT (MSIT) (No. 2022R1C1C1010319) and Ministry of Education (NRF-2020R1I1A306779). The authors thank the Pohang Accelerator Laboratory (PLS-II) for providing the synchrotron radiation source at 3C SAXS-I and 9A USAXS beamlines used in this study.	Abbott LF, 2004, NATURE, V431, P796, DOI 10.1038/nature03010; BACKUS J, 1978, COMMUN ACM, V21, P613, DOI 10.1145/359576.359579; Bian JH, 2021, APPL PHYS REV, V8, DOI 10.1063/5.0067352; BLOCHL PE, 1994, PHYS REV B, V49, P16223, DOI 10.1103/PhysRevB.49.16223; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Cassuto Y, 2013, IEEE INT SYMP INFO, P156, DOI 10.1109/ISIT.2013.6620207; Chang CC, 2018, INT EL DEVICES MEET; Chang T, 2011, ACS NANO, V5, P7669, DOI 10.1021/nn202983n; Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723; Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5; Choi Y, 2020, ACS APPL MATER INTER, V12, P4707, DOI 10.1021/acsami.9b17742; Deng JY, 2023, NANOSCALE, V15, P553, DOI 10.1039/d2nr05382a; Eckel C, 2022, NANO LETT, V22, P973, DOI 10.1021/acs.nanolett.1c03832; Fortune ES, 2001, TRENDS NEUROSCI, V24, P381, DOI 10.1016/S0166-2236(00)01835-X; Fu YM, 2022, ADV ELECTRON MATER, V8, DOI 10.1002/aelm.202200463; Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310; Go GT, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000012; Go SX, 2021, APL MATER, V9, DOI 10.1063/5.0056656; Han W, 2013, ANGEW CHEM INT EDIT, V52, P2564, DOI 10.1002/anie.201209632; He YL, 2021, J APPL PHYS, V130, DOI 10.1063/5.0069456; He YL, 2018, J MATER CHEM C, V6, P5336, DOI 10.1039/c8tc00530c; Huang CH, 2021, ACS APPL MATER INTER, V13, P52822, DOI 10.1021/acsami.1c18329; Jin M, 2022, ADV FUNCT MATER, V32, DOI 10.1002/adfm.202201048; KAKALIOS J, 1987, PHYS REV LETT, V59, P1037, DOI 10.1103/PhysRevLett.59.1037; Kim J, 2023, NANOSCALE HORIZ, V8, P1417, DOI 10.1039/d3nh00201b; Kim K, 2013, ADV MATER, V25, P1693, DOI 10.1002/adma.201203116; Kim MK, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101846; Kim MK, 2019, NANO LETT, V19, P2044, DOI 10.1021/acs.nanolett.9b00180; Kim N, 2023, ADV INTELL SYST-GER, V5, DOI 10.1002/aisy.202300016; Kim S, 2015, NANO LETT, V15, P2203, DOI 10.1021/acs.nanolett.5b00697; Kim S, 2017, ACS APPL MATER INTER, V9, P40420, DOI 10.1021/acsami.7b11191; Kim Y, 2018, SCIENCE, V360, P998, DOI 10.1126/science.aao0098; Kresse G, 1996, PHYS REV B, V54, P11169, DOI 10.1103/PhysRevB.54.11169; Lee E, 2023, ACS APPL MATER INTER, V15, P15839, DOI 10.1021/acsami.2c21688; Lee J, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/ab793d; Liang XC, 2020, APPL PHYS LETT, V116, DOI 10.1063/1.5120069; Liu DY, 2022, ADV FUNCT MATER, V32, DOI 10.1002/adfm.202203527; Liu GC, 2022, ADV FUNCT MATER, V32, DOI 10.1002/adfm.202200959; Liu L, 2023, ADV FUNCT MATER, V33, DOI 10.1002/adfm.202210119; Mingmin Shi, 2020, Journal of Physics: Conference Series, V1631, DOI 10.1088/1742-6596/1631/1/012042; Mun JW, 2018, ADV FUNCT MATER, V28, DOI 10.1002/adfm.201804222; Nielsen CB, 2013, ADV MATER, V25, P1859, DOI 10.1002/adma.201201795; Perdew JP, 1996, PHYS REV LETT, V77, P3865, DOI 10.1103/PhysRevLett.77.3865; Qian C, 2016, ACS APPL MATER INTER, V8, P26169, DOI 10.1021/acsami.6b08866; Santschi LA, 2003, BRAIN RES, V962, P78, DOI 10.1016/S0006-8993(02)03846-5; Shao L, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202101951; Sharbati MT, 2018, ADV MATER, V30, DOI 10.1002/adma.201802353; Shen HG, 2019, ADV MATER, V31, DOI 10.1002/adma.201905018; Shi LY, 2020, NANOSCALE ADV, V2, P1811, DOI 10.1039/d0na00100g; Shi W, 2020, ADV MATER, V32, DOI 10.1002/adma.201901493; Song S, 2000, NAT NEUROSCI, V3, P919, DOI 10.1038/78829; Stolte M, 2016, ADV FUNCT MATER, V26, P7415, DOI 10.1002/adfm.201602994; Strakosas X, 2015, J APPL POLYM SCI, V132, DOI 10.1002/app.41735; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Sun C, 2015, J PHYS CHEM C, V119, P18014, DOI 10.1021/acs.jpcc.5b03867; Thouin F, 2019, NAT MATER, V18, P349, DOI [10.1038/s41563-018-0262-7, 10.1016/0022-3093(95)00355-X]; Wan QZ, 2019, ADV MATER TECHNOL-US, V4, DOI 10.1002/admt.201900037; Wu MY, 2021, SMALL, V17, DOI 10.1002/smll.202101770; Xiao ZG, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600100; Xu YC, 2021, ADV ELECTRON MATER, V7, DOI 10.1002/aelm.202100336; Yang JW, 2018, ANN OCCUP ENVIRON ME, V30, DOI 10.1186/s40557-018-0250-z; Yang SF, 2017, ADV SCI, V4, DOI 10.1002/advs.201700048; Yu TF, 2020, ACS APPL MATER INTER, V12, P33968, DOI 10.1021/acsami.0c06109; Zucker RS, 2002, ANNU REV PHYSIOL, V64, P355, DOI 10.1146/annurev.physiol.64.092501.114547	64	1	1	32	32	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2198-3844		ADV SCI	Adv. Sci.	APR	2024	11	16								10.1002/advs.202400304	http://dx.doi.org/10.1002/advs.202400304		FEB 2024	12	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science	QI6I0	38408158	gold, Green Published			2024-07-03	WOS:001174746400001
C	Dodge, J; Sap, M; Marasovic, A; Agnew, W; Ilharco, G; Groeneveld, D; Mitchell, M; Gardner, M			Assoc Computat Linguist	Dodge, Jesse; Sap, Maarten; Marasovic, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt			Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus	2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021)			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing (EMNLP)	NOV 07-11, 2021	Punta Cana, DOMINICAN REP					Large language models have led to remarkable progress on many NLP tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping significant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and find a significant amount of text from unexpected sources like patents and US military websites. Then we explore the content of the text itself, and find machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark NLP datasets. To understand the impact of the filters applied to create this dataset, we evaluate the text that was removed, and show that blocklist filtering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.	[Sap, Maarten; Marasovic, Ana; Agnew, William; Ilharco, Gabriel] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA 98195 USA; [Mitchell, Margaret] Hugging Face, New York, NY USA; [Dodge, Jesse; Sap, Maarten; Marasovic, Ana; Groeneveld, Dirk; Gardner, Matt] Allen Inst Artificial Intelligence, Seattle, WA 98103 USA	University of Washington; University of Washington Seattle	Dodge, J (corresponding author), Allen Inst Artificial Intelligence, Seattle, WA 98103 USA.	jessed@allenai.org		Sap, Maarten/0000-0002-0701-4654				[Anonymous], 2011, P 49 ANN M ASS COMPU; Bañón M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4555; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barocas Solon., 2017, SIGCIS; Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bentivogli L., 2009, TAC, V7, P1; Blodgett S. L., 2016, P 2016 C EMPIRICAL M, P1119; Breitfeller LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1664; Carlini Nicholas, 2020, ARXIV201207805CS; Caswell Isaac, 2021, P AFRICANLNP WORKSH; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P76; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; Croom AM, 2013, LANG COMMUN, V33, P177, DOI 10.1016/j.langcom.2013.03.008; Dagan Ido, 2005, MACHINE LEARNING CHA, P177; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dinan E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4537; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; El-Kishky A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5960; Fedus William, 2021, ARXIV210103961; Galinsky AD, 2013, PSYCHOL SCI, V24, P2020, DOI 10.1177/0956797613482943; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Gebru T., 2018, Datasheets for Datasets; Gehman S, 2020, M ASS FOR COMPUTATIO; Giampiccolo Danilo, 2007, P ACL PASCAL WORKSH, P1; Gokaslan Aaron, 2019, OPENWEB TEXT CORPUS; Groenwold S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5877; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Habernal I, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P914; Hamilton William L, 2016, Proc Conf Empir Methods Nat Lang Process, V2016, P595, DOI 10.18653/v1/D16-1057; Harikrishnan R., 2006, Plant Health Progress, P1; Henighan T., 2020, ARXIV201014701; Hermann KM, 2015, 29 ANN C NEURAL INFO, V28; Hutchinson B, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P560, DOI 10.1145/3442188.3445918; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Jo ES, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P306, DOI 10.1145/3351095.3372829; Kaplan Jared, 2020, Scaling laws for neural language models; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Kiela Douwe., 2021, P 2021 C N AM CHAPT; Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519; Lebret Remi, 2016, P 2016 C EMPIRICAL M, P1203, DOI [10.18653/v1/D16-1128, DOI 10.18653/V1/D16-1128]; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Li Tao, 2020, FINDINGS ASS COMPUTA, P3475, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.311; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Y., 2019, CoRR abs/1907.11692; Luccioni A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P182; Meehan A, 2020, MODERNISM AND SUBJECTIVITY, 1 EDITION, P23; Nagel S., 2016, CC NEWS; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Nekoto W, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2144; Nie Yixin, 2020, P 58 ANN M ASS COMPU, P4885, DOI [10.18653/v1/2020.acl-main.441, DOI 10.18653/V1/2020.ACL-MAIN.441, DOI 10.18653/V1/2020.ACL-MAIN, 10.18653/.v1/2020.acl-main.441]; Paullada Amandalynne, 2020, ML RETROSPECTIVES SU; Pinsof D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178534; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Rosa J., 2019, LOOKING LANGUAGE SOU; Schäfer R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4500; Schwenk Holger, 2019, CoRR; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Simonite Tom, 2021, AI LIST DIRTY NAUGHT; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Suárez PJO, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1703; Tatman Rachael, 2020, WHAT I WONT BUILD WI; Trinh Trieu H, 2018, A simple method for commonsense reasoning; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wang WQ, 2012, INT CONF SIGN PROCES, P2007, DOI 10.1109/ICoSP.2012.6491974; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Zellers Rowan, 2019, Advances in Neural Information Processing Systems; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	78	38	44	2	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-09-4				2021							1286	1305						20	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT8XM					2024-07-03	WOS:000855966301031
C	Campos, R; Jorge, A; Jatowt, A; Bhatia, S; Litvak, M		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Campos, Ricardo; Jorge, Alipio; Jatowt, Adam; Bhatia, Sumit; Litvak, Marina			The 7<SUP>th</SUP> International Workshop on Narrative Extraction from Texts: Text2Story 2024	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp				The Text2Story Workshop series, dedicated to Narrative Extraction from Texts, has been running successfully since 2018. Over the past six years, significant progress, largely propelled by Transformers and Large Language Models, has advanced our understanding of natural language text. Nevertheless, the representation, analysis, generation, and comprehensive identification of the different elements that compose a narrative structure remains a challenging objective. In its seventh edition, the workshop strives to consolidate a common platform and a multidisciplinary community for discussing and addressing various issues related to narrative extraction tasks. In particular, we aim to bring to the forefront the challenges involved in understanding narrative structures and integrating their representation into established frameworks, as well as in modern architectures (e.g., transformers) and AI-powered language models (e.g., chatGPT) which are now common and form the backbone of almost every IR and NLP application. Text2Story encompasses sessions covering full research papers, work-in-progress, demos, resources, position and dissemination papers, along with keynote talks. Moreover, there is dedicated space for informal discussions on methods, challenges, and the future of research in this dynamic field.	[Campos, Ricardo; Jorge, Alipio] INESCTEC, LIAAD, Porto, Portugal; [Campos, Ricardo] Univ Beira Interior, Covilha, Portugal; [Campos, Ricardo] Polytech Inst Tomar, Smart Cities Res Ctr Ci2, Tomar, Portugal; [Jorge, Alipio] Univ Porto, FCUP, Porto, Portugal; [Jatowt, Adam] Univ Innsbruck, Innsbruck, Austria; [Bhatia, Sumit] Adobe Syst, MDSR Lab, Bangalore, Karnataka, India; [Litvak, Marina] Shamoon Coll Engn, Beer Sheva, Israel	INESC TEC; Universidade da Beira Interior; Instituto Politecnico de Tomar; Universidade do Porto; University of Innsbruck; Adobe Systems Inc.	Campos, R (corresponding author), INESCTEC, LIAAD, Porto, Portugal.; Campos, R (corresponding author), Univ Beira Interior, Covilha, Portugal.; Campos, R (corresponding author), Polytech Inst Tomar, Smart Cities Res Ctr Ci2, Tomar, Portugal.	ricardo.campos@ubi.pt; amjorge@fc.up.pt; adam.jatowt@uibk.ac.at; Sumit.Bhatia@adobe.com; marinal@sce.ac.il	; Jorge, Alipio/A-1721-2008	Litvak, Marina/0000-0003-3044-3681; Campos, Ricardo/0000-0002-8767-8126; Jorge, Alipio/0000-0002-5475-1382	National Funds through the Portuguese funding agency, FCT -Fundacao para a Ciencia e a Tecnologia; (PTDC); Alipio Jorge within project [LA/P/0063/2020]	National Funds through the Portuguese funding agency, FCT -Fundacao para a Ciencia e a Tecnologia(Fundacao para a Ciencia e a Tecnologia (FCT)); (PTDC); Alipio Jorge within project	Ricardo Campos is financed by National Funds through the Portuguese funding agency, FCT -Fundacao para a Ciencia e a Tecnologia, within the project StorySense (10.54499/2022.14409312.PTDC) and Alipio Jorge within project LA/P/0063/2020.	Alonso Jose M., 2021, Trustworthy AI - Integrating Learning, Optimization and Reasoning. First International Workshop, TAILOR 2020. Revised Selected Papers. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 12641), P63, DOI 10.1007/978-3-030-73959-1_5; Amorim Evelin., 2021, P 4 INT WORKSHOP NAR, V2860, P49; Athanasakou V., 2020, P 1 JOINT WORKSH FIN, P1; Ayed A.B., 2021, Explainable AI Within the Digital Transformation and Cyber Physical Systems, P69, DOI [10.1007/978-3-030-76409-8, DOI 10.1007/978-3-030-76409-8]; Campos R., 2020, LNCS, V12036, P648; Campos R., 2021, LNCS, V2657, P701; Campos R, 2022, LECT NOTES COMPUT SC, V13186, P552, DOI 10.1007/978-3-030-99739-7_68; Campos R, 2018, LECT NOTES COMPUT SC, V10772, P684, DOI 10.1007/978-3-319-76941-7_63; Celikyilmaz A, 2021, Arxiv, DOI arXiv:2006.14799; El-Haj M., 2020, P 1 JOINT WORKSH FIN, P1; El-Haj M., 2022, P 4 FIN NARR PROC WO; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Gomes D., 2021, The Past Web: Exploring Web Archives; Gonçalves F, 2023, LECT NOTES COMPUT SC, V13982, P248, DOI 10.1007/978-3-031-28241-6_22; Grobelny J., 2018, International Journal of Academic Research in Business and Social Sciences, V8, P430; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Jorge A., 2023, Advances in Information Retrieval., V3982, P377; Jorge A., 2019, LNCS, V11438, P389; Jorge AM, 2019, INFORM PROCESS MANAG, V56, P1771, DOI 10.1016/j.ipm.2019.05.004; Jorge AM, 2018, LECT NOTES COMPUT SC, V10772, P833; Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101; Martinez-Alvarez M., 2016, Advances in Information Retrieval, P878, DOI DOI 10.1007/978-3-319-30671-1_85; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Vo N, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P335, DOI 10.1145/3331184.3331248; Ozlem U., 2013, Biomedical Inf., V46, P1; Pasquali Arian, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11438), P251, DOI 10.1007/978-3-030-15719-7_34; Pasquali A., LNCS, V12656, P497; Piper A., 2023, P BIG PICT WORKSH SI, P28; Ranade P, 2022, IEEE ACCESS, V10, P101575, DOI 10.1109/ACCESS.2022.3205314; Saakyan A, 2021, Arxiv, DOI arXiv:2106.03794; Santana B, 2023, ARTIF INTELL REV, V56, P8393, DOI 10.1007/s10462-022-10338-7; Sun SM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P807; Sun WY, 2013, J BIOMED INFORM, V46, pS5, DOI 10.1016/j.jbi.2013.07.004; Wu YF, 2020, JOURNAL PRACT, V14, P1008, DOI 10.1080/17512786.2019.1682940; Zmandar N., 2021, P 3 FINANCIAL NARRAT, P120	35	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56068-2; 978-3-031-56069-9	LECT NOTES COMPUT SC			2024	14612						391	397		10.1007/978-3-031-56069-9_52	http://dx.doi.org/10.1007/978-3-031-56069-9_52			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EC					2024-07-03	WOS:001211835200052
C	Fu, LY; Newman, B; Jakesch, M; Kreps, S			ACM	Fu, Liye; Newman, Benjamin; Jakesch, Maurice; Kreps, Sarah			Comparing Sentence-Level Suggestions to Message-Level Suggestions in AI-Mediated Communication	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023)			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg			AGENDA	Traditionally, writing assistance systems have focused on short or even single-word suggestions. Recently, large language models like GPT-3 have made it possible to generate significantly longer natural-sounding suggestions, offering more advanced assistance opportunities. This study explores the trade-offs between sentence- vs. message-level suggestions for AI-mediated communication. We recruited 120 participants to act as staffers from legislators offices who often need to respond to large volumes of constituent concerns. Participants were asked to reply to emails with different types of assistance. The results show that participants receiving message-level suggestions responded faster and were more satisfied with the experience, as they mainly edited the suggested drafts. In addition, the texts they wrote were evaluated as more helpful by others. In comparison, participants receiving sentence-level assistance retained a higher sense of agency, but took longer for the task as they needed to plan the flow of their responses and decide when to use suggestions. Our findings have implications for designing task-appropriate communication assistance systems.	[Fu, Liye] Thomson Reuters Labs, Toronto, ON, Canada; [Newman, Benjamin] Allen Inst Artifcial Intelligence, Seattle, WA USA; [Fu, Liye; Jakesch, Maurice; Kreps, Sarah] Cornell Univ, Ithaca, NY 14853 USA	Cornell University	Fu, LY (corresponding author), Thomson Reuters Labs, Toronto, ON, Canada.; Fu, LY (corresponding author), Cornell Univ, Ithaca, NY 14853 USA.	liye.fu@thomsonreuters.com; benjaminn@allenai.org; mpj32@cornell.edu; sarah.kreps@cornell.edu		Jakesch, Maurice/0000-0002-2642-3322; Kreps, Sarah/0000-0002-0924-4234				Aral S, 2019, SCIENCE, V365, P858, DOI 10.1126/science.aaw8243; Arnold KC, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P603, DOI 10.1145/2984511.2984584; Banovic N, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340126; Barbera P, 2019, AM POLIT SCI REV, V113, P883, DOI 10.1017/S0003055419000352; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani Rishi, 2021, ARXIV210807258; Bradshaw S., 2017, Computational Propaganda Research Project, P1; Bruns A, 2019, Are flter bubbles real?; Buschek D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445372; Buschek D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173829; Chen MX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/3292500.3330723; Congressional Management Foundation, 2017, HANDL VOL; Congressional Management Foundation, 2022, COMM C; Dou Yao, 2022, P 60 ANN M ASS COMP, V1, DOI [DOI 10.18653/V1/2022.ACL-LONG.501, 10.18653/v1/2022.acl-long]; Dunlop Mark, 2012, P SIGCHI C HUMAN FAC, P2669, DOI [DOI 10.1145/2207676.2208659, 10.1145/2207676.2208659]; Fowler A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P649, DOI 10.1145/2702123.2702503; Goodman Joshua, 2002, LANGUAGE MODELING SO, P194, DOI [DOI 10.1145/502716.502753, 10.1145/ 502716.502753]; Grifth Francis J., 1977, ENGLISH GRAMMAR COMP; Grose CR, 2015, AM J POLIT SCI, V59, P724, DOI 10.1111/ajps.12164; Hancock JT, 2020, J COMPUT-MEDIAT COMM, V25, P89, DOI 10.1093/jcmc/zmz022; Hertel-Fernandez A, 2019, AM POLIT SCI REV, V113, P1, DOI 10.1017/S0003055418000606; Huang P.-S., 2019, ARXIV191103064; Jakesch Maurice, 2022, ARXIV220607271; James Christina, 2000, P CHI 00, P49, DOI DOI 10.1145/633292.633324; Kannan A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P955, DOI 10.1145/2939672.2939801; Khondker HH, 2011, GLOBALIZATIONS, V8, P675, DOI 10.1080/14747731.2011.621287; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Kreps Sarah, 2022, TECHNOLOGIES DECEPTI; Kristensson PO, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P335, DOI 10.1145/2628363.2628405; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Li J., 2016, P 2016 C N AM CHAPTE, P110, DOI DOI 10.18653/V1; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin Stephanie, 2021, ARXIV210907958; Lubars Brian, 2019, ASK NOT WHAT AI CAN; Nozza Debora, 2021, 2021 C N AM CHAPT AS; Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004; Palin K, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340120; Quinn P, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P83, DOI 10.1145/2858036.2858305; Rae Jack W, 2021, arXiv:2112.11446; Singh N, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3511599; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; The OpenGov Foundation, 2017, TECHNICAL REPORT; Vaswani A, 2017, ADV NEUR IN, V30; Vertanen K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P659, DOI 10.1145/2702123.2702135; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Weidinger Laura, 2021, arXiv preprint arXiv:2112.04359; Welleck S., 2020, 8 INT C LEARN REPR I, P1; Wodzak Sophie, 2022, CAN STANDARDIZED TES; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Zhuravskaya E, 2020, ANNU REV ECON, V12, P415, DOI 10.1146/annurev-economics-081919-050239	50	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3581351	http://dx.doi.org/10.1145/3544548.3581351			13	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV5HH		Bronze, Green Submitted			2024-07-03	WOS:001048393803055
J	Xue, JT; Wang, YC; Wei, CW; Liu, XF; Woo, JY; Kuo, CCJ				Xue, Jintang; Wang, Yun-Cheng; Wei, Chengwei; Liu, Xiaofeng; Woo, Jonghye; Kuo, C. C. Jay			Bias and Fairness in Chatbots: An Overview	APSIPA TRANSACTIONS ON SIGNAL AND INFORMATION PROCESSING			English	Article						Chatbots; ChatGPT; Bias; Fairness; Natural Language Processing	RACIAL BIAS; GENDER; CHALLENGES; MODELS; ALEXA; ELIZA; SIRI	Chatbots have been studied for more than half a century. With the rapid development of natural language processing (NLP) technologies in recent years, chatbots using large language models (LLMs) have received much attention nowadays. Compared with traditional ones, modern chatbots are more powerful and have been used in real-world applications. There are, however, bias and fairness concerns in modern chatbot design. Due to the huge amounts of training data, extremely large model sizes, and lack of interpretability, bias mitigation and fairness preservation of modern chatbots are challenging. Thus, a comprehensive overview on bias and fairness in chatbot systems is given in this paper. The history of chatbots and their categories are first reviewed. Then, bias sources and potential harms in applications are analyzed. Considerations in designing fair and unbiased chatbot systems are examined. Finally, future research directions are discussed.	[Xue, Jintang; Wang, Yun-Cheng; Wei, Chengwei; Kuo, C. C. Jay] Univ Southern Calif, Los Angeles, CA 90089 USA; [Liu, Xiaofeng; Woo, Jonghye] Massachusetts Gen Hosp, Dept Radiol, Gordon Ctr Med Imaging, Boston, MA 02114 USA; [Liu, Xiaofeng; Woo, Jonghye] Harvard Med Sch, Boston, MA 02114 USA	University of Southern California; Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School	Xue, JT (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.	jintangx@usc.edu		Xue, Jintang/0009-0004-3531-8147				Abbasi Mohsen, 2019, P 2019 SIAM INT C DA, P801; Abboud R., 2020, P 34 INT C NEURAL IN, V33, P9649; Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Adam M, 2021, ELECTRON MARK, V31, P427, DOI 10.1007/s12525-020-00414-7; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081; Aron Jacob., 2011, How innovative is apple's new voice assistant, siri?; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Baeza-Yates R, 2018, COMMUN ACM, V61, P54, DOI 10.1145/3209581; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Baker RS, 2022, INT J ARTIF INTELL E, V32, P1052, DOI 10.1007/s40593-021-00285-9; Ball-Burack A, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P116, DOI 10.1145/3442188.3445875; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Beattie H, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ASSURED AUTONOMY (ICAA 2022), P117, DOI 10.1109/ICAA52185.2022.00023; Bernotat J, 2021, INT J SOC ROBOT, V13, P477, DOI 10.1007/s12369-019-00562-7; Bernotat J, 2017, LECT NOTES ARTIF INT, V10652, P75, DOI 10.1007/978-3-319-70022-9_8; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Blodgett SL, 2020, Arxiv, DOI arXiv:2005.14050; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bolton T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072312; Bolukbasi T, 2016, ADV NEUR IN, V29; Booth Brandon M., 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P268, DOI 10.1145/3462244.3479897; Bradesko L., 2012, P SLOVENIAN LANGUAGE, P34; Brahnam S, 2012, INTERACT COMPUT, V24, P139, DOI 10.1016/j.intcom.2012.05.001; Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burtell M, 2023, Arxiv, DOI arXiv:2303.08721; Cahn J., 2017, CHATBOT: Architecture, design; Cain DM, 2008, JAMA-J AM MED ASSOC, V299, P2893, DOI 10.1001/jama.299.24.2893; Caldarini G, 2022, INFORMATION, V13, DOI 10.3390/info13010041; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Caton S, 2020, Arxiv, DOI arXiv:2010.04053; Cercas Curry A., 2018, P 2 ACL WORKSH ETH N, P7; Chan A., 2022, AI and Ethics, V3, P53, DOI DOI 10.1007/S43681-022-00148-6; Chang Kai-Wei, 2019, P 2019 C EMPIRICAL M; Chaves AP, 2021, INT J HUM-COMPUT INT, V37, P729, DOI 10.1080/10447318.2020.1841438; Chen CN, 2018, P NATL ACAD SCI USA, V115, pE10013, DOI 10.1073/pnas.1807862115; Chen Y, 2016, CLIN THER, V38, P688, DOI 10.1016/j.clinthera.2015.12.001; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cirillo D, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0288-5; COLBY KM, 1981, BEHAV BRAIN SCI, V4, P515, DOI 10.1017/S0140525X00000030; COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6; Costa P, 2019, TECHNOETIC ARTS, V17, P171, DOI 10.1386/tear_00014_1; Costa P, 2018, J SCI TECHNOL ARTS, V10, P59, DOI 10.7559/citarj.v10i3.563; Crawford Kate, 2017, C NEUR INF PROC SYST; Day T, 2023, PROF GEOGR, V75, P1024, DOI 10.1080/00330124.2023.2190373; Delgado-Rodríguez M, 2004, J EPIDEMIOL COMMUN H, V58, P635, DOI 10.1136/jech.2003.008466; Deryugina OV, 2010, SCI TECH INF PROCESS, V37, P143, DOI 10.3103/S0147688210020097; Dev S, 2021, Arxiv, DOI arXiv:2007.00049; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Domnich A, 2021, Arxiv, DOI [arXiv:2103.11436, 10.48550/arXiv.2103.11436, DOI 10.48550/ARXIV.2103.11436]; Elsafoury F, 2024, Arxiv, DOI arXiv:2305.12829; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; Eyssel F, 2012, J APPL SOC PSYCHOL, V42, P2213, DOI 10.1111/j.1559-1816.2012.00937.x; Feine J., 2020, CHATBOT RES DESIGN, P79, DOI DOI 10.1007/978-3-030-39540-7_6; Feng SY, 2021, Arxiv, DOI arXiv:2103.15122; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.07683, DOI 10.48550/ARXIV.2304.07683]; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Firat M., 2023, How Chat Gpt Can Transform Autodidactic Experiences and Open Education; Fischer R, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-015-1663-6; Folstad A., 2017, interactions, V24, P38, DOI [DOI 10.1145/3085558, 10.1145/3085558]; Folstad A, 2018, LECT NOTES COMPUT SC, V11193, P194, DOI 10.1007/978-3-030-01437-7_16; Fraiwan M, 2023, Arxiv, DOI arXiv:2305.00237; Frolov S, 2021, NEURAL NETWORKS, V144, P187, DOI 10.1016/j.neunet.2021.07.019; Galhotra S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P498, DOI 10.1145/3106237.3106277; Garrido-Muñoz I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073184; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Ge X., 2023, P 61 ANN M ASS COMP, V1, P6947, DOI [10.18653/v1/2023.acllong.384, DOI 10.18653/V1/2023.ACLLONG.384]; Gordon Jonathan, 2013, P 2013 WORKSHOP AUTO, P25, DOI [10.1145/2509558.2509563, DOI 10.1145/2509558.2509563]; Gravel J., 2023, Mayo Clin Proc Digit Health, V1, P226, DOI [DOI 10.1016/J.MCPDIG.2023.05.004, 10.1016/j.mcpdig.2023.05.004]; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Haque M.U., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.05856; Harms JG, 2019, IEEE INTERNET COMPUT, V23, P13, DOI 10.1109/MIC.2018.2881519; Hendricks LA, 2018, LECT NOTES COMPUT SC, V11207, P793, DOI 10.1007/978-3-030-01219-9_47; High R., 2012, IBM Corporation Redbooks; Hosseini M., 2023, medRxiv; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391; Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93; Jain V., 2023, EMMANUEL PROSPECTS C; Janssen A, 2020, BUS INFORM SYST ENG+, V62, P211, DOI 10.1007/s12599-020-00644-1; Jiao AR, 2020, J PHYS CONF SER, V1487, DOI 10.1088/1742-6596/1487/1/012014; Bellamy RKE, 2018, Arxiv, DOI [arXiv:1810.01943, DOI 10.48550/ARXIV.1810.01943]; Kaczorowska-Spychalska D, 2019, MANAG-POL, V23, P251, DOI 10.2478/manment-2019-0015; Kalyan K. S., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.05542, 10.48550/arXiv.2108.05542]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Këpuska V, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P99, DOI 10.1109/CCWC.2018.8301638; Kerly A, 2007, KNOWL-BASED SYST, V20, P177, DOI 10.1016/j.knosys.2006.11.014; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Kizilcec R.F, 2022, The ethics of artificial intelligence in education, P174; Klayman J., 1995, Psychology of Learning and Motivation, V32, P385, DOI [DOI 10.1016/S0079-7421, 10.1016/S0079-7421(08)60315-1, DOI 10.1016/S0079-7421(08)60315-1]; Kleinberg J, 2016, Arxiv, DOI [arXiv:1609.05807, DOI 10.48550/ARXIV.1609.05807, 10.48550/arXiv.1609.05807]; Kochling A., 2020, Business Research, V13, P795, DOI DOI 10.1007/S40685-020-00134-W; Kooli C, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15075614; Kordzadeh N, 2022, EUR J INFORM SYST, V31, P388, DOI 10.1080/0960085X.2021.1927212; Korteling JE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01561; Kostick-Quenet KM, 2022, J LAW MED ETHICS, V50, P92, DOI 10.1017/jme.2022.13; Kuo CCJ, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103685; Kurniawan AA, 2015, 2015 INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH), P326, DOI 10.1109/ICSITech.2015.7407826; Kusner M, 2017, ADV NEUR IN, V30; LaGrandeur K., 2020, ETHICS, DOI DOI 10.1007/S43681-020-00010-7; Lalwani T, 2018, INT J INNOV RES COMP; Lauscher A, 2020, AAAI CONF ARTIF INTE, V34, P8131; Lee N., 2019, P 2019 WORKSHOP WIDE, P177; Li S, 2019, IEEE T EM TOP COMP I, V3, P297, DOI 10.1109/TETCI.2019.2892755; Li Y., 2023, ARXIV; Linardatos P, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010018; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192; Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7; McDonnell M, 2019, INTERACT COMPUT, V31, P116, DOI 10.1093/iwc/iwz007; McGee R. W., 2023, An Empirical Study, V2023; McNamee Paul, 2005, Journal of Computing Sciences in Colleges, V20, P94; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Meissner P, 2017, EUR MANAG J, V35, P430, DOI 10.1016/j.emj.2016.12.004; Mhasawade V, 2021, NAT MACH INTELL, V3, P659, DOI 10.1038/s42256-021-00373-4; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mitchell S, 2021, ANNU REV STAT APPL, V8, P141, DOI 10.1146/annurev-statistics-042720-125902; Mohanani R, 2020, IEEE T SOFTWARE ENG, V46, P1318, DOI 10.1109/TSE.2018.2877759; Mokander J., 2023, AI & Ethics; Nadeem A., 2020, Gender Bias in AI: A review of contributing factors and mitigating strategies; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nass C, 1997, J APPL SOC PSYCHOL, V27, P864, DOI 10.1111/j.1559-1816.1997.tb00275.x; Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880; Neff G, 2016, INT J COMMUN-US, V10, P4915; Nelson Gregory S, 2019, N C Med J, V80, P220, DOI 10.18043/ncm.80.4.220; Ning YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194050; Nirala KK, 2022, MULTIMED TOOLS APPL, V81, P22215, DOI 10.1007/s11042-021-11458-y; Noor P, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m363; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058; Park Ji Ho, 2018, arXiv; Parrish A, 2022, Arxiv, DOI arXiv:2110.08193; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Qraitem M, 2023, PROC CVPR IEEE, P20311, DOI 10.1109/CVPR52729.2023.01945; Rajkomar A, 2018, ANN INTERN MED, V169, P866, DOI 10.7326/M18-1990; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Rho, 2020, BASIC DEMOGRAPHIC PR, P7, DOI DOI 10.1111/J.0887-378X.2004.00328.X; Rivas P, 2023, AI-BASEL, V4, P375, DOI 10.3390/ai4020019; Roller S, 2020, Arxiv, DOI arXiv:2004.13637; Roselli D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P539, DOI 10.1145/3308560.3317590; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rudinger R, 2018, Arxiv, DOI arXiv:1804.09301; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Saleiro P, 2018, Aequitas: A Bias and Fairness Audit Toolkit, DOI 10.48550/arXiv.1811.05577; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarker Iqbal H, 2021, SN Comput Sci, V2, P160, DOI 10.1007/s42979-021-00592-x; Satu MS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION ENGINEERING (ICCIE), P87; Schlesinger A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173889; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Selbst AD, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P59, DOI 10.1145/3287560.3287598; Seo S, 2022, INT J HOSP MANAG, V102, DOI 10.1016/j.ijhm.2022.103166; Shawar B. A., 2002, School of Computing research report 2002.19; Shawar B. A., 2007, P 4 CORP LING C; Sheng EMY, 2020, Arxiv, DOI arXiv:2005.00268; Sheng Emily, 2021, arXiv; Shum HY, 2018, FRONT INFORM TECH EL, V19, P10, DOI 10.1631/FITEE.1700826; Si Wai Man, 2022, CCS '22: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, P2659, DOI 10.1145/3548606.3560599; Singh Siddhant, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1074, DOI 10.1109/ICRITO48877.2020.9197943; Solaiman I, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P111, DOI 10.1145/3593013.3593981; Srinivasan R, 2021, COMMUN ACM, V64, P44, DOI 10.1145/3464903; Suhaili SM, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115461; Sun JS, 2023, Arxiv, DOI arXiv:2307.07697; Sun TY, 2019, Arxiv, DOI arXiv:1906.08976; Suresh H, 2021, Arxiv, DOI [arXiv:1901.10002, 10.48550/arXiv.1901.10002]; Suresh H, 2021, PROCEEDINGS OF 2021 ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2021, DOI 10.1145/3465416.3483305; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Tan X, 2021, Arxiv, DOI arXiv:2106.15561; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thorat S.A., 2020, P INT C INN COMP COM; Touvron H., 2023, arXiv; Turing A. M, 2009, Computing machinery and intelligence; Ukpabi DC, 2019, ROBOTS, ARTIFICIAL INTELLIGENCE, AND SERVICE AUTOMATION IN TRAVEL, TOURISM AND HOSPITALITY, P105, DOI 10.1108/978-1-78756-687-320191006; Vashishth S., 2020, INT C LEARN REPR, P1; Vasudevan S, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2773, DOI 10.1145/3340531.3412705; Vaswani A, 2017, ADV NEUR IN, V30; Verma S, 2018, 2018 IEEE/ACM INTERNATIONAL WORKSHOP ON SOFTWARE FAIRNESS (FAIRWARE 2018), P1, DOI [10.1145/3194770.3194776, 10.23919/FAIRWARE.2018.8452913]; Viswanath H, 2023, Arxiv, DOI arXiv:2302.05508; Wallace R. S., 2009, The anatomy of ALICE; Wang CA, 2024, POSTGRAD MED, V136, P22, DOI [10.1080/00325481.2023.2288562, 10.30420/566091317]; Wang S., 2023, arXiv; Wang X, 2024, Arxiv, DOI [arXiv:2302.10035, DOI 10.48550/ARXIV.2302.10035]; Wang YC, 2023, IEEE OPEN J COMM SOC, V4, P2952, DOI 10.1109/OJCOMS.2023.3320646; Wei CW, 2023, Arxiv, DOI [arXiv:2303.05759, 10.48550/arXiv.2303.05759]; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Weizenbaum J., 1976, Computer Power and Human Reason: From Judgment to Calculation; West M., 2019, ID BLUSH I COULD CLO, DOI DOI 10.54675/RAPC9356; WINSHIP C, 1992, ANNU REV SOCIOL, V18, P327, DOI 10.1146/annurev.so.18.080192.001551; Wolf M. J., 2017, ACM SIGCAS Computers and Society, V47, P54, DOI 10.1145/3144592.3144598; Woods HS, 2018, CRIT STUD MEDIA COMM, V35, P334, DOI 10.1080/15295036.2018.1488082; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xiong T., 2017, P 2017 C EMPIRICAL M, P564, DOI DOI 10.18653/V1/D17-1060; Zabel S, 2021, LECT NOTES COMPUT SC, V12764, P184, DOI 10.1007/978-3-030-78468-3_13; Zafar MB, 2017, PR MACH LEARN RES, V54, P962; Zelaszczyk M., 2023, Cross-modal text and visual generation: A systematic review. Part 1-Image to text; ZEMCIK M. T., 2019, DEStech Transactions on Computer Science and Engineering, V10; Zhang CS, 2023, Arxiv, DOI arXiv:2303.07909; Zhang JZ, 2023, Arxiv, DOI arXiv:2305.07609; Zhao JY, 2018, Arxiv, DOI arXiv:1804.06876; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhou J., 2023, ARXIV; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]; Zumstein D., 2017, Transactions and Services. IADIS International Journal on WWW/Internet, V15, P96	220	0	0	9	9	NOW PUBLISHERS INC	HANOVER	PO BOX 1024, HANOVER, MA 02339, UNITED STATES	2048-7703			APSIPA TRANS SIGNAL	APSIPA Trans. Signal Inf. Proc.		2024	13	2			SI					10.1561/116.00000064	http://dx.doi.org/10.1561/116.00000064			44	Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Engineering	ME0K9		gold, Green Submitted			2024-07-03	WOS:001191830200001
C	Zhao, XD; Li, L; Wang, YX			ASSOC COMPUTAT LINGUIST	Zhao, Xuandong; Li, Lei; Wang, Yu-Xiang			Provably Confidential Language Modelling	NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES			English	Proceedings Paper	Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies	JUL 10-15, 2022	Seattle, WA	Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data				Large language models are shown to memorize privacy information such as social security numbers in training data. Given the sheer scale of the training corpus, it is challenging to screen and filter all privacy data, either manually or automatically. In this paper, we propose Confidentially Redacted Training (CRT), a method to train language generation models while protecting the confidential segments. We borrow ideas from differential privacy (which solves a related but distinct problem) and show that our method is able to provably prevent unintended memorization by randomizing parts of the training process. Moreover, we show that redaction with an approximately correct screening policy amplifies the confidentiality guarantee. We implement the method for both LSTM and GPT language models. Our experimental results show that the models trained by CRT obtain almost the same perplexity while preserving strong confidentiality(1).	[Zhao, Xuandong; Li, Lei; Wang, Yu-Xiang] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA	University of California System; University of California Santa Barbara	Zhao, XD (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.	xuandongzhao@cs.ucsb.edu; leili@cs.ucsb.edu; yuxiangw@cs.ucsb.edu	DOU, LIPING/KAL-7005-2024		NSF [2048091]; UCSB; Direct For Computer & Info Scie & Enginr; Division Of Computer and Network Systems [2048091] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); UCSB; Direct For Computer & Info Scie & Enginr; Division Of Computer and Network Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The work was partially supported by NSF Award # 2048091. XZ was supported by UCSB Chancellor's Fellowship. We would like to thank the anonymous reviewers for their thoughtful comments. We would also like to thank Siqi Ouyang for the helpful discussion and Yang Gao for polishing up the draft.	Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Anil Rohan, 2021, ABS210801624 CORR; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Balle B, 2018, ADV NEUR IN, V31; Bartolomeo G, 2013, IDENTIFICATION AND MANAGEMENT OF DISTRIBUTED DATA: NGN, CONTENT-CENTRIC NETWORKS AND THE WEB, P49; BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Carlini Nicholas, 2021, USENIX SEC S; Devlin J., 2018, BERT PRE TRAINING DE; Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14; Feldman V, 2020, ACM S THEORY COMPUT, P954, DOI 10.1145/3357713.3384290; Ganguly Debasis, 2015, P 38 INT ACM SIGIR C; Ghosh A, 2015, GAME ECON BEHAV, V91, P334, DOI 10.1016/j.geb.2013.06.013; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hosseini-Asl Ehsan, 2020, ABS200500796 CORR; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Jarvinen Kimmo, 2004, Design and Implementation of a SHA-1 Hash Module on FPGAs; Kandpal Nikhil, 2022, ARXIV220206539; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lee K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8424; Li Xuechen, 2021, ABS211005679 ARXIV; McMahan H. B., 2018, P INT C LEARN REPR; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel Colin, 2020, ABS191010683 ARXIV; Shi Weiyan, 2021, ABS210812944 ARXIV; Triastcyn A., 2020, INT C MACHINE LEARNI, P9583; Vaswani A, 2017, ADV NEUR IN, V30; Weischedel R., 2013, Ontonotes Release 5.0 ldc2013t19, P23; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zang Xiaoxue, 2020, P 2 WORKSH NAT LANG, P109; Zhao Tiancheng, 2018, SIGDIAL C	32	2	2	2	3	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-71-1				2022							943	955						13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9EE					2024-07-03	WOS:000859869501004
J	Li, Z; Wei, Q; Huang, LC; Li, JF; Hu, Y; Chuang, YS; He, JP; Das, A; Keloth, VK; Yang, YT; Diala, CS; Roberts, KE; Tao, C; Jiang, XQ; Zheng, WJ; Xu, H				Li, Zhao; Wei, Qiang; Huang, Liang-Chin; Li, Jianfu; Hu, Yan; Chuang, Yao-Shun; He, Jianping; Das, Avisha; Keloth, Vipina Kuttichi; Yang, Yuntao; Diala, Chiamaka S.; Roberts, Kirk E.; Tao, Cui; Jiang, Xiaoqian; Zheng, W. Jim; Xu, Hua			Ensemble pretrained language models to extract biomedical knowledge from literature	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						named entity recognition; relation extraction; large language model; ensemble learning; knowledge base	RECOGNITION; NAME	Objectives The rapid expansion of biomedical literature necessitates automated techniques to discern relationships between biomedical concepts from extensive free text. Such techniques facilitate the development of detailed knowledge bases and highlight research deficiencies. The LitCoin Natural Language Processing (NLP) challenge, organized by the National Center for Advancing Translational Science, aims to evaluate such potential and provides a manually annotated corpus for methodology development and benchmarking.Materials and Methods For the named entity recognition (NER) task, we utilized ensemble learning to merge predictions from three domain-specific models, namely BioBERT, PubMedBERT, and BioM-ELECTRA, devised a rule-driven detection method for cell line and taxonomy names and annotated 70 more abstracts as additional corpus. We further finetuned the T0pp model, with 11 billion parameters, to boost the performance on relation extraction and leveraged entites' location information (eg, title, background) to enhance novelty prediction performance in relation extraction (RE).Results Our pioneering NLP system designed for this challenge secured first place in Phase I-NER and second place in Phase II-relation extraction and novelty prediction, outpacing over 200 teams. We tested OpenAI ChatGPT 3.5 and ChatGPT 4 in a Zero-Shot setting using the same test set, revealing that our finetuned model considerably surpasses these broad-spectrum large language models.Discussion and Conclusion Our outcomes depict a robust NLP system excelling in NER and RE across various biomedical entities, emphasizing that task-specific models remain superior to generic large ones. Such insights are valuable for endeavors like knowledge graph development and hypothesis formulation in biomedical research.	[Li, Zhao; Wei, Qiang; Huang, Liang-Chin; Li, Jianfu; Hu, Yan; Chuang, Yao-Shun; He, Jianping; Das, Avisha; Yang, Yuntao; Diala, Chiamaka S.; Roberts, Kirk E.; Tao, Cui; Jiang, Xiaoqian; Zheng, W. Jim] Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX 77030 USA; [Keloth, Vipina Kuttichi; Xu, Hua] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT 06510 USA; [Xu, Hua] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St, New Haven, CT 06510 USA	University of Texas System; University of Texas Health Science Center Houston; Yale University; Yale University	Zheng, WJ (corresponding author), Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX 77030 USA.; Xu, H (corresponding author), Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St, New Haven, CT 06510 USA.	wenjin.j.zheng@uth.tmc.edu; hua.xu@yale.edu	He, JianPing/H-9536-2018	Hu, Yan/0009-0008-2413-5918	National Institutes of Health (NIH) [1UL1TR003167, 1R01AG066749, 1U24MH130988-01, R01LM011934, R21EB029575, R01AG078154]; Department of Defense [W81XWH-22-1-0164]; Cancer Prevention and Research Institute of Texas [RP170668]	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Department of Defense(United States Department of Defense); Cancer Prevention and Research Institute of Texas(Cancer Prevention & Research Institute of Texas)	This work is partly supported by the National Institutes of Health (NIH) through grants 1UL1TR003167, 1R01AG066749, 1U24MH130988-01, R01LM011934, R21EB029575, R01AG078154, Department of Defense W81XWH-22-1-0164, and the Cancer Prevention and Research Institute of Texas through grant RP170668.	Akhondi SA, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/1758-2946-7-S1-S10; Alrowili S., 2021, P 20 WORKSHOP BIOMED, P221; Arora S, 2022, Arxiv, DOI [arXiv:2210.02441, arXiv:2210.02441]; Bach S.H., 2022, arXiv; Bada M, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-161; Bengio E, 2021, ADV NEUR IN, V34; Ding N, 2021, Arxiv, DOI arXiv:2111.01998; Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu Y, 2022, IEEE INT CONF HEALT, P606, DOI 10.1109/ICHI54592.2022.00119; Huang ZH, 2015, Arxiv, DOI [arXiv:1508.01991, DOI 10.48550/ARXIV.1508.01991]; Islamaj R, 2021, J BIOMED INFORM, V118, DOI 10.1016/j.jbi.2021.103779; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Leser U, 2005, BRIEF BIOINFORM, V6, P357, DOI 10.1093/bib/6.4.357; Luo L, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac282; Luoma J, 2020, Arxiv, DOI arXiv:2006.01563; Malafoglia V, 2021, CURR OPIN PHARMACOL, V57, P184, DOI 10.1016/j.coph.2021.02.007; Malki MA, 2020, PHARMACOGENOMICS J, V20, P355, DOI 10.1038/s41397-019-0122-0; Qi P, 2020, Arxiv, DOI [arXiv:2003.07082, 10.48550/arXiv.2003.07082, DOI 10.48550/ARXIV.2003.07082]; Raffel C, 2020, J MACH LEARN RES, V21; Sanh V, 2022, arXiv; Sarkar S, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P1180, DOI 10.1145/3487553.3524933; Song BS, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab282; Vaswani A, 2017, ADV NEUR IN, V30; Wei CH, 2015, BIOMED RES INT-UK, V2015, DOI 10.1155/2015/918710; Xia Fei., 2012, P 3 WORKSHOP BUILDIN; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zeng DH, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060283; Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203; Zhu QL, 2018, BIOINFORMATICS, V34, P1547, DOI 10.1093/bioinformatics/btx815	31	0	0	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 MAR 23	2024										10.1093/jamia/ocae061	http://dx.doi.org/10.1093/jamia/ocae061		MAR 2024	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	LU7Y0	38520725	hybrid			2024-07-03	WOS:001189391600001
J	May, M; Körner-Riffard, K; Kollitsch, L; Burger, M; Brookman-May, SD; Rauchenwald, M; Marszalek, M; Eredics, K				May, Matthias; Koerner-Riffard, Katharina; Kollitsch, Lisa; Burger, Maximilian; Brookman-May, Sabine D.; Rauchenwald, Michael; Marszalek, Martin; Eredics, Klaus			Evaluating the Efficacy of AI Chatbots as Tutors in Urology: A Comparative Analysis of Responses to the 2022 In-Service Assessment of the European Board of Urology	UROLOGIA INTERNATIONALIS			English	Article; Early Access						Artificial intelligence; Large language model; Urology; In-Service Assessment; European Board of Urology; ChatGPT; Bing AI		Introduction: This study assessed the potential of large language models (LLMs) as educational tools by evaluating their accuracy in answering questions across urological subtopics. Methods: Three LLMs (ChatGPT-3.5, ChatGPT-4, and Bing AI) were examined in two testing rounds, separated by 48 h, using 100 Multiple-Choice Questions (MCQs) from the 2022 European Board of Urology (EBU) In-Service Assessment (ISA), covering five different subtopics. The correct answer was defined as "formal accuracy" (FA) representing the designated single best answer (SBA) among four options. Alternative answers selected from LLMs, which may not necessarily be the SBA but are still deemed correct, were labeled as "extended accuracy" (EA). Their capacity to enhance the overall accuracy rate when combined with FA was examined. Results: In two rounds of testing, the FA scores were achieved as follows: ChatGPT-3.5: 58% and 62%, ChatGPT-4: 63% and 77%, and BING AI: 81% and 73%. The incorporation of EA did not yield a significant enhancement in overall performance. The achieved gains for ChatGPT-3.5, ChatGPT-4, and BING AI were as a result 7% and 5%, 5% and 2%, and 3% and 1%, respectively (p > 0.3). Within urological subtopics, LLMs showcased best performance in Pediatrics/Congenital and comparatively less effectiveness in Functional/BPS/Incontinence. Conclusion: LLMs exhibit suboptimal urology knowledge and unsatisfactory proficiency for educational purposes. The overall accuracy did not significantly improve when combining EA to FA. The error rates remained high ranging from 16 to 35%. Proficiency levels vary substantially across subtopics. Further development of medicine-specific LLMs is required before integration into urological training programs.	[May, Matthias] St Elisabeth Hosp Straubing, Dept Urol, Bros Mercy Hosp, Straubing, Germany; [Koerner-Riffard, Katharina; Burger, Maximilian] Univ Regensburg, Caritas St Josef Med Ctr, Dept Urol, Regensburg, Germany; [Kollitsch, Lisa; Rauchenwald, Michael; Marszalek, Martin; Eredics, Klaus] Klin Donaustadt, Dept Urol & Androl, Vienna, Austria; [Brookman-May, Sabine D.] LMU, Univ Munich, Dept Urol, Munich, Germany; [Brookman-May, Sabine D.] Johnson & Johnson Innovat Med Res & Dev, Spring House, PA USA; [Rauchenwald, Michael] European Board Urol, Arnhem, Netherlands; [Eredics, Klaus] Paracelsus Med Univ, Dept Urol, Salzburg, Austria	University of Regensburg; University of Munich; Paracelsus Private Medical University	Körner-Riffard, K (corresponding author), Univ Regensburg, Caritas St Josef Med Ctr, Dept Urol, Regensburg, Germany.							Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Caglar U, 2024, J PEDIATR UROL, V20, DOI 10.1016/j.jpurol.2023.08.003; Cakir H, 2024, INT UROL NEPHROL, V56, P17, DOI 10.1007/s11255-023-03773-0; Cheung BHH, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290691; Deebel NA, 2023, UROLOGY, V177, P29, DOI 10.1016/j.urology.2023.05.010; Eppler M, 2024, EUR UROL, V85, P146, DOI 10.1016/j.eururo.2023.10.014; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Huynh LM, 2023, UROL PRACT, V10, P408, DOI 10.1097/UPJ.0000000000000406; Klang E, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04752-w; Kollitsch L, 2024, WORLD J UROL, V42, DOI 10.1007/s00345-023-04749-6; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lewandowski M, 2023, CLIN EXP DERMATOL, V49, P686, DOI 10.1093/ced/llad255; May M, 2024, EUR UROL ONCOL, V7, P155, DOI 10.1016/j.euo.2023.08.013; Musheyev D, 2024, EUR UROL, V85, P13, DOI 10.1016/j.eururo.2023.07.004; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Teoh JYC, 2021, BJU INT, V128, P397, DOI 10.1111/bju.15517	20	0	0	0	0	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	0042-1138	1423-0399		UROL INT	Urol.Int.	2024 MAR 30	2024										10.1159/000537854	http://dx.doi.org/10.1159/000537854		MAR 2024	8	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	TR9E0	38555637				2024-07-03	WOS:001243096100001
J	Hakam, HT; Prill, R; Korte, L; Lovrekovi, B; Ostoji, M; Ramadanov, N; Muehlensiepen, F				Hakam, Hassan Tarek; Prill, Robert; Korte, Lisa; Lovrekovi, Bruno; Ostoji, Marko; Ramadanov, Nikolai; Muehlensiepen, Felix			Human-Written vs AI-Generated Texts in Orthopedic Academic Literature: Comparative Qualitative Analysis	JMIR FORMATIVE RESEARCH			English	Article						artificial intelligence; AI; large language model; LLM; research; orthopedic surgery; sports medicine; orthopedics; surgery; orthopedic; qualitative study; medical database; feedback; detection; tool; scientific integrity; study design	ARTIFICIAL-INTELLIGENCE	Background: As large language models (LLMs) are becoming increasingly integrated into different aspects of health care, questions about the implications for medical academic literature have begun to emerge. Key aspects such as authenticity in academic writing are at stake with artificial intelligence (AI) generating highly linguistically accurate and grammatically sound texts. Objective: The objective of this study is to compare human-written with AI-generated scientific literature in orthopedics and sports medicine. Methods: Five original abstracts were selected from the PubMed database. These abstracts were subsequently rewritten with the assistance of 2 LLMs with different degrees of proficiency. Subsequently, researchers with varying degrees of expertise and with different areas of specialization were asked to rank the abstracts according to linguistic and methodological parameters. Finally, researchers had to classify the articles as AI generated or human written. Results: Neither the researchers nor the AI-detection software could successfully identify the AI-generated texts. Furthermore, the criteria previously suggested in the literature did not correlate with whether the researchers deemed a text to be AI generated or whether they judged the article correctly based on these parameters. Conclusions: The primary finding of this study was that researchers were unable to distinguish between LLM-generated and human-written texts. However, due to the small sample size, it is not possible to generalize the results of this study. As is the case with any tool used in academic research, the potential to cause harm can be mitigated by relying on the transparency and integrity of the researchers. With scientific integrity at stake, further research with a similar study design should be conducted to determine the magnitude of this issue.	[Ramadanov, Nikolai] Univ Clin Brandenburg, Brandenburg Med Sch, Ctr Orthopaed & Trauma Surg, Brandenburg, Germany; [Prill, Robert; Ramadanov, Nikolai] Univ Clin Brandenburg, Fac Hlth Sci, Brandenburg, Germany; [Prill, Robert; Muehlensiepen, Felix] JBI Affiliated Grp, Ctr Evidence Based Practice Brandenburg, Brandenburg, Germany; [Korte, Lisa; Muehlensiepen, Felix] Univ Clin Brandenburg, Fac Hlth Sci, Ctr Hlth Serv Res, Rudersdorf Bei Berlin, Germany; [Lovrekovi, Bruno] Univ Hosp Merkur, Fac Orthopaed, Zagreb, Croatia; [Ostoji, Marko] Univ Hosp Mostar, Dept Orthopaed, Mostar, Bosnia & Herceg; [Hakam, Hassan Tarek] Univ Clin Brandenburg, Ctr Orthopaed & Trauma Surg, Brandenburg Med Sch, Hochstr 29, D-14770 Brandenburg, Germany	University of Mostar	Hakam, HT (corresponding author), Univ Clin Brandenburg, Ctr Orthopaed & Trauma Surg, Brandenburg Med Sch, Hochstr 29, D-14770 Brandenburg, Germany.	hassantarek.hakam@mhb-fontane.de	Prill, Robert/AAC-3898-2019	Prill, Robert/0000-0002-4916-1206; Hakam, Hassan Tarek/0009-0008-5957-0848; Korte, Lisa/0000-0002-1515-6441; Muehlensiepen, Felix/0000-0001-8571-7286; Lovrekovic, Bruno/0000-0003-3765-1483				[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Beaufils P, 2018, ORTHOP TRAUMATOL-SUR, V104, pS137, DOI 10.1016/j.otsr.2017.04.016; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Cheng KM, 2023, ANN BIOMED ENG, V51, P1658, DOI 10.1007/s10439-023-03213-1; Ciaccio Edward J., 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101253; da Silva JAT, 2023, ANN BIOMED ENG, V51, P2103, DOI 10.1007/s10439-023-03247-5; Dankelman LHM, 2023, EUR J TRAUMA EMERG S, V49, P681, DOI 10.1007/s00068-022-02128-1; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Federer SJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0260471; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gu JJ, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100511; Gupta Puneet, 2023, Foot Ankle Orthop, V8, p24730114221151079, DOI 10.1177/24730114221151079; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Keller RE, 2022, KNEE SURG SPORT TR A, V30, P1915, DOI 10.1007/s00167-021-06849-5; Kuo RYL, 2022, RADIOLOGY, V304, P50, DOI 10.1148/radiol.211785; Myers TG, 2020, J BONE JOINT SURG AM, V102, P830, DOI 10.2106/JBJS.19.01128; Nicholls M, 2021, KNEE SURG SPORT TR A, V29, P2701, DOI 10.1007/s00167-021-06538-3; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shah RM, 2022, CURR REV MUSCULOSKE, V15, P121, DOI 10.1007/s12178-022-09738-7; Spalding T, 2020, CLIN SPORT MED, V39, P37, DOI 10.1016/j.csm.2019.08.012; Spang RC, 2018, BMJ OPEN SPORT EXERC, V4, DOI 10.1136/bmjsem-2016-000212; Suchikova Y, 2023, NATURE, V614, P413, DOI 10.1038/d41586-023-00381-x; Tay A., AI writing tools promise faster manuscripts for researchers; Wells ME, 2021, SPORTS MED ARTHROSC, V29, P154, DOI 10.1097/JSA.0000000000000311; Wiley TJ, 2020, CLIN SPORT MED, V39, P185, DOI 10.1016/j.csm.2019.08.002; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712; Zellner J, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/537686	29	0	0	8	8	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2024	8								e52164	10.2196/52164	http://dx.doi.org/10.2196/52164			7	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	IS3L6	38363631	gold, Green Published			2024-07-03	WOS:001168280900005
J	Li, YM; Zhao, J; Li, MQ; Dang, YF; Yu, EV; Li, JF; Sun, ZN; Hussein, U; Wen, JG; Abdelhameed, AM; Mai, JH; Li, SD; Yu, Y; Hu, XY; Yang, DW; Feng, JN; Li, ZH; He, JP; Tao, W; Duan, TH; Lou, YY; Li, F; Tao, C				Li, Yiming; Zhao, Jeff; Li, Manqi; Dang, Yifang; Yu, Evan; Li, Jianfu; Sun, Zenan; Hussein, Usama; Wen, Jianguo; Abdelhameed, Ahmed M.; Mai, Junhua; Li, Shenduo; Yu, Yue; Hu, Xinyue; Yang, Daowei; Feng, Jingna; Li, Zehan; He, Jianping; Tao, Wei; Duan, Tiehang; Lou, Yanyan; Li, Fang; Tao, Cui			RefAI: a GPT-powered retrieval-augmented generative tool for biomedical literature recommendation and summarization	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						generative pretrained transformer; retrieval-augmented generation; large language model; literature recommendation; text summarization		Objectives: Precise literature recommendation and summarization are crucial for biomedical professionals. While the latest iteration of generative pretrained transformer (GPT) incorporates 2 distinct modes-real-time search and pretrained model utilization-it encounters challenges in dealing with these tasks. Specifically, the real-time search can pinpoint some relevant articles but occasionally provides fabricated papers, whereas the pretrained model excels in generating well-structured summaries but struggles to cite specific sources. In response, this study introduces RefAI, an innovative retrieval-augmented generative tool designed to synergize the strengths of large language models (LLMs) while overcoming their limitations. Materials and Methods: RefAI utilized PubMed for systematic literature retrieval, employed a novel multivariable algorithm for article recommendation, and leveraged GPT-4 turbo for summarization. Ten queries under 2 prevalent topics ("cancer immunotherapy and target therapy" and "LLMs in medicine") were chosen as use cases and 3 established counterparts (ChatGPT-4, ScholarAI, and Gemini) as our baselines. The evaluation was conducted by 10 domain experts through standard statistical analyses for performance comparison. Results: The overall performance of RefAI surpassed that of the baselines across 5 evaluated dimensions-relevance and quality for literature recommendation, accuracy, comprehensiveness, and reference integration for summarization, with the majority exhibiting statistically significant improvements (P-values <.05). Discussion: RefAI demonstrated substantial improvements in literature recommendation and summarization over existing tools, addressing issues like fabricated papers, metadata inaccuracies, restricted recommendations, and poor reference integration. Conclusion: By augmenting LLM with external resources and a novel ranking algorithm, RefAI is uniquely capable of recommending high-quality literature and generating well-structured summaries, holding the potential to meet the critical needs of biomedical professionals in navigating and synthesizing vast amounts of scientific literature.	[Li, Yiming; Li, Manqi; Dang, Yifang; Yu, Evan; Sun, Zenan; Wen, Jianguo; Li, Zehan; He, Jianping] Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX 77030 USA; [Zhao, Jeff] Univ Texas Austin, Coll Nat Sci, Dept Comp Sci, Austin, TX 78712 USA; [Li, Manqi; Tao, Wei] Univ Texas Hlth Sci Ctr Houston, Sch Publ Hlth, Dept Biostat & Data Sci, Houston, TX 77030 USA; [Li, Jianfu; Abdelhameed, Ahmed M.; Hu, Xinyue; Feng, Jingna; Duan, Tiehang; Li, Fang; Tao, Cui] Mayo Clin, Dept Artificial Intelligence & Informat, 4500 San Pablo Rd, Jacksonville, FL 32224 USA; [Hussein, Usama] Univ Texas MD Anderson Canc Ctr, Dept Lymphoma & Myeloma, Houston, TX 77030 USA; [Mai, Junhua] Houston Methodist Acad Inst, Dept Nanomed, Houston, TX 77030 USA; [Li, Shenduo; Lou, Yanyan] Mayo Clin, Dept Med, Div Hematol & Oncol, Jacksonville, FL 32224 USA; [Yu, Yue] Mayo Clin, Dept Quantitat Hlth Sci, Rochester, MN 55905 USA; [Yang, Daowei] Univ Texas MD Anderson Canc Ctr, Dept Translat Mol Pathol, Houston, TX 77030 USA	University of Texas System; University of Texas Health Science Center Houston; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Health Science Center Houston; University of Texas School Public Health; Mayo Clinic; University of Texas System; UTMD Anderson Cancer Center; Mayo Clinic; Mayo Clinic; University of Texas System; UTMD Anderson Cancer Center	Li, F; Tao, C (corresponding author), Mayo Clin, Dept Artificial Intelligence & Informat, 4500 San Pablo Rd, Jacksonville, FL 32224 USA.	li.fang@mayo.edu; tao.cui@mayo.edu		Dang, Yifang/0000-0002-4014-2957	National Institute of Allergy and Infectious Diseases of the National Institutes of Health [R01AI130460, U24AI171008]; American Heart Association [19GPSGC35180031]; Cancer Prevention and Research Institute of Texas [RP220244]	National Institute of Allergy and Infectious Diseases of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID)); American Heart Association(American Heart Association); Cancer Prevention and Research Institute of Texas(Cancer Prevention & Research Institute of Texas)	This work was supported by the National Institute of Allergy and Infectious Diseases of the National Institutes of Health grant numbers R01AI130460 and U24AI171008, the American Heart Association grant number 19GPSGC35180031, and Cancer Prevention and Research Institute of Texas award RP220244.	About, PubMed; Aiumtrakul N, 2023, J PERS MED, V13, DOI 10.3390/jpm13101457; Alberts B, 2014, P NATL ACAD SCI USA, V111, P5773, DOI 10.1073/pnas.1404402111; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2022, sentence-transformers (Sentence Transformers); [Anonymous], 2023, Paper Digest; [Anonymous], 2023, The Best ChatGPT Plugins for Research; [Anonymous], 2023, GPT-4 architecture, datasets, costs and more leaked; Basiri M, 2023, PERS MED, V20, P413, DOI 10.2217/pme-2023-0083; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; clarivate, about us; Day T, 2023, PROF GEOGR, V75, P1024, DOI 10.1080/00330124.2023.2190373; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Ge J., 2023, medRxiv; Gonzalez-Marquez R., 2023, bioRxiv; gptstore, ChatGPT Plugin-ScholarAI; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Jensen LJ, 2006, NAT REV GENET, V7, P119, DOI 10.1038/nrg1768; Jin Q, 2023, J AM SOC NEPHROL, V34, P1302, DOI 10.1681/ASN.0000000000000166; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Leite DFB, 2019, CLINICS, V74, DOI 10.6061/clinics/2019/e1403; Lesterhuis WJ, 2011, NAT REV DRUG DISCOV, V10, P591, DOI 10.1038/nrd3500; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li YM, 2024, Arxiv, DOI [arXiv:2404.05415, 10.48550/arXiv.2404.05415, DOI 10.48550/ARXIV.2404.05415]; Li YM, 2024, PLOS ONE, V19, DOI 10.1371/journal.pone.0300919; Li YM, 2024, J BIOMED INFORM, V152, DOI 10.1016/j.jbi.2024.104621; Liu YX, 2024, BBA-REV CANCER, V1879, DOI 10.1016/j.bbcan.2023.189068; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Milian RD, 2023, MAYO CLIN PROC, V98, P1444, DOI 10.1016/j.mayocp.2023.07.009; Nazir Anam, 2023, Meta Radiol, V1, DOI 10.1016/j.metrad.2023.100022; Peng C, 2024, J BIOMED INFORM, V153, DOI 10.1016/j.jbi.2024.104630; Raghani NR, 2024, MED ONCOL, V41, DOI 10.1007/s12032-023-02280-7; Randolph J.J., 2009, Practical Assessment, Research, and Evaluation, V14, P13, DOI DOI 10.7275/B0AZ-8T74; ScholarAI, ABOUT US; SerpApi, Google Search Engine Results API; Sharun K, 2023, ANN MED SURG, V85, P5275, DOI 10.1097/MS9.0000000000001228; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Unlu O., 2024, medRxiv; Waisberg E, 2024, EYE, V38, P642, DOI 10.1038/s41433-023-02760-0; Wecker E., 2024, Welch medical library guides: expert searching: PubMed search tips; Weisstein E.W., Normal Distribution; Westland JC, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271949; Zakka C., 2024, NEJM AI, V1, pAIoa2300068	43	0	0	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 JUN 10	2024										10.1093/jamia/ocae129	http://dx.doi.org/10.1093/jamia/ocae129		JUN 2024	10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	TS8B3	38857454				2024-07-03	WOS:001243328800001
J	Berce, C				Berce, Cristian			Artificial intelligence generated clinical score sheets: looking at the two faces of Janus	LABORATORY ANIMAL RESEARCH			English	Article						Score sheets; Preclinical; LLM; Artificial intelligence; In vivo	COLITIS; MODEL	In vivo experiments are increasingly using clinical score sheets to ensure minimal distress to the animals. A score sheet is a document that includes a list of specific symptoms, behaviours and intervention guidelines, all balanced to for an objective clinical assessment of experimental animals. Artificial Intelligence (AI) technologies are increasingly being applied in the field of preclinical research, not only in analysis but also in documentation processes, reflecting a significant shift towards more technologically advanced research methodologies. The present study explores the application of Large Language Models (LLM) in generating score sheets for an animal welfare assessment in a preclinical research setting. Focusing on a mouse model of inflammatory bowel disease, the study evaluates the performance of three LLM - ChatGPT-4, ChatGPT-3.5, and Google Bard - in creating clinical score sheets based on specified criteria such as weight loss, stool consistency, and visible fecal blood. Key parameters evaluated include the consistency of structure, accuracy in representing severity levels, and appropriateness of intervention thresholds. The findings reveal a duality in LLM-generated score sheets: while some LLM consistently structure their outputs effectively, all models exhibit notable variations in assigning numerical values to symptoms and defining intervention thresholds accurately. This emphasizes the dual nature of AI performance in this field-its potential to create useful foundational drafts and the critical need for professional review to ensure precision and reliability. The results highlight the significance of balancing AI-generated tools with expert oversight in preclinical research.	[Berce, Cristian] Fed Food Safety & Vet Off, Anim Hlth & Welf Div, Bern, Switzerland		Berce, C (corresponding author), Fed Food Safety & Vet Off, Anim Hlth & Welf Div, Bern, Switzerland.	cristian.berce@blv.admin.ch		Berce, Cristian/0000-0002-5073-8172	Federal Food Safety and Veterinary Office in Switzerland; Google Bard	Federal Food Safety and Veterinary Office in Switzerland; Google Bard(Google Incorporated)	The author would like to acknowledge and to thank Dr. Otto Maissen and Dr. Martin Reist from the Federal Food Safety and Veterinary Office in Switzerland for their invaluable support and insightful feedback on this paper. Also, while not real individuals in the traditional sense, the author also wishes to express gratitude to DEEPL, ChatGPT-4 and Google Bard, three artificial intelligence models. Their assistance in proofreading and refining this paper was invaluable and greatly appreciated and their contributions underline the growing significance of AI tools in academic research.	Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bugnon P, 2016, LAB ANIM-UK, V50, P414, DOI 10.1177/0023677216671552; Eichele DD, 2017, WORLD J GASTROENTERO, V23, P6016, DOI 10.3748/wjg.v23.i33.6016; Esplugas M, 2023, J HAND SURG-EUR VOL, V48, P819, DOI 10.1177/17531934231185746; Gancarcikova S, 2020, CELLS-BASEL, V9, DOI 10.3390/cells9122571; Häger C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143824; Kittichai V, 2023, JOVE-J VIS EXP, DOI 10.3791/65557; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Kunitsu Y, 2023, JMIR MED EDUC, V9, DOI 10.2196/48452; Lambert J, 2023, COMPUT SCH, DOI 10.1080/07380569.2023.2256710; Li D, 2022, QUANT IMAG MED SURG, V12, P3193, DOI 10.21037/qims-21-1062; Liu Y., 2023, MetaRadiology, V1; Melgar S, 2005, AM J PHYSIOL-GASTR L, V288, pG1328, DOI 10.1152/ajpgi.00467.2004; Pushpanathan K, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.108163; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04473-y; Schueller SM, 2023, J CONSULT CLIN PSYCH, V91, P559, DOI 10.1037/ccp0000848; Smith D, 2018, LAB ANIM-UK, V52, P5, DOI 10.1177/0023677217744587; Ullman-Culleré MH, 1999, LAB ANIM SCI, V49, P319; van Vlissingen JMF, 2015, LAB ANIM-UK, V49, P267, DOI 10.1177/0023677215584249; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]	21	0	0	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	1738-6055	2233-7660		LAB ANIM RES	Lab. Anim. Res.	MAY 16	2024	40	1							21	10.1186/s42826-024-00206-6	http://dx.doi.org/10.1186/s42826-024-00206-6			5	Medicine, Research & Experimental; Veterinary Sciences	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine; Veterinary Sciences	QV5J9	38750604	gold			2024-07-03	WOS:001223655000001
J	Wong, GKW; Li, SYK				Wong, Gary K. W.; Li, Simon Y. K.			An Exploratory Study of Helping Undergraduate Students Solve Literature Review Problems Using Litstudy and NLP	EDUCATION SCIENCES			English	Review						literature review; topic modeling; NLP; litstudy; AI; LLM	RECOMMENDATION SYSTEM	(1) Many undergraduate students struggle to produce a good literature review in their dissertations, as they are not experienced, do not have sufficient time, and do not have the required skills to articulate information. (2) Subsequently, we deployed Litstudy and NLP tools and developed a recommendation system to analyze articles in an academic database to help the students produce literature reviews. (3) The recommendation system successfully performed three levels of analysis. The elementary-level analysis provided demographic statistical analysis to the students, helping them understand the background information of the selected articles they would review. The intermediate-level analysis provided visualization of citations in network graphs for the students to understand the relationships of the articles' authors, regions, and institutes so that the flow of ideas, development, and similarity of the selected articles can be better analyzed. The advanced level of analysis provided topic modeling functions for the students to understand the high-level themes of the selected articles to improve productivity as they read through them and simultaneously boost their creativity. (4) The three levels of analysis successfully analyzed the selected articles to provide innovative results and triggered the students to handle literature reviews in a new way. Further enhancement opportunities were identified in integrating the NLP technologies with large language models to facilitate the generation of research ideas/insights. This would be an exciting opportunity to have AI/NLP integrated to help the students with their research.	[Wong, Gary K. W.; Li, Simon Y. K.] Univ Hong Kong, Fac Educ, Hong Kong 999077, Peoples R China	University of Hong Kong	Li, SYK (corresponding author), Univ Hong Kong, Fac Educ, Hong Kong 999077, Peoples R China.	wongkwg@hku.hk; simonykli2004@gmail.com	Wong, Gary/AAZ-9504-2021	Wong, Gary/0000-0003-1269-0734	RGC/URC through the University of Hong Kong [101002152]	RGC/URC through the University of Hong Kong	This project is funded and supported by the Teaching Development Grant (Ref: 101002152) from the RGC/URC through the University of Hong Kong.	Alghamdi R, 2015, INT J ADV COMPUT SC, V6, P147; American Psychological Association, 2010, PUBL MAN AM PSYCH AS; Anaya L., 2011, University North Texas, V(Vol. 226); Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Batul J.M., 2001, Jumping Connections: A Graph-Theoretic Model for Recommender Systems; Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Castelo N., 2019, Blurring the line between human and machine: Marketing artificial intelligence (doctoral dissertation); Cooper H. M., 1988, Knowledge in Society, V1, P104, DOI [10.1007/bf03177550, DOI 10.1007/BF03177550]; Cui Z., 2022, arXiv; Dale R, 2020, NAT LANG ENG, V26, P481, DOI 10.1017/S135132492000025X; Denney AS, 2013, J CRIM JUSTICE EDUC, V24, P218, DOI 10.1080/10511253.2012.730617; Evangelopoulos NE, 2013, WIRES COGN SCI, V4, P683, DOI 10.1002/wcs.1254; Ferrari R., 2015, "Rev. Gen. Psychol., V24, P230, DOI [10.1179/2047480615Z.000000000329, DOI 10.1179/2047480615Z.000000000329, DOI 10.1037/1089-2680.1.3.311]; Finch WH., 2018, TRANSL ISS PSYCH SCI, V4, P403, DOI DOI 10.1037/TPS0000173; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Foster A., 2023, P IPHS 484 SEN SEM G; Gall M.D., 2006, Educational research: An introduction, V8th; Crespo RG, 2011, COMPUT HUM BEHAV, V27, P1445, DOI 10.1016/j.chb.2010.09.012; Greshake K, 2023, Arxiv, DOI arXiv:2302.12173; Hanafi M., 2022, P 4 WORKSH DAT SCI H, P43; Heldens S, 2022, SOFTWAREX, V20, DOI 10.1016/j.softx.2022.101207; Huang J., 2022, arXiv; Jelodar H, 2019, MULTIMED TOOLS APPL, V78, P15169, DOI 10.1007/s11042-018-6894-4; Jiang WX, 2023, Arxiv, DOI arXiv:2303.02552; Kang Y, 2020, J MANAG ANAL, V7, P139, DOI 10.1080/23270012.2020.1756939; Li YX, 2018, Arxiv, DOI arXiv:1701.07274; Likhitha S., 2019, International Journal of Computer Applications, V178, P1, DOI [10.5120/ijca2019919265, DOI 10.5120/IJCA2019919265]; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Liu P, 2023, Arxiv, DOI [arXiv:2302.03735, 10.48550/arXiv.2302.03735, DOI 10.48550/ARXIV.2302.03735]; Shahsavar Z, 2020, COGENT EDUC, V7, DOI 10.1080/2331186X.2020.1784620; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Srinivasa-Desikan B., 2018, Natural Language Processing and Computational Linguistics: A practical guide to text analysis with Python, Gensim, spaCy, and Keras; Weng SS, 2008, EXPERT SYST APPL, V34, P1857, DOI 10.1016/j.eswa.2007.02.023; Wu XJ, 2022, FUTURE GENER COMP SY, V135, P364, DOI 10.1016/j.future.2022.05.014; Yang C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102543; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420; Zhang TY, 2023, Arxiv, DOI arXiv:2302.13048; Zhang XF, 2020, INFORM SCIENCES, V519, P306, DOI 10.1016/j.ins.2020.01.044; Zhang Y., 2021, P NEURIPS 2021 WORKS	40	0	0	9	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7102		EDUC SCI	Educ. Sci.	OCT	2023	13	10							987	10.3390/educsci13100987	http://dx.doi.org/10.3390/educsci13100987			19	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	W8QN1		gold			2024-07-03	WOS:001094219600001
J	Veres, C; Sampson, J				Veres, Csaba; Sampson, Jennifer			Self supervised learning and the poverty of the stimulus	DATA & KNOWLEDGE ENGINEERING			English	Article						Classification; Learnability; Text mining; Machine Learning; NLP; Language	NATURAL-LANGUAGE	Diathesis alternations are the possible expressions of the arguments of verbs in different, systematically related subcategorization frames. Semantically similar verbs such as spill and spray can behave differently with respect to the alternations they can participate in. For example one can "spill/spray water on the plant", but while one can "spray the plant with water", it is odd to say "spill the plant with water". "Spray"is a verb which can alternate between syntactic frames while "spill"is not alternating. How human speakers learn the difference between such verbs is not clearly understood, because the primary linguistic data (PLD) they receive does not appear sufficient to infer the knowledge required for adult competence. More generally the poverty of the stimulus (POS) hypothesis states that the PLD is not sufficient for a learner to infer full adult competence of language. That is, learning relies on prior constraints introduced by the language faculty. We tested state-of-the-art machine learning models trained by self supervision, and found some evidence that they could in fact learn the correct pattern of acceptability judgement in the locative alternation. However, we argued that this was partially a result of fine-tuning which introduced negative evidence into the learning data, which facilitated shortcut learning. Large language models (LLMs) cannot learn some linguistic facts from normal language data, but they can compensate to some extent by learning spurious correlated features when negative feedback is introduced during the training cycle.	[Veres, Csaba] Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway; [Sampson, Jennifer] Equinor UK Ltd, London, England	University of Bergen; Equinor	Veres, C (corresponding author), Univ Bergen, Dept Informat Sci & Media Studies, Bergen, Norway.	csaba.veres@uib.no						Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292; [Anonymous], 2007, The Stuff of Thought: Language as a Window into Human Nature; [Anonymous], 1989, Learnability and cognition: The acquisition of argument structure; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; BAKER CL, 1979, LINGUIST INQ, V10, P533; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Berwick RC, 2011, COGNITIVE SCI, V35, P1207, DOI 10.1111/j.1551-6709.2011.01189.x; Bley-Vroman R., 2001, STUD SECOND LANG ACQ, V23, P207; Braine M., 1995, NAMES THINGS, P352; Brooks PJ, 1999, LANGUAGE, V75, P720, DOI 10.2307/417731; Bross Fabian, Acceptability Ratings in Linguistics: A Practical Guide to Grammaticality Judgments, Data Collection, and Statistical Analysis; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; CHOI S, 1991, COGNITION, V41, P83, DOI 10.1016/0010-0277(91)90033-Z; Chomsky N., 1965, Aspects of the Theory of Syntax; Chomsky Noam, 1980, Columbia Classics in Philosophy; Cowie F., 2017, STANFORD ENCY PHILOS, V2017; Devlin J., 2018, BERT PRE TRAINING DE; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Grechishnikova D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79682-4; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Jackendoff R., 1983, Semantics and Cognition. Semantics and Cognition, P283; Jackendoff Ray, 1990, Semantic structures / ray jackendoff, P322; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kann Katharina, 2019, P SOC COMPUTATION LI, P287, DOI [DOI 10.7275/Q5JS-4Y86, 10.7275/q5js-4y86]; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Levin Beth, 1993, ENGLISH VERB CLASSES; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; Mitchell M, 2023, SCIENCE, V381, DOI 10.1126/science.adj5957; Perfors A, 2010, J CHILD LANG, V37, P607, DOI 10.1017/S0305000910000012; PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061; Quinn T, 2018, TLS-TIMES LIT SUPPL, P31; Ruis L, 2023, Arxiv, DOI [arXiv:2210.14986, DOI 10.48550/ARXIV.2210.14986]; Sahlgren M, 2008, ITAL J LINGUIST, V20, P33; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Scholkopf B., 2021, arXiv, DOI [10.48550/ARXIV.2102.11107, DOI 10.48550/ARXIV.2102.11107]; Vaswani A, 2017, ADV NEUR IN, V30; Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505; Veres C, 2019, LECT NOTES ARTIF INT, V11919, P369, DOI 10.1007/978-3-030-35288-2_30; Wang A., 2019, INT C LEARNING REPRE; Wang A, 2019, ADV NEUR IN, V32; Wang W, 2019, Arxiv, DOI arXiv:1908.04577; Warstadt Alex, 2018, Neural network acceptability judgments; Wikipedia contributors, 2023, Instrumental case-Wikipedia, the free encyclopedia; Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237	48	0	0	1	2	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0169-023X	1872-6933		DATA KNOWL ENG	Data Knowl. Eng.	SEP	2023	147								102208	10.1016/j.datak.2023.102208	http://dx.doi.org/10.1016/j.datak.2023.102208		AUG 2023	17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Q7YO7		hybrid			2024-07-03	WOS:001059645300001
J	Chervenak, J; Lieman, H; Blanco-Breindel, M; Jindal, S				Chervenak, Joseph; Lieman, Harry; Blanco-Breindel, Miranda; Jindal, Sangita			The promise and peril of using a large language model to obtain clinical information: ChatGPT performs strongly as a fertility counseling tool with limitations	FERTILITY AND STERILITY			English	Article						Artificial intelligence; natural language processing; fertility knowledge; counseling; online	UNITED-STATES; KNOWLEDGE	Objective: To compare the responses of the large language model-based "ChatGPT"to reputable sources when given fertility-related clinical prompts. Design: The "Feb 13"version of ChatGPT by OpenAI was tested against established sources relating to patient-oriented clinical information: 17 "frequently asked questions (FAQs)"about infertility on the Centers for Disease Control (CDC) Website, 2 validated fertility knowledge surveys, the Cardiff Fertility Knowledge Scale and the Fertility and Infertility Treatment Knowledge Score, as well as the American Society for Reproductive Medicine committee opinion "optimizing natural fertility."Setting: Academic medical center. Patient(s): Online AI Chatbot. Intervention(s): Frequently asked questions, survey questions and rephrased summary statements were entered as prompts in the chatbot over a 1-week period in February 2023. Main Outcome Measure(s): For FAQs from CDC: words/response, sentiment analysis polarity and objectivity, total factual statements, rate of statements that were incorrect, referenced a source, or noted the value of consulting providers. For fertility knowledge surveys: Percentile according to published population data. For Committee Opinion: Whether response to conclusions rephrased as questions identified missing facts. Result(s): When administered the CDC's 17 infertility FAQ's, ChatGPT produced responses of similar length (207.8 ChatGPT vs. 181.0 CDC words/response), factual content (8.65 factual statements/response vs. 10.41), sentiment polarity (mean 0.11 vs. 0.11 on a scale of-1 (negative) to 1 (positive)), and subjectivity (mean 0.42 vs. 0.35 on a scale of 0 (objective) to 1 (subjective)). In total, 9 (6.12%) of 147 ChatGPT factual statements were categorized as incorrect, and only 1 (0.68%) statement cited a reference. ChatGPT would have been at the 87th percentile of Bunting's 2013 international cohort for the Cardiff Fertility Knowledge Scale and at the 95th percentile on the basis of Kudesia's 2017 cohort for the Fertility and Infertility Treatment Knowledge Score. ChatGPT reproduced the missing facts for all 7 summary statements from "optimizing natural fertility."Conclusion(s): A February 2023 version of "ChatGPT"demonstrates the ability of generative artificial intelligence to produce relevant, meaningful responses to fertility-related clinical queries comparable to established sources. Although performance may improve with medical domain-specific training, limitations such as the inability to reliably cite sources and the unpredictable possibility of fabricated information may limit its clinical use. (Fertil Sterile 2023;120:575-83. (c) 2023 by American Society for Reproductive Medicine.)	[Chervenak, Joseph; Lieman, Harry; Blanco-Breindel, Miranda; Jindal, Sangita] Montefiores Inst Reprod Med & Hlth, Albert Einstein Coll Med, 141 S Central Ave, Hartsdale, NY 10530 USA	Yeshiva University	Chervenak, J (corresponding author), Montefiores Inst Reprod Med & Hlth, Albert Einstein Coll Med, 141 S Central Ave, Hartsdale, NY 10530 USA.	joseph.chervenak@gmail.com		Chervenak, Joseph/0000-0002-2567-0030				Agrawal A., 2022, Power and prediction: The disruptive economics of artificial intelligence; [Anonymous], 2012, The New York Times; asrm, ASRM Committee Opinion; Babel A, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.669869; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bishop L, 2023, SSRN Electron J; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Breckons M, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.961; Bunting L, 2013, HUM REPROD, V28, P385, DOI 10.1093/humrep/des402; CDC, INF FAQS; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Denecke K, 2023, J BIOMED INFORM, V140, DOI 10.1016/j.jbi.2023.104336; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; fortune, Tech leaders warn that ChatGPT bots can make mistakes; Frosio G, 2023, SSRN Electron J; Gao QY, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/3440778; Geller T, 2008, IEEE COMPUT GRAPH, V28, P11, DOI 10.1109/MCG.2008.79; google, Fertility; google, Google AI updates: bard and new AI features in Search; Huang JYJ, 2005, FERTIL STERIL, V83, P538, DOI 10.1016/j.fertnstert.2004.08.036; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kong WW, 2021, J MED INTERNET RES, V23, DOI 10.2196/30409; Kortemeyer G, 2023, Could Artif-Intell Agent Pass Introductory Phys Course?; Kudesia R, 2017, FERTIL STERIL, V108, P711, DOI 10.1016/j.fertnstert.2017.07.1158; Kumar V, 2022, IETE TECH REV, V39, P953, DOI 10.1080/02564602.2021.1936224; Liu ZX, 2022, ANN TRANSL MED, V10, DOI 10.21037/atm-22-1613; Loria S, 2014, TextBlob Simpl. Text Process, V3, P2014; mashable, ChatGPT is the fastest growing app of all time; mckinsey, What is ChatGPT, DALL-E, and generative AI?; Medenilla A., 2023, PLoS Digital Health, V2; medium, ChatGPT & You: Language Generation's Uncanny Valley; Microsoft, Documentation: text sentiment analysis; nytimes, Microsoft's bing chatbot offers some puzzling and inaccurate responses; Open AI, Releases GPT-4 AI that it claims is state of the art; Open AI, US; PALLEN M, 1995, BRIT MED J, V311, P1422, DOI 10.1136/bmj.311.7017.1422; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Penzias A, 2022, FERTIL STERIL, V117, P53, DOI 10.1016/j.fertnstert.2021.10.007; pypi, TextBlob: simplified language processing; reuters, ChatGPT sets record for fastest-growing user base; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Schwartz LM, 2019, JAMA-J AM MED ASSOC, V321, P80, DOI 10.1001/jama.2018.19320; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Stokel-Walker Chris, 2022, Nature; Sun YL, 2019, J MED INTERNET RES, V21, DOI 10.2196/12522; Swain J, 2020, J ASSIST REPROD GEN, V37, P2817, DOI 10.1007/s10815-020-01950-z; Tan SSL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5729; theguardian, ChatGPT can tell jokes, even write articles. But Only Humans Can Detect its Fluent Bullshit; Tingiris S, 2021, Exploring GPT-3: an unofficial first look at the general-purpose language processing AP from OpenAI; UpToDate, About us; venturebeat, Got it AI creates truth checker for chat gpt hallucinations; Waudby-Smith IER, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198687; Zaninovic N, 2020, FERTIL STERIL, V114, P914, DOI 10.1016/j.fertnstert.2020.09.157	56	17	17	15	27	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0015-0282	1556-5653		FERTIL STERIL	Fertil. Steril.	SEP	2023	120	3	2				575	583		10.1016/j.fertnstert.2023.05.151	http://dx.doi.org/10.1016/j.fertnstert.2023.05.151		AUG 2023	9	Obstetrics & Gynecology; Reproductive Biology	Science Citation Index Expanded (SCI-EXPANDED)	Obstetrics & Gynecology; Reproductive Biology	W6WH2	37217092	hybrid			2024-07-03	WOS:001093006600001
J	Kuwahara, T; Hara, K; Mizuno, N; Haba, S; Okuno, N; Fukui, T; Urata, M; Yamamoto, Y				Kuwahara, Takamichi; Hara, Kazuo; Mizuno, Nobumasa; Haba, Shin; Okuno, Nozomi; Fukui, Toshitaka; Urata, Minako; Yamamoto, Yoshitaro			Current status of artificial intelligence analysis for the treatment of pancreaticobiliary diseases using endoscopic ultrasonography and endoscopic retrograde cholangiopancreatography	DEN OPEN			English	Review						artificial intelligence; deep learning; EUS; pancreas; ERCP	FINE-NEEDLE-ASPIRATION; NEURAL-NETWORK ANALYSIS; DIFFERENTIAL-DIAGNOSIS; CHRONIC-PANCREATITIS; INTERNATIONAL CONSENSUS; DIABETIC-RETINOPATHY; EUS IMAGES; VALIDATION; ACCURACY; CANCER	Pancreatic and biliary diseases encompass a range of conditions requiring accurate diagnosis for appropriate treatment strategies. This diagnosis relies heavily on imaging techniques like endoscopic ultrasonography and endoscopic retrograde cholangiopancreatography. Artificial intelligence (AI), including machine learning and deep learning, is becoming integral in medical imaging and diagnostics, such as the detection of colorectal polyps. AI shows great potential in diagnosing pancreatobiliary diseases. Unlike machine learning, which requires feature extraction and selection, deep learning can utilize images directly as input. Accurate evaluation of AI performance is a complex task due to varied terminologies, evaluation methods, and development stages. Essential aspects of AI evaluation involve defining the AI's purpose, choosing appropriate gold standards, deciding on the validation phase, and selecting reliable validation methods. AI, particularly deep learning, is increasingly employed in endoscopic ultrasonography and endoscopic retrograde cholangiopancreatography diagnostics, achieving high accuracy levels in detecting and classifying various pancreatobiliary diseases. The AI often performs better than doctors, even in tasks like differentiating benign from malignant pancreatic tumors, cysts, and subepithelial lesions, identifying gallbladder lesions, assessing endoscopic retrograde cholangiopancreatography difficulty, and evaluating the biliary strictures. The potential for AI in diagnosing pancreatobiliary diseases, especially where other modalities have limitations, is considerable. However, a crucial constraint is the need for extensive, high-quality annotated data for AI training. Future advances in AI, such as large language models, promise further applications in the medical field.	[Kuwahara, Takamichi; Hara, Kazuo; Mizuno, Nobumasa; Haba, Shin; Okuno, Nozomi; Fukui, Toshitaka; Urata, Minako; Yamamoto, Yoshitaro] Aichi Canc Ctr Hosp, Dept Gastroenterol, Nagoya, Aichi, Japan; [Kuwahara, Takamichi] Aichi Canc Ctr Hosp, Dept Gastroenterol, 1-1 Kanokoden, Chikusa ku, Nagoya, Aichi 4648681, Japan	Aichi Cancer Center; Aichi Cancer Center	Kuwahara, T (corresponding author), Aichi Canc Ctr Hosp, Dept Gastroenterol, 1-1 Kanokoden, Chikusa ku, Nagoya, Aichi 4648681, Japan.	kuwa_tak@aichi-cc.jp	Okuno, Nozomi/AHE-2009-2022	Okuno, Nozomi/0000-0001-6376-687X; Kuwahara, Takamichi/0000-0001-8348-8926	JSPS KAKENHI [21K15938]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	JSPS KAKENHI, Grant/Award Number:21K15938	Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547; Chen PT, 2021, J GASTROEN HEPATOL, V36, P286, DOI 10.1111/jgh.15380; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.1136/bmj.g7594, 10.1016/j.jclinepi.2014.11.010, 10.7326/M14-0697, 10.1002/bjs.9736, 10.1186/s12916-014-0241-z, 10.1038/bjc.2014.639, 10.7326/M14-0698, 10.1016/j.eururo.2014.11.025]; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018; COTTON PB, 1991, GASTROINTEST ENDOSC, V37, P383, DOI 10.1016/S0016-5107(91)70740-2; Das A, 2008, GASTROINTEST ENDOSC, V67, P861, DOI 10.1016/j.gie.2007.08.036; Fusaroli P, 2016, GASTROINTEST ENDOSC, V84, P587, DOI 10.1016/j.gie.2016.06.006; Gorris M, 2021, DIGEST ENDOSC, V33, P231, DOI 10.1111/den.13875; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Haba S, 2013, J GASTROENTEROL, V48, P973, DOI 10.1007/s00535-012-0695-8; Hirai K, 2022, GASTRIC CANCER, V25, P382, DOI 10.1007/s10120-021-01261-x; Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2; Hirooka Y, 2015, J MED ULTRASON, V42, P151, DOI 10.1007/s10396-014-0571-7; Horie Y, 2019, GASTROINTEST ENDOSC, V89, P25, DOI 10.1016/j.gie.2018.07.037; Huang L, 2023, ENDOSCOPY, V55, P4, DOI 10.1055/a-1850-6717; Ishikawa T, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020434; Jang SI, 2021, J GASTROEN HEPATOL, V36, P3548, DOI 10.1111/jgh.15673; Kim T, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87737-3; Kim YH, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103162; Kurita Y, 2020, DIGEST ENDOSC, V32, P399, DOI 10.1111/den.13497; Kurita Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43314-3; Kuwahara Takamichi, 2022, Nihon Shokakibyo Gakkai Zasshi, V119, P610, DOI 10.11405/nisshoshi.119.610; Kuwahara T, 2023, ENDOSCOPY, V55, P140, DOI 10.1055/a-1873-7920; Kuwahara T, 2021, DIGEST ENDOSC, V33, P298, DOI 10.1111/den.13880; Kuwahara T, 2020, J MED ULTRASON, V47, P413, DOI 10.1007/s10396-020-01026-6; Kuwahara T, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000045; Lambin P, 2012, EUR J CANCER, V48, P441, DOI 10.1016/j.ejca.2011.11.036; Lloyd RV., 2017, WHO CLASSIFICATION T; Machicado JD, 2021, GASTROINTEST ENDOSC, V94, P78, DOI 10.1016/j.gie.2020.12.054; Marya NB, 2021, GUT, V70, P1335, DOI 10.1136/gutjnl-2020-322821; Mayra N., 2023, GASTROINTEST ENDOSC, V97, P268; Minoda Y, 2020, J GASTROENTEROL, V55, P1119, DOI 10.1007/s00535-020-01725-4; Naito Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87748-0; Nguon LS, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061052; Norton ID, 2001, GASTROINTEST ENDOSC, V54, P625, DOI 10.1067/mge.2001.118644; Oh CK, 2021, J GASTROEN HEPATOL, V36, P3387, DOI 10.1111/jgh.15653; Okazaki K, 2017, PANCREATOLOGY, V17, P1, DOI 10.1016/j.pan.2016.12.003; Ozkan M, 2016, ENDOSC ULTRASOUND, V5, P101, DOI 10.4103/2303-9027.180473; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Saftoiu A, 2008, GASTROINTEST ENDOSC, V68, P1086, DOI 10.1016/j.gie.2008.04.031; Saftoiu A, 2015, GASTROINTEST ENDOSC, V82, P59, DOI 10.1016/j.gie.2014.11.040; Saftoiu A, 2012, CLIN GASTROENTEROL H, V10, P84, DOI 10.1016/j.cgh.2011.09.014; Seven G, 2022, DIGEST DIS, V40, P427, DOI 10.1159/000520032; Sugimoto Y, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28058-5; Tanaka H, 2022, J GASTROEN HEPATOL, V37, P841, DOI 10.1111/jgh.15780; Tanaka M, 2017, PANCREATOLOGY, V17, P738, DOI 10.1016/j.pan.2017.07.007; Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152; Tonozuka R, 2021, J HEPATO-BIL-PAN SCI, V28, P95, DOI 10.1002/jhbp.825; WHO Classification of Tumours Editorial Board, 2019, Digestive System Tumours (World Health Organization Classification of Tumours), V5; Wiersema MJ, 1997, GASTROENTEROLOGY, V112, P1087, DOI 10.1016/S0016-5085(97)70164-1; Yang XT, 2022, ENDOSCOPY, V54, P251, DOI 10.1055/a-1476-8931; Zhang BL, 2023, SURG ENDOSC, V37, P1649, DOI 10.1007/s00464-022-09597-w; Zhang J, 2020, GASTROINTEST ENDOSC, V92, P874, DOI 10.1016/j.gie.2020.04.071; Zhang MM, 2010, GASTROINTEST ENDOSC, V72, P978, DOI 10.1016/j.gie.2010.06.042; Zhu ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063820	57	3	3	8	54	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2692-4609			DEN OPEN	DEN Open	APR	2024	4	1							e267	10.1002/deo2.267	http://dx.doi.org/10.1002/deo2.267			10	Gastroenterology & Hepatology	Emerging Sources Citation Index (ESCI)	Gastroenterology & Hepatology	K8QV2	37397344	Green Published, gold			2024-07-03	WOS:001019036800001
J	Xiang, BM; Shao, YN				Xiang, Bangmeng; Shao, Yunna			SUMLLAMA: Efficient Contrastive Representations and Fine-Tuned Adapters for Bug Report Summarization	IEEE ACCESS			English	Article						Computer bugs; Task analysis; Training; Codes; Semantics; Self-supervised learning; Vectors; Software maintenance; Bug report summarization; efficient fine-tuning; software maintenance; contrastive representation		In software maintenance, concise summaries of bug reports are crucial, significantly enhancing developer efficiency and ultimately improving software quality and user experience. Large language models (LLMs) have become the standard method for bug report summarization due to their powerful representation capabilities. However, LLM-based approaches face two primary challenges: accurately modeling the contextual relationships between various components within a bug report and the risk of overfitting when fine-tuning LLMs on datasets of limited size. To address these challenges, we propose a novel approach, SumLLaMA, which leverages contrastive learning pre-training and parameter-efficient fine-tuning. Contrastive learning pre-training is employed to construct contextual relations between components in a single bug report, enabling SumLLaMA to learn sequence-level representations. For parameter-efficient fine-tuning, we fine-tune a smaller adapter instead of the entire LLM, reducing the number of parameters trained to about 1/1500 of the original model, effectively mitigating the risk of overfitting. To evaluate the effectiveness of SumLLaMA, we compare it against five baseline models, including a state-of-the-art model, on a publicly available dataset. The experimental results show that SumLLaMA outperforms all baselines by up to 26.66, 17.10, and 24.01 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, respectively, achieving a state-of-the-art result for automated bug report summarization.	[Xiang, Bangmeng; Shao, Yunna] Zhejiang Coll Secur Technol, Wenzhou 325000, Zhejiang, Peoples R China		Shao, YN (corresponding author), Zhejiang Coll Secur Technol, Wenzhou 325000, Zhejiang, Peoples R China.	shaoyunna2024@163.com			Wenzhou Municipal Science and Technology Plan Project	Wenzhou Municipal Science and Technology Plan Project	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Akleman E., 2020, Computer, V53, P1, DOI [10.1109/MC.2020.3004171, DOI 10.1109/MC.2020.3004171]; Arya D, 2019, PROC INT CONF SOFTW, P454, DOI 10.1109/ICSE.2019.00058; Bai JZ, 2023, Arxiv, DOI [arXiv:2309.16609, 10.48550/arXiv.2309.16609, DOI 10.48550/ARXIV.2309.16609]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen X., 2018, P ADV NEUR INF PROC, V31, P11; Chen ZM, 2023, Arxiv, DOI arXiv:2309.14846; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fang S, 2023, PROC INT CONF SOFTW, P602, DOI 10.1109/ICSE48619.2023.00060; Fang S, 2022, J SYST SOFTWARE, V185, DOI 10.1016/j.jss.2021.111160; Fang S, 2021, IEEE T RELIAB, V70, P563, DOI 10.1109/TR.2021.3074412; Fang S, 2021, INFORM SOFTWARE TECH, V134, DOI 10.1016/j.infsof.2021.106542; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P933, DOI 10.1145/3180155.3180167; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; Jiang H, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-014-0372-y; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Li XC, 2018, INT C PROGRAM COMPRE, P144, DOI 10.1145/3196321.3196326; Li Y, 2023, IEEE T SOFTWARE ENG, V49, P4639, DOI 10.1109/TSE.2023.3308952; Liu HR, 2020, INT C PROGRAM COMPRE, P94, DOI 10.1145/3387904.3389272; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lotufo R, 2015, EMPIR SOFTW ENG, V20, P516, DOI 10.1007/s10664-014-9311-2; Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166; Mani S., 2012, P ACM SIGSOFT 20 INT, P1, DOI DOI 10.1145/2393596.2393607; Mei J., 2010, P 16 ACM SIGKDD INT, P1009, DOI [DOI 10.1145/1835804.1835931)(2010, DOI 10.1145/1835804.1835931]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006; Rastkar S, 2014, IEEE T SOFTWARE ENG, V40, P366, DOI 10.1109/TSE.2013.2297712; Roziere B, 2024, Arxiv, DOI arXiv:2308.12950; Shao B., 2024, IEEE Access, V12, P37653; Silva A, 2024, Arxiv, DOI arXiv:2312.15698; Su JL, 2024, NEUROCOMPUTING, V568, DOI 10.1016/j.neucom.2023.127063; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yuan DW, 2023, IEEE T RELIAB, V72, P511, DOI 10.1109/TR.2022.3176922; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253; Zhu X., 2007, P HUM LANG TECHN C N, P97	44	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						78562	78571		10.1109/ACCESS.2024.3397326	http://dx.doi.org/10.1109/ACCESS.2024.3397326			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	TR2E2					2024-07-03	WOS:001242913100001
J	Mao, TZ; Yoshie, O; Fu, JL; Mao, WX				Mao, Tiezheng; Yoshie, Osamu; Fu, Jialing; Mao, Weixin			Seeing both sides: context-aware heterogeneous graph matching networks for extracting-related arguments	NEURAL COMPUTING & APPLICATIONS			English	Article						Natural language process; Argument mining; Argument pair extraction; Graph matching networks; Heterogeneous graph neural networks		Our research focuses on extracting exchanged views from dialogical documents through argument pair extraction (APE). The objective of this process is to facilitate comprehension of complex argumentative discourse by finding the related arguments. The APE comprises two stages: argument mining and argument matching. Researchers typically employ sequence labeling models for mining arguments and text matching models to calculate the relationships between them, thereby generating argument pairs. However, these approaches fail to capture long-distance contextual information and struggle to fully comprehend the complex structure of arguments. In our work, we propose the context-aware heterogeneous graph matching (HGMN) model for the APE task. First, we design a graph schema specifically tailored to argumentative texts, along with a heterogeneous graph attention network that effectively captures context information and structural information of arguments. Moreover, the text matching between arguments is converted into a graph matching paradigm and a multi-granularity graph matching model is proposed to handle the intricate relationships between arguments at various levels of granularity. In this way, the semantics of argument are modeled structurally and thus capture the complicated correlations between arguments. Extensive experiments are conducted to evaluate the HGMN model, including comparisons with existing methods and the GPT series of large language models (LLM). The results demonstrate that HGMN outperforms the state-of-the-art method.	[Mao, Tiezheng; Yoshie, Osamu; Mao, Weixin] Waseda Univ, Grad Sch Informat Prod & Syst, Fukuoka, Japan; [Fu, Jialing] Guangdong Univ Finance & Econ, Guangzhou, Guangdong, Peoples R China	Waseda University; Guangdong University of Finance & Economics	Yoshie, O (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, Fukuoka, Japan.	yoshie@waseda.jp		Yoshie, Osamu/0000-0002-4192-554X				Afantenos S, 2018, ARGUM COMPUT; [Anonymous], 2014, P 2014 C EMPIRICAL M; Arora Sahiba, 2022, ARXIV; Bao J, 2021, PROC EMNLP; Bao JZ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P29; Beltagy I., 2020, arXiv; BommaritoII M, 2022, ARXIV; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S., 2023, arXiv; Chakrabarty T, 2019, PROC EMNLP; Chen Danqi, 2014, EMNLP, P740; Chen L, 2020, P ACL; Chen X., 2023, arXiv; Cheng L, 2021, P ACL; Cheng L, 2022, P ACL; Cheng LY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7000; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dua D, 2022, ARXIV; Dutta S, 2020, INFORM PROCESSING MA; Ferragina P, 2010, P 19 ACM INT C INF K, P1625, DOI [DOI 10.1145/1871437.1871689.(VER, DOI 10.1145/1871437.1871689, 10.1145/1871437.1871689]; Fromm M, 2021, PROC AAAI; Garg S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6174; Glaese A, 2022, ARXIV; Gretz S, 2020, AAAI CONF ARTIF INTE, V34, P7805; Hamilton WL, 2017, ADV NEUR IN, V30; Hoffman MD, 2010, P NEURIPS; Hou Y, 2017, P 4 WORKSH ARG MIN; Hua X, 2019, PROC NAACL; Huang KY, 2021, PROC AAAI; Kingma D. P., 2017, ARXIV; Kocon J, 2023, ARXIV; Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Kuribayashi T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4691; Li S, 2022, NEURAL COMPUT APPL; Ling X, 2023, IEEE T NEUR NET LEAR, V34, P799, DOI 10.1109/TNNLS.2021.3102234; Liu Y., 2019, CoRR abs/1907.11692; Min S., 2022, ARXIV; Morio G, 2019, 2019 IEEE 13 INT C S; Morio G, 2018, P 5 WORKSH ARG MIN; Morio G, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3259; Morris J, 2020, P EMNLP FIND; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Ouyang L., 2022, ARXIV; Persing I, 2016, P NAACL; Qiu L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6140; Ragesh R, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P860, DOI 10.1145/3437963.3441746; Rocha G, 2018, P 5 WORKSH ARG MIN; Schiller B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P380; Shnarch E, 2018, P ACL; Song W, 2020, PROC IJCAI; Stab C, 2017, COMPUT LINGUIST, V43, P619, DOI 10.1162/COLI_a_00295; Sun Q, 2022, NEURAL COMPUT APPL, V34, P15429, DOI 10.1007/s00521-022-07223-3; Swanson R, 2015, P 16 ANN M SPEC INT; Tay Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4425; Trautmann D, 2020, PROC AAAI; Tu M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2704; Velickovic P., 2017, stat, V1050, P10; Wachsmuth H, 2016, P COLING; Wang XZ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4569; Wei J, 2022, PROC NEURIPS; Welling M., 2016, INT C LEARN REPR ICL; Xu J, 2020, P ACL; Yao L, 2019, AAAI CONF ARTIF INTE, P7370; Yasunaga Michihiro., 2017, P CONLL; Yuan J, 2021, P ACL FIND; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174	66	0	0	6	6	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0941-0643	1433-3058		NEURAL COMPUT APPL	Neural Comput. Appl.	MAR	2024	36	9					4741	4762		10.1007/s00521-023-09250-0	http://dx.doi.org/10.1007/s00521-023-09250-0		DEC 2023	22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IO9X8		hybrid			2024-07-03	WOS:001126339700002
C	Lakkaraju, K; Jones, SE; Vuruma, SKR; Pallagani, V; Muppasani, B; Srivastava, B			ACM	Lakkaraju, Kausik; Jones, Sara Elizabeth; Vuruma, Sai Krishna Revanth; Pallagani, Vishal; Muppasani, Bharath; Srivastava, Biplav			LLMs for Financial Advisement: A Fairness and Efficacy Study in Personal Decision Making	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank				As Large Language Model (LLM) based chatbots are becoming more accessible, users are relying on these chatbots for reliable and personalized recommendations in diverse domains, ranging from code generation to financial advisement. In this context, we set out to investigate how such systems perform in the personal finance domain, where financial inclusion has been an overarching stated aim of banks for decades. We test widely used LLM-based chatbots, ChatGPT and Bard, and compare their performance against SafeFinance, a rule-based chatbot built using the Rasa platform. The comparison is across two critical tasks: product discovery and multi-product interaction, where product refers to banking products like Credit Cards, Certificate of Deposits, and Checking Accounts. With this study, we provide interesting insights into the chatbots' efficacy in financial advisement and their ability to provide fair treatment across different user groups. We find that both Bard and ChatGPT can make errors in retrieving basic online information, the responses they generate are inconsistent across different user groups, and they cannot be relied on for reasoning involving banking products. On the other hand, despite their limited generalization capabilities, rule-based chatbots like SafeFinance provide safe and reliable answers to users that can be traced back to their original source. Overall, although the outputs of the LLM-based chatbots are fluent and plausible, there are still critical gaps in providing consistent and reliable financial information.	[Lakkaraju, Kausik; Jones, Sara Elizabeth; Pallagani, Vishal; Muppasani, Bharath; Srivastava, Biplav] Univ South Carolina, AI Inst, Columbia, SC 29208 USA; [Vuruma, Sai Krishna Revanth] Univ South Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA	University of South Carolina System; University of South Carolina Columbia; University of South Carolina System; University of South Carolina Columbia	Lakkaraju, K (corresponding author), Univ South Carolina, AI Inst, Columbia, SC 29208 USA.	kausik@email.sc.edu; sej15@email.sc.edu; svuruma@email.sc.edu; vishalp@mailbox.sc.edu; bharath@email.sc.edu; biplav.s@sc.edu	Srivastava, Biplav/W-2921-2019	Srivastava, Biplav/0000-0002-7292-3838; Jones, Sara Elizabeth/0009-0008-9208-9933; Vuruma, Sai Krishna Revanth/0009-0009-3741-9343; Lakkaraju, Kausik/0000-0002-4446-7185				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blut M, 2021, J ACAD MARKET SCI, V49, P632, DOI 10.1007/s11747-020-00762-y; Bocklisch T, 2017, Arxiv, DOI arXiv:1712.05181; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; De Lucia C, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12135317; Discover, Discover Student Credit Cards FAQ; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Google, 2023, Google bard; Hu BZ, 2022, Arxiv, DOI arXiv:2211.16742; Khalafallah A, 2010, MEDITERR J HEMATOL I, V2, DOI [10.1136/bmj.l4898, 10.4084/MJHID.2010.005]; Kiritchenko S., 2018, P 7 JOINT C LEXICAL, P43, DOI DOI 10.18653/V1/S18-2005; Lakkaraju Kausik, 2023, PREPRINT; Lavrenko V., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P389, DOI 10.1145/354756.354845; Li Xiang Lorraine, 2022, P 2022 C EMPIRICAL M, P11838; Liu Z, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4513; masterpiececakes, ABOUT US; Min B., 2021, arXiv; Muppasani B, 2022, Arxiv, DOI arXiv:2212.11219; Pallagani Vishal, 2022, arXiv; Pozanco Daniel Borrajo Alberto, 2022, PFPT: a Personal Finance Planning Tool by means of Heuristic Search and Automated Planning; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Visa, Have a lost or stolen card?; Wikipedia, Jaccard Index; Wolfram Stephen, 2023, ChatGPT gets its "Wolfram superpowers; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xiao Ziang, 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P2, DOI 10.1145/3581641.3584031; Xing C, 2017, AAAI CONF ARTIF INTE, P3351; Yue Thomas, 2023, GPTQuant's conversational AI: Simplifying investment research for all; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	32	0	0	17	17	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							100	107		10.1145/3604237.3626867	http://dx.doi.org/10.1145/3604237.3626867			8	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		hybrid			2024-07-03	WOS:001124982700012
J	Wu, GQ; Zheng, F				Wu, GQ; Zheng, F			A method to build a super small but practically accurate language model for handheld devices	JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY			English	Article						language model; language model compression; piecewise linear warping; rank-based quantization		In this paper, an important question, whether a small language model can be practically accurate enough, is raised. Afterwards, the purpose of a language model, the problems that a language model faces, and the factors that affect the performance of a language model, are analyzed. Finally, a novel method for language model compression is proposed, which makes the large language model usable for applications in handheld devices, such as mobiles, smart phones, personal digital assistants (PDAs), and handheld personal computers (HPCs). In the proposed language model compression method, three aspects are included. First, the language model parameters are analyzed and a criterion based on the importance measure of n-grams is used to determine which n-grams should be kept and which removed. Second, a piecewise linear warping method is proposed to be used to compress the uni-gram count values in the full language model. And third, a rank-based quantization method is adopted to quantize the bi-gram probability values. Experiments show that by using this compression method the language model can be reduced dramatically to only about 1M bytes while the performance almost does not decrease. This provides good evidence that a language model compressed by means of a well-designed compression technique is practically accurate enough, and it makes the language model usable in handheld devices.	Tsinghua Univ, Ctr Speech Technol, State Key Lab Intelligent Technol & Syst, Dept Comp Sci & Technol, Beijing 100084, Peoples R China	Tsinghua University	Tsinghua Univ, Ctr Speech Technol, State Key Lab Intelligent Technol & Syst, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	wgq@sp.cs.tsinghua.edu.cn; fzheng@sp.cs.tsinghua.edu.cn						[Anonymous], 1998, PROC BROADCAST NEWS; [Anonymous], 1932, Selective studies and the principle of relative frequency in language; DI S, 2000, INT S CHIN SPOK LANG, P347; GOODMAN J, 2000, INT C SPOK LANG PROC; Jelinek F., 1990, READINGS SPEECH RECO; JELINEK F, 1986, PATTERN RECOGNITION; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; NIESLER TR, 1995, VARIABLE LENGTH CATE; Seymore K, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P232, DOI 10.1109/ICSLP.1996.607084; WHITTAKER E, 2001, EUR AALB DENM, P33; WU GQ, 2001, EUR AALB DENM SEPT 3, V3, P2139; WU GQ, 2002, INT C SPOK LANG PROC, V2, P925; YAN PJ, 2000, INT S CHIN SPOK LANG, P141; Zheng F, 1999, INT CONF ACOUST SPEE, P601, DOI 10.1109/ICASSP.1999.759738; Zheng F, 2000, J COMPUT SCI TECH-CH, V15, P461, DOI 10.1007/BF02950410	15	5	8	1	3	SCIENCE PRESS	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, BEIJING 100717, PEOPLES R CHINA	1000-9000	1860-4749		J COMPUT SCI TECH-CH	J. Comput. Sci. Technol.	NOV	2003	18	6					747	755		10.1007/BF02945463	http://dx.doi.org/10.1007/BF02945463			9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	752LG					2024-07-03	WOS:000187161600008
J	Saenz, AD; Harned, Z; Banerjee, O; Abràmoff, MD; Rajpurkar, P				Saenz, Agustina D.; Harned, Zach; Banerjee, Oishi; Abramoff, Michael D.; Rajpurkar, Pranav			Autonomous AI systems in the face of liability, regulations and costs	NPJ DIGITAL MEDICINE			English	Review								Autonomous AI systems in medicine promise improved outcomes but raise concerns about liability, regulation, and costs. With the advent of large-language models, which can understand and generate medical text, the urgency for addressing these concerns increases as they create opportunities for more sophisticated autonomous AI systems. This perspective explores the liability implications for physicians, hospitals, and creators of AI technology, as well as the evolving regulatory landscape and payment models. Physicians may be favored in malpractice cases if they follow rigorously validated AI recommendations. However, AI developers may face liability for failing to adhere to industry-standard best practices during development and implementation. The evolving regulatory landscape, led by the FDA, seeks to ensure transparency, evaluation, and real-world monitoring of AI systems, while payment models such as MPFS, NTAP, and commercial payers adapt to accommodate them. The widespread adoption of autonomous AI systems can potentially streamline workflows and allow doctors to concentrate on the human aspects of healthcare.	[Saenz, Agustina D.; Banerjee, Oishi; Rajpurkar, Pranav] Harvard Med Sch, Dept Biomed Informat, Boston, MA 02115 USA; [Saenz, Agustina D.] Brigham & Womens Hosp, Dept Med, Boston, MA USA; [Saenz, Agustina D.] Harvard Med Sch, Dept Med, Boston, MA USA; [Harned, Zach] Stanford Univ, Ctr Artificial Intelligence Med & Imaging, Palo Alto, CA USA; [Harned, Zach] Fenwick & West LLP, Mountain View, CA USA; [Abramoff, Michael D.] Univ Iowa, Dept Ophthalmol & Visual Sci, Iowa City, IA USA; [Abramoff, Michael D.] Univ Iowa, Dept Biomed Engn, Iowa City, IA USA; [Abramoff, Michael D.] Univ Iowa, Dept Elect & Comp Engn, Iowa City, IA USA; [Abramoff, Michael D.] Digital Diagnost Inc, Coralville, IA USA	Harvard University; Harvard Medical School; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School; Stanford University; University of Iowa; University of Iowa; University of Iowa	Rajpurkar, P (corresponding author), Harvard Med Sch, Dept Biomed Informat, Boston, MA 02115 USA.	pranav_rajpurkar@hms.harvard.edu	Abramoff, Michael David/IZP-9416-2023	Abramoff, Michael David/0000-0002-3490-0037; Rajpurkar, Pranav/0000-0002-8030-3727				Abràmoff MD, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00621-w; Abràmoff MD, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0040-6; Amer Diabet Assoc, 2020, DIABETES CARE, V43, pS135, DOI 10.2337/dc20-s011; [Anonymous], New Medical Services ad New Technologies; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Bitterman DS, 2023, JAMA ONCOL, V9, P612, DOI 10.1001/jamaoncol.2023.0012; Blueprint for Trustworthy AI, Implementation Guidance and Assurance for healthcare Coalition for Health AI; Crigger E, 2022, J MED SYST, V46, DOI 10.1007/s10916-021-01790-z; de Hond AAH, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-021-00549-7; Morey JR, 2020, medRxiv, DOI [10.1101/2020.07.02.20143834, 10.1101/2020.07.02.20143834, DOI 10.1101/2020.07.02.20143834]; Price WN, 2019, JAMA-J AM MED ASSOC, V322, P1765, DOI 10.1001/jama.2019.15064; Shrank WH, 2019, JAMA-J AM MED ASSOC, V322, P1501, DOI 10.1001/jama.2019.13978; Tobia K, 2021, J NUCL MED, V62, P17, DOI 10.2967/jnumed.120.256032	13	5	5	3	5	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	OCT 6	2023	6	1							185	10.1038/s41746-023-00929-1	http://dx.doi.org/10.1038/s41746-023-00929-1			3	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	U0PC0	37803209	gold			2024-07-03	WOS:001081902000001
C	Tepelyan, R; Gopal, A			ACM	Tepelyan, Ruslan; Gopal, Achintya			Generative Machine Learning for Multivariate Equity Returns	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		Stock Returns; Generative Modeling; Variational Autoencoders; Normalizing Flows; Risk Forecasting; Portfolio Optimization		The use of machine learning to generate synthetic data has grown in popularity with the proliferation of text-to-image models and especially large language models. The core methodology these models use is to learn the distribution of the underlying data, similar to the classical methods common in finance of fitting statistical models to data. In this work, we explore the efficacy of using modern machine learning methods, specifically conditional importance weighted autoencoders (a variant of variational autoencoders) and conditional normalizing flows, for the task of modeling the returns of equities. The main problem we work to address is modeling the joint distribution of all the members of the S&P 500, or, in other words, learning a 500-dimensional joint distribution. We show that this generative model has a broad range of applications in finance, including generating realistic synthetic data, volatility and correlation estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization.	[Tepelyan, Ruslan; Gopal, Achintya] Bloomberg, New York, NY 10022 USA		Tepelyan, R (corresponding author), Bloomberg, New York, NY 10022 USA.	rtepelyan@bloomberg.net; agopal6@bloomberg.net						Behrmann J, 2019, PR MACH LEARN RES, V97; Buehler Hans, 2020, arXiv; Burda Yuri, 2016, 4 INT C LEARN REPR; Dinh L., 2017, DENSITY ESTIMATION U; Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]; Engle R, 2002, J BUS ECON STAT, V20, P339, DOI 10.1198/073500102288618487; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; Fama EF, 2015, J FINANC ECON, V116, P1, DOI 10.1016/j.jfineco.2014.10.010; GARMAN MB, 1980, J BUS, V53, P67, DOI 10.1086/296072; GLOSTEN LR, 1993, J FINANC, V48, P1779, DOI 10.2307/2329067; Gopal Achintya, 2020, ESG Imputation Using DLVMs; Gopal Achintya, 2020, arXiv; King DB, 2015, ACS SYM SER, V1214, P1; Kingma D. P., 2017, ARXIV; Kuleshov V, 2018, PR MACH LEARN RES, V80; Ledoit O, 2022, J FINANC ECONOMET, V20, P187, DOI 10.1093/jjfinec/nbaa007; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.1111/j.1540-6261.1952.tb01525.x; Papamakarios G, 2021, J MACH LEARN RES, V22; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Teshima T, 2020, Proceedings of the 34th International Conference on Neural Information Processing Systems, V33, P3362; van den Oord A, 2016, PR MACH LEARN RES, V48; Vaswani A, 2017, ADV NEUR IN, V30; Wiese Magnus, 2019, arXiv; Wiese Magnus, 2021, arXiv; Winkler C, 2023, Arxiv, DOI arXiv:1912.00042	26	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							159	166		10.1145/3604237.3626884	http://dx.doi.org/10.1145/3604237.3626884			8	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		Green Submitted			2024-07-03	WOS:001124982700019
C	Shah, C; Bender, EM			Assoc Comp Machinery	Shah, Chirag; Bender, Emily M.			Situating Search	CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL			English	Proceedings Paper	7th ACM SIGIR Conference on Human Information Interaction and Retrieval (CHIIR)	MAR 14-18, 2022	ELECTR NETWORK	ACM SIGIR, ACM SIGCHI, Assoc Comp Machinery, Google, Lexis Nexis, ITSG, Thomson Reuters		Search models; Language models; Information Seeking Strategies	INFORMATION-SEEKING; MEDIA COVERAGE; FALSE BALANCE; DESIGN; USER	Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user's needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.	[Shah, Chirag; Bender, Emily M.] Univ Washington, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Shah, C (corresponding author), Univ Washington, Seattle, WA 98195 USA.	chirags@uw.edu; ebender@uw.edu		Bender, Emily M./0000-0001-5384-6227				[Anonymous], 1995, Information Seeking in Electronic Environments; Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; BAWDEN D, 1986, J INF SCI, V12, P203, DOI 10.1177/016555158601200501; BELKIN NJ, 1995, EXPERT SYST APPL, V9, P379, DOI 10.1016/0957-4174(95)00011-W; BELKIN NJ, 1980, CAN J INFORM SCI, V5, P133; BELKIN NJ, 1993, INFORM PROCESS MANAG, V29, P325, DOI 10.1016/0306-4573(93)90059-M; Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Bolukbasi T, 2016, ADV NEUR IN, V29; Boykoff MT, 2004, GLOBAL ENVIRON CHANG, V14, P125, DOI 10.1016/j.gloenvcha.2003.10.001; Brüggemann M, 2017, GLOBAL ENVIRON CHANG, V42, P58, DOI 10.1016/j.gloenvcha.2016.11.004; Bush V., 1945, ATLANTIC MONTHLY, V176, P101, DOI DOI 10.1145/227181.227186; Bystrom Katriina., 2007, Proceedings of the Sixth International Conference on Conceptions of Library and Information Science-"Featuring the Future", V12, P1; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Choi E., 2013, Proceedings of ASIST Conference, V50, P1; Choi E, 2017, J INF SCI, V43, P424, DOI 10.1177/0165551516645530; Cool C, 2002, COLIS4: EMERGING FRAMEWORKS AND METHODS, P1; Dervin B., 1998, Journal of Knowledge Management, V2, P36, DOI 10.1108/13673279810249369; Dervin B., 1983, INT COMMUNICATION AS; Dervin B., 2012, Public Communication Campaigns, V4th, P147, DOI DOI 10.4135/9781544308449; Dinan E, 2021, Arxiv, DOI [arXiv:2107.03451, 10.48550/arxiv.2107.03451, DOI 10.48550/ARXIV.2107.03451]; Dixon GN, 2013, SCI COMMUN, V35, P358, DOI 10.1177/1075547012458290; Froehlich TJ, 2017, BID-TEXTOS UNIV BIBL, DOI 10.1344/BiD2017.39.8; Garrido M., 2017, Development and Access to Information; Gazan R, 2011, J AM SOC INF SCI TEC, V62, P2301, DOI 10.1002/asi.21562; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Gebru Timnit, 2020, The Oxford Handbook of Ethics of AI; Ghosh S, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P22, DOI 10.1145/3176349.3176386; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Google Search Help, GOOGL FEAT SNIPP WOR; Hirschheim R., 2011, The Oxford Handbook of Management Information Systems, P16; Ingwersen P, 1996, J DOC, V52, P3, DOI 10.1108/eb026960; Jarvelin Kalervo, 2011, SIGIR Forum, V45, P17, DOI 10.1145/2093346.2093348; Kelly D, 2013, J AM SOC INF SCI TEC, V64, P745, DOI 10.1002/asi.22799; Kim N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3932; Kolomiyets O, 2011, INFORM SCIENCES, V181, P5412, DOI 10.1016/j.ins.2011.07.047; Koskela M, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3150975; Krasner-Khait Barbara, 2001, HIST MAGAZINE, V4, P1; KUHLTHAU CC, 1991, J AM SOC INFORM SCI, V42, P361, DOI 10.1002/(SICI)1097-4571(199106)42:5<361::AID-ASI6>3.0.CO;2-#; Lascarides A, 2009, J SEMANT, V26, P109, DOI 10.1093/jos/ffn013; Leeder C, 2016, INFORM RES, V21; Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979; Marcus Gary, 2021, GRADIENT; Mehrotra Rishabh., 2016, P 2016 C N AM CHAPTE, P599; Mengliang Zhu, 2019, Journal of Physics: Conference Series, V1302, DOI 10.1088/1742-6596/1302/2/022076; Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Mitsui M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1121, DOI 10.1145/3077136.3080737; Nathan Lisa P., 2008, Proceedings of the 7th ACM Conference on Designing Interactive Systems. DIS 2008, P1, DOI 10.1145/1394445.1394446; Nguyen PH, 2016, IEEE CONF VIS ANAL, P91, DOI 10.1109/VAST.2016.7883515; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; Pickens Jeremy., 2021, DANCING DIGITAL LAND; Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183; Ruotsalo T, 2015, COMMUN ACM, V58, P86, DOI 10.1145/2656334; Salton G., 1993, SIGIR Forum, P49; Saussure Ferdinand de, 1959, Course in general linguistics; Schutz A., 1974, STRUCTURES LIFE WORL; Shah C., 2017, Social Information Seeking; Shah C, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P62, DOI 10.1145/3176349.3176389; Shah C, 2014, J INF SCI, V40, P669, DOI 10.1177/0165551514534140; Shah Chirag., 2021, Synthesis Lectures onSynthesis Lectures on Information Concepts, Retrieval, and Services, V13, P1; Smith CL, 2019, PROCEEDINGS OF THE 2019 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'19), P55, DOI 10.1145/3295750.3298940; Stitzlein Sarah M., 2004, ELECT J SCI ED, V9, P2; Sweeney L, 2013, COMMUN ACM, V56, P44, DOI 10.1145/2447976.2447990; Vakkari P, 2003, ANNU REV INFORM SCI, V37, P413, DOI 10.1002/aris.1440370110; Vakkari P, 2016, J INF SCI, V42, P7, DOI 10.1177/0165551515615833; Wardle C., 2018, Journalism, Fake News, and Disinformation: Handbook for Journalism Education and Training, V12; White R. W., 2009, Exploratory search: Beyond the Query-Response Paradigm; White R.W., 2006, P 15 ACM INT C INFOR, P297, DOI DOI 10.1145/1183614.1183659; Wilson ML, 2009, J AM SOC INF SCI TEC, V60, P1407, DOI 10.1002/asi.21080; Wilson TD, 1997, INFORM PROCESS MANAG, V33, P551, DOI 10.1016/S0306-4573(97)00028-9; WILSON TD, 1981, J DOC, V37, P3, DOI 10.1108/eb026702; Young NJ, 2001, REF USER SERV Q, V41, P159; Zhao YL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060459	77	22	25	3	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9186-3				2022							221	232		10.1145/3498366.3505816	http://dx.doi.org/10.1145/3498366.3505816			12	Computer Science, Cybernetics; Computer Science, Information Systems; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BU2DZ		Bronze			2024-07-03	WOS:000884359900021
C	Han, WJ; Pang, B; Wu, YNA			Assoc Computat Linguist	Han, Wenjuan; Pang, Bo; Wu, Yingnian			Robust Transfer Learning with Pretrained Language Models through Adapters	ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2			English	Proceedings Paper	Joint Conference of 59th Annual Meeting of the Association-for-Computational-Linguistics (ACL) / 11th International Joint Conference on Natural Language Processing (IJCNLP) / 6th Workshop on Representation Learning for NLP (RepL4NLP)	AUG 01-06, 2021	ELECTR NETWORK	Assoc Computat Linguist, Apple, Bloomberg Engn, Facebook AI, Google Res, Amazon Science, ByteDance, Megagon Labs, Microsoft, Baidu, DeepMind, Tencent, IBM, Alibaba Grp, Duolingo, Naver, Babelscape, Bosch, LegalForce, Adobe ETS				Transfer learning with large pretrained transformer-based language models like BERT has become a dominating approach for most NLP tasks. Simply fine-tuning those large language models on downstream tasks or combining it with task-specific pretraining is often not robust. In particular, the performance considerably varies as the random seed changes or the number of pretraining and/or fine-tuning iterations varies, and the fine-tuned model is vulnerable to adversarial attack. We propose a simple yet effective adapter-based approach to mitigate these issues. Specifically, we insert small bottleneck layers (i.e., adapter) within each layer of a pretrained model, then fix the pretrained layers and train the adapter layers on the downstream task data, with (1) task-specific unsupervised pretraining and then (2) task-specific supervised training (e.g., classification, sequence labeling). Our experiments demonstrate that such a training scheme leads to improved stability and adversarial robustness in transfer learning to various downstream tasks.(1)	[Han, Wenjuan] Beijing Inst Gen Artificial Intelligence, Beijing, Peoples R China; [Pang, Bo; Wu, Yingnian] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA USA	University of California System; University of California Los Angeles	Han, WJ (corresponding author), Beijing Inst Gen Artificial Intelligence, Beijing, Peoples R China.	hanwenjuan@bigai.ai; bopang@ucla.edu; ywu@ucla.edu	Han, Wenjuan/J-6584-2019	Han, Wenjuan/0000-0003-0957-8493	NSF [DMS 2015577]	NSF(National Science Foundation (NSF))	Y. W. is partially supported by NSF DMS 2015577.	[Anonymous], 2019, CORR ABS190108746; Clark K., 2020, 8 INT C LEARN REPR I; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Devlin J., 2018, BERT PRE TRAINING DE; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Houlsby N, 2019, PR MACH LEARN RES, V97; Lan Zhenzhong, 2019, INT C LEARN REPR; Lee Cheolhyoung, 2019, INT C LEARN REPR; Lewis Mike, 2020, ADV NEURAL INFORM PR, V33; Li L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6193; Liu HR, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3044; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Mosbach Marius, 2020, INT C LEARN REPR; Nijkamp Erik, P 2021 C N AM CHAPT, P5196; Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P7; Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46; Pfeiffer Jonas, ARXIV PREPRINT ARXIV; Phang Jason, 2018, Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-Data Tasks; Raffel C, 2020, J MACH LEARN RES, V21; Ren SH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1085; Ruder S, 2019, Neural transfer learning for natural language processing; Sun Lichao, 2020, ARXIV PREPRINT ARXIV; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wolf Thomas, 2020, P EMNLP, P38, DOI DOI 10.18653/V1/2020.EMNLP-DEMOS.6	25	9	9	3	3	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-954085-53-4				2021							854	861						8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BS1QD					2024-07-03	WOS:000694699200108
J	Bai, XY; Zhu, ZM; Schwing, A; Forsyth, D; Gruev, V				Bai, Xiaoyang; Zhu, Zhongmin; Schwing, Alexander; Forsyth, David; Gruev, Viktor			Learning a global underwater geolocalization model with sectoral transformer	OPTICS EXPRESS			English	Article							POLARIZED-LIGHT; COMPASS; VISION; IMAGER	Polarization-based underwater geolocalization presents an innovative method for positioning unmanned autonomous devices beneath the water surface, in environments where GPS signals are ineffective. While the state-of-the-art deep neural network (DNN) method achieves high-precision geolocalization based on sun polarization patterns in same -site tasks, its learning-based nature limits its generalizability to unseen sites and subsequently impairs its performance on cross-site tasks, where an unavoidable domain gap between training and test data exists. In this paper, we present an advanced Deep Neural Network (DNN) methodology, which includes a neural network built on a Transformer architecture, similar to the core of large language models such as ChatGPT, and integrates an unscented Kalman filter (UKF) for estimating underwater geolocation using polarization-based images. This combination effectively simulates the sun's daily trajectory, yielding enhanced performance across different locations and quicker inference speeds compared to current benchmarks. Following thorough analysis of over 10 million polarization images from four global locations, we conclude that our proposed technique significantly boosts cross-site geolocalization accuracy by around 28% when contrasted with traditional DNN methods. (c) 2024 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement	[Bai, Xiaoyang; Schwing, Alexander; Forsyth, David] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Zhu, Zhongmin; Schwing, Alexander; Gruev, Viktor] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Gruev, Viktor] Univ Illinois, Dept Bioengn, Urbana, IL 61801 USA; [Gruev, Viktor] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA; [Gruev, Viktor] Univ Illinois, Carle Illinois Coll Med, Urbana, IL 61820 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Gruev, V (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.; Gruev, V (corresponding author), Univ Illinois, Dept Bioengn, Urbana, IL 61801 USA.; Gruev, V (corresponding author), Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA.; Gruev, V (corresponding author), Univ Illinois, Carle Illinois Coll Med, Urbana, IL 61820 USA.	vgruev@illinois.edu			Air Force Office of Scientific Research [FA9550-24-1-0112]; Office of Naval Research [N00014-19-1-2400, N00014-21-1-2177]	Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research)	Funding. Air Force Office of Scientific Research (FA9550-24-1-0112) ; Office of Naval Research (N00014-19-1-2400, N00014-21-1-2177) .	Bai XY, 2023, ELIGHT, V3, DOI 10.1186/s43593-023-00050-6; Chen KC, 2024, Arxiv, DOI arXiv:2402.06150; Cheng RZ, 2021, IEEE COMPUT SOC CONF, P3113, DOI 10.1109/CVPRW53098.2021.00348; Choi J, 2019, IEEE I CONF COMP VIS, P6829, DOI 10.1109/ICCV.2019.00693; Conde MV, 2021, IEEE COMPUT SOC CONF, P3951, DOI 10.1109/CVPRW53098.2021.00444; Cronin TW, 2003, INTEGR COMP BIOL, V43, P549, DOI 10.1093/icb/43.4.549; Dacke M, 2003, NATURE, V424, P33, DOI 10.1038/424033a; DelMoral P, 1997, CR ACAD SCI I-MATH, V325, P653, DOI 10.1016/S0764-4442(97)84778-7; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Finn C., 2019, PMLR; Garcia M, 2018, OPTICA, V5, P1240, DOI 10.1364/OPTICA.5.001240; Garcia M, 2017, OPTICA, V4, P1263, DOI 10.1364/OPTICA.4.001263; González-García J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041256; Gruev V, 2010, OPT EXPRESS, V18, P19087, DOI 10.1364/OE.18.019087; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoi SCH, 2021, NEUROCOMPUTING, V459, P249, DOI 10.1016/j.neucom.2021.04.112; Jung J, 2017, IEEE UNDERWATER TECH; Leonard JJ, 2016, SPRINGER HANDBOOK OF OCEAN ENGINEERING, P341; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Liu C, 2021, AAAI CONF ARTIF INTE, V35, P8635; Marshall NJ, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.134213; Muheim R, 2006, SCIENCE, V313, P837, DOI 10.1126/science.1129709; Palmer C, 2023, ENGINEERING-PRC, V22, P10, DOI 10.1016/j.eng.2023.01.001; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Patel RN, 2020, CURR BIOL, V30, P1981, DOI 10.1016/j.cub.2020.03.023; Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891; Pomozi I, 2001, J EXP BIOL, V204, P2933; Powell SB, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao6841; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Sahoo A, 2019, OCEAN ENG, V181, P145, DOI 10.1016/j.oceaneng.2019.04.011; Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871; Shashar N, 2004, J EXP BIOL, V207, P3619, DOI 10.1242/jeb.01187; Suresh V, 2021, Arxiv, DOI arXiv:2109.05427; Terejanu G. A., 2008, Extended kalman filter tutorial, P27; Tonizzo A, 2009, OPT EXPRESS, V17, P5666, DOI 10.1364/OE.17.005666; Torr P. H. S., 2015, PR MACH LEARN RES, DOI DOI 10.1007/978-3-319-50077-5_2; Vanschoren J, 2018, Arxiv, DOI [arXiv:1810.03548, 10.48550/arXiv.1810.03548]; Vaswani A, 2017, ADV NEUR IN, V30; Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463; Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Waterman TH, 2006, BIOL REV, V81, P111, DOI 10.1017/S1464793105006883; WATERMAN TH, 1954, SCIENCE, V120, P927, DOI 10.1126/science.120.3127.927; Wehner R, 2001, J EXP BIOL, V204, P2589; Wehner R, 2006, P NATL ACAD SCI USA, V103, P12575, DOI 10.1073/pnas.0604430103; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Welch G., 1995, INTRO KALMAN FILTER; Xu JL, 2019, IEEE ACCESS, V7, P156694, DOI 10.1109/ACCESS.2019.2949697; Yang Y, 2021, IEEE COMMUN SURV TUT, V23, P815, DOI 10.1109/COMST.2021.3059998; You KC, 2019, PROC CVPR IEEE, P2715, DOI 10.1109/CVPR.2019.00283; Zhang S, 2022, COMPUT SCI REV, V46, DOI 10.1016/j.cosrev.2022.100510; Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555	54	0	0	0	0	Optica Publishing Group	WASHINGTON	2010 MASSACHUSETTS AVE NW, WASHINGTON, DC 20036 USA	1094-4087			OPT EXPRESS	Opt. Express	JUN 3	2024	32	12					20706	20718		10.1364/OE.515192	http://dx.doi.org/10.1364/OE.515192			13	Optics	Science Citation Index Expanded (SCI-EXPANDED)	Optics	UT8A0	38859446	gold			2024-07-03	WOS:001250388400004
J	Yuan, QM; Tian, C; Song, YD; Ou, PH; Zhu, MM; Zhao, HY; Yang, YD				Yuan, Qianmu; Tian, Chong; Song, Yidong; Ou, Peihua; Zhu, Mingming; Zhao, Huiying; Yang, Yuedong			GPSFun: geometry-aware protein sequence function predictions with language models	NUCLEIC ACIDS RESEARCH			English	Article; Early Access							BINDING-SITES; SCALE	Knowledge of protein function is essential for elucidating disease mechanisms and discovering new drug targets. However, there is a widening gap between the exponential growth of protein sequences and their limited function annotations. In our prior studies, we have developed a series of methods including GraphPPIS, GraphSite, LMetalSite and SPROF-GO for protein function annotations at residue or protein level. To further enhance their applicability and performance, we now present GPSFun, a versatile web server for Geometry-aware Protein Sequence Function annotations, which equips our previous tools with language models and geometric deep learning. Specifically, GPSFun employs large language models to efficiently predict 3D conformations of the input protein sequences and extract informative sequence embeddings. Subsequently, geometric graph neural networks are utilized to capture the sequence and structure patterns in the protein graphs, facilitating various downstream predictions including protein-ligand binding sites, gene ontologies, subcellular locations and protein solubility. Notably, GPSFun achieves superior performance to state-of-the-art methods across diverse tasks without requiring multiple sequence alignments or experimental protein structures. GPSFun is freely available to all users at https://bio-web1.nscc-gz.cn/app/GPSFun with user-friendly interfaces and rich visualizations. Graphical Abstract	[Yuan, Qianmu; Tian, Chong; Song, Yidong; Ou, Peihua; Zhu, Mingming; Yang, Yuedong] Sun Yat sen Univ, Sch Comp Sci & Engn, Guangzhou 510000, Guangdong, Peoples R China; [Zhao, Huiying] Sun Yat sen Univ, Sun Yat sen Mem Hosp, Guangzhou 510000, Guangdong, Peoples R China	Sun Yat Sen University; Sun Yat Sen University	Yang, YD (corresponding author), Sun Yat sen Univ, Sch Comp Sci & Engn, Guangzhou 510000, Guangdong, Peoples R China.; Zhao, HY (corresponding author), Sun Yat sen Univ, Sun Yat sen Mem Hosp, Guangzhou 510000, Guangdong, Peoples R China.	zhaohy8@mail.sysu.edu.cn; yangyd25@mail.sysu.edu.cn	; Yang, Yuedong/C-9394-2009	zhao, huiying/0000-0001-9134-536X; Yuan, Qianmu/0000-0001-6098-9103; Yang, Yuedong/0000-0002-6782-2813	National Key Research and Development Program of China [2022YFF1203100]; Research and Development Project of Pazhou Lab (Huangpu) [2023K0606]; Shenzhen Science and Technology Plan Project [CJGJZD20220517142201004]	National Key Research and Development Program of China; Research and Development Project of Pazhou Lab (Huangpu); Shenzhen Science and Technology Plan Project	National Key Research and Development Program of China [2022YFF1203100]; Research and Development Project of Pazhou Lab (Huangpu) [2023K0606]; Shenzhen Science and Technology Plan Project [CJGJZD20220517142201004]. Funding for open access charge: Shenzhen Science and Technology Plan Project [CJGJZD20220517142201004].	Abdin O, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03445-2; Armenteros JJA, 2017, BIOINFORMATICS, V33, P3387, DOI 10.1093/bioinformatics/btx431; Bateman A, 2023, NUCLEIC ACIDS RES, V51, pD523, DOI 10.1093/nar/gkac1052; Bhandari BK, 2020, BIOINFORMATICS, V36, P4691, DOI 10.1093/bioinformatics/btaa578; Buchfink B, 2015, NAT METHODS, V12, P59, DOI 10.1038/nmeth.3176; Chen JW, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00488-1; Costanzo M, 2016, SCIENCE, V353, DOI 10.1126/science.aaf1420; Cruz LM, 2017, METHODS MOL BIOL, V1654, P55, DOI 10.1007/978-1-4939-7231-9_5; Dauparas J, 2022, SCIENCE, V378, P49, DOI 10.1126/science.add2187; Eisenberg D, 2000, NATURE, V405, P823, DOI 10.1038/35015694; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Fu LM, 2012, BIOINFORMATICS, V28, P3150, DOI 10.1093/bioinformatics/bts565; Gainza P, 2020, NAT METHODS, V17, P184, DOI 10.1038/s41592-019-0666-6; Gao Z., 2022, The Eleventh International Conference on Learning Representations; Gligorijevic V, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23303-9; Hon J, 2021, BIOINFORMATICS, V37, P23, DOI 10.1093/bioinformatics/btaa1102; Hu XZ, 2016, BIOINFORMATICS, V32, P3260, DOI 10.1093/bioinformatics/btw396; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kingma D. P., 2017, ARXIV; Krapp LF, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37701-8; Kulmanov M, 2020, BIOINFORMATICS, V36, P422, DOI 10.1093/bioinformatics/btz595; Lai BQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab502; Li PP, 2023, NUCLEIC ACIDS RES, V51, DOI 10.1093/nar/gkad288; Li SL, 2014, NUCLEIC ACIDS RES, V42, P10086, DOI 10.1093/nar/gku681; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Lu W., 2022, Advances in neural information processing systems, V35, P7236; Paszke A, 2019, ADV NEUR IN, V32; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Sehnal D, 2021, NUCLEIC ACIDS RES, V49, pW431, DOI 10.1093/nar/gkab314; Stark H, 2022, 39 INT C MACHINE LEA; Thumuluri V, 2022, NUCLEIC ACIDS RES, V50, pW228, DOI 10.1093/nar/gkac278; Thumuluri V, 2022, BIOINFORMATICS, V38, P941, DOI 10.1093/bioinformatics/btab801; Tubiana J, 2022, NAT METHODS, V19, P730, DOI 10.1038/s41592-022-01490-7; Varadi M, 2022, NUCLEIC ACIDS RES, V50, pD439, DOI 10.1093/nar/gkab1061; Wan S, 2017, BIOINFORMATICS, V33, P749, DOI 10.1093/bioinformatics/btw717; Wang RH, 2022, BIOINFORMATICS, V38, P3351, DOI 10.1093/bioinformatics/btac352; Xia CQ, 2020, BIOINFORMATICS, V36, P3018, DOI 10.1093/bioinformatics/btaa110; Xia Y, 2021, NUCLEIC ACIDS RES, V49, DOI 10.1093/nar/gkab044; Yao SW, 2021, NUCLEIC ACIDS RES, V49, pW469, DOI 10.1093/nar/gkab398; You RH, 2021, BIOINFORMATICS, V37, pI262, DOI 10.1093/bioinformatics/btab270; You RH, 2019, NUCLEIC ACIDS RES, V47, pW379, DOI 10.1093/nar/gkz388; You RH, 2018, BIOINFORMATICS, V34, P2465, DOI 10.1093/bioinformatics/bty130; Yu DJ, 2013, IEEE ACM T COMPUT BI, V10, P994, DOI 10.1109/TCBB.2013.104; Yuan QM, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad117; Yuan QM, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac444; Yuan QM, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab564; Yuan QM, 2022, BIOINFORMATICS, V38, P125, DOI 10.1093/bioinformatics/btab643; Zhang CX, 2024, NUCLEIC ACIDS RES, V52, pD404, DOI 10.1093/nar/gkad630; Zhang Z., 2022, 11 INT C LEARNING RE; Zhao ZJ, 2018, J CHEM INF MODEL, V58, P1459, DOI 10.1021/acs.jcim.8b00019	51	0	0	8	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048	1362-4962		NUCLEIC ACIDS RES	Nucleic Acids Res.	2024 MAY 13	2024										10.1093/nar/gkae381	http://dx.doi.org/10.1093/nar/gkae381		MAY 2024	8	Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	QG5M9	38738636	gold			2024-07-03	WOS:001219739800001
J	Polak, PB; Prusa, JD; Khoshgoftaar, TM				Billion Polak, Preston; Prusa, Joseph D.; Khoshgoftaar, Taghi M.			Low-shot learning and class imbalance: a survey	JOURNAL OF BIG DATA			English	Article						Low-shot learning; Few-shot learning; Zero-shot learning; Class imbalance; Class-imbalanced learning; Machine learning	OBJECT DETECTION; RECOGNITION; NETWORK	The tasks of few-shot, one-shot, and zero-shot learning-or collectively "low-shot learning" (LSL)-at first glance are quite similar to the long-standing task of class imbalanced learning; specifically, they aim to learn classes for which there is little labeled data available. Motivated by this similarity, we conduct a survey to review the recent literature for works which combine these fields in one of two ways, either addressing the obstacle of class imbalance within a LSL setting, or utilizing LSL techniques or frameworks in order to combat class imbalance within other settings. In our survey of over 60 papers in a wide range of applications from January 2020 to July 2023 (inclusive), we examine and report methodologies and experimental results, find that most works report performance at or above their respective state-of-the-art, and highlight current research gaps which hold potential for future work, especially those involving the use of LSL techniques in imbalanced tasks. To this end, we emphasize the lack of works utilizing LSL approaches based on large language models or semantic data, and works using LSL for big-data imbalanced tasks.	[Billion Polak, Preston; Prusa, Joseph D.; Khoshgoftaar, Taghi M.] Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA	State University System of Florida; Florida Atlantic University	Polak, PB (corresponding author), Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.	pbillionpola2019@fau.edu	Billion-Polak, Preston/JXW-8082-2024		Machine Learning Laboratory at Florida Atlantic University	Machine Learning Laboratory at Florida Atlantic University	We would like to thank the reviewers in the Data Mining and Machine Learning Laboratory at Florida Atlantic University.	Agarwal A, 2022, Attention guided cosine margin for overcoming class-imbalance in few-shot road object detection; Arfeen A, 2022, BMVC; Bansal A, 2021, Arxiv, DOI [arXiv:2106.09643, 10.48550/arxiv.2106.09643, DOI 10.48550/ARXIV.2106.09643]; Bedi Punam, 2020, Procedia Computer Science, V171, P780, DOI 10.1016/j.procs.2020.04.085; Bedi P, 2021, APPL INTELL, V51, P1133, DOI 10.1007/s10489-020-01886-y; Bhosale S, 2021, INTERSPEECH, P946, DOI 10.21437/Interspeech.2021-1249; Boudiaf M, 2020, Arxiv, DOI arXiv:2008.11297; Bragg Jonathan, 2021, Advances in Neural Information Processing Systems, V34, P15787; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen RQ, 2020, AAAI CONF ARTIF INTE, V34, P10575; Chen W-Y, 2018, A closer look at few-shot classification; Chen XY, 2020, Arxiv, DOI [arXiv:2012.14255, 10.48550/arxiv.2012.14255]; Chen XC, 2023, INFORM SCIENCES, V634, P206, DOI 10.1016/j.ins.2023.03.105; Chen Z, 2020, IET IMAGE PROCESS, V14, P2855, DOI 10.1049/iet-ipr.2019.0618; Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002; Cheng Ouyang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P762, DOI 10.1007/978-3-030-58526-6_45; Cui HJ, 2021, IEEE T MED IMAGING, V40, P2656, DOI 10.1109/TMI.2020.3045775; Cui ZY, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104381; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Deng LZ, 2022, IEEE T INTELL TRANSP, V23, P25249, DOI 10.1109/TITS.2022.3199805; Dong NQ, 2022, LECT NOTES COMPUT SC, V13438, P67, DOI 10.1007/978-3-031-16452-1_7; Duan R., 2021, A survey of few-shot learning: an effective method for intrusion detection. Security and communication networks; Dutta Titir, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P349, DOI 10.1007/978-3-030-58558-7_21; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan Q, 2020, Arxiv, DOI [arXiv:1908.01998, 10.48550/arXiv.1908.01998]; Fernández-Llaneza D, 2021, ACS OMEGA, V6, P11086, DOI 10.1021/acsomega.1c01266; Finn C, 2017, PR MACH LEARN RES, V70; Gao A, 2023, IEEE T SMART GRID, V14, P4565, DOI 10.1109/TSG.2023.3263219; Gao YX, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070783; Gesi J, 2021, P 15 ACM IEEE INT S, P1, DOI [10.1145/3475716.3475791, DOI 10.1145/3475716.3475791]; Guan J, 2020, INT CONF ACOUST SPEE, P4047, DOI [10.1109/ICASSP40776.2020.9052900, 10.1109/icassp40776.2020.9052900]; Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550; Gupta P, 2021, 2021 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2021), P404, DOI 10.1109/DICTA52665.2021.9647357; He C, 2022, IEEE SIGNAL PROC LET, V29, P1097, DOI 10.1109/LSP.2022.3168195; He C, 2021, IEEE COMPUT SOC CONF, P3554, DOI 10.1109/CVPRW53098.2021.00395; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Heidari A, 2019, INT CONF MANAGE DATA, P829, DOI 10.1145/3299869.3319888; Hess S, 2022, Arxiv, DOI arXiv:2211.14668; Hu YQ, 2021, Arxiv, DOI arXiv:2006.03806; Hua YN, 2022, IEEE T IND INFORM, V18, P3248, DOI 10.1109/TII.2021.3107785; Huang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8651, DOI 10.1109/ICCV48922.2021.00855; Huang SH, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P505, DOI [10.1109/icoin48656.2020.9016599, 10.1109/ICOIN48656.2020.9016599]; Huang X, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13193816; Huang Y, 2023, AAAI, V37, P405, DOI 10.1609/aaai.v37i1.25114; Ji Z, 2022, IEEE T CYBERNETICS, V52, P6543, DOI 10.1109/TCYB.2020.3004641; Ji Z, 2021, IEEE T IMAGE PROCESS, V30, P1648, DOI 10.1109/TIP.2020.3046861; Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Kim M, 2023, Meta-learning with adaptive weighted loss for imbalanced cold-start recommendation, DOI [10.1145/3583780.3614965, DOI 10.1145/3583780.3614965]; Krizhevsky A., LEARNING MULTIPLE LA; Kumar A, 2023, Arxiv, DOI [arXiv:2112.07434, 10.48550/arxiv.2112.07434, DOI 10.48550/ARXIV.2112.07434]; Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6; Lei WH, 2024, IEEE T MED IMAGING, V43, P175, DOI 10.1109/TMI.2023.3294975; Li GM, 2022, PHYS STATUS SOLIDI A, V219, DOI 10.1002/pssa.202200333; Li Kang, 2024, IEEE Trans Neural Netw Learn Syst, V35, P6206, DOI 10.1109/TNNLS.2022.3232394; Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023; Li M, 2022, Mathematical problems in engineering; Li QZ, 2021, NEUROCOMPUTING, V449, P117, DOI 10.1016/j.neucom.2021.03.073; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu TY, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103094; Liu XX, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18986-z; Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ma S, 2021, 2021 IEEE INT C MULT, P1, DOI [10.1109/icme51207.2021.9428261, DOI 10.1109/ICME51207.2021.9428261]; Majee A, 2021, AAAI WORKSH MET META, P115; Masihullah S, 2021, INT C PATT RECOG, P5812, DOI 10.1109/ICPR48806.2021.9412368; Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355; Nichol A, 2018, Arxiv, DOI arXiv:1803.02999; Ochal Mateusz, 2023, IEEE Transactions on Artificial Intelligence, P1348, DOI 10.1109/TAI.2023.3298303; Olah J., 2021, arXiv; Parnami A., 2022, arXiv; Patil S, 2020, EMPIR SOFTW ENG, V25, P1341, DOI 10.1007/s10664-019-09779-6; Patra A, 2020, IEEE J BIOMED HEALTH, V24, P1046, DOI 10.1109/JBHI.2020.2973372; Pei ZY, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abe5e3; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Radford A, 2021, PR MACH LEARN RES, V139; Rahman S, 2020, AAAI CONF ARTIF INTE, V34, P11932; Ren M., 2018, META LEARNING SEMI S; Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, 10.1109/TPAMI.2016.2577031, DOI 10.1109/TPAMI.2016.2577031]; Renteria S, 2021, bioRxiv, DOI DOI 10.1101/2021.03.16.435625; Romanov S, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534239; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Samuel D, 2021, IEEE WINT CONF APPL, P286, DOI 10.1109/WACV48630.2021.00033; Seliya N, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00514-x; Sharma R, 2021, I CONF VLSI DESIGN, P163, DOI 10.1109/VLSID51830.2021.00033; Shi YZ, 2021, IEEE T GEOSCI REMOTE, V59, P6894, DOI 10.1109/TGRS.2020.3032528; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Skorokhodov I, 2021, Arxiv, DOI [arXiv:2006.11328, 10.48550/arXiv.2006.11328]; Smith LN, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.880729; Snell J, 2017, ADV NEUR IN, V30; Sümer Ö, 2023, STUD HEALTH TECHNOL, V302, P932, DOI 10.3233/SHTI230312; Sunder V, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7633, DOI 10.1109/ICASSP39728.2021.9413405; Sussman GJ, 1997, AI Memos; Tambwekar A, 2021, IEEE INT CONF COMP V, P3063, DOI 10.1109/ICCVW54120.2021.00341; Tao R, 2022, Towards class-balanced transductive few-shot learning; Tavallaee M., 2009, 2009 IEEE S COMP INT, P1, DOI [DOI 10.1109/CISDA.2009.5356528, 10.1109/CISDA.2009.5356528]; Tax D.M.J., 2001, Ph.D. Thesis; Thong Hoang, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P34, DOI 10.1109/MSR.2019.00016; Tian Y., 2020, MED IM COMP COMP ASS, V2266, P274, DOI [DOI 10.48550/ARXIV.2006.14811, 10.1007/978-3-030-59725-2_27]; Tolstikhin I., 2017, arXiv; Triantafillou E, 2019, Meta-dataset: a dataset of datasets for learning to learn from few examples.; Triantafillou E, 2017, ADV NEUR IN, V30; Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914; Van Hulse J., 2007, P 24 INT C MACH LEAR, P935, DOI DOI 10.1145/1273496.1273614; Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190; Veilleux O., 2021, Adv. Neural Inf. Process. Syst, V34, P9290; Vinyals O, 2016, 30 C NEURAL INFORM P, V29; Olson AW, 2020, Arxiv, DOI [arXiv:2010.13850, 10.48550/arxiv.2010.13850, DOI 10.48550/ARXIV.2010.13850]; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929; Wang X, 2020, Arxiv, DOI arXiv:2003.06957; Wang Y, 2023, Exploring vision-language models for imbalanced learning, DOI [10.1007/s11263-023-01868-w, DOI 10.1007/S11263-023-01868-W]; Wang Y, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14143255; Wang Y, 2023, NEURAL COMPUT APPL, V35, P10751, DOI 10.1007/s00521-023-08262-0; Weng W-H., 2020, Machine Learning for Health, P415; Wenjuan G, 2022, ACM transactions on multimedia computing, communications and applications; Wertheimer D, Few-shot learning in long-tailed settings; Wertheimer D, 2019, PROC CVPR IEEE, P6551, DOI 10.1109/CVPR.2019.00672; Wolters P, 2023, Arxiv, DOI arXiv:2107.13616; Wu Chunpeng, 2022, 2022 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)., P275, DOI 10.1109/ICCCBDA55098.2022.9778859; Wu GL, 2021, AAAI CONF ARTIF INTE, V35, P2889; Wu XY, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24070936; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xinting Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14042, DOI 10.1109/CVPR42600.2020.01406; Yang HQ, 2022, PROC CVPR IEEE, P7581, DOI 10.1109/CVPR52688.2022.00744; Ye CK, 2022, INT C PATT RECOG, P2078, DOI 10.1109/ICPR56361.2022.9956666; Yu T., 2022, Center loss guided prototypical networks for unbalance few-shot industrial fault diagnosis. Mobile information systems; Yuan Y, 2020, IEEE WINT CONF APPL, P3578, DOI [10.1109/WACV45572.2020.9093521, 10.1109/wacv45572.2020.9093521]; Zhai XH, 2022, PROC CVPR IEEE, P18102, DOI 10.1109/CVPR52688.2022.01759; Zhan Z, 2022, COMPUT IND, V138, DOI 10.1016/j.compind.2022.103628; Zhang LB, 2020, IEEE J-STARS, V13, P2778, DOI 10.1109/JSTARS.2020.2995703; Zhang L, 2021, PROC CVPR IEEE, P14419, DOI 10.1109/CVPR46437.2021.01419; Zhang SY, 2021, PROC CVPR IEEE, P2361, DOI 10.1109/CVPR46437.2021.00239; Zhang ZH, 2020, PROCEEDINGS OF 2020 3RD INTERNATIONAL CONFERENCE ON UNMANNED SYSTEMS (ICUS), P1152, DOI 10.1109/ICUS50048.2020.9274981; Zhou JH, 2021, Arxiv, DOI [arXiv:2103.10130, DOI 10.48550/ARXIV.2103.10130, 10.48550/arxiv.2103.10130]; Zhu LC, 2020, PROC CVPR IEEE, P4343, DOI 10.1109/CVPR42600.2020.00440; Ziko I, 2020, ICML	142	0	0	11	11	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2196-1115		J BIG DATA-GER	J. Big Data	JAN 2	2024	11	1							1	10.1186/s40537-023-00851-z	http://dx.doi.org/10.1186/s40537-023-00851-z			37	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EG4A2		gold			2024-07-03	WOS:001137743700004
J	Lai, NS; Tew, YS; Zhong, XL; Yin, J; Li, JL; Yan, BH; Wang, XA				Lai, Nung Siong; Tew, Yi Shen; Zhong, Xialin; Yin, Jun; Li, Jiali; Yan, Binhang; Wang, Xiaonan			Artificial Intelligence (AI) Workflow for Catalyst Design and Optimization	INDUSTRIAL & ENGINEERING CHEMISTRY RESEARCH			English	Article							BAYESIAN OPTIMIZATION	In the pursuit of novel catalyst development to address pressing environmental concerns and energy demand, conventional design and optimization methods often fall short due to the complexity and vastness of the catalyst parameter space. The advent of Machine Learning (ML) has ushered in a new era in the field of catalyst optimization, offering potential solutions to the shortcomings of traditional techniques. However, existing methods fail to effectively harness the vast information contained within the expanding body of scientific literature on catalyst synthesis. To address this gap, this study proposes an innovative Artificial Intelligence (AI) workflow that integrates large-language models (LLMs), Bayesian optimization, and an active learning loop to expedite and enhance catalyst optimization. Our methodology combines advanced language understanding with robust optimization strategies, effectively translating knowledge extracted from the diverse literature into actionable parameters for practical experimentation and optimization. In this article, we demonstrate the application of this AI workflow in the optimization of catalyst synthesis for ammonia production. The results underscore the workflow's ability to streamline the catalyst development process, offering a swift, resource-efficient, and high-precision alternative to conventional methods.	[Lai, Nung Siong; Tew, Yi Shen; Zhong, Xialin; Yan, Binhang; Wang, Xiaonan] Tsinghua Univ, Dept Chem Engn, Beijing 100084, Peoples R China; [Yin, Jun; Li, Jiali] Natl Univ Singapore, Dept Chem & Biomol Engn, Singapore 117576, Singapore	Tsinghua University; National University of Singapore	Wang, XA (corresponding author), Tsinghua Univ, Dept Chem Engn, Beijing 100084, Peoples R China.	wangxiaonan@tsinghua.edu.cn	Wang, Xiaonan/T-1102-2017; Jun, Yin/KLG-3017-2024; Yan, Binhang/HPB-7612-2023	Wang, Xiaonan/0000-0001-9775-2417; Jun, Yin/0000-0002-8993-3178; Yan, Binhang/0000-0003-2833-8022	National Key R&D Program of China [2022ZD0117501]	National Key R&D Program of China	This work is supported by the National Key R&D Program of China (No. 2022ZD0117501).	Alpaydin E., 2016, MACHINE LEARNING THE; Banu A, 2020, INT J ADV MANUF TECH, V106, P4247, DOI 10.1007/s00170-020-04923-9; BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34; Cernak T, 2017, J MED CHEM, V60, P3594, DOI 10.1021/acs.jmedchem.6b01543; Chen DX, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-022-00959-5; Couckuyt I, 2014, J GLOBAL OPTIM, V60, P575, DOI 10.1007/s10898-013-0118-2; Daulton S., 2020, Advances in Neural Information Processing Systems, V33, P9851, DOI DOI 10.48550/ARXIV.2006.05078; Ertl G., 1997, HDB HETEROGENEOUS CA; Fechete I, 2012, CATAL TODAY, V189, P2, DOI 10.1016/j.cattod.2012.04.003; Feng K, 2022, ACS CATAL, V12, P4696, DOI 10.1021/acscatal.2c00583; Garnett R., 2023, Bayesian Optimization; Garrido-Merchán EC, 2020, NEUROCOMPUTING, V380, P20, DOI 10.1016/j.neucom.2019.11.004; Gong FM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207595; Greenhill S, 2020, IEEE ACCESS, V8, P13937, DOI 10.1109/ACCESS.2020.2966228; Gunantara N, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1502242; Hao J, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141811274; Hargreaves J. S., 2022, HETEROGENEOUS CATALY; Häse F, 2018, CHEM SCI, V9, P7642, DOI 10.1039/c8sc02239a; Hickman RJ, 2023, REACT CHEM ENG, V8, P2284, DOI 10.1039/d3re00008g; Humphreys J, 2021, ADV ENERG SUST RES, V2, DOI 10.1002/aesr.202000043; Jablonka K. M., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-fw8n4, DOI 10.26434/CHEMRXIV-2023-FW8N4]; Joly JF, 2013, CATAL TODAY, V218, P153, DOI 10.1016/j.cattod.2013.09.010; Joshi H, 2022, CHEM-ING-TECH, V94, P1645, DOI 10.1002/cite.202200071; Khatamsaz D, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01006-7; Khatamsaz D, 2022, ACTA MATER, V236, DOI 10.1016/j.actamat.2022.118133; Lendrem D, 2001, ORG PROCESS RES DEV, V5, P324, DOI 10.1021/op000025i; Li YA, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102513; Loh WL, 1996, ANN STAT, V24, P2058, DOI 10.1214/aos/1069362310; Mao A., 2023, PREPRINT; Norskov JK, 2009, NAT CHEM, V1, P37, DOI [10.1038/NCHEM.121, 10.1038/nchem.121]; Okazawa K, 2022, ACS OMEGA, V7, P45403, DOI 10.1021/acsomega.2c05988; OpenAI, 2022, Introducing chatgpt; Owen MR, 2001, ORG PROCESS RES DEV, V5, P308, DOI 10.1021/op000024q; Panday R., 2008, THESIS W VIRGINIA U; Pedersen JK., 2021, Angew. Chemie, V1333, P24346, DOI [10.1002/ange.202108116, DOI 10.1002/ANGE.202108116]; Pomberger A, 2022, REACT CHEM ENG, V7, P1368, DOI 10.1039/d2re00008c; Ru B., 2020, INT C MACH LEARN PML, P8276; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Shields BJ, 2021, NATURE, V590, P89, DOI 10.1038/s41586-021-03213-y; Snoek J., 2012, ADV NEURAL INFORM PR; STEIN M, 1987, TECHNOMETRICS, V29, P143, DOI 10.2307/1269769; Taylor CJ, 2023, CHEM REV, V123, P3089, DOI 10.1021/acs.chemrev.2c00798; Torres JAG, 2022, J AM CHEM SOC, DOI 10.1021/jacs.2c08592; Volk AA, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37139-y; Ye TN, 2020, NATURE, V583, P391, DOI 10.1038/s41586-020-2464-9	45	3	3	16	30	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0888-5885	1520-5045		IND ENG CHEM RES	Ind. Eng. Chem. Res.	OCT 12	2023	62	43					17835	17848		10.1021/acs.iecr.3c02520	http://dx.doi.org/10.1021/acs.iecr.3c02520		OCT 2023	14	Engineering, Chemical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	X0IJ9		Green Submitted			2024-07-03	WOS:001092855500001
C	Scells, H; Schlatt, F; Potthast, M			ACM	Scells, Harrisen; Schlatt, Ferdinand; Potthast, Martin			Smooth Operators for Effective Systematic Review Queries	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		systematic reviews; Boolean queries; retrieval models	INFORMATION-RETRIEVAL; MODEL; WORKLOAD	Effective queries are crucial to minimising the time and cost of medical systematic reviews, as all retrieved documents must be judged for relevance. Boolean queries, developed by expert librarians, are the standard for systematic reviews. They guarantee reproducible and verifiable retrieval and more control than free-text queries. However, the result sets of Boolean queries are unranked and difficult to control due to the strict Boolean operators. We address these problems in a single unified retrieval model by formulating a class of smooth operators that are compatible with and extend existing Boolean operators. Our smooth operators overcome several short-comings of previous extensions of the Boolean retrieval model. In particular, our operators are independent of the underlying ranking function, so that exact-match and large language model rankers can be combined in the same query. We found that replacing Boolean operators with equivalent or similar smooth operators often improves the effectiveness of queries. Their properties make tuning a query to precision or recall intuitive and allow greater control over how documents are retrieved. This additional control leads to more effective queries and reduces the cost of systematic reviews.	[Scells, Harrisen; Potthast, Martin] Univ Leipzig, Leipzig, Germany; [Schlatt, Ferdinand] Friedrich Schiller Univ Jena, Jena, Germany; [Potthast, Martin] ScaDS AI, Leipzig, Germany	Leipzig University; Friedrich Schiller University of Jena	Scells, H (corresponding author), Univ Leipzig, Leipzig, Germany.			Schlatt, Ferdinand/0000-0002-6032-909X; Scells, Harrisen/0000-0001-9578-7157	Alexander von Humboldt Stiftung Research Fellowship; European Commission [GA 101070014]	Alexander von Humboldt Stiftung Research Fellowship(Alexander von Humboldt Foundation); European Commission(European Union (EU)European Commission Joint Research Centre)	Dr Harrisen Scells is the recipient of an Alexander von Humboldt Stiftung Research Fellowship. Thiswork was partially funded by the European Commission under GA 101070014 (OpenWebSearch.EU). The authors wish to thank Lukas Gienapp, Theresa Elstner, and Niklas Deckers for their feedback on early revisions of this paper. The authors also wish to thank the reviewers for their helpful and insightful feedback on this paper.	Alharbi A, 2020, J AM MED INFORM ASSN, V27, P1658, DOI 10.1093/jamia/ocaa148; Alharbi Amal, 2018, CEUR WORKSHOP P WORK, V2125; Ananiadou S, 2009, SOC SCI COMPUT REV, V27, P509, DOI 10.1177/0894439309332293; [Anonymous], 2006, P 15 ACM INT C INF K, DOI [DOI 10.1145/1183614.1183671, 10.1145/1183614.1183671]; BOOKSTEIN A, 1980, J AM SOC INFORM SCI, V31, P240, DOI 10.1002/asi.4630310403; BORDOGNA G, 1993, J AM SOC INFORM SCI, V44, P70, DOI 10.1002/(SICI)1097-4571(199303)44:2<70::AID-ASI2>3.0.CO;2-I; BUELL DA, 1981, INFORM PROCESS MANAG, V17, P249, DOI 10.1016/0306-4573(81)90019-4; Chaumond Julien, 2019, P 33 C NEURAL INFORM; Clark J., 2013, Methods of Clinical Epidemiology, P187, DOI DOI 10.1007/978-3-642-37131-812; Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929; Cormack GV, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P758, DOI 10.1145/1571941.1572114; Cormack Gordon V, 2018, CEUR Workshop Proceedings: Working Notes of CLEF 2018: Conference and Labs of the Evaluation Forum; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Higgins JPT, 2020, COCHRANE HDB SYSTEMA; Hofstätter S, 2022, LECT NOTES COMPUT SC, V13186, P144, DOI 10.1007/978-3-030-99739-7_17; Hsu DF, 2005, INFORM RETRIEVAL, V8, P449, DOI 10.1007/s10791-005-6994-4; Kanoulas Evangelos, 2017, CEUR WORKSHOP P WORK; Kanoulas Evangelos, 2019, CEUR WORKSHOP P WORK, V2380; Kanoulas Evangelos, 2018, CEUR WORKSHOP P WORK; Karimi Sarvnaz, 2009, P 3 INT WORKSH DAT T, P89, DOI DOI 10.1145/1651318.1651338; Kim Y, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P825; Lee GE, 2018, ACM/SIGIR PROCEEDINGS 2018, P455, DOI 10.1145/3209978.3209994; Lipscomb CE, 2000, B MED LIBR ASSOC, V88, P265; LOSEE R, 1987, J AM SOC INFORM SCI, V38, P239, DOI 10.1002/(SICI)1097-4571(198707)38:4<239::AID-ASI4>3.0.CO;2-6; Martinez D., 2008, Proceedings of the 13th Australasian Document Computing Symposium; Michelson M, 2019, CONT CLIN TRIAL COMM, V16, DOI 10.1016/j.conctc.2019.100443; Minas Adamantios, 2018, CEUR WORKSHOP P WORK; Miwa M, 2014, J BIOMED INFORM, V51, P242, DOI 10.1016/j.jbi.2014.06.005; National Library of Medicine (US), 1963, Medical Subject Headings: Main Headings, Sub-headings, and Cross References Used in the Index Medicus and the National Library of Medicine Catalog; O'Mara-Eves A, 2015, SYST REV-LONDON, V4, DOI 10.1186/2046-4053-4-5; PAICE CD, 1984, INFORM TECHNOL R & D, V3, P33; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pohl Stefan, 2010, Computer Science, V102; Przybyla P, 2018, RES SYNTH METHODS, V9, P470, DOI 10.1002/jrsm.1311; RADECKI T, 1979, INFORM PROCESS MANAG, V15, P247, DOI 10.1016/0306-4573(79)90031-1; Rekabsaz N, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2507, DOI 10.1145/3404835.3463242; ROBERTSON SE, 1977, J DOC, V33, P294, DOI 10.1108/eb026647; SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466; Salton G., 1982, Technical Report; Scells Harrisen, 2022, ICTIR '22: Proceedings of the 2022 ACM SIGIR International Conference on Theory of Information Retrieval, P34, DOI 10.1145/3539813.3545143; Scells Harrisen, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P399, DOI 10.1007/978-3-030-45439-5_27; Scells H, 2021, INFORM RETRIEVAL J, V24, P3, DOI 10.1007/s10791-020-09381-1; Scells H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1646, DOI 10.1145/3308558.3313544; Scells H, 2018, ACM/SIGIR PROCEEDINGS 2018, P475, DOI 10.1145/3209978.3210020; Scells Harrisen, 2023, P 46 INT RETRIEVAL A; Scells Harrisen, 2019, P 2019 COCHR C; Shaw J. A., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P105; Shemilt I, 2014, RES SYNTH METHODS, V5, P31, DOI 10.1002/jrsm.1093; Smith Maria, 1990, Aspects of the P-Norm Model of Information Retrieval: Syntactic Query Generation, Efficiency, and Theoretical Properties; Stansfield CM, 2015, Journal of the European Association for Health Information and Libraries, V11, P8; Cormack GV, 2015, Arxiv, DOI arXiv:1504.06868; Vogt C. C., 1999, Information Retrieval, V1, P151, DOI 10.1023/A:1009980820262; Wallace BC., 2012, P 2 ACM SIGHIT INT H, P819, DOI [DOI 10.1145/2110363.2110464, 10.1145/2110363.2110464]; Wallace BC, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-55; WALLER WG, 1979, INFORM PROCESS MANAG, V15, P235, DOI 10.1016/0306-4573(79)90030-X; Wang S, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON FLEXIBLE AND PRINTABLE SENSORS AND SYSTEMS (FLEPS), DOI 10.1109/FLEPS51544.2021.9469747; Wang S., 2022, Intell. Syst. with Appl., V16; Wang S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3176, DOI 10.1145/3477495.3531748; Wang Shuai, 2022, Neural Rankers for Effective Screening Prioritisation in Medical Systematic Review Literature Search, DOI [10.1145/3572960.3572980, DOI 10.1145/3572960.3572980]; Wu Huaying, 2018, Methodsa Companion to Methods in Enzymology, V4, P5; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	62	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							580	590		10.1145/3539618.3591768	http://dx.doi.org/10.1145/3539618.3591768			11	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG					2024-07-03	WOS:001118084000060
C	Dzeparoska, K; Lin, JY; Tizghadam, A; Leon-Garcia, A		Boutaba, R; Chemouil, P; Limam, N; Ghaderi, M; Badonnel, R; Fulber-Garcia, V		Dzeparoska, Kristina; Lin, Jieyu; Tizghadam, Ali; Leon-Garcia, Alberto			LLM-based policy generation for intent-based management of applications	2023 19TH INTERNATIONAL CONFERENCE ON NETWORK AND SERVICE MANAGEMENT, CNSM	International Conference on Network and Service Management		English	Proceedings Paper	19th International Conference on Network and Service Management (CNSM) - Network and Service Management in the Era of Generative AI and Digital Twins	OCT 30-NOV 02, 2023	Niagara Falls, CANADA	IEEE, IEEE Commun Soc, ACM SIGCOMM, IFIP, ACM In Cooperat, IFIP Working Grp 6 6 Network & Distributed Syst Management, IEEE Commun Soc Comm Network Operat & Management			NETWORKS	Automated management requires decomposing high-level user requests, such as intents, to an abstraction that the system can understand and execute. This is challenging because even a simple intent requires performing a number of ordered steps. And the task of identifying and adapting these steps (as conditions change) requires a decomposition approach that cannot be exactly pre-defined beforehand. To tackle these challenges and support automated intent decomposition and execution, we explore the few-shot capability of Large Language Models (LLMs). We propose a pipeline that progressively decomposes intents by generating the required actions using a policy-based abstraction. This allows us to automate the policy execution by creating a closed control loop for the intent deployment. To do so, we generate and map the policies to APIs and form application management loops that perform the necessary monitoring, analysis, planning and execution. We evaluate our proposal with a usecase to fulfill and assure an application service chain of virtual network functions. Using our approach, we can generalize and generate the necessary steps to realize intents, thereby enabling intent automation for application management.	[Dzeparoska, Kristina; Lin, Jieyu; Tizghadam, Ali; Leon-Garcia, Alberto] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada	University of Toronto	Dzeparoska, K (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.	kristina.dzeparoska@mail.utoronto.ca; jieyu.lin@mail.utoronto.ca; ali.tizghadam@utoronto.ca; alberto.leongarcia@utoronto.ca						[Anonymous], 2021, Metro Ethernet Forum; Bezahaf M, 2021, PROCEEDINGS OF THE 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2021): ACCELERATING NETWORK SOFTWARIZATION IN THE COGNITIVE AGE, P31, DOI 10.1109/NetSoft51509.2021.9492554; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cesila CH, 2023, IEEE Confer on Netwo, P534, DOI 10.1109/NetSoft57336.2023.10175491; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clemm A, 2022, RFC 9315; Dzeparoska K, 2021, IEEE ACCESS, V9, P159882, DOI 10.1109/ACCESS.2021.3129990; Jacobs AS, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P625; Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055; Kiran M, 2018, FUTURE GENER COMP SY, V79, P205, DOI 10.1016/j.future.2017.04.020; Leivadeas A, 2023, IEEE COMMUN SURV TUT, V25, P625, DOI 10.1109/COMST.2022.3215919; Lin JY, 2023, IEEE Confer on Netwo, P539, DOI 10.1109/NetSoft57336.2023.10175410; Mahtout Hocine, 2020, SNTA '20: Proceedings of the 3rd International Workshop on Systems and Network Telemetry and Analytics, P27, DOI 10.1145/3391812.3396269; Nguyent MTA, 2022, IEEE ICC, P2972, DOI 10.1109/ICC45855.2022.9838633; OpenAI, 2023, GPT-4 Technical Report; Ouyang Y, 2021, IEEE NETWORK, V35, P75, DOI 10.1109/MNET.001.2100194; Pang L, 2020, IEEE ACCESS, V8, P22862, DOI 10.1109/ACCESS.2020.2969208; Tian BC, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P214, DOI 10.1145/3341302.3342088; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Vedula N, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2009, DOI 10.1145/3366423.3380268; Yang CA, 2023, IEEE COMMUN MAG, V61, P106, DOI 10.1109/MCOM.002.2200119; Zeydan Engin, 2020, 2020 IEEE 91 VEH TEC, P1	23	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2165-9605		978-3-903176-59-1	INT CONF NETW SER			2023														7	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering; Telecommunications	BW2KT					2024-07-03	WOS:001117985100029
C	Pal, V; Yates, A; Kanoulas, E; de Rijke, M		Rogers, A; Boyd-Graber, J; Okazaki, N		Pal, Vaishali; Yates, Andrew; Kanoulas, Evangelos; de Rijke, Maarten			MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Recent advances in tabular question answering (QA) with large language models are constrained in their coverage and only answer questions over a single table. However, real-world queries are complex in nature, often over multiple tables in a relational database or web page. Single table questions do not involve common table operations such as set operations, Cartesian products (joins), or nested queries. Furthermore, multi-table operations often result in a tabular output, which necessitates table generation capabilities of tabular QA models. To fill this gap, we propose a new task of answering questions over multiple tables. Our model, MultiTabQA, not only answers questions over multiple tables, but also generalizes to generate tabular answers. To enable effective training, we build a pre-training dataset comprising of 132,645 SQL queries and tabular answers. Further, we evaluate the generated tables by introducing table-specific metrics of varying strictness assessing various levels of granularity of the table structure. MultiTabQA outperforms state-of-the-art single table QA models adapted to a multi-table QA setting by finetuning on three datasets: Spider, Atis and GeoQuery.	[Pal, Vaishali; Yates, Andrew; Kanoulas, Evangelos; de Rijke, Maarten] Univ Amsterdam, Amsterdam, Netherlands; [Pal, Vaishali] Elsevier, Discovery Lab, Amsterdam, Netherlands	University of Amsterdam; Reed Elsevier; Elsevier	Pal, V (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.; Pal, V (corresponding author), Elsevier, Discovery Lab, Amsterdam, Netherlands.	v.pal@uva.nl; a.c.yates@uva.nl; e.kanoulas@uva.nl; m.derijke@uva.nl		de Rijke, Maarten/0000-0002-1086-0202	Elsevier's Discovery Lab; Dutch Research Council (NWO) [016.Vidi.189.039, 314-99-301]; H2020-EU.3.4. Societal Challenges, Smart, Green and Integrated Transport [814961]; Hybrid Intelligence Center, a 10-year program - Dutch Ministry of Education, Culture and Science through NWO	Elsevier's Discovery Lab; Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO)); H2020-EU.3.4. Societal Challenges, Smart, Green and Integrated Transport(European Union (EU)H2020 Societal Challenges Programme); Hybrid Intelligence Center, a 10-year program - Dutch Ministry of Education, Culture and Science through NWO	We thank Elsevier's Discovery Lab for their support throughout this project and funding this work. This work was also supported by the Dutch Research Council (NWO) under project numbers 016.Vidi.189.039 and 314-99-301, by H2020-EU.3.4. Societal Challenges, Smart, Green and Integrated Transport (814961), and by the Hybrid Intelligence Center, a 10-year program funded by the Dutch Ministry of Education, Culture and Science through NWO, https://hybrid-intelligence-centre.nl.All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.	Andrejczuk Ewa, 2022, arXiv preprint arXiv:2210.09162; [Anonymous], 2015, ARXIV150800305; Bengio Y., 2009, ICML, P41, DOI DOI 10.1145/1553374.1553380; Cai Zefeng, 2022, ARXIV221011888; Chen Jieying, 2013, P 7 INT WORKSH DAT M; Cheng Zhoujun, 2021, ARXIV210806712; Cheng Zhoujun, 2021, ARXIV210907323; Dahl D.A., 1994, HUMAN LANGUAGE TECHN; Eisenschlos JM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7606; Gu Zihui, 2022, ARXIV221102816; Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320; Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089; Jain P., 2018, NAACL HLT, V2, P622; Jena Aashna, 2022, FINDINGS ASS COMPUTA, P4512; Jin Nengzheng, 2022, ARXIV220705270; Lee CH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2261; Liu Qian, 2021, ARXIV210707653; Liu Ruixue, 2022, P 29 INT C COMP LING, P3741; Ma KX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1605; Nan Linyong, 2021, ARXIV210400369; Pal KK, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P3095; Pal V, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P41; Price P, 1990, SPEECH NATURAL LANGU; Shankarampeta Abhilash, 2022, P 2 C AS PAC CHAPT A, P706; Shi TZ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1849; Shigarov A, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1482; Wu XQ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2518; Yin Pengcheng, 2020, P 58 ANN M ASS COMPU, P8413, DOI [DOI 10.18653/V1/2020.ACL, 10.18653/v1/2020.acl-main.745, DOI 10.18653/V1/2020.ACL-MAIN.745]; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Yu Tao, 2021, INT C LEARN REPR; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zhang S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1537, DOI 10.1145/3397271.3401205; Zhong V., 2017, ARXIV170900103; Zhou Fan, 2022, ARXIV220512682; Zhou Yuxuan, 2022, ARXIV220408753; Zhu Fengbin, 2021, ARXIV210507624	36	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							6322	6334						13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086805018
J	Ghimire, P; Kim, K; Acharya, M				Ghimire, Prashnna; Kim, Kyungki; Acharya, Manoj			Opportunities and Challenges of Generative AI in Construction Industry: Focusing on Adoption of Text-Based Models	BUILDINGS			English	Article						generative AI; implementation framework; construction; AEC; GPT; LLM; PaLM; Llama; fine-tuning	MANAGEMENT; LOGISTICS; NETWORKS; DISPUTES	In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLMs) like OpenAI's GPT, Google's PaLM, and Meta's Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI's early stage adoption within the construction sector. Given GenAI's unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors' opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture and engineering domains.	[Ghimire, Prashnna; Kim, Kyungki] Univ Nebraska Lincoln, Durham Sch Architectural Engn & Construct, Dept Architectural Engn, Lincoln, NE 68588 USA; [Acharya, Manoj] SRI Int, Menlo Pk, CA 94025 USA	University of Nebraska System; University of Nebraska Lincoln; SRI International	Ghimire, P (corresponding author), Univ Nebraska Lincoln, Durham Sch Architectural Engn & Construct, Dept Architectural Engn, Lincoln, NE 68588 USA.	pghimire3@huskers.unl.edu; kkim13@unl.edu; manoj.acharya@sri.com		Ghimire, Prashnna/0009-0000-2689-9905				Abioye SO, 2021, J BUILD ENG, V44, DOI 10.1016/j.jobe.2021.103299; Afzal F, 2021, INT J MANAG PROJ BUS, V14, P300, DOI 10.1108/IJMPB-02-2019-0047; AI Caucus Leaders, Introduce Bipartisan Bill to Expand Access to AI Research; Akepanidtaworn K., 2023, Medium; Al Qady M, 2010, J CONSTR ENG M, V136, P294, DOI 10.1061/(ASCE)CO.1943-7862.0000131; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; Andenæs E, 2020, BUILDINGS-BASEL, V10, DOI 10.3390/buildings10100189; [Anonymous], Activity. Dr. Bradley Hyatt; [Anonymous], 2023, GPT-3; [Anonymous], Survey of Generative AI in Architecture and Design; [Anonymous], Finetuning Large Language Models-DeepLearning; Baduge SK, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104440; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Balmer VM, 2022, Arxiv, DOI [arXiv:2211.16406, DOI 10.48550/ARXIV.2211.16406]; Bassir David, 2023, International Journal for Simulation and Multidisciplinary Design Optimization, DOI 10.1051/smdo/2023005; Becerik-Gerber B, 2012, J CONSTR ENG M, V138, P431, DOI 10.1061/(ASCE)CO.1943-7862.0000433; Bengio Y, 2001, ADV NEUR IN, V13, P932; Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134; Bloch T, 2018, AUTOMAT CONSTR, V91, P256, DOI 10.1016/j.autcon.2018.03.018; Bock T, 2007, AUTON ROBOT, V22, P201, DOI 10.1007/s10514-006-9008-5; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao Y, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000784; Chen JH, 2008, AUTOMAT CONSTR, V17, P773, DOI 10.1016/j.autcon.2008.02.005; Chen JD, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000628; Chen JM, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13071861; Cheng MY, 2009, AUTOMAT CONSTR, V18, P164, DOI 10.1016/j.autcon.2008.07.001; Chokwitthaya C, 2019, Arxiv, DOI arXiv:1906.05767; Chou JS, 2013, J COMPUT CIVIL ENG, V27, P51, DOI 10.1061/(ASCE)CP.1943-5487.0000197; Choudhari S, 2017, CONSTR INNOV-ENGL, V17, P158, DOI 10.1108/CI-03-2016-0014; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chua DKH, 2005, J CONSTR ENG M, V131, P715, DOI 10.1061/(ASCE)0733-9364(2005)131:6(715); Chung SH, 2023, AUTOMAT CONSTR, V154, DOI 10.1016/j.autcon.2023.105020; Cohn C., 2023, Towards a Formative Feedback Generation Agent: Leveraging a Human-in-the-Loop, Chain-of-Thought Prompting Approach with LLMs to Evaluate Formative Assessment Responses in K-12 Science; Coskuner G, 2021, WASTE MANAGE RES, V39, P499, DOI 10.1177/0734242X20935181; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Dai SC, 2023, Arxiv, DOI arXiv:2310.15100; Darko A, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103081; Debrah C, 2022, AUTOMAT CONSTR, V137, DOI 10.1016/j.autcon.2022.104192; Delgado JMD, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107836; Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]; Dinh L, 2017, Arxiv, DOI [arXiv:1605.08803, DOI 10.48550/ARXIV.1605.08803]; Doersch C, 2021, Arxiv, DOI arXiv:1606.05908; Dogru T, 2023, J HOSP TOUR RES, DOI 10.1177/10963480231188663; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; El Zini J, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3529755; Elfahham Y, 2019, ALEX ENG J, V58, P499, DOI 10.1016/j.aej.2019.05.002; Fang WL, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103013; Fang Y, 2019, ENG CONSTR ARCHIT MA, V26, P2289, DOI 10.1108/ECAM-09-2018-0386; Fathi S, 2020, RENEW SUST ENERG REV, V133, DOI 10.1016/j.rser.2020.110287; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fui-Hoon Nah F, 2023, J. Inf. Technol. Case Appl. Res, V25, P277, DOI [DOI 10.1080/15228053.2023.2233814, 10.1080/15228053.2023.2233814]; georgeho, Autoregressive Models in Deep Learning-A Brief Survey; Ghimire P., 2023, P 2 INT C CONSTRUCTI; Goel R, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCCI50826.2021.9402337; Goh YM, 2013, CONSTR MANAG ECON, V31, P460, DOI 10.1080/01446193.2013.797095; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Google AI, PaLM 2-Google AI; Gozalo-Brizuela R., 2023, arXiv; Guan L, 2023, Arxiv, DOI arXiv:2305.14909; Hassan HAM, 2022, LECT NOTES COMPUT SC, V13286, P215, DOI 10.1007/978-3-031-08473-7_20; Hatami M, 2022, COMPUTING IN CIVIL ENGINEERING 2021, P1171; Hatami M, 2022, CONSTRUCTION RESEARCH CONGRESS 2022: COMPUTER APPLICATIONS, AUTOMATION, AND DATA ANALYTICS, P1298; Heimerl F, 2014, P ANN HICSS, P1833, DOI 10.1109/HICSS.2014.231; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hoskere Vedhus., 2018, VISION BASED STRUCTU; Hu WF, 2008, 2008 INTERNATIONAL SEMINAR ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, PROCEEDINGS, P372, DOI 10.1109/FITME.2008.142; Huang D, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P425, DOI 10.1109/MIPR.2019.00086; Jang S, 2023, Arxiv, DOI [arXiv:2306.14165, 10.48550/arXiv.2306.14165 2306.14165, DOI 10.48550/ARXIV.2306.141652306.14165]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kabir A.I., 2020, Inform. Econ, V24, P55, DOI DOI 10.24818/ISSN14531305/24.4.2020.05; Kammoun A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527850; Kar AK, 2022, J CLEAN PROD, V376, DOI 10.1016/j.jclepro.2022.134120; Kazerouni A, 2023, Arxiv, DOI arXiv:2211.07804; Kim J., 2019, P 2019 INT COUNCIL R; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Kuang WR, 2023, Arxiv, DOI arXiv:2309.00363; Kumar M, 2020, Arxiv, DOI arXiv:1903.01434; Kuo CH, 2021, IEEE ACCESS, V9, P50738, DOI 10.1109/ACCESS.2021.3068269; Lee Jieun, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P1241, DOI 10.1145/3503161.3548094; Lei T, 2016, Arxiv, DOI arXiv:1606.04155; Li CL, 2018, IEEE IJCNN; Li Y, 2018, INFORM SCIENCES, V450, P301, DOI 10.1016/j.ins.2018.03.050; Lin SS, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103490; Liu C, 2022, CONSTR INNOV-ENGL, V22, P141, DOI 10.1108/CI-02-2020-0017; Liu JJ, 2022, AUTOMAT CONSTR, V140, DOI 10.1016/j.autcon.2022.104302; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu V, 2023, Arxiv, DOI arXiv:2304.08551; Liu Y, 2023, J MATERIOMICS, V9, P798, DOI 10.1016/j.jmat.2023.05.001; Lu WS, 2021, WASTE MANAGE, V134, P78, DOI 10.1016/j.wasman.2021.08.012; Mahmoodzadeh A, 2022, AUTOMAT CONSTR, V139, DOI 10.1016/j.autcon.2022.104305; Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011; Mehmood MU, 2019, ENERG BUILDINGS, V202, DOI 10.1016/j.enbuild.2019.109383; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mishra S, 2023, Arxiv, DOI [arXiv:2302.07440, 10.48550/arXiv.2302.07440 2302.07440, DOI 10.48550/ARXIV.2302.074402302.07440]; Mo ZB, 2023, LECT NOTES ARTIF INT, V13715, P323, DOI 10.1007/978-3-031-26409-2_20; Moon S, 2022, AUTOMAT CONSTR, V142, DOI 10.1016/j.autcon.2022.104465; Mulero-Palencia S, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13126576; Narazaki Y, 2021, MECH SYST SIGNAL PR, V160, DOI 10.1016/j.ymssp.2021.107850; Nasruddin, 2019, SUSTAIN ENERGY TECHN, V35, P48, DOI 10.1016/j.seta.2019.06.002; NLTK, Natural Language Toolkit; openai, GPT-4; Oyediran H., 2021, P INT S AUTOMATION R; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Pan M, 2022, J CONSTR ENG M, V148, DOI 10.1061/(ASCE)CO.1943-7862.0002324; Paneru S, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13020552; Paneru S, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103940; Pantoja-Rosero BG, 2022, CONSTR BUILD MATER, V344, DOI 10.1016/j.conbuildmat.2022.128264; Patton DU, 2023, J SOC SOC WORK RES, V14, P553, DOI 10.1086/726042; Piñeiro-Martín A, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12143170; Ploennigs J, 2024, Arxiv, DOI arXiv:2307.02511; Poh CQX, 2018, AUTOMAT CONSTR, V93, P375, DOI 10.1016/j.autcon.2018.03.022; Pokharel S, 2023, ENVIRON MODELL SOFTW, V166, DOI 10.1016/j.envsoft.2023.105730; Pournader M, 2021, INT J PROD ECON, V241, DOI 10.1016/j.ijpe.2021.108250; Prieto SA, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13040857; Qwiklabs, Introduction to Generative AI; Rahimian FP, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103012; Sacks R, 2020, DEV BUILT ENVIRON, V4, DOI 10.1016/j.dibe.2020.100011; Saka A, 2023, Arxiv, DOI arXiv:2305.18997; Saka AB, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2022.101869; Sakhakarmi S, 2019, J CONSTR ENG M, V145, DOI 10.1061/(ASCE)CO.1943-7862.0001601; Sanni-Anibire MO, 2022, INT J CONSTR MANAG, V22, P2134, DOI 10.1080/15623599.2020.1768326; Saravanan Vignesh, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P1218, DOI 10.1109/CSCI46756.2018.00234; Schneider F., 2023, arXiv; Semaan N, 2017, ENG CONSTR ARCHIT MA, V24, P61, DOI 10.1108/ECAM-06-2015-0094; Seo J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207347; Sha A., 2023, 12 Best Large Language Models (LLMs); Spencer BF, 2019, ENGINEERING-PRC, V5, P199, DOI 10.1016/j.eng.2018.11.030; Succar B, 2009, AUTOMAT CONSTR, V18, P357, DOI 10.1016/j.autcon.2008.10.003; Tan K, 2018, MATEC WEB CONF, V206, DOI 10.1051/matecconf/201820601008; Teizer J, 2015, ADV ENG INFORM, V29, P225, DOI 10.1016/j.aei.2015.03.006; textblob.readthedocs, TextBlob: Simplified Text Processing; Thanaki J., 2017, Python natural language processing; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Van T.N., 2021, J. Appl. Sci. Technol. Trends, V2, P96; Vaswani A, 2017, ADV NEUR IN, V30; Vencer Lanz Vincent T., 2023, 2023 8th International Conference on Business and Industrial Research (ICBIR), P392, DOI 10.1109/ICBIR57571.2023.10147684; Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583; Weng L., WHAT ARE DIFFUSION M; Weng L., Flow-Based Deep Generative Models; Williams TP, 2014, AUTOMAT CONSTR, V43, P23, DOI 10.1016/j.autcon.2014.02.014; Wu AN, 2022, BUILD ENVIRON, V223, DOI 10.1016/j.buildenv.2022.109477; Wu T, 2023, Arxiv, DOI arXiv:2305.09515; Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128; Xu GX, 2019, IEEE ACCESS, V7, P51522, DOI 10.1109/ACCESS.2019.2909919; Xu X, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58445; Xu YY, 2021, DEV BUILT ENVIRON, V6, DOI 10.1016/j.dibe.2021.100045; Yang YQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112528; Yaseen ZM, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041514; You A, 2022, EYE VISION, V9, DOI 10.1186/s40662-022-00277-3; You HX, 2023, Arxiv, DOI arXiv:2304.11018; You K, 2023, AUTOMAT CONSTR, V150, DOI 10.1016/j.autcon.2023.104852; Yu KH, 2021, ENVIRON IMPACT ASSES, V86, DOI 10.1016/j.ejar.2020.106492; Yuan Y, 2023, IEEE I CONF COMP VIS, P15964, DOI 10.1109/ICCV51070.2023.01467; Zabin A, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101474; Zhang CS, 2023, Arxiv, DOI arXiv:2303.07909; Zhang C, 2019, BUILDSYS'19: PROCEEDINGS OF THE 6TH ACM INTERNATIONAL CONFERENCE ON SYSTEMS FOR ENERGY-EFFICIENT BUILDINGS, CITIES, AND TRANSPORTATION, P287, DOI 10.1145/3360322.3360861; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zheng JW, 2023, AUTOMAT CONSTR, V155, DOI 10.1016/j.autcon.2023.105067; Zheng JW, 2023, Arxiv, DOI arXiv:2304.09333; Zhu ZH, 2010, AUTOMAT CONSTR, V19, P944, DOI 10.1016/j.autcon.2010.06.008	163	2	2	63	63	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-5309		BUILDINGS-BASEL	BUILDINGS-BASEL	JAN	2024	14	1							220	10.3390/buildings14010220	http://dx.doi.org/10.3390/buildings14010220			29	Construction & Building Technology; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	FX9Z7		gold			2024-07-03	WOS:001149282600001
J	Zheng, ZL; Zhang, OF; Borgs, C; Chayes, JT; Yaghi, OM				Zheng, Zhiling; Zhang, Oufan; Borgs, Christian; Chayes, Jennifer T.; Yaghi, Omar M.			ChatGPT Chemistry Assistant for Text Mining and the Prediction of MOF Synthesis	JOURNAL OF THE AMERICAN CHEMICAL SOCIETY			English	Article							METAL-ORGANIC FRAMEWORKS; RANDOM FOREST; DESIGN; CLASSIFICATION; STABILITY; ENERGY; UNITS; TOOL	We use prompt engineering to guide ChatGPT in the automationoftext mining of metal-organic framework (MOF) synthesis conditionsfrom diverse formats and styles of the scientific literature. Thiseffectively mitigates ChatGPT's tendency to hallucinate information,an issue that previously made the use of large language models (LLMs)in scientific fields challenging. Our approach involves the developmentof a workflow implementing three different processes for text mining,programmed by ChatGPT itself. All of them enable parsing, searching,filtering, classification, summarization, and data unification withdifferent trade-offs among labor, speed, and accuracy. We deploy thissystem to extract 26 257 distinct synthesis parameters pertainingto approximately 800 MOFs sourced from peer-reviewed research articles.This process incorporates our ChemPrompt Engineering strategy to instructChatGPT in text mining, resulting in impressive precision, recall,and F1 scores of 90-99%. Furthermore, with the data set builtby text mining, we constructed a machine-learning model with over87% accuracy in predicting MOF experimental crystallization outcomesand preliminarily identifying important factors in MOF crystallization.We also developed a reliable data-grounded MOF chatbot to answer questionsabout chemical reactions and synthesis procedures. Given that theprocess of using ChatGPT reliably mines and tabulates diverse MOFsynthesis information in a unified format while using only narrativelanguage requiring no coding expertise, we anticipate that our ChatGPTChemistry Assistant will be very useful across various other chemistrysubdisciplines.	[Zheng, Zhiling; Yaghi, Omar M.] Univ Calif Berkeley, Dept Chem, Berkeley, CA 94720 USA; [Zheng, Zhiling; Yaghi, Omar M.] Univ Calif Berkeley, Kavli Energy Nanosci Inst, Berkeley, CA 94720 USA; [Zheng, Zhiling; Borgs, Christian; Chayes, Jennifer T.; Yaghi, Omar M.] Univ Calif Berkeley, Bakar Inst Digital Mat Planet, Coll Comp Data Sci & Soc, Berkeley, CA 94720 USA; [Borgs, Christian; Chayes, Jennifer T.] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Chayes, Jennifer T.] Univ Calif Berkeley, Dept Math, Berkeley, CA 94720 USA; [Chayes, Jennifer T.] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA; [Chayes, Jennifer T.] Univ Calif Berkeley, Sch Informat, Berkeley, CA 94720 USA; [Yaghi, Omar M.] KACST UC, King Abdulaziz City Sci & Technol, Berkeley Ctr Excellence Nanomat Clean Energy Appli, Riyadh 11442, Saudi Arabia	University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley	Yaghi, OM (corresponding author), Univ Calif Berkeley, Dept Chem, Berkeley, CA 94720 USA.; Yaghi, OM (corresponding author), Univ Calif Berkeley, Kavli Energy Nanosci Inst, Berkeley, CA 94720 USA.; Yaghi, OM (corresponding author), Univ Calif Berkeley, Bakar Inst Digital Mat Planet, Coll Comp Data Sci & Soc, Berkeley, CA 94720 USA.; Yaghi, OM (corresponding author), KACST UC, King Abdulaziz City Sci & Technol, Berkeley Ctr Excellence Nanomat Clean Energy Appli, Riyadh 11442, Saudi Arabia.	yaghi@berkeley.edu		Chayes, Jennifer/0000-0003-4020-8618; Borgs, Christian/0000-0001-5653-0498; Yaghi, Omar/0000-0002-5611-3325; Zheng, Zhiling/0000-0001-6090-2258	Defense Advanced Research Projects Agency (DARPA) [HR0011-21-C-0020]; National Institutes of Health (NIH) [5R01GM127627-04]; Kavli ENSI Graduate Student Fellowship; Bakar Institute of Digital Materials for the Planet (BIDMaP); OpenAI	Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Kavli ENSI Graduate Student Fellowship; Bakar Institute of Digital Materials for the Planet (BIDMaP); OpenAI	Z.Z. extends special gratitude to Jiayi Weng (OpenAI) for valuable discussions on harnessing the potential of ChatGPT. In addition, Z.Z. acknowledges the inspiring guidance and input from Kefan Dong (Stanford University), Long Lian (University of California, Berkeley), and Yifan Deng (Carnegie Mellon University), all of whom contributed to shaping the study's design and enhancing the performance of ChatGPT. We express our appreciation to Dr. Nakul Rampal from the Yaghi laboratory for insightful discussions. Our gratitude is also extended for the financial support received from the Defense Advanced Research Projects Agency (DARPA) under contract HR0011-21-C-0020. O.Z. acknowledges funding and extends thanks for the support provided by the National Institutes of Health (NIH) under grant 5R01GM127627-04. Additionally, Z.Z. is grateful for the financial support received through a Kavli ENSI Graduate Student Fellowship and the Bakar Institute of Digital Materials for the Planet (BIDMaP). This work is independently developed by the University of California, Berkeley research team and not affiliated, endorsed, or sponsored by OpenAI.	Ahneman DT, 2018, SCIENCE, V360, P186, DOI 10.1126/science.aar5169; [Anonymous], 2016, CRC Handbook of Chemistry and Physics, V96th; [Anonymous], 2013, NIPS; [Anonymous], 1995, Random Decision Forest, P278; Aspuru-Guzik A, 2018, ACS CENTRAL SCI, V4, P144, DOI 10.1021/acscentsci.7b00550; Batra R, 2020, NAT MACH INTELL, V2, P704, DOI 10.1038/s42256-020-00249-z; Bloch ED, 2011, J AM CHEM SOC, V133, P14814, DOI 10.1021/ja205976v; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bulatov A, 2024, Arxiv, DOI [arXiv:2304.11062, 10.48550/arXiv.2304.11062, DOI 10.48550/ARXIV.2304.11062]; Chen HM, 2018, DRUG DISCOV TODAY, V23, P1241, DOI 10.1016/j.drudis.2018.01.039; Chung YG, 2019, J CHEM ENG DATA, V64, P5985, DOI 10.1021/acs.jced.9b00835; Chung YG, 2014, CHEM MATER, V26, P6185, DOI 10.1021/cm502594j; Colón YJ, 2017, CRYST GROWTH DES, V17, P5801, DOI 10.1021/acs.cgd.7b00848; Dao T., 2022, Advances in Neural Information Processing Systems, V35, P16344, DOI [10.48550/arXiv2205.14135, DOI 10.48550/ARXIV2205.14135]; de Santana FB, 2019, FOOD CHEM, V293, P323, DOI 10.1016/j.foodchem.2019.04.073; Firat M., 2023, Journal of Applied Learning and Teaching, V1, P57; Franklin EB, 2022, ATMOS MEAS TECH, V15, P3779, DOI 10.5194/amt-15-3779-2022; Furukawa H, 2011, INORG CHEM, V50, P9147, DOI 10.1021/ic201376t; Gándara F, 2014, J AM CHEM SOC, V136, P5271, DOI 10.1021/ja501606h; Glasby LT, 2023, CHEM MATER, V35, P4510, DOI 10.1021/acs.chemmater.3c00788; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Gong W, 2022, J AM CHEM SOC, V144, P1826, DOI 10.1021/jacs.1c11836; Hadley M., 2018, PREPRINT, Patent No. [2018070243, 2018040240]; Han Y., Synthesis Methods and Crystallization; IntechOpen, V2020, P1, DOI DOI 10.5772/INTECHOPEN.90435; Hanikel N, 2023, ACS CENTRAL SCI, V9, P551, DOI 10.1021/acscentsci.3c00018; He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553; Hu ZC, 2013, CRYST GROWTH DES, V13, P4204, DOI 10.1021/cg4012185; Jablonka KM, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-fw8n4, 10.26434/chemrxiv-2023-fw8n4, DOI 10.26434/CHEMRXIV-2023-FW8N4]; Jensen Z, 2019, ACS CENTRAL SCI, V5, P892, DOI 10.1021/acscentsci.9b00193; Kaiser TM, 2019, MOLECULES, V24, DOI 10.3390/molecules24112115; Kapsiani S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93070-6; Kaspar C, 2021, NATURE, V594, P345, DOI 10.1038/s41586-021-03453-y; Köppen M, 2018, CRYST GROWTH DES, V18, P4060, DOI 10.1021/acs.cgd.8b00439; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Le Q., 2014, DISTRIBUTED REPRESEN, P1188; Li MY, 2020, CRYST GROWTH DES, V20, P2866, DOI 10.1021/acs.cgd.0c00258; Liu TF, 2015, J AM CHEM SOC, V137, P413, DOI 10.1021/ja5111317; Luo Y, 2022, ANGEW CHEM INT EDIT, V61, DOI 10.1002/anie.202200242; Lyu H, 2020, CHEM-US, V6, P2219, DOI 10.1016/j.chempr.2020.08.008; Ma KK, 2023, CHEM MATER, V35, P2342, DOI 10.1021/acs.chemmater.2c03288; Matlin SA, 2015, NAT CHEM, V7, P941, DOI 10.1038/nchem.2389; Meyer JG, 2019, J CHEM INF MODEL, V59, P4438, DOI 10.1021/acs.jcim.9b00236; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Moghadam PZ, 2017, CHEM MATER, V29, P2618, DOI 10.1021/acs.chemmater.7b00441; Nandy A, 2023, MATTER-US, V6, P1585, DOI 10.1016/j.matt.2023.03.009; Nandy A, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01181-0; Nandy A, 2021, J AM CHEM SOC, V143, P17535, DOI 10.1021/jacs.1c07217; Nguyen KT, 2009, CHEMMEDCHEM, V4, P1803, DOI 10.1002/cmdc.200900317; Park H, 2022, J CHEM INF MODEL, V62, P1190, DOI 10.1021/acs.jcim.1c01297; Park S, 2018, J CHEM INF MODEL, V58, P244, DOI 10.1021/acs.jcim.7b00608; Pauling L, 1932, J AM CHEM SOC, V54, P3570, DOI 10.1021/ja01348a011; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajappan R, 2009, IND ENG CHEM RES, V48, P9708, DOI 10.1021/ie8018406; Reinsch H, 2013, CHEM MATER, V25, P17, DOI 10.1021/cm3025445; Rowsell JLC, 2006, J AM CHEM SOC, V128, P1304, DOI 10.1021/ja056639q; Seifert S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62338-8; SHANNON RD, 1976, ACTA CRYSTALLOGR A, V32, P751, DOI 10.1107/S0567739476001551; Suyetin M, 2021, FARADAY DISCUSS, V231, P224, DOI 10.1039/d1fd00011j; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Torrisi SB, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00376-6; van Deursen R, 2010, J CHEM INF MODEL, V50, P1924, DOI 10.1021/ci100237q; Yaghi OM, 2019, INTRODUCTION TO RETICULAR CHEMISTRY: METAL-ORGANIC FRAMEWORKS AND COVALENT ORGANIC FRAMEWORKS, P1, DOI 10.1002/9783527821099; Yaghi OM, 2003, NATURE, V423, P705, DOI 10.1038/nature01650; Zheng Z., 2023, Mol. Front. J, P1, DOI [10.1142/S2529732523400011, DOI 10.1142/S2529732523400011]; Zheng ZL, 2023, ISR J CHEM, V63, DOI 10.1002/ijch.202300017	66	63	63	141	300	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0002-7863	1520-5126		J AM CHEM SOC	J. Am. Chem. Soc.	AUG 7	2023	145	32					18048	18062		10.1021/jacs.3c05819	http://dx.doi.org/10.1021/jacs.3c05819		AUG 2023	15	Chemistry, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	P3CF7	37548379	Green Submitted, Green Accepted, Green Published			2024-07-03	WOS:001052894400001
C	Gaur, M; Tsamoura, E; Sreedharan, S; Mittal, S			ACM	Gaur, Manas; Tsamoura, Efthymia; Sreedharan, Sarath; Mittal, Sudip			KiL 2023: 3rd International Workshop on Knowledge-infused Learning	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD		Neurosymbolic AI; Knowledge-infused Learning; Explainable AI; Safe AI; Language Models; Games; Programming Languages		Recent prolific advances in artificial intelligence through the incorporation of domain knowledge have constituted a new paradigm for AI and data mining communities. For example, the human feedback-based language generation in ChatGPT (a large language model (LLM)), the use of Protein Bank in DeepMind's AlphaFold, and the use of 23 rules of safety in DeepMind's Sparrow have demonstrated the success of teaming human knowledge and AI. In addition, the knowledge retrieval-guided language modeling methods have strengthened the association between knowledge and AI. However, translating research methods and resources into practice presents a new challenge for the machine learning and data/knowledge mining communities. For example, in DARPA's Explainable AI seminar, the need for explainable contextual adaptation is seen as the 3rd phase of AI, facilitating the interplay between data and knowledge for explainability, safety, and, eventually, trust. However, policymakers and practitioners assert serious usability and privacy concerns that constrain adoption, notably in high-consequence domains, such as cybersecurity, healthcare, and other social good domains. In addition, limitations in output quality, measurement, and interactive ability, including both the provision of explanations and the acceptance of user preferences, result in low adoption rates in such domains. This workshop aims to accelerate our pace towards creating innovative methods for integrating knowledge into contemporary AI and data science methods and develop metrics for assessing performance in various applications.	[Gaur, Manas] Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA; [Tsamoura, Efthymia] Samsung AI Res, Cambridge, England; [Sreedharan, Sarath] Colorado State Univ, Ft Collins, CO 80523 USA; [Mittal, Sudip] Mississippi State Univ, Mississippi State, MS 39762 USA	University System of Maryland; University of Maryland Baltimore County; Colorado State University; Mississippi State University	Gaur, M (corresponding author), Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA.	manas@umbc.edu; efi.tsamoura@samsung.com; sarath.sreedharan@colostate.edu; mittal@cse.msstate.edu		Sreedharan, Sarath/0000-0002-2299-0178; Mittal, Sudip/0000-0001-9151-8347; Gaur, Manas/0000-0002-5411-2230					0	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5857	5858		10.1145/3580305.3599199	http://dx.doi.org/10.1145/3580305.3599199			2	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ					2024-07-03	WOS:001118896305112
J	Suslo, R; Paplick, M; Drobnik, J; Klakocar, J; Godzinski, J				Suslo, Robert; Paplick, Mateusz; Drobnik, Jaroslaw; Klakocar, Jacek; Godzinski, Jan			Potential of use of modern information technology solutions in the work of hospital infection control team, including antibiotic therapy optimisation, reduction of alert pathogen infections and vaccination popularisation	FAMILY MEDICINE AND PRIMARY CARE REVIEW			English	Article						medical informatics; artificial intelligence; machine learning; augmented reality; infection control; medical law.	HEALTH-CARE; MANDATORY VACCINATION; DISEASE DIAGNOSIS; NEURAL-NETWORK; BIG DATA	Background. Classic hospital information technology (IT) systems are being upgraded to new functional levels due to the rapid evolution and introduction into everyday operation emerging solutions based on machine learning (ML), artificial intelligence (AI), augmented reality (AR) and large language models (LLM), including the famous ChatGPT.Objectives. The objective of the study was identification of potential practical applications of emerging IT solutions to various aspects of identified routine activities of ICTs, including hospital hygiene improvement, antibiotic stewardship adherence and vaccination enforcement and popularisation.Material and methods. Related merit and legally defined duties of infection control teams (ICTs) at Polish hospitals were examined and compared against the capabilities of emerging IT solutions.Results. It presents as inevitable that personal universal AI-based virtual assistant of medical staff, melting together modern broadband wireless connection to expanding IT infrastructure and its new emerging solutions, including ML, LLM and already relatively inexpensive AR tools, will revolutionise the everyday practice of hospital epidemiology.Conclusions. It is foreseeable that in the near future, all hospital IT tools will present a single coherent solution oriented on the common goal of achieving maximal patient health and staff safety, providing holistic, individualised, continuous and omnipresent support to Hospital Infection Control Teams, every other member of the hospital staff, all hospitalised patients, as well as their accompanying persons.	[Suslo, Robert] Wroclaw Med Univ, Hlth Sci Fac, Populat Hlth Dept, Epidemiol & Med Educ Unit, Wroclaw, Poland; [Paplick, Mateusz; Godzinski, Jan] Wroclaw Med Univ, Gen Med Fac, Dev Age Traumatol & Emergency Med Unit, Wroclaw, Poland; [Drobnik, Jaroslaw] Wroclaw Med Univ, Gen Med Fac, Family Med Dept, Family Med Unit, Wroclaw, Poland; [Klakocar, Jacek] Lower Silesian Voivodship Sanit & Epidemiol Stn, Wroclaw, Poland; [Suslo, Robert] Uniwersytet Med Wrocławiu, Katedra Zdrow Populacyjnego, Zakład Epidemiologii & Edukacji Zdrowotnej, Wydział Nauk Zdrowiu, ul Bujwida 44, PL-50345 Wroclaw, Poland	Wroclaw Medical University; Wroclaw Medical University; Wroclaw Medical University	Suslo, R (corresponding author), Uniwersytet Med Wrocławiu, Katedra Zdrow Populacyjnego, Zakład Epidemiologii & Edukacji Zdrowotnej, Wydział Nauk Zdrowiu, ul Bujwida 44, PL-50345 Wroclaw, Poland.	robert.suslo@umw.edu.pl		Paplicki, Mateusz/0000-0002-4169-9298				Alanazi Abdullah, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20053846; Aleid A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063808; Alimbayev A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35551-4; Alkim E, 2012, NEURAL NETWORKS, V33, P88, DOI 10.1016/j.neunet.2012.04.010; Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x; Amponsah A. A., 2022, INT J INF MANAGE DAT, V2; [Anonymous], Regulation of the Minister of Finance Number 12/PMK.010/2017 on Determination of Products with Export Tariff; [Anonymous], [Act of 8 December 2008 on preventing and combating infections and infectious diseases in humans] (Dz.U.2008nr234poz.1570zm.,t.j.Dz.U.2022poz.1657).; [Anonymous], 2010, WHO best practices for injections and related procedures toolkit; [Anonymous], 2024, Regulation of the Minister of Health of 27 May 2010 on the method of documenting the implementation of activities preventing the spread of infections and infectious diseases and the conditions and period of storage of this documentation; [Anonymous], 2009, WHO GUIDELINES HAND; Arena F, 2022, COMPUTERS, V11, DOI 10.3390/computers11020028; Atkov OY, 2012, J CARDIOL, V59, P190, DOI 10.1016/j.jjcc.2011.11.005; Baashar Yahia, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20053940; Banjar H, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19052875; Barbosa DC, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-3; Barwad A, 2012, CYTOM PART B-CLIN CY, V82B, P107, DOI 10.1002/cyto.b.20632; Bas Tomas Gabriel, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20064839; Basile G, 2022, J CLIN MED, V11, DOI 10.3390/jcm11133644; Bates DW, 2014, HEALTH AFFAIR, V33, P1123, DOI 10.1377/hlthaff.2014.0041; Bi QF, 2019, AM J EPIDEMIOL, V188, P2222, DOI 10.1093/aje/kwz189; Black AD, 2011, PLOS MED, V8, DOI 10.1371/journal.pmed.1000387; Blumenthal D, 2007, NEW ENGL J MED, V356, P2527, DOI 10.1056/NEJMhpr066212; Bokor A, 1996, AM J PREV MED, V12, P143, DOI 10.1016/S0749-3797(18)30332-5; Bucci S, 2019, PSYCHOL PSYCHOTHER-T, V92, P277, DOI 10.1111/papt.12222; Cabitza F, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00075; CDC and ICAN, 2019, Best Practices for Environmental Cleaning in Healthcare Facilities in Resource-Limited Settings; Cewe P, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081413; Chartier Y., 2014, Safe management of wastes from health-care activities; Chen RJ, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12177192; Chioma R, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053211; Doll Michelle E, 2022, Antimicrob Steward Healthc Epidemiol, V2, pe126, DOI 10.1017/ash.2022.264; Doron S, 2011, MAYO CLIN PROC, V86, P1113, DOI 10.4065/mcp.2011.0358; Drobnik J, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115600; Dunn B, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10060690; Er O, 2008, J MED SYST, V32, P429, DOI 10.1007/s10916-008-9148-6; European Union, 2000, Regulation (EC) N141/2000 of the European Parliament and of the Council of 16 December 1999 on Orphan Medicinal Products; Field Robert I, 2009, P T, V34, P615; Flessa S, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph181910026; Ginsberg J, 2009, NATURE, V457, P1012, DOI 10.1038/nature07634; Griffin Joan M, 2020, Mayo Clin Proc Innov Qual Outcomes, V4, P90, DOI 10.1016/j.mayocpiqo.2019.10.007; Guo HL, 2021, JAMIA OPEN, V4, DOI 10.1093/jamiaopen/ooaa072; Ho Indy Man Kit, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20105881; Jamil F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050505; Jayakumar P, 2019, CLIN ORTHOP RELAT R, V477, P1777, DOI 10.1097/CORR.0000000000000873; Jones SS, 2012, NEW ENGL J MED, V366, P2243, DOI 10.1056/NEJMp1204980; Kamal MA, 2023, CLINICS PRACT, V13, P470, DOI 10.3390/clinpract13020042; Kaye KS, 2015, INFECT CONT HOSP EP, V36, P369, DOI 10.1017/ice.2014.79; Khatri Naresh, 2015, Mo Med, V112, P41; Klauer K, 2013, Emergency Physicians Monthly, V20, P22; Koruga N, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12092061; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lewandrowski KU, 2023, J PERS MED, V13, DOI 10.3390/jpm13050852; Seguí FL, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17062008; Mahdi S S., 2023, International Journal of Information Management Data Insights, V3, P100144, DOI [DOI 10.1016/J.JJIMEI.2022.100144, 10.1016/j.jjimei.2022.100144]; Martins MV, 2023, COMPUTATION, V11, DOI 10.3390/computation11060115; McCormick D, 2012, HEALTH AFFAIR, V31, P488, DOI 10.1377/hlthaff.2011.0876; Meng M, 2019, AM J INFECT CONTROL, V47, P439, DOI 10.1016/j.ajic.2018.10.012; Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181; Pankhurst T, 2021, JMIR MED INF, V9, DOI 10.2196/29532; Paplicki M, 2020, FAM MED PRIM CARE RE, V22, P252, DOI 10.5114/fmpcr.2020.98255; Paplicki M, 2018, FAM MED PRIM CARE RE, V20, P389, DOI 10.5114/fmpcr.2018.80081; Pines J, 2013, Emergency Physicians Monthly, V20, P22; Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1; Riccardo F, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061120; Roganovic J, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11101480; Ross C, 2022, Statnews.com6 October; Roth JA, 2018, INFECT CONT HOSP EP, V39, P1457, DOI 10.1017/ice.2018.265; Salathé M, 2018, LIFE SCI SOC POLICY, V14, DOI 10.1186/s40504-017-0065-7; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Smith H L, 2000, Hosp Top, V78, P13; Stafford H, 2023, CANCERS, V15, DOI 10.3390/cancers15123094; Sus#o R, 2006, Fam Med Prim Care Rev, V8, P778; Suslo R, 2019, Postepy medycyny ratunkowej 2019, P29; Suslo R, 2018, Legal and administrative aspects of electronic communication, P105; Suslo R, 2017, Acta Universitatis Wratislaviensis. Prawo, V323, P151, DOI [10.19195/0524-4544.323.14, DOI 10.19195/0524-4544.323.14]; Suslo R, 2007, Fam Med Prim Care Rev, V9, P866; Suslo R, 2017, Lekarz POZ, V3, P269; Suslo R, 2022, VACCINES-BASEL, V10, DOI 10.3390/vaccines10071026; Suslo R, 2018, FAM MED PRIM CARE RE, V20, P271, DOI 10.5114/fmpcr.2018.78273; Suslo R, 2017, FAM MED PRIM CARE RE, V19, P313, DOI 10.5114/fmpcr.2017.69297; Suslo R, 2008, FAM MED PRIM CARE RE, V10, P696; Thandar MM, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph192417075; Visibelli A, 2023, BIOMEDICINES, V11, DOI 10.3390/biomedicines11030887; von Ende E, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13050892; Wang CF, 2021, J MED INTERNET RES, V23, DOI 10.2196/27880; Wiens J, 2018, CLIN INFECT DIS, V66, P149, DOI 10.1093/cid/cix731; Wright SB, 2010, INFECT CONT HOSP EP, V31, P127, DOI 10.1086/650199; Xu N, 2021, J HOSP INFECT, V109, P101, DOI 10.1016/j.jhin.2020.12.009; Zhai KV, 2023, PROCESSES, V11, DOI 10.3390/pr11030939	90	0	0	2	2	TERMEDIA PUBLISHING HOUSE LTD	POZNAN	KLEEBERGA 2, POZNAN, 61-615, POLAND	1734-3402	2449-8580		FAM MED PRIM CARE RE	Fam. Med. Prim. Care Rev.		2023	25	4					427	435		10.5114/fmpcr.2023.132616	http://dx.doi.org/10.5114/fmpcr.2023.132616			9	Primary Health Care	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	DY6U9		gold			2024-07-03	WOS:001135699900005
J	Kuckelman, IJ; Wetley, K; Yi, PH; Ross, AB				Kuckelman, Ian J.; Wetley, Karla; Yi, Paul Hyunsoo; Ross, Andrew Bailey			Translating musculoskeletal radiology reports into patient-friendly summaries using ChatGPT-4	SKELETAL RADIOLOGY			English	Article						ChatGPT; Artificial intelligence; Large language models; Patient education; Musculoskeletal; Report		Objective To assess the feasibility of using large language models (LLMs), specifically ChatGPT-4, to generate concise and accurate layperson summaries of musculoskeletal radiology reports. Methods Sixty radiology reports, comprising 20 MR shoulder, 20 MR knee, and 20 MR lumbar spine reports, were obtained via PACS. The reports were deidentified and then submitted to ChatGPT-4, with the prompt "Produce an organized and concise layperson summary of the findings of the following radiology report. Target a reading level of 8-9th grade and word count <300 words." Three (two primary and one later added for validation) independent readers evaluated the summaries for completeness and accuracy compared to the original reports. Summaries were rated on a scale of 1 to 3: 1) summaries that were incorrect or incomplete, potentially providing harmful or confusing information; 2) summaries that were mostly correct and complete, unlikely to cause confusion or harm; and 3) summaries that were entirely correct and complete. Results All 60 responses met the criteria for word count and readability. Mean ratings for accuracy were 2.58 for reader 1, 2.71 for reader 2, and 2.77 for reader 3. Mean ratings for completeness were 2.87 for reader 1 and 2.73 for reader 2 and 2.87 for reader 3. For accuracy, reader 1 identified three summaries as a 1, reader 2 identified one, and reader 3 identified none. For the two primary readers, inter-reader agreement was low for accuracy (kappa 0.33) and completeness (kappa 0.29). There were no statistically significant changes in inter-reader agreement when the third reader's ratings were included in analysis. Conclusion Overall ratings for accuracy and completeness of the AI-generated layperson report summaries were high with only a small minority likely to be confusing or inaccurate. This study illustrates the potential for leveraging generative AI, such as ChatGPT-4, to automate the production of patient-friendly summaries for musculoskeletal MR imaging.	[Kuckelman, Ian J.; Wetley, Karla; Ross, Andrew Bailey] Univ Wisconsin Madison, Sch Med & Publ Hlth, 750 Highland Ave, Madison, WI 53705 USA; [Yi, Paul Hyunsoo] Univ Maryland, Sch Med, 655 Baltimore St S, Baltimore, MD 21201 USA	University of Wisconsin System; University of Wisconsin Madison; University System of Maryland; University of Maryland Baltimore	Kuckelman, IJ (corresponding author), Univ Wisconsin Madison, Sch Med & Publ Hlth, 750 Highland Ave, Madison, WI 53705 USA.	kuckelman@wisc.edu; kwetley@uwhealth.org; pyi@som.umaryland.edu; aross@uwhealth.org						Bush RA, 2017, J AMBUL CARE MANAG, V40, P238, DOI 10.1097/JAC.0000000000000175; Deeds S, 2018, AM J MED QUAL, V33, P642, DOI 10.1177/1062860618770043; Hartung MP, 2020, RADIOGRAPHICS, V40, P1658, DOI 10.1148/rg.2020200020; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; HENDEE WR, 1989, JAMA-J AM MED ASSOC, V262, P2420; Johnson Annette J, 2009, J Am Coll Radiol, V6, P786, DOI 10.1016/j.jacr.2009.07.010; Kuckelman IJ, 2024, ACAD RADIOL, V31, P338, DOI 10.1016/j.acra.2023.08.020; Li H, 2023, CLIN IMAG, V101, P137, DOI 10.1016/j.clinimag.2023.06.008; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; OpenAI, 2021, CHATGPT VERSION 4 CO; Readability Formulas, 2023, FREE READABILITY FOR; Salmi L, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n426; Shanafelt TD, 2016, MAYO CLIN PROC, V91, P836, DOI 10.1016/j.mayocp.2016.05.007	13	3	3	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0364-2348	1432-2161		SKELETAL RADIOL	Skeletal Radiol.	AUG	2024	53	8					1621	1624		10.1007/s00256-024-04599-2	http://dx.doi.org/10.1007/s00256-024-04599-2		JAN 2024	4	Orthopedics; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Radiology, Nuclear Medicine & Medical Imaging	WL3R3	38270616				2024-07-03	WOS:001150393100001
J	Wang, YF; Zeng, WT; Liu, CZ; Ye, ZH; Sun, JW; Ji, JX; Jiang, ZH; Yan, XY; Wu, YY; Wang, YG; Yang, DQ; Wang, LY; Zhang, DQ; Wang, C; Chen, LB				Wang, Yufei; Zeng, Wenting; Liu, Changzhen; Ye, Zhuohan; Sun, Jiawei; Ji, Junxiang; Jiang, Zhihan; Yan, Xianyi; Wu, Yongyi; Wang, Yigao; Yang, Dingqi; Wang, Leye; Zhang, Daqing; Wang, Cheng; Chen, Longbiao			CrowdBot: An Open-Environment Robot Management System for On-Campus Services	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						crowdsensing; robot management; reinforcement learning; online streaming task assignment; dynamic task schedule; equipment-swappable robots	TASK ALLOCATION; OPTIMIZATION; RELIABILITY	In contemporary campus environments, the provision of timely and efficient services is increasingly challenging due to limitations in accessibility and the complexity and openness of the environment. Existing service robots, while operational, often struggle with adaptability and dynamic task management, leading to inefficiencies. To overcome these limitations, we introduce CrowdBot, a robot management system that enhances service in campus environments. Our system leverages a hierarchical reinforcement learning-based cloud-edge hybrid scheduling framework (REDIS), for efficient online streaming task assignment and dynamic action scheduling. To verify the REDIS framework, we have developed a digital twin simulation platform, which integrates large language models and hot-swapping technology. This facilitates seamless human-robot interaction, efficient task allocation, and cost-effective execution through the reuse of robot equipment. Our comprehensive simulations corroborate the system's remarkable efficacy, demonstrating significant improvements with a 24.46% reduction in task completion times, a 9.37% decrease in travel distances, and up to a 3% savings in power usage. Additionally, the system achieves a 7.95% increase in the number of tasks completed and a 9.49% reduction in response time. Real-world case studies further affirm CrowdBot's capability to adeptly execute tasks and judiciously recycle resources, thereby offering a smart and viable solution for the streamlined management of campus services.	[Wang, Yufei; Zeng, Wenting; Liu, Changzhen; Ye, Zhuohan; Sun, Jiawei; Ji, Junxiang; Wu, Yongyi; Wang, Yigao; Wang, Cheng; Chen, Longbiao] Xiamen Univ, Sch Informat, Xiamen, Fujian, Peoples R China; [Jiang, Zhihan] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China; [Yan, Xianyi] East China Normal Univ, Sch Software Engn, Shanghai, Peoples R China; [Yang, Dingqi] Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China; [Wang, Leye; Zhang, Daqing] Peking Univ, Sch Comp Sci, Beijing, Peoples R China	Xiamen University; University of Hong Kong; East China Normal University; University of Macau; Peking University	Chen, LB (corresponding author), Xiamen Univ, Sch Informat, Xiamen, Fujian, Peoples R China.	wangyufei1@stu.xmu.edu.cn; 21620192203320@stu.xmu.edu.cn; liucz@stu.xmu.edu.cn; yezhuohan@stu.xmu.edu.cn; 22920202200778@stu.xmu.edu.cn; 34520192201443@stu.xmu.edu.cn; zhjiang@connect.hku.hk; 10205101536@stu.ecnu.edu.cn; yongyiwu@stu.xmu.edu.cn; wangyigao@stu.xmu.edu.cn; dingqiyang@um.edu.mo; leyewang@pku.edu.cn; daqing.zhang@telecom-sudparis.eu; cwang@xmu.edu.cn; longbiaochen@xmu.edu.cn		Jiang, Zhihan/0000-0003-4857-7143	NSF of China [61802325]; Open Research Project Programme of the State Key Laboratory of Internet of Things for Smart City (University of Macau) [SKL-IoTSC(UM)-2021-2023/ORP/GA06/2022]; University of Macau [MYRG2022-00048-IOTSC]; Science and Technology Development Fund, Macau SAR [0038/2021/AGJ]; FuXiaQuan National Independent Innovation Demonstration Zone Collaborative Innovation Platform [3502ZCQXT2021003]	NSF of China(National Natural Science Foundation of China (NSFC)); Open Research Project Programme of the State Key Laboratory of Internet of Things for Smart City (University of Macau); University of Macau; Science and Technology Development Fund, Macau SAR; FuXiaQuan National Independent Innovation Demonstration Zone Collaborative Innovation Platform	We would like to thank the reviewers for their constructive suggestions. This research is supported by NSF of China No. 61802325, the Open Research Project Programme of the State Key Laboratory of Internet of Things for Smart City (University of Macau) (Ref. No.: SKL-IoTSC(UM)-2021-2023/ORP/GA06/2022), the University of Macau (MYRG2022-00048-IOTSC), the Science and Technology Development Fund, Macau SAR (0038/2021/AGJ) and the FuXiaQuan National Independent Innovation Demonstration Zone Collaborative Innovation Platform (No. 3502ZCQXT2021003).	Aeppel T., 2015, Wall Street Journal, V1, pD1; Ahreum Lee, 2020, CSCW '20: 23rd Conference on Computer-Supported Cooperative Work and Social Computing, P305, DOI 10.1145/3406865.3418321; Ali A, 2021, SUSTAIN COMPUT-INFOR, V32, DOI 10.1016/j.suscom.2021.100608; Attiya G, 2006, J PARALLEL DISTR COM, V66, P1259, DOI 10.1016/j.jpdc.2006.06.006; Benjamin R., 2012, New York Times, V29; Benny R., 2022, International Journal of Open Information Technologies, V10, P21; Chen RF, 2020, INT CONF WIRE COMMUN, P245, DOI 10.1109/WCSP49889.2020.9299801; Chen YX, 2021, IEEE ROBOT AUTOM LET, V6, P4337, DOI 10.1109/LRA.2021.3068103; Chen Z., 2020, Proc. VLDB Endow., V13, P2479, DOI [10.14778/3407790.3407839, DOI 10.14778/3407790.3407839]; Chen Z., 2023, Sustainability, V15; de Freitas Edison Pignaton, 2021, 2021 International Conference on Unmanned Aircraft Systems (ICUAS), P909, DOI 10.1109/ICUAS51884.2021.9476740; Deisenroth MP., 2013, FOUND TRENDS ROBOT, V2, P1, DOI DOI 10.1561/2300000021; Fuentes-Moraleda L, 2020, TOUR MANAG PERSPECT, V36, DOI 10.1016/j.tmp.2020.100751; Ganti RK, 2011, IEEE COMMUN MAG, V49, P32, DOI 10.1109/MCOM.2011.6069707; Gao HF, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072751; Garrido G. G., 2020, CLAWAR 2020; Guo B., 2016, IEEE Communications Magazine; Hamama B., 2020, City, Territory and Architecture, V7, P1; Ho C.-J., 2012, ser. AAAI' 12, P45, DOI DOI 10.1007/JHEP06(2012)045; Jiang Z., 2021, IEEE Transactions on Mobile Computing; Juliani A, 2020, Arxiv, DOI [arXiv:1809.02627, 10.48550/arXiv.1809.02627, DOI 10.48550/ARXIV.1809.02627]; Kang QM, 2013, J PARALLEL DISTR COM, V73, P1106, DOI 10.1016/j.jpdc.2013.03.008; Kastner Linh, 2022, 2022 International Conference on Robotics and Automation (ICRA), P833, DOI 10.1109/ICRA46639.2022.9812111; Konda VR, 2000, ADV NEUR IN, V12, P1008; Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006; Le Pape C., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P488, DOI 10.1109/ROBOT.1990.126026; Lee I, 2015, BUS HORIZONS, V58, P431, DOI 10.1016/j.bushor.2015.03.008; Lillicrap T. P., 2019, arXiv; Liu YM, 2022, IEEE T MOBILE COMPUT, V21, P878, DOI 10.1109/TMC.2020.3015750; Liu ZY, 2018, IEEE DECIS CONTR P, P4481, DOI 10.1109/CDC.2018.8619480; Lujak M., 2020, AIRO@ AI* IA, P49; Mnih V, 2013, Arxiv, DOI [arXiv:1312.5602, DOI 10.48550/ARXIV.1312.5602]; Odrowaz-Coates A, 2015, INT SOCIOL, V30, P233, DOI 10.1177/0268580915578759; Pan Y, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448079; Quigley M., 2009, ICRA WORKSHOP OPEN S, V3, P5, DOI DOI 10.1109/IECON.2015.7392843; Robertson J, 2007, CRIT ASIAN STUD, V39, P369, DOI 10.1080/14672710701527378; Saadawy N. A., 2022, Civil Engineering and Architecture, V10, P189; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Spong M.W., 2020, Robot Modeling and Control; Szocik K, 2022, J APPL SEC RES, V17, P530, DOI 10.1080/19361610.2021.1923365; Tu YP, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14020030; [王晓宁 Wang Xiaoning], 2022, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V22, P228; Wang YJ, 2020, IEEE T COMPUT SOC SY, V7, P1033, DOI 10.1109/TCSS.2020.2995760; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Xiang F., 2020, 2020 IEEE CVF C COMP, p11 094; Yu DH, 2019, IEEE ACCESS, V7, P33094, DOI 10.1109/ACCESS.2019.2902913; Yuen M.-C., 2012, CROWDKDD 12, P22, DOI [10.1145/2442657.2442661, DOI 10.1145/2442657.2442661]; Zenati A, 2022, P AMER CONTR CONF, P1898, DOI 10.23919/ACC53348.2022.9867692; Zhang XM, 2021, IEEE T MOBILE COMPUT, V20, P1001, DOI 10.1109/TMC.2019.2955688; Zhao Y, 2021, PROC INT CONF DATA, P265, DOI 10.1109/ICDE51399.2021.00030	52	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAY	2024	8	2							80	10.1145/3659601	http://dx.doi.org/10.1145/3659601			27	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	RR2F4		Bronze			2024-07-03	WOS:001229316000039
J	Riviere, JG; Palacin, PS; Butte, MJ				Riviere, Jacques G.; Palacin, Pere Soler; Butte, Manish J.			Proceedings from the inaugural Artificial Intelligence in Primary Immune Deficiencies (AIPID) conference	JOURNAL OF ALLERGY AND CLINICAL IMMUNOLOGY			English	Article						Artificial intelligence; machine learning; large lan guage models; natural language processing; electronic health re cords; inborn errors of immunity; diagnosis; ethics	PRIMARY IMMUNODEFICIENCY DISEASES; DIAGNOSTIC ODYSSEY; IMPACT	Here, we summarize the proceedings of the inaugural Artificial Intelligence in Primary Immune Deficiencies conference, during which experts and advocates gathered to advance research into the applications of artificial intelligence (AI), machine learning, and other computational tools in the diagnosis and management of inborn errors of immunity (IEIs). The conference focused on the key themes of expediting IEI diagnoses, challenges in data collection, roles of natural language processing and large language models in interpreting electronic health records, and ethical considerations in implementation. Innovative AI -based tools trained on electronic health records and claims databases have discovered new patterns of warning signs for IEIs, facilitating faster diagnoses and enhancing patient outcomes. Challenges in training AIs persist on account of data limitations, especially in cases of rare diseases, overlapping phenotypes, and biases inherent in current data sets. Furthermore, experts highlighted the significance of ethical considerations, data protection, and the necessity for open science principles. The conference delved into regulatory frameworks, equity in access, and the imperative for collaborative efforts to overcome these obstacles and harness the transformative potential of AI. Concerted efforts to successfully integrate AI into daily clinical immunology practice are still needed. (J Allergy Clin Immunol 2024;153:637-42.)	[Riviere, Jacques G.; Palacin, Pere Soler] Hosp Infantil & Dona, Infect & Immun Pediat Patients Res Grp, Vall Hebron Barcelona Hosp Campus, Barcelona, Spain; [Riviere, Jacques G.; Palacin, Pere Soler] Hosp Infantil & Dona, Pediat Infect Dis & Immunodeficiencies Unit, Vall Hebron Barcelona Hosp Campus, Barcelona, Spain; [Riviere, Jacques G.; Palacin, Pere Soler] Jeffrey Modell Diagnost & Res Ctr Primary Immunode, Barcelona, Spain; [Riviere, Jacques G.; Palacin, Pere Soler] Univ Autonoma Barcelona, Barcelona, Spain; [Butte, Manish J.] Univ Calif Los Angeles, Dept Pediat, Div Immunol Allergy & Rheumatol, Los Angeles, CA USA; [Butte, Manish J.] Univ Calif Los Angeles, Dept Microbiol Immunol & Mol Genet, Los Angeles, CA USA; [Butte, Manish J.] Univ Calif Los Angeles, Dept Human Genet, Los Angeles, CA USA; [Butte, Manish J.] Pediat, 10833 Le Conte Ave,12-430 MDCC, Los Angeles, CA 90095 USA	Hospital Universitari Vall d'Hebron; Hospital Universitari Vall d'Hebron; Autonomous University of Barcelona; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Butte, MJ (corresponding author), Pediat, 10833 Le Conte Ave,12-430 MDCC, Los Angeles, CA 90095 USA.	mbutte@mednet.ucla.edu		Butte, Manish/0000-0002-4490-5595				Aref L, 2022, BIOINFORMATICS, V38, P4972, DOI 10.1093/bioinformatics/btac619; Barrera JAM, 2023, CLIN IMMUNOL, V255, DOI 10.1016/j.clim.2023.109759; Basel D, 2017, PEDIATR CLIN N AM, V64, P265, DOI 10.1016/j.pcl.2016.08.017; Bastarache L, 2023, AM J HUM GENET, V110, P1522, DOI 10.1016/j.ajhg.2023.07.012; Bastarache L, 2021, ANNU REV BIOMED DA S, V4, P1, DOI 10.1146/annurev-biodatasci-122320-112352; Bastarache L, 2018, SCIENCE, V359, P1233, DOI 10.1126/science.aal4043; Bernstam EV, 2022, J AM MED INFORM ASSN, V29, P753, DOI 10.1093/jamia/ocab289; Biedermann P, 2021, BMC MED RES METHODOL, V21, DOI 10.1186/s12874-021-01434-3; Carmichael N, 2015, J GENET COUNS, V24, P325, DOI 10.1007/s10897-014-9773-9; Cassini T, 2023, GENET MED, V25, DOI 10.1016/j.gim.2023.100966; Cunha Joao, 2023, Procedia Computer Science, P874, DOI 10.1016/j.procs.2023.03.118; Cunningham-Rundles C, 2004, J ALLERGY CLIN IMMUN, V113, P747, DOI 10.1016/j.jaci.2004.01.761; Fang HM, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.0320; Johnson R, 2022, Health Informatics, DOI [10.1101/2022.08.03.22278352, DOI 10.1101/2022.08.03.22278352]; Keller MD, 2016, J ALLERGY CLIN IMMUN, V138, P544, DOI 10.1016/j.jaci.2016.01.018; Lawrence MG, 2023, J Allergy Clin Immunol Pract; Lugo Reyes SO, 2020, Stiehm's immune deficiencies, V2nd, P1129; Modell F, 2009, IMMUNOL RES, V44, P132, DOI 10.1007/s12026-008-8092-3; Modell V, 2018, IMMUNOL RES, V66, P367, DOI 10.1007/s12026-018-8996-5; Modell V, 2011, IMMUNOL RES, V51, P61, DOI 10.1007/s12026-011-8241-y; Odnoletkova I, 2018, ORPHANET J RARE DIS, V13, DOI 10.1186/s13023-018-0941-0; Orange JS, 2011, J ALLERGY CLIN IMMUN, V127, P1360, DOI 10.1016/j.jaci.2011.02.039; Park K, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0279641; Perez Sust Pol, 2020, JMIR Public Health Surveill, V6, pe19106, DOI 10.2196/19106; Prince BT, 2020, PEDIATR HEALTH MED T, V11, P257, DOI 10.2147/PHMT.S254253; Rider NL, 2020, medRxiv, DOI [10.1101/2020.06.12.20129692, 10.1101/2020.06.12.20129692, DOI 10.1101/2020.06.12.20129692]; Rider N, 2023, CLIN IMMUNOL, V250, P151, DOI 10.1016/j.clim.2023.109602; Rider NL, 2023, J ALLERGY CLIN IMMUN, V151, P272, DOI 10.1016/j.jaci.2022.10.005; Rider NL, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0237285; Rider NL, 2019, FRONT PEDIATR, V7, DOI 10.3389/fped.2019.00070; Riviere JG, 2023, INT PRIMARY IMMUNODE; Rosell AM, 2016, J GENET COUNS, V25, P1019, DOI 10.1007/s10897-016-9933-1; Routes J, 2016, J CLIN IMMUNOL, V36, P450, DOI 10.1007/s10875-016-0279-0; Schiavo E, 2022, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.790455; Seth N, 2021, J ALLERGY CLIN IMMUN, V148, P1442, DOI 10.1016/j.jaci.2021.10.010; Shuey MM, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad655; Sobreira Nara, 2015, Hum Mutat, V36, P928, DOI 10.1002/humu.22844; Steinkamp J, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.33348; Zurek B, 2021, EUR J HUM GENET, V29, P1325, DOI 10.1038/s41431-021-00859-0	39	0	0	2	2	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0091-6749	1097-6825		J ALLERGY CLIN IMMUN	J. Allergy Clin. Immunol.	MAR	2024	153	3					637	642		10.1016/j.jaci.2024.01.002	http://dx.doi.org/10.1016/j.jaci.2024.01.002		MAR 2024	6	Allergy; Immunology	Science Citation Index Expanded (SCI-EXPANDED)	Allergy; Immunology	NW9N2	38224784				2024-07-03	WOS:001203610200001
J	Chen, X; Li, J; Ye, YT				Chen, Xi; Li, Jun; Ye, Yuting			A feasibility study for the application of AI-generated conversations in pragmatic analysis	JOURNAL OF PRAGMATICS			English	Article						ChatGPT; Speech act; Pragmalinguistic; Sociopragmatic; Pragmatic competence	CONVENTIONAL EXPRESSIONS; SPEECH-ACT; INDIRECTNESS; LEARNERS; REQUESTS; REALIZATION; PERSPECTIVE; STRATEGIES; L2	This study explores the potential of including AI-generated language in pragmatic analysis - a field that has primarily been conducted on human language use. With the rapid growth of large language models, AI-generated texts and AI-human interactions constitute a growing field where pragmatics research is expanding to. Language data that humans used to hold a full authorship may also involve modifications made by AI. The foremost concern is thus the pragmatic qualities of AI-generated language, such as whether and to which extent AI data mirror the pragmatic patterns we have found in human speech behaviours. In this study, we compare 148 ChatGPT-generated conversations with 82 human-written ones and 354 human evaluations of these conversations. The data are analysed using various methods, including traditional speech strategy coding, four computational methods developed in NLP, and four statistical tests. The findings reveal that ChatGPT performs equally well as human participants in four out of the five tested pragmalinguistic features and five out of six sociopragmatic features. Additionally, the conversations generated by ChatGPT exhibit higher syntactic diversity and a greater sense of formality compared to those written by humans. As a result, our participants are unable to distinguish ChatGPT-generated conversations from human-written ones. (c) 2024 Elsevier B.V. All rights reserved.	[Chen, Xi] Univ Cent Lancashire, Preston, England; [Li, Jun] Southern Univ Sci & Technol, Shenzhen, Peoples R China; [Ye, Yuting] Southern Univ Sci & Technol, Business Sch 335, SUSTech, Shenzhen, Peoples R China	University of Central Lancashire; Southern University of Science & Technology; Southern University of Science & Technology	Chen, X (corresponding author), Univ Cent Lancashire, Preston, England.; Ye, YT (corresponding author), Southern Univ Sci & Technol, Business Sch 335, SUSTech, Shenzhen, Peoples R China.	xchenresearch@outlook.com; yeyt2023@sustech.edu.cn		Chen, Xi/0000-0003-2393-532X				Aaron Lazare M.D., 2005, On Apology; Abadie A, 2005, REV ECON STUD, V72, P1, DOI 10.1111/0034-6527.00321; [Anonymous], 1996, Lang. Sci., DOI DOI 10.1016/S0388-0001(96)00054-X; Austin JL., 1962, How to do Things with Words; Bachmann L.F., 1990, Fundamental Considerations in Language Testing; Bardovi-Harlig K., 2005, System, V33, P401; Bardovi-Harlig K, 2012, ANNU REV APPL LINGUI, V32, P206, DOI 10.1017/S0267190512000086; Beebe L., 1990, DEV COMMUNICATIVE CO, P55; Bella S, 2011, J PRAGMATICS, V43, P1718, DOI 10.1016/j.pragma.2010.11.005; Bertrand M, 2004, Q J ECON, V119, P249, DOI 10.1162/003355304772839588; Blum-Kulka Shoshana., 1989, CROSS CULTURAL PRAGM; BLUMKULKA S, 1987, J PRAGMATICS, V11, P131, DOI 10.1016/0378-2166(87)90192-5; BLUMKULKA S, 1984, APPL LINGUIST, V5, P196, DOI 10.1093/applin/5.3.196; Brown Penelope., 1978, Politeness: Some Universals in Language Usage; Bybee Joan, 2010, Language, Usage and Cognition, P151, DOI [10.1017/CBO9780511750526.009, DOI 10.1017/CBO9780511750526.009]; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Chang YF, 2011, LANG SCI, V33, P786, DOI 10.1016/j.langsci.2011.02.002; Chen X, 2023, IRAL-INT REV APPL LI, DOI 10.1515/iral-2022-0230; Chen X, 2022, J PRAGMATICS, V202, P7, DOI 10.1016/j.pragma.2022.10.010; Chen X, 2022, FOREIGN LANG ANN, V55, P1128, DOI 10.1111/flan.12656; Chen X, 2021, J PRAGMATICS, V178, P315, DOI 10.1016/j.pragma.2021.03.022; Cheng TP, 2016, LANG AWARE, V25, P159, DOI 10.1080/09658416.2016.1154568; Cohen A., 1996, STUD SECOND LANG ACQ, V18, P253, DOI 10.1017/S027226310001490X; Cook V, 1999, TESOL QUART, V33, P185, DOI 10.2307/3587717; Culpeper J, 2021, J PRAGMATICS, V175, P146, DOI 10.1016/j.pragma.2021.01.008; Cunningham DJ, 2017, SYSTEM, V64, P46, DOI 10.1016/j.system.2016.12.006; Economidou-Kogetsidis M, 2016, J PRAGMATICS, V106, P1, DOI 10.1016/j.pragma.2016.10.001; Economidou-Kogetsidis M, 2013, J PRAGMATICS, V53, P21, DOI 10.1016/j.pragma.2013.03.014; Edmonds A, 2014, STUD SECOND LANG ACQ, V36, P69, DOI 10.1017/S0272263113000557; Eelen Gino., 2001, CRITIQUE POLITENESS; Fatemeh M, 2021, IRAL-INT REV APPL LI, V59, P55, DOI 10.1515/iral-2017-0084; Fraser B, 2010, STUD PRAGMAT, V9, P15; Fukushima S., 1996, Language and Science, V18, P671, DOI [10.1016/S0388-0001(96)00041-1, DOI 10.1016/S0388-0001(96)00041-1]; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Grainger K, 2016, DIRECTNESS AND INDIRECTNESS ACROSS CULTURES, P1; Gumperz J.J., 1982, DISCOURSE STRATEGIES, DOI DOI 10.1017/CBO9780511611834; Herbold S, 2023, Arxiv, DOI [arXiv:2304.14276, DOI 10.48550/ARXIV.2304.14276]; Hoshi S, 2022, APPL LINGUIST, V43, P698, DOI 10.1093/applin/amab074; House J, 2021, LINGUA, V264, DOI 10.1016/j.lingua.2021.103162; Hymes D, 1966, SOCIOLINGUISTICS, P114; Ishihara N., 2010, TEACHING LEARNING PR; Ishihara Noriko, 2009, P 2008 TEMPLE U JAPA, P1; Ji H, 2023, J RES TECHNOL EDUC, V55, P48, DOI 10.1080/15391523.2022.2142873; Kinginger C., 2004, FRONTIERS INTERDISCI, VVX, P19; Kwon J., 2004, Multilingua, V23, P339, DOI 10.1515/mult.2004.23.4.339; Laughlin V.T., 2015, ETS Research Report Series, V1, P1, DOI DOI 10.1002/ETS2.12053; Leech Geoffrey, 1983, PRINCIPLES PRAGMATIC; Li YK, 2023, ASSESS WRIT, V56, DOI 10.1016/j.asw.2023.100707; Liao WX, 2023, Arxiv, DOI [arXiv:2304.11567, 10.48550/ARXIV.2304.11567, DOI 10.48550/ARXIV.2304.11567]; Loconte R., 2023, Challenging ChatGPT 'intelligence' with human tools: A neuropsychological investigation on prefrontal functioning of a large language model, DOI [10.2139/ssrn.4377371, DOI 10.2139/SSRN.4377371]; Ma YQ, 2023, Arxiv, DOI [arXiv:2301.10416, 10.48550/arXiv.2301.10416, DOI 10.48550/ARXIV.2301.10416]; Morgan Stephen L., 2014, Analytical Methods for Social Research, Vsecond, DOI [10.1017/CBO9781107587991, DOI 10.1017/CBO9781107587991]; Nelson GL, 2002, INT J INTERCULT REL, V26, P39, DOI 10.1016/S0147-1767(01)00037-2; Purpura J E., 2004, Assessing Grammar, DOI DOI 10.1017/CBO9780511733086; Qiu Zhuang, 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/QTBH9; Rose K., 2001, PRAGMATICS LANGUAGE; Rosen LD, 2010, COMMUN RES, V37, P420, DOI 10.1177/0093650210362465; Rosenbaum Paul R., 2002, Springer Series in Statistics; Shao KQ, 2019, SYSTEM, V86, DOI 10.1016/j.system.2019.102121; Shishavan HB, 2016, LANG COMMUN, V47, P75, DOI 10.1016/j.langcom.2016.01.001; Shishavan HB, 2013, MULTILINGUA, V32, P801, DOI 10.1515/multi-2013-0038; Su H, 2023, J PRAGMATICS, V212, P44, DOI 10.1016/j.pragma.2023.05.004; Su H, 2017, J PRAGMATICS, V111, P72, DOI 10.1016/j.pragma.2017.02.008; Su YW, 2017, FOREIGN LANG ANN, V50, P433, DOI 10.1111/flan.12263; Taguchi N., 2006, Pragmatics, V16, P513, DOI [10.1075/prag.16.4.05tag, DOI 10.1075/PRAG.16.4.05TAG]; Taguchi N, 2015, INT J APPL LINGUIST, V25, P343, DOI 10.1111/ijal.12073; Taguchi Naoko, 2011, Analysis of Appropriateness, Accuracy, Fluency, V49, P265, DOI [10.1515/iral.2011.015, DOI 10.1515/IRAL.2011.015]; Takahashi T., 1987, JALT J, V8, P131; Tantucci V, 2022, J PRAGMATICS, V194, P54, DOI 10.1016/j.pragma.2022.04.012; THOMAS J, 1983, APPL LINGUIST, V4, P91, DOI 10.1093/applin/4.2.91; van Compernolle R.A., 2014, De Gruyter, DOI DOI 10.21832/9781783091409; Van Ek J.A., 1986, OBJECTIVES FOREIGN L, V1; VANDIJK TA, 1979, J PRAGMATICS, V3, P447, DOI 10.1016/0378-2166(79)90019-5	73	0	0	19	19	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0378-2166	1879-1387		J PRAGMATICS	J. Pragmat.	APR	2024	223						14	30		10.1016/j.pragma.2024.01.003	http://dx.doi.org/10.1016/j.pragma.2024.01.003		FEB 2024	17	Linguistics; Language & Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics	OE2D3					2024-07-03	WOS:001205511200001
J	Durairaj, KK; Baker, O; Bertossi, D; Dayan, S; Karimi, K; Kim, R; Most, S; Robotti, E; Rosengaus, F				Durairaj, K. Kay; Baker, Omer; Bertossi, Dario; Dayan, Steven; Karimi, Kian; Kim, Roy; Most, Sam; Robotti, Enrico; Rosengaus, Frank			Artificial Intelligence Versus Expert Plastic Surgeon: Comparative Study Shows ChatGPT "Wins" Rhinoplasty Consultations: Should We Be Worried?	FACIAL PLASTIC SURGERY & AESTHETIC MEDICINE			English	Article								Introduction: Large language models, such as ChatGPT, hold tremendous promise to bridge gaps in patient education and enhance the decision-making resources available online for patients seeking nasal surgery.Objective: To compare the performance of ChatGPT in answering preoperative and postoperative patient questions related to septorhinoplasty.Methods: Two sets of responses were collected for the questions: one from an expert rhinoplasty surgeon with over two decades of experience, and the other from ChatGPT-3.5. Seven expert rhinoplasty surgeons, blinded to the source of responses, independently assessed the responses using a 5-point Likert scale in four performance areas: empathy, accuracy, completeness, and overall quality.Results: ChatGPT outperformed physician responses in three of the four performance areas, earning significantly higher ratings in accuracy, completeness, and overall quality (p < 0.001). In addition, ChatGPT was overwhelmingly preferred over physician responses (p < 0.001), with evaluators favoring ChatGPT in 80.95% of instances.Conclusions: ChatGPT has demonstrated its remarkable ability to deliver accurate, complete, and high-quality responses to preoperative and postoperative patient questions. Although certain improvements are warranted, this artificial intelligence tool has shown its potential to effectively counsel and educate prospective septorhinoplasty patients at a level comparable with or exceeding that of an expert surgeon.	[Durairaj, K. Kay] Huntington Hosp, Dept Otolaryngol Head & Neck Surg, 800 S Fairmount Ave,Suite 325, Pasadena, CA 91105 USA; [Durairaj, K. Kay; Baker, Omer] Medical Corp, Pasadena, CA USA; [Bertossi, Dario] Univ Verona, Dept Head & Neck Surg, Verona, Italy; [Dayan, Steven] Denova Res, Chicago, IL USA; [Karimi, Kian] Dr Kian Nasal & Facial Plast Surg, Los Angeles, CA USA; [Kim, Roy; Most, Sam] Stanford Univ, Div Facial Plast & Reconstruct Surg, Stanford, CA USA	University of Southern California; Huntington Memorial Hospital; University of Verona; Stanford University	Durairaj, KK (corresponding author), Huntington Hosp, Dept Otolaryngol Head & Neck Surg, 800 S Fairmount Ave,Suite 325, Pasadena, CA 91105 USA.	drkay@beautybydrkay.com		bertossi, dario/0000-0002-8635-9967; Karimi, Kian/0000-0002-3803-8560; Most, Sam/0000-0002-7385-3149				Akinosun M, 2023, FACIAL PLAST SURG AE, V25, P536, DOI 10.1089/fpsam.2022.0388; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Burgess DJ, 2010, J GEN INTERN MED, V25, pS169, DOI 10.1007/s11606-009-1221-4; Chew HSJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/32939; Dugdale DC, 1999, J GEN INTERN MED, V14, pS34, DOI 10.1046/j.1525-1497.1999.00263.x; Farina M, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1130913; Fassas SN, 2022, FACIAL PLAST SURG AE, V24, P363, DOI 10.1089/fpsam.2021.0100; Flynn JP, 2021, FACIAL PLAST SURG AE, V23, P339, DOI 10.1089/fpsam.2020.0328; Freeman SC., 2023, STATPEARLS; Freiberg A, 1997, PLAST RECONSTR SURG, V100, P1824, DOI 10.1097/00006534-199712000-00029; Hu K., 2023, Reuters; Jones HE, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005098; Kanavakis G, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245557; Khansa I, 2016, AESTHET SURG J, V36, pNP1, DOI 10.1093/asj/sjv095; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; Papadopulos NA, 2021, FACIAL PLAST SURG, V37, P639, DOI 10.1055/s-0041-1725174; Park CW, 2020, J KOREAN MED SCI, V35, DOI 10.3346/jkms.2020.35.e379; Rohrich R, 2021, PLAST RECONSTR SURG, V148, P1021, DOI 10.1097/PRS.0000000000008494; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Shamil E, 2022, FACIAL PLAST SURG, V38, P530, DOI 10.1055/s-0041-1735622; Shanafelt Tait D, 2022, Mayo Clin Proc, V97, P2248, DOI 10.1016/j.mayocp.2022.09.002; Walsh S, 2019, IRISH J MED SCI, V188, P1379, DOI 10.1007/s11845-019-01999-5; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7	25	4	4	4	4	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	2689-3614	2689-3622		FACIAL PLAST SURG AE	Facial Plast. Surg. Aesthet. Med.	JUN 1	2024	26	3					270	275		10.1089/fpsam.2023.0224	http://dx.doi.org/10.1089/fpsam.2023.0224		NOV 2023	6	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	TX0I0	37982677				2024-07-03	WOS:001141249000001
J	Truhn, D; Weber, CD; Braun, BJ; Bressem, K; Kather, JN; Kuhl, C; Nebelung, S				Truhn, Daniel; Weber, Christian D.; Braun, Benedikt J.; Bressem, Keno; Kather, Jakob N.; Kuhl, Christiane; Nebelung, Sven			A pilot study on the efficacy of GPT-4 in providing orthopedic treatment recommendations from MRI reports	SCIENTIFIC REPORTS			English	Article							ARTHRITIS	Large language models (LLMs) have shown potential in various applications, including clinical practice. However, their accuracy and utility in providing treatment recommendations for orthopedic conditions remain to be investigated. Thus, this pilot study aims to evaluate the validity of treatment recommendations generated by GPT-4 for common knee and shoulder orthopedic conditions using anonymized clinical MRI reports. A retrospective analysis was conducted using 20 anonymized clinical MRI reports, with varying severity and complexity. Treatment recommendations were elicited from GPT-4 and evaluated by two board-certified specialty-trained senior orthopedic surgeons. Their evaluation focused on semiquantitative gradings of accuracy and clinical utility and potential limitations of the LLM-generated recommendations. GPT-4 provided treatment recommendations for 20 patients (mean age, 50 years +/- 19 [standard deviation]; 12 men) with acute and chronic knee and shoulder conditions. The LLM produced largely accurate and clinically useful recommendations. However, limited awareness of a patient's overall situation, a tendency to incorrectly appreciate treatment urgency, and largely schematic and unspecific treatment recommendations were observed and may reduce its clinical usefulness. In conclusion, LLM-based treatment recommendations are largely adequate and not prone to 'hallucinations', yet inadequate in particular situations. Critical guidance by healthcare professionals is obligatory, and independent use by patients is discouraged, given the dependency on precise data input.	[Truhn, Daniel; Nebelung, Sven] Univ Hosp RWTH Aachen, Dept Diagnost & Intervent Radiol, Pauwels St 30, D-52074 Aachen, Germany; [Weber, Christian D.] Univ Hosp RWTH Aachen, Dept Orthopaed & Trauma Surg, Aachen, Germany; [Braun, Benedikt J.] Eberhard Karls Univ Tuebingen, Univ Hosp Tuebingen, BG Hosp, Schnarrenbergstr 95, Tubingen, Germany; [Bressem, Keno] Charite Univ Med Berlin, Dept Radiol, Hindenburgdamm 30, D-12203 Berlin, Germany; [Bressem, Keno] Free Univ Berlin, Hindenburgdamm 30, D-12203 Berlin, Germany; [Bressem, Keno] Humboldt Univ, Hindenburgdamm 30, D-12203 Berlin, Germany; [Kather, Jakob N.] Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Kather, Jakob N.] Univ Hosp Dresden, Dept Med 1, Dresden, Germany; [Kather, Jakob N.] Univ Hosp RWTH Aachen, Dept Med 3, Aachen, Germany; [Kather, Jakob N.] Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany	RWTH Aachen University; RWTH Aachen University Hospital; RWTH Aachen University; RWTH Aachen University Hospital; Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Technische Universitat Dresden; Technische Universitat Dresden; Carl Gustav Carus University Hospital; RWTH Aachen University; RWTH Aachen University Hospital; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg	Nebelung, S (corresponding author), Univ Hosp RWTH Aachen, Dept Diagnost & Intervent Radiol, Pauwels St 30, D-52074 Aachen, Germany.	snebelung@ukaachen.de	Truhn, Daniel/AAG-9359-2021	Truhn, Daniel/0000-0002-9605-0728; Braun, Benedikt/0000-0001-7575-0568; Weber, Christian David/0000-0001-8778-8002	German Federal Ministry of Health [ZMVI1-2520DAT111]; Max-Eder-Programme of the German Cancer Aid [70113864]; German Federal Ministry of Education and Research [01KD2104C, 01EO2101, 01KD2215A, 031L0312A, 01KT2302]; German Academic Exchange Service [57616814]; German Federal Joint Committee [01VSF21048]; European Union [101057091, 101096312]; National Institute for Health and Care Research (NIHR) Leeds Biomedical Research Centre [NIHR213331]; European Union's Horizon Europe programme (ODELIA) [101057091, 101079894]; Deutsche Forschungsgemeinschaft (DFG) [NE 2136/3-1, TR 1700/7-1]; Projekt DEAL; Horizon Europe - Pillar II [101096312, 101057091] Funding Source: Horizon Europe - Pillar II	German Federal Ministry of Health; Max-Eder-Programme of the German Cancer Aid; German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); German Academic Exchange Service(Deutscher Akademischer Austausch Dienst (DAAD)); German Federal Joint Committee; European Union(European Union (EU)); National Institute for Health and Care Research (NIHR) Leeds Biomedical Research Centre; European Union's Horizon Europe programme (ODELIA); Deutsche Forschungsgemeinschaft (DFG)(German Research Foundation (DFG)); Projekt DEAL; Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	Open Access funding enabled and organized by Projekt DEAL. JNK is supported by the German Federal Ministry of Health (DEEP LIVER, ZMVI1-2520DAT111) and the Max-Eder-Programme of the German Cancer Aid (grant #70113864), the German Federal Ministry of Education and Research (PEARL, 01KD2104C; CAMINO, 01EO2101; SWAG, 01KD2215A; TRANSFORM LIVER, 031L0312A; TANGERINE, 01KT2302 through ERA-NET Transcan), the German Academic Exchange Service (SECAI, 57616814), the German Federal Joint Committee (Transplant.KI, 01VSF21048) the European Union's Horizon Europe and innovation programme (ODELIA, 101057091; GENIAL, 101096312) and the National Institute for Health and Care Research (NIHR, NIHR213331) Leeds Biomedical Research Centre. The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health and Social Care. DT is supported by the European Union's Horizon Europe programme (ODELIA, 101057091), by grants from the Deutsche Forschungsgemeinschaft (DFG) (TR 1700/7-1), and the German Federal Ministry of Education and Research (SWAG, 01KD2215A; TRANSFORM LIVER, 031L0312A). SN is funded by grants from the Deutsche Forschungsgemeinschaft (DFG) (NE 2136/3-1). KB is supported by the European Union's Horizon Europe programme (COMFORT, 101079894).	Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bera K, 2024, CURR PROBL DIAGN RAD, V53, P215, DOI 10.1067/j.cpradiol.2023.10.013; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chillemi C, 2013, ARTHRITIS, DOI 10.1155/2013/370231; Coakley G, 2006, RHEUMATOLOGY, V45, P1039, DOI 10.1093/rheumatology/kel163a; Fangtham M, 2012, SEMIN ARTHRITIS RHEU, V41, P604, DOI 10.1016/j.semarthrit.2011.06.018; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kaandorp CJE, 1997, ARTHRITIS RHEUM-US, V40, P884, DOI 10.1002/art.1780400516; Khader F, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.230806; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Naziri Q, 2018, J ORTHOP, V15, P837, DOI 10.1016/j.jor.2018.08.006; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Olsen A. S., 2021, Principles of Orthopedic Practice for Primary Care Providers, P425; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Richardson JP, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00509-1; Ruby D., 2023, ChatGPT Statistics for 2023 (New Data + GPT-4 Facts); Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shan L, 2015, J BONE JOINT SURG AM, V97A, P156, DOI 10.2106/JBJS.M.00372; Shea YF, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.25000; Stanzione A., 2023, DIAGNOSTIC INTERVENT; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Tippareddy Charit, 2023, Curr Probl Diagn Radiol, DOI 10.1067/j.cpradiol.2023.08.018; Vallier HA, 2013, J ORTHOP TRAUMA, V27, P543, DOI 10.1097/BOT.0b013e31829efda1; Vuurberg G, 2018, BRIT J SPORT MED, V52, P956, DOI 10.1136/bjsports-2017-098106	28	6	6	5	7	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	NOV 17	2023	13	1							20159	10.1038/s41598-023-47500-2	http://dx.doi.org/10.1038/s41598-023-47500-2			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CL3Q3	37978240	gold, Green Published			2024-07-03	WOS:001125371600058
J	Pack, A; Maloney, J				Pack, Austin; Maloney, Jeffrey			Using Generative Artificial Intelligence for Language Education Research: Insights from Using OpenAI's ChatGPT	TESOL QUARTERLY			English	Article								Progress made in Natural Language Processing (NLP) and Artificial Intelligence (AI) in recent years has resulted in these tools becoming more accessible for individuals who lack professional training. Of particular note are large language models, such as OpenAI's GPT-3.5. Discussions of utilizing AI for language education usually focus on the impact the technology will have on students and teachers. Less frequently the center of attention is how generative AI tools can empower researchers. The purpose of this paper is to raise awareness by demonstrating and discussing examples of how OpenAI's chatbot, ChatGPT, can be leveraged as a tool for language education researchers. After briefly introducing the use of AI generative tools in the field, this paper demonstrates how a researcher, without any understanding of NLP or AI, may use ChatGPT to assist with research through multiple means, including approaches to its use for compiling and summarizing information, and as a research assistant throughout multiple steps of research. This is followed by a discussion of potential ethical concerns of using AI for research in the field. We conclude by issuing a call for further work examining how researchers can harness the potential of this technology in ethical ways.	[Pack, Austin; Maloney, Jeffrey] Brigham Young Univ Hawaii, Laie, HI 96762 USA	Brigham Young University; Brigham Young University - Hawaii	Pack, A (corresponding author), Brigham Young Univ Hawaii, Laie, HI 96762 USA.	austin.pack@byuh.edu		Maloney, Jeffrey/0000-0003-3769-7502; Pack, Austin/0000-0002-3861-5620				Akgun Selin, 2022, AI Ethics, V2, P431, DOI 10.1007/s43681-021-00096-7; Baker R S., 2021, Algorithmic bias in education, DOI DOI 10.35542/OSF.IO/PBMVZ; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bogen M., 2019, All the ways hiring algorithms can introduce bias, V6; ChatGPT FAQ, 2023, CHATGPT GEN FAQ; De Costa PI, 2021, LANG TEACHING, V54, P58, DOI 10.1017/S0261444820000257; Ducar C, 2018, FOREIGN LANG ANN, V51, P779, DOI 10.1111/flan.12366; Elicit, 2023, ASK RES QUEST; Godwin-Jones R, 2022, LANG LEARN TECHNOL, V26, P5, DOI 10.10125/73474; Godwin-Jones R, 2021, LANG LEARN TECHNOL, V25, P4; Gretel, 2023, SAF INC GEN AI YOUR; Guo Q, 2022, COMPUT ASSIST LANG L, V35, P2312, DOI 10.1080/09588221.2021.1879161; Idder A., 2021, ARTIF INTELL; Ingley SJ, 2023, TRENDS ECOL EVOL, V38, P785, DOI 10.1016/j.tree.2023.05.007; Iris, 2023, YOUR RES WORKSP; Koltovskaia S, 2020, ASSESS WRIT, V44, DOI 10.1016/j.asw.2020.100450; Liang JC, 2023, INTERACT LEARN ENVIR, V31, P4270, DOI 10.1080/10494820.2021.1958348; McCrocklin S., 2019, Journal of Second Language Pronunciation, V5, P98, DOI DOI 10.1075/JSLP.16034.MCC; Meurers D., 2012, ENCY APPL LINGUISTIC, P4193, DOI DOI 10.1002/9781405198431.WBEAL0858.PUB2; Moriarty P., 2023, CHATGPT DOES PHYS 60; Norris JM, 2015, LANG LEARN, V65, P470, DOI 10.1111/lang.12104; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; OpenAI, 2023, CHATGPT; Rietz T., 2021, P ACM C HUMAN FACTOR, DOI DOI 10.1145/3411764.3445591; Sterling S., 2018, The Palgrave Handbook of Applied Linguistics Research Methodology, P163, DOI [DOI 10.1057/978-1-137-59900-1_8, 10.1057/978-1-137-59900-1_8]; Talarian, 2023, GPT SHEETS DOCS; Wingard J., 2023, FORBES 0110; Woods D., 2023, NPR 0203	28	3	3	89	227	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0039-8322	1545-7249		TESOL QUART	Tesol Q.	DEC	2023	57	4					1571	1582		10.1002/tesq.3253	http://dx.doi.org/10.1002/tesq.3253		AUG 2023	12	Education & Educational Research; Linguistics	Social Science Citation Index (SSCI)	Education & Educational Research; Linguistics	X6VH3					2024-07-03	WOS:001041684200001
C	Campos, R; Jorge, A; Jatowt, A; Bhatia, S; Litvak, M		Kamps, J; Goeuriot, L; Crestani, F; Maistro, M; Joho, H; Davis, B; Gurrin, C; Kruschwitz, U; Caputo, A		Campos, Ricardo; Jorge, Alipio; Jatowt, Adam; Bhatia, Sumit; Litvak, Marina			The 6th International Workshop on Narrative Extraction from Texts: Text2Story 2023	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2023, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	45th European Conference on Information Retrieval (ECIR)	APR 02-06, 2023	Dublin, IRELAND	Dublin City Univ, British Comp Soc, Informat Retrieval Specialist Grp				Over these past five years, significant breakthroughs, led by Transformers and large language models, have been made in understanding natural language text. However, the ability to capture contextual nuances in longer texts is still an elusive goal, let alone the understanding of consistent fine-grained narrative structures in text. These unsolved challenges and the interest in the community are at the basis of the sixth edition of Text2Story workshop to be held in Dublin on April 2nd, 2023 in conjunction with the 45th European Conference on Information Retrieval (ECIR'23). In its sixth edition, we aim to bring to the forefront the challenges involved in understanding the structure of narratives and in incorporating their representation in well-established models, as well as in modern architectures (e.g., transformers) which are now common and form the backbone of almost every IR and NLP application. It is hoped that the workshop will provide a common forum to consolidate the multi-disciplinary efforts and foster discussions to identify the wide-ranging issues related to the narrative extraction and generation task. Text2Story includes sessions devoted to full research papers, work-in-progress, demos and dissemination papers, keynote talks and space for an informal discussion of the methods, of the challenges and of the future of this research area.	[Campos, Ricardo; Jorge, Alipio] LIAAD INESCTEC, Porto, Portugal; [Campos, Ricardo] Ci2 Smart Cities Res Ctr Polytechn Inst Tomar, Tomar, Portugal; [Jorge, Alipio] Univ Porto, FCUP, Porto, Portugal; [Jatowt, Adam] Univ Innsbruck, Innsbruck, Austria; [Bhatia, Sumit] Adobe Syst, MDSR Lab, Noida, India; [Litvak, Marina] Shamoon Coll Engn, Beer Sheva, Israel	Universidade do Porto; INESC TEC; Universidade do Porto; University of Innsbruck; Adobe Systems Inc.	Campos, R (corresponding author), LIAAD INESCTEC, Porto, Portugal.; Campos, R (corresponding author), Ci2 Smart Cities Res Ctr Polytechn Inst Tomar, Tomar, Portugal.	ricardo.campos@ipt.pt; amjorge@fc.up.pt; adam.jatowt@uibk.ac.at; Sumit.Bhatia@adobe.com; marinal@sce.ac.il	Jorge, Alípio/A-1721-2008; Campos, Ricardo/GWC-2301-2022	Jorge, Alípio/0000-0002-5475-1382; Campos, Ricardo/0000-0002-8767-8126; Litvak, Marina/0000-0003-3044-3681	Portuguese funding agency, FCT - Fundacao para a Ciencia e a Tecnologia [LA/P/0063/2020]; project Text2Story - ERDF - European Regional Development Fund through the Norte Portugal Regional Operational Programme - NORTE 2020 under the Portugal 2020 Partnership Agreement; FCT - Fundacao para a Ciencia e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology) within project Text2Story [PTDC/CCI-COM/31857/2017 (NORTE-01-0145-FEDER-031857)]	Portuguese funding agency, FCT - Fundacao para a Ciencia e a Tecnologia(Fundacao para a Ciencia e a Tecnologia (FCT)); project Text2Story - ERDF - European Regional Development Fund through the Norte Portugal Regional Operational Programme - NORTE 2020 under the Portugal 2020 Partnership Agreement; FCT - Fundacao para a Ciencia e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology) within project Text2Story	Ricardo Campos and Alipio Jorge are financed by National Funds through the Portuguese funding agency, FCT - Fundacao para a Ciencia e a Tecnologia, within project LA/P/0063/2020 and by the project Text2Story, financed by the ERDF - European Regional Development Fund through the Norte Portugal Regional Operational Programme - NORTE 2020 under the Portugal 2020 Partnership Agreement and by National Funds through the FCT - Fundacao para a Ciencia e a Tecnologia, I.P. (Portuguese Foundation for Science and Technology) within project Text2Story, with reference PTDC/CCI-COM/31857/2017 (NORTE-01-0145-FEDER-031857).	Alonso J. M, 2020, Lecture Notes in Computer Science, P63; Athanasakou V., 2020, P 1 JOINT WORKSH FIN, P1; Ayed A.B., 2021, Explainable AI Within the Digital Transformation and Cyber Physical Systems, P69, DOI [10.1007/978-3-030-76409-8, DOI 10.1007/978-3-030-76409-8]; Campos R., 2020, LNCS, V12036, P648; Campos R., 2021, LNCS, V12657, P701, DOI [10.1007/978-3-030-72240-1_84, DOI 10.1007/978-3-030-72240-1_84]; Campos R, 2022, LECT NOTES COMPUT SC, V13186, P552, DOI 10.1007/978-3-030-99739-7_68; Campos R, 2018, LECT NOTES COMPUT SC, V10772, P684, DOI 10.1007/978-3-319-76941-7_63; Celikyilmaz A, 2021, Arxiv, DOI arXiv:2006.14799; El-Haj M., 2021, P 3 FIN NARR PROC WO; Elhadi M, 2020, PATHOG GLOB HEALTH, V114, P230, DOI 10.1080/15575330.2020.1769292; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Goncalves F., 2023, LNCS; Grobelny J., 2018, International Journal of Academic Research in Business and Social Sciences, V8, P430; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Jorge A. M., 2019, PROC EUR C INF RETR, P389; Jorge AM, 2019, INFORM PROCESS MANAG, V56, P1771, DOI 10.1016/j.ipm.2019.05.004; Jorge AM, 2018, LECT NOTES COMPUT SC, V10772, P833; Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101; Martinez-Alvarez M., 2016, Advances in Information Retrieval, P878, DOI DOI 10.1007/978-3-319-30671-1_85; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Vo N, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P335, DOI 10.1145/3331184.3331248; Ozlem U., 2013, Biomedical Inf., V46, P1; Pasquali Arian, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12656), P497, DOI 10.1007/978-3-030-72113-8_33; Pasquali Arian, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11438), P251, DOI 10.1007/978-3-030-15719-7_34; Saakyan A, 2021, Arxiv, DOI arXiv:2106.03794; Santana B, 2023, ARTIF INTELL REV, V56, P8393, DOI 10.1007/s10462-022-10338-7; Sun SM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P807; Wu YF, 2020, JOURNAL PRACT, V14, P1008, DOI 10.1080/17512786.2019.1682940; Zmandar N., 2021, P 3 FINANCIAL NARRAT, P120	29	0	0	0	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-28240-9; 978-3-031-28241-6	LECT NOTES COMPUT SC			2023	13982						377	383		10.1007/978-3-031-28241-6_40	http://dx.doi.org/10.1007/978-3-031-28241-6_40			7	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV1RO					2024-07-03	WOS:000995495200040
C	Golia, L; Kalita, J			Assoc Computing Machinery	Golia, Logan; Kalita, Jugal			Action-Item-Driven Summarization of Long Meeting Transcripts	PROCEEDINGS OF 2023 7TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2023			English	Proceedings Paper	7th International Conference on Natural Language Processing and Information Retrieval (NLPIR)	DEC 15-17, 2023	Seoul, SOUTH KOREA			neural networks; text summarization; topic segmentation; action item extraction		The increased prevalence of online meetings has significantly enhanced the practicality of a model that can automatically generate the summary of a given meeting. This paper introduces a novel and effective approach to automate the generation of meeting summaries. Current approaches to this problem generate general and basic summaries, considering the meeting simply as a long dialogue. However, our novel algorithms can generate abstractive meeting summaries that are driven by the action items contained in the meeting transcript. This is done by recursively generating summaries and employing our action-item extraction algorithm for each section of the meeting in parallel. All of these sectional summaries are then combined and summarized together to create a coherent and action-item-driven summary. In addition, this paper introduces three novel methods for dividing up long transcripts into topic-based sections to improve the time efficiency of our algorithm, as well as to resolve the issue of large language models (LLMs) forgetting long-term dependencies. Our pipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an approximately 4.98% increase from the current state-of-the-art result produced by a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.(1)	[Golia, Logan] Rice Univ, Houston, TX 77251 USA; [Kalita, Jugal] Univ Colorado, Colorado Springs, CO USA	Rice University; University of Colorado System; University of Colorado at Colorado Springs	Golia, L (corresponding author), Rice Univ, Houston, TX 77251 USA.	lsg3@rice.edu; jkalita@uccs.edu						Clark K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P643; Cohen ADN, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2862; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong Z., 2023, arXiv; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Feng XC, 2022, Arxiv, DOI arXiv:2107.03175; Gliwa Bogdan, 2019, P 2 WORKSHOP NEW FRO, P70, DOI DOI 10.18653/V1/D19-5409; Gupta S, 2019, EXPERT SYST APPL, V121, P49, DOI 10.1016/j.eswa.2018.12.011; Hearst MA, 1997, COMPUT LINGUIST, V23, P33; Koh HY, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3545176; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mccowan Iain, 2005, Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research; Mohammed Farooq Abdulla FM, 2022, 2022 INT C COMM COMP, P1, DOI DOI 10.1109/IC3IOT53935.2022.9767933; Nagamatsu Kenji, 2021, arXiv; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Obonyo Ishmael., 2022, Exploring the limits of a base BART for multi-document summarization in the medical domain; Rennard V, 2023, Arxiv, DOI arXiv:2208.04163; Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_00313, 10.1162/tacl_a_.00313]; Shinde Kartik., 2022, AUTOMATIC MINUTING P; Solbiati Alessandro, 2021, UNS TOP SEGM M BERT; Song KT, 2020, Arxiv, DOI arXiv:2004.09297; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wu J., 2021, arXiv; Yang XJ, 2023, Arxiv, DOI arXiv:2302.08081; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang Yusen, 2022, arXiv; Zhong Ming, 2022, arXiv	29	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0922-7				2023							91	98		10.1145/3639233.3639253	http://dx.doi.org/10.1145/3639233.3639253			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6NK		Green Submitted			2024-07-03	WOS:001179071500014
C	He, JB; Wang, L; Hu, Y; Liu, N; Liu, H; Xu, X; Shen, HT			IEEE	He, Jiabang; Wang, Lei; Hu, Yi; Liu, Ning; Liu, Hui; Xu, Xing; Shen, Heng Tao			ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Large language models (LLMs), such as GPT-3 and ChatGPT, have demonstrated remarkable results in various natural language processing (NLP) tasks with in-context learning, which involves inference based on a few demonstration examples. Despite their successes in NLP tasks, no investigation has been conducted to assess the ability of LLMs to perform document information extraction ( DIE) using in-context learning. Applying LLMs to DIE poses two challenges: the modality and task gap. To this end, we propose a simple but effective in-context learning framework called ICL-D3IE, which enables LLMs to perform DIE with different types of demonstration examples. Specifically, we extract the most difficult and distinct segments from hard training documents as hard demonstrations for benefiting all test instances. We design demonstrations describing relationships that enable LLMs to understand positional relationships. We introduce formatting demonstrations for easy answer extraction. Additionally, the framework improves diverse demonstrations by updating them iteratively. Our experiments on three widely used benchmark datasets demonstrate that the ICL-D3IE framework enables Davinci-003/ChatGPT to achieve superior performance when compared to previous pre-trained methods fine-tuned with full training in both the in-distribution (ID) setting and in the out-of-distribution (OOD) setting. Code is available at https://github.com/MAEHCM/ICL-D3IE.	[He, Jiabang; Hu, Yi; Xu, Xing; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China; [He, Jiabang; Hu, Yi; Xu, Xing; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China; [Wang, Lei] Singapore Management Univ, Singapore, Singapore; [Liu, Ning] Beijing Forestry Univ, Beijing, Peoples R China; [Liu, Hui] Beijing Rongda Technol Co Ltd, Beijing, Peoples R China	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Singapore Management University; Beijing Forestry University	Xu, X (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu, Peoples R China.; Wang, L (corresponding author), Singapore Management Univ, Singapore, Singapore.	lei.wang.2019@phdcs.smu.edu.sg; xing.xu@uestc.edu.cn	Shen, Heng Tao/ABD-5331-2021		National Natural Science Foundation of China [62222203, 61976049]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by National Natural Science Foundation of China under Grants (No. 62222203 and 61976049).	Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao HY, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P4261, DOI 10.1145/3503161.3547877; CAO Rui, 2022, PROMPTING MULTIMODAL; Chen Wenhu, 2022, ARXIV221112588; Chowdhery Aakanksha, 2022, ABS220402311 ARXIV; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong Qingxiu, 2022, SURVEY CONTEXT LEARN; Dong Qingxiu, 2022, ARXIV230100234; Dosovitskiy A, 2021, INT C LEARNING REPRE; Gu Zhangxuan, 2022, CVPR; Guo Jiaxian, 2022, ARXIV221210846; Hong Teakgyu, 2022, AAAI; Hu Yushi, 2022, ARXIV221109699; Huang Yupan, 2022, ARXIV220408387; Jaume G, 2019, PROC INT CONF DOC, P1, DOI 10.1109/ICDARW.2019.10029; Kim Geewook, 2022, EUR C COMP VIS ECCV; Li Junlong, 2022, ARXIV220302378; Li PC, 2021, SMALL SCI, V1, DOI 10.1002/smsc.202000015; Li Yulin, 2021, ACM Multimedia; Liu Xiaojing, 2019, Graph Convolution for Multimodal Information Extraction from Visually Rich Documents; Lu Pan, 2022, ARXIV220914610; Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Park Seunghyun, 2019, Cord: A consolidated receipt dataset for post-ocr parsing; Park Seunghyun, 2019, WORKSH DOC INT NEURI; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Shaikh Omar, 2022, ARXIV221208061; Suzgun Mirac, 2022, ABS221009261 ARXIV; Tsimpoukelli Maria, 2021, ARXIV210613884; Wang Boshi, 2022, ARXIV221210001; Wang Jiapeng, 2022, ACL; Wang Lei, 2022, ARXIV221114777; Wang Xuezhi, 2022, arXiv:2203.11171; Wei Jason, 2022, 36 C NEUR INF PROC S; Wei Jason, 2022, ABS220607682 CORR; Xu Y., 2021, ENERGY ENVIRON MATER, V5, P1; XU YH, 2020, LAYOUTLM PRETRAINING, P1192, DOI DOI 10.1145/3394486.3403172; Xu YH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1192, DOI 10.1145/3394486.3403172; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Zeng Andy, 2022, ARXIV220400598; Zhang Susan, 2022, ABS220501068 CORR; Zhao Xiaohui, 2019, ARXIV190312363; Zheng Huang, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1516, DOI 10.1109/ICDAR.2019.00244; Zhou Denny, 2022, arXiv:2205.10625	45	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							19428	19437		10.1109/ICCV51070.2023.01785	http://dx.doi.org/10.1109/ICCV51070.2023.01785			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO		Green Submitted			2024-07-03	WOS:001169500504006
C	Li, P; Sun, TX; Tang, Q; Yan, H; Wu, YB; Huang, XJ; Qiu, XP		Rogers, A; Boyd-Graber, J; Okazaki, N		Li, Peng; Sun, Tianxiang; Tang, Qiong; Yan, Hang; Wu, Yuanbin; Huang, Xuanjing; Qiu, Xipeng			CODEIE: Large Code Generation Models are Better Few-Shot Information Extractors	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is non-trivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks. Experiment results on seven benchmarks show that our method consistently outperforms fine-tuning moderate-size pre-trained models specially designed for IE tasks (e.g., UIE) and prompting NL-LLMs under few-shot settings. We further conduct a series of in-depth analyses to demonstrate the merits of leveraging Code-LLMs for IE tasks.(1)	[Li, Peng] Fudan Univ, Acad Engn & Technol, Shanghai, Peoples R China; [Sun, Tianxiang; Tang, Qiong; Yan, Hang; Huang, Xuanjing; Qiu, Xipeng] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China; [Wu, Yuanbin] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China	Fudan University; Fudan University; East China Normal University	Qiu, XP (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.	lip21@m.fudan.edu.cn; txsun19@fudan.edu.cn; qtang22@m.fudan.edu.cn; hyan19@fudan.edu.cn; ybwu@cs.ecnu.edu.cn; xjhuang@fudan.edu.cn; xpqiu@fudan.edu.cn			National Natural Science Foundation of China [62236004, 62022027]; CCF-Baidu Open Fund	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCF-Baidu Open Fund	We would like to express our gratitude to the reviewers for their helpful comments and suggestions. We are also very grateful to Yaojie Lu for his friendly assistance during our experiments. This work was supported by the National Natural Science Foundation of China (No. 62236004 and No. 62022027) and CCF-Baidu Open Fund.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Brown Tom B., 2020, Advances in Neural Information Processing Systems; Cabot PLH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2370; Chen M., 2021, ARXIV; Cheng Zhoujun, 2022, ABS221002875 CORR; Chowdhery Aakanksha, 2022, CoRR, abs/2204.02311; Doddington G., 2004, LREC, P1; Epure Elena V., 2021, ABS210811857 CORR; Grishman R, 2019, NAT LANG ENG, V25, P677, DOI 10.1017/S1351324919000512; Gutierrez Bernal Jimenez, 2022, ABS220308410 CORR; Hoffmann Jordan, 2022, ABS220315556 CORR; Josifoski M, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4626; Li X, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P17; Lu YJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5755; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Madaan Aman, 2022, ABS221007128 CORR; Min Sewon, 2022, ABS220212837 CORR; Paolini G., 2021, 9 INT C LEARNING REP; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae Jack W., 2021, ABS211211446 CORR; Raffel C, 2020, J MACH LEARN RES, V21; Riedel S, 2010, LECT NOTES ARTIF INT, V6323, P148, DOI 10.1007/978-3-642-15939-8_10; Sang E. T. K., 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195; Sun T., 2022, PROC ICML, P20841; Suzgun Mirac, 2022, ABS221009261 CORR; Walker C., 2006, Ace 2005 multilingual training corpus, DOI DOI 10.35111/MWXC-VH88; Wang Xingyao, 2022, ABS221012810 CORR; Wang YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P220; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Yan H., 2021, P 59 ANN M ASS COMPU, P5808; Yan H, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2416; Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P50	32	2	2	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15339	15353						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962507008
J	Hashimoto, DA; Johnson, KB				Hashimoto, Daniel A.; Johnson, Kevin B.			The Use of Artificial Intelligence Tools to Prepare Medical School Applications	ACADEMIC MEDICINE			English	Editorial Material								Advances in artificial intelligence (AI) have been changing the landscape in daily life and the practice of medicine. As these tools have evolved to become consumer-friendly, AI has become more accessible to many individuals, including applicants to medical school. With the rise of AI models capable of generating complex passages of text, questions have arisen regarding the appropriateness of using such tools to assist in the preparation of medical school applications.In this commentary, the authors offer a brief history of AI tools in medicine and describe large language models, a form of AI capable of generating natural language text passages. They question whether AI assistance should be considered inappropriate in preparing applications and compare it with the assistance some applicants receive from family, physician friends, or consultants. They call for clearer guidelines on what forms of assistance-human and technological-are permitted in the preparation of medical school applications. They recommend that medical schools steer away from blanket bans on AI tools in medical education and instead consider mechanisms for knowledge sharing about AI between students and faculty members, incorporation of AI tools into assignments, and the development of curricula to teach the use of AI tools as a competency.	[Hashimoto, Daniel A.] Univ Penn, Gen Robot Automat Sensing & Percept Lab, Philadelphia, PA USA; [Johnson, Kevin B.] Univ Penn, Pediat Biomed Informat & Sci Commun, Philadelphia, PA USA; [Hashimoto, Daniel A.] 3400 Spruce St, 4 Silverstein Pavil, Philadelphia, PA 19104 USA	University of Pennsylvania; University of Pennsylvania	Hashimoto, DA (corresponding author), 3400 Spruce St, 4 Silverstein Pavil, Philadelphia, PA 19104 USA.	daniel.hashimoto@pennmedicine.upenn.edu		/0000-0003-4725-3104				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], APPL ACC PROT APPL; [Anonymous], 2022, 2022 FACTS APPL MATR; [Anonymous], DEF ROL AUTH CONTR; [Anonymous], PARTS YOUR MED SCH A; Association of American Medical Colleges (AAMC), HOL REV; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bellman R., 1978, An Introduction to Artificial Intelligence: Can Computers Think?; Cohen TA., 2022, INTELLIGENT SYSTEMS; Conrad SS, 2016, ACAD MED, V91, P1472, DOI 10.1097/ACM.0000000000001403; DeVilbiss MB, 2023, ACAD MED, V98, P865, DOI 10.1097/ACM.0000000000005261; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Hashimoto DA., 2021, Artificial Intelligence in Surgery: Understanding the Role of AI in Surgical Practice; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kirchner JH., THE OPEN; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Mascagni P, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00707-5; MILLER RA, 1982, NEW ENGL J MED, V307, P468, DOI 10.1056/NEJM198208193070803; Mollick E. R., 2023, The Wharton School Research Paper, DOI DOI 10.2139/SSRN.4391243; Radford A., 2018, IMPROVING LANGUAGE U; Russell RG, 2023, ACAD MED, V98, P348, DOI 10.1097/ACM.0000000000004963; SHORTLIFFE EH, 1973, COMPUT BIOMED RES, V6, P544, DOI 10.1016/0010-4809(73)90029-3; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Williams C, 2021, ACAD MED, V96, pS219, DOI 10.1097/ACM.0000000000004281; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	26	4	4	5	6	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	1040-2446	1938-808X		ACAD MED	Acad. Med.	SEP	2023	98	9					978	982		10.1097/ACM.0000000000005309	http://dx.doi.org/10.1097/ACM.0000000000005309			5	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	Q8XH3	37369073	Bronze			2024-07-03	WOS:001060289200009
J	Khondkaryan, L; Tevosyan, A; Navasardyan, H; Khachatrian, H; Tadevosyan, G; Apresyan, L; Chilingaryan, G; Navoyan, Z; Stopper, H; Babayan, N				Khondkaryan, Lusine; Tevosyan, Ani; Navasardyan, Hayk; Khachatrian, Hrant; Tadevosyan, Gohar; Apresyan, Lilit; Chilingaryan, Gayane; Navoyan, Zaven; Stopper, Helga; Babayan, Nelly			Datasets Construction and Development of QSAR Models for Predicting Micronucleus In Vitro and In Vivo Assay Outcomes	TOXICS			English	Article						micronucleus; in vitro; in vivo; prediction; ensemble; chemotypes analysis	GENOTOXICITY	In silico (quantitative) structure-activity relationship modeling is an approach that provides a fast and cost-effective alternative to assess the genotoxic potential of chemicals. However, one of the limiting factors for model development is the availability of consolidated experimental datasets. In the present study, we collected experimental data on micronuclei in vitro and in vivo, utilizing databases and conducting a PubMed search, aided by text mining using the BioBERT large language model. Chemotype enrichment analysis on the updated datasets was performed to identify enriched substructures. Additionally, chemotypes common for both endpoints were found. Five machine learning models in combination with molecular descriptors, twelve fingerprints and two data balancing techniques were applied to construct individual models. The best-performing individual models were selected for the ensemble construction. The curated final dataset consists of 981 chemicals for micronuclei in vitro and 1309 for mouse micronuclei in vivo, respectively. Out of 18 chemotypes enriched in micronuclei in vitro, only 7 were found to be relevant for in vivo prediction. The ensemble model exhibited high accuracy and sensitivity when applied to an external test set of in vitro data. A good balanced predictive performance was also achieved for the micronucleus in vivo endpoint.	[Khondkaryan, Lusine; Tadevosyan, Gohar; Apresyan, Lilit; Babayan, Nelly] NAS RA, Inst Mol Biol, Yerevan 0014, Armenia; [Khondkaryan, Lusine; Tevosyan, Ani; Navasardyan, Hayk; Tadevosyan, Gohar; Apresyan, Lilit; Navoyan, Zaven; Babayan, Nelly] Toxometris ai, Yerevan 0009, Armenia; [Tevosyan, Ani; Khachatrian, Hrant; Chilingaryan, Gayane] YerevaNN, Yerevan 0025, Armenia; [Khachatrian, Hrant] Yerevan State Univ, Dept Informat & Appl Math, Yerevan 0025, Armenia; [Stopper, Helga] Univ Wurzburg, Inst Pharmacol & Toxicol, D-97078 Wurzburg, Germany	National Academy of Sciences of Armenia; Institute of Molecular Biology - NAS RA; Yerevan State University; University of Wurzburg	Babayan, N (corresponding author), NAS RA, Inst Mol Biol, Yerevan 0014, Armenia.; Babayan, N (corresponding author), Toxometris ai, Yerevan 0009, Armenia.	l_khondkaryan@mb.sci.am; atevosyan@toxometris.ai; hnavasardyan@toxometris.ai; hrant@yerevann.com; g_tadevosyan@mb.sci.am; l_apresyan@mb.sci.am; gayane@yerevann.com; znavoyan@toxometris.ai; stopper@toxi.uni-wuerzburg.de; n_babayan@mb.sci.am	Babayan, Nelly/KGM-2638-2024	Babayan, Nelly/0000-0001-9205-7693; Stopper, Helga/0000-0003-4168-8211	RA MES (Republic of Armenia, Ministry of Educationand Science) State Committee of Science [20TTCG-1F004]	RA MES (Republic of Armenia, Ministry of Educationand Science) State Committee of Science	This research was funded by the RA MES (Republic of Armenia, Ministry of Educationand Science) State Committee of Science, in the framework of the research project No 20TTCG-1F004.	[Anonymous], EU Pesticides List of Approved Active Substances of Pesticides; [Anonymous], FDA FDA Drugs; [Anonymous], 2016, Test No. 487, DOI [DOI 10.1787/9789264264861-EN, 10.1787/9789264264861-en]; ASHBY J, 1988, MUTAT RES, V204, P17, DOI 10.1016/0165-1218(88)90114-0; Baderna D, 2020, J HAZARD MATER, V385, DOI 10.1016/j.jhazmat.2019.121638; Benigni R, 2020, EXPERT OPIN DRUG MET, V16, P651, DOI 10.1080/17425255.2020.1785428; Benigni R, 2012, MUTAGENESIS, V27, P87, DOI 10.1093/mutage/ger064; Bernauer U, 2021, REGUL TOXICOL PHARM, V127, DOI 10.1016/j.yrtph.2021.105052; Blagus R, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-106; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Butina D, 1999, J CHEM INF COMP SCI, V39, P747, DOI 10.1021/ci9803381; Canipa S, 2016, MUTAGENESIS, V31, P17, DOI 10.1093/mutage/gev047; Carracedo-Reboredo P, 2021, COMPUT STRUCT BIOTEC, V19, P4538, DOI 10.1016/j.csbj.2021.08.011; Chemical Carcinogenesis Research Information System (CCRIS), ABOUT US; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chilingaryan G., 2022, arXiv; Coley CW, 2019, CHEM SCI, V10, P370, DOI 10.1039/c8sc04228d; Corvi R, 2017, FOOD CHEM TOXICOL, V106, P600, DOI 10.1016/j.fct.2016.08.024; ECHA, Endocrine Disruptor Assessment List; ECHA, 2016, Practical Guide How to Use and Report (Q)SARs. Practical Guide 5, DOI [10.2823/81818, DOI 10.2823/81818]; ECHA EU Biocides, List of Approved Substances in Biocides; ECHA REACH, Registered Substances List; ECHA SVHCs, Candidate List of Substances of Very High Concern for Authorisation; Elder DP, 2009, J PHARM PHARMACOL, V61, P269, DOI 10.1211/jpp/61.03.0001; EURL, ECVAM Genotoxicity and Carcinogenicity Consolidated Database of Ames Negative Chemicals; europa.eu, EURL ECVAM Genotoxicity and Carcinogenicity Consolidated Database of Ames Positive Chemicals; Fan DF, 2018, TOXICOL RES-UK, V7, P211, DOI 10.1039/c7tx00259a; Honma M, 2019, MUTAGENESIS, V34, P3, DOI 10.1093/mutage/gey031; Hsieh JH, 2019, CHEM RES TOXICOL, V32, P1384, DOI 10.1021/acs.chemrestox.9b00053; ICH, 2015, ICH M7-Assessment and Control of DNA Reactive (Mutagenic) Impurities in Pharmaceuticals to Limit Potential Carcinogenic Risk; Judson RS, 2010, ENVIRON HEALTH PERSP, V118, P485, DOI 10.1289/ehp.0901392; Kramer O, 2016, STUD BIG DATA, V20, P45, DOI 10.1007/978-3-319-33383-0_5; Landrum G., RDKIT OPEN SOURCE CH, DOI DOI 10.1007/S10822-016-9949-5; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Mendez D, 2019, NUCLEIC ACIDS RES, V47, pD930, DOI 10.1093/nar/gky1075; Mitchell JBO, 2014, WIRES COMPUT MOL SCI, V4, P468, DOI 10.1002/wcms.1183; Morita T, 2019, MUTAGENESIS, V34, P91, DOI 10.1093/mutage/gey017; Müller L, 2006, REGUL TOXICOL PHARM, V44, P198, DOI 10.1016/j.yrtph.2005.12.001; OECD, 2014, Test No. 474: Mammalian Erythrocyte Micronucleus Test, DOI [10.1787/9789264224292-en, DOI 10.1787/9789264224292-EN]; OECD, 2017, OECD Series on Testing and Assessment, V238, DOI [10.1787/9789264274761-en, DOI 10.1787/9789264274761-EN]; Paszke A, 2019, ADV NEUR IN, V32; Prati R.C., 2009, P 4 INT C ART INT TU; Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7; SCP, 2001, Preliminary Opinion of the Scientific Committee on Plants Regarding the Evaluation of Benomyl, Carbendazim and Thiophanate-methyl in the Context of Council Directive 91/414/EEC Concerning the Placing of Plant Protection Products on the Market; Stavitskaya L., 2015, Genotoxicity and Carcinogenicity Testing of Pharmaceuticals, V1st ed., P13, DOI DOI 10.1007/978-3-319-22084-0_2; Sukumar N., 2014, Applications of Metaheuristics in Process Engineering, P315, DOI [DOI 10.1007/978-3-319-06508-3_13, 10.1007/978-3-319-06508-3_13]; Tcheremenskaia O, 2021, EXPERT OPIN DRUG MET, V17, P987, DOI 10.1080/17425255.2021.1938540; Tetko IV, 2005, J COMPUT AID MOL DES, V19, P453, DOI 10.1007/s10822-005-8694-y; Tweats DJ, 2007, MUTAT RES-GEN TOX EN, V627, P92, DOI 10.1016/j.mrgentox.2006.10.006; Tweats DJ, 2016, MUTAGENESIS, V31, P309, DOI 10.1093/mutage/gev070; Chawla NV, 2011, Arxiv, DOI [arXiv:1106.1813, 10.48550/arxiv.1106.1813, 10.1613/jair.953]; Van Bossuyt M, 2020, TOXICOL LETT, V329, P80, DOI 10.1016/j.toxlet.2020.04.016; Van Hulse J., 2007, P 24 INT C MACH LEAR, P935, DOI DOI 10.1145/1273496.1273614; Vapnik V. N., 1963, Autom Remote Control, V24, P774; Wang J, 2019, ENVIRON INT, V126, P377, DOI 10.1016/j.envint.2019.02.024; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Yang CH, 2015, J CHEM INF MODEL, V55, P510, DOI 10.1021/ci500667v; Yoo JW, 2020, REGUL TOXICOL PHARM, V113, DOI 10.1016/j.yrtph.2020.104620	59	0	0	3	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2305-6304		TOXICS	Toxics	SEP	2023	11	9							785	10.3390/toxics11090785	http://dx.doi.org/10.3390/toxics11090785			15	Environmental Sciences; Toxicology	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Toxicology	S9TZ0	37755795	Green Published, gold			2024-07-03	WOS:001074530800001
J	Kulikova, AV; Diaz, DJ; Chen, T; Cole, TJ; Ellington, AD; Wilke, CO				Kulikova, Anastasiya V.; Diaz, Daniel J.; Chen, Tianlong; Cole, T. Jeffrey; Ellington, Andrew D.; Wilke, Claus O.			Two sequence- and two structure-based ML models have learned different aspects of protein biochemistry	SCIENTIFIC REPORTS			English	Article							PREDICTION	Deep learning models are seeing increased use as methods to predict mutational effects or allowed mutations in proteins. The models commonly used for these purposes include large language models (LLMs) and 3D Convolutional Neural Networks (CNNs). These two model types have very different architectures and are commonly trained on different representations of proteins. LLMs make use of the transformer architecture and are trained purely on protein sequences whereas 3D CNNs are trained on voxelized representations of local protein structure. While comparable overall prediction accuracies have been reported for both types of models, it is not known to what extent these models make comparable specific predictions and/or generalize protein biochemistry in similar ways. Here, we perform a systematic comparison of two LLMs and two structure-based models (CNNs) and show that the different model types have distinct strengths and weaknesses. The overall prediction accuracies are largely uncorrelated between the sequence- and structure-based models. Overall, the two structure-based models are better at predicting buried aliphatic and hydrophobic residues whereas the two LLMs are better at predicting solvent-exposed polar and charged amino acids. Finally, we find that a combined model that takes the individual model predictions as input can leverage these individual model strengths and results in significantly improved overall prediction accuracy.	[Kulikova, Anastasiya V.; Cole, T. Jeffrey; Wilke, Claus O.] Univ Texas Austin, Dept Integrat Biol, Austin, TX 78712 USA; [Diaz, Daniel J.] Univ Texas Austin, Dept Chem, Austin, TX USA; [Kulikova, Anastasiya V.; Diaz, Daniel J.; Ellington, Andrew D.] Univ Texas Austin, Ctr Syst & Synthet Biol, Dept Mol Biosci, Austin, TX USA; [Diaz, Daniel J.; Chen, Tianlong] Univ Texas Austin, Inst Fdn Machine Learning IFML, Austin, TX USA; [Chen, Tianlong] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX USA	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin	Wilke, CO (corresponding author), Univ Texas Austin, Dept Integrat Biol, Austin, TX 78712 USA.	wilke@austin.utexas.edu	Wilke, Claus O./B-4643-2008	Wilke, Claus/0000-0002-7470-9261; Ellington, Andrew/0000-0001-6246-5338	Welch Foundation [F-1654]; Department of Defense - Defense Threat Reduction Agency [HDTRA12010011]; National Institutes of Health [R01 AI148419]; NSF's National AI Institute for Foundations of Machine Learning [2019844]; Advanced Micro Devices, Inc.; Jane and Roland Blumberg Centennial Professorship in Molecular Evolution; Dwight W. and Blanche Faye Reeder Centennial Fellowship in Systematic and Evolutionary Biology at UT Austin; U.S. Department of Defense (DOD) [HDTRA12010011] Funding Source: U.S. Department of Defense (DOD)	Welch Foundation(The Welch Foundation); Department of Defense - Defense Threat Reduction Agency(United States Department of DefenseDefense Threat Reduction Agency); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NSF's National AI Institute for Foundations of Machine Learning; Advanced Micro Devices, Inc.; Jane and Roland Blumberg Centennial Professorship in Molecular Evolution; Dwight W. and Blanche Faye Reeder Centennial Fellowship in Systematic and Evolutionary Biology at UT Austin; U.S. Department of Defense (DOD)(United States Department of Defense)	This work was supported by grants from the Welch Foundation (F-1654), the Department of Defense - Defense Threat Reduction Agency (HDTRA12010011), and the National Institutes of Health (R01 AI148419). T.C. was supported by a fellowship from the NSF's National AI Institute for Foundations of Machine Learning (2019844). We would like to thank Advanced Micro Devices, Inc. (AMD) for the donation of critical hardware and support resources from its HPC Fund that made this work possible. C.O.W. also acknowledges funding from the Jane and Roland Blumberg Centennial Professorship in Molecular Evolution and the Dwight W. and Blanche Faye Reeder Centennial Fellowship in Systematic and Evolutionary Biology at UT Austin.	Abadi M., 2015, TensorFlow: Large-scale machine learning on heterogeneous systems, V1; Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754; Bateman A, 2021, NUCLEIC ACIDS RES, V49, pD480, DOI 10.1093/nar/gkaa1100; Bilbao Imanol, 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P173, DOI 10.1109/INTELCIS.2017.8260032; Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020; Castro E, 2022, NAT MACH INTELL, V4, P840, DOI 10.1038/s42256-022-00532-1; Chen Tianlong, 2023, 11 INT C LEARN REPR; d'Oelsnitz S, 2023, bioRxiv, DOI [10.1101/2023.04.05.535710, 10.1101/2023.04.05.535710, DOI 10.1101/2023.04.05.535710]; Dehghanpoor R, 2018, MOLECULES, V23, DOI 10.3390/molecules23020251; Diaz DJ, 2023, bioRxiv, DOI [10.1101/2023.05.15.540857, 10.1101/2023.05.15.540857, DOI 10.1101/2023.05.15.540857]; Diaz DJ, 2023, CURR OPIN STRUC BIOL, V78, DOI 10.1016/j.sbi.2022.102518; Dolinsky TJ, 2007, NUCLEIC ACIDS RES, V35, pW522, DOI 10.1093/nar/gkm276; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Elnaggar A, 2021, Arxiv, DOI [arXiv:2007.06225, 10.48550/arXiv.2007.06225]; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Hoie MH, 2022, CELL REP, V38, DOI 10.1016/j.celrep.2021.110207; Hsu C, 2021, bioRxiv, DOI [10.1101/2021.03.28.437402, 10.1101/2021.03.28.437402, DOI 10.1101/2021.03.28.437402]; Jones DT, 2012, BIOINFORMATICS, V28, P184, DOI 10.1093/bioinformatics/btr638; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kulikova AV, 2021, J BIOL PHYS, V47, P435, DOI 10.1007/s10867-021-09593-6; Lin ZM, 2022, bioRxiv, DOI [10.1101/2022.07.20.500902, 10.1101/2022.07.20.500902, DOI 10.1101/2022.07.20.500902]; Lu HY, 2022, NATURE, V604, P662, DOI 10.1038/s41586-022-04599-z; Meier J., 2021, ADV NEURAL INF PROCE, V34, P29287; Mitternacht Simon, 2016, F1000Res, V5, P189, DOI 10.12688/f1000research.7931.1; Paik I, 2023, BIOCHEMISTRY-US, V62, P410, DOI 10.1021/acs.biochem.1c00451; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Shroff R, 2020, ACS SYNTH BIOL, V9, P2927, DOI 10.1021/acssynbio.0c00345; Tien MZ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080635; Torng W, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1702-0; van den Bent I, 2021, EVOL BIOINFORM, V17, DOI 10.1177/11769343211062608; Varis D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8246; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Villegas-Morcillo A, 2021, BIOINFORMATICS, V37, P162, DOI 10.1093/bioinformatics/btaa701; Wang H., 2022, IEEE ACM T COMPUT BI, V1, P8523; Wickham H., 2019, JOSS, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]; Yang KK, 2018, BIOINFORMATICS, V34, P2642, DOI 10.1093/bioinformatics/bty178	37	1	1	5	7	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	AUG 16	2023	13	1								10.1038/s41598-023-40247-w	http://dx.doi.org/10.1038/s41598-023-40247-w			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	P3XK1	37587128	gold, Green Published			2024-07-03	WOS:001050004400043
C	Gong, YQ; Ding, XC; Su, YH; Shen, K; Liu, ZY; Zhang, GN			ACM	Gong, Yuqi; Ding, Xichen; Su, Yehui; Shen, Kaiming; Liu, Zhongyi; Zhang, Guannan			An Unified Search and Recommendation Foundation Model for Cold-Start Scenario	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		search and recommendation; LLM; multi-domain recommendation		In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc.	[Gong, Yuqi; Ding, Xichen; Su, Yehui; Shen, Kaiming] Ant Grp, Beijing, Peoples R China; [Liu, Zhongyi; Zhang, Guannan] Ant Grp, Hangzhou, Peoples R China		Gong, YQ (corresponding author), Ant Grp, Beijing, Peoples R China.	gongyuqi.gyq@antgroup.com; xichen.dxc@antgroup.com; suyehui.syh@antgroup.com; kaiming.skm@antgroup.com; zhongyi.lzy@antgroup.com; zgn138592@antgroup.com		Liu, Zhongyi/0000-0001-9478-8107; Zhang, Guannan/0000-0002-7091-2318				Ai QY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P645, DOI 10.1145/3077136.3080813; Brown Tom B., 2020, Advances in Neural Information Processing Systems; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Cui Zeyu, 2022, ARXIV220508084CSIR; Cui Zeyu, 2022, ABS220508084 CORR; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding XC, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2336, DOI 10.1145/3292500.3330716; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Ganin Y, 2016, J MACH LEARN RES, V17; Gretton A, 2012, J MACH LEARN RES, V13, P723; Huan ZX, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P4175, DOI 10.1145/3580305.3599955; Kong WZ, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3178, DOI 10.1145/3534678.3539137; Li NM, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4183, DOI 10.1145/3511808.3557674; Liu J, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P360, DOI 10.1145/3485447.3511964; Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007; Sheng XR, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4104, DOI 10.1145/3459637.3481941; Si ZH, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1313, DOI 10.1145/3539618.3591786; Si ZH, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P224, DOI 10.1145/3485447.3511951; Tang HY, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P269, DOI 10.1145/3383313.3412236; Touvron Hugo, 2023, CoRR abs/2302.13971; Xu J, 2018, ACM/SIGIR PROCEEDINGS 2018, P1365; Yao J, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2373, DOI 10.1145/3459637.3482489; Zamani H, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P717, DOI 10.1145/3336191.3371818; Zamani Hamed, 2018, CEUR Workshop Proceedings, V2167, P36; Zeng A., 2022, ARXIV221002414; Zhao K, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1461, DOI 10.1145/3488560.3498414; Zhao Wayne Xin, 2023, ABS230318223 CORR	27	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							4595	4601		10.1145/3583780.3614657	http://dx.doi.org/10.1145/3583780.3614657			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Submitted			2024-07-03	WOS:001161549504117
J	Mediakov, O; Vysotska, V				Mediakov, O.; Vysotska, V.			SONGS CONTINUATION GENERATION TECHNOLOGY BASED ON TEST GENERATION STRATEGIES, TEXTMINING AND LANGUAGE MODEL T5	RADIO ELECTRONICS COMPUTER SCIENCE CONTROL			English	Article						text generation; T5 language model; Transformers; author's style; Contrastive search; Top-p sampling; Top-k sampling; Multinomial sampling; Beam search; Diverse beam search; Greedy search; and Beam-search multinomial sampling		Context. Pre-trained large language models are currently the driving force behind the development of not only NLP, but also deep learning systems in general. Model transformers are able to solve virtually all problems that currently exist, provided that certain requirements and training practices are met. In turn, words, sentences and texts are the basic and most important way of communication between intellectually developed beings. Of course, speech and texts are used to convey certain emotions, events, etc. One of the main ways of using language to describe experienced emotions is songs with lyrics. However, often due to the need to preserve rhyme and rhyming, the dimensions of verse lines, song structure, etc., artists have to use repetition of lines in the lyrics. In addition, the process of writing texts can be long. Objective of the study is to develop information technology for generating the continuation of song texts based on the T5 machine learning model with (SA, specific author) and without (NSA, non-specific author) consideration of the author's style. Method. Choosing a decoding strategy is important for the generation process. However, instead of favoring a particular strategy, the system will support multiple strategies. In particular, the following 8 strategies: Contrastive search, Top-p sampling, Top-k sampling, Multinomial sampling, Beam search, Diverse beam search, Greedy search, and Beam-search multinomial sampling. Results. A machine learning model was developed to generate the continuation of song lyrics using large language models, in particular the T5 model, to accelerate, complement and increase the flexibility of the songwriting process. Conclusions. The created model shows excellent results of generating the continuation of song texts on test data. Analysis of the raw data showed that the NSA model has less degrading results, while the SA model needs to balance the amount of text for each author. Several text metrics such as BLEU, RougeL and RougeN are calculated to quantitatively compare the results of the models and generation strategies. The value of the BLEU metric is the most variable, and its value varies significantly depending on the strategy. At the same time, Rouge metrics have less variability, a smaller range of values. For comparison, 8 different decoding methods for text generation, supported by the transformers library, were used. From all the results of the text comparison, it is clear that the metrically best method of song text generation is beam search and its variations, in particular beam sampling. Contrastive search usually outperformed the conventional greedy approach. The top-p and top-k methods are not clearly superior to each other, and in different situations gave different results.	[Mediakov, O.; Vysotska, V.] Lviv Polytech Natl Univ, Informat Syst & Networks Dept, Lvov, Ukraine	Ministry of Education & Science of Ukraine; Lviv Polytechnic National University	Mediakov, O (corresponding author), Lviv Polytech Natl Univ, Informat Syst & Networks Dept, Lvov, Ukraine.		Vysotska, Victoria/P-7714-2016	Vysotska, Victoria/0000-0001-6417-3689				Abadi M., 2015, arXiv, DOI DOI 10.48550/ARXIV.1603.04467; Chiang Ting-Rui, 2021, P 4 BLACKBOXNLP WORK, P228, DOI [10.18653/v1/2021.blackboxnlp-1.16, DOI 10.18653/V1/2021.BLACKBOXNLP-1.16]; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Google, SentencePiece; Hugging Face community, Text generation strategies; Hugging Face community, T5; Hugging Face community, About us; Hugging Face community, Transformers. State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX; Vijayakumar AK, 2018, Arxiv, DOI arXiv:1610.02424; KerasNLP, about us; Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012; Lacoste A, 2019, Arxiv, DOI [arXiv:1910.09700, 10.48550/arXiv.1910.09700]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Mathur N., 2020, P 58 ANN M ASS COMPU, P4984, DOI DOI 10.18653/V1/2020.ACL; Murray K, 2018, Arxiv, DOI arXiv:1808.10006; Paulus R, 2017, Arxiv, DOI [arXiv:1705.04304, 10.48550/arXiv.1705.04304]; Prokipchuk O, 2023, RADIO ELECTRON COMPU, P103, DOI 10.15588/1607-3274-2023-2-11; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Sennrich R., Subword Neural Machine Translation; Shah D., Song Lyrics Dataset; Su YX, 2022, Arxiv, DOI arXiv:2202.06417; Swift T., Taylor Swift Music; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; von Platen Patrick, How to generate text: using different decoding methods for language generation with Transformers; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144	25	0	0	0	0	ZAPORIZHZHYA NATL TECHNICAL UNIV	ZAPORIZHZHYA	VUL ZHUKOVSKA, 64, ZAPORIZHZHYA, 69063, UKRAINE	1607-3274	2313-688X		RADIO ELECTRON COMPU	Radio Electron. Comput. Sci. Control		2023		4					157	174		10.15588/1607-3274-2023-4-15	http://dx.doi.org/10.15588/1607-3274-2023-4-15			18	Computer Science, Hardware & Architecture	Emerging Sources Citation Index (ESCI)	Computer Science	IF9S8		gold			2024-07-03	WOS:001165038500011
J	Milligan, G; Bernard, A; Dowthwaite, L; Vallejos, EP; Davis, J; Salhi, L; Goulding, J				Milligan, Gregor; Bernard, Aynsley; Dowthwaite, Liz; Vallejos, Elvira Perez; Davis, Jamie; Salhi, Louisa; Goulding, James			Developing a single-session outcome measure using natural language processing on digital mental health transcripts	COUNSELLING & PSYCHOTHERAPY RESEARCH			English	Article; Early Access						digital mental health; large language models; natural language processing; outcome measure; topic modelling	VALIDITY; THERAPY	BackgroundCurrent outcome measures in digital mental health lack granularity, especially for single-session interventions. This study aimed to address this by utilising natural language processing (NLP) methods to create a clear and relevant outcome measure. This paper describes the development of the Adult Session Wants and Needs Outcome Measure (Adult SWAN-OM), a novel outcome measure for the Qwell digital mental healthcare platform to understand service user (SU) needs engaging in single-session therapy (SST).MethodsThe research employs a multi-phased approach combining NLP methods with the typical stages of outcome measures development as follows: (1) assumption definition and validation with SUs and clinicians; (2) transcript theme extraction using the RoBERTa large language model (LLM) in conjunction with topic modelling to extract themes from 254 single-session transcripts from 192 SUs; (3) clinical item refinement focus group; (4) content validity with clinicians and SUs to improve the relevance and clarity of the items; and (5) outcome measure finalisation in a workshop held with clinicians to consolidate the final wording.ResultsNinety-six potential wants and needs were generated and distilled into 12 measure items. The outcome measure was shown to be relevant and clear to both SUs and clinicians when used in the context of SST.ConclusionThis study highlights the potential of combining NLP approaches with co-creation methods in single-session outcome measure development. We argue that the incorporation of clinical expertise and SU experience ensures the clarity and applicability of such measures and that this approach to capturing single-session wants and needs promises novel insights for supporting digital mental health interventions.	[Milligan, Gregor; Goulding, James] Univ Nottingham, Nottingham Univ Business Sch, N LAB, Nottingham, England; [Milligan, Gregor] Univ Nottingham, Horizon CDT, Nottingham, England; [Bernard, Aynsley; Davis, Jamie; Salhi, Louisa] Kooth PLC, London W2 1AY, England; [Dowthwaite, Liz; Vallejos, Elvira Perez] Univ Nottingham, Horizon Digital Econ Res, Nottingham, England; [Vallejos, Elvira Perez] Univ Nottingham, Sch Med, Nottingham, England	University of Nottingham; University of Nottingham; University of Nottingham; University of Nottingham	Bernard, A (corresponding author), Kooth PLC, London W2 1AY, England.	abernard@kooth.com			Kooth PLC	Kooth PLC	No Statement Availabler No Statement Available	Althoff Tim, 2016, Trans Assoc Comput Linguist, V4, P463; Ashworth M, 2019, ADM POLICY MENT HLTH, V46, P425, DOI 10.1007/s10488-019-00928-z; Bianchi F, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P759; Blais MA, 1999, J PERS ASSESS, V73, P359, DOI 10.1207/S15327752JPA7303_5; Blei D. M., 2006, P 23 INT C MACH LEAR; Clarke A, 2011, BMC PUBLIC HEALTH, V11, DOI 10.1186/1471-2458-11-487; Cook BL, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/8708434; Coppersmith G, 2018, BIOMED INFORM INSIGH, V10, DOI 10.1177/1178222618792860; De Ossorno Garcia S., 2022, Examining concurrent validity and item selection of the wants and needs outcome measure (SWANOM) in a webbased therapy service (preprint), DOI [10.2196/preprints.40122, DOI 10.2196/PREPRINTS.40122]; Garcia SD, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.748145; Denner S., 1997, Journal of Mental Health, V6, P275, DOI DOI 10.1080/09638239718806; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dryden W., 2020, What is singlesession therapy?; Dryden W, 2020, AUST NZ J FAM THER, V41, P283, DOI 10.1002/anzf.1424; Evans C, 2002, BRIT J PSYCHIAT, V180, P51, DOI 10.1192/bjp.180.1.51; Goodman R, 1997, J CHILD PSYCHOL PSYC, V38, P581, DOI 10.1111/j.1469-7610.1997.tb01545.x; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Honary M, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/11473; Hoyt M F., 2018, Single-session therapy by walk-in or appointment: Administrative, clinical, and supervisory aspects of one-at-a-time services, P3, DOI [10.4324/9781351112437, DOI 10.4324/9781351112437]; Hymmen P, 2013, J MENT HEALTH, V22, P60, DOI 10.3109/09638237.2012.670880; Jaidka K, 2020, P NATL ACAD SCI USA, V117, P10165, DOI 10.1073/pnas.1906364117; Janizek JD, 2021, J MACH LEARN RES, V22; Kessler RC, 2003, ARCH GEN PSYCHIAT, V60, P184, DOI 10.1001/archpsyc.60.2.184; Kherwa P, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.159623; Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x; Kwan B, 2015, BMC PSYCHIATRY, V15, DOI 10.1186/s12888-015-0664-x; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu ZL, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.779091; LYNN MR, 1986, NURS RES, V35, P382; Mindel C, 2021, CHILD ADOL MENT H-UK, V26, P339, DOI 10.1111/camh.12456; Arachchige IAN, 2021, INFORMATION, V12, DOI 10.3390/info12110444; Oseguera O., 2017, HCI international 2017Posters' extended abstracts, P473, DOI [10.1007/978-3-319-58750-966, DOI 10.1007/978-3-319-58750-966]; Polit DF, 2006, RES NURS HEALTH, V29, P489, DOI 10.1002/nur.20147; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Rose D, 2011, INT REV PSYCHIATR, V23, P41, DOI 10.3109/09540261.2010.545990; Schwartz HA, 2016, BIOCOMPUT-PAC SYM, P516; Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092; Strous RD, 2009, J NERV MENT DIS, V197, P585, DOI 10.1097/NMD.0b013e3181b09068; Twigg E, 2009, COUNS PSYCHOTHER RES, V9, P160, DOI 10.1080/14733140902979722; Young J, 2019, BRIT J GUID COUNS, V47, P645, DOI 10.1080/03069885.2019.1581129; Yusoff MSB., 2019, Education in Medicine Journal, V11, P49, DOI [DOI 10.21315/EIMJ2019.11.2.6, 10.21315/eimj2019.11.2.6]; Zeberga K, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7893775	42	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1473-3145	1746-1405		COUNS PSYCHOTHER RES	Couns. Psychother. Res.	2024 MAY 30	2024										10.1002/capr.12766	http://dx.doi.org/10.1002/capr.12766		MAY 2024	12	Psychology, Clinical	Emerging Sources Citation Index (ESCI)	Psychology	SM3B1		hybrid			2024-07-03	WOS:001234819200001
J	Srivastava, A; Das, S; Choudhury, N; Psiakis, R; Silva, PH; Pal, D; Basu, K				Srivastava, Amisha; Das, Sanjay; Choudhury, Navnil; Psiakis, Rafail; Silva, Pedro Henrique; Pal, Debjit; Basu, Kanad			SCAR: Power Side-Channel Analysis at RTL Level	IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS			English	Article						Encryption; Hardware; Power demand; Codes; Graph neural networks; Feature extraction; Task analysis; Graph neural network (GNN); large language model (LLM); power side-channel (PSC) attack; register-transfer level (RTL)		Power side-channel (PSC) attacks exploit the dynamic power consumption of cryptographic operations to leak sensitive information about encryption hardware. Therefore, it is necessary to conduct a PSC analysis to assess the susceptibility of cryptographic systems and mitigate potential risks. Existing PSC analysis primarily focuses on postsilicon implementations, which are inflexible in addressing design flaws, leading to costly and time-consuming postfabrication design re-spins. Hence, presilicon PSC analysis is required for the early detection of vulnerabilities to improve design robustness. In this article, we introduce SCAR, a novel presilicon PSC analysis framework based on graph neural networks (GNNs). SCAR converts register-transfer level (RTL) designs of encryption hardware into control-data flow graphs (CDFGs) and use that to detect the design modules susceptible to side-channel leakage. Furthermore, we incorporate a deep-learning-based explainer in SCAR to generate quantifiable and human-accessible explanations of our detection and localization decisions. We have also developed a fortification component as a part of SCAR that uses large-language models (LLMs) to automatically generate and insert additional design code at the localized zone to shore up the side-channel leakage. When evaluated on popular encryption algorithms like advanced encryption standard (AES), RSA, and PRESENT, and postquantum cryptography (PQC) algorithms like Saber and CRYSTALS-Kyber, SCAR, achieves up to 94.49% localization accuracy, 100% precision, and 90.48% recall. Additionally, through explainability analysis, SCAR reduces features for GNN model training by 57% while maintaining comparable accuracy. We believe that SCAR will transform the security-critical hardware design cycle, resulting in faster design closure at a reduced design cost.	[Srivastava, Amisha; Das, Sanjay; Choudhury, Navnil; Basu, Kanad] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA; [Psiakis, Rafail; Silva, Pedro Henrique] Technol Innovat Inst, Secure Syst Res Ctr, Abu Dhabi, U Arab Emirates; [Pal, Debjit] Univ Illinois, Dept Elect & Comp Engn, Chicago, IL 60607 USA	University of Texas System; University of Texas Dallas; Technology Innovation Institute; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Srivastava, A (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75080 USA.	axs220007@utdallas.edu		Choudhury, Navnil/0000-0002-2374-9212; Pal, Debjit/0000-0003-3722-5126; Srivastava, Amisha/0009-0008-9231-6331	Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates	Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates	No Statement Available	Ambrose Jude Angelo, 2008, 2008 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), P678, DOI 10.1109/ICCAD.2008.4681650; .aoki.ecei.tohoku, VERILOG DESIGNS; Aoki K., 2001, AREAS CRYPTOGRAPHY; Avanzi R, 2017, IACR T SYMMETRIC CRY, V2017, P4, DOI 10.13154/tosc.v2017.i1.4-44; Aysu A, 2018, DES AUT TEST EUROPE, P1253; Banik S, 2015, LECT NOTES COMPUT SC, V9453, P411, DOI 10.1007/978-3-662-48800-3_17; Benini G., 1997, DYNAMIC POWER MANAGE; Bernstein DJ, 2017, NATURE, V549, P188, DOI 10.1038/nature23461; Blomer J., 2004, PROC INT WORKSHOP SE; Buchanan W. J., 2017, J CYBER SECUR TECHNO, V11, P187, DOI [DOI 10.1080/23742917.2017.1384917, 10.1080/23742917.2017.1384917]; Canto AC, 2023, IEEE T EMERG TOP COM, V11, P791, DOI 10.1109/TETC.2022.3217006; Carlet C, 2005, LECT NOTES COMPUT SC, V3797, P49; Chang Y., 2023, arXiv; De Cnudde T., 2015, CRYPTOGRA PHY INFORM; Gattu N, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415692; Gharavi H., 2024, IEEE COMMUN SURV TUT, DOI [10.1109/COMST.2024.3355222, DOI 10.1109/COMST.2024.3355222]; Goldmine, TOOL ENHANCING VERIF; Gupta A, 2021, MATER TODAY-PROC, V46, P10927, DOI 10.1016/j.matpr.2021.01.950; He M. T., 2019, IEEE VLSI TEST SYMP, P1, DOI DOI 10.1109/vts.2019.8758600; Homma N, 2010, IEEE T COMPUT, V59, P795, DOI 10.1109/TC.2009.176; Imran Malik, 2021, ASHES '21: Proceedings of the 5th Workshop on Attacks and Solutions in Hardware Security, P85, DOI 10.1145/3474376.3487278; Joy Persial G., 2011, International Journal of Advance Scientific Research Review, V1, P54; Kumar K. Sudeendra, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P574, DOI 10.1109/ISVLSI.2017.106; Lin L, 2020, 2020 6TH IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2020) (FORMERLY INIS), P133, DOI 10.1109/iSES50453.2020.00038; Ma HC, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P79, DOI 10.1145/3489517.3530413; Meng X., 2023, ARXIV; Mujdei C., 2022, ACM TRANSEMBEDDED CO, V23, P1; Naveed H., 2023, ARXIV; nps, VERY COMPACTPERFECTL; O'Flynn C, 2014, LECT NOTES COMPUT SC, V8622, P243, DOI 10.1007/978-3-319-10175-0_17; Park J., 2022, IACR CRYPTOL EPRINT, P527; Penedo G., 2023, arXiv; Poesia G., 2022, ARXIV; Pundir N, 2022, IEEE T VLSI SYST, V30, P1207, DOI 10.1109/TVLSI.2022.3175067; Randolph M, 2020, CRYPTOGRAPHY-BASEL, V4, DOI 10.3390/cryptography4020015; Repka Marek, 2015, International Journal of Computer Network and Information Security, V7, P10, DOI 10.5815/ijcnis.2015.06.02; Sarker A, 2023, IEEE T COMPUT AID D, V42, P2418, DOI 10.1109/TCAD.2022.3218614; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Tarjan R., 1971, Conference record 1971 12th annual symposium on switching and automata theory, P114, DOI 10.1137/0201010; Thakur S., 2023, ARXIV; Tiri K, 2007, DES AUT CON, P15, DOI 10.1109/DAC.2007.375044; Trust-Hub, US; Tsukioka A, 2019, IEEE LETT ELECTROMAG, V1, P83, DOI 10.1109/LEMCPA.2020.2978624; Vasselle A., 2019, CRYPTOL EPRINT ARCH; Yaman F, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1020; Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240; Zhang T, 2021, DES AUT CON, P709, DOI 10.1109/DAC18074.2021.9586210; Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001; Zidaric N, 2024, CRYPTOGR COMMUN, V16, P129, DOI 10.1007/s12095-023-00656-0	49	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1063-8210	1557-9999		IEEE T VLSI SYST	IEEE Trans. Very Large Scale Integr. (VLSI) Syst.	JUN	2024	32	6					1110	1123		10.1109/TVLSI.2024.3390601	http://dx.doi.org/10.1109/TVLSI.2024.3390601		APR 2024	14	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RU5L4		Green Submitted			2024-07-03	WOS:001208870900001
J	Gwon, YN; Kim, JH; Chung, HS; Jung, EJ; Chun, J; Lee, S; Shim, SR				Gwon, Yong Nam; Kim, Jae Heon; Chung, Hyun Soo; Jung, Eun Jee; Chun, Joey; Lee, Serin; Shim, Sung Ryul			The Use of Generative AI for Scientific Literature Searches for Systematic Reviews: ChatGPT and Microsoft Bing AI Performance Evaluation	JMIR MEDICAL INFORMATICS			English	Article						artificial intelligence; search engine; systematic review; evidence-based medicine; ChatGPT; language model; education; tool; clinical decision support system; decision support; support; treatment		Background: A large language model is a type of artificial intelligence (AI) model that opens up great possibilities for health care practice, research, and education, although scholars have emphasized the need to proactively address the issue of unvalidated and inaccurate information regarding its use. One of the best-known large language models is ChatGPT (OpenAI). It is believed to be of great help to medical research, as it facilitates more efficient data set analysis, code generation, and literature review, allowing researchers to focus on experimental design as well as drug discovery and development. Objective: This study aims to explore the potential of ChatGPT as a real -time literature search tool for systematic reviews and clinical decision support systems, to enhance their efficiency and accuracy in health care settings. Methods: The search results of a published systematic review by human experts on the treatment of Peyronie disease were selected as a benchmark, and the literature search formula of the study was applied to ChatGPT and Microsoft Bing AI as a comparison to human researchers. Peyronie disease typically presents with discomfort, curvature, or deformity of the penis in association with palpable plaques and erectile dysfunction. To evaluate the quality of individual studies derived from AI answers, we created a structured rating system based on bibliographic information related to the publications. We classified its answers into 4 grades if the title existed: A, B, C, and F. No grade was given for a fake title or no answer. Results: From ChatGPT, 7 (0.5%) out of 1287 identified studies were directly relevant, whereas Bing AI resulted in 19 (40%) relevant studies out of 48, compared to the human benchmark of 24 studies. In the qualitative evaluation, ChatGPT had 7 grade A, 18 grade B, 167 grade C, and 211 grade F studies, and Bing AI had 19 grade A and 28 grade C studies. Conclusions: This is the first study to compare AI and conventional human systematic review methods as a real -time literature collection tool for evidence-based medicine. The results suggest that the use of ChatGPT as a tool for real -time evidence generation is not yet accurate and feasible. Therefore, researchers should be cautious about using such AI. The limitations of this study using the generative pre-trained transformer model are that the search for research topics was not diverse and that it did not prevent the hallucination of generative AI. However, this study will serve as a standard for future studies by providing an index to verify the reliability and consistency of generative AI from a user's point of view. If the reliability and consistency of AI literature search services are verified, then the use of these technologies will help medical research greatly.	[Gwon, Yong Nam; Kim, Jae Heon; Chun, Joey; Lee, Serin] Soonchunhyang Univ, Seoul Hosp, Coll Med, Dept Urol, Seoul, South Korea; [Chung, Hyun Soo; Jung, Eun Jee] Soonchunhyang Univ, Coll Med, Cheonan, South Korea; [Chun, Joey] Cranbrook Kingswood Upper Sch, Bloomfield Hills, MI USA; [Lee, Serin] Case Western Reserve Univ, Dept Biochem, Cleveland, OH USA; [Shim, Sung Ryul] Konyang Univ, Coll Med, Dept Biomed Informat, 158 Gwanjeodong Ro, Daejeon 35365, South Korea; [Shim, Sung Ryul] Konyang Univ Hosp, Konyang Med Data Res Grp, KYMERA, Daejeon, South Korea	Soonchunhyang University; Soonchunhyang University; University System of Ohio; Case Western Reserve University; Konyang University; Konyang University; Konyang University Hospital	Shim, SR (corresponding author), Konyang Univ, Coll Med, Dept Biomed Informat, 158 Gwanjeodong Ro, Daejeon 35365, South Korea.	sungryul.shim@gmail.com			Soonchunhyang University Research Fund	Soonchunhyang University Research Fund	This work was supported by the Soonchunhyang University Research Fund. This body had no involvement in the study design; in the collection, analysis, and interpretation of data; in the writing of the report; and in the decision to submit the article for publication.	[Anonymous], 2022, OpenAI; [Anonymous], 2023, Google; [Anonymous], 2020, About us; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bajwa Junaid, 2021, Future Healthc J, V8, pe188, DOI 10.7861/fhj.2021-0095; Bing, About us; Chung E, 2016, J SEX MED, V13, P905, DOI 10.1016/j.jsxm.2016.04.062; ClinicalTrials.gov, US; Cochrane Library, about us; consilium, US; Covidence, About us; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Google Scholar, ABOUT US; GUYATT G, 1992, JAMA-J AM MED ASSOC, V268, P2420, DOI 10.1001/jama.1992.03490170092032; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037; Lee HY, 2024, WORLD J MENS HEALTH, V42, P133, DOI 10.5534/wjmh.230016; Models, OpenAI; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; precedenceresearch, 2023, Artificial intelligence (AI) in healthcare market (by component: software, hardware, services; by application: virtual assistants, diagnosis, robot assisted surgery, clinical trials, wearable, others; by technology: machine learning, natural language processing, context-aware computing, computer vision; by end user)-global industry analysis, size, share, growth, trends, regional outlook, and forecast 2022-2030; PubMed, About Us; PubMed Research, whatplugin.ai; Reid R, 2023, How to write an effective GPT-3 or GPT-4 prompt; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Tai MCT, 2020, TZU CHI MED J, V32, P339, DOI 10.4103/tcmj.tcmj_71_20; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Wogu IAP, 2017, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTING NETWORKING AND INFORMATICS (ICCNI 2017); Zahlan A, 2023, TECHNOL SOC, V74, DOI 10.1016/j.techsoc.2023.102321; Zhou ZH, 2023, EUR UROL, V84, P355, DOI 10.1016/j.eururo.2023.03.037; Ziegler A, 2023, GitHub Blog	32	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2291-9694		JMIR MED INF	JMIR Med. Inf.		2024	12								e51187	10.2024/1/e51187	http://dx.doi.org/10.2024/1/e51187			12	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	RG0L9					2024-07-03	WOS:001226395600002
J	Dougherty, RF; Clarke, P; Atli, M; Kuc, J; Schlosser, D; Dunlop, BW; Hellerstein, DJ; Aaronson, ST; Zisook, S; Young, AH; Carhart-Harris, R; Goodwin, GM; Ryslik, GA				Dougherty, Robert F.; Clarke, Patrick; Atli, Merve; Kuc, Joanna; Schlosser, Danielle; Dunlop, Boadie W.; Hellerstein, David J.; Aaronson, Scott T.; Zisook, Sidney; Young, Allan H.; Carhart-Harris, Robin; Goodwin, Guy M.; Ryslik, Gregory A.			Psilocybin therapy for treatment resistant depression: prediction of clinical outcome by natural language processing	PSYCHOPHARMACOLOGY			English	Article; Early Access						Psilocybin; Depression; Natural language processing; Emotional breakthrough index; Machine learning; AI	LIFE-THREATENING CANCER; DISORDER; ANXIETY; CAREGIVERS; SYMPTOMS; TRIAL	Rationale Therapeutic administration of psychedelics has shown significant potential in historical accounts and recent clinical trials in the treatment of depression and other mood disorders. A recent randomized double-blind phase-IIb study demonstrated the safety and efficacy of COMP360, COMPASS Pathways' proprietary synthetic formulation of psilocybin, in participants with treatment-resistant depression. Objective While the phase-IIb results are promising, the treatment works for a portion of the population and early prediction of outcome is a key objective as it would allow early identification of those likely to require alternative treatment. Methods Transcripts were made from audio recordings of the psychological support session between participant and therapist 1 day post COMP360 administration. A zero-shot machine learning classifier based on the BART large language model was used to compute two-dimensional sentiment (valence and arousal) for the participant and therapist from the transcript. These scores, combined with the Emotional Breakthrough Index (EBI) and treatment arm were used to predict treatment outcome as measured by MADRS scores. (Code and data are available at https://github.com/compasspathways/Sentiment2D.) Results Two multinomial logistic regression models were fit to predict responder status at week 3 and through week 12. Cross-validation of these models resulted in 85% and 88% accuracy and AUC values of 88% and 85%. Conclusions A machine learning algorithm using NLP and EBI accurately predicts long-term patient response, allowing rapid prognostication of personalized response to psilocybin treatment and insight into therapeutic model optimization. Further research is required to understand if language data from earlier stages in the therapeutic process hold similar predictive power.	[Dougherty, Robert F.; Clarke, Patrick; Atli, Merve; Kuc, Joanna; Schlosser, Danielle; Goodwin, Guy M.; Ryslik, Gregory A.] COMPASS Pathways, London, England; [Dunlop, Boadie W.] Emory Univ, Atlanta, GA USA; [Hellerstein, David J.] Columbia Univ, New York, NY USA; [Aaronson, Scott T.] Sheppard Pratt, Baltimore, MD USA; [Zisook, Sidney] Univ Calif San Diego, San Diego, CA USA; [Young, Allan H.] Kings Coll London, London, England; [Carhart-Harris, Robin] Univ Calif San Francisco, San Francisco, CA USA	Emory University; Columbia University; University of California System; University of California San Diego; University of London; King's College London; University of California System; University of California San Francisco	Dougherty, RF (corresponding author), COMPASS Pathways, London, England.	robert.dougherty@compasspathways.com	Aaronson, Scott/GPW-8956-2022; Aaronson, Scott T/S-3028-2017	Kuc, Joanna/0000-0003-4159-7176	COMPASS Path-finder Ltd, London, UK	COMPASS Path-finder Ltd, London, UK	& nbsp;This study was funded and sponsored by COMPASS Path-finder Ltd, London, UK. A contract research organization (Worldwide Clinical Trials), paid by the sponsor, supervised the conduct of the trial under the direction of the sponsor. An independent contract research organization (MedAvante) was responsible for conducting MADRS assessments with blinded remote raters.	Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carhart-Harris R, 2021, NEW ENGL J MED, V384, P1402, DOI 10.1056/NEJMoa2032994; Carhart-Harris RL, 2016, LANCET PSYCHIAT, V3, P619, DOI 10.1016/S2215-0366(16)30065-7; Cavedoni S, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00245; COMPASS Pathways, 2022, SAF EFF PSIL PART TR; Coravos A, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0090-4; Corey-Lisle PK, 2002, J CLIN PSYCHIAT, V63, P717, DOI 10.4088/JCP.v63n0810; Culpepper L, 2015, AM J MED, V128, pS1, DOI 10.1016/j.amjmed.2015.07.001; Davis AK, 2021, JAMA PSYCHIAT, V78, P481, DOI 10.1001/jamapsychiatry.2020.3285; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ferguson JM, 2001, J CLIN PSYCHIAT, V62, P22; Goodwin GM, 2022, NEW ENGL J MED, V387, P1637, DOI 10.1056/NEJMoa2206443; Gregory E, 2020, J AFFECT DISORDERS, V274, P593, DOI 10.1016/j.jad.2020.05.101; Griffiths RR, 2016, J PSYCHOPHARMACOL, V30, P1181, DOI 10.1177/0269881116675513; Grob CS, 2011, ARCH GEN PSYCHIAT, V68, P71, DOI 10.1001/archgenpsychiatry.2010.116; Haijen ECHM, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00897; Hirschfeld RMA, 2000, J CLIN PSYCHIAT, V61, P268, DOI 10.4088/JCP.v61n0405; Jacobson NC, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0078-0; Jain R, 2022, DRUGS-REAL WOR OUTC, V9, P477, DOI 10.1007/s40801-022-00316-4; Judd LL, 2000, ARCH GEN PSYCHIAT, V57, P375, DOI 10.1001/archpsyc.57.4.375; Judd LL, 1998, J AFFECT DISORDERS, V50, P97, DOI 10.1016/S0165-0327(98)00138-4; Lawrence D, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.f2539; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Lex H, 2019, J AFFECT DISORDERS, V243, P401, DOI 10.1016/j.jad.2018.09.062; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; Mrazek DA, 2014, PSYCHIAT SERV, V65, P977, DOI 10.1176/appi.ps.201300059; Murphy R, 2022, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.788155; Muttoni S, 2019, J AFFECT DISORDERS, V258, P11, DOI 10.1016/j.jad.2019.07.076; Nemeroff CB, 2007, J CLIN PSYCHIAT, V68, P17; Otte C, 2016, NAT REV DIS PRIMERS, V2, DOI 10.1038/nrdp.2016.65; Passie T, 2002, ADDICT BIOL, V7, P357, DOI 10.1080/1355621021000005937; Peill JM, 2022, J PSYCHOPHARMACOL, V36, P31, DOI 10.1177/02698811211066709; Rathod S, 2022, J AFFECT DISORDERS, V300, P551, DOI 10.1016/j.jad.2021.12.090; Roseman L, 2019, J PSYCHOPHARMACOL, V33, P1076, DOI 10.1177/0269881119855974; Ross S, 2016, J PSYCHOPHARMACOL, V30, P1165, DOI 10.1177/0269881116675512; Rush AJ, 2006, AM J PSYCHIAT, V163, P1905, DOI 10.1176/appi.ajp.163.11.1905; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Souery D, 2007, J CLIN PSYCHIAT, V68, P1062, DOI 10.4088/JCP.v68n0713; Stasak B, 2016, INTERSPEECH, P485, DOI 10.21437/Interspeech.2016-867; Tabeleao V, 2018, COMMUNITY MENT HLT J, V54, P211, DOI 10.1007/s10597-017-0126-7; Tai SJ, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.586682; THASE ME, 1994, PSYCHIAT ANN, V24, P232, DOI 10.3928/0048-5713-19940501-09; van Melle JP, 2004, PSYCHOSOM MED, V66, P814, DOI 10.1097/01.psy.0000146294.82810.9c; van Wijngaarden B, 2004, J AFFECT DISORDERS, V81, P211, DOI 10.1016/S0165-0327(03)00168-X; Vancappel A., 2021, Journal of Affective Disorders Reports, V6, DOI [DOI 10.1016/J.JADR.2021.100272, 10.1016/J.JADR.2021.100272]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wiles N, 2014, HEALTH TECHNOL ASSES, V18, P1, DOI 10.3310/hta18310; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914	50	1	1	3	7	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0033-3158	1432-2072		PSYCHOPHARMACOLOGY	Psychopharmacology	2023 AUG 22	2023										10.1007/s00213-023-06432-5	http://dx.doi.org/10.1007/s00213-023-06432-5		AUG 2023	9	Neurosciences; Pharmacology & Pharmacy; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Pharmacology & Pharmacy; Psychiatry	P8AD8	37606733	hybrid, Green Published			2024-07-03	WOS:001052834600002
J	Sandmann, S; Riepenhausen, S; Plagwitz, L; Varghese, J				Sandmann, Sarah; Riepenhausen, Sarah; Plagwitz, Lucas; Varghese, Julian			Systematic analysis of ChatGPT, Google search and Llama 2 for clinical decision support tasks	NATURE COMMUNICATIONS			English	Article							INFORMATION	It is likely that individuals are turning to Large Language Models (LLMs) to seek health advice, much like searching for diagnoses on Google. We evaluate clinical accuracy of GPT-3 center dot 5 and GPT-4 for suggesting initial diagnosis, examination steps and treatment of 110 medical cases across diverse clinical disciplines. Moreover, two model configurations of the Llama 2 open source LLMs are assessed in a sub-study. For benchmarking the diagnostic task, we conduct a naive Google search for comparison. Overall, GPT-4 performed best with superior performances over GPT-3 center dot 5 considering diagnosis and examination and superior performance over Google for diagnosis. Except for treatment, better performance on frequent vs rare diseases is evident for all three approaches. The sub-study indicates slightly lower performances for Llama models. In conclusion, the commercial LLMs show growing potential for medical question answering in two successive major releases. However, some weaknesses underscore the need for robust and regulated AI models in health care. Open source LLMs can be a viable option to address specific needs regarding data privacy and transparency of training. People will likely use ChatGPT to seek health advice. Here, the authors show promising performance of ChatGPT and open source models, but a lack of high accuracy considering medical question answering. Improvements are expected over time via domain-specific finetuning and integration of regulations.	[Sandmann, Sarah; Riepenhausen, Sarah; Plagwitz, Lucas; Varghese, Julian] Univ Munster, Inst Med Informat, Munster, Germany	University of Munster	Varghese, J (corresponding author), Univ Munster, Inst Med Informat, Munster, Germany.	julian.varghese@uni-muenster.de	Sandmann, Sarah/X-6727-2019	Sandmann, Sarah/0000-0002-5011-0641; Riepenhausen, Sarah Luise/0000-0002-0623-2625	Open Access Publication Fund of the University of Munster	Open Access Publication Fund of the University of Munster	We acknowledge support from the Open Access Publication Fund of the University of Munster (S.S., S.R., L.P., J.V.).	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bonferroni C., 2010, Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commericiali di Firenze, DOI [10.4135/9781412961288.n455, DOI 10.4135/9781412961288.N455]; Cocco AM, 2018, MED J AUSTRALIA, V209, P342, DOI 10.5694/mja17.00889; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Griggs RC, 2009, MOL GENET METAB, V96, P20, DOI 10.1016/j.ymgme.2008.10.003; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lenders JWM, 2014, J CLIN ENDOCR METAB, V99, P1915, DOI 10.1210/jc.2014-1498; North F, 2012, TELEMED E-HEALTH, V18, P213, DOI 10.1089/tmj.2011.0127; Raats M. M., 1992, Food Quality and Preference, V3, P89, DOI 10.1016/0950-3293(91)90028-D; Signorell A., 2023, DescTools: Tools for Descriptive Statistics; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Tang HW, 2006, BRIT MED J, V333, P1143, DOI 10.1136/bmj.39003.640567.AE; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vallo Hult Helena, 2023, Stud Health Technol Inform, V305, P580, DOI 10.3233/SHTI230563; Varghese J., 2023, J Hepatol, pS0168; Varghese J, 2020, VISC MED, V36, P443, DOI 10.1159/000511930; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yang Hong, 2023, Nature, DOI 10.1038/d41586-023-01026-9; Zheng HY, 2023, AM J MED, V136, P725, DOI 10.1016/j.amjmed.2023.02.011	26	2	2	15	15	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2041-1723		NAT COMMUN	Nat. Commun.	MAR 6	2024	15	1							2050	10.1038/s41467-024-46411-8	http://dx.doi.org/10.1038/s41467-024-46411-8			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	KO1X4	38448475	gold			2024-07-03	WOS:001180826600013
J	Lee, GH; Lee, KJ; Jeong, B; Kim, T				Lee, Gun Ho; Lee, Kyoung Jun; Jeong, Baek; Kim, Taekyung			Developing Personalized Marketing Service Using Generative AI	IEEE ACCESS			English	Article						Generative AI; Business; Generative adversarial networks; Artificial intelligence; personalized marketing message; persuasion theory; prompt engineering		In today's world, the development of social network services (SNS) like Facebook and Instagram has enabled consumers to acquire information about products through various channels. The acquisition of diverse information has led to a diversification in consumer preferences and requirements. As consumer preferences diversify and online channels expand, there is an increasing need for companies to provide personalized marketing. Among the means of personalized marketing, personalized marketing messages are a key tool that can enhance customer engagement. However, a limitation of personalized marketing message services is the cost issue associated with manually writing individual marketing messages for personalization. To solve this problem, when developing automated technology for personalized marketing messages, there were concerns about the complexity of model development and the quality of messages generated automatically. In this study, we propose the Persuasive Message Intelligence (PMI) service, which utilizes the recently prominent Large Language Model for automated individual personalized marketing messages. PMI generates marketing messages through prompt engineering based on the theory of persuasion in marketing and prior research on AI-generated messages, and validates the elements of prompts through surveys. The trial and error of researchers presented in this study, along with the know-how and rules of prompt engineering, will serve as guidelines for those who wish to develop services through prompts in the future.	[Lee, Gun Ho; Lee, Kyoung Jun; Jeong, Baek; Kim, Taekyung] Kyung Hee Univ, Dept Big Data Analyt, Seoul 02447, South Korea	Kyung Hee University	Kim, T (corresponding author), Kyung Hee Univ, Dept Big Data Analyt, Seoul 02447, South Korea.	tk_kim@khu.ac.kr	Kim, Taekyung/JDX-0821-2023; Lee, Kyoung Jun/KIE-2557-2024	Kim, Taekyung/0000-0001-5089-2914; Lee, Kyoung Jun/0000-0002-7774-6551; Lee, GUNHO/0009-0009-6000-1674	BK21 Fostering Outstanding Universities for Research (FOUR)	BK21 Fostering Outstanding Universities for Research (FOUR)	No Statement Available	Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Arango L, 2023, J ADVERTISING, V52, P486, DOI 10.1080/00913367.2023.2183285; Aslam Huzaifa, 2021, SEISENSE Bus. Rev., V1, P12, DOI DOI 10.33215/SBR.V1I3.660; Ballentine B, 2016, TECH COMMUN-STC, V63, P212; Cheng JL, 2023, Arxiv, DOI arXiv:2311.04155; Dehnert M, 2022, HUM COMMUN RES, V48, P386, DOI 10.1093/hcr/hqac006; Dell-Kuster S, 2014, BMC MED RES METHODOL, V14, DOI 10.1186/1471-2288-14-96; Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146; Kang Y., 2022, Research Anthology on Social Media Advertising and Building Consumer Relationships, P1899; Karinshak Elise, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579592; Kim TW, 2020, PSYCHOL SCI, V31, P363, DOI 10.1177/0956797620904985; Kortemeyer G, 2023, Arxiv, DOI arXiv:2309.09338; Krishnan R, 2005, INFORM SYST RES, V16, P307, DOI 10.1287/isre.1050.0063; Lim S, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1129082; Lina L. F., 2021, Sriwijaya International Journal of Dynamic Economics and Business, V5, P147, DOI [10.29259/sijdeb.v1i2.147-156, DOI 10.29259/SIJDEB.V1I2.147-156]; Matz S., 2023, Tech. Rep.; Olufemi J., 2015, Tech. Rep.; OpenAI, 2023, Prompt Engineering; Qian M., 2023, PROC 1 WORKSHOP NLP, P20; Samsudin Syahrul Nizam, 2022, 2022 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS)., P84, DOI 10.1109/I2CACIS54679.2022.9815482; Szirtes T., 2012, Society and Economy, V34, P139, DOI DOI 10.1556/SOCEC.2011.0009; White TB, 2008, MARKET LETT, V19, P39, DOI 10.1007/s11002-007-9027-9; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Zuell C., 2016, Res. Methods, V25, P3	24	0	0	62	62	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						22394	22402		10.1109/ACCESS.2024.3361946	http://dx.doi.org/10.1109/ACCESS.2024.3361946			9	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	JE5X2		gold			2024-07-03	WOS:001171511800001
J	Shin, J; Jo, E; Yoon, Y; Jung, J				Shin, Junho; Jo, Eunkyung; Yoon, Yeohoon; Jung, Jaehee			A System for Interviewing and Collecting Statements Based on Intent Classification and Named Entity Recognition Using Augmentation	APPLIED SCIENCES-BASEL			English	Article						child sexual abuse interview; intent classification; named entity recognition; data augmentation; NICHD	INVESTIGATIVE INTERVIEWS; FORENSIC INTERVIEWS; PROTOCOL; QUALITY; ABUSE; DISCLOSURE; CHILDREN; VICTIMS	In cases of child sexual abuse, interviewing and obtaining trustworthy statements from victims and witnesses is essential because their statements are the only evidence. It is crucial to ascertain objectively the credibility of the victim's statements, which may vary based on the nature of the questions posed by the forensic interviewer. Therefore, interview skills that eliminate subjective opinions require a high level of training for forensic interviewers. To reduce high-risk subjective interviews, objectively analyzing statements is essential. Understanding the victim's intent and named entity recognition (NER) in the statements is necessary to give the victim open-ended questions and memory recall. Therefore, the system provides an intent classification and NER method that follows the National Institute of Child Health and Human Development Investigative Interview Protocol, which outlines the collection of objective statements. Large language models such as BERT and KoBERT, along with data augmentation techniques, were proposed using a restricted training dataset of limited size to achieve effective intent classification and NER performance. Additionally, a system that can collect objective statements with the proposed model was developed and it was confirmed that it could assist statement analysts. The verification results showed that the model achieved average F1-scores of 95.5% and 97.8% for intent classification and NER, respectively, which improved the results of the limited data by 3.4% and 3.7%, respectively.	[Shin, Junho; Jung, Jaehee] Myongji Univ, Dept Informat & Commun Engn, Yongin 17058, South Korea; [Jo, Eunkyung] Dongguk Univ, Coll Police & Criminal Justice, Seoul 04620, South Korea; [Yoon, Yeohoon] Supreme Prosecutors Off, Forens Sci Div, Seoul 06590, South Korea	Myongji University; Dongguk University	Jung, J (corresponding author), Myongji Univ, Dept Informat & Commun Engn, Yongin 17058, South Korea.	entus0123@naver.com; ekjo@dongguk.edu; yhyoon@spo.go.kr; jhjung@mju.ac.kr			National R&D program of the Supreme Prosecutor's Office (SPO); National Research Foundation of Korea (NRF) - Ministry of Science, ICT and Future Planning [NRF-2022R1F1A1061476]	National R&D program of the Supreme Prosecutor's Office (SPO); National Research Foundation of Korea (NRF) - Ministry of Science, ICT and Future Planning(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This study was supported in part by a grant from the National R & D program of the Supreme Prosecutor 's Office (SPO) and the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT and Future Planning (NRF-2022R1F1A1061476).	AI Hub, About us; Amer Eslam, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P263, DOI 10.1109/MIUCC52538.2021.9447652; Bitbucket, ABOUT US; Blanc C, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102264; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Cui Yiming, 2020, P 2020 C EMPIRICAL M, P657, DOI [/10.18653/v1/2020.findings-emnlp.58, 10.18653/v1/2020.findings-emnlp.58]; Dai X, 2020, Arxiv, DOI arXiv:2010.11683; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhiman A, 2020, Arxiv, DOI arXiv:2007.06511; Ettinger Tara R, 2022, SN Soc Sci, V2, P101, DOI 10.1007/s43545-022-00397-6; Fernandes D, 2024, TRAUMA VIOLENCE ABUS, V25, P1382, DOI 10.1177/15248380231177317; Fernandez-Martinez F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031610; Hershkowitz I, 2006, CHILD ABUSE NEGLECT, V30, P753, DOI 10.1016/j.chiabu.2005.10.016; Ho A, 2018, J COMMUN, V68, P712, DOI 10.1093/joc/jqy026; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jo H., 2017, Korean Word Embedding Using FastText, P705; Kikuta Y., 2019, BERT Pretrained Model Trained on Japanese Wikipedia Articles; Kingma D. P., 2017, ARXIV; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Lamb M.E., 2000, APPL DEV SCI, V6, P114, DOI [DOI 10.1207/S1532480XADS06032, DOI 10.1207/S1532480XADS0603_2]; Lamb M.E., 2018, Tell me what happened; Lamb ME, 2007, CHILD ABUSE NEGLECT, V31, P1201, DOI 10.1016/j.chiabu.2007.03.021; Lamb ME, 2009, APPL COGNITIVE PSYCH, V23, P449, DOI 10.1002/acp.1489; Lee JH, 2024, IEEE T COMPUT SOC SY, V11, P514, DOI 10.1109/TCSS.2023.3238477; Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209; Malloy LC, 2013, CHILD MALTREATMENT, V18, P245, DOI 10.1177/1077559513497250; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Minhas R, 2022, AI SOC, V37, P265, DOI 10.1007/s00146-021-01165-5; Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619871808; Orbach Y, 2000, CHILD ABUSE NEGLECT, V24, P733, DOI 10.1016/S0145-2134(00)00137-X; Pires T, 2019, Arxiv, DOI arXiv:1906.01502; pypi, ABOUT US; Rapp A, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102630; Saywitz K.J., 2009, CHILDREN VICTIM WITN, P102; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Sidaoui K, 2020, J SERV MANAGE, V31, P745, DOI 10.1108/JOSM-11-2019-0341; SKT-Brain Korean, 2021, BERT Pre-Trained Cased (KoBERT); Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862; Steller M., 1989, PSYCHOL METHODS CRIM, P217; Sternberg KJ, 1997, CHILD ABUSE NEGLECT, V21, P1133, DOI 10.1016/S0145-2134(97)00071-9; Sternberg KJ, 2001, J APPL PSYCHOL, V86, P997, DOI 10.1037/0021-9010.86.5.997; Tidmarsh P, 2023, J POLICE CRIM PSYCHO, V38, P318, DOI 10.1007/s11896-021-09446-x; Tsai WHS, 2021, PSYCHOL MARKET, V38, P2377, DOI 10.1002/mar.21556; Vaswani A, 2017, ADV NEUR IN, V30; Wei Jason, 2019, EDA: Easy data augmentation techniques for boosting performance on text classification tasks; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Yi M, 2017, J POLICE CRIM PSYCHO, V32, P279, DOI 10.1007/s11896-016-9220-y; Yi MS, 2016, J POLICE CRIM PSYCHO, V31, P155, DOI 10.1007/s11896-015-9170-9	48	0	0	6	7	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	OCT	2023	13	20							11545	10.3390/app132011545	http://dx.doi.org/10.3390/app132011545			22	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	X0RN2		gold			2024-07-03	WOS:001095610700001
C	Valentino, M; Thayaparan, M; Ferreira, D; Freitas, A			Assoc Advancement Artificial Intelligence	Valentino, Marco; Thayaparan, Mokanarangan; Ferreira, Deborah; Freitas, Andre			Hybrid Autoregressive Inference for Scalable Multi-Hop Explanation Regeneration	THIRTY-SIXTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FOURTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE / TWELVETH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE	AAAI Conference on Artificial Intelligence		English	Proceedings Paper	36th AAAI Conference on Artificial Intelligence / 34th Conference on Innovative Applications of Artificial Intelligence / 12th Symposium on Educational Advances in Artificial Intelligence	FEB 22-MAR 01, 2022	ELECTR NETWORK	Assoc Advancement Artificial Intelligence				Regenerating natural language explanations in the scientific domain has been proposed as a benchmark to evaluate complex multi-hop and explainable inference. In this context, large language models can achieve state-of-the-art performance when employed as cross-encoder architectures and fine-tuned on human-annotated explanations. However, while much attention has been devoted to the quality of the explanations, the problem of performing inference efficiently is largely under studied. Cross-encoders, in fact, are intrinsically not scalable, possessing limited applicability to real-world scenarios that require inference on massive facts banks. To enable complex multi-hop reasoning at scale, this paper focuses on bi-encoder architectures, investigating the problem of scientific explanation regeneration at the intersection of dense and sparse models. Specifically, we present SCAR (for Scalable Autoregressive Inference), a hybrid framework that iteratively combines a Transformer-based bi-encoder with a sparse model of explanatory power, designed to leverage explicit inference patterns in the explanations. Our experiments demonstrate that the hybrid framework significantly outperforms previous sparse models, achieving performance comparable with that of state-of-the-art cross-encoders while being approximate to 50 times faster and scalable to corpora of millions of facts. Further analyses on semantic drift and multi-hop question answering reveal that the proposed hybridisation boosts the quality of the most challenging explanations, contributing to improved performance on downstream inference tasks.	[Valentino, Marco; Thayaparan, Mokanarangan; Ferreira, Deborah; Freitas, Andre] Univ Manchester, Manchester, Lancs, England; [Valentino, Marco; Thayaparan, Mokanarangan; Freitas, Andre] Idiap Res Inst, Martigny, Switzerland	University of Manchester	Valentino, M (corresponding author), Univ Manchester, Manchester, Lancs, England.; Valentino, M (corresponding author), Idiap Res Inst, Martigny, Switzerland.	marco.valentino@manchester.ac.uk	Freitas, Andre/AAT-9885-2020	Freitas, Andre/0000-0002-4430-4837				[Anonymous], 2019, P 13 WORKSH GRAPH BA, DOI DOI 10.1145/3299869.3319879; Bhakthavatsalam Sumithra, 2020, ARXIV200500660; Cartuyvels Ruben, 2020, P 28 INT C COMPUTATI, P6916; Chia Y. K., 2019, Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing, P85; Cowhey Isaac, 2018, CoRR; Das Rajarshi, 2019, P 13 WORKSH GRAPH BA, P101; Demszky D., 2018, ARXIV180902922; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhingra B., 2019, INT C LEARN REPR; Ferreira D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2175; Hadsell R, 2006, IEEE C COMP VIS PATT, P1735; Humeau Samuel, 2019, INT C LEARN REPR; Jansen Peter, 2019, P 13 WORKSH GRAPH BA, P63; Jansen Peter, 2016, P 26 INT C COMP LING, P2956; Jansen PA, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2732; Jhamtani H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P137; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khashabi D., 2019, ARXIV190102522; Khashabi Daniel, 2018, P 2018 C N AM CHAPT, V1, P252, DOI 10.18653/v1/N18-1023; Khot T, 2020, AAAI CONF ARTIF INTE, V34, P8082; Khot Tushar, 2019, ARXIV191011473; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lin BY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4611; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Thayaparan M, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1; Thayaparan Mokanarangan, 2020, ARXIV201000389; Valentino M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P200; Vaswani A, 2017, ADV NEUR IN, V30; Welbl J., 2018, T ASS COMPUTATIONAL, V6, P287, DOI DOI 10.1162/TACL_A_00021; Wiegreffe Sarah, 2021, ARXIV210212060; Xie ZN, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5456; Xiong Wenhan, 2021, INT C LEARN REPR; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Zhao C, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4635	37	0	0	1	1	ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE	PALO ALTO	2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA	2159-5399	2374-3468	978-1-57735-876-3	AAAI CONF ARTIF INTE			2022							11403	11411						9	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU3UW					2024-07-03	WOS:000893639104047
J	Xin, DT; Jiang, JF; Takamichi, S; Saito, Y; Aizawa, A; Saruwatari, H				Xin, Detai; Jiang, Junfeng; Takamichi, Shinnosuke; Saito, Yuki; Aizawa, Akiko; Saruwatari, Hiroshi			JVNV: A Corpus of Japanese Emotional Speech With Verbal Content and Nonverbal Expressions	IEEE ACCESS			English	Article						Corpus design; emotional speech corpus; Japanese corpus; large-scale language model; nonverbal expression; nonverbal vocalization	RECOGNITION; VOICES	We present the JVNV, a Japanese emotional speech corpus with verbal content and nonverbal vocalizations whose scripts are generated by a large-scale language model. Existing emotional speech corpora lack not only proper emotional scripts but also nonverbal vocalizations (NVs) that are essential expressions in spoken language to express emotions. We propose an automatic script generation method to produce emotional scripts by providing seed words with sentiment polarity and phrases of nonverbal vocalizations to ChatGPT using prompt engineering. We select 514 scripts with balanced phoneme coverage from the generated candidate scripts with the assistance of emotion confidence scores and language fluency scores. Experimental results show that JVNV has better phoneme coverage and emotion recognizability than previous Japanese emotional speech corpora. We then benchmark JVNV on emotional text-to-speech synthesis using discrete codes to represent NVs. The results demonstrate that there still exists a gap between the performance of synthesizing read-aloud speech and emotional speech, and adding NVs in the speech makes the task even harder, which brings new challenges for this task and makes JVNV a valuable resource for relevant works in the future. To our best knowledge, JVNV is the first speech corpus that generates scripts automatically using large language models.	[Xin, Detai; Jiang, Junfeng; Takamichi, Shinnosuke; Saito, Yuki; Saruwatari, Hiroshi] Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo, Tokyo 1138656, Japan; [Aizawa, Akiko] Natl Inst Informat, Chiyoda, Tokyo 1018430, Japan	University of Tokyo; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Xin, DT (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo, Tokyo 1138656, Japan.	detai_xin@ipc.i.u-tokyo.ac.jp			Japan Science and Technology Agency (JST) Support for Pioneering Research Initiated by the Next Generation (SPRING)	Japan Science and Technology Agency (JST) Support for Pioneering Research Initiated by the Next Generation (SPRING)	No Statement Available	Adigwe A, 2018, Arxiv, DOI arXiv:1806.09514; [Anonymous], 1980, Theories of Emotion, DOI DOI 10.1016/B978-0-12-558701-3.50007-7; Arimoto Y, 2012, ACOUST SCI TECHNOL, V33, P359, DOI 10.1250/ast.33.359; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531; Bozkurt B., 2003, PROC 8 EUR C SPEECH, P277; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cadic D, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P99; Chenchah F, 2014, PROCEDIA COMPUT SCI, V39, P139, DOI 10.1016/j.procs.2014.11.020; Cohn M, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P293; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ekman P., 1971, P NEBR S MOT, P207; Francois H., 2001, PROC 7 EUR C SPEECH, P829; Gillick J, 2021, INTERSPEECH, P2481, DOI 10.21437/Interspeech.2021-353; Graves A., 2006, P 23 INT C MACH LEAR, P369, DOI 10.1145/1143844.1143891; Hall JA, 2009, J NONVERBAL BEHAV, V33, P149, DOI 10.1007/s10919-009-0070-5; Higashiyama Masahiko, 2008, P 14 ANN M ASS NAT L, P584; Hsu CC, 2022, Arxiv, DOI arXiv:2206.12662; Hsu WN, 2021, IEEE-ACM T AUDIO SPE, V29, P3451, DOI 10.1109/TASLP.2021.3122291; Huang KY, 2019, INT CONF ACOUST SPEE, P5866, DOI 10.1109/ICASSP.2019.8682283; Kajiwara T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2095; Kim J., 2020, Advances in Neural Information Processing Systems, V33, P8067; Kingma D. P., 2017, ARXIV; Kominek J., 2004, P SSW, P223; Kong J., 2020, NIPS 20 P 34 INT C N, P17022; Kreuk F., 2022, PROC EMNLP, P11200; Krul A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2030; Lausen A, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0499-z; Lima CF, 2013, BEHAV RES METHODS, V45, P1234, DOI 10.3758/s13428-013-0324-3; lio K., 2017, The LJ Speech Dataset; Liu XC, 2023, IEEE-ACM T AUDIO SPE, V31, P2507, DOI 10.1109/TASLP.2023.3285283; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luong H.-T., 2021, arXiv; Mehrabian A., 2017, Nonverbal Communication; Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457; Nose T, 2017, IEEE-ACM T AUDIO SPE, V25, P1107, DOI 10.1109/TASLP.2017.2688585; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Paszke A, 2019, ADV NEUR IN, V32; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ren Y., 2021, INT C LEARN REPR ICL; Saito Y, 2022, INTERSPEECH, P5155, DOI 10.21437/Interspeech.2022-300; Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699; Sauter DA, 2010, P NATL ACAD SCI USA, V107, P2408, DOI 10.1073/pnas.0908239106; Scherer KR, 2011, J NONVERBAL BEHAV, V35, P305, DOI 10.1007/s10919-011-0115-4; Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5; SCHERER KR, 1994, EMOTIONS: ESSAYS ON EMOTION THEORY, P161; Sonobe R, 2017, Arxiv, DOI arXiv:1711.00354; Takamichi S., 2024, Speech Commun., V156; Takeishi Emika, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P16, DOI 10.1109/ICSDA.2016.7918977; Tatham M., 2004, EXPRESSION SPEECH AN; Testa B, 2023, Arxiv, DOI arXiv:2211.09273; Trouvain J., 2012, PROCTHE LREC WORKSHO, P36; Tzirakis P., 2023, PROC IEEE INT C ACOU, P1; Vaswani A, 2017, ADV NEUR IN, V30; Veaux C., 1028, Superseded-CSTR VCTK Corpux: English Multi-speaker Corpus for Catr Voice Cloning Toolkit; Wei J, 2022, Trans. Mach. Learn. Res.; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xin D., 2022, PROC ICML EXPRESSIVE; Xin D., 2023, P INTERSPEECH, P17; Zhang H., 2023, PROC IEEE INT C ACOU, P1	60	0	0	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						19752	19764		10.1109/ACCESS.2024.3360885	http://dx.doi.org/10.1109/ACCESS.2024.3360885			13	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	IA8N3		gold, Green Submitted			2024-07-03	WOS:001163693000001
J	Alvarado, R				Alvarado, Ramon			AI as an Epistemic Technology	SCIENCE AND ENGINEERING ETHICS			English	Article						AI; Technology; Epistemic; Knowledge tools	ARTIFICIAL-INTELLIGENCE; BIG DATA; TRUST; KNOWLEDGE; FUTURE	In this paper I argue that Artificial Intelligence and the many data science methods associated with it, such as machine learning and large language models, are first and foremost epistemic technologies. In order to establish this claim, I first argue that epistemic technologies can be conceptually and practically distinguished from other technologies in virtue of what they are designed for, what they do and how they do it. I then proceed to show that unlike other kinds of technology (including other epistemic technologies) AI can be uniquely positioned as an epistemic technology in that it is primarily designed, developed and deployed to be used in epistemic contexts such as inquiry, it is specifically designed, developed and deployed to manipulate epistemic content such as data, and it is designed, developed and deployed to do so particularly through epistemic operations such as prediction and analysis. As has been shown in recent work in the philosophy and ethics of AI (Alvarado, AI and Ethics, 2022a), understanding AI as an epistemic technology will also have significant implications for important debates regarding our relationship to AI technologies. This paper includes a brief overview of such implications, particularly those pertaining to explainability, opacity, trust and even epistemic harms related to AI technologies.	[Alvarado, Ramon] Univ Oregon, Philosophy Dept, Eugene, OR 97403 USA	University of Oregon	Alvarado, R (corresponding author), Univ Oregon, Philosophy Dept, Eugene, OR 97403 USA.	ralvarad@uoregon.edu						Alvarado R., 2021, PREPRINT; Alvarado R., 2022, AI Ethics, DOI [10.1007/s43681-022-00224-x, DOI 10.1007/S43681-022-00224-X]; Alvarado R., 2020, BIG DATA DEMOCRACY; Alvarado R, 2017, NEW LITERARY HIST, V48, P729; Alvarado R, 2022, BIOETHICS, V36, P121, DOI 10.1111/bioe.12959; Alvarado R, 2022, FOUND SCI, V27, P1183, DOI 10.1007/s10699-021-09812-2; [Anonymous], 2009, I SEMANTICS; Anthony C, 2018, ACAD MANAGE REV, V43, P661, DOI 10.5465/amr.2016.0334; BAIER AC, 1985, NOUS, V19, P53, DOI 10.2307/2215117; Baird Davis., 2004, THING KNOWLEDGE PHIL; Barocas, 2017, NIPS TUTORIAL, V1, P2; Becker PeterWilliam Clark., 2001, LITTLE TOOLS KNOWLED; Bergstrom C. T., 2021, Calling bullshit: The art of skepticism in a data-driven world; Bhatt S, 2020, IEEE INTERNET COMPUT, V24, P66, DOI 10.1109/MIC.2020.2979620; Bjerring J.C., 2021, Philos. Technol, V34, P349, DOI DOI 10.1007/S13347-019-00391-6; Boge FJ, 2022, MIND MACH, V32, P43, DOI 10.1007/s11023-021-09569-4; Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878; Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512; Calvo P, 2016, SYNTHESE, V193, P1323, DOI 10.1007/s11229-016-1040-1; Carbonell J.G., 1983, Mach. Learn, V1, P3, DOI [DOI 10.1007/978-3-662-12405-5, 10.1007/978-3-662-12405-5]; Cho JH, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3277666; Chockley K, 2016, J AM COLL RADIOL, V13, P1415, DOI 10.1016/j.jacr.2016.07.010; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; Danks D, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P521, DOI 10.1145/3306618.3314228; Daston L, 2012, OSIRIS, V27, P156, DOI 10.1086/667826; Davenport TH, 2018, HARVARD BUS REV, V96, P108; Davies T., 2013, Proceedings of the 5th Annual ACM Web Science Conference on - WebSci'13, P75, DOI DOI 10.1145/2464464.2464472; Dougherty D, 2012, ORGAN SCI, V23, P1467, DOI 10.1287/orsc.1110.0700; Dretske F, 2000, PHILOS PHENOMEN RES, V60, P591, DOI 10.2307/2653817; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; Durán JM, 2018, MIND MACH, V28, P645, DOI 10.1007/s11023-018-9481-6; Durán JM, 2021, J MED ETHICS, V47, P329, DOI [10.1136/medethics-2020-106820, 10.1136/medethics-2021-107531]; el Naqa I, 2015, What Is Machine Learning?, P311, DOI DOI 10.1007/978-3-319-18305-3_1; Ferrario A., 2021, The meaning of "Explainability fosters trust in AI; Ferrario A., 2020, Philosophy & Technology, V33, P523, DOI [10.1007/s13347-019-00378-3, DOI 10.1007/S13347-019-00378-3]; Ferrario A, 2021, J MED ETHICS, V47, P437, DOI 10.1136/medethics-2020-106922; Floridi L, 2015, SYNTHESE, V192, P1199, DOI 10.1007/s11229-014-0610-3; Fricker M, 2008, THEORIA-SPAIN, V23, P69; Fricker M, 2021, TORRES LUCCA, V10, P97; Friedrich Markus., 2018, The Birth of the Archive: A History of Knowledge, DOI 10.3998/mpub.9394529; Girer N., 2011, ADDERALL USAGE COLL; Goldman AI, 2018, PHILOS APPL COGNITIV, DOI [10.4324/9780429493355, DOI 10.4324/9780429493355]; Goldman Alvin, 1986, Epistemology and cognition; GOLINSKI J, 1994, OSIRIS, V9, P30, DOI 10.1086/368728; Hartnett K., 2015, QUANTA MAGAZINE, P19; Hengstler M, 2016, TECHNOL FORECAST SOC, V105, P105, DOI 10.1016/j.techfore.2015.12.014; Hernández-Orallo J, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P507, DOI 10.1145/3306618.3314238; Hinton G., 2016, P MACH LEARN MARK IN; Humphreys P, 2004, Extending Ourselves: Computational Science, Empiricism, and Scientific Method, DOI [10.1093/0195158709.001.0001, DOI 10.1093/0195158709.001.0001]; Humphreys P, 2009, EPISTEME-J INDIV SOC, V6, P221, DOI 10.3366/E1742360009000653; Humphreys P, 2009, SYNTHESE, V169, P615, DOI 10.1007/s11229-008-9435-2; Jha S, 2016, JAMA-J AM MED ASSOC, V316, P2353, DOI 10.1001/jama.2016.17438; Jöhnk J, 2021, BUS INFORM SYST ENG+, V63, P5, DOI 10.1007/s12599-020-00676-7; Kiernan J., 2016, MOJ WOMENS HLTH, V3, P167, DOI [DOI 10.15406/MOJWH.2016.03, 10.15406/mojwh.2016.03]; KIM J, 1982, PHILOS STUD, V41, P51, DOI 10.1007/BF00353523; Knowles B, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P262, DOI 10.1145/3442188.3445890; Kroes P., 2002, DUAL NATURE TECHNICA; Kroes P. A., 2003, The Philosophy of Scientific Experimentation, P68; Kroes P, 2010, CAMB J ECON, V34, P51, DOI 10.1093/cje/bep019; Lankton NK, 2015, J ASSOC INF SYST, V16, P880, DOI 10.17705/1jais.00411; Lazar S., IN PRESS; Lombardo P, 2020, EUR J RADIOL, V122, DOI 10.1016/j.ejrad.2019.108771; London AJ, 2019, HASTINGS CENT REP, V49, P15, DOI 10.1002/hast.973; Mazurowski MA, 2019, J AM COLL RADIOL, V16, P1077, DOI 10.1016/j.jacr.2019.01.026; McCraw BW, 2015, SOC EPISTEMOL, V29, P413, DOI 10.1080/02691728.2014.971907; McKnight D.H., 2011, ACM Transactions on Management Information Systems, V2, DOI [10.1145/1985347.1985353, DOI 10.1145/1985347.1985353]; Millar J, 2015, IEEE TECHNOL SOC MAG, V34, P47, DOI 10.1109/MTS.2015.2425612; Miller B, 2021, SCI TECHNOL HUM VAL, V46, P53, DOI 10.1177/0162243919900965; Miller B, 2017, NEW MEDIA SOC, V19, P1945, DOI 10.1177/1461444816644805; Miller B, 2013, EPISTEME-J INDIV SOC, V10, P117, DOI 10.1017/epi.2013.11; Mitchell Melanie, 2019, ARTIFICIAL INTELLIGE; Morrison M., 2015, Reconstructing reality. Models, Mathematics, and simulations; Norman DA., 1991, Designing Interaction, V1, P17; Páez A, 2019, MIND MACH, V29, P441, DOI 10.1007/s11023-019-09502-w; Páez A, 2009, SYNTHESE, V170, P131, DOI 10.1007/s11229-008-9361-3; Pincock C., 2011, MATH SCI REPRESENTAT; Piredda G, 2020, PHENOMENOL COGN SCI, V19, P549, DOI 10.1007/s11097-019-09628-3; Polger TW, 2013, ANAL PHILOS, V54, P72, DOI 10.1111/phib.12007; Ratti E., 2022, AI Ethics, V2, P1, DOI DOI 10.1007/S43681-022-00141-Z; Ratto M., 2012, HDB RES COMPUTATIONA, P567, DOI [10.4018/978-1-61350-116-0.ch023, DOI 10.4018/978-1-61350-116-0.CH023]; Record I., 2018, EXTENDED EPISTEMOLOG; Reiner P. B., 2017, NEUROETHICS ANTICIPA, P108; Rossi F., 2018, J. Int. Affairs, V72, P127; Russo F., 2022, Techno-scientific practices: An informational approach; Ryan M, 2020, SCI ENG ETHICS, V26, P2749, DOI 10.1007/s11948-020-00228-y; Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483; Sarle W. S., 1994, Neural networks and statistical models, DOI 10.1016/j.eswa.2007.10.005; Schifano F, 2020, PSYCHOTHER PSYCHOSOM, V89, P274, DOI 10.1159/000507897; Sethumadhavan A, 2019, ERGON DES, V27, P34, DOI 10.1177/1064804618818592; Simion M., 2019, INQUIRY, DOI [10.1080/0020174X.2018.1562373, DOI 10.1080/0020174X.2018.1562373]; Simion M, 2018, INQUIRY, V61, P914, DOI 10.1080/0020174X.2017.1392894; Simon J, 2010, ETHICS INF TECHNOL, V12, P343, DOI 10.1007/s10676-010-9243-5; Stolz S., 2012, JL Educ, V41, P585; Studer R, 2006, IEEE INTELL SYST, V21, P8, DOI 10.1109/MIS.2006.63; Sullivan E, 2019, AUSTRALAS J PHILOS, V97, P673, DOI 10.1080/00048402.2018.1564337; Symons J., 2014, SOFTWARE INTENSIVE S, V27, P461; Symons J, 2022, SYNTHESE, V200, DOI 10.1007/s11229-022-03631-z; Symons J, 2019, MIND MACH, V29, P37, DOI 10.1007/s11023-018-9487-0; Symons J, 2010, HIST PHIL LIFE SCI, V32, P233; Van Helden A, 1994, Osiris, V9, P1, DOI 10.1086/368726; VANHELDEN A, 1994, OSIRIS, V9, P9; Varga MD, 2012, J EVID-INFORM SOC WO, V9, P293, DOI 10.1080/15433714.2010.525402; Viola M., 2021, Phenomenology and Mind, V15, DOI 10.17454/pam-2000; Weisberg M, 2009, PHILOS SCI, V76, P225, DOI 10.1086/644786; Wilholt T, 2013, BRIT J PHILOS SCI, V64, P233, DOI 10.1093/bjps/axs007; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Yan Y, 2019, J GERIATR CARDIOL, V16, P585, DOI 10.11909/j.issn.1671-5411.2019.08.010	107	4	4	15	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1353-3452	1471-5546		SCI ENG ETHICS	Sci. Eng. Ethics	OCT	2023	29	5							32	10.1007/s11948-023-00451-3	http://dx.doi.org/10.1007/s11948-023-00451-3			30	Ethics; Engineering, Multidisciplinary; History & Philosophy Of Science; Multidisciplinary Sciences; Philosophy	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Engineering; History & Philosophy of Science; Science & Technology - Other Topics; Philosophy	P6ZE5	37603120	Green Submitted			2024-07-03	WOS:001052128700001
C	Kim, N; Schuster, S		Rogers, A; Boyd-Graber, J; Okazaki, N		Kim, Najoung; Schuster, Sebastian			Entity Tracking in Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Keeping track of how states of entities change as a text or dialog unfolds is a key prerequisite to discourse understanding. Yet, there have been few systematic investigations into the ability of large language models (LLMs) to track discourse entities. In this work, we present a task probing to what extent a language model can infer the final state of an entity given an English description of the initial state and a series of state-changing operations. We use this task to first investigate whether Flan-T5, GPT-3 and GPT-3.5 can track the state of entities, and find that only GPT-3.5 models, which have been pretrained on large amounts of code, exhibit this ability. We then investigate whether smaller models pretrained primarily on text can learn to track entities, through finetuning T5 on several training/evaluation splits. While performance degrades for more complex splits, we find that even when evaluated on a different set of entities from training or longer operation sequences, a finetuned model can perform nontrivial entity tracking. Taken together, these results suggest that language models can learn to track entities but pretraining on text corpora alone does not make this capacity surface.	[Kim, Najoung] Boston Univ, Dept Linguist, Boston, MA 02215 USA; [Schuster, Sebastian] Saarland Univ, Dept Language Sci & Technol, Saarbrucken, Germany	Boston University; Saarland University	Kim, N (corresponding author), Boston Univ, Dept Linguist, Boston, MA 02215 USA.	najoung@bu.edu; seschust@lst.uni-saarland.de			NSF [2030859]; European Research Council (ERC) under the European Union [948878]	NSF(National Science Foundation (NSF)); European Research Council (ERC) under the European Union(European Research Council (ERC))	We thank Jacob Andreas, Ellie Pavlick, Allyson Ettinger, Tal Linzen, Will Merrill, and the members of the NYU Computation and Psycholinguistics lab for discussions, and Belinda Li for sharing model outputs and details about their data preparation procedures and experiments. We thank Cookie for contributing to the authorship decision and for emotional support. This research was conducted in part through the NYU IT High Performance Computing resources, services, and staff expertise, and it was supported by the NSF under Grant #2030859 to the Computing Research Association for the CIFellows Project and the European Research Council (ERC) under the European Union's Horizon 2020 Research and Innovation Program (Grant Agreement #948878). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation nor the Computing Research Association.	Aina L, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3772; [Anonymous], CoRR; [Anonymous], 2010, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics; [Anonymous], 2016, P INT C LEARN REPR; Bamman D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P44; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bogin Ben, 2022, DOES GPT 3 PERFORM C; Bogin Ben, 2022, P 2022 C EMP METH NA; Bosselut Antoine, 2018, P 6 INT C LEARN REPR; Chen H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P172; Chung Hyung Won, 2022, ARXIV221011416; Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828; Cote M.A., 2018, Revised Selected Papers, P41; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; GROENENDIJK J, 1991, LINGUIST PHILOS, V14, P39, DOI 10.1007/BF00628304; Gupta A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P759; Gupta Aditya, 2019, P 3 WORKSH STRUCT PR, P7; Heim I., 2002, Formal semantics the essential readings, P223; Henaff Mikael, 2017, INT C LEARN REPR ICL; Ji Y, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, P1830; Kamp H, 2011, HANDBOOK OF PHILOSOPHICAL LOGIC, VOL 15, SECOND EDITION, P125, DOI 10.1007/978-94-007-0485-5_3; Karttunen L., 1976, Syntax and Semantics, V7, P363; Kiddon C., 2015, P 2015 C EMP METH NA, P982; Lampinen Andrew Kyle, 2022, ARXIV221015303; Lee H., 2011, P 15 C COMPUTATIONAL, P28; Lee K., 2017, P 2017 EMNLP; Leech G., 2001, Word Frequencies in Written and Spoken English; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813; Li Kenneth, 2023, INT C LEARN REPR ICL; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Linzen T., 2020, P 58 ANN M ASS COMP, P5210, DOI [DOI 10.18653/V1/2020.ACL-MAIN.465, 10.18653/v1/2020.acl-main.465]; Loaiciga Sharid, 2022, P 29 INT C COMP LING, P875; Long R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1456; Madaan Aman, 2022, P 2022 C EMP METH NA, P1384; Merrill W, 2021, T ASSOC COMPUT LING, V9, P1047, DOI 10.1162/tacl_a_00412; Mishra BD, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4496; Nieuwland MS, 2006, J COGNITIVE NEUROSCI, V18, P1098, DOI 10.1162/jocn.2006.18.7.1098; OpenAI, 2023, Gpt-4 technical report; Ouyang Long, 2022, ARXIV220302155; Potts Christopher, 2020, MEDIUM BLOG POST; Pradhan S, 2012, JOINT C EMNLP CONLL, P1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rahman V., 2012, P 2012 JOINT C EMPIR, P777; Sap M., 2022, P 2022 C EMPIRICAL M, P3762, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.248; Schuster S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P969; Sorodoc IT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4177; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Toshniwal S, 2022, AAAI CONF ARTIF INTE, P11385; Toshniwal S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8519; Tsai Chen Feng, 2023, ARXIV230402868; Uryupina O, 2020, NAT LANG ENG, V26, P95, DOI 10.1017/S1351324919000056; Walker C., 2006, Ace 2005 multilingual training corpus, DOI DOI 10.35111/MWXC-VH88; Winograd Terry, 1971, THESIS; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu W, 2020, ACL, P6953, DOI [10.18653/v1/2020.acl-main.622, DOI 10.18653/V1/2020.ACL-MAIN.622]	57	1	2	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							3835	3855						21	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086802032
J	Mubarak, R; Alsboui, T; Alshaikh, O; Inuwa-Dutse, I; Khan, S; Parkinson, S				Mubarak, Rami; Alsboui, Tariq; Alshaikh, Omar; Inuwa-Dutse, Isa; Khan, Saad; Parkinson, Simon			A Survey on the Detection and Impacts of Deepfakes in Visual, Audio, and Textual Formats	IEEE ACCESS			English	Article						Deepfakes; Visualization; Surveys; Social networking (online); Deep learning; Generative adversarial networks; Audio systems; Text analysis; visual; audio; text	NATURAL-LANGUAGE; NEURAL-NETWORKS; DIGITAL IMAGE; FAKE NEWS; LIP-SYNC; DEEP; STATE; WATERMARKING; TECHNOLOGY; CHALLENGES	In the rapidly evolving digital landscape, the generation of fake visual, audio, and textual content poses a significant threat to the trust of society, political stability, and integrity of information. The generation process has been enhanced and simplified using Artificial Intelligence techniques, which have been termed deepfake. Although significant attention has been paid to visual and audio deepfakes, there is also a burgeoning need to consider text-based deepfakes. Due to advancements in natural language processing and large language models, the potential of manipulating textual content to reshape online discourse and misinformation has increased. This study comprehensively examines the multifaceted nature and impacts of deep-fake-generated media. This work explains the broad implications of deepfakes in social, political, economic, and technological domains. State-of-the-art detection methodologies for all types of deepfake are critically reviewed, highlighting the need for unified, real-time, adaptable, and generalised solutions. As the challenges posed by deepfakes intensify, this study underscores the importance of a holistic approach that integrates technical solutions with public awareness and legislative action. By providing a comprehensive overview and establishing a framework for future exploration, this study seeks to assist researchers, policymakers, and practitioners navigate the complexities of deepfake phenomena.	[Mubarak, Rami] Minist Interior, Royal Acad Police, Manama 33305, Bahrain; [Alsboui, Tariq; Alshaikh, Omar; Inuwa-Dutse, Isa; Khan, Saad; Parkinson, Simon] Univ Huddersfield, Dept Comp Sci, Huddersfield HD1 3DH, England	University of Huddersfield	Parkinson, S (corresponding author), Univ Huddersfield, Dept Comp Sci, Huddersfield HD1 3DH, England.	s.parkinson@hud.ac.uk	; Inuwa-Dutse, Isa/AAQ-8170-2020	Khan, Saad/0000-0001-8613-8200; Inuwa-Dutse, Isa/0000-0001-9930-8117; Mubarak, Rami/0009-0006-9469-5297; Alsboui, Tariq/0000-0001-6004-3756; ALSHAIKH, Omar/0000-0002-1350-8933; Parkinson, Simon/0000-0002-1747-9914				aclanthology, Towards Personalised Synthesised Voices for Individuals With Vocal Disabilities: Voice Banking and Reconstruction; Advertising Standards Authority, Committee of Advertising Practice; Afchar D, 2018, IEEE INT WORKS INFOR; Agarwal S., 2019, P IEEE C WORKSH COMP, P38, DOI DOI 10.1109/ICCV.2015.425; Agarwal S, 2020, IEEE COMPUT SOC CONF, P2814, DOI 10.1109/CVPRW50498.2020.00338; Agarwal S, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360904; Aïmeur E, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01028-5; AlBadawy EA., 2019, CVPR WORKSH, P104; Albahar M., 2019, Journal of Theoretical and Applied Information Technology, V97, P3242; Aljasem M, 2021, IEEE T INF FOREN SEC, V16, P3524, DOI 10.1109/TIFS.2021.3082303; Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211; Alzantot M, 2019, Arxiv, DOI arXiv:1907.00501; Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152; [Anonymous], 2022, The GuardianNovember 25; [Anonymous], 2018, Opinion | In India, Journalists Face Slut-Shaming and Rape Threats; [Anonymous], 2020, 'Deepfakes' ranked as most serious AI crime threat; [Anonymous], 2023, bbc18 Jun; Appel M, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmac008; Atallah M. J., 2001, Information Hiding, P185; Bakhtin A, 2019, Arxiv, DOI arXiv:1906.03351; Baltrusaitis T, 2016, IEEE WINT CONF APPL; Bateman J., 2020, Deepfakes and synthetic media in the financial system: assessing threat scenarios; bbc, Martin Lewis Felt 'Sick' Seeing Deepfake Scam ad on Facebook; Bessi A., 2016, First Monday, V21, DOI 10.5210/fm.v21i11.7090; Bhatt P., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.01170; Blue L, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P2691; Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001; Bode L, 2021, CONVERGENCE-US, V27, P849, DOI 10.1177/13548565211034044; Boneh D, 2019, IEEE SECUR PRIV, V17, P64, DOI 10.1109/MSEC.2019.2934193; Borrelli C, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00116-3; Botha J, 2020, PR INT CONF INF WAR, P57, DOI 10.34190/ICCWS.20.085; Boutadjine A., 2023, P INT C ADV EL CONTR, P1; Brown P. F., 1983, Comput. Linguistics, V18, P31; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caldwell M, 2020, CRIME SCI, V9, DOI 10.1186/s40163-020-00123-8; Chakraborty S, 2023, Arxiv, DOI arXiv:2304.04736; Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603; Chang M.-C., 2018, PROC IEEE INT WORKSH, P1; ChatGPT, about us; Chen jun-fu, 2021, Journal of Software, P551, DOI 10.13328/j.cnki.jos.006135; Chen T., 2020, P SPEAK LANG REC WOR, P132; Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J; Chesney R, 2019, FOREIGN AFF, V98, P147; Childers D. G., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P748; Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287; Citron D. K., 2019, Foreign Affairs, V10, P1; Coccomini DA, 2022, LECT NOTES COMPUT SC, V13233, P219, DOI 10.1007/978-3-031-06433-3_19; Conti E, 2022, INT CONF ACOUST SPEE, P8962, DOI 10.1109/ICASSP43922.2022.9747186; Costales Jefferson A., 2023, 2023 International Conference on Innovative Data Communication Technologies and Application (ICIDCA), P730, DOI 10.1109/ICIDCA56705.2023.10099668; Cozzolino D, 2019, Arxiv, DOI arXiv:1812.02510; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Crothers EN, 2023, IEEE ACCESS, V11, P70977, DOI 10.1109/ACCESS.2023.3294090; Dagar D, 2022, INT J MULTIMED INF R, V11, P219, DOI 10.1007/s13735-022-00241-w; Damiani J, A voice deepfake was used to scam a CEO out of $243,000; Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582; Das RK, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6349, DOI 10.1109/ICASSP39728.2021.9413501; Dasgupta D., 2019, P IEEE INT S TECHN H, P1; de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677; de Lima O, 2020, Arxiv, DOI arXiv:2006.14749; de Rancourt-Raymond A., 2023, Journal of Financial Crime, V30, P1066; de Ruiter A., 2021, Philosophy and Technology, V34, P1311, DOI [DOI 10.1007/S13347-021-00459-2, 10.1007/s13347-021-00459-2]; deepfakesweb, Make Your Own Deepfakes; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhariwal P, 2021, ADV NEUR IN, V34; Doan T.-P., 2023, P IEEE INT C AC SPEE, P1; Dobber T, 2021, INT J PRESS/POLIT, V26, P69, DOI 10.1177/1940161220944364; epfl, Risk Governance and The Rise of Deepfakes; Etienne Hubert, 2021, AI Ethics, V1, P553, DOI 10.1007/s43681-021-00072-1; europa, Ethics Guidelines for Trustworthy AI-FUTURIUM-European Commission; exist, This Person Does Not Exist-Random AI Generated Photos of Fake Persons; FaceApp, Face Editor; Fagni T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251415; Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213; Figueira A, 2017, PROCEDIA COMPUT SCI, V121, P817, DOI 10.1016/j.procs.2017.11.106; Fröhling L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.443; ft, Fears Grow of Deepfake ID Scams Following Progress Hack; Galle M, 2021, Arxiv, DOI arXiv:2111.02878; Gao Y, 2021, Arxiv, DOI arXiv:2104.04111; Gehrmann S, 2019, Arxiv, DOI arXiv:1906.04043; Ghazi-Tehrani AK, 2021, VICTIMS OFFENDERS, V16, P316, DOI 10.1080/15564886.2020.1829224; github, Github-deepfakes/faceswap: Deepfakes software for all; Godulla A, 2021, SCM STUD COMM MEDIA, V10, P72, DOI 10.5771/2192-4007-2021-1-72; Gomez-Alanis A, 2019, INTERSPEECH, P1068, DOI 10.21437/Interspeech.2019-2212; Gomez-Alanis A, 2019, IEEE-ACM T AUDIO SPE, V27, P1985, DOI 10.1109/TASLP.2019.2937413; Greengard S, 2020, COMMUN ACM, V63, P17, DOI 10.1145/3371409; Guarnera L, 2020, IEEE COMPUT SOC CONF, P2841, DOI 10.1109/CVPRW50498.2020.00341; Guera D., 2018, PROC 15 IEEE INT C A, P1; Guera D, 2019, Arxiv, DOI arXiv:1906.08743; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Nguyen HH, 2019, Arxiv, DOI arXiv:1910.12467; Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893; Haliassos A, 2021, PROC CVPR IEEE, P5037, DOI 10.1109/CVPR46437.2021.00500; Hameleers M, 2022, SOC MEDIA SOC, V8, DOI 10.1177/20563051221116346; Hamza A, 2022, IEEE ACCESS, V10, P134018, DOI 10.1109/ACCESS.2022.3231480; Hanitzsch T, 2018, INT J PRESS/POLIT, V23, P3, DOI 10.1177/1940161217740695; Harris KR, 2021, SYNTHESE, V199, P13373, DOI 10.1007/s11229-021-03379-y; Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hernandez-Ortega J, 2020, Arxiv, DOI arXiv:2010.00400; Nguyen-Son HQ, 2017, ASIAPAC SIGN INFO PR, P1504; Hong J, 2012, COMMUN ACM, V55, P74, DOI 10.1145/2063176.2063197; Hu C, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104611; Ice J., 2019, Case Western Reserve law review, V70, P417; Ippolito D, 2020, Arxiv, DOI arXiv:1911.00650; Jain A, 2018, INT CONF BIOMETR THE; Jawahar G, 2020, Arxiv, DOI arXiv:2011.01314; Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848; Jung JW, 2020, Arxiv, DOI arXiv:2004.00526; Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660; Kammoun A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527850; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236; Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336; Khan S., 2021, ACM Comput. Surv., V53, P1; Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Kirchengast T, 2020, INF COMMUN TECHNOL L, V29, P308, DOI 10.1080/13600834.2020.1794615; Koopman M, 2018, 20 IR MACH VIS IM PR, P133; Korshunov P, 2018, Arxiv, DOI arXiv:1812.08685; Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270; Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397; Korus P, 2019, PROC CVPR IEEE, P8613, DOI 10.1109/CVPR.2019.00882; Kowalczyk P., 2022, Detecting and understanding textual deepfakes in online reviews; Krishna K, 2023, Arxiv, DOI arXiv:2303.13408; Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019; Lai CI, 2019, Arxiv, DOI arXiv:1904.01120; Lai CI, 2019, INT CONF ACOUST SPEE, P6316, DOI 10.1109/ICASSP.2019.8682640; Langa J, 2021, BOSTON U LAW REV, V101, P761; Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337; Langguth J, 2021, FRONT COMMUN, V6, DOI 10.3389/fcomm.2021.632317; LeCun Y., 2007, Predicting structured data; Li X, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6354, DOI 10.1109/ICASSP39728.2021.9413828; Lim SY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083926; Liu XD, 2019, Arxiv, DOI arXiv:1901.11504; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Trinh L, 2021, IEEE WINT CONF APPL, P1972, DOI 10.1109/WACV48630.2021.00202; Lovato J, 2024, Arxiv, DOI [arXiv:2210.10026, 10.48550/ARXIV.2210.10026, DOI 10.48550/ARXIV.2210.10026]; Ma YX, 2021, Arxiv, DOI arXiv:2108.05684; Ma Zhiyuan, 2023, 2023 4th Information Communication Technologies Conference (ICTC), P396, DOI 10.1109/ICTC57116.2023.10154671; malavida, FakeApp 2.2-Download for PC Free; Marra F, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035099; Masood M, 2023, APPL INTELL, V53, P3974, DOI 10.1007/s10489-022-03766-z; Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020; McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]; Meral HM, 2009, COMPUT SPEECH LANG, V23, P107, DOI 10.1016/j.csl.2008.04.001; Metz R., Facebook and YouTube Say They Removed Zelensky Deepfake | CNN Business; midjourney, DALLE 2; Mink J, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P1669; Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Mittal T, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2823, DOI 10.1145/3394171.3413570; Mo YCA, 2022, INT CONF ACOUST SPEE, P6392, DOI 10.1109/ICASSP43922.2022.9746059; Montasari Reza, 2020, International Journal of Organizational and Collective Intelligence, P37, DOI 10.4018/IJOCI.2020040103; Montasari R., 2021, Digital Forensic Investigation of Internet of Things (IoT) Devices; Monteiro J, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101096; Montserrat DM, 2020, IEEE COMPUT SOC CONF, P2851, DOI 10.1109/CVPRW50498.2020.00342; murf, Voice Cloning: Realistic Text to speech Voice Cloning Online | Murf; Mustak M, 2023, J BUS RES, V154, DOI 10.1016/j.jbusres.2022.113368; Najari S, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-021-00800-9; Nataraj L, 2019, Arxiv, DOI arXiv:1903.06836; Natsume R, 2018, Arxiv, DOI arXiv:1804.03447; Nguyen HH, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185974; Nirkin Y, 2023, IEEE T PATTERN ANAL, V45, P560, DOI 10.1109/TPAMI.2022.3155571; openai, DALLE 2; Orabi M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102250; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Pant K, 2020, AACL-IJCNLP 2020: THE 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P37; Papastergiopoulos C, 2022, 1ST ACM INTERNATIONAL WORKSHOP ON MULTIMEDIA AI AGAINST DISINFORMATION, MAD 2022, P3, DOI 10.1145/3512732.3533585; Parkinson Simon, 2023, 2023 IEEE 3rd International Conference on Computer Communication and Artificial Intelligence (CCAI), P272, DOI 10.1109/CCAI57533.2023.10201300; Parkinson S, 2023, IET BIOMETRICS, V12, P25, DOI 10.1049/bme2.12087; Parkinson S, 2021, IET BIOMETRICS, V10, P163, DOI 10.1049/bme2.12017; Patel D, 2023, COMPUT GRAPH-UK, V110, P19, DOI 10.1016/j.cag.2022.11.005; Pavis M, 2021, CONVERGENCE-US, V27, P974, DOI 10.1177/13548565211033418; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Perov I, 2021, Arxiv, DOI arXiv:2005.05535; Pfefferkorn R., 2019, BU Pub. Int. LJ, V29, P245; Pianese A, 2022, IEEE INT WORKS INFOR, DOI 10.1109/WIFS55849.2022.9975428; Piantadosi ST, 2014, PSYCHON B REV, V21, P1112, DOI 10.3758/s13423-014-0585-6; Ping W, 2018, Arxiv, DOI arXiv:1710.07654; Piva A., 2013, International Scholarly Research Notices, P1, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]; Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532; Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1428, DOI 10.1145/3343031.3351066; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rana MS, 2022, IEEE ACCESS, V10, P25494, DOI 10.1109/ACCESS.2022.3154404; Raval MS, 2022, ASIAPAC SIGN INFO PR, P1837, DOI 10.23919/APSIPAASC55919.2022.9980089; Regulation P., 2018, Proc. Intouch, V25, P1; resemble, AI Voice Generator With Text to Speech and Speech to SpeechResemble AI; Rethlefsen ML, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-020-01542-z; Rini R, 2020, PHILOS IMPRINT, V20, P1; Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805; Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009; Roopak M, 2023, FORENS SCI INT-DIGIT, V47, DOI 10.1016/j.fsidi.2023.301637; Sabir E., 2019, Interfaces (GUI), V3, P80; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Salvi D, 2023, PROCEEDINGS OF THE 2ND ACM INTERNATIONAL WORKSHOP ON MULTIMEDIA AI AGAINST DISCRIMINATION, MAD 2023, P3, DOI 10.1145/3592572.3592844; Semaan P., 2012, J Comput Sci Res, V1, P50; Shahzad SA, 2022, ASIAPAC SIGN INFO PR, P1885, DOI 10.23919/APSIPAASC55919.2022.9980296; Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7; Singh Prabhat, 2021, 2021 International Conference on Technological Advancements and Innovations (ICTAI), P11, DOI 10.1109/ICTAI53825.2021.9673465; Sisman B, 2021, IEEE-ACM T AUDIO SPE, V29, P132, DOI 10.1109/TASLP.2020.3038524; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Subramani N, 2020, AAAI CONF ARTIF INTE, V34, P5859; Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640;  RTP, 2020, Arxiv, DOI arXiv:2008.03464; Tak H, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6369, DOI 10.1109/ICASSP39728.2021.9414234; Tan X, 2022, Arxiv, DOI arXiv:2205.04421; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; techtarget, GANs vs. VAEs: What is the Best Generative AI Approach? | TechTarget; Teng Zhang, 2020, 2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology (CCET), P67, DOI 10.1109/CCET50901.2020.9213159; Tesfagergish SG, 2021, LECT NOTES COMPUT SC, V12954, P523, DOI 10.1007/978-3-030-86979-3_37; Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525; Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014; Tong A., Deepfaking it: America's 2024 Election Collides With AI Boom; Tourille J, 2022, 1ST ACM INTERNATIONAL WORKSHOP ON MULTIMEDIA AI AGAINST DISINFORMATION, MAD 2022, P44, DOI 10.1145/3512732.3533584; tykefilms, My Blonde GF-Tyke Films; Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; Vaswani A, 2017, ADV NEUR IN, V30; Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101; Vizoso A, 2021, MEDIA COMMUN-LISBON, V9, P291, DOI 10.17645/mac.v9i1.3494; Wadhera S, 2022, Arxiv, DOI arXiv:2207.06909; Wahl-Jorgensen K, 2021, JOURNAL PRACT, V15, P803, DOI 10.1080/17512786.2021.1908838; Wang P, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1557, DOI 10.1145/3184558.3191610; Wang R, 2020, Arxiv, DOI arXiv:1909.06122; Wang R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1207, DOI 10.1145/3394171.3413716; Wang YX, 2017, Arxiv, DOI arXiv:1703.10135; weforum, How Can We Combat the Worrying Rise in Deepfake Content?; Weikmann T, 2023, DIGIT JOURNAL, DOI 10.1080/21670811.2023.2194665; Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282; Whittaker L, 2021, AUSTRALAS MARK J, V29, P204, DOI 10.1177/1839334921999479; Wirth R. P. J., 2021, P 14 INT C ADV HUM O, P26; Wu ZZ, 2020, Arxiv, DOI arXiv:2009.09637; Yadlin-Segal A, 2021, CONVERGENCE-US, V27, P36, DOI 10.1177/1354856520923963; Yang JC, 2022, IEEE T CIRC SYST VID, V32, P4854, DOI 10.1109/TCSVT.2021.3133859; Yang JC, 2021, IEEE T INF FOREN SEC, V16, P4234, DOI 10.1109/TIFS.2021.3102487; Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164; Yi JY, 2023, Arxiv, DOI arXiv:2104.03617; Yin WP, 2017, Arxiv, DOI arXiv:1702.01923; Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765; Zellers R., 2020, P ADV NEUR INF PROC, P1; Zendran M, 2021, PROCEDIA COMPUT SCI, V192, P834, DOI 10.1016/j.procs.2021.08.086; Zhang JX, 2019, IEEE-ACM T AUDIO SPE, V27, P631, DOI 10.1109/TASLP.2019.2892235; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T, 2022, MULTIMED TOOLS APPL, V81, P6259, DOI 10.1007/s11042-021-11733-y; Zhang X, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035107; Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497; Zhang Y, 2021, IEEE SIGNAL PROC LET, V28, P937, DOI 10.1109/LSP.2021.3076358; Zhang ZY, 2021, PROCEEDINGS OF THE 2021 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, IH&MMSEC 2021, P13, DOI 10.1145/3437880.3460408; Zheng Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777; Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416; Zhu XY, 2021, PROC CVPR IEEE, P2928, DOI 10.1109/CVPR46437.2021.00295	257	1	1	29	29	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						144497	144529		10.1109/ACCESS.2023.3344653	http://dx.doi.org/10.1109/ACCESS.2023.3344653			33	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	DK2R0		gold			2024-07-03	WOS:001131871200001
C	Savelka, J			ACM	Savelka, Jaromir			Unlocking Practical Applications in Legal Domain: Evaluation of GPT for Zero-Shot Semantic Annotation of Legal Texts	PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023			English	Proceedings Paper	19th International Conference on Artificial Intelligence and Law (ICAIL)	JUN 19-23, 2023	Univ Minho Law Sch, Braga, PORTUGAL	Int Assoc Artificial Intelligence & Law, Univ Minho Informat Dept Engn Sch, JUSGOV Res Ctr Justice & Governance, Centro Algoritmi, Intelligent Syst Associated Lab, Thomson Reuters, Centro Juridico Minho, Antas da Cunha ECIJA Soc Advogados, Visionware, Simplexico, Assoc Advancement Artificial Intelligence, ACM SIGAI	Univ Minho Law Sch	Semantic legal annotation; generative pre-trained transformers; GPT; transfer learning; zero-shot; adjudicatory	DECISIONS; EXTRACTION	We evaluated the capability of a state-of-the-art generative pretrained transformer (GPT) model to perform semantic annotation of short text snippets (one to few sentences) coming from legal documents of various types. Discussions of potential uses (e.g., document drafting, summarization) of this emerging technology in legal domain have intensified, but to date there has not been a rigorous analysis of these large language models' (LLM) capacity in sentence-level semantic annotation of legal texts in zero-shot learning settings. Yet, this particular type of use could unlock many practical applications (e.g., in contract review) and research opportunities (e.g., in empirical legal studies). We fill the gap with this study. We examined if and how successfully the model can semantically annotate small batches of short text snippets (10-50) based exclusively on concise definitions of the semantic types. We found that the GPT model performs surprisingly well in zero-shot settings on diverse types of documents (F-1 =.73 on a task involving court opinions, .86 for contracts, and .54 for statutes and regulations). These findings can be leveraged by legal scholars and practicing lawyers alike to guide their decisions in integrating LLMs in wide range of workflows involving semantic annotation of legal texts.	[Savelka, Jaromir] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Savelka, J (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	jsavelka@cs.cmu.edu	Savelka, Jaromir/GOK-0488-2022	Savelka, Jaromir/0000-0002-3674-5456				Bhattacharya P, 2019, FRONT ARTIF INTEL AP, V322, P3, DOI 10.3233/FAIA190301; Biagioli, 2005, P 10 INT C ART INT L, P133, DOI DOI 10.1145/1165485.1165506; Blair-Stanek A, 2023, Arxiv, DOI arXiv:2302.06100; Boniol P., 2020, P NATURAL LEGAL LANG; Brandner K, 2019, 13TH EUROPEAN CONFERENCE ON SOFTWARE ARCHITECTURE (ECSA 2019), VOL 2, P22, DOI 10.1145/3344948.3344959; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalkidis I., 2017, Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law, P19, DOI DOI 10.1145/3086512.3086515; Chalkidis Ilias, 2021, arXiv; de Maat E, 2010, FRONT ARTIF INTEL AP, V223, P87, DOI 10.3233/978-1-60750-682-9-87; Farzindar Atefeh, 2004, JURIX 2004; Francesconi Enrico, 2010, Integrating a bottomup and topdown methodology for building semantic resources for the multilingual legal domain; Goodhue John, 2023, Classification of Trademark Distinctiveness using OpenAI GPT 3.5 model; Hamilton S, 2023, arXiv; Harasta Jakub, 2019, Jusletter IT, V4; Hendrycks D., 2021, 35 C NEURAL INFORM P; Huihui Xu, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P250, DOI 10.1145/3462757.3466098; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Katz D. M., 2023, GPT-4 Passes the Bar Exam; Kingma D. P., 2017, ARXIV; Leivaditi S, 2020, Arxiv, DOI arXiv:2010.10386; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ouyang Long, 2022, Systems. Advances in Neural Information Processing; Petrova A, 2020, FRONT ARTIF INTEL AP, V334, P133, DOI 10.3233/FAIA200857; Poudyal P, 2020, P 7 WORKSHOP ARGUMEN, P67; Savelka Jaromir, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P129, DOI 10.1145/3462757.3466149; Savelka J, 2018, FRONT ARTIF INTEL AP, V313, P111, DOI 10.3233/978-1-61499-935-5-111; Savelka J, 2014, FRONT ARTIF INTEL AP, V271, P133, DOI 10.3233/978-1-61499-468-8-133; Savelka J, 2015, FRONT ARTIF INTEL AP, V279, P101, DOI 10.3233/978-1-61499-609-5-101; Savelka J, 2017, TRAIT AUTOM LANG, V58, P21; Savelka Jaromir, 2020, CrossDomain Generalization and Knowledge Transfer in Transformers Trained on Legal Data; Savelka Jaromir, 2017, WORKSHOP AUTOMATED S, P10; Savelka Jaromir, 2015, P 15 INT C ARTIFICIA, P216; Sweeney Patricia M, 2013, Network Analysis in Law, P53; Thanh NH, 2023, Arxiv, DOI arXiv:2304.06912; Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994; Walker V. R., 2017, P 16 EDITION INT C A, P217; Walker Vern R, 2019, ASAIL@ ICAIL, V2385; Wang SH, 2023, Arxiv, DOI arXiv:2301.00876; Wang Su, 2022, arXiv, DOI DOI 10.48550/ARXIV.2212; Westermann H, 2020, FRONT ARTIF INTEL AP, V334, P164, DOI 10.3233/FAIA200860; Westermann H, 2019, FRONT ARTIF INTEL AP, V322, P123, DOI 10.3233/FAIA190313; Winkels R, 2012, FRONT ARTIF INTEL AP, V250, P157, DOI 10.3233/978-1-61499-167-0-157; Wyner A, 2011, FRONT ARTIF INTEL AP, V235, P113, DOI 10.3233/978-1-60750-981-3-113; Xu H., 2021, Legal Knowledge and Information Systems, P33; Xu HH, 2020, FRONT ARTIF INTEL AP, V334, P184, DOI 10.3233/FAIA200862	45	3	3	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0197-9				2023							447	451		10.1145/3594536.3595161	http://dx.doi.org/10.1145/3594536.3595161			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Government & Law	BW3KK		Green Submitted, hybrid			2024-07-03	WOS:001139079400053
J	Fliorent, R; Fardman, B; Podwojniak, A; Javaid, K; Tan, IJ; Ghani, H; Truong, TM; Rao, B; Heath, C				Fliorent, Rebecca; Fardman, Brian; Podwojniak, Alicia; Javaid, Kiran; Tan, Isabella J.; Ghani, Hira; Truong, Thu M.; Rao, Babar; Heath, Candrice			Artificial intelligence in dermatology: advancements and challenges in skin of color	INTERNATIONAL JOURNAL OF DERMATOLOGY			English	Review						artificial intelligence; ethnic skin; racial disparities; skin of color	DIGITAL PHOTOGRAPHY; CANCER-RISK; REPRESENTATION; CLASSIFICATION; LIMITATIONS	Artificial intelligence (AI) uses algorithms and large language models in computers to simulate human-like problem-solving and decision-making. AI programs have recently acquired widespread popularity in the field of dermatology through the application of online tools in the assessment, diagnosis, and treatment of skin conditions. A literature review was conducted using PubMed and Google Scholar analyzing recent literature (from the last 10 years through October 2023) to evaluate current AI programs in use for dermatologic purposes, identifying challenges in this technology when applied to skin of color (SOC), and proposing future steps to enhance the role of AI in dermatologic practice. Challenges surrounding AI and its application to SOC stem from the underrepresentation of SOC in datasets and issues with image quality and standardization. With these existing issues, current AI programs inevitably do worse at identifying lesions in SOC. Additionally, only 30% of the programs identified in this review had data reported on their use in dermatology, specifically in SOC. Significant development of these applications is required for the accurate depiction of darker skin tone images in datasets. More research is warranted in the future to better understand the efficacy of AI in aiding diagnosis and treatment options for SOC patients.	[Fliorent, Rebecca; Fardman, Brian; Podwojniak, Alicia; Javaid, Kiran] Rowan Virtua Sch Osteopath Med, Stratford, NJ USA; [Tan, Isabella J.] Rutgers Robert Wood Johnson Med Sch, New Brunswick, NJ USA; [Ghani, Hira] Northwestern Univ, Feinberg Sch Med, Chicago, IL USA; [Truong, Thu M.; Rao, Babar] Rutgers Robert Wood Johnson, Ctr Dermatol, 1 Worlds Fair Dr, Somerset, NJ 08873 USA; [Heath, Candrice] Temple Univ, Lewis Katz Sch Med, Philadelphia, PA USA	Rutgers University System; Rutgers University New Brunswick; Rutgers University Biomedical & Health Sciences; Northwestern University; Feinberg School of Medicine; Rutgers University System; Rutgers University New Brunswick; Rutgers University Biomedical & Health Sciences; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Truong, TM (corresponding author), Rutgers Robert Wood Johnson, Ctr Dermatol, 1 Worlds Fair Dr, Somerset, NJ 08873 USA.	tmt117@njms.rutgers.edu		Podwojniak, Alicia/0009-0005-5109-2405; Fliorent, Rebecca/0009-0003-5934-8896; Truong, Thu/0000-0002-6282-801X; Fardman, Brian/0000-0003-1755-8396				Adamson AS, 2018, JAMA DERMATOL, V154, P1247, DOI 10.1001/jamadermatol.2018.2348; Aggarwal P I, 2022, J DERMATOL TREAT, V33, P2257, DOI 10.1080/09546634.2021.1944970; Ahmed F, 2022, J AM ACAD DERMATOL, V87, pE193, DOI 10.1016/j.jaad.2022.08.009; Alvarado SM, 2021, J AM ACAD DERMATOL, V84, P1427, DOI DOI 10.1016/j.jaad.2020.06.041; Amini A, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P289, DOI 10.1145/3306618.3314243; [Anonymous], DEVELOPING MONK SKIN; [Anonymous], 2021, CASUAL CONVERSATIONS; Ashique K T, 2015, Indian Dermatol Online J, V6, P158, DOI 10.4103/2229-5178.156381; Baig IT, 2023, CLIN DERMATOL, V41, P171, DOI 10.1016/j.clindermatol.2022.10.001; Behbahani S, 2021, BRIT J DERMATOL, V184, P158, DOI 10.1111/bjd.19406; Bellicoso E, 2021, J CUTAN MED SURG, V25, P409, DOI 10.1177/12034754211007430; Chen RH, 2016, TELEMED E-HEALTH, V22, P45, DOI 10.1089/tmj.2014.0249; Chilukuri S., 2019, SHOWDOWN SMARTPHONE; Daneshjou R, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq6147; Daneshjou R, 2022, JAMA DERMATOL, V158, P90, DOI 10.1001/jamadermatol.2021.4915; De A, 2020, INDIAN J DERMATOL, V65, P352, DOI 10.4103/ijd.IJD_418_20; DeGrave AJ., 2023, MEDRXIV; Diao JA, 2022, J AM ACAD DERMATOL, V86, P950, DOI 10.1016/j.jaad.2021.03.088; Doshi T., 2022, IMPROVING SKIN TONE; Du-Harpur X, 2020, BRIT J DERMATOL, V183, P423, DOI 10.1111/bjd.18880; FITZPATRICK TB, 1988, ARCH DERMATOL, V124, P869, DOI 10.1001/archderm.124.6.869; Goon P, 2021, Skin Health Dis, V1, pe40, DOI 10.1002/ski2.40; Goyal M, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104065; Grossarth S, 2023, CURR ONCOL REP, V25, P635, DOI 10.1007/s11912-023-01407-3; Guido N., 2021, J SURG DERMATOL, V6, P14; Heath CR, 2021, CUTIS, V108, P155, DOI 10.12788/cutis.0343; Hereford B, 2022, J AM ACAD DERMATOL, V87, P1434, DOI 10.1016/j.jaad.2022.08.003; Kamulegeya LH, 2019, bioRxiv; Kashetsky N, 2023, J DTSCH DERMATOL GES, V21, P1102, DOI 10.1111/ddg.15129; Lester JC, 2019, BRIT J DERMATOL, V180, P1521, DOI 10.1111/bjd.17608; Li ZX, 2022, J CLIN MED, V11, DOI 10.3390/jcm11226826; Liopyris K, 2022, DERMATOLOGY THER, V12, P2637, DOI 10.1007/s13555-022-00833-8; Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3; Liu YY, 2023, DERMATOLOGY, V239, P499, DOI 10.1159/000530225; MacLellan AN, 2021, J AM ACAD DERMATOL, V85, P353, DOI 10.1016/j.jaad.2020.04.019; Matsumoto M, 2018, J AM ACAD DERMATOL, V78, P701, DOI 10.1016/j.jaad.2017.11.033; Meckley AL, 2022, J AM ACAD DERMATOL, V86, pE57, DOI 10.1016/j.jaad.2021.09.041; Monk E., The Monk Skin Tone Scale; Narla A, 2018, J INVEST DERMATOL, V138, P2108, DOI 10.1016/j.jid.2018.06.175; Navarrete-Dechent C, 2021, J INVEST DERMATOL, V141, P1325, DOI 10.1016/j.jid.2020.06.040; Navarrete-Dechent C, 2018, J INVEST DERMATOL, V138, P2277, DOI 10.1016/j.jid.2018.04.040; Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028; Omiye JA, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1278232; Pandya AG, 2016, J AM ACAD DERMATOL, V74, P584, DOI 10.1016/j.jaad.2015.10.044; Patel S, 2021, CLIN DERMATOL, V39, P667, DOI 10.1016/j.clindermatol.2021.03.012; Patil S, 2020, INDIAN DERMATOL ONL, V11, P910, DOI 10.4103/idoj.IDOJ_61_20; Phillips M, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.13436; Pichon LC, 2010, ETHNIC DIS, V20, P174; Rezk E, 2022, JMIR RES PROTOC, V11, DOI 10.2196/34896; Rundle CW, 2021, CLIN DERMATOL, V39, P657, DOI 10.1016/j.clindermatol.2021.03.011; Scheinfeld N, 2008, J AM ACAD DERMATOL, V59, P351, DOI 10.1016/j.jaad.2008.02.018; Sommers MS, 2019, ETHNIC DIS, V29, P505, DOI 10.18865/ed.29.3.505; Suri A., 2022, PRACTICAL AI HEALTHC, P229; Ware OR, 2020, CUTIS, V105, P77; Wen D, 2022, LANCET DIGIT HEALTH, V4, pE64, DOI 10.1016/S2589-7500(21)00252-1; Wilson Britney N, 2021, Int J Womens Dermatol, V7, P391, DOI 10.1016/j.ijwd.2021.04.001; Winkler JK, 2019, JAMA DERMATOL, V155, P1135, DOI 10.1001/jamadermatol.2019.1735	57	1	1	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0011-9059	1365-4632		INT J DERMATOL	Int. J. Dermatol.	APR	2024	63	4					455	461		10.1111/ijd.17076	http://dx.doi.org/10.1111/ijd.17076		MAR 2024	7	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	LQ7Q3	38444331	hybrid			2024-07-03	WOS:001179009900001
J	Meltzer, P; Lambourne, JG; Grandi, D				Meltzer, Peter; Lambourne, Joseph G.; Grandi, Daniele			What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models Through User-Provided Names in Computer Aided Design Files	JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING			English	Article						artificial intelligence; big data and analytics; computer aided design; data driven engineering; machine learning for engineering applications		Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work, we propose that the natural language names designers use in computer aided design (CAD) software are a valuable source of such knowledge, and that large language models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks. In particular, we extract and clean a large corpus of natural language part, feature, and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also identify key limitations to using LLMs with text data alone, and our findings provide a strong motivation for further work into multi-modal text-geometry models. To aid and encourage further work in this area we make all our data and code publicly available.	[Meltzer, Peter; Lambourne, Joseph G.] Autodesk Res, London WC2R 0QE, England; [Grandi, Daniele] Autodesk Res, San Fransciso, CA 94105 USA	Autodesk, Inc.	Meltzer, P; Lambourne, JG (corresponding author), Autodesk Res, London WC2R 0QE, England.; Grandi, D (corresponding author), Autodesk Res, San Fransciso, CA 94105 USA.	pete.meltzer@autodesk.com; joseph.lambourne@autodesk.com; joseph.lambourne@autodesk.com						Bespalov D., 2005, Proceedings of the 2005 ACM Symposium on Solid and Physical Modeling-SPM '05, V1, P275; Bharadwaj A, 2019, PROCEEDINGS OF THE ASME 14TH INTERNATIONAL MANUFACTURING SCIENCE AND ENGINEERING CONFERENCE, 2019, VOL 1; Bian S., 2022, INT DES ENG TECHN C; Bird S., 2009, NATURAL LANGUAGE PRO; Bohm M., 2004, INT MECH ENG C EXPOS, P55; Bohm MR, 2008, COMPUT AIDED DESIGN, V40, P801, DOI 10.1016/j.cad.2007.09.003; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown Tom B, 2020, Neural Information Processing Systems; Carlson A, 2010, AAAI CONF ARTIF INTE, P1306; Chen K, 2019, LECT NOTES COMPUT SC, V11363, P100, DOI 10.1007/978-3-030-20893-6_7; Cheong H, 2011, J MECH DESIGN, V133, DOI 10.1115/1.4003249; Dayma B., 2021, Dalle Mini, V7; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng YX, 2020, INT J ADV ROBOT SYST, V17, DOI [10.1177/1729881420911257, 10.1177/1729881420921327]; Ferrero V., 2020, PyDamp: Python-Based Data Addition and Management of PSQL databases; Fisher M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866204; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; Han ZZ, 2019, AAAI CONF ARTIF INTE, P126; Hirtz J, 2002, RES ENG DES, V13, P65, DOI 10.1007/s00163-001-0008-3; Jones B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480562; Khalid Nasir, 2022, ACM T GRAPH TOG P SI; Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983; Korbi A, 2022, P I MECH ENG B-J ENG, V236, P219, DOI 10.1177/09544054211025775; Kurtoglu T., 2005, 15 INT C ENG DES ENG; Kwon L, 2022, AI EDAM, V36, DOI 10.1017/S0890060422000130; Lee J, 2019, PR MACH LEARN RES, V97; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Mehmood MA, 2017, 2017 IEEE 13TH MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P164, DOI 10.1109/MICC.2017.8311752; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Phelan K., 2014, ASME DES ENG TECHN A, P1; Radford A., 2018, IMPROVING LANGUAGE U; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A, 2021, PR MACH LEARN RES, V139; Rocchio JJ, 1971, Relevance feedback in information retrieval; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Salton G., 1991, P 14 ANN INT ACM SIG, P356, DOI [DOI 10.1145/122860.122897, 10.1145/122860.122897]; Sanghi A., 2022, IEEE CVF C COMP VIS; Sanghi A, 2022, Arxiv, DOI arXiv:2211.01427; Sanh Victor, 2020, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Sarica S, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112995; Schinko C, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 1, P306, DOI 10.5220/0006268103060313; Schlachter K., 2022, SIGGRAPH ASIA; Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649; Szykman S, 2000, IEEE INTELL SYST APP, V15, P48, DOI 10.1109/5254.846285; Tan ZX, 2020, AI OPEN, V1, P5, DOI 10.1016/j.aiopen.2020.11.001; Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502; Vaswani A, 2017, ADV NEUR IN, V30; Willis KDD, 2022, PROC CVPR IEEE, P15828, DOI 10.1109/CVPR52688.2022.01539; Chang AX, 2015, Arxiv, DOI arXiv:1512.03012; Yi L, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275027; Zhang C, 2021, AI OPEN, V2, P205, DOI 10.1016/j.aiopen.2021.12.001; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	55	1	1	2	2	ASME	NEW YORK	TWO PARK AVE, NEW YORK, NY 10016-5990 USA	1530-9827	1944-7078		J COMPUT INF SCI ENG	J. Comput. Inf. Sci. Eng.	JAN 1	2024	24	1							011002	10.1115/1.4062454	http://dx.doi.org/10.1115/1.4062454			11	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF6Y6					2024-07-03	WOS:001123887200012
J	Ong, H; Ong, J; Cheng, RBK; Wang, CL; Lin, MR; Ong, D				Ong, Hannah; Ong, Joshua; Cheng, Rebekah; Wang, Calvin; Lin, Murong; Ong, Dennis			GPT Technology to Help Address Longstanding Barriers to Care in Free Medical Clinics	ANNALS OF BIOMEDICAL ENGINEERING			English	Article						GPT; Free medical clinic; Electronic Health Records; Barriers to care		The implementation of technology in healthcare has revolutionized patient-centered decision making by providing contextualized information about a patient's healthcare journey, leading to increased efficiency (Keyworth et al. in BMC Med Inform Decis Mak 18:93, 2018, https://doi.org/10.1186/s12911-018-0661-3). Artificial intelligence has been integrated within Electronic Health Records (EHR) to prompt screenings or diagnostic tests based on a patient's holistic health profile. While larger hospitals have already widely adopted these technologies, free clinics hold lower utilization of these advanced capability EHRs. The patient population at a free clinic faces a multitude of factors that limits their access to comprehensive care, thus requiring necessary efforts and measures to close the gap in healthcare disparities. Emerging Artificial Intelligence (AI) technology, such as OpenAI's ChatGPT, GPT-4, and other large language models (LLMs) have remarkable potential to improve patient care outcomes, promote health equity, and enhance comprehensive and holistic care in resource-limited settings. This paper aims to identify areas in which integrating these LLM AI advancements into free clinics operations can optimize and streamline healthcare delivery to underserved patient populations. This paper also identifies areas of improvements in GPT that are necessary to deliver those services.	[Ong, Hannah] Ohio State Univ, Coll Med, Columbus, OH 43210 USA; [Ong, Joshua] Univ Michigan, Michigan Med, Ann Arbor, MI USA; [Cheng, Rebekah] Virginia Commonwealth Univ, Dept Phys Therapy, Richmond, VA USA; [Wang, Calvin] Rutgers State Univ, Coll Med Robert Wood Johnson, New Brunswick, NJ USA; [Lin, Murong] Verizon, San Jose, CA USA; [Ong, Dennis] Amazon, Amazon Web Serv, Seattle, WA USA	University System of Ohio; Ohio State University; University of Michigan System; University of Michigan; Virginia Commonwealth University; Rutgers University System; Rutgers University New Brunswick; Amazon.com	Ong, H (corresponding author), Ohio State Univ, Coll Med, Columbus, OH 43210 USA.	Hannah.ong@osumc.edu	Ong, Joshua/JPX-0619-2023	Ong, Joshua/0000-0003-4860-827X; Ong, Hannahong1/0000-0002-6041-0322				Ayanian JZ, 2000, JAMA-J AM MED ASSOC, V284, P2061, DOI 10.1001/jama.284.16.2061; Bedford Lydia K, 2020, SN Compr Clin Med, V2, P2271, DOI 10.1007/s42399-020-00585-6; Birs A, 2016, CUREUS J MED SCIENCE, V8, DOI 10.7759/cureus.500; Chien SY, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17103495; Christy SM, 2017, J HEALTH COMMUN, V22, P923, DOI 10.1080/10810730.2017.1377322; Darnell JS, 2010, ARCH INTERN MED, V170, P946, DOI 10.1001/archinternmed.2010.107; Keyworth C, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0661-3; Mallow Jennifer A, 2014, Open J Nurs, V4, P912; Marbouh D, 2020, RISK MANAG HEALTHC P, V13, P509, DOI 10.2147/RMHP.S232114; National Commission on Prevention Priorities, 2007, PREV CAR NAT PROF US; Syed ST, 2013, J COMMUN HEALTH, V38, P976, DOI 10.1007/s10900-013-9681-1; Yong P.L., 2010, HEALTHCARE IMPERATIV	12	5	5	17	35	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	SEP	2023	51	9					1906	1909		10.1007/s10439-023-03256-4	http://dx.doi.org/10.1007/s10439-023-03256-4		JUN 2023	4	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	O2UY8	37355478				2024-07-03	WOS:001019903200001
J	Shahira, KC; Joshi, P; Lijiya, A				Shahira, K. C.; Joshi, Pulkit; Lijiya, A.			Data Extraction and Question Answering on Chart Images Towards Accessibility and Data Interpretation	IEEE OPEN JOURNAL OF THE COMPUTER SOCIETY			English	Article						Data mining; Bars; Visualization; Question answering (information retrieval); Data visualization; Pipelines; Feature extraction; Chart accessibility; data visualization; information retrieval; image processing; object detection; table question answering		Graphical representations such as chart images are integral to web pages and documents. Automating data extraction from charts is possible by reverse-engineering the visualization pipeline. This study proposes a framework that automates data extraction from bar charts and integrates it with question-answering. The framework employs an object detector to recognize visual cues in the image, followed by text recognition. Mask-RCNN for plot element detection achieves a mean average precision of 95.04% at a threshold of 0.5 which decreases as the Intersection over Union (IoU) threshold increases. A contour approximation-based approach is proposed for extracting the bar coordinates, even at a higher IoU of 0.9. The textual and visual cues are associated with the legend text and preview, and the chart data is finally extracted in tabular format. We introduce an extension to the TAPAS model, called TAPAS++, by incorporating new operations and table question answering is done using TAPAS++ model. The chart summary or description is also produced in an audio format. In the future, this approach could be expanded to enable interactive question answering on charts by accepting audio inquiries from individuals with visual impairments and do more complex reasoning using Large Language Models.	[Shahira, K. C.; Joshi, Pulkit; Lijiya, A.] Natl Inst Technol Calicut, Kozhikode 673601, India	National Institute of Technology (NIT System); National Institute of Technology Calicut	Shahira, KC (corresponding author), Natl Inst Technol Calicut, Kozhikode 673601, India.	kcshahira@gmail.com; pulkit_m210383cs@nitc.ac.in; lijiya@nitc.ac.in						Al-Zaidy R. A., 2015, P 8 INT C KNOWL CAPT, P1; Al-Zaidy Rabah A, 2016, WORKSH 30 AAAI C ART; Bajic F, 2023, INT J DOC ANAL RECOG, V26, P453, DOI 10.1007/s10032-022-00424-5; Balaji A, 2018, Arxiv, DOI [arXiv:1812.10636, 10.48550/arXiv.1812.10636, DOI 10.48550/ARXIV.1812.10636]; Chen Y, 2023, Arxiv, DOI [arXiv:2302.11713, 10.48550/arXiv.2302.11713, DOI 10.48550/ARXIV.2302.11713]; Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005; De P, 2018, IEEE INT ADV COMPUT, P20, DOI 10.1109/IADCC.2018.8692104; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Herzig J, 2020, Arxiv, DOI arXiv:2004.02349; Hoque E, 2022, COMPUT GRAPH FORUM, V41, P555, DOI 10.1111/cgf.14573; Jobin KV, 2019, PROC INT CONF DOC, P74, DOI 10.1109/ICDARW.2019.00018; Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592; Kahou Samira Ebrahimi, 2017, arXiv, DOI DOI 10.48550/ARXIV.1710.07300; Li NH, 2019, AAAI CONF ARTIF INTE, P6706; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu X, 2015, PROC INT CONF DOC, P801, DOI 10.1109/ICDAR.2015.7333872; Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702; Masry A, 2023, Arxiv, DOI arXiv:2305.14761; Masry A, 2022, Arxiv, DOI arXiv:2203.10244; Methani N, 2020, IEEE WINT CONF APPL, P1516, DOI 10.1109/WACV45572.2020.9093523; Mishchenko A., 2011, 2011 Sixth International Conference on Digital Information Management, P115, DOI 10.1109/ICDIM.2011.6093320; Raffel C, 2020, J MACH LEARN RES, V21; Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030; Savva M., 2011, P 24 ANN ACM S US IN, P393; Shahira KC, 2021, IEEE ACCESS, V9, P52926, DOI 10.1109/ACCESS.2021.3069205; Shahira KC, 2019, TENCON IEEE REGION, P858, DOI 10.1109/tencon.2019.8929594; Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41; Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027; Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142; Zhou YP, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P605, DOI 10.1109/ICIP.2000.899506	34	0	0	0	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		2644-1268		IEEE OPEN J COMP SOC	IEEE Open J. Comput. Soc.		2023	4						314	325		10.1109/OJCS.2023.3328767	http://dx.doi.org/10.1109/OJCS.2023.3328767			12	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering	Z3XT8		gold			2024-07-03	WOS:001111448000001
C	Si, CL; Friedman, D; Joshi, N; Feng, S; Chen, DQ; He, H		Rogers, A; Boyd-Graber, J; Okazaki, N		Si, Chenglei; Friedman, Dan; Joshi, Nitish; Feng, Shi; Chen, Danqi; He, He			Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				In-context learning (ICL) is an important paradigm for adapting large language models (LLMs) to new tasks, but the generalization behavior of ICL remains poorly understood. We investigate the inductive biases of ICL from the perspective of feature bias: which feature ICL is more likely to use given a set of underspecified demonstrations in which two features are equally predictive of the labels. First, we characterize the feature biases of GPT-3 models by constructing underspecified demonstrations from a range of NLP datasets and feature combinations. We find that LLMs exhibit clear feature biases-for example, demonstrating a strong bias to predict labels according to sentiment rather than shallow lexical features, like punctuation. Second, we evaluate the effect of different interventions that are designed to impose an inductive bias in favor of a particular feature, such as adding a natural language instruction or using semantically relevant label words. We find that, while many interventions can influence the learner to prefer a particular feature, it can be difficult to overcome strong prior biases. Overall, our results provide a broader picture of the types of features that ICL may be more likely to exploit and how to impose inductive biases that are better aligned with the intended task.(1)	[Si, Chenglei] Univ Maryland, College Pk, MD 20742 USA; [Friedman, Dan; Chen, Danqi] Princeton Univ, Princeton, NJ 08544 USA; [Joshi, Nitish; He, He] NYU, New York, NY 10003 USA; [Feng, Shi] Univ Chicago, Chicago, IL 60637 USA	University System of Maryland; University of Maryland College Park; Princeton University; New York University; University of Chicago	Si, CL (corresponding author), Univ Maryland, College Pk, MD 20742 USA.	clsi@umd.edu; dfriedman@cs.princeton.edu			National Science Foundation [IIS-2211779]; Sloan research fellowship; Samsung Advanced Institute of Technology; NSF Graduate Research Fellowship [1839302]	National Science Foundation(National Science Foundation (NSF)); Sloan research fellowship(Alfred P. Sloan Foundation); Samsung Advanced Institute of Technology(Samsung); NSF Graduate Research Fellowship(National Science Foundation (NSF))	We thank Alex Tamkin, Xi Ye, Sewon Min, and Jordan Boyd-Graber for their helpful feedback. This research is partially funded by the National Science Foundation (IIS-2211779), a Sloan research fellowship, Samsung Advanced Institute of Technology (under the project Next Generation Deep Learning: From Pattern Recognition to AI) and AWS AI. NJ is supported by an NSF Graduate Research Fellowship under grant number 1839302.	Akyurek Ekin, 2023, INT C LEARN REPR ICL; [Anonymous], 2011, P 49 ANN M ASS COMPU; Asghar Nabiha, 2016, ARXIV160505362; Borkan Daniel, 2019, WWW; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chan S.C., 2022, ADV NEURAL INFORM PR; CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1, DOI 10.1017/S0140525X00001515; Chung H.W., 2022, SCALING INSTRUCTION; Clark Christopher, 2019, N AM ASS COMP LING H; Dasgupta Ishita, 2022, P 39 INT C MACH LEAR, P4816; Gao Tianyu, 2021, Making pre-trained language models better few-shot learners; Geirhos Robert, 2020, Nature Machine Intelligence, V2, P665, DOI 10.1038/s42256-020-00257-z; Gururangan Suchin, 2018, N AM CHAPT ASS COMP; Hendrycks D, 2019, PR MACH LEARN RES, V97; Hendrycks Dan, 2020, PRETRAINED TRANSFORM; Joshi Nitish, 2022, EMPIRICAL METHODS NA; Lampinen Andrew Kyle, 2022, FIND EMP METH NAT LA; Le Scao Teven, 2022, ARXIV221105100; Lovering C., 2021, INT C LEARN REPR ICL, P2021; Lu Yao, 2022, FANTASTICALLY ORDERE; McCoy R. T., 2019, Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference; McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304; McCoy R Thomas, 2018, COGSCI; Min Sewon, 2022, EMPIRICAL METHODS NA; Mishra Swaroop, 2021, NATURAL INSTRUCTIONS; Mueller Aaron, 2022, FIND ASS COMP LIN AC; Ouyang L., 2022, NEURIPS; Pan Jane, 2023, FIND ASS COMP LING A; Pezeshkpour Pouya, 2022, FIND ASS COMP LING A; Poliak Adam, 2018, N AM CHAPT ASS COMP; Sagawa S., 2020, INT C MACH LEARN ICM; Saunshi Nikunj, 2021, INT C LEARN REPR; Shi Weijia, 2022, EMPIRICAL METHODS NA; Shinoda Kazutoshi, 2022, WHICH SHORTCUT SOLUT; Si Chenglei, 2023, INT C LEARN REPR ICL; Tamkin Alex, 2023, INT C LEARN REPR ICL; Tu LF, 2020, T ASSOC COMPUT LING, V8, P621, DOI 10.1162/tacl_a_00335; Voita Elena, 2020, EMPIRICAL METHODS NA; von Oswald Johannes, 2022, ARXIV221207677; Wang Yizhong, 2022, EMPIRICAL METHODS NA; Warstadt A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P217; Warstadt Alex, 2020, COGSCI; Webson Albert, 2022, N AM CHAPT ASS COMP; Wei C, 2021, ADV NEUR IN; Wei Jason, 2022, ADV NEURAL INFORM PR; Wei Jerry W., 2023, LARGER LANGUAGE MODE; Williams Adina, 2018, N AM CHAPT ASS COMP; Xie Sang Michael, 2022, INT C LEARN REPR ICL; Ye Xi, 2022, ADV NEURAL INFORM PR; Zhang S., 2022, Opt: Open pre-trained transformer language models; Zhang Tianyi, 2021, N AM CHAPT ASS COMP; Zhao Zihao., 2021, INT C MACH LEARN ICM	52	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							11289	11310						22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962503002
C	Telili, A; Hamidouche, W; Fezza, SA; Morin, L			IEEE	Telili, Ahmed; Hamidouche, Wassim; Fezza, Sid Ahmed; Morin, Luce			EFFICIENT PER-SHOT TRANSFORMER-BASED BITRATE LADDER PREDICTION FOR ADAPTIVE VIDEO STREAMING	2023 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, ICIP	IEEE International Conference on Image Processing ICIP		English	Proceedings Paper	30th IEEE International Conference on Image Processing (ICIP)	OCT 08-11, 2023	Kuala Lumpur, MALAYSIA	IEEE, Inst Elect & Elect Engineers, Signal Proc Soc		Bitrate ladder; video compression; HEVC; vision transformer; adaptive video streaming		Recently, HTTP adaptive streaming (HAS) has become a standard approach for over-the-top (OTT)-based video streaming services due to its ability to provide smooth streaming. In HAS, stream representations are encoded to target a specific bitrate providing a wide range of operating bitrates known as the bitrate ladder. In the past, a fixed bitrate ladder approach for all videos has been widely used. However, such a method does not consider video content, which can vary considerably in motion, texture, and scene complexity. Moreover, building a per-title bitrate ladder based on an exhaustive encoding is quite expensive due to the large encoding parameter space. Thus, alternative solutions allowing accurate and efficient per-title bitrate ladder prediction are in great demand. On the other hand, self-attention-based architectures have achieved tremendous performance in large language models (LLMs) and particularly vision transformers (ViTs) in computer vision tasks. Therefore, this paper investigates ViT's capabilities in building an efficient bitrate ladder without performing any encoding process. We provide the first in-depth analysis of the prediction accuracy and the complexity overhead induced by the ViTs model in predicting the bitrate ladder on a large and diverse video dataset. The source code of the proposed solution and the dataset will be made publicly available.	[Telili, Ahmed; Hamidouche, Wassim; Morin, Luce] Univ Rennes, CNRS, INSA Rennes, IETR,UMR 6164, Rennes, France; [Hamidouche, Wassim] Technol Innovat Ins, POB 9639, Abu Dhabi, U Arab Emirates; [Fezza, Sid Ahmed] Natl Higher Sch Telecommun, Oran, Algeria; [Fezza, Sid Ahmed] ICT, Oran, Algeria	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite de Rennes; Institut National des Sciences Appliquees de Rennes	Telili, A (corresponding author), Univ Rennes, CNRS, INSA Rennes, IETR,UMR 6164, Rennes, France.			Telili, Ahmed/0000-0002-2659-7840	Region Bretagne under the DEEPTEC project	Region Bretagne under the DEEPTEC project	This work has been supported by Region Bretagne under the DEEPTEC project.	Amirpour Hadi, 2022, IEEE T CIRCUITS SYST; [Anonymous], 2022, 2022 10 EUR WORKSH V, DOI DOI 10.1145/3565476.3569643; Ballas N., 2015, Delving deeper into convolutional networks for learning video representations; Bertasius G, 2021, PR MACH LEARN RES, V139; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; Forsythe A, 2009, LECT NOTES ARTIF INT, V5639, P158, DOI 10.1007/978-3-642-02728-4_17; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang TC, 2021, PROCEEDINGS OF THE 31ST ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV '21), P67, DOI 10.1145/3458306.3458873; Katsavounidis Ioannis, Dynamic optimizer-a perceptual video en coding optimization framework; Katsenou AV, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954529; Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338; Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167; Morris Crispian, 2023, ARXIV230208455; Paul Somdyuti, 2022, ARXIV220604877; Radosavovic Ilija, 2020, Designing network design spaces, P10428, DOI DOI 10.1109/CVPR42600.2020.01044; Sandvine, Global Internet Phenomena Report 2023; Silhavy Daniel, 2022, SMPTE Motion Imag. J., V131, P42; Telili A, 2022, PICT COD SYMP, P325, DOI 10.1109/PCS56426.2022.10018038; Wang Y, 2019, EVID-BASED COMPL ALT, V2019, DOI 10.1155/2019/2089586	20	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1522-4880		978-1-7281-9835-4	IEEE IMAGE PROC			2023							1835	1839		10.1109/ICIP49359.2023.10222094	http://dx.doi.org/10.1109/ICIP49359.2023.10222094			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1IU					2024-07-03	WOS:001106821001182
C	Wang, HM; Yuan, Y; Liu, ZY; Shen, JH; Yin, YC; Xiong, J; Xie, EZ; Shi, H; Li, YJ; Li, L; Yin, J; Li, ZG; Liang, XD		Rogers, A; Boyd-Graber, J; Okazaki, N		Wang, Haiming; Yuan, Ye; Liu, Zhengying; Shen, Jianhao; Yin, Yichun; Xiong, Jing; Xie, Enze; Shi, Han; Li, Yujun; Li, Lin; Yin, Jian; Li, Zhenguo; Liang, Xiaodan			DT-Solver: Automated Theorem Proving with Dynamic-Tree Sampling Guided by Proof-level Value Function	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Recent advances in neural theorem-proving resort to large language models and tree searches. When proving a theorem, a language model advises single-step actions based on the current proving state and the tree search finds a sequence of correct steps using actions given by the language model. However, prior works often conduct constant computation efforts for each proving state while ignoring that the hard states often need more exploration than easy states. Moreover, they evaluate and guide the proof search solely depending on the current proof state instead of considering the whole proof trajectory as human reasoning does. Here, to accommodate general theorems, we propose a novel Dynamic-Tree Driven Theorem Solver (DT-Solver) by guiding the search procedure with state confidence and proof-level values. Specifically, DT-Solver introduces a dynamic-tree Monte-Carlo search algorithm, which dynamically allocates computing budgets for different state confidences, guided by a new proof-level value function to discover proof states that require substantial exploration. Experiments on two popular theorem-proving datasets, PISA and Mathlib, show significant performance gains by our DT-Solver over the state-of-the-art approaches, with a 6.65% improvement on average in terms of success rate. And especially under low computing resource settings (11.03% improvement on average).	[Wang, Haiming; Xiong, Jing; Yin, Jian; Liang, Xiaodan] Sun Yat Sen Univ, Guangzhou, Peoples R China; [Yuan, Ye; Shen, Jianhao] Peking Univ, Beijing, Peoples R China; [Liu, Zhengying; Yin, Yichun; Xie, Enze; Shi, Han; Li, Yujun; Li, Lin; Li, Zhenguo] Huawei Noahs Ark Lab, Montreal, PQ, Canada; [Liang, Xiaodan] MBZUAI, Abu Dhabi, U Arab Emirates	Sun Yat Sen University; Peking University; Mohamed Bin Zayed University of Artificial Intelligence	Yin, J; Liang, XD (corresponding author), Sun Yat Sen Univ, Guangzhou, Peoples R China.; Liang, XD (corresponding author), MBZUAI, Abu Dhabi, U Arab Emirates.	wanghm39@mail2.sysu.edu.cn; yuanye_pku@pku.edu.cn; liuzhengying2@huawei.com; jhshen@pku.edu.cn; yinyichun@huawei.com; xiongj69@mail2.sysu.edu.cn; xie.enze@huawei.com; shi.han@huawei.com; liyujun9@huawei.com; lilin29@huawei.com; issjyin@mail.sysu.edu.cn; Li.Zhenguo@huawei.com; xdliang328@gmail.com			National Key R&D Program of China [2020AAA0109700]; Shenzhen Science and Technology Program [RCYX20200714114642083]; Shenzhen Fundamental Research Program [JCYJ20190807154211365]	National Key R&D Program of China; Shenzhen Science and Technology Program; Shenzhen Fundamental Research Program	This work was supported in part by the National Key R&D Program of China under Grant No. 2020AAA0109700, Shenzhen Science and Technology Program (Grant No. RCYX20200714114642083) and Shenzhen Fundamental Research Program(Grant No. JCYJ20190807154211365)	Alemi AA, 2016, ADV NEUR IN, V29; [Anonymous], 2016, ARXIV160802644; Bansal K, 2020, J AUTOM REASONING, V64, P1333, DOI 10.1007/s10817-020-09573-w; Barras Bruno, 1997, COQ PROOF ASSISTANT, P214; Bentkamp A, 2021, LECT NOTES ARTIF INT, V12699, P396, DOI 10.1007/978-3-030-79876-5_23; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; de Moura Leonardo, 2015, LECT NOTES COMPUTER, P378; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Han Jesse Michael, 2021, ARXIV210206203; Harrison J, 2014, HDB HIST LOGIC COMPU, V9, P135, DOI DOI 10.1016/B978-0-444-51624-4.50004-6; Howard W.A., 1980, Essays on Combinatory Logic, Lambda Calculus and Formalism; Jiang Albert Q, 2022, ARXIV220510893; Jiang Albert Qiaochu, 2021, LISA LANGUAGE MODELS; Kovacs Laura, 2013, Computer Aided Verification. 25th International Conference, CAV 2013. Proceedings. LNCS 8044, P1, DOI 10.1007/978-3-642-39799-8_1; Lample Guillaume, 2022, ARXIV220511491; Li Wenda, 2020, ICLR 2021; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; McCarthy J, 2006, AI MAG, V27, P12; MEGILL DAVID WHEELER A, 2019, Metamath: A Computer Language for Mathematical Proofs; Paulson Lawrence C., 1994, Isabelle: A Generic Theorem Prover; Polu Stanislas, 2020, ARXIV200903393CSSTAT; Polu Stanislas, 2022, ARXIV220201344; Rabe Markus Norman, 2020, Mathematical Reasoning via Self-supervised Skip-tree Training; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., Language Models are Unsupervised Multitask Learners, P24; Reed Scott, 2022, ARXIV220506175; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schulz S, 2002, AI COMMUN, V15, P111; Silver D., 2017, ARXIV171201815; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Vaswani A, 2017, ADV NEUR IN, V30; Wang Mingzhe, 2020, Advances in Neural Information Processing Systems, V33, P18146; Wu Yuhuai, 2021, ICLR 2021; Zheng Kunhao, 2021, miniF2F: a cross-system benchmark for formal Olympiad-level mathematics	34	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							12632	12646						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962504022
C	Wang, XY; Li, S; Ji, H		Rogers, A; Boyd-Graber, J; Okazaki, N		Wang, Xingyao; Li, Sha; Ji, Heng			CODE4STRUCT: Code Generation for Few-Shot Event Structure Prediction	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			NATURAL-LANGUAGE	Large Language Model (LLM) trained on a mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. We observe that semantic structures can be conveniently translated into code and propose CODE4STRUCT to leverage such text-tostructure translation capability to tackle structured prediction tasks. As a case study, we formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code. This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance1 and type annotation(2) to introduce external knowledge or add constraints. We show that, with sufficient in-context examples, formulating EAE as a code generation problem is advantageous over using variants of text-based prompts. Despite only using 20 training event instances for each event type, CODE4STRUCT is comparable to supervised models trained on 4,202 instances and outperforms current stateof-the-art (SOTA) trained on 20-shot data by 29.5% absolute F1. By leveraging the inheritance feature of PL, CODE4STRUCT can use 10-shot training data from a sibling event type to predict arguments for zero-resource event types and outperforms the zero-shot baseline by 12% absolute F1. 3	[Wang, Xingyao; Li, Sha; Ji, Heng] Univ Illinois, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Wang, XY (corresponding author), Univ Illinois, Urbana, IL 61801 USA.	xingyao6@illinois.edu; shal2@illinois.edu; hengji@illinois.edu			U.S. DARPA KAIROS Program [FA8750-19-2-1004]; U.S. DARPA AIDA Program [FA8750-18-2-0014]; U.S. DARPA ITM Program [FA8650-23-C-7316]	U.S. DARPA KAIROS Program(United States Department of Defense); U.S. DARPA AIDA Program(United States Department of Defense); U.S. DARPA ITM Program	We thank the anonymous reviewers for their helpful suggestions and comments. This research is based upon work supported by U.S. DARPA KAIROS Program No. FA8750-19-2-1004, U.S. DARPA AIDA Program No. FA8750-18-2-0014 and U.S. DARPA ITM Program No. FA8650-23-C-7316. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.	[Anonymous], 2016, P 2016 C N AM CHAPT, DOI DOI 10.1109/BIBE.2016.41; [Anonymous], 2022, P 2022 C N AM CHAPT; Banarescu L., 2013, P 7 LING ANN WORKSH, P178; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, ARXIV220402311; Doddington G., 2004, LREC, P1; Du X, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P671; Gao Luyu, 2022, ABS221110435 ARXIV; Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483; Hoffmann Jordan, 2022, arXiv; Huang KH, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5257; Ji Heng, 2008, P ANN M ASS COMP LIN; Li Q., 2013, LONG PAPERS ASS COMP, P73, DOI DOI 10.1021/BI00231A020; Li S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P894; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin Y., 2020, P 58 ANN M ASS COMPU, P7999, DOI DOI 10.18653/V1/2020.ACL-MAIN.713; Liu Jiachang, 2021, WORKSH KNOWL EXTR IN; Liu J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1641; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Lu YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2795; Madaan Aman, 2022, ARXIV221007128; MILLER LA, 1981, IBM SYST J, V20, P184, DOI 10.1147/sj.202.0184; Min S., 2022, ABS220212837 ARXIV; Nguyen T.H., 2016, P 2016 C N AM CHAPT, P300, DOI DOI 10.18653/V1/N16-1034; Nijkamp Erik, 2022, CONVERSATIONAL PARAD; Ouyang Long, 2022, ABS220302155 ARXIV; Paolini Giovanni, 2021, arXiv preprint arXiv:2101.05779; SEBRECHTS MM, 1985, BEHAV RES METH INS C, V17, P268, DOI 10.3758/BF03214395; Singh Ishika, 2022, PROG PROMPT GENERATI; Sun S., 2019, INT C LEARN REPR; Wadden D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5784; Zhang ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P39; Zhao Tony, 2021, ABS210209690 ARXIV	33	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							3640	3663						24	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086802020
J	Earp, BD; Mann, SP; Allen, J; Salloch, S; Suren, V; Jongsma, K; Braun, M; Wilkinson, D; Sinnott-Armstrong, W; Rid, A; Wendler, D; Savulescu, J				Earp, Brian D.; Mann, Sebastian Porsdam; Allen, Jemima; Salloch, Sabine; Suren, Vynn; Jongsma, Karin; Braun, Matthias; Wilkinson, Dominic; Sinnott-Armstrong, Walter; Rid, Annette; Wendler, David; Savulescu, Julian			A Personalized Patient Preference Predictor for Substituted Judgments in Healthcare: Technically Feasible and Ethically Desirable	AMERICAN JOURNAL OF BIOETHICS			English	Article; Early Access						Advance directives; algorithm; generative AI; large language models; Patient Preference Predictor; substituted judgment	ADVANCE DIRECTIVES; DECISION-MAKING; INCAPACITATED PATIENTS; FAMILY-MEMBERS; WELL	When making substituted judgments for incapacitated patients, surrogates often struggle to guess what the patient would want if they had capacity. Surrogates may also agonize over having the (sole) responsibility of making such a determination. To address such concerns, a Patient Preference Predictor (PPP) has been proposed that would use an algorithm to infer the treatment preferences of individual patients from population-level data about the known preferences of people with similar demographic characteristics. However, critics have suggested that even if such a PPP were more accurate, on average, than human surrogates in identifying patient preferences, the proposed algorithm would nevertheless fail to respect the patient's (former) autonomy since it draws on the 'wrong' kind of data: namely, data that are not specific to the individual patient and which therefore may not reflect their actual values, or their reasons for having the preferences they do. Taking such criticisms on board, we here propose a new approach: the Personalized Patient Preference Predictor (P4). The P4 is based on recent advances in machine learning, which allow technologies including large language models to be more cheaply and efficiently 'fine-tuned' on person-specific data. The P4, unlike the PPP, would be able to infer an individual patient's preferences from material (e.g., prior treatment decisions) that is in fact specific to them. Thus, we argue, in addition to being potentially more accurate at the individual level than the previously proposed PPP, the predictions of a P4 would also more directly reflect each patient's own reasons and values. In this article, we review recent discoveries in artificial intelligence research that suggest a P4 is technically feasible, and argue that, if it is developed and appropriately deployed, it should assuage some of the main autonomy-based concerns of critics of the original PPP. We then consider various objections to our proposal and offer some tentative replies.	[Earp, Brian D.; Mann, Sebastian Porsdam; Wilkinson, Dominic; Savulescu, Julian] Univ Oxford, Oxford, England; [Earp, Brian D.; Wilkinson, Dominic; Savulescu, Julian] Natl Univ Singapore, Singapore City, Singapore; [Earp, Brian D.] Yale Univ, New Haven, CT USA; [Earp, Brian D.] Hastings Ctr, New Haven, CT USA; [Allen, Jemima] Monash Univ, Monash, Australia; [Salloch, Sabine; Suren, Vynn] Hannover Med Sch, Hannover, Germany; [Jongsma, Karin] Univ Med Ctr Utrecht, Julius Ctr, Utrecht, Netherlands; [Braun, Matthias] Univ Bonn, Bonn, Germany; [Wilkinson, Dominic] John Radcliffe Hosp, Oxford, England; [Wilkinson, Dominic] Murdoch Childrens Res Inst, Murdoch, WA, Australia; [Sinnott-Armstrong, Walter] Duke Univ, Durham, NC USA; [Rid, Annette; Wendler, David] NIH Clin Ctr, Bethesda, MD USA; [Earp, Brian D.] Univ Oxford, Fac Philosophy, Uehiro Ctr Pract Ethics, Oxford, England	University of Oxford; National University of Singapore; Yale University; Monash University; Hannover Medical School; Utrecht University; Utrecht University Medical Center; University of Bonn; University of Oxford; Murdoch Children's Research Institute; Duke University; National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); University of Oxford	Earp, BD (corresponding author), Univ Oxford, Fac Philosophy, Uehiro Ctr Pract Ethics, Oxford, England.	brian.earp@philosophy.ox.ac.uk	Wilkinson, Dominic J/G-1380-2012	Braun, Matthias/0000-0002-6687-6027; Wilkinson, Dominic/0000-0003-3958-8633	OpenAI	OpenAI	No Statement Available	Allen JW, 2024, J MED ETHICS, V50, P77, DOI 10.1136/jme-2023-109347; Askell A, 2021, Arxiv, DOI [arXiv:2112.00861, DOI 10.48550/ARXIV.2112.00861]; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Benzinger L. J., 2023, Artificial Intelligence to support ethical decision-making for incapacitated patients: A survey among German anesthesiologists and internists; Berger JT, 2005, J CLIN ETHIC, V16, P3; Biller-Andorno N, 2022, J MED ETHICS, V48, P175, DOI 10.1136/medethics-2020-106786; Biller-Andorno N, 2019, NEW ENGL J MED, V381, P1480, DOI 10.1056/NEJMms1904869; Bleher Hannah, 2022, AI Ethics, V2, P747, DOI 10.1007/s43681-022-00135-x; Braun M, 2022, J MED ETHICS, V48, P579, DOI 10.1136/medethics-2021-107675; Braun M, 2021, J MED ETHICS, V47, P394, DOI 10.1136/medethics-2020-106134; Brock DW, 2014, J MED PHILOS, V39, P153, DOI 10.1093/jmp/jhu002; Christian B., 2020, The Alignment Problem: Machine Learning and Human Values; Church KW, 2021, NAT LANG ENG, V27, P763, DOI 10.1017/S1351324921000322; Ciroldi M, 2007, INTENS CARE MED, V33, P807, DOI 10.1007/s00134-007-0582-6; de Kerckhove D, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0367; Demaree-Cotton J, 2022, AM J BIOETHICS, V22, P1, DOI 10.1080/15265161.2022.2075968; Ditto PH, 2014, J MED PHILOS, V39, P196, DOI 10.1093/jmp/jhu007; Dresser R, 2014, J MED PHILOS, V39, P178, DOI 10.1093/jmp/jhu004; Earp B. D., 2022, Experimental Philosophy of Identity and the Self, P183; Earp BD, 2022, J MED ETHICS, V48, P287, DOI 10.1136/medethics-2022-108307; Earp BD, 2021, THEOR MED BIOETH, V42, P91, DOI 10.1007/s11017-021-09546-z; Earp Brian D, 2020, AJOB Empir Bioeth, V11, P30, DOI 10.1080/23294515.2020.1714792; Ferrario A, 2023, J MED ETHICS, V49, P185, DOI 10.1136/jme-2023-108945; Ferrario A, 2023, J MED ETHICS, V49, P165, DOI 10.1136/jme-2022-108371; Gabriel I, 2020, MIND MACH, V30, P411, DOI 10.1007/s11023-020-09539-2; Giubilini Alberto, 2018, Philos Technol, V31, P169, DOI 10.1007/s13347-017-0285-z; Gloeckler S, 2022, YALE J BIOL MED, V95, P349; Houts RM, 2002, MED DECIS MAKING, V22, P39, DOI 10.1177/02729890222062900; Hubbard R, 2020, SCI ENG ETHICS, V26, P3217, DOI 10.1007/s11948-020-00266-6; Jardas EJ, 2022, J MED ETHICS, V48, P304, DOI 10.1136/medethics-2021-107629; John S, 2014, J MED PHILOS, V39, P169, DOI 10.1093/jmp/jhu008; John SD, 2018, J MED ETHICS, V44, P864, DOI 10.1136/medethics-2018-104941; Jongsma KR, 2015, MONASH BIOETH REV, V33, P167, DOI 10.1007/s40592-015-0034-y; Kang W. C., 2023, arXivpreprint, P1, DOI [10.48550/arXiv.2305.06474, DOI 10.48550/ARXIV.2305.06474]; Kenton Z, 2021, Arxiv, DOI arXiv:2103.14659; Kim J., 2023, arXiv preprint, P1, DOI [10.48550/arXiv.2305.09620, DOI 10.48550/ARXIV.2305.09620]; Kim SYH, 2014, J MED PHILOS, V39, P187, DOI 10.1093/jmp/jhu010; Kirk H. R., 2023, arXiv preprint, P1, DOI [10.48550/arXiv.2303.05453, DOI 10.48550/ARXIV.2303.05453]; Lamanna Camillo, 2018, AMA J Ethics, V20, pE902, DOI 10.1001/amajethics.2018.902; Lewis J., 2023, Encyclopedia of the philosophy of law and social philosophy, DOI [10.1007/978-94-007-6730-0_1053-1, DOI 10.1007/978-94-007-6730-0_1053-1]; Lindemann H, 2014, J MED PHILOS, V39, P161, DOI 10.1093/jmp/jhu003; Mainz JT, 2023, J MED ETHICS, V49, P221, DOI 10.1136/jme-2022-108427; Mann SP, 2023, AM J BIOETHICS, V23, P28, DOI 10.1080/15265161.2023.2233356; O'Neil C, 2022, J MED ETHICS, V48, P315, DOI 10.1136/medethics-2022-108288; Perry JE, 2005, ANN INTERN MED, V143, P744, DOI 10.7326/0003-4819-143-10-200511150-00012; Rid A, 2014, J MED PHILOS, V39, P130, DOI 10.1093/jmp/jhu006; Rid A, 2014, J MED PHILOS, V39, P104, DOI 10.1093/jmp/jhu001; Ryan M, 2004, BMJ-BRIT MED J, V328, P360, DOI 10.1136/bmj.328.7436.360; Sacchi L, 2015, ARTIF INTELL MED, V65, P19, DOI 10.1016/j.artmed.2014.10.004; Savulescu Julian, 2015, Beyond Artificial Intelligence, P79, DOI [DOI 10.1007/978-3-319-09668-16, 10.1007/978-3-319-09668-1_6, DOI 10.1007/978-3-319-09668-1_6]; Schwartz SM, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00031; Schwitzgebel E, 2023, Arxiv, DOI arXiv:2302.01339; Senthilnathan I., Working paper; Shalowitz DI, 2007, PLOS MED, V4, P423, DOI 10.1371/journal.pmed.0040035; Shalowitz DI, 2006, ARCH INTERN MED, V166, P493, DOI 10.1001/archinte.166.5.493; Sharadin NP, 2018, J MED ETHICS, V44, P857, DOI 10.1136/medethics-2017-104509; Silveira M., 2022, Advance Care Planning and Advance Directives; Sinnott-Armstrong W, 2021, J PRACT ETHICS, V9, DOI 10.3998/jpe.1175; Smucker WD, 2000, MED DECIS MAKING, V20, P271, DOI 10.1177/0272989X0002000303; Stocking CB, 2006, NEUROLOGY, V66, P1361, DOI 10.1212/01.wnl.0000216424.66098.55; Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129; Toomey J., 2023, arXiv; Tooming U, 2023, ROUT STUD CONTEMP PH, P17, DOI 10.4324/9781003310945-3; van Kinschot CMJ, 2021, EUR J ENDOCRINOL, V184, P803, DOI 10.1530/EJE-20-1490; Wasserman D, 2023, J MED ETHICS, V49, P580, DOI 10.1136/jme-2022-108707; Wendler D, 2016, J MED ETHICS, V42, P235, DOI 10.1136/medethics-2015-103001; Wu LF, 2023, FOUND TRENDS MACH LE, V16, P119, DOI 10.1561/2200000096	67	2	2	2	2	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1526-5161	1536-0075		AM J BIOETHICS	Am. J. Bioeth.	2023 DEC 16	2023										10.1080/15265161.2023.2296402	http://dx.doi.org/10.1080/15265161.2023.2296402		DEC 2023	14	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	FD9W2	38226965	hybrid			2024-07-03	WOS:001143951700001
C	Beermann, J; Benfer, R; Both, M; Müller, J; Diedrich, C		Dorksen, H; Scanzio, S; Jasperneite, J; Wisniewski, L; Man, KF; Sauter, T; Seno, L; Trsek, H; Vyatkin, V		Beermann, Jo; Benfer, Rebekka; Both, Maximilian; Mueller, Jochen; Diedrich, Christian			Comparison of different natural language processing models to achieve semantic interoperability of heterogeneous asset administration shells	2023 IEEE 21ST INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, INDIN	IEEE International Conference on Industrial Informatics INDIN		English	Proceedings Paper	IEEE 21st International Conference on Industrial Informatics (INDIN)	JUL 17-20, 2023	Lemgo, GERMANY	IEEE, INIT THOWL, Fraunhofer IOSB INA, IEEE Ind Elect Soc		semantic interoperability; natural language processing; Industrie 4.0		Self-organizing systems represent the next level of building automation and make it possible to reduce the manual engineering effort of automation systems. For self-organizing systems to be able to interact interoperable, the system components must be mapped by uniform digital twins and described in a semantically interoperable manner. Semantic interoperability is implemented in the current research approach of Industrie 4.0 through homogeneous semantics. However, given the large number of different manufacturers of technical components, agreement on uniform semantics seems unlikely. This paper presents a method that extends the Industrie 4.0 approach to heterogeneous semantics. Semantic interoperability is realized through the automated mapping of heterogeneous vocabularies to target semantics. Models from the artificial intelligence sub-field natural language processing are used for automated mapping. In this paper, existing models of natural language processing are compared with each other in terms of their mapping accuracy. A dataset based on the ECLASS standard is being developed as a basis for the comparison. This dataset is also being used to create new models that are fine-tuned to the target vocabulary. The results show that the mapping accuracy of existing approaches improves through fine-tuning by an average of 7.5% up to 93%. In addition to the improvement through fine-tuning, this work analyses the influence of the model size on the mapping accuracy by using large language models. Moreover, it examines the integration of structured knowledge in the form of knowledge graphs.	[Beermann, Jo; Benfer, Rebekka; Both, Maximilian; Mueller, Jochen] TH Koln, Fac Proc Engn Energy & Mech Syst, Cologne, Germany; [Diedrich, Christian] Otto von Guericke Univ, Inst Automat Technol, Magdeburg, Germany	Otto von Guericke University	Beermann, J (corresponding author), TH Koln, Fac Proc Engn Energy & Mech Syst, Cologne, Germany.	jo_rasmus.beermann@th-koeln.de; rebekka.benfer@th-koeln.de; maximilian_alexander.both@th-koeln.de; jochen.mueller@th-koeln.de; christian.diedrich@ovgu.de						Beermann J., 2023, ECLASS dataset-copus part, DOI [10.57967/hf/0409, DOI 10.57967/HF/0409]; Beermann J., 2023, gart-labor/all-mpnetbase-v2-eclass, DOI [10.57967/hf/0412, DOI 10.57967/HF/0412]; Beermann J., 2023, gart-labor/paraphraseMiniLM-L6-v2-eclass, DOI [10.57967/hf/0413, DOI 10.57967/HF/0413]; Beermann J., 2023, ECLASS dataset-query part, DOI [10.57967/hf/0410, DOI 10.57967/HF/0410]; Beermann J., 2023, gart-labor/engdistilBERT-se-eclass, DOI [10.57967/hf/0411, DOI 10.57967/HF/0411]; Benfer R., 2023, AUT 2023 VDI VERL; Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901; Both M., 2022, CLIMA 2022 C MAY 14, DOI [10.34641/clima.2022.144, DOI 10.34641/CLIMA.2022.144]; Both M., 2019, 4 INT ROT EQ C SEP; Both M, 2021, AT-AUTOM, V69, P940, DOI 10.1515/auto-2021-0050; Brick Consortium Inc., BRICK. A uniform metadata schema for buildings; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cartus M., 2022, CLIMA, P1, DOI [10.34641/clima.2022.143, DOI 10.34641/CLIMA.2022.143]; Clark K., 2020, ICLR C 2020 MAR 23; Delvin J., 2018, BERT: Pre-training of deep bidirectional transformers for language understanding; ECLASS, ECLASS-Standard for master data and semantics for digitalization.; Federal Ministry for Economic Affairs and Energy, 2019, Position Paper. Interoperability-Our vision for Industrie 4.0: Interoperable communication between machines within networked digital ecosystems; Federal Ministry for Economic Affairs and Energy, 2020, Submodel Templates of the Asset Administration Shell: ZVEI Digital Nameplate for industrial equipment; Federal Ministry for Economic Affairs and Energy, 2020, Details Of the Administration Shell. Part 1-The exchange of information between partners in the value chain of Industrie 4.0; Federal Ministry for Economic Affairs and Energy, 2019, 2030 Vision for Industrie 4.0. Shaping Digital Ecosystems Globally.; Industrial Digital Twin Association, 2022, Digital Nameplate for Industrial Equipment; International Electronical Commission, Common data dictionary (CDD); International Electrotechnical Commission, 2019, IEC Whitepaper; InterOpera, InterOpera-Home.; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Liu Pengfei, 2021, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing; Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070; McCrae JP., LINKED OPEN DATA CLO; Muller J, 2007, Automation of the engineering of communication-capable plant components in plant-related asset management in the process industry; Nogueira R., 2020, Document ranking with a pretrained sequence-tosequence model; Plattform Industrie 4.0, Industrial Digital Twin Association; Project Haystack, An Open-Source initiative to streamline working with IoT Data.; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae Jack W., 2022, SCALING LANGUAGE MOD; Raffel C, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer; Reimers N, SentenceTransformer Ranking; Reimers N., 2022, Sentence transformer: all-MiniLM-L6-v2; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Sanh Victor., 2021, Multi- task prompted training enables zero-shot task gener- alization.; Sanh Victor, 2019, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Standardization Council Industrie 4.0, 2022, Progress Report Standardization Progress I4.0; Sun T., 2020, P 28 INT C COMP LING, P3660, DOI [DOI 10.18653/V1/2020.COLING-MAIN.327, DOI 10.18653/V1/2020.COLING-MAIN.327,URL]; Vaswani A, 2017, ADV NEUR IN, V30; VDI Society for Measurement and Automation Technology/Platform Industrie 4.0, 2020, VDI/VDE 2193; VDI Society for Measurement and Automation Technology/Platform Industrie 4.0, 2019, VDI-Statusreport Industrie 4.0 Begriffe/Terms 2019; Xian Yongqin., 2017, Zero-shot learning - a comprehensive evaluation of the good, the bad and the ugly	47	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1935-4576		978-1-6654-9313-0	IEEE INTL CONF IND I			2023										10.1109/INDIN51400.2023.10218154	http://dx.doi.org/10.1109/INDIN51400.2023.10218154			6	Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BV7GC					2024-07-03	WOS:001066089800097
J	Kaarre, J; Feldt, R; Keeling, LE; Dadoo, S; Zsidai, B; Hughes, JD; Samuelsson, K; Musahl, V				Kaarre, Janina; Feldt, Robert; Keeling, Laura E.; Dadoo, Sahil; Zsidai, Balint; Hughes, Jonathan D.; Samuelsson, Kristian; Musahl, Volker			Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information	KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY			English	Article						Large language models; ChatGPT; Anterior cruciate ligament; ACL; Artificial intelligence; Correctness		PurposeTo investigate the potential use of large language models (LLMs) in orthopaedics by presenting queries pertinent to anterior cruciate ligament (ACL) surgery to generative pre-trained transformer (ChatGPT, specifically using its GPT-4 model of March 14th 2023). Additionally, this study aimed to evaluate the depth of the LLM's knowledge and investigate its adaptability to different user groups. It was hypothesized that the ChatGPT would be able to adapt to different target groups due to its strong language understanding and processing capabilities.MethodsChatGPT was presented with 20 questions and response was requested for two distinct target audiences: patients and non-orthopaedic medical doctors. Two board-certified orthopaedic sports medicine surgeons and two expert orthopaedic sports medicine surgeons independently evaluated the responses generated by ChatGPT. Mean correctness, completeness, and adaptability to the target audiences (patients and non-orthopaedic medical doctors) were determined. A three-point response scale facilitated nuanced assessment.ResultsChatGPT exhibited fair accuracy, with average correctness scores of 1.69 and 1.66 (on a scale from 0, incorrect, 1, partially correct, to 2, correct) for patients and medical doctors, respectively. Three of the 20 questions (15.0%) were deemed incorrect by any of the four orthopaedic sports medicine surgeon assessors. Moreover, overall completeness was calculated to be 1.51 and 1.64 for patients and medical doctors, respectively, while overall adaptiveness was determined to be 1.75 and 1.73 for patients and doctors, respectively.ConclusionOverall, ChatGPT was successful in generating correct responses in approximately 65% of the cases related to ACL surgery. The findings of this study imply that LLMs offer potential as a supplementary tool for acquiring orthopaedic knowledge. However, although ChatGPT can provide guidance and effectively adapt to diverse target audiences, it cannot supplant the expertise of orthopaedic sports medicine surgeons in diagnostic and treatment planning endeavours due to its limited understanding of orthopaedic domains and its potential for erroneous responses.	[Kaarre, Janina; Keeling, Laura E.; Dadoo, Sahil; Hughes, Jonathan D.; Musahl, Volker] Univ Pittsburgh, UPMC Freddie Fu Sports Med Ctr, Dept Orthopaed Surg, Pittsburgh, PA 15260 USA; [Kaarre, Janina; Zsidai, Balint; Samuelsson, Kristian] Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Orthopaed, Goteborgsvagen 31, S-43180 Molndal, Sweden; [Feldt, Robert] Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden; [Samuelsson, Kristian] Sahlgrens Univ Hosp, Dept Orthopaed, Molndal, Sweden	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Gothenburg; Chalmers University of Technology; Sahlgrenska University Hospital	Kaarre, J (corresponding author), Univ Pittsburgh, UPMC Freddie Fu Sports Med Ctr, Dept Orthopaed Surg, Pittsburgh, PA 15260 USA.; Kaarre, J (corresponding author), Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Orthopaed, Goteborgsvagen 31, S-43180 Molndal, Sweden.	janina.kaarre@gu.se; robert.feldt@chalmers.se; keelingle@upmc.edu; dadoos@upmc.edu; balint.zsidai@gu.se; hughesjd3@upmc.edu; kristian.samuelsson@gu.se; musahlv@upmc.edu	Hughes, Jonathan D./AAL-3860-2020	Hughes, Jonathan D./0000-0002-1298-7514; Kaarre, Janina/0000-0003-2559-8283	University of Gothenburg	University of Gothenburg	Open access funding provided by University of Gothenburg. No funding was received for this study	Ali R., 2023, MEDRXIV, DOI 10.1101/2023.03.25.23287743; [Anonymous], 2023, GPT-4; [Anonymous], 2023, WHO calls for safe and ethical AI for health; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beltrami Eric J, 2024, J Am Acad Dermatol, V90, P879, DOI 10.1016/j.jaad.2023.02.052; Borji A., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2302.03494; Bubeck S., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12712; Diermeier T, 2020, ORTHOP J SPORTS MED, V8, DOI 10.1177/2325967120931097; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Liu P., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.13586; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; OpenAI, 2023, Introducing chatgpt; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Sherman SL, 2021, J ISAKOS, V6, P322, DOI 10.1136/jisakos-2020-000567; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; White J., 2023, ARXIV, DOI [DOI 10.48550/ARXIV.2302.11382, 10.48550/arxiv.2302.11382]; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	24	13	13	12	20	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0942-2056	1433-7347		KNEE SURG SPORT TR A	Knee Surg. Sports Traumatol. Arthrosc.	NOV	2023	31	11					5190	5198		10.1007/s00167-023-07529-2	http://dx.doi.org/10.1007/s00167-023-07529-2		AUG 2023	9	Orthopedics; Sport Sciences; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Sport Sciences; Surgery	FP2F4	37553552	Green Published, hybrid			2024-07-03	WOS:001044338600003
J	Ferreira, R; Canesche, M; Jamieson, P; Neto, OPV; Nacif, JAM				Ferreira, Ricardo; Canesche, Michael; Jamieson, Peter; Neto, Omar P. Vilela; Nacif, Jose A. M.			Examples and tutorials on using Google Colab and Gradio to create online interactive student-learning modules	COMPUTER APPLICATIONS IN ENGINEERING EDUCATION			English	Article; Early Access						digital systems; distance learning; interactive; virtual laboratory; web-based	FRAMEWORK; HARDWARE	This work provides online learning modules and instructions on how educators can leverage these technologies to help students learn in a personalized online environment. In particular, we focus on Google Colab, and the features provided by the Gradio Python library to provide interactivity within these modules. The contributions of this work include: (1) Development of a teaching framework using Gradio/Colab that offers automated grading and feedback for both educators and students; (2) Design of a versatile proposal, accommodating beginners with a straightforward interface while addressing the needs of advanced learners; (3) Creation of a comprehensive set of examples tailored for teaching digital logic subjects, with adaptability for application in various computer science areas. (4) A classification of these example learning modules in terms of their learning level for the students; (5) A novel client-server approach based on Colab/Gradio, allowing teachers to manage the main notebook efficiently while providing a lightweight and reliable interface for students. The goal of this work is to further expose educators to the remarkable capabilities that cloud computing brings to online supplemental education, noting that large language models such as ChatGPT complement this work, in that chatbots will be able to guide students in these dynamic simulations.	[Ferreira, Ricardo; Nacif, Jose A. M.] Univ Fed Vicosa, Dept Informat, Vicosa, Brazil; [Canesche, Michael; Neto, Omar P. Vilela] Univ Fed Minas Gerais, Comp Sci Dept, Belo Horizonte, Brazil; [Jamieson, Peter] Miami Univ, Dept Elect & Comp Engn, Oxford, OH USA; [Ferreira, Ricardo] Univ Fed Vicosa, Comp Sci Dept DPI, Av PH Rolfs, BR-36570900 Vicosa, Brazil	Universidade Federal de Vicosa; Universidade Federal de Minas Gerais; University System of Ohio; Miami University; Universidade Federal de Vicosa	Ferreira, R (corresponding author), Univ Fed Vicosa, Comp Sci Dept DPI, Av PH Rolfs, BR-36570900 Vicosa, Brazil.	ricardo@ufv.br	Ferreira, Ricardo/IVU-8552-2023; Canesche, Michael/ITU-8513-2023; Nacif, Jose Augusto M./O-7552-2016	Canesche, Michael/0000-0001-7882-0787; Ferreira, Ricardo/0000-0003-1802-7829; Nacif, Jose Augusto M./0000-0003-0703-5620	Fundacao de Amparo a Pesquisa doEstado de Minas Gerais; Coordernacao deAperfeicoamento de Pessoal de NivelSuperior-Brasil (CAPES) [001]; FAPEMIG; CNPq; UFV	Fundacao de Amparo a Pesquisa doEstado de Minas Gerais(Fundacao de Amparo a Pesquisa do Estado de Minas Gerais (FAPEMIG)); Coordernacao deAperfeicoamento de Pessoal de NivelSuperior-Brasil (CAPES); FAPEMIG(Fundacao de Amparo a Pesquisa do Estado de Minas Gerais (FAPEMIG)); CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); UFV	Fundacao de Amparo a Pesquisa doEstado de Minas Gerais; Coordernacao deAperfeicoamento de Pessoal de NivelSuperior-Brasil (CAPES),Grant/Award Number: Code 001;FAPEMIG, CNPq, and UFV	Abid A, 2019, Arxiv, DOI [arXiv:1906.02569, DOI 10.48550/ARXIV.1906.02569]; Al-Gahmi A, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P425, DOI 10.1145/3478431.3499379; Barba L. A., 2019, Teaching and learning with Jupyter, P1; Beg M, 2021, COMPUT SCI ENG, V23, P36, DOI 10.1109/MCSE.2021.3052101; Berkel K., 2021, Multi-processor system-on-chip 2: Applications, P157; Bloom BS., 2001, TAXONOMY LEARNING TE, DOI DOI 10.7771/1541-5015.1355; Brayton R, 2010, LECT NOTES COMPUT SC, V6174, P24, DOI 10.1007/978-3-642-14295-6_5; Canesche M., 2023, Colab and Gradio examples; Canesche M., 2021, 2021 IEEE International Symposium on Circuits and Systems (ISCAS), P1; Chattopadhyay S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376729; Chen C, 2020, J COMPUT ASSIST LEAR, V36, P581, DOI 10.1111/jcal.12427; Davies A, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1008326; De smet Ruben, 2022, 2022 IEEE 9th International Conference on e-Learning in Industrial Electronics (ICELIE), P1, DOI 10.1109/ICELIE55228.2022.9969419; Despujol I, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00359-1; Doulos, 2021, EDA playground; Drake C., 2015, P 14 PYTH SCI C SCIP, P26; Elhayany Mohamed, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P275, DOI 10.1145/3491140.3529537; Elhayany M, 2023, PROCEEDINGS OF THE TENTH ACM CONFERENCE ON LEARNING @ SCALE, L@S 2023, P321, DOI 10.1145/3573051.3596180; Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483; Ferreira Roberta R., 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286515; Freeman J, 2019, COMMUN ACM, V62, P78, DOI 10.1145/3333613; González-Carrillo CD, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132112050; Horn M., 2022, P 2022 CHI C HUM FAC, P1; Idowu S, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3543847; Jamieson P, 2016, PROC FRONT EDUC CONF; Jiang SN, 2020, IEEE MICRO, V40, P58, DOI 10.1109/MM.2020.2997638; Kang D, 2021, POLYM COMPOSITE, V42, P2171, DOI 10.1002/pc.25966; Kim B, 2021, J STAT DATA SCI EDUC, V29, pS103, DOI 10.1080/10691898.2020.1860726; Lau S, 2020, S VIS LANG HUM CEN C, DOI 10.1109/vl/hcc50065.2020.9127201; Lee I, 2022, AAAI CONF ARTIF INTE, P12783; Li JG, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102886; Lowe-Power J, 2020, Arxiv, DOI arXiv:2007.03152; Materzok M., 2019, Proceedings of the 8th Computer Science Education Research Conference, P110; Menke J, 2023, ARCH PHARM, V356, DOI 10.1002/ardp.202200628; Nagar S., 2018, Introduction to Python for Engineers and Scientists, P31; Naps T.L., 2002, ACM SIGCSE Bulletin, Volume, V35, P131, DOI DOI 10.1145/960568.782998; Nethercote N, 2007, ACM SIGPLAN NOTICES, V42, P89, DOI 10.1145/1273442.1250746; Passe F., 2020, 2020 IEEE INT S CIRC, P1; Pérez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53; Petrie C, 2023, COMPUT SCI EDUC, DOI 10.1080/08993408.2023.2240657; R. R, 2013, Puentedura. SAMR and TPCK: Intro to advanced practice, V12; Reparaz C, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106423; Roessler P, 2019, 2019 27TH AUSTROCHIP WORKSHOP ON MICROELECTRONICS (AUSTROCHIP), P87, DOI 10.1109/Austrochip.2019.00027; Rossant C., 2013, Learning IPython for interactive computing and data visualization; Rule A, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007007; Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606; Shalan M, 2017, P IEEE INT C MICRO, P39, DOI 10.1109/MSE.2017.7945081; Smith David H., 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P914, DOI 10.1145/3408877.3432361; Spertus E., 2021, WCAE'21: Proceedings of the 2021 Workshop on Computer Architecture Education, P1; Vega L, 2020, IEEE MICRO, V40, P103, DOI 10.1109/MM.2020.2997610; Wang W, 2023, LIBR HI TECH, V41, P432, DOI 10.1108/LHT-06-2022-0306; Wiggins G., 1998, Understanding by design; Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851	53	0	0	12	12	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1061-3773	1099-0542		COMPUT APPL ENG EDUC	Comput. Appl. Eng. Educ.	2024 FEB 29	2024										10.1002/cae.22729	http://dx.doi.org/10.1002/cae.22729		FEB 2024	17	Computer Science, Interdisciplinary Applications; Education, Scientific Disciplines; Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Education & Educational Research; Engineering	JU1D8					2024-07-03	WOS:001175576000001
J	Li, X; Lan, L; Lahza, H; Yang, SW; Wang, SH; Yang, WJ; Liu, HZ; Zhang, YD				Li, Xiang; Lan, Long; Lahza, Husam; Yang, Shaowu; Wang, Shuihua; Yang, Wenjing; Liu, Hengzhu; Zhang, Yudong			EAFP-Med: An efficient adaptive feature processing module based on prompts for medical image detection	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Adaptive Detection; Cross-Domain; Feature Processing; Medical Images; Prompt		The rapid proliferation of medical imaging technologies presents a significant challenge for cross-domain adaptive image detection, as lesion representations can vary dramatically across technologies. To address this issue, we draw inspiration from large language models to propose EAFP-Med, an efficient adaptive feature processing module based on prompts for medical image detection. EAFP-Med incorporates a prompt-driven dynamic parameter update mechanism, empowering it to extract cross-domain multi-scale lesion features from medical images of diverse modalities adaptively. This exceptional flexibility liberates it from the constraints of any particular imaging technique, fostering great adaptability. Furthermore, EAFP-Med can also serve as a feature preprocessing module connected to any model front-end to enhance the lesion features in input images. Moreover, we propose a novel adaptive disease detection model named EAFP-Med ST, which utilizes the Swin Transformer V2 - Tiny (SwinV2-T) as its backbone and connects it to EAFP-Med. We have compared our method to nine state-of-the-art methods. Experimental results show that the overall accuracy of EAFP Med ST on chest Xray, brain magnetic resonance imaging, and skin image datasets is 98.47 %, 97.60 %, and 99.06 %, respectively, superior to all the compared state-of-the-art methods.	[Li, Xiang; Lan, Long; Yang, Shaowu; Yang, Wenjing; Liu, Hengzhu] Natl Univ Def Technol, Coll Comp Sci & Technol, Changsha 410073, Peoples R China; [Li, Xiang; Lan, Long; Yang, Shaowu; Yang, Wenjing] Natl Univ Def Technol, Inst Quantum Informat, Changsha 410073, Peoples R China; [Li, Xiang; Lan, Long; Yang, Shaowu; Yang, Wenjing] Natl Univ Def Technol, Coll Comp Sci & Technol, State Key Lab High Performance Comp, Changsha 410073, Peoples R China; [Lahza, Husam; Yang, Wenjing; Liu, Hengzhu; Zhang, Yudong] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Technol, Jeddah 21589, Saudi Arabia; [Wang, Shuihua] Xian Jiaotong Liverpool Univ, Dept Biol Sci, Suzhou 215123, Jiangsu, Peoples R China; [Zhang, Yudong] Univ Leicester, Sch Comp & Math Sci, Leicester LE1 7RH, England; [Zhang, Yudong] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China; [Wang, Shuihua] Univ Liverpool, Dept Math Sci, Liverpool L69 3BX, England	National University of Defense Technology - China; National University of Defense Technology - China; National University of Defense Technology - China; King Abdulaziz University; Xi'an Jiaotong-Liverpool University; University of Leicester; Southeast University - China; University of Liverpool	Yang, WJ; Liu, HZ; Zhang, YD (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Technol, Jeddah 21589, Saudi Arabia.	lixiang@nudt.edu.cn; long.lan@nudt.edu.cn; hlahza@kau.edu.sa; shaowu.yang@nudt.edu.cn; shuihua.wang@xjtlu.edu.cn; wenjing.yang@nudt.edu.cn; hengzhuliu@nudt.edu.cn; yudongzhang@seu.edu.cn	Zhang, Yudong/I-7633-2013; Wang, shuihua/G-7326-2016; li, xiang/HZL-9423-2023	Wang, shuihua/0000-0003-4713-2791; li, xiang/0000-0001-5804-8734; Yang, Wenjing/0000-0002-6997-0406; Lahza, Husam/0000-0002-5109-7856; Lan, Long/0000-0002-4238-8985	China Scholarship Council; National Natural Science Foundation of China [91948303-1, 611803375, 61803375, 12002380, 62106278, 62101575, 61906210]; National Key R&D Program of China [2021ZD0140301]; Postgraduate Scientific Research Innovation Project of Hunan Province [QL20210018]	China Scholarship Council(China Scholarship Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; Postgraduate Scientific Research Innovation Project of Hunan Province	This work is supported by the China Scholarship Council; the National Natural Science Foundation of China: 91948303-1; the National Key R & D Program of China (2021ZD0140301); the National Natural Science Foundation of China: 611803375, No. 61803375, No. 12002380, No. 62106278, No. 62101575, No. 61906210; the Postgraduate Scientific Research Innovation Project of Hunan Province:<EM><STRONG> </STRONG></EM>QL20210018.	Akkilic AN, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121257; Alsattar HA, 2024, EXPERT SYST APPL, V236, DOI 10.1016/j.eswa.2023.121300; [Anonymous], 2012, Dementia cases set to triple by 2050 but still largely ignored; Asif S, 2023, NEURAL NETWORKS, V167, P342, DOI 10.1016/j.neunet.2023.08.035; Asraf A., 2021, COVID19 Pneumonia Normal Chest Xray PA Dataset; Bala D., Monkeypox Skin Images Dataset (MSID); Bi XA, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101950; Cai MY, 2017, IEEE T SYST MAN CY-S, V47, P2444, DOI 10.1109/TSMC.2016.2531647; Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097; Han B, 2016, IFAC PAPERSONLINE, V49, P1442, DOI 10.1016/j.ifacol.2016.07.774; Hu ZT, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107304; Huo XZ, 2024, BIOMED SIGNAL PROCES, V87, DOI 10.1016/j.bspc.2023.105534; Lakhan A, 2023, APPL SOFT COMPUT, V147, DOI 10.1016/j.asoc.2023.110804; Li YW, 2023, PROC CVPR IEEE, P18278, DOI 10.1109/CVPR52729.2023.01753; Modi S, 2011, IEEE-ASME T MECH, V16, P874, DOI 10.1109/TMECH.2011.2161094; Seethi VDR, 2024, EXPERT SYST APPL, V236, DOI 10.1016/j.eswa.2023.121226; Sharma R, 2023, IEEE J BIOMED HEALTH, V27, P4995, DOI 10.1109/JBHI.2022.3215533; Thieme AH, 2023, NAT MED, V29, P738, DOI 10.1038/s41591-023-02225-7; Uraninjo, 2022, Augmented Alzheimer MRI Dataset V2; WHO, 2023, 2022 23 MPOX MONKEYP; WHO, 2017, Dementia: Number of people affected to triple in next 30 years; who, Coronavirus Disease (COVID-19) Pandemic: Overview; World Health Organization, 2019, WHO reveals leading causes of death and disability worldwide: 2000-2019; World Health Organization (WHO), 2023, Mpox (monkeypox); Zhang T, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120472; Zhang WJ, 2010, ENTERP INF SYST-UK, V4, P99, DOI 10.1080/17517571003763380; Zhang WJ, 2018, WORLD AUTOMAT CONG, P232, DOI 10.23919/WAC.2018.8430387	27	0	0	10	10	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	AUG 1	2024	247								123334	10.1016/j.eswa.2024.123334	http://dx.doi.org/10.1016/j.eswa.2024.123334		JAN 2024	12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	JE7F1		Green Submitted, hybrid			2024-07-03	WOS:001171545900001
C	McGuire, ES; Tomuro, N		Dondio, P; Brennan, A; DeRosa, F; Bellotti, F; Rocha, M; Schonbohm, A; Koskinen, A		McGuire, Erik S.; Tomuro, Noriko			What Can You Do with a Sword? Gender Biases in Text Game Affordances	GAMES AND LEARNING ALLIANCE, GALA 2023	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Conference on Games and Learning Alliance (GALA)	NOV 29-DEC 01, 2023	Dublin, IRELAND	Serious Games Soc, Technol Univ Dublin, Sci Fdn Ireland Happy Maths Project, TU Dublin Sch Comp Sci, CAPTRS, Ctr Adv Preparedness & Threat Response Simulat		gender bias; generative ai; text games		Game mechanics can be viewed in terms of affordances: possible actions offered by the environment-depending on the agent (e.g., in a fantasy role-playing game, a sword can be wielded by a knight, but probably not by a dragon). Recently, text generated by large language models (LLMs) has been used to create open-ended text-based game content. However, LLMs have been shown to generate sexist text when trained on gender-biased data. If bias manifests in educational text game affordances it could harm goal achievement. We examine binary gender biases in LIGHT, an English-language persona-based dataset for researching language grounded in a fantasy adventure world, training LLMs on LIGHT and analyzing the diversity of affordances in quests. We find male characters have a more diverse space of affordances yet are less diverse in practice (e.g., mostly wielding a sword) in original and generated quests. To gauge impact on gameplay, we create games from LIGHT quests which can be played in the TextWorld research framework. Artificial agents trained only on male games significantly outperform female, suggesting an impact of affordance biases. These findings illustrate risks in AI- or data-driven generation of serious game content where gender is involved: overlooked biases in affordances can propagate, autonomously enforcing harmful, stereotypical behaviors.	[McGuire, Erik S.; Tomuro, Noriko] Depaul Univ, Chicago, IL 60604 USA	DePaul University	McGuire, ES (corresponding author), Depaul Univ, Chicago, IL 60604 USA.	emcguir8@depaul.edu; tomuro@cs.depaul.edu						Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Ammanabrolu P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8099; Ammanabrolu P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P807; Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli; Cote Marc-Alexandre, 2018, CGW IJCAI; Dinan Emily, 2020, P 2020 C EMP METH NA; Fernandez Galeote D., 2022, PROC 25 INT ACAD MIN, P256, DOI 10.1145/3569219.3569414; Fulda N, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1039; Garner J, 2022, IRAL-INT REV APPL LI, V60, P909, DOI 10.1515/iral-2019-0169; Glaveanu VP, 2020, REV GEN PSYCHOL, V24, P335, DOI 10.1177/1089268020961763; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; McClelland T, 2023, PHILOS PHENOMEN RES, V107, P501, DOI 10.1111/phpr.12929; Nguyen CT, 2019, PHILOS REV, V128, P423, DOI 10.1215/00318108-7697863; Protopsaltis A, 2010, INT J EMERG TECHNOL, V5, P4, DOI 10.3991/ijet.v5s3.1495; Ulmer D., 2022, arXiv; Urbanek J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P673; Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101; Xinogalos S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136563; Yao SY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8736	19	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-49064-4; 978-3-031-49065-1	LECT NOTES COMPUT SC			2024	14475						451	456		10.1007/978-3-031-49065-1_48	http://dx.doi.org/10.1007/978-3-031-49065-1_48			6	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW4IB					2024-07-03	WOS:001148163700048
J	Meynard-Piganeau, B; Fabbri, C; Weigt, M; Pagnani, A; Feinauer, C				Meynard-Piganeau, Barthelemy; Fabbri, Caterina; Weigt, Martin; Pagnani, Andrea; Feinauer, Christoph			Generating interacting protein sequences using domain-to-domain translation	BIOINFORMATICS			English	Article							RESIDUE	Motivation: Being able to artificially design novel proteins of desired function is pivotal in many biological and biomedical applications. Generative statistical modeling has recently emerged as a new paradigm for designing amino acid sequences, including in particular models and embedding methods borrowed from natural language processing (NLP). However, most approaches target single proteins or protein domains, and do not take into account any functional specificity or interaction with the context. To extend beyond current computational strategies, we develop a method for generating protein domain sequences intended to interact with another protein domain. Using data from natural multidomain proteins, we cast the problem as a translation problem from a given interactor domain to the new domain to be generated, i.e. we generate artificial partner sequences conditional on an input sequence. We also show in an example that the same procedure can be applied to interactions between distinct proteins.Results: Evaluating our model's quality using diverse metrics, in part related to distinct biological questions, we show that our method outperforms state-of-the-art shallow autoregressive strategies. We also explore the possibility of fine-tuning pretrained large language models for the same task and of using Alphafold 2 for assessing the quality of sampled sequences.Availability and implementationData and code on .	[Meynard-Piganeau, Barthelemy; Weigt, Martin] Sorbonne Univ, Inst Biol Paris Seine, Computat & Quantitat Biol, CNRS,LCQB UMR 7238, F-75005 Paris, France; [Meynard-Piganeau, Barthelemy; Fabbri, Caterina; Feinauer, Christoph] Bocconi Univ, Dept Comp Sci, I-20100 Milan, Italy; [Pagnani, Andrea] Politecn Torino, Duca Abruzzi 24, I-10129 Turin, Italy; [Pagnani, Andrea] Italian Inst Genom Med, Str Prov 142, I-10060 Candiolo, Italy	Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS); Bocconi University; Polytechnic University of Turin	Meynard-Piganeau, B (corresponding author), Sorbonne Univ, Inst Biol Paris Seine, Computat & Quantitat Biol, CNRS,LCQB UMR 7238, F-75005 Paris, France.	barthelemy.meynard@polytechnique.edu	Weigt, Martin/L-8851-2016; Pagnani, Andrea/J-2363-2015	Weigt, Martin/0000-0002-0492-3684; Pagnani, Andrea/0000-0002-6509-0807; Meynard-Piganeau, Barthelemy/0000-0002-7153-8735				Alberts BJ, 2002, Molecular Biology of the Cell, V4th; Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1; Anishchenko I, 2017, P NATL ACAD SCI USA, V114, P9122, DOI 10.1073/pnas.1702664114; [Anonymous], 1998, Biological sequence analysis: probabilistic models of proteins and nucleic acids; Armenteros Jose Juan Almagro, 2020, bioRxiv; Bitbol AF, 2016, P NATL ACAD SCI USA, V113, P12180, DOI 10.1073/pnas.1606762113; Burley SK, 2017, METHODS MOL BIOL, V1606, P627, DOI 10.1007/978-1-4939-7000-1_26; Cheng RR, 2014, P NATL ACAD SCI USA, V111, pE563, DOI 10.1073/pnas.1323734111; Clavero-Alvarez A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32986-y; Ekeberg M, 2013, PHYS REV E, V87, DOI 10.1103/PhysRevE.87.012707; Figliuzzi M, 2018, MOL BIOL EVOL, V35, P1018, DOI 10.1093/molbev/msy007; Finn RD, 2011, NUCLEIC ACIDS RES, V39, pW29, DOI 10.1093/nar/gkr367; Grechishnikova D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79682-4; Gueudré T, 2016, P NATL ACAD SCI USA, V113, P12186, DOI 10.1073/pnas.1607570113; Hawkins-Hooker A, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008736; Hesslow D, 2022, Arxiv, DOI arXiv:2205.05789; Hsu C., 2022, bioRxiv; Jang E, 2017, Arxiv, DOI [arXiv:1611.01144, DOI 10.48550/ARXIV.1611.01144]; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Lin Z., 2022, BIORXIV, V379, P2022; Madani A, 2020, Arxiv, DOI [arXiv:2004.03497, 10.48550/arXiv.2004.03497]; Marchand A, 2022, CURR OPIN STRUC BIOL, V74, DOI 10.1016/j.sbi.2022.102370; McPartlon M., 2022, bioRxiv; Meier J, 2021, ADV NEUR IN, V34; Muscat M, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007621; Nambiar A, 2020, ACM-BCB 2020 - 11TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, DOI 10.1145/3388440.3412467; Rao R, 2021, PR MACH LEARN RES, V139; Reimer JM, 2019, SCIENCE, V366, P706, DOI 10.1126/science.aaw4388; Repecka D, 2021, NAT MACH INTELL, V3, P324, DOI 10.1038/s42256-021-00310-5; Riesselman AJ, 2018, NAT METHODS, V15, P816, DOI 10.1038/s41592-018-0138-4; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Russ WP, 2020, SCIENCE, V369, P440, DOI 10.1126/science.aba3304; Shin JE, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22732-w; Szurmant H, 2018, CURR OPIN STRUC BIOL, V50, P26, DOI 10.1016/j.sbi.2017.10.014; Trinquier J, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25756-4; Tubiana J, 2019, ELIFE, V8, DOI 10.7554/eLife.39397; Vaswani A, 2017, ADV NEUR IN, V30; Wu ZC, 2021, CURR OPIN CHEM BIOL, V65, P18, DOI 10.1016/j.cbpa.2021.04.004; Wu Z, 2020, ACS SYNTH BIOL, V9, P2154, DOI 10.1021/acssynbio.0c00219; Zhang H., 2021, P 35 INT C NEUR INF, V34, P14252; Zhou XG, 2022, NAT COMPUT SCI, V2, P265, DOI 10.1038/s43588-022-00232-1	42	0	0	1	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803	1367-4811		BIOINFORMATICS	Bioinformatics	JUL 1	2023	39	7							btad401	10.1093/bioinformatics/btad401	http://dx.doi.org/10.1093/bioinformatics/btad401			10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	M1JR8	37399105	gold, Green Published			2024-07-03	WOS:001027790700004
C	Joshi, B; Liu, ZY; Ramnath, S; Chan, A; Tong, ZW; Nie, SL; Wang, QF; Choi, YJ; Ren, X		Rogers, A; Boyd-Graber, J; Okazaki, N		Joshi, Brihi; Liu, Ziyi; Ramnath, Sahana; Chan, Aaron; Tong, Zhewei; Nie, Shaoliang; Wang, Qifan; Choi, Yejin; Ren, Xiang			Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond a certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory, and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales, or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging. We show that, by estimating a rationale's helpfulness in answering similar unseen instances, we can measure its human utility to a better extent. We also translate this finding into an automated score, GEN- U, that we propose, which can help improve LMs' ability to generate rationales with better human utility, while maintaining most of its task performance. Lastly, we release all code and collected data with this project.(1)	[Joshi, Brihi; Liu, Ziyi; Ramnath, Sahana; Chan, Aaron; Ren, Xiang] Univ Southern Calif, Los Angeles, CA 90007 USA; [Tong, Zhewei] Tsinghua Univ, Beijing, Peoples R China; [Nie, Shaoliang; Wang, Qifan] Meta AI, New York, NY USA; [Choi, Yejin; Ren, Xiang] Allen Inst Artificial Intelligence, Seattle, WA USA; [Choi, Yejin] Univ Washington, Seattle, WA USA	University of Southern California; Tsinghua University; University of Washington; University of Washington Seattle	Joshi, B (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	brihijos@usc.edu; zliu2803@usc.edu; sramnath@usc.edu; chanaaro@usc.edu; tzw19@mails.tsinghua.edu.cn; snie@meta.com; wqfcr@meta.com; yejin@cs.washington.edu; xiangren@usc.edu			Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA) [201919051600007, 2022-22072200006]; Defense Advanced Research Projects Activity (DARPA) [HR00112220046]; NSF [IIS 2048211]; USC INK Research Lab	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA); Defense Advanced Research Projects Activity (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NSF(National Science Foundation (NSF)); USC INK Research Lab	This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via Contract Nos. 201919051600007 and 2022-22072200006, Defense Advanced Research Projects Activity (DARPA) No. HR00112220046, NSF IIS 2048211, and gift awards from Google, Amazon, JP Morgan, and Sony. We would like to thank all of our collaborators at USC NLP Group, USC INK Research Lab, Meta AI and AI2, specially Swabha Swayamdipta and Ameya Godbole for their constructive feedback on this work.	Aggarwal S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3050; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863; Camburu Oana-Maria, 2018, E SNLI NATURAL LANGU; Carton Samuel, 2020, P INT AAAI C WEB SOC, V14, P95, DOI DOI 10.1609/ICWSM.V14I1.7282; Chan Aaron, 2022, ARXIV220700779; Chen Hanjie, 2022, ARXIV221004982; Chen LL, 2021, ADV NEUR IN, V34; Chen Valerie, 2022, USE CASE GROUNDED SI; Chu Eric, 2020, ARE VISUAL EXPLANATI; Doshi-Velez F., 2017, RIGOROUS SCI INTERPR, DOI 10.48550/arXiv.1702.08608; Ehsan U, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P81, DOI 10.1145/3278721.3278736; Feng Shi, 2018, WHAT CAN A2 DO ME EV; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Golovneva Olga, 2022, Roscoe: A suite of metrics for scoring step-by-step reasoning; González AV, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1103; Hase Peter, 2020, ARXIV201004119; Hummel JE, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00867; Idahl Maximilian, 2021, P 1 WORKSH TRUSTW NA, P68, DOI 10.18653/v1/2021.trustnlp-1.8; Janner M., 2021, ADV NEURAL INFORM PR, V34, P1273; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Keil FC, 2006, ANNU REV PSYCHOL, V57, P227, DOI 10.1146/annurev.psych.57.102904.190100; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Khashabi Daniel, 2022, ARXIV220212359; Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Lamm Matthew, 2020, Qed: A framework and dataset for explanations in question answering; Lampinen Andrew K., 2022, CAN LANGUAGE MODELS; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Alisa, 2022, WANLI WORKER COLLABO; Lombrozo T, 2006, TRENDS COGN SCI, V10, P464, DOI 10.1016/j.tics.2006.08.004; Lombrozo T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00700; Lu X., 2022, Advances in Neural Information Processing Systems (NeurIPS); Marasovic Ana, 2022, FINDINGS ASS COMPUTA, P410, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.31; Mihaylov Todor, 2018, C EMP METH NAT LANG; Nangia Nikita, 2019, HUMAN VS MUPPET CONS; Narang Sharan, 2020, WT5 TRAINING TEXT TE; Paranjape B, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4179; Patterson R, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00559; Raffel C, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer; Raffel C, 2020, J MACH LEARN RES, V21; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Saunders William, 2022, SELF CRITIQUING MODE; Schuff Hendrik, 2022, ARXIV221007126; Sun Jiao, 2022, INVESTIGATING BENEFI; Talmor Alon, 2021, 35 C NEUR INF PROC S; Tan Chenhao, 2021, DIVERSITY LIMITS HUM; Wang Ben, 2021, Gpt-j-6b: A 6 billion parameter autoregressive language model; Wang XR, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P318, DOI 10.1145/3397481.3450650; Wei Jason, 2022, Chain of thought prompting elicits reasoning in large language models; Wiegreffe S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P632; Wiegreffe S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10266; Wiegreffe Sarah, 2021, TEACH ME EXPLAIN REV; Wiegreffe Sarah, 2020, ARXIV201012762; You WC, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON EFFICIENT BENCHMARKING IN NLP (NLP POWER 2022), P11; Yuan Ann, 2021, SYNTHBIO CASE STUDY; Zelikman Eric, 2022, STAR BOOTSTRAPPING R	56	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							7103	7128						26	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086806012
J	Lim, B; Cevik, J; Seth, I; Sofiadellis, F; Ross, RJ; Rozen, WM; Cuomo, R				Lim, Bryan; Cevik, Jevan; Seth, Ishith; Sofiadellis, Foti; Ross, Richard J.; Rozen, Warren M.; Cuomo, Roberto			Evaluating Artificial Intelligence's Role in Teaching the Reporting and Interpretation of Computed Tomographic Angiography for Preoperative Planning of the Deep Inferior Epigastric Artery Perforator Flap	JPRAS OPEN			English	Article						CT Angiogram; CTA; Large Language Models; ChatGPT; BARD; Bing	BREAST RECONSTRUCTION; EFFICIENCY	Background: Artificial intelligence (AI) has the potential to transform preoperative planning for breast reconstruction by enhancing the efficiency, accuracy, and reliability of radiology reporting through automatic interpretation and perforator identification. Large language models (LLMs) have recently advanced significantly in medicine. This study aimed to evaluate the proficiency of contemporary LLMs in interpreting computed tomography angiography (CTA) scans for deep inferior epigastric perforator (DIEP) flap preoperative planning. Methods: Four prominent LLMs, ChatGPT-4, BARD, Perplexity, and BingAI, answered six questions on CTA scan reporting. A panel of expert plastic surgeons with extensive experience in breast reconstruction assessed the responses using a Likert scale. In contrast, the responses' readability was evaluated using the Flesch Reading Ease score, the Flesch-Kincaid Grade level, and the Coleman-Liau Index. The DISCERN score was utilized to determine the responses' suitability. Statistical significance was identified through a t -test, and P -values < 0.05 were considered significant. Results: BingAI provided the most accurate and useful responses to prompts, followed by Perplexity, ChatGPT, and then BARD. BingAI had the greatest Flesh Reading Ease (34.7 +/- 5.5) and DISCERN (60.5 +/- 3.9) scores. Perplexity had higher Flesch-Kincaid Grade level (20.5 +/- 2.7) and Coleman-Liau Index (17.8 +/- 1.6) scores than other LLMs. Conclusion: LLMs exhibit limitations in their capabilities of reporting CTA for preoperative planning of breast reconstruction, yet the rapid advancements in technology hint at a promising future. AI stands poised to enhance the education of CTA reporting and aid preoperative planning. In the future, AI technology could provide automatic CTA interpretation, enhancing the efficiency, accuracy, and reliability of CTA reports. (c) 2024 The Author(s). Published by Elsevier Ltd on behalf of British Association of Plastic, Reconstructive and Aesthetic Surgeons. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )	[Lim, Bryan; Cevik, Jevan; Seth, Ishith; Sofiadellis, Foti; Ross, Richard J.; Rozen, Warren M.] Peninsula Hlth, Dept Plast Surg, Melbourne, Vic 3199, Australia; [Lim, Bryan; Cevik, Jevan; Seth, Ishith; Rozen, Warren M.] Monash Univ, Fac Med, Melbourne, Vic 3004, Australia; [Cuomo, Roberto] Univ Siena, Dept Med Surg & Neurosci, Plast Surg Unit, I-53100 Siena, Italy; [Cuomo, Roberto] Univ Siena, Dept Med Surg & Neurosci, I-53100 Siena, Italy	Peninsula Health; Monash University; University of Siena; University of Siena	Cuomo, R (corresponding author), Univ Siena, Dept Med Surg & Neurosci, Plast Surg Unit, I-53100 Siena, Italy.	robertocuomo@outlook.com	Cuomo, Roberto/AFI-8757-2022; Seth, Ishith/IXX-0725-2023	Cuomo, Roberto/0000-0002-8396-095X; Seth, Ishith/0000-0001-5444-8925; Cevik, Jevan/0000-0003-1115-1763; Lim, Bryan/0009-0007-9647-5180; Rozen, Warren Matthew/0000-0002-4092-182X; , Richard/0009-0008-1068-3147				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Atkinson CJ, 2024, J CLIN MED, V13, DOI 10.3390/jcm13030900; Canizares O, 2015, ANN PLAS SURG, V75, P186, DOI 10.1097/SAP.0000000000000559; Casella D, 2023, MEDICINA-LITHUANIA, V59, DOI 10.3390/medicina59101703; Cevik J, 2023, ANZ J Surg.; Cina A, 2013, EUR RADIOL, V23, P2333, DOI 10.1007/s00330-013-2834-x; Civaner MM, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03852-3; Colakoglu S, 2022, J PLAST RECONSTR AES, V75, P45, DOI 10.1016/j.bjps.2021.05.050; Cuomo R, 2021, J CLIN MED, V10, DOI 10.3390/jcm10102082; Cuomo R, 2020, J INVEST SURG, V33, P673, DOI 10.1080/08941939.2018.1554731; Cuomo R, 2020, J INVEST SURG, V33, P189, DOI 10.1080/08941939.2018.1484199; Duong MT, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190389; Haddock NT, 2020, PLAST RECONSTR SURG, V146, P719, DOI 10.1097/PRS.0000000000007148; Hembd A, 2018, PLAST RECONSTR SURG, V142, P583, DOI 10.1097/PRS.0000000000004631; Johnson MB, 2000, CLIN RADIOL, V55, P912, DOI 10.1053/crad.2000.0518; Lim B, 2023, J CLIN MED, V12, DOI 10.3390/jcm12206524; Lin A, 2022, LANCET DIGIT HEALTH, V4, DOI 10.1016/S2589-7500(22)00022-X; Mavioso C, 2020, BREAST, V50, P19, DOI 10.1016/j.breast.2020.01.001; Mijuskovic B, 2019, J PLAST RECONSTR AES, V72, P1632, DOI 10.1016/j.bjps.2019.06.008; O'Connor EF, 2016, GLAND SURG, V5, P93, DOI 10.3978/j.issn.2227-684X.2015.05.17; Rozen WM, 2008, PLAST RECONSTR SURG, V121, P367, DOI 10.1097/01.prs.0000298313.28983.f4; Rozen WM, 2009, MICROSURG, V29, P119, DOI 10.1002/micr.20590; Rozen WM, 2010, J PLAST RECONSTR AES, V63, P289, DOI 10.1016/j.bjps.2008.10.007; Savage TR, 2021, ACAD MED, V96, P1229, DOI 10.1097/ACM.0000000000004183; Schaverien MV, 2011, ANN PLAS SURG, V67, P671, DOI 10.1097/SAP.0b013e3181fab9ea; Seah J, 2022, CARDIOVASC INTER RAD, V45, P283, DOI 10.1007/s00270-021-03044-4; Seth I, 2024, EUR J PLAST SURG, V47, DOI 10.1007/s00238-024-02162-9; Sisti A, 2021, AESTHET PLAST SURG, V45, P1078, DOI 10.1007/s00266-020-01989-4; Tejani AS, 2023, RADIOL-ARTIF INTELL, V5, DOI 10.1148/ryai.220084; Tolsgaard MG, 2023, MED TEACH, V45, P565, DOI 10.1080/0142159X.2023.2180340; Varoquaux G, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00592-y; Voglino C, 2021, OBES SURG, V31, P3715, DOI 10.1007/s11695-021-05486-8; Voglino C, 2020, J GASTROINTEST SURG, V24, P2722, DOI 10.1007/s11605-019-04482-9; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7	35	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-5878			JPRAS OPEN	JPRAS Open	JUN	2024	40						273	285		10.1016/j.jpra.2024.03.010	http://dx.doi.org/10.1016/j.jpra.2024.03.010			13	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	SV7F0	38708385	gold, Green Published			2024-07-03	WOS:001237282200001
J	Kim, S; Mollaei, P; Antony, A; Magar, R; Farimani, AB				Kim, Seongwon; Mollaei, Parisa; Antony, Akshay; Magar, Rishikesh; Barati Farimani, Amir			GPCR-BERT: Interpreting Sequential Design of G Protein-Coupled Receptors Using Protein Language Models	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							DRUG DISCOVERY; PREDICTION; TARGETS	With the rise of transformers and large language models (LLMs) in chemistry and biology, new avenues for the design and understanding of therapeutics have been opened up to the scientific community. Protein sequences can be modeled as language and can take advantage of recent advances in LLMs, specifically with the abundance of our access to the protein sequence data sets. In this letter, we developed the GPCR-BERT model for understanding the sequential design of G protein-coupled receptors (GPCRs). GPCRs are the target of over one-third of Food and Drug Administration-approved pharmaceuticals. However, there is a lack of comprehensive understanding regarding the relationship among amino acid sequence, ligand selectivity, and conformational motifs (such as NPxxY, CWxP, and E/DRY). By utilizing the pretrained protein model (Prot-Bert) and fine-tuning with prediction tasks of variations in the motifs, we were able to shed light on several relationships between residues in the binding pocket and some of the conserved motifs. To achieve this, we took advantage of attention weights and hidden states of the model that are interpreted to extract the extent of contributions of amino acids in dictating the type of masked ones. The fine-tuned models demonstrated high accuracy in predicting hidden residues within the motifs. In addition, the analysis of embedding was performed over 3D structures to elucidate the higher-order interactions within the conformations of the receptors.	[Kim, Seongwon] Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA; [Mollaei, Parisa; Antony, Akshay; Magar, Rishikesh; Barati Farimani, Amir] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA; [Barati Farimani, Amir] Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA; [Barati Farimani, Amir] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University	Farimani, AB (corresponding author), Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA.; Farimani, AB (corresponding author), Carnegie Mellon Univ, Dept Biomed Engn, Pittsburgh, PA 15213 USA.; Farimani, AB (corresponding author), Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA.	barati@cmu.edu	Farimani, Amir Barati/K-4601-2019; Barati Farimani, Amir/F-2356-2013	Barati Farimani, Amir/0000-0002-2952-8576; Magar, Rishikesh/0000-0001-6216-0518; Kim, Seongwon/0009-0007-7092-5497	Center for Machine Learning and Health, School of Computer Science, Carnegie Mellon University; Center for Machine Learning in Health; Carnegie Mellon University; Mechanical Engineering Department at CMU	Center for Machine Learning and Health, School of Computer Science, Carnegie Mellon University; Center for Machine Learning in Health; Carnegie Mellon University; Mechanical Engineering Department at CMU	This work is supported by the Center for Machine Learning in Health (CMLH) at Carnegie Mellon University and a start-up fund from the Mechanical Engineering Department at CMU.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ANFINSEN CB, 1973, SCIENCE, V181, P223, DOI 10.1126/science.181.4096.223; Ballesteros J. A., 1995, METHODS INNEUROSCIEN, V25, P366; Bengio Y, 2012, ABS12065538 CORR, P1; Berman H, 2003, NAT STRUCT BIOL, V10, P980, DOI 10.1038/nsb1203-980; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Branden C. I., 2012, Introduction to ProteinStructure; Bridle John S, 1990, Neurocomputing: Algorithms, architectures and applications, P227; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chou KC, 2001, PROTEINS, V43, P246, DOI 10.1002/prot.1035; Chou KC, 2011, J THEOR BIOL, V273, P236, DOI 10.1016/j.jtbi.2010.12.024; CREIGHTON TE, 1990, BIOCHEM J, V270, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Farimani AB, 2018, BIOPHYS J, V114, p62A; Fredriksson R, 2003, MOL PHARMACOL, V63, P1256, DOI 10.1124/mol.63.6.1256; Golding GB, 1998, MOL BIOL EVOL, V15, P355, DOI 10.1093/oxfordjournals.molbev.a025932; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodsell DS, 2020, PROTEIN SCI, V29, P52, DOI 10.1002/pro.3730; Guntuboina C, 2023, J PHYS CHEM LETT, V14, P10427, DOI 10.1021/acs.jpclett.3c02398; Hauser AS, 2017, NAT REV DRUG DISCOV, V16, P829, DOI 10.1038/nrd.2017.178; Hollingsworth SA, 2018, NEURON, V99, P1129, DOI 10.1016/j.neuron.2018.08.011; Horn F, 2003, NUCLEIC ACIDS RES, V31, P294, DOI 10.1093/nar/gkg103; Hu W., 2020, INT C LEARNING REPRE; Huang H, 2014, J MOL ENDOCRINOL, V53, P319, DOI 10.1530/JME-14-0184; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kingma D. P., 2015, INT C FORLEARNING RE; Kostenis E, 2005, CIRCULATION, V111, P1806, DOI 10.1161/01.CIR.0000160867.23556.7D; Kroeze WK, 2003, J CELL SCI, V116, P4867, DOI 10.1242/jcs.00902; Lagerström MC, 2008, NAT REV DRUG DISCOV, V7, P339, DOI 10.1038/nrd2518; Lappano R, 2011, NAT REV DRUG DISCOV, V10, P47, DOI 10.1038/nrd3320; Lesk A., 2010, INTRO PROTEINSCIENCE; Li HL, 2021, NUCLEIC ACIDS RES, V49, DOI 10.1093/nar/gkab829; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Milligan G, 2006, BRIT J PHARMACOL, V147, pS46, DOI 10.1038/sj.bjp.0706405; Mollaei P., 2023, BIORXIV, p2023.04.16.536913, DOI [10.1101/2023.04.16.536913, DOI 10.1101/2023.04.16.536913]; Mollaei P, 2023, J CHEM INF MODEL, V63, P2296, DOI 10.1021/acs.jcim.3c00032; Molnar C., 2020, INTERPRETABLE MACHIN; Nair V., 2010, P ICML, P807; Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565; Nussinov R, 2022, J PHYS CHEM B, DOI 10.1021/acs.jpcb.2c04346; Ofer D, 2021, COMPUT STRUCT BIOTEC, V19, P1750, DOI 10.1016/j.csbj.2021.03.022; Oliveira L, 1999, PROTEIN ENG, V12, P1087, DOI 10.1093/protein/12.12.1087; Olivella M, 2013, BMC STRUCT BIOL, V13, DOI 10.1186/1472-6807-13-3; Oprea TI, 2018, NAT REV DRUG DISCOV, V17, P317, DOI 10.1038/nrd.2018.14; Patthy L., 2009, PROTEIN EVOLUTION; Pierce KL, 2002, NAT REV MOL CELL BIO, V3, P639, DOI 10.1038/nrm908; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radivojac P, 2013, NAT METHODS, V10, P221, DOI [10.1038/NMETH.2340, 10.1038/nmeth.2340]; Rosenbaum DM, 2009, NATURE, V459, P356, DOI 10.1038/nature08144; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Sadowski MI, 2009, CURR OPIN STRUC BIOL, V19, P357, DOI 10.1016/j.sbi.2009.03.008; Schro'dinger L., 2020, PYMOL; Schwaller P, 2021, NAT MACH INTELL, V3, P144, DOI 10.1038/s42256-020-00284-w; Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576; Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7; Shukla A. K. G., 2016, PROTEIN COUPLEDRECEP; Smrcka AV, 2008, CELL MOL LIFE SCI, V65, P2191, DOI 10.1007/s00018-008-8006-5; Sriram K, 2018, MOL PHARMACOL, V93, P251, DOI 10.1124/mol.117.111062; STRADER CD, 1995, FASEB J, V9, P745, DOI 10.1096/fasebj.9.9.7601339; Suzek BE, 2015, BIOINFORMATICS, V31, P926, DOI 10.1093/bioinformatics/btu739; Tuncbag N, 2011, PHYS BIOL, V8, DOI 10.1088/1478-3975/8/3/035006; Tuteja N, 2009, PLANT SIGNAL BEHAV, V4, P942, DOI 10.4161/psb.4.10.9530; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Wess J, 1997, FASEB J, V11, P346, DOI 10.1096/fasebj.11.5.9141501; Wettschureck N, 2005, PHYSIOL REV, V85, P1159, DOI 10.1152/physrev.00003.2005; Wood TC, 1999, J MOL BIOL, V291, P977, DOI 10.1006/jmbi.1999.2972; Yadav P, 2022, COMPUT STRUCT BIOTEC, V20, P2564, DOI 10.1016/j.csbj.2022.05.016; Zhang QC, 2012, NATURE, V490, P556, DOI 10.1038/nature11503; Zhang R, 2012, ACTA PHARMACOL SIN, V33, P372, DOI 10.1038/aps.2011.173	71	0	0	1	1	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	FEB 10	2024	64	4					1134	1144		10.1021/acs.jcim.3c01706	http://dx.doi.org/10.1021/acs.jcim.3c01706		FEB 2024	11	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	IT8E9	38340054	Green Submitted, Green Published, hybrid			2024-07-03	WOS:001166423700001
C	Zakkas, P; Verberne, S; Zavrel, J		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Zakkas, Pavlos; Verberne, Suzan; Zavrel, Jakub			SumBlogger: Abstractive Summarization of Large Collections of Scientific Articles	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp				We propose a prompt-based pipeline for extreme summarization of large collections of scientific articles, which facilitates the consumption of scientific knowledge in high-volume fast-paced fields like AI. Although prompting of generative large language models (LLMs) has been applied to news summarization, its effectiveness in the scientific domain and in multi-document summarization is underexplored. We propose a three-step approach for summarizing a large collection of documents (e.g. hundreds or thousands of papers published in a conference). First, selecting representative papers per document cluster, second, performing single-document summarization (SDS) of the selected papers, and third, aggregating these in a multi-document summarization (MDS) step. Both the single-document summaries and the multi-document summaries are generated with an instruction-tuned LLM. The cluster summaries are used to generate a blog post summarizing a conference. We show that our SDS model achieves better results than strong fine-tuned models on the SciTLDR benchmark. Our two-step approach reaches the performance of state-of-the-art fine-tuned MDS models on the Multi-XScience benchmark. Through a small-scale user study, we find that, although a human-written blog post is clearly preferred over an automatically generated one, the users appreciate the good informativeness and factuality of our pipeline. Our findings demonstrate the potential use of generative LLMs as a way to digest large amounts of scientific papers and help researchers to stay up-to-date with rapidly evolving fields.	[Zakkas, Pavlos; Verberne, Suzan] Leiden Univ, Leiden, Netherlands; [Zakkas, Pavlos; Zavrel, Jakub] Zeta Alpha, Amsterdam, Netherlands	Leiden University - Excl LUMC; Leiden University	Zakkas, P (corresponding author), Leiden Univ, Leiden, Netherlands.; Zakkas, P (corresponding author), Zeta Alpha, Amsterdam, Netherlands.	zakkas@zeta-alpha.com; s.verberne@liacs.leidenuniv.nl; zavrel@zeta-alpha.com		Verberne, Suzan/0000-0002-9609-9505				Bai Y., 2022, 2204.05862; Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bertsch A., 2023, Unlimiformer: Long-range transformers with unlimited length input; Bosma M., 2023, Chain-of-thought prompting elicits reasoning in large language models; Brown T., 2020, NIPS, P1877; Cachola I., 2020, TLDR: Extreme summarization of scientific documents; Dong Q., 2023, A survey on in-context learning; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Fadaee M., 2020, A new neural search and insights platform for navigating and organizing AI research; Fu J., 2023, Gptscore: Evaluate as you desire; Goyal Tanya, 2022, News summarization and evaluation in the era of gpt-3; Graham Y., 2015, P 2015 C EMPIRICAL M, P128, DOI DOI 10.18653/V1/D15-1013; Guo M., 2022, Longt5: Efficient text-to-text transformer for long sequences; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kryscinski W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P540; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Li M., 2023, Towards summarizing multiple documents with hierarchical relationships; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu NF., 2023, LOST MIDDLE LANGUAGE; Liu S., 2022, P INT JOINT C ART IN, P4259; Liu Y., 2023, G-eval: Nlg evaluation using gpt-4 with better human alignment; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2890; Lu Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8068; Mao Y., 2022, Citesum: citation text-guided scientific extreme summarization and domain adaptation with limited supervision; Martins P.H., 2022, 8-former: Infinite memory transformer; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; OpenAI, 2023, GPT-4 Technical Report; Ore O., 1962, C PUBLICATIONS; Phang J., 2022, Investigating efficiently extending transformers for long input summarization; Raffel C, 2020, J MACH LEARN RES, V21; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Surita G., 2020, Can questions summarize a corpus? using question generation for characterizing covid-19 research; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thielmann A, 2023, Arxiv, DOI arXiv:2303.17324; Traag VA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41695-z; Trabelsi M., 2023, Absformer: Transformer-based model for unsupervised multi-document abstractive summarization; van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3; Vaswani A, 2017, ADV NEUR IN, V30; Wang Q, 2024, BENCHMARKING, V31, P466, DOI 10.1108/BIJ-04-2022-0257; Wei Jason, 2022, Finetuned language models are zero-shot learners; Whissell JS, 2011, INFORM RETRIEVAL, V14, P466, DOI 10.1007/s10791-011-9163-y; White J, 2023, A prompt pattern catalog to enhance prompt engineering with chatgpt; Wu J, 2021, ARCH MICROBIOL, V203, P2875, DOI [10.1007/s00203-021-02277-8, 10.1007/s10489-021-02330-5]; Xiao W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5245; Xu Y., 2023, Inheritsumm: a general, versatile and compact summarizer by distilling from GPT; You Y., 2023, A hierarchical encodingdecoding scheme for abstractive multi-document summarization; Zhang H., 2023, Summit: Iterative text summarization via chatgpt; Zhang Jingqing, 2020, Pegasus: Pre-training with extracted gap-sentences for abstractive summa; Zhang T., 2020, INT C LEARNING REPRE; Zhang XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2069; Zhang Z., 2022, Is neural topic modelling better than clustering? an empirical study on clustering with contextual embeddings for topics	53	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56026-2; 978-3-031-56027-9	LECT NOTES COMPUT SC			2024	14608						371	386		10.1007/978-3-031-56027-9_23	http://dx.doi.org/10.1007/978-3-031-56027-9_23			16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DX					2024-07-03	WOS:001211830500023
J	Crcek, N; Patekar, J				Crcek, Nikola; Patekar, Jakob			Writing with AI: University Students' Use of ChatGPT	JOURNAL OF LANGUAGE AND EDUCATION			English	Article						ChatGPT; academic honesty; academic integrity; plagiarism; ethics; artificial intelligence	ACADEMIC DISHONESTY; PREVALENCE; PERCEPTIONS; PLAGIARISM; ATTITUDES	Background: ChatGPT, a chatbot based on a large language model, captured global attention toward the end of 2022. With its potential to generate comprehensive texts of a variety of genres based on a string of straightforward prompts, it was soon perceived as a threat by many in various fields, including - and in particular - education. Schools across the world began banning its use as instructors started to receive suspiciously well-written essays and assignments from their students.Aim: This study aimed to investigate the prevalence of use of ChatGPT among university students for written assignments, explore the ways students utilize the tool, and examine students' perspectives on the ethical aspects of its use.Method: An online questionnaire was designed to collect data from 201 students from private and public universities in Croatia.Results: The results show that more than half of the participants use ChatGPT for written assignments, that most use it to generate ideas, while many use it to summarize, paraphrase, proofread, but also to write a part of the assignment for them. According to the participants, the most ethically acceptable use of ChatGPT is for generating ideas, while other uses are perceived by many as being unethical; this, however, has not prevented some students from engaging in behaviors they deem unethical.Conclusion: We conclude that universities and instructors need to take a decisive stand on artificial intelligence in education and provide clear guidelines to students regarding the ethical use of ChatGPT and emerging technologies.	[Crcek, Nikola; Patekar, Jakob] RIT Croatia, Zagreb, Croatia		Patekar, J (corresponding author), RIT Croatia, Zagreb, Croatia.	jakob.patekar@outlook.com	Patekar, Jakob/R-2335-2018	Patekar, Jakob/0000-0001-7371-0087				Anitha P., 2021, Journal of Studies in Social Sciences and Humanities, V7, P1; Bilic-Zulle L, 2005, CROAT MED J, V46, P126; Brimble M, 2005, AUST EDUC RES, V32, P19, DOI 10.1007/BF03216825; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; DAVIS SF, 1992, TEACH PSYCHOL, V19, P16, DOI 10.1207/s15328023top1901_3; Denisova-Schmidt E, 2020, Corruption in higher education: Global challenges and responses; Dukic D., 2022, Vjesnik bibliotekara Hrvatske, V65, P251, DOI [10.30754/vbh.65.1.927, DOI 10.30754/VBH.65.1.927]; Eaton S. E, 2022, Academic integrity in Canada: An enduring and essential challenge, DOI [DOI 10.1007/978-3-030-83255-1_8, 10.1007/978-3-030-83255-1, DOI 10.1007/978-3-030-83255-1]; Greitemeyer T, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e19909; Hill G, 2021, RES PRACT TECH ENHAN, V16, DOI 10.1186/s41039-021-00166-8; Ives B, 2017, HIGH EDUC, V74, P815, DOI 10.1007/s10734-016-0079-8; Jowarder MI., 2023, Indonesian Journal of Innovation and Applied Sciences (IJIAS), V3, P194, DOI [10.47540/ijias.v3i2.878, DOI 10.47540/IJIAS.V3I2.878]; Majstorovic D., 2016, Vjesnik bibliotekara Hrvatske, V59, P131; Malesky A, 2022, ETHICS BEHAV, V32, P12, DOI 10.1080/10508422.2020.1869006; Ngo T. T. A., 2023, Int. J. Emerg. Technol. Learn, V18, P4, DOI [DOI 10.3991/IJET.V18I17.39019, 10.3991/ijet.v18i14.39903, DOI 10.3991/IJET.V18I14.39903, 10.3991/ijet.v18i17.39019]; O'Rourke J, 2010, ETHICS BEHAV, V20, P47, DOI 10.1080/10508420903482616; Petrak O, 2014, CROAT J EDUC, V16, P81; Pupovac V, 2010, BIOCHEM MEDICA, V20, P307; Rigby D, 2015, J ECON BEHAV ORGAN, V111, P23, DOI 10.1016/j.jebo.2014.12.019; Singh H, 2023, EDUC SCI, V13, DOI 10.3390/educsci13090924; Stambuk M, 2015, CROAT J EDUC, V17, P259; Sweeney S, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100818; Taradi SK, 2012, J MED ETHICS, V38, P376, DOI 10.1136/medethics-2011-100015; Vaccino-Salvadore S, 2023, LANGUAGES-BASEL, V8, DOI 10.3390/languages8030191; Walker M, 2012, J ACAD ETHICS, V10, P27, DOI 10.1007/s10805-012-9150-y; Yilmaz R., 2023, Comput. Hum. Behav. Artif. Hum, V1, P100005, DOI [DOI 10.1016/J.CHBAH.2023.100005, https://doi.org/10.1016/j.chbah.2023.100005]	28	1	1	85	85	NATL RESEARCH UNIV HIGHER SCH ECONOMICS	MOSCOW	SHABOLOVKA, 26, MOSCOW, 119049, RUSSIA		2411-7390		J LANG EDUC	J. Lang. Educ.		2023	9	4					128	138		10.17323/jle.2023.17379	http://dx.doi.org/10.17323/jle.2023.17379			11	Education & Educational Research; Linguistics	Emerging Sources Citation Index (ESCI)	Education & Educational Research; Linguistics	EF3X8		Green Submitted, gold			2024-07-03	WOS:001137479500002
C	Zhou, DQ; Wang, K; Gu, JY; Peng, XY; Lian, DZ; Zhang, YF; You, Y; Feng, JS			IEEE	Zhou, Daquan; Wang, Kai; Gu, Jianyang; Peng, Xiangyu; Lian, Dongze; Zhang, Yifan; You, Yang; Feng, Jiashi			Dataset Quantization	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				State-of-the-art deep neural networks are trained with large amounts (millions or even billions) of data. The expensive computation and memory costs make it difficult to train them on limited hardware resources, especially for recent popular large language models (LLM) and computer vision models (CV). Recent popular dataset distillation methods are thus developed, aiming to reduce the number of training samples via synthesizing small-scale datasets via gradient matching. However, as the gradient calculation is coupled with the specific network architecture, the synthesized dataset is biased and performs poorly when used for training unseen architectures. To address these limitations, we present dataset quantization (DQ), a new framework to compress large-scale datasets into small subsets which can be used for training any neural network architectures. Extensive experiments demonstrate that DQ is able to generate condensed small datasets for training unseen network architectures with state-of-the-art compression ratios for lossless model training. To the best of our knowledge, DQ is the first method that can successfully distill large-scale datasets such as ImageNet- 1k with a stateof-the-art compression ratio. Notably, with 60% data from ImageNet and 20% data from Alpaca's instruction tuning data, the models can be trained with negligible or no performance drop for both vision tasks (including classification, semantic segmentation, and object detection) as well as language tasks (including instruction tuning tasks such as BBH and DROP).	[Zhou, Daquan; Feng, Jiashi] Bytedance Inc, Beijing, Peoples R China; [Wang, Kai; Gu, Jianyang; Peng, Xiangyu; Lian, Dongze; Zhang, Yifan; You, Yang] Natl Univ Singapore, Singapore, Singapore	National University of Singapore	Feng, JS (corresponding author), Bytedance Inc, Beijing, Peoples R China.; You, Y (corresponding author), Natl Univ Singapore, Singapore, Singapore.	daquan.zhou@u.nus.edu; kai.wang@comp.nus.edu.sg; gu_jianyang@zju.edu.cn; youy@comp.nus.edu.sg; jshfeng@bytedance.com		Gu, Jianyang/0000-0002-4060-7427	National Research Foundation, Singapore under its AI Singapore Programme AISG [AISG2-PhD-2021-08-008]; NUS startup grant (Presidential Young Professorship); ARCTIC grant; Alibaba grant; SMI grant; Singapore MOE Tier1 grant	National Research Foundation, Singapore under its AI Singapore Programme AISG; NUS startup grant (Presidential Young Professorship); ARCTIC grant; Alibaba grant; SMI grant; Singapore MOE Tier1 grant(Ministry of Education, Singapore)	This research is supported by the National Research Foundation, Singapore under its AI Singapore Programme AISG Award No: AISG2-PhD-2021-08-008). Yang You's research group is being sponsored by NUS startup grant (Presidential Young Professorship), Singapore MOE Tier1 grant, ByteDance grant, ARCTIC grant, SMI grant and Alibaba grant.	[Anonymous], 2020, ECCV; Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1708, DOI 10.1109/ICCV48922.2021.00175; Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254; Chen K, 2019, Arxiv, DOI [arXiv:1906.07155, DOI 10.48550/ARXIV.1906.07155]; Chen K, 2009, SIAM J COMPUT, V39, P923, DOI 10.1137/070699007; Chen Mark, 2021, ARXIV210703374; Coleman Cody, 2019, ARXIV190611829; Contributors M., 2020, MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark; Dean Jeff, 2021, GOOGLE BLOG; Devlin J., 2018, BERT PRE TRAINING DE; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Guo Chengcheng, 2022, ARXIV220408499; He K., 2016, 2016 IEEE C COMPUTER, P770, DOI 10.1109/CVPR.2016.90; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Huang L., 2020, ADV NEURAL INFORM PR, V33, P325; Iyer Rishabh, 2021, Algorithmic Learning Theory, P722; Killamsetty K, 2021, PR MACH LEARN RES, V139; Krizhevsky A., LEARNING MULTIPLE LA; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Yanqing, 2023, ICCV 2023, P1; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167; Mirzasoleiman Baharan, 2020, ICML; Qin ZH, 2023, Arxiv, DOI arXiv:2303.04947; Sener O., 2018, P 6 INT C LEARN REPR; Sinha Samarth, 2020, ICML; Soomro Khurram, 2012, CTR RES COMPUTER VIS, V2, P11; Srivastava Aarohi, 2022, arXiv; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Toneva M., 2019, INT C LEARN REPR, P1; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang K, 2023, Arxiv, DOI arXiv:2303.04707; Wang K, 2022, PROC CVPR IEEE, P12186, DOI 10.1109/CVPR52688.2022.01188; Wang TZ, 2020, Arxiv, DOI arXiv:1811.10959; Wang WH, 2022, Arxiv, DOI arXiv:2208.10442; Welling M., 2009, P 26 ANN INT C MACH, P1121; Wightman R., 2019, Pytorch image models; Zhao Bo, 2021, ICLR, V1, P3; Zhao Bo, 2021, INT C LEARN REPR; Zhao Bo, 2021, DATASET CONDENSATION; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0; Zhou Chunting, 2023, ARXIV230511206; Zhou DQ, 2022, PR MACH LEARN RES	44	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							17159	17170		10.1109/ICCV51070.2023.01578	http://dx.doi.org/10.1109/ICCV51070.2023.01578			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO					2024-07-03	WOS:001169500501073
C	Bender, M; Braun, T; Möller, R; Gehrke, M		Seipel, D; Steen, A		Bender, Magnus; Braun, Tanya; Moeller, Ralf; Gehrke, Marcel			LESS is More: LEan Computing for Selective Summaries	ADVANCES IN ARTIFICIAL INTELLIGENCE, KI 2023	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	46th German Conference on Artificial Intelligence (KI)	SEP 26-29, 2023	Berlin, GERMANY	German Informat Soc, German Sect Artificial Intelligence, Springer				An agent in pursuit of a task may work with a corpus containing text documents. To perform information retrieval on the corpus, the agent may need annotations-additional data associated with the documents. Subjective Content Descriptions (SCDs) provide additional location-specific data for text documents. SCDs can be estimated without additional supervision for any corpus of text documents. However, the estimated SCDs lack meaningful descriptions, i.e., labels consisting of short summaries. Labels are important to identify relevant SCDs and documents by the agent and its users. Therefore, this paper presents LESS, a LEan computing approach for Selective Summaries, which can be used as labels for SCDs. LESS uses word distributions of the SCDs to compute labels. In an evaluation, we compare the labels computed by LESS with labels computed by large language models and show that LESS computes similar labels but requires less data and computational power.	[Bender, Magnus; Moeller, Ralf; Gehrke, Marcel] Univ Lubeck, Inst Informat Syst, Ratzeburger Allee 160, D-23562 Lubeck, Germany; [Braun, Tanya] Univ Munster, Comp Sci Dept, Einstein Str 62, D-48155 Munster, Germany	University of Lubeck; University of Munster	Bender, M (corresponding author), Univ Lubeck, Inst Informat Syst, Ratzeburger Allee 160, D-23562 Lubeck, Germany.	bender@ifis.uni-luebeck.de; tanya.braun@uni-muenster.de; moeller@ifis.uni-luebeck.de; gehrke@ifis.uni-luebeck.de		Gehrke, Marcel/0000-0001-9056-7673; Braun, Tanya/0000-0003-0282-4284; Bender, Magnus/0000-0002-1854-225X	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy [EXC 2176, 390893796]	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy(German Research Foundation (DFG))	The research was partly funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy - EXC 2176 "Understanding Written Artefacts: Material, Interaction and Transmission in Manuscript Cultures", project no. 390893796. The research was conducted within the scope of the Centre for the Study of Manuscript Cultures (CSMC) at Universitat Hamburg.	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bender M, 2023, 2023 IEEE 17TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC, P266, DOI 10.1109/ICSC56153.2023.00052; Bender M, 2022, INT J SEMANT COMPUT, V16, P521, DOI 10.1142/S1793351X2240013X; Bhatia S., 2016, Proceedings of the 26th International Conference on Computational Linguistics (COLING 2016), P953; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Elnaggar A, 2018, PROCEEDINGS OF 2018 ARTIFICIAL INTELLIGENCE AND CLOUD COMPUTING CONFERENCE (AICCC 2018), P9, DOI 10.1145/3299819.3299844; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507; Gehman S, 2020, M ASS FOR COMPUTATIO; Hindle A, 2013, EMPIR SOFTW ENG, V18, P1125, DOI 10.1007/s10664-012-9209-9; Kuhr F, 2019, LECT NOTES ARTIF INT, V11919, P357, DOI 10.1007/978-3-030-35288-2_29; Lau Jey Han, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, P1536; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Moratanch N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P265; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vijayarani S., 2015, International Journal of Computer Science Communication Networks, V5, P7; Yang ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1865; Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P779	18	1	1	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-42607-0; 978-3-031-42608-7	LECT NOTES ARTIF INT			2023	14236						1	14		10.1007/978-3-031-42608-7_1	http://dx.doi.org/10.1007/978-3-031-42608-7_1			14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4UF					2024-07-03	WOS:001155305700001
C	Zheng, HY; Zhu, YT; Jiang, LY; Cho, K; Oermann, EK		Padmakumar, V; Vallejo, G; Fu, Y		Zheng, Hongyi; Zhu, Yixin Tracy; Jiang, Lavender Yao; Cho, Kyunghyun; Oermann, Eric Karl			Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-SRW 2023, VOL 4			English	Proceedings Paper	61st Annual Meeting of the Association-for-Computational-Linguistics / Student Research Workshop (ACL-SRW)	JUL 10-12, 2023	Toronto, CANADA	Assoc Computat Linguist, Google, NSF				Recent advances in large language models have led to renewed interest in natural language processing in healthcare using the free text of clinical notes. One distinguishing characteristic of clinical notes is their long time span over multiple long documents. The unique structure of clinical notes creates a new design choice: when the context length for a language model predictor is limited, which part of clinical notes should we choose as the input? Existing studies either choose the inputs with domain knowledge or simply truncate them. We propose a framework to analyze the sections with high predictive power. Using MIMIC-III, we show that: 1) predictive power distribution is different between nursing notes and discharge notes and 2) combining different types of notes could improve performance when the context length is large. Our findings suggest that a carefully selected sampling function could enable more efficient information extraction from clinical notes.	[Zheng, Hongyi; Zhu, Yixin Tracy; Jiang, Lavender Yao; Cho, Kyunghyun; Oermann, Eric Karl] NYU Ctr Data Sci, New York, NY 10011 USA; [Jiang, Lavender Yao; Oermann, Eric Karl] NYU Langone Hth, New York, NY USA		Zheng, HY (corresponding author), NYU Ctr Data Sci, New York, NY 10011 USA.	hz2212@nyu.edu; yz5880@nyu.edu; lyj2002@nyu.edu; kyunghyun.cho@nyu.edu; eric.oermann@nyulangone.org						Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Beltagy I., 2020, arXiv; Darabi S, 2020, IEEE J BIOMED HEALTH, V24, P3268, DOI 10.1109/JBHI.2020.2984931; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Johnson AEW, 2023, SCI DATA, V10, DOI 10.1038/s41597-022-01899-x; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Li Y., 2022, ARXIV; Schneeweiss S, 2001, AM J EPIDEMIOL, V154, P854, DOI 10.1093/aje/154.9.854; Thapa NB, 2022, 2022 AUSTRALIAN COMPUTER SCIENCE WEEK (ACSW 2022), P193, DOI 10.1145/3511616.3513115; Yang GC, 2022, Arxiv, DOI arXiv:2211.07047	10	0	0	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-69-2				2023							104	108						5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RW					2024-07-03	WOS:001181053700011
C	Chi, TC; Fan, TH; Ramadge, PJ; Rudnicky, AI		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Chi, Ta-Chung; Fan, Ting-Han; Ramadge, Peter J.; Rudnicky, Alexander I.			KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					Relative positional embeddings (RPE) have received considerable attention since RPEs effectively model the relative distance among tokens and enable length extrapolation. We propose KERPLE, a framework that generalizes relative position embedding for extrapolation by kernelizing positional differences. We achieve this goal using conditionally positive definite (CPD) kernels, a class of functions known for generalizing distance metrics. To maintain the inner product interpretation of self-attention, we show that a CPD kernel can be transformed into a PD kernel by adding a constant offset. This offset is implicitly absorbed in the Softmax normalization during self-attention. The diversity of CPD kernels allows us to derive various RPEs that enable length extrapolation in a principled way. Experiments demonstrate that the logarithmic variant achieves excellent extrapolation performance on three large language modeling datasets. Our implementation and pretrained checkpoints are released at https://github.com/chijames/KERPLE.git.	[Chi, Ta-Chung; Rudnicky, Alexander I.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Fan, Ting-Han; Ramadge, Peter J.] Princeton Univ, Princeton, NJ USA	Carnegie Mellon University; Princeton University	Chi, TC (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	tachungc@andrew.cmu.edu; tinghanf@princeton.edu; ramadge@princeton.edu; air@cs.cmu.edu			NSF MRI Award [1919452]	NSF MRI Award(National Science Foundation (NSF)NSF - Office of the Director (OD))	We thank the anonymous reviewers for their insightful feedback and suggestions. We thank Princeton Research Computing for the technical support on the Della and the Adroit clusters. The third author acknowledges support from NSF MRI Award: 1919452.	Berg C., 1984, HARMONIC ANAL SEMIGR; Black Sid, 2021, GPT NEOX LARGE SCALE; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen PC, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2974; Chen YW, 2021, ADV NEUR IN, V34; Choromanski K., 2021, INT C LEARN REPR ICL; Clark K., 2020, 8 INT C LEARN REPR I; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhillon I. S., 2004, 10 ACM INT C KNOWLED, P551, DOI DOI 10.1145/1014052.1014118; Dufter Philipp, 2022, COMPUT LINGUIST, P1; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Gehring J., 2017, P 34 INT C MACH LEAR, V70, P1243; He P, 2020, ICLR; Huang C.-Z. A., 2019, INT C LEARN REPR; Huang Zhiheng, 2020, FINDINGS ASS COMPUTA, P3327, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.298; Kalamkar Dhiraj., 2019, A study of bfloat16 for deep learning training; Katharopoulos A, 2020, PR MACH LEARN RES, V119; Ke Guolin, 2021, INT C LEARN REPR; Kiyono S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3309; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Leslie Christina, 2001, BIOCOMPUTING 2002, P564; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Likhomanenko T., 2021, P ADV NEUR INF PROC, V34, P16079; Liu Y., 2019, CoRR abs/1907.11692; Mika S., 1998, ADV NEURAL INFORM PR, V11; Peng Hao, 2021, INT C LEARN REPR; Press O., 2022, INT C LEARN REPR; Qin Z., 2022, INT C LEARN REPR; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rahimi A., 2007, ADV NEURAL INFORM PR, P1177, DOI DOI 10.5555/2981562.2981710; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300; Schoenberg IJ, 1938, T AM MATH SOC, V44, P522, DOI 10.2307/1989894; Scholkopf Bernhard, 2000, ADV NEURAL INFORM PR, V13; Shaw P., 2018, P 2018 C N AM CHAPT, P464, DOI DOI 10.48550/ARXIV.1803.02155; Shoeybi M., 2019, Megatron-lm: Training multibillion parameter language models using model parallelism; Su Jianlin, 2021, ARXIV210409864; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; Tsai YHH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4344; Vaswani A, 2017, ADV NEUR IN, V30; Wang XL, 2020, IEEE INT SYMP PARAL, P1328, DOI 10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00197; Wennberg U, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P130; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu CH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2059; Wu K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10013, DOI 10.1109/ICCV48922.2021.00988; Xiong YY, 2021, AAAI CONF ARTIF INTE, V35, P14138; Yang ZL, 2019, ADV NEUR IN, V32; Ying CX, 2021, ADV NEUR IN, V34	51	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259104023
C	Jaimovitch-López, G; Castellano-Falcón, D; Ferri, C; Hernández-Orallo, J		Ranzato, M; Beygelzimer, A; Dauphin, Y; Liang, PS; Vaughan, JW		Jaimovitch-Lopez, Gonzalo; Castellano-Falcon, David; Ferri, Cesar; Hernandez-Orallo, Jose			Think Big, Teach Small: Do Language Models Distil Occam's Razor?	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)	Advances in Neural Information Processing Systems		English	Proceedings Paper	35th Conference on Neural Information Processing Systems (NeurIPS)	DEC 06-14, 2021	ELECTR NETWORK					Large language models have recently shown a remarkable ability for few-shot learning, including patterns of algorithmic nature. However, it is still an open question to determine what kind of patterns these models can capture and how many examples they need in their prompts. We frame this question as a teaching problem with strong priors, and study whether language models can identify simple algorithmic concepts from small witness sets. In particular, we explore how several GPT architectures, program induction systems and humans perform in terms of the complexity of the concept and the number of additional examples, and how much their behaviour differs. This first joint analysis of language models and machine teaching can address key questions for artificial intelligence and machine learning, such as whether some strong priors, and Occam's razor in particular, can be distilled from data, making learning from a few examples possible.	[Jaimovitch-Lopez, Gonzalo; Castellano-Falcon, David; Ferri, Cesar; Hernandez-Orallo, Jose] Univ Politecn Valencia, VRAIN, Valencia, Spain; [Hernandez-Orallo, Jose] Univ Cambridge, Leverhulme Ctr Future Intelligence, Cambridge, England	Universitat Politecnica de Valencia; University of Cambridge	Jaimovitch-López, G (corresponding author), Univ Politecn Valencia, VRAIN, Valencia, Spain.	gonzalojaimovitch@gmail.com; dcastf01@gmail.com; cferri@dsic.upv.es; jorallo@upv.es	Hernandez-Orallo, Jose/H-9166-2015		EU (FEDER); MCIN/AEI [RTI2018-094403-B-C32]; ERDF A way of making Europe; Generalitat Valenciana [PROMETEO/2019/098, INNEST/2021/317]; European Union with the "Programa Operativo del Fondo Europeo de Desarrollo Regional (FEDER) de la Comunitat Valenciana"; EU [952215]; FLI [RFP2-152]; US DARPA [HR00112120007]	EU (FEDER)(European Union (EU)); MCIN/AEI; ERDF A way of making Europe; Generalitat Valenciana(Center for Forestry Research & Experimentation (CIEF)); European Union with the "Programa Operativo del Fondo Europeo de Desarrollo Regional (FEDER) de la Comunitat Valenciana"; EU(European Union (EU)); FLI; US DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	We thank OpenAI for giving us early access to GPT-3 through their API. We thank support by the EU (FEDER) and Spanish grant RTI2018-094403-B-C32 funded by MCIN/AEI/10.13039/501100011033 and by "ERDF A way of making Europe", Generalitat Valenciana under grant PROMETEO/2019/098 and INNEST/2021/317 (Project cofunded by the European Union with the "Programa Operativo del Fondo Europeo de Desarrollo Regional (FEDER) de la Comunitat Valenciana 2014-2020"), EU's Horizon 2020 research and innovation programme under grant agreement No. 952215 (TAILOR), the FLI under grant RFP2-152, and US DARPA HR00112120007 (RECoG-AI). We thank the anonymous reviewers for their comments and interaction during the discussion process. We are grateful to Dan Hendricks, Fernando Martinez-Plumed and Richard Evans for useful discussions, Carlos Monserrat for some assistance with the plots, Lidia Contreras-Ochando for her help with MagicHaskeller and Maria Jose Ramirez-Quintana for their help with questions about visualisation, inductive programming and Louise. We also thank Stephen Muggleton and Stassa Patsantzis for their help with Louise. Finally, we thank the participants who completed the questionnaire.	Ai L, 2021, MACH LEARN, V110, P695, DOI 10.1007/s10994-020-05941-0; [Anonymous], 2020, ECAI, DOI DOI 10.3233/FAIA200217; B hm C., 1964, ICC Bull, V3, P187; Basu S., 2013, AAAI; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cakmak M, 2014, ARTIF INTELL, V217, P198, DOI 10.1016/j.artint.2014.08.005; Chater N, 2003, TRENDS COGN SCI, V7, P19, DOI 10.1016/S1364-6613(02)00005-0; Degen J., 2020, PSYCHOL REV; Devlin J., 2019, CoRR, P4171; Dingle K, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03101-6; Dowe David L., 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P204, DOI 10.1007/978-3-642-22887-2_21; Garcia-Piqueras M, 2021, LECT NOTES ARTIF INT, V12975, P705, DOI 10.1007/978-3-030-86486-6_43; Goodman ND, 2016, TRENDS COGN SCI, V20, P818, DOI 10.1016/j.tics.2016.08.005; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282; Hendrycks D., 2021, ICLR; Hernandez-Orallo J., 2021, Human-Like Machine Intelligence, P171; Hupkes D, 2020, J ARTIF INTELL RES, V67, P757; Izacard Gautier, 2020, arXiv preprint arXiv:2007.01282; Katayama S., 2011, P AAIP 2011 4 INT WO, P63; Khan F., 2011, Advances in Neural Information Processing Systems, P1449; Kirstain Y., 2021, ARXIV211004374; Kuhl N., 2020, ARXIV201203661; Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11; Li M., 2008, An Introduction to Kolmogorov Complexity and Its Applications; Lu Yao, 2021, ARXIV210408786; Marcus Gary, 2020, TECHNOLOGY REV; Melo FS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2567; Patsantzis S, 2021, MACH LEARN, V110, P755, DOI 10.1007/s10994-020-05945-w; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Shah Harshay, 2020, ARXIV200607710; SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x; Sinha K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4506; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2; Sun WL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235502; Telle JA, 2019, MACH LEARN, V108, P1653, DOI 10.1007/s10994-019-05821-2; Toshniwal S., 2021, LEARNING CHESS BLIND; Valle-Perez G., 2019, ICLR; Vaswani A, 2017, ADV NEUR IN, V30; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; Webson Albert, 2021, ARXIV210901247; Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341; Xu Shusheng, 2020, EMNLP; Yang S. C.-H., 2017, WORKSH TEACH MACH RO; Yee WH, 2021, INT REV ADM SCI, V87, P256, DOI 10.1177/0020852321992110; Zhao Tony Z., 2021, arXiv:2102.09690; Zhu XJ, 2015, AAAI CONF ARTIF INTE, P4083	50	0	0	1	2	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258			ADV NEUR IN			2021														13	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU6IB					2024-07-03	WOS:000925183302035
J	Kumari, A; Kumari, A; Singh, A; Singh, SK; Juhi, A; Dhanvijay, AKD; Pinjar, MJ; Mondal, H				Kumari, Amita; Kumari, Anita; Singh, Amita; Singh, Sanjeet K.; Juhi, Ayesha; Dhanvijay, Anup Kumar D.; Pinjar, Mohammed Jaffer; Mondal, Himel			Large Language Models in Hematology Case Solving: A Comparative Study of ChatGPT-3.5, Google Bard, and Microsoft Bing	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						ai and robotics in healthcare; microsoft bing; google bard; chatgpt; pathology; hematology; hematologic diseases; natural language processing; search engine; pathologists		Background Large language models (LLMs), such as ChatGPT-3.5, Google Bard, and Microsoft Bing, have shown promising capabilities in various natural language processing (NLP) tasks. However, their performance and accuracy in solving domain-specific questions, particularly in the field of hematology, have not been extensively investigated. Objective This study aimed to explore the capability of LLMs, namely, ChatGPT-3.5, Google Bard, and Microsoft Bing (Precise), in solving hematology-related cases and comparing their performance. Methods This was a cross- sectional study conducted in the Department of Physiology and Pathology, All India Institute of Medical Sciences, Deoghar, Jharkhand, India. We curated a set of 50 cases on hematology covering a range of topics and complexities. The dataset included queries related to blood disorders, hematologic malignancies, laboratory test parameters, calculations, and treatment options. Each case and related question was prepared with a set of correct answers to compare with. We utilized ChatGPT-3.5, Google Bard Experiment, and Microsoft Bing (Precise) for question-answering tasks. The answers were checked by two physiologists and one pathologist. They rated the answers on a rating scale from one to five. The average score of the three models was compared by Friedman's test with Dunn's post-hoc test. The performance of the LLMs was compared with a median of 2.5 by a one-sample median test as the curriculum from which the questions were curated has a 50% pass grade. Results The scores among the three LLMs were significantly different (p-value < 0.0001) with the highest score by ChatGPT (3.15 +/- 1.19), followed by Bard (2.23 +/- 1.17) and Bing (1.98 +/- 1.01). The score of ChatGPT was significantly higher than 50% (p-value = 0.0004), Bard's score was close to 50% (p-value = 0.38), and Bing's score was significantly lower than the pass score (p-value = 0.0015). Conclusion The LLMs reveal significant differences in solving case vignettes in hematology. ChatGPT exhibited the highest score, followed by Google Bard and Microsoft Bing. The observed performance trends suggest that ChatGPT holds promising potential in the medical domain. However, none of the models was capable of answering all questions accurately. Further research and optimization of language models can offer valuable contributions to healthcare and medical education applications.	[Kumari, Amita; Kumari, Anita; Singh, Amita; Juhi, Ayesha; Dhanvijay, Anup Kumar D.; Pinjar, Mohammed Jaffer; Mondal, Himel] All India Inst Med Sci, Physiol, Deoghar, India; [Singh, Sanjeet K.] All India Inst Med Sci, Pathol, Deoghar, India		Mondal, H (corresponding author), All India Inst Med Sci, Physiol, Deoghar, India.	himelmkcg@gmail.com	Mondal, Himel/G-5111-2017; Yadav, Anita Kumari/P-2853-2015; Dhanvijay, Anupkumar/ADQ-8203-2022	Mondal, Himel/0000-0001-6950-5857; Yadav, Anita Kumari/0000-0001-5365-6271; Pinjar, Mohammed Jaffer/0000-0002-8130-3999; Kumari, Amita/0000-0002-8638-8661				Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40977; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Mondal H, 2023, INDIAN DERMATOL ONL, V14, P482, DOI 10.4103/idoj.idoj_72_23; Mondal H, 2022, INDIAN DERMATOL ONL, V13, P539, DOI 10.4103/idoj.idoj_605_21; Obstfeld AE, 2023, J APPL LAB MED, V8, P129, DOI 10.1093/jalm/jfac108; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Wang J, 2020, J MED INTERNET RES, V22, DOI 10.2196/16816	16	16	16	11	22	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 21	2023	15	8							e43861	10.7759/cureus.43861	http://dx.doi.org/10.7759/cureus.43861			7	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	R5TD7	37736448	gold, Green Published			2024-07-03	WOS:001064967100010
J	Edwards, CJ; Erstad, BL				Edwards, Christopher J.; Erstad, Brian L.			Evaluation of a Generative Language Model Tool for Writing Examination Questions	AMERICAN JOURNAL OF PHARMACEUTICAL EDUCATION			English	Article						Artificial intelligence; Chatbot; Laboratory tests; Examination questions; Pharmacy		Objective: To describe an evaluation of a generative language model tool to write examination questions for a new elective course focused on the interpretation of common clinical laboratory results being developed as an elective for students in a Bachelor of Science in Pharmaceutical Sciences program. Methods: A total of 100 multiple-choice questions were generated using a publicly available large language model for a course dealing with common laboratory values. Two independent evaluators with extensive training and experience in writing multiple-choice questions evaluated each question for appropriate formatting, clarity, correctness, relevancy, and difficulty. For each question, a final dichotomous judgment was assigned by each reviewer, usable as written or not usable written. Results: The major finding of this study was that a generative language model (ChatGPT 3.5) could generate multiple-choice questions for assessing common laboratory value information but only about half the questions (50% and 57% for the 2 evaluators) were deemed usable without modification. General agreement between evaluator comments was common (62% of comments) with more than 1 correct answer being the most common reason for commenting on the lack of usability (N = 27). Conclusion: The generally positive findings of this study suggest that the use of a generative language model tool for developing examination questions is deserving of further investigation.	[Edwards, Christopher J.; Erstad, Brian L.] Univ Arizona, Dept Pharm Practice & Sci, R Ken Coit Coll Pharm, Tucson, AZ 85721 USA	University of Arizona	Erstad, BL (corresponding author), Univ Arizona, Dept Pharm Practice & Sci, R Ken Coit Coll Pharm, Tucson, AZ 85721 USA.	erstad@pharmacy.arizona.edu						[Anonymous], NATL LIB MED; Busch F, 2023, MED SCI EDUC, V33, P1007, DOI 10.1007/s40670-023-01815-x; CLIA program and HIPAA privacy rule, 2014, patients' access to test reports.; Davis Kristina A, 2016, AMA J Ethics, V18, P826, DOI 10.1001/journalofethics.2016.18.8.pfor1-1608; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ghorashi N, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43271; Haladyna TM, 1989, Appl Meas Educ., V2, P37, DOI [DOI 10.1207/S15324818AME0201_3, 10.1207/s15324818ame0201_3]; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Jowsey T, 2023, TRENDS MOL MED, V29, P971, DOI 10.1016/j.molmed.2023.08.012; Steitz BD, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.3572; Zhang Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/18725	11	0	0	6	6	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0002-9459	1553-6467		AM J PHARM EDUC	Am. J. Pharm. Educ.	APR	2024	88	4							100684	10.1016/j.ajpe.2024.100684	http://dx.doi.org/10.1016/j.ajpe.2024.100684			3	Education, Scientific Disciplines; Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Pharmacology & Pharmacy	PV7J1	38479646	gold			2024-07-03	WOS:001216920200001
C	Erbacher, P; Falissard, L; Guigue, V; Soulier, L		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Erbacher, Pierre; Falissard, Louis; Guigue, Vincent; Soulier, Laure			Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book QA	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		budgeted search; hallucination		While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning techniques to train our model on a small amount of data. Our model directly provides answers for 78.2% of the known queries and opts to search for 77.2% of the unknown ones. This results in the API being utilized only 62% of the time.	[Erbacher, Pierre; Soulier, Laure] Sorbonne Univ, Paris, France; [Falissard, Louis] Sorbonne Ctr Artificial Intelligence, Paris, France; [Falissard, Louis] Univ Paris 08, St Denis, France; [Guigue, Vincent] Paris Saclay, AgroParisTech, Gif Sur Yvette, France	Sorbonne Universite; Universite Paris-VIII; AgroParisTech; Universite Paris Saclay	Erbacher, P (corresponding author), Sorbonne Univ, Paris, France.	pierre.erbacher@isir.upmc.fr; vincent.guigue@agroparistech.fr; laure.soulier@isir.upmc.fr			ANR JCJC project SESAMS [ANR18-CE23-0001]; Sorbonne Center for Artificial Intelligence	ANR JCJC project SESAMS(Agence Nationale de la Recherche (ANR)); Sorbonne Center for Artificial Intelligence	We would also like to thank the ANR JCJC project SESAMS (Project-ANR18-CE23-0001) and the Sorbonne Center for Artificial Intelligence for supporting this work.	Borgeaud S., 2022, INT C MACHINE LEARNI, P2206; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Curran Associates Inc., 2014, about us; Guerreiro NM, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1059; Guu K, 2020, PR MACH LEARN RES, V119; Hu E.J., 2022, INT C LEARN REPR; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Kadavath Saurav, 2022, Language models (mostly) know what they know; Kuhn L, 2023, Semantic uncertainty: linguistic invariances for uncertainty estimation in natural language generation; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086; Lee N, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1971; Lewis P., 2020, P 34 INT C NEUR INF; Manakul P., 2023, Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Nakano R, 2022, WebGPT: Browser-assisted question-answering with human feedback; Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46; Raffel C, 2020, J MACH LEARN RES, V21; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Schick Timo, 2023, Toolformer: Language models can teach themselves to use tools; Shuster K, 2022, Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage; Thoppilan Romal, 2022, Lamda: Language models for dialog applications; Wei J., 2022, Emergent abilities of large language models; Yuan W., 2021, Advances in Neural Information Processing Systems, P27263	28	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56062-0; 978-3-031-56063-7	LECT NOTES COMPUT SC			2024	14610						393	402		10.1007/978-3-031-56063-7_31	http://dx.doi.org/10.1007/978-3-031-56063-7_31			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DZ					2024-07-03	WOS:001211833300031
J	Deng, JW; Chen, Z; Sun, H; Zhang, ZX; Wu, JCZ; Nakagawa, S; Ren, FJ; Huang, ML				Deng, Jiawen; Chen, Zhuang; Sun, Hao; Zhang, Zhexin; Wu, Jincenzi; Nakagawa, Satoshi; Ren, Fuji; Huang, Minlie			Enhancing Offensive Language Detection with Data Augmentation and Knowledge Distillation	RESEARCH			English	Article								Offensive language detection has received important attention and plays a crucial role in promoting healthy communication on social platforms, as well as promoting the safe deployment of large language models. Training data is the basis for developing detectors; however, the available offense-related dataset in Chinese is severely limited in terms of data scale and coverage when compared to English resources. This significantly affects the accuracy of Chinese offensive language detectors in practical applications, especially when dealing with hard cases or out-of-domain samples. To alleviate the limitations posed by available datasets, we introduce AugCOLD (Augmented Chinese Offensive Language Dataset), a largescale unsupervised dataset containing 1 million samples gathered by data crawling and model generation. Furthermore, we employ a multiteacher distillation framework to enhance detection performance with unsupervised data. That is, we build multiple teachers with publicly accessible datasets and use them to assign soft labels to AugCOLD. The soft labels serve as a bridge for knowledge to be distilled from both AugCOLD and multiteacher to the student network, i.e., the final offensive detector. We conduct experiments on multiple public test sets and our well-designed hard tests, demonstrating that our proposal can effectively improve the generalization and robustness of the offensive language detector.	[Deng, Jiawen; Chen, Zhuang; Sun, Hao; Zhang, Zhexin; Wu, Jincenzi; Huang, Minlie] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, CoAI Grp,DCST,Inst Artificial Intelligence, Beijing 100084, Peoples R China; [Nakagawa, Satoshi] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138654, Japan; [Ren, Fuji] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China	Tsinghua University; University of Tokyo; University of Electronic Science & Technology of China	Deng, JW; Huang, ML (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, State Key Lab Intelligent Technol & Syst, CoAI Grp,DCST,Inst Artificial Intelligence, Beijing 100084, Peoples R China.	dengjw2016@gmail.com; aihuang@tsinghua.edu.cn			National Science Foundation for Distinguished Young Scholars [6212-5604]; NSFC [61936010, 61876096]; Guoqiang Institute of Tsinghua University; Tsinghua-Toyota Joint Research Fund;  [2019GQG1];  [2020GQG0005]	National Science Foundation for Distinguished Young Scholars(National Natural Science Foundation of China (NSFC)National Science Fund for Distinguished Young Scholars); NSFC(National Natural Science Foundation of China (NSFC)); Guoqiang Institute of Tsinghua University; Tsinghua-Toyota Joint Research Fund; ; 	k was supported by the National Science Foundation for Distinguished Young Scholars (with No. 6212-5604) and the NSFC projects (Key project with No. 61936010 and regular project with No. 61876096) . This work was also supported by the Guoqiang Institute of Tsinghua University, with Grant No. 2019GQG1 and 2020GQG0005, and sponsored by Tsinghua-Toyota Joint Research Fund.	Baheti A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4846; Chung YL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2819; Davidson T, 2017, Arxiv, DOI arXiv:1703.04009; Deng J., 2022, P 2022 C EMPIRICAL M, P11580; Deng JW, 2023, Arxiv, DOI [arXiv:2302.09270, DOI 10.48550/ARXIV.2302.09270, 10.48550/arXiv.2302.09270]; Dinan E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4537; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Gu YX, 2023, MACH INTELL RES, V20, P207, DOI 10.1007/s11633-022-1387-3; Hartvigsen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3309; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hu HT, 2020, PROC CVPR IEEE, P3120, DOI 10.1109/CVPR42600.2020.00319; Jahan M. S., 2021, arXiv; Jiang Aiqi, 2022, Online Social Networks and Media, DOI 10.1016/j.osnem.2021.100182; Kim Y, 2016, Arxiv, DOI arXiv:1606.07947; Li W, 2021, arXiv, DOI [10.48550/arXiv.2112.01048, DOI 10.48550/ARXIV.2112.01048]; Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271; Markov T, 2022, Arxiv, DOI arXiv:2208.03274; Mi F, 2022, Arxiv, DOI arXiv:2203.17090; Nguyen-Meidine LT, 2021, IEEE WINT CONF APPL, P1338, DOI 10.1109/WACV48630.2021.00138; Noever D, 2018, Arxiv, DOI [arXiv:1810.01869, 10.48550/arXiv.1810.01869, DOI 10.48550/ARXIV.1810.01869]; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Price I., 2020, P 4 WORKSHOP ONLINE, P114, DOI DOI 10.18653/V1/2020.ALW-1.15; Qian J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4755; Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300; Rosenthal S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P915; Sap Maarten, 2020, P 58 ANN M ASS COMPU, P5477; Sheng E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P750; Su H.-P., 2017, P 1 WORKSH AB LANG O, P18, DOI DOI 10.18653/V1/W17-3003; Sun H, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3906; Wang YQ, 2023, Arxiv, DOI arXiv:2210.05892; Wang ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3711; Wu MC, 2019, INT CONF ACOUST SPEE, P2202, DOI 10.1109/ICASSP.2019.8682450; Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1391, DOI 10.1145/3038912.3052591; Xiangru Tang, 2020, Chinese Computational Linguistics. 19th China National Conference, CCL 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12522), P300, DOI 10.1007/978-3-030-63031-7_22; Xu J, 2021, Arxiv, DOI arXiv:2010.07079; Yang H., 2020, P 2 WORKSHOP TROLLIN, P6; You S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1285, DOI 10.1145/3097983.3098135; Zampieri M, 2019, Arxiv, DOI [arXiv:1902.09666, 10.48550/ARXIV.1902.09666]; Zhang YJ, 2021, J ASSOC INF SCI TECH, V72, P1477, DOI 10.1002/asi.24496; Zhou H, 2021, Arxiv, DOI arXiv:2108.01547; Zhou JY, 2022, LECT NOTES ARTIF INT, V13552, P342, DOI 10.1007/978-3-031-17189-5_31; Zhou Jingyan, 2022, FINDINGS ASS COMPUTA, P3576	43	0	0	7	8	AMER ASSOC ADVANCEMENT SCIENCE	WASHINGTON	1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA	2096-5168	2639-5274		RESEARCH-CHINA	Research	SEP 18	2023	6								0189	10.34133/research.0189	http://dx.doi.org/10.34133/research.0189			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CA7Z2	37727321	Green Published, gold			2024-07-03	WOS:001122607000001
J	Manzoor, MF; Farooq, MS; Haseeb, M; Farooq, U; Khalid, S; Abid, A				Manzoor, Muhammad Faraz; Farooq, Muhammad Shoaib; Haseeb, Muhammad; Farooq, Uzma; Khalid, Sohail; Abid, Adnan			Exploring the Landscape of Intrinsic Plagiarism Detection: Benchmarks, Techniques, Evolution, and Challenges	IEEE ACCESS			English	Review						Intrinsic; plagiarism; feature extraction; machine learning; deep learning; evolution; challenges		In the realm of text analysis, intrinsic plagiarism detection plays a crucial role by aiming to identify instances of plagiarized content within a document and determining whether parts of the text originate from the same author. As the development of Large Language Models (LLMs) based content generation tools such as, ChatGPT is publicly available, the challenge of intrinsic plagiarism has become increasingly significant in various domains. Consequently, there is a growing demand for robust and accurate detection methods to address this evolving landscape. This study conducts a comprehensive Systematic Literature Review (SLR), analyzing 44 research papers that explore various facets of intrinsic plagiarism detection, including common datasets, feature extraction techniques, and detection methods. This SLR also highlights the evolution of detection approaches over time and the challenges faced in this context especially challenges associated with low-resource languages. To the best of our knowledge, there is no SLR exclusively based on the intrinsic plagiarism detection that bridge the gap in existing literature and offering valuable insights to researchers and practitioners. By consolidating the state-of-the-art findings, this SLR serves as a foundation for future research, enabling the development of more effective and efficient plagiarism detection solutions to combat the ever-evolving challenges posed by plagiarism in today's digital age.	[Manzoor, Muhammad Faraz; Farooq, Muhammad Shoaib; Haseeb, Muhammad; Farooq, Uzma] Univ Management & Technol, Dept Comp Sci, Lahore 54770, Pakistan; [Khalid, Sohail] Petr Engn Applicat Serv Dept Saudi Aramco, Dhahran 31311, Saudi Arabia; [Abid, Adnan] Univ Punjab, Fac Comp & Informat Technol, Dept Data Sci, Lahore 54590, Pakistan	University of Management & Technology (UMT); University of Punjab	Abid, A (corresponding author), Univ Punjab, Fac Comp & Informat Technol, Dept Data Sci, Lahore 54590, Pakistan.	adnan.abid@pu.edu.pk	Farooq, Muhammad Shoaib/AAC-8760-2020	Farooq, Muhammad Shoaib/0000-0002-4095-8868; Manzoor, Muhammad Faraz/0000-0001-6489-2157; FAROOQ, Muhammad Shoaib/0000-0003-3263-2646				Abdolahi M, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P40, DOI 10.1109/KBEI.2017.8325018; Abid A, 2016, NEURAL COMPUT APPL, V27, P1207, DOI 10.1007/s00521-015-1945-5; Almuqren L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.510; AlSallal M, 2019, FUTURE GENER COMP SY, V96, P700, DOI 10.1016/j.future.2017.11.023; Alsallal M, 2014, 2013 SIXTH INTERNATIONAL CONFERENCE ON DEVELOPMENTS IN ESYSTEMS ENGINEERING (DESE), P145, DOI 10.1109/DeSE.2013.34; Alzahrani S, 2022, J KING SAUD UNIV-COM, V34, P1110, DOI 10.1016/j.jksuci.2020.04.009; [Anonymous], 2016, P 10 INT WORKSH SEM, DOI DOI 10.18653/V1/S16-1086; Aria M, 2017, J INFORMETR, V11, P959, DOI 10.1016/j.joi.2017.08.007; Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0; Bensalem I., 2012, P 2 SPAN C INF RETR; Bensalem Imene., 2014, C EMPIRICAL METHODS, P1459; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brooke J., 2012, P CLEF ONL WORK NOT, P1; Bruton SV, 2014, ACCOUNT RES, V21, P176, DOI 10.1080/08989621.2014.848071; Chandere V, 2021, Ann Roman Soc Cell Biol, P7110; Clough P., 2003, National Plagiarism Advisory Service, 2003, P391; Cobo MJ, 2012, J AM SOC INF SCI TEC, V63, P1609, DOI 10.1002/asi.22688; Curran D, 2010, LECT NOTES ARTIF INT, V6206, P33; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eisa TAE, 2015, ONLINE INFORM REV, V39, P383, DOI 10.1108/OIR-12-2014-0315; Eissen SMZ, 2007, STUD CLASS DATA ANAL, P359; Eissen SMZ, 2006, LECT NOTES COMPUT SC, V3936, P565; Elberzhager F, 2012, INFORM SOFTWARE TECH, V54, P1, DOI 10.1016/j.infsof.2011.06.003; Farooq U, 2021, NEURAL COMPUT APPL, V33, P14357, DOI 10.1007/s00521-021-06079-3; Ferreira R, 2014, EXPERT SYST APPL, V41, P5780, DOI 10.1016/j.eswa.2014.03.023; Ferrero J., 2017, P 15 C EUR CHAPT ASS, V2, P415, DOI DOI 10.18653/V1/E17-2066; Foltynek T, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3345317; Garner HR, 2011, UROL ONCOL-SEMIN ORI, V29, P95, DOI 10.1016/j.urolonc.2010.09.016; Ghaeini M. R., 2013, P CEUR WORKSH, V1179; Gomes K. P., 2020, Cbie, P1633, DOI [10.5753/cbie.sbie.2020.1633, DOI 10.5753/CBIE.SBIE.2020.1633]; Gruenthal H., 2009, Knowl. Quest, V37, P70; Gupta Hritvik, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P511, DOI 10.1109/ICAIS50930.2021.9395976; Haider MM, 2020, IEEE REGION 10 SYMP, P283; Hamborg F, 2019, INT J DIGIT LIBRARIE, V20, P391, DOI 10.1007/s00799-018-0261-y; He H., 2016, P 10 INT WORKSH SEM, P1103, DOI [DOI 10.18653/V1/S16-1170, 10.18653/v1/s16-1170]; Hima bindu sri S., 2021, Journal of Physics: Conference Series, V2040, DOI 10.1088/1742-6596/2040/1/012044; Hongyuan Zha, 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P113; Hourrane O, 2019, INT J ADV COMPUT SC, V10, P646; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Ishaq M., 2023, Education and Information Technologies, V28; Iyer A., 2020, CEUR WORKSHOP PROC, V2696, P22; Jiffriya MAC, 2021, J Sci-FAS-SEUSL, V02, P47; Karas D., 2017, P CEUR WORKSH, V1866; Kestemont M., 2011, P PAN, V63, P1; Khaled F., 2021, IRAQI J SCI, V62, P2771, DOI DOI 10.24996/IJS.2021.62.8.30; Khalil M., 2023, LEARNING COLLABORATI, DOI [10.1007/978-3-031-34411-4_32, DOI 10.1007/978-3-031-34411-4_32]; Khan J. A., 2017, P CEUR WORKSH, V1866; Khonji M, 2021, IEEE ACCESS, V9, P101124, DOI 10.1109/ACCESS.2021.3098192; Kim Y, 2011, QUAL SOC WORK, V10, P190, DOI 10.1177/1473325010362001; Kopev D., 2018, Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, V11089; Kurniawan K, 2018, INT CONF ASIAN LANG, P215, DOI 10.1109/IALP.2018.8629109; Kuta M, 2014, LECT NOTES ARTIF INT, V8468, P500, DOI 10.1007/978-3-319-07176-3_44; Kuznetsov M. P., 2016, P CLEF WORK NOTES, P912; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lilian N., 2020, Res. Publications, V18, P14675; Magooda A., 2016, P WORK FOR INF RETR, V1587, P126; Mansouri A, 2008, INT J COMPUT SCI NET, V8, P339; Méndez JR, 2006, LECT NOTES ARTIF INT, V4177, P449; Misargopoulos A., 2022, P IFIP INT C ART INT, V652; Muhr M., 2010, P NOT PAP CLEF LABS, P22; Mukhtar N, 2020, ARTIF INTELL REV, V53, P2521, DOI 10.1007/s10462-019-09740-5; Oberreuter G., 2011, APPROACHES INTRINSIC; Oberreuter G, 2013, EXPERT SYST APPL, V40, P3756, DOI 10.1016/j.eswa.2012.12.082; Oberreuter G, 2011, LECT NOTES COMPUT SC, V6882, P11, DOI 10.1007/978-3-642-23863-5_2; Oloo V. A., 2022, Int. J. Comput. Trends Technol., V70, P15, DOI [10.14445/22312803/ijctt-v70i5p103, DOI 10.14445/22312803/IJCTT-V70I5P103]; Pecorari D, 2014, LANG TEACHING, V47, P269, DOI 10.1017/S0261444814000056; Polydouri A., 2017, 18 INT C ENG APPL NE, V2, P87, DOI [10.1007/978-3-319-65172-9, DOI 10.1007/978-3-319-65172-9]; Polydouri A, 2020, EVOL SYST-GER, V11, P503, DOI 10.1007/s12530-018-9232-1; Potthast M., 2011, P CEUR WORKSH, V1177; Rahman Rashedur., 2015, P 16 ANN M SPEC INT, P144, DOI [DOI 10.18653/V1/W15-4619, 10.18653/v1/W15-4619]; Ramzan M, 2019, IEEE ACCESS, V7, P107560, DOI 10.1109/ACCESS.2019.2932114; Rao S., 2011, P CEUR WORKSH, V1177, P2; Rinnan Å, 2009, INFRARED SPECTROSCOPY FOR FOOD QUALITY ANALYSIS AND CONTROL, P29, DOI 10.1016/B978-0-12-374136-3.00002-X; Safin K., 2017, P CEUR WORKSH, V1866; Safin K., 2018, P CEUR WORKSH, V2125; Saini A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P13, DOI 10.1109/ICCCIS51004.2021.9397187; Sengupta M. S., 2015, CTBC's IRJ, V2, P19; ShaukatTamboli M., 2013, Int. J. Comput. Appl., V77, P11, DOI [10.5120/13566-1375, DOI 10.5120/13566-1375]; Singh Rhia, 2021, CLEF WORKING NOTES, P2137; Specht G., 2015, P INT C APPL NAT LAN, P297; Stamatatos E., 2009, Threshold, V2, P500; Stamatatos E., 2016, RES COMPUTING SCI, V123, P9; Stein B, 2011, LANG RESOUR EVAL, V45, P63, DOI 10.1007/s10579-010-9115-y; Strom Eivind, 2021, CLEF WORKING NOTES, P2146; Su JD, 2020, IEEE ACCESS, V8, P100551, DOI 10.1109/ACCESS.2020.2997675; Suanmali L., 2009, arXiv:0906.4690, V2; Suanmali L, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS, P142, DOI 10.1109/HIS.2009.36; Tayal MA, 2017, COMPUT SPEECH LANG, V41, P214, DOI 10.1016/j.csl.2016.07.002; Tehseen R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062420; Tian J., 2016, P 10 INT WORKSH SEM, P621, DOI [10.18653/v1/s16-1094, DOI 10.18653/V1/S16-1094]; Tschuggnall Michael, 2012, Natural Language Processing and Information Systems. Proceedings 17th International Conference on Applications of Natural Language to Information Systems, NLDB 2012, P284, DOI 10.1007/978-3-642-31178-9_35; Tschuggnall M., 2013, Datenbanksysteme fur Business, Technol. und Web, V14, P241; Vartapetiance A., 2012, P WORK NOT PAP CLEF, P1; Wang JH, 2007, LECT NOTES COMPUT SC, V4426, P857; Widyassari Adhika Pramita, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P491; Widyassari AP, 2020, J KING SAUD UNIV-COM, V34, P1029, DOI 10.1016/j.jksuci.2020.05.006; Xiuli Hua, 2013, Chinese Lexical Semantics. 13th Workshop, CLSW 2012. Revised Selected Papers, P58, DOI 10.1007/978-3-642-36337-5_7; Zainuddin N, 2018, APPL INTELL, V48, P1218, DOI 10.1007/s10489-017-1098-6; Zhang H, 2018, LECT NOTES COMPUT SC, V11314, P398, DOI 10.1007/978-3-030-03493-1_42; Zhang J., 2020, P 37 INT C MACH LEAR, V1681, P11265; Zuo C., 2019, P CEUR WORKSH, V2380, P9	101	0	0	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						140519	140545		10.1109/ACCESS.2023.3338855	http://dx.doi.org/10.1109/ACCESS.2023.3338855			27	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	DD6S8		gold			2024-07-03	WOS:001130138900001
J	Si, YQ; Wang, JQ; Xu, H; Roberts, K				Si, Yuqi; Wang, Jingqi; Xu, Hua; Roberts, Kirk			Enhancing clinical concept extraction with contextual embeddings	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						clinical concept extraction; contextual embeddings; language model	INFORMATION EXTRACTION; WORD EMBEDDINGS	Objective: Neural network-based representations ("embeddings") have dramatically advanced natural language processing (NLP) tasks, including clinical NLP tasks such as concept extraction. Recently, however, more advanced embedding methods and representations (eg, ELMo, BERT) have further pushed the state of the art in NLP, yet there are no common best practices for how to integrate these representations into clinical tasks. The purpose of this study, then, is to explore the space of possible options in utilizing these new models for clinical concept extraction, including comparing these to traditional word embedding methods (word2vec, GloVe, fastText). Materials and Methods: Both off-the-shelf, open-domain embeddings and pretrained clinical embeddings from MIMIC-III (Medical Information Mart for Intensive Care III) are evaluated. We explore a battery of embedding methods consisting of traditional word embeddings and contextual embeddings and compare these on 4 concept extraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We also analyze the impact of the pretraining time of a large language model like ELMo or BERT on the extraction performance. Last, we present an intuitive way to understand the semantic information encoded by contextual embeddings. Results: Contextual embeddings pretrained on a large clinical corpus achieves new state-of-the-art performances across all concept extraction tasks. The best-performing model outperforms all state-of-the-art methods with respective F1-measures of 90.25, 93.18 (partial), 80.74, and 81.65. Conclusions: We demonstrate the potential of contextual embeddings through the state-of-the-art performance these methods achieve on clinical concept extraction. Additionally, we demonstrate that contextual embeddings encode valuable semantic information not accounted for in traditional word representations.	[Si, Yuqi; Wang, Jingqi; Xu, Hua; Roberts, Kirk] Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, 7000 Fannin St,Suite E730F, Houston, TX 77030 USA	University of Texas System; University of Texas Health Science Center Houston	Roberts, K (corresponding author), Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, 7000 Fannin St,Suite E730F, Houston, TX 77030 USA.	Kirk.Roberts@uth.tmc.edu	Roberts, Kirk/AAZ-4169-2021	Roberts, Kirk/0000-0001-6525-5213; Si, Yuqi/0000-0002-8123-8947	U.S. National Institutes of Health (NIH); Cancer Prevention and Research Institute of Texas (CPRIT); National Library of Medicine (NLM) [R00LM012104, R01LM010681]; National Cancer Institute [U24CA194215]; CPRIT [RP170668, RR180012]	U.S. National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Cancer Prevention and Research Institute of Texas (CPRIT)(Cancer Prevention & Research Institute of Texas); National Library of Medicine (NLM)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM)); National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); CPRIT(Cancer Prevention & Research Institute of Texas)	This work was supported by the U.S. National Institutes of Health (NIH) and the Cancer Prevention and Research Institute of Texas (CPRIT). Specifically, NIH support comes from the National Library of Medicine (NLM) under award R00LM012104 (to KR) and R01LM010681 (to HX), as well as the National Cancer Institute under award U24CA194215 (to HX). CPRIT support for computational resources was provided under awards RP170668 (W. Jim Zheng) and RR180012 (Xiaoqian Jiang).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; [Anonymous], P INT C LEARN REPR; [Anonymous], P MACH LEARN HLTH ML; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Bethard Steven, 2016, P 10 INT WORKSH SEM, P1052; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Browne AC., 2000, National Library of Medicine Technical Reports, P18; Chalapathy Raghavendra., 2016, ARXIV161108373, P7; Chang F. X., 2015, APPL WORD EMBEDDINGS, V13, P321; de Bruijn B, 2011, J AM MED INFORM ASSN, V18, P557, DOI 10.1136/amiajnl-2011-000150; Devlin J., 2018, BERT PRE TRAINING DE; Elhadad N., 2015, P 9 INT WORKSH SEM E, P303, DOI [DOI 10.18653/V1/S15-2051, 10.18653/v1/S15-2051]; Florez E., 2018, International Workshop on Medication and Adverse Drug Event Detection, P7; Habibi M, 2017, BIOINFORMATICS, V33, pI37, DOI 10.1093/bioinformatics/btx228; Huang K., 2019, CHIL WORKSH; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kundeti SR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1937, DOI 10.1109/BigData.2016.7840814; Lee H., 2011, P 15 C COMPUTATIONAL, P28; Lee Jinhyuk, 2019, BioBERT: a pre-trained biomedical language representation model for biomedical text mining; Liu ZJ, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0468-7; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Pakhomov Serguei, 2010, AMIA Annu Symp Proc, V2010, P572; Pakhomov SVS, 2016, BIOINFORMATICS, V32, P3635, DOI 10.1093/bioinformatics/btw529; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Pike J, 2014, MORAL GEOGRAPHIES OF CHILDREN, YOUNG PEOPLE AND FOOD BEYOND: JAMIE'S SCHOOL DINNERS, P172; Pradhan S., 2014, SEMEVAL COLING, P54; Radford A., 2018, IMPROVING LANGUAGE U; Rink B, 2011, J AM MED INFORM ASSN, V18, P594, DOI 10.1136/amiajnl-2011-000153; Roberts KM, 2016, CHALLENGES OF PARTY-BUILDING IN LATIN AMERICA, P51; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Shen YK, 2017, AAAI CONF ARTIF INTE, P3511; Si Yuqi, 2018, AMIA Annu Symp Proc, V2018, P1524; Stubbs A, 2015, J BIOMED INFORM, V58, pS11, DOI 10.1016/j.jbi.2015.06.007; Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628; Suominen H, 2013, LECT NOTES COMPUT SC, V8138, P212, DOI 10.1007/978-3-642-40802-1_24; Tang Buzhou, 2015, AMIA Annu Symp Proc, V2015, P1184; Tang BZ, 2013, BMC MED INFORM DECIS, V13, DOI 10.1186/1472-6947-13-S1-S1; Unanue IJ, 2017, J BIOMED INFORM, V76, P102, DOI 10.1016/j.jbi.2017.11.007; Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203; Vaswani A., 2017, P ANN C NEUR INF PRO, P5998; Velupillai S, 2018, J BIOMED INFORM, V88, P11, DOI 10.1016/j.jbi.2018.10.005; Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Wu Yonghui, 2015, AMIA Annu Symp Proc, V2015, P1326; Xu Hua, 2011, AMIA Annu Symp Proc, V2011, P1564; Zhang Y., 2014, P 8 INT WORKSH SEM E, P802	47	131	146	21	130	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	NOV	2019	26	11					1297	1304		10.1093/jamia/ocz096	http://dx.doi.org/10.1093/jamia/ocz096			8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	JP3LQ	31265066	Bronze, Green Published, Green Submitted			2024-07-03	WOS:000498169400018
J	Sun, LB; Wang, YX; Qin, WH				Sun, Libo; Wang, Yongxiang; Qin, Wenhu			A language-directed virtual human motion generation approach based on musculoskeletal models	COMPUTER ANIMATION AND VIRTUAL WORLDS			English	Article						character animation; deep reinforcement learning; language commands; musculoskeletal model		The development of the systems capable of synthesizing natural and life-like motions for virtual characters has long been a central focus in computer animation. It needs to generate high-quality motions for characters and provide users with a convenient and flexible interface for guiding character motions. In this work, we propose a language-directed virtual human motion generation approach based on musculoskeletal models to achieve interactive and higher-fidelity virtual human motion, which lays the foundation for the development of language-directed controllers in physics-based character animation. First, we construct a simplified model of musculoskeletal dynamics for the virtual character. Subsequently, we propose a hierarchical control framework consisting of a trajectory tracking layer and a muscle control layer, obtaining the optimal control policy for imitating the reference motions through the training. We design a multi-policy aggregation controller based on large language models, which selects the motion policy with the highest similarity to user text commands from the action-caption data pool, facilitating natural language-based control of virtual character motions. Experimental results demonstrate that the proposed approach not only generates high-quality motions highly resembling reference motions but also enables users to effectively guide virtual characters to perform various motions via natural language instructions. We propose a language-directed virtual human motion generation approach based on musculoskeletal models to achieve interactive and higher-fidelity virtual human motion. It takes reference motion data, caption and text prompts as inputs, realizing the natural language motion controller through three components: constructing an action-caption data pool, learning the control policies for imitating the motion, and semantic matching selection. image	[Sun, Libo; Wang, Yongxiang; Qin, Wenhu] Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China	Southeast University - China	Sun, LB; Qin, WH (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Nanjing 210096, Peoples R China.	sunlibo@seu.edu.cn; qinwenhu@seu.edu.cn			Key R&D Program of Jiangsu Province; Jiangsu Modern Agricultural Industry Single Technology Research and Development project [CX(23)3120]; Advanced Computing and Intelligent Engineering (National Level) Laboratory Fund;  [BE2023010-3]	Key R&D Program of Jiangsu Province; Jiangsu Modern Agricultural Industry Single Technology Research and Development project; Advanced Computing and Intelligent Engineering (National Level) Laboratory Fund; 	This work was supported by the Key R&D Program of Jiangsu Province under grant BE2023010-3, Jiangsu Modern Agricultural Industry Single Technology Research and Development project under grant CX(23)3120, and Advanced Computing and Intelligent Engineering (National Level) Laboratory Fund.	Agrawal S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925893; Ahuja C, 2019, INT CONF 3D VISION, P719, DOI 10.1109/3DV.2019.00084; Anand AS., A deep reinforcement learning based approach towards generating human walking behavior with a neuromuscular model. 2019 IEEERAS 19th international conference on humanoid robots (humanoids). Piscataway; Anderson FC, 2001, J BIOMECH ENG-T ASME, V123, P381, DOI 10.1115/1.1392310; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399; Geyer H, 2010, IEEE T NEUR SYS REH, V18, P263, DOI 10.1109/TNSRE.2010.2047592; Ghosh A., Synthesis of compositional animations from textual descriptions. Proceedings of the IEEE/CVF international conference on computer vision. Piscataway; Haarnoja T, 2018, PR MACH LEARN RES, V80; Hill AV, 1938, PROC R SOC SER B-BIO, V126, P136, DOI 10.1098/rspb.1938.0050; Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663; Juravsky Jordan, 2022, SA '22 Conference Papers: SIGGRAPH Asia 2022 Conference Papers, DOI 10.1145/3550469.3555391; Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972; Lee SH., 2006, ACM SIGGRAPH 2006 papers; Lee Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661233; Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315; Liu LB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2893476; Nichol A, 2022, Arxiv, DOI arXiv:2112.10741; Park Jong-Min, 2022, arXiv; Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311; Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602; Plappert M, 2018, ROBOT AUTON SYST, V109, P13, DOI 10.1016/j.robot.2018.07.006; Qin WH, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2092; Radford A., Learning transferable visual models from natural language supervision. International conference on machine learning. PMLR; 2021. p. 87488763; Ramesh A., 2022, arXiv; Schulman J., 2017, ARXIV; Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208; Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505; Sueda S., 2008, ACM SIGGRAPH 2008 papers, P18; Sun LB, 2024, COMPUT ANIMAT VIRT W, V35, DOI 10.1002/cav.2209; Tan F., Text2scene: generating compositional scenes from textual descriptions. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. Piscataway; Tassa Y., Synthesis and stabilization of complex behaviors through online trajectory optimization. 2012 IEEE/RSJ international conference on intelligent robots and systems. Piscataway; Tevet G, 2022, LECT NOTES COMPUT SC, V13682, P358, DOI 10.1007/978-3-031-20047-2_21; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang Y, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555490; Xie Z., 2022, ACM SIGGRAPH 2022 C, P19; Yin ZQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459817	37	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1546-4261	1546-427X		COMPUT ANIMAT VIRT W	Comput. Animat. Virtual Worlds	MAY	2024	35	3							e2257	10.1002/cav.2257	http://dx.doi.org/10.1002/cav.2257			15	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TA1E3					2024-07-03	WOS:001238434800001
J	Hermann, CE; Patel, JM; Boyd, L; Aviki, E; Stasenko, M				Hermann, Catherine E.; Patel, Jharna M.; Boyd, Leslie; Aviki, Emeline; Stasenko, Marina			Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions	GYNECOLOGIC ONCOLOGY			English	Article						Arti ficial Intelligence; ChatGPT; Cervical dysplasia; HPV vaccination; Cervical cancer	DISPARITIES	Objective. To quantify the accuracy of ChatGPT in answering commonly asked questions pertaining to cervical cancer prevention, diagnosis, treatment, and survivorship/quality-of-life (QOL). Methods. ChatGPT was queried with 64 questions adapted from professional society websites and the au-thors' clinical experiences. The answers were scored by two attending Gynecologic Oncologists according to the following scale: 1) correct and comprehensive, 2) correct but not comprehensive, 3) some correct, some in-correct, and 4) completely incorrect. Scoring discrepancies were resolved by additional reviewers as needed. The proportion of responses earning each score were calculated overall and within each question category.Results. ChatGPT provided correct and comprehensive answers to 34 (53.1%) questions, correct but not com-prehensive answers to 19 (29.7%) questions, partially incorrect answers to 10 (15.6%) questions, and completely incorrect answers to 1 (1.6%) question. Prevention and survivorship/QOL had the highest proportion of "correct" scores (scores of 1 or 2) at 22/24 (91.7%) and 15/16 (93.8%), respectively. ChatGPT performed less well in the treatment category, with 15/21 (71.4%) correct scores. It performed the worst in the diagnosis category with only 1/3 (33.3%) correct scores.Conclusion. ChatGPT accurately answers questions about cervical cancer prevention, survivorship, and QOL. It performs less accurately for cervical cancer diagnosis and treatment. Further development of this immensely popular large language model should include physician input before it can be utilized as a tool for Gynecologists or recommended as a patient resource for information on cervical cancer diagnosis and treatment.(c) 2023 Elsevier Inc. All rights reserved.	[Hermann, Catherine E.; Patel, Jharna M.; Boyd, Leslie; Stasenko, Marina] New York Univ Langone Hlth, Dept Obstet & Gynecol, Div Gynecol Oncol, New York, NY USA; [Aviki, Emeline] New York Univ Langone Hlth Long Isl, Dept Obstet & Gynecol, Div Gynecol Oncol, Mineola, NY USA; [Hermann, Catherine E.] NYU Langone Hlth, Dept OBGYN, Div Oncol, 240 E 38th St,20th Floor, New York, NY 10016 USA	New York University; NYU Langone Medical Center	Hermann, CE (corresponding author), NYU Langone Hlth, Dept OBGYN, Div Oncol, 240 E 38th St,20th Floor, New York, NY 10016 USA.	catherine.e.hermann@gmail.com		Patel, Jharna/0000-0003-0426-0419				[Anonymous], 2022, OpenAI ChatGPT: optimizing language models for dialogue; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Collins Y, 2014, GYNECOL ONCOL, V133, P353, DOI 10.1016/j.ygyno.2013.12.039; Gilson A., 2023, JMIR Med Educ., V8; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Kothari AN, 2023, ANN SURG ONCOL, V30, P3174, DOI 10.1245/s10434-023-13442-2; McElfish PA, 2021, J RACIAL ETHN HEALTH, V8, P1260, DOI 10.1007/s40615-020-00886-5; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Spencer JC, 2023, AM J PREV MED, V65, P667, DOI 10.1016/j.amepre.2023.04.016; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Yoo W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172548	16	2	2	6	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0090-8258	1095-6859		GYNECOL ONCOL	Gynecol. Oncol.	DEC	2023	179						164	168		10.1016/j.ygyno.2023.11.008	http://dx.doi.org/10.1016/j.ygyno.2023.11.008		NOV 2023	5	Oncology; Obstetrics & Gynecology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology; Obstetrics & Gynecology	CA3U4	37988948				2024-07-03	WOS:001122497400001
J	Xu, R; Wang, Z				Xu, Rui; Wang, Zhong			Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges	HELIYON			English	Article						ChatGPT; Healthcare; Digital media; Applications; Opportunities; Challenges; Digital health; Generative artificial intelligence; Large language models; Artificial intelligence generated content	CHATGPT; MEDICINE	Introduction: The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges. Methods: This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the subcategories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers. Results: This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics. Conclusions: The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs' economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.	[Xu, Rui; Wang, Zhong] Guangdong Univ Technol, Sch Econ, Guangzhou, Peoples R China; [Wang, Zhong] Guangdong Univ Technol, Key Lab Digital Econ & Data Governance, Guangzhou, Peoples R China	Guangdong University of Technology; Guangdong University of Technology	Wang, Z (corresponding author), Guangdong Univ Technol, Key Lab Digital Econ & Data Governance, Guangzhou, Peoples R China.	xur2022@163.com; wz@gdut.edu.cn			National Social Science Fund of China [21BJL038]	National Social Science Fund of China	This research was funded by the National Social Science Fund of China (Grant No. 21BJL038) .	Ahmed S.K., 2023, ChatGPT's influence on journal impact factors: a paradigm shift, DOI [10.2139/ssrn.4467193, DOI 10.2139/SSRN.4467193]; Ahmed SK, 2023, ANN BIOMED ENG, V51, P2351, DOI 10.1007/s10439-023-03262-6; Alhasan K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36263; Ali M.J., 2023, Readership Awareness Series-Paper 4: Chatbots and ChatGPT-Ethical Considerations in Scientific Publications, Seminars in ophthalmology, V4; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Nguyen A, 2020, MEDIA COMMUN-LISBON, V8, P323, DOI 10.17645/mac.v8i2.3352; Anderson LE, 2020, SEX REPROD HEALTHC, V25, DOI 10.1016/j.srhc.2020.100534; Arditi C, 2016, BMC HEALTH SERV RES, V16, DOI 10.1186/s12913-016-1816-5; Awal SS, 2023, J PUBLIC HEALTH-HEID, DOI 10.1007/s10389-023-02170-2; Aydin O., 2023, Academic Platform Journal of Engineering and Smart Systems, V11, P118, DOI [10.2139/ssrn.4341500, DOI 10.2139/SSRN.4341500]; Berg M., 2012, Interactions: Studies in Communication & Culture, V3, P71, DOI [DOI 10.1386/ISCC.3.1.711, 10.1386/iscc.3.1, DOI 10.1386/ISCC.3.1]; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brynjolfsson E., 2023, Technical Report; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Couldry N., 2012, Media, Society, World: Social Theory and Digital Media Practice; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Eysenbach G., 2008, Credibility of Health Information and Digital Media: New Perspectives and Implications for Youth; Ferrag MA, 2023, Arxiv, DOI [arXiv:2303.11751, 10.48550/arXiv.2303.11751, DOI 10.48550/ARXIV.2303.11751]; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hu X, 2023, Arxiv, DOI [arXiv:2304.02796, DOI 10.1016/J.PROCIR.2023.05.001, 10.48550/arXiv.2304.02796, DOI 10.48550/ARXIV.2304.02796]; Huang HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00239-y; Huang P.G. Sonya, 2022, Generative AI: a creative new world; Iftikhar L., 2023, EC Paediatrics, V12, P45; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Klang E, 2023, THER ADV GASTROENTER, V16, DOI 10.1177/17562848231218618; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Kuckartz U., 2013, Qualitative Text Analysis: A Guide to Methods, Practice and Using Software; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Loh E, 2024, BMJ LEAD, V8, P51, DOI 10.1136/leader-2023-000797; Lupton D., 2017, Digital health: Critical and cross-disciplinary perspectives; Mack CA, 2011, IEEE T SEMICONDUCT M, V24, P202, DOI 10.1109/TSM.2010.2096437; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Martínez G, 2023, Arxiv, DOI [arXiv:2303.01255, 10.48550/arXiv.2303.01255]; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McGee R.W., 2023, Working Paper; Muller M, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503719; Nguyen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1324; Nov O, 2023, medRxiv, DOI [10.1101/2023.01.23.23284735, 10.1101/2023.01.23.23284735, DOI 10.1101/2023.01.23.23284735]; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Olczak J, 2021, ACTA ORTHOP, V92, P513, DOI 10.1080/17453674.2021.1918389; Panda A., 2021, Vikalpa, V46, P71, DOI [10.1177/02560909211025361, DOI 10.1177/02560909211025361]; Parray A.A., 2023, ChatGPT and global public health: applications, challenges, ethical considerations and mitigation strategies, DOI [10.1016/j.glt.2023.05.001, DOI 10.1016/J.GLT.2023.05.001]; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Roberts C.W., 2020, Text Analysis for the Social Sciences: Methods for Drawing Statistical Inferences from Texts and Transcripts; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sedaghat S, 2023, CLIN MED, V23, P278, DOI 10.7861/clinmed.2023-0078; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Teebagy S, 2023, medRxiv, DOI [10.1101/2023.04.03.23287957, 10.1101/2023.04.03.23287957, DOI 10.1101/2023.04.03.23287957]; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Ufuk F, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230276; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wang DJ, 2023, Arxiv, DOI [arXiv:2304.03892, 10.48550/arXiv.2304.03892, DOI 10.48550/ARXIV.2304.03892]; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang Z, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1108621; Wang Z, 2019, ISR J HEALTH POLICY, V8, DOI 10.1186/s13584-019-0293-9; Wenxiu P., 2015, J ED SOCIAL RES, V5, P245, DOI DOI 10.5901/JESR.2015.V5N3P245; West CG, 2023, Arxiv, DOI [arXiv:2303.17012, 10.48550/arXiv.2303.17012]; Xiao DV, 2023, J PEDIATR SURG, V58, P2410, DOI 10.1016/j.jpedsurg.2023.07.008; Xie YQ, 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00765-8; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Zohny H, 2023, J MED ETHICS, V49, P79, DOI 10.1136/jme-2023-108909	82	0	0	0	0	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2405-8440		HELIYON	Heliyon	JUN 30	2024	10	12							e32364	10.1016/j.heliyon.2024.e32364	http://dx.doi.org/10.1016/j.heliyon.2024.e32364			16	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	WE1C0		gold			2024-07-03	WOS:001253090800001
C	Alessio, M; Faggioli, G; Ferro, N			ACM	Alessio, Marco; Faggioli, Guglielmo; Ferro, Nicola			DECAF: A Modular and Extensible Conversational Search Framework	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Conversational Search; Experimental Framework; Benchmark		The Conversational Search (CS) paradigm allows for an intuitive interaction between the user and the system through natural language sentences and it is increasingly being adopted in various scenarios. However, its widespread experimentation has led to the birth of a multitude of conversational search systems with custom implementations and variants of information retrieval models. This exacerbates the reproducibility crisis already observed in several research areas, including Information Retrieval (IR). To address this issue, we propose DECAF: a modular and extensible conversational search framework designed for fast prototyping and development of conversational agents. Our framework integrates all the components that characterize a modern conversational search system and allows for the seamless integration of Machine Learning (ML) and Large Language Models (LLMs)-based techniques. Furthermore, thanks to its uniform interface, DECAF allows for experiments characterized by a high degree of reproducibility. DECAF contains several state-of-the-art components including query rewriting, search functions under BoW and dense paradigms, and re-ranking functions. Our framework is tested on two well-known conversational collections: TREC CAsT 2019 and TREC CAsT 2020 and the results can be used by future practitioners as baselines. Our contributions include the identification of a series of state-of-the-art components for the conversational search task and the definition of a modular framework for its implementation.	[Alessio, Marco; Faggioli, Guglielmo; Ferro, Nicola] Univ Padua, Padua, Italy	University of Padua	Alessio, M (corresponding author), Univ Padua, Padua, Italy.	marco.alessio.1@studenti.unipd.it; faggioli@dei.unipd.it; ferro@dei.unipd.it	faggioli, guglielmo/ABT-4575-2022; Ferro, Nicola/L-5292-2015	Ferro, Nicola/0000-0001-9219-6239; Faggioli, Guglielmo/0000-0002-5070-2049	University of Padova Strategic Research Infrastructure Grant 2017: "CAPRI: Calcolo ad Alte Prestazioni per la Ricerca e l'Innovazione"	University of Padova Strategic Research Infrastructure Grant 2017: "CAPRI: Calcolo ad Alte Prestazioni per la Ricerca e l'Innovazione"	The work was partially supported by University of Padova Strategic Research Infrastructure Grant 2017: "CAPRI: Calcolo ad Alte Prestazioni per la Ricerca e l'Innovazione"	Aliannejadi M, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P16, DOI 10.1145/3459637.3482231; Aliannejadi M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P475, DOI 10.1145/3331184.3331265; Anand Avishek, 2020, ABS200508658 CORR; [Anonymous], 2016, P SIGDIAL 2016 C 17, DOI DOI 10.18653/V1/W16-3649; Bangalore S, 2008, IEEE T AUDIO SPEECH, V16, P1249, DOI 10.1109/TASL.2008.2001102; ChengXiang Zhai, 2008, Foundations and Trends in Information Retrieval, V2, P137, DOI 10.1561/1500000008; Dacrema MF, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P101, DOI 10.1145/3298689.3347058; Dalton Jeffrey, 2020, ABS200313624 CORR; Dalton Jeffrey, 2020, NIST SPECIAL PUBLICA; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ferro N, 2017, ACM J DATA INF QUAL, V8, DOI 10.1145/3020206; Ferro N, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P25, DOI 10.1145/2911451.2911530; Ferro N, 2010, LECT NOTES COMPUT SC, V6241, P552, DOI 10.1007/978-3-642-15754-7_68; Formal Thibault, 2021, ABS210705720 CORR; Formal Thibault, 2021, ABS210910086 CORR; Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1; Gu JC, 2020, IEEE-ACM T AUDIO SPE, V28, P369, DOI 10.1109/TASLP.2019.2955290; Hui Kai, 2017, P 2017 C EMP METH NA, P1049, DOI DOI 10.18653/V1/D17-1110; Jingtao Zhan, 2021, SIGIR '21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, P1503, DOI 10.1145/3404835.3462880; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Kharazmi S, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2882782; Krasakis Antonios Minas, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P129, DOI 10.1145/3409256.3409817; Li JT, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3453183; Li YQ, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3498557; Lin J., 2016, Lecture Notes in Computer Science; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Lin SC, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3446426; Lin Sheng-Chieh, 2020, ABS201011386 CORR; MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317; MacDonald Craig, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P161, DOI 10.1145/3409256.3409829; Mele I, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2057, DOI 10.1145/3397271.3401268; Mele I, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102682; Nogueira R., 2019, ABS190104085 CORR; Otmazgin Shon, 2022, P 2 C ASIA PACIFIC C, P48; Otmazgin Shon, 2022, ABS220512644 CORR, DOI [10.48550/arXiv.2205.12644, DOI 10.48550/ARXIV.2205.12644]; Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517; Penha Gustavo, 2020, CEUR WORKSHOP P, V2666; Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183; Raffel C, 2020, J MACH LEARN RES, V21; Raposo G, 2022, LECT NOTES COMPUT SC, V13186, P199, DOI 10.1007/978-3-030-99739-7_23; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Tao CY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P267, DOI 10.1145/3289600.3290985; TUN ZY, 2022, TREC CAST 2021 CONVE, DOI DOI 10.1145/3543829.3543830; Vakulenko S, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P355, DOI 10.1145/3437963.3441748; Voskarides N, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P921, DOI 10.1145/3397271.3401130; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046; Xiong CY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/3077136.3080809; Xiong Lee, 2021, ICLR; Yan R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5520; Yang J.-H., 2019, TREC; Yang PL, 2018, ACM J DATA INF QUAL, V10, DOI 10.1145/3239571; Yang PL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1253, DOI 10.1145/3077136.3080721; Yang W, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1129, DOI 10.1145/3331184.3331340; Yang Z, 2018, LECT NOTES COMPUT SC, V11168, P16, DOI 10.1007/978-3-030-01012-6_2; Yu S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P829, DOI 10.1145/3404835.3462856; Zamani Hamed, 2022, ARXIV220108808; Zhang E, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2521, DOI 10.1145/3404835.3462782	59	1	1	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							3075	3085		10.1145/3539618.3591913	http://dx.doi.org/10.1145/3539618.3591913			11	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG					2024-07-03	WOS:001118084003012
C	Chen, R; Chen, YW; Jiao, NX; Jia, K			IEEE	Chen, Rui; Chen, Yongwei; Jiao, Ningxin; Jia, Kui			Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Automatic 3D content creation has achieved rapid progress recently due to the availability of pre-trained, large language models and image diffusion models, forming the emerging topic of text-to-3D content creation. Existing text-to-3D methods commonly use implicit scene representations, which couple the geometry and appearance via volume rendering and are suboptimal in terms of recovering finer geometries and achieving photorealistic rendering; consequently, they are less effective for generating highquality 3D assets. In this work, we propose a new method of Fantasia3D for high- quality text-to-3D content creation. Key to Fantasia3D is the disentangled modeling and learning of geometry and appearance. For geometry learning, we rely on a hybrid scene representation, and propose to encode surface normal extracted from the representation as the input of the image diffusion model. For appearance modeling, we introduce the spatially varying bidirectional reflectance distribution function (BRDF) into the text-to-3D task, and learn the surface material for photorealistic rendering of the generated surface. Our disentangled framework is more compatible with popular graphics engines, supporting relighting, editing, and physical simulation of the generated 3D assets. We conduct thorough experiments that show the advantages of our method over existing ones under different text-to-3D task settings. Project page and source codes: https://fantasia3d.github.io/.	[Chen, Rui; Chen, Yongwei; Jiao, Ningxin; Jia, Kui] South China Univ Technol, Guangzhou, Guangdong, Peoples R China	South China University of Technology	Jia, K (corresponding author), South China Univ Technol, Guangzhou, Guangdong, Peoples R China.				Program for Guangdong Introducing Innovative and Entrepreneurial Teams [2017ZT07X183]; Guangdong R&D key project of China [2019B010155001]	Program for Guangdong Introducing Innovative and Entrepreneurial Teams; Guangdong R&D key project of China	This work is supported in part by Program for Guangdong Introducing Innovative and Entrepreneurial Teams (No.: 2017ZT07X183) and Guangdong R&D key project of China (No.: 2019B010155001).	Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917; Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978; [Anonymous], About Us; Balaji Yogesh, 2022, arXiv preprint arXiv:2211.01324; Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580; Bi S., 2020, arXiv preprint arXiv:2008.03824; Blender Online Community, 2018, Blender-a 3D modelling and rendering package; Chen Wenzheng, 2021, ADV NEURAL INFORM PR, V34, P22834; Chen Y, 2022, LECT NOTES COMPUT SC, V13338, P3, DOI 10.1007/978-3-031-06794-5_1; Clarisse, UV EDG PADD; Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378; Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042; Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094; Khalid NM, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555392; Labschutz M., 2011, I COMPUTER GRAPHICS, V6, P124; Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861; Li Muheng, 2022, ARXIV221203293; Lin Chen-Hsuan, 2022, ARXIV221110440; Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI 10.1145/37401.37422; McAuley S., 2012, ACM SIGGRAPH 2012 Courses, SIGGRAPH'12, p10:1, DOI DOI 10.1145/2343483.2343493; Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459; Metzer Gal, 2022, ARXIV221107600; Michel Oscar, 2022, P IEEE CVF C COMP VI; Mildenhall Ben, 2020, ECCV, P405, DOI DOI 10.1007/978-3-030-58452-8_24; Mordvintsev A., 2018, Distill, V3, pe12, DOI 10. 23915/distill.00012; Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127; Munkberg J, 2022, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR52688.2022.00810; Nam Gimin, 2022, ARXIV221200842; Nichol Alex, 2021, P MACHINE LEARNING R; Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025; Peng BH, 2019, ADV NEUR IN, V32; Poole B., 2023, INT C LEARN REPR ICL, P1; Ramesh Aditya, 2022, ARXIV220406125; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saharia Chitwan, 2022, Advances in Neural Information Processing Systems; Schuhmann Christoph, 2022, ADV NEURAL INFORM PR; Shen T., 2021, Advances in Neural Information Processing Systems, V34, P6087; Shue J Ryan, 2022, ARXIV221116677; Stability, STABL DIFF; Tang Jiaxiang, STABLE DREAMFUSION; Walter B., 2007, RENDERING TECHNIQUES, P195, DOI 10.2312/EGWR/EGSR07/195-206; Wang Tengfei, 2023, P IEEE CVF C COMP VI; Wu HZ, 2011, COMPUT GRAPH FORUM, V30, P465, DOI 10.1111/j.1467-8659.2011.01890.x; Yariv L, 2021, ADV NEUR IN; Young Jonathan, 2021, xatlas; Zhang Y, 2020, IEEE RAD FREQ INTEGR, P3, DOI [10.1109/RFIC49505.2020.9218347, 10.1109/rfic49505.2020.9218347]; Zhao BY, 2022, INTERV NEURORADIOL, V28, P115, DOI 10.1177/15910199211018328; Zhou LQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5806, DOI 10.1109/ICCV48922.2021.00577	49	2	2	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							22189	22199		10.1109/ICCV51070.2023.02033	http://dx.doi.org/10.1109/ICCV51070.2023.02033			11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO		Green Submitted			2024-07-03	WOS:001169500506075
J	AlDahoul, N; Rahwan, T; Zaki, Y				AlDahoul, Nouar; Rahwan, Talal; Zaki, Yasir			PoLYTC: a novel BERT-based classifier to detect political leaning of YouTube videos based on their titles	JOURNAL OF BIG DATA			English	Article						YouTube; Political leaning; BERT classifier; PoLYTC		Over two-thirds of the U.S. population uses YouTube, and a quarter of U.S. adults regularly receive their news from it. Despite the massive political content available on the platform, to date, no classifier has been proposed to classify the political leaning of YouTube videos. The only exception is a classifier that requires extensive information about each video (rather than just the title) and classifies the videos into just three classes (rather than the widely-used categorization into six classes). To fill this gap, "PoLYTC" (Political Leaning YouTube Classifier) is proposed to classify YouTube videos based on their titles into six political classes. PoLYTC utilizes a large language model, namely BERT, and is fine-tuned on a public dataset of 11.5 million YouTube videos. Experiments reveal that the proposed solution achieves high accuracy (75%) and high F1-score (77%), thereby outperforming the state of the art. To further validate the solution's classification performance, several videos were collected from numerous prominent news agencies' YouTube channels, such as Fox News and The New York Times, which have widely known political leanings. These videos were classified based on their titles, and the results have shown that, in the vast majority of cases, the predicted political leaning matches that of the news agency. PoLYTC can help YouTube users make informed decisions about which videos to watch and can help researchers analyze the political content on YouTube.	[AlDahoul, Nouar; Rahwan, Talal; Zaki, Yasir] New York Univ Abu Dhabi, Comp Sci, Abu Dhabi, U Arab Emirates	New York University Abu Dhabi	Zaki, Y (corresponding author), New York Univ Abu Dhabi, Comp Sci, Abu Dhabi, U Arab Emirates.	yasir.zaki@nyu.edu						Abu-El-Haija S, 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.08675; Aksenov D, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, P121; [Anonymous], 2023, AllSides Media Bias Chart; [Anonymous], 2023, YouTube: YouTube for Press; Beltagy I, 2019, P 2019 C EMP METH NA, P3; Ceci L., 2023, YouTube: Hours of video uploaded every minute 2022; D'Alonzo S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271947; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Di Gennaro G, 2021, J SUPERCOMPUT, V77, P12320, DOI 10.1007/s11227-021-03743-2; Dinkov Yoan., 2019, PREDICTING LEADING P; Essa E, 2023, COMPLEX INTELL SYST, V9, P6581, DOI 10.1007/s40747-023-01098-0; Fenglei Gu, 2021, 2021 International Conference on Signal Processing and Machine Learning (CONF-SPML), P286, DOI 10.1109/CONF-SPML54095.2021.00062; Fernando KRM, 2022, IEEE T NEUR NET LEAR, V33, P2940, DOI 10.1109/TNNLS.2020.3047335; github, 2023, tensorflow: BERT (Bidirectional Encoder Representations from Transformers); google-research, 2018, BERT implementation; Hosseinmardi H, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2101967118; Ibrahim H, 2023, PNAS NEXUS, V2, DOI 10.1093/pnasnexus/pgad264; Jiang J, 2023, P INT AAAI C WEB SOC, V17, P459, DOI [10.1609/icwsm.v17i1.22160, DOI 10.1609/ICWSM.V17I1.22160]; Kalra Gurjyot Singh, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P74, DOI 10.1109/ICCCIS48478.2019.8974514; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Konitzer T, 2021, PUBLIC OPIN QUART, V85, P347, DOI 10.1093/poq/nfab023; Kulkarni V, 2018, Arxiv, DOI arXiv:1809.03485; Ledwich M, 1912, arXiv; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li C, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2594; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mock F, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2122636119; Nyhan B, 2023, NATURE, V620, P137, DOI 10.1038/s41586-023-06297-w; Peng YF, 2019, Arxiv, DOI arXiv:1906.05474; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; pewresearch, 2019, Americans almost equally prefer to get local news online or on TV Set; Reddy RR, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P77; Ribeiro M, 2021, Arxiv, DOI arXiv:1908.08313; Savigny J., 2017, 2017 INT C ADV INF C, P1, DOI 10.1109/ICAICTA.2017.8090986; Schomer A., 2020, US YouTube advertising 2020; Tasnim Z, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P724, DOI 10.1109/ESCI50559.2021.9396875; Wang CC, 2020, 2020 4TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2020, P37, DOI 10.1145/3443279.3443304; Xiao ZP, 2023, EPJ DATA SCI, V12, DOI 10.1140/epjds/s13688-023-00386-6; Yifan Shen, 2021, 2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC), P144, DOI 10.1109/ICFTIC54370.2021.9647258	39	0	0	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2196-1115		J BIG DATA-GER	J. Big Data	JUN 5	2024	11	1							80	10.1186/s40537-024-00946-1	http://dx.doi.org/10.1186/s40537-024-00946-1			16	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TD0G6		gold			2024-07-03	WOS:001239199300001
J	Zhang, YY; Zhang, CZ				Zhang, Yingyi; Zhang, Chengzhi			Extracting problem and method sentence from scientific papers: a context-enhanced transformer using formulaic expression desensitization	SCIENTOMETRICS			English	Article; Early Access						Sentence extraction from scientific papers; Problem and method sentence extraction; Data augmentation; Formulaic expression desensitization; Context-enhanced transformer		Billions of scientific papers lead to the need to identify essential parts from the massive text. Scientific research is an activity from putting forward problems to using methods. To learn the main idea from scientific papers, we focus on extracting problem and method sentences. Annotating sentences within scientific papers is labor-intensive, resulting in small-scale datasets that limit the amount of information models can learn. This limited information leads models to rely heavily on specific forms, which in turn reduces their generalization capabilities. This paper addresses the problems caused by small-scale datasets from three perspectives: increasing dataset scale, reducing dependence on specific forms, and enriching the information within sentences. To implement the first two ideas, we introduce the concept of formulaic expression (FE) desensitization and propose FE desensitization-based data augmenters to generate synthetic data and reduce models' reliance on FEs. For the third idea, we propose a context-enhanced transformer that utilizes context to measure the importance of words in target sentences and to reduce noise in the context. Furthermore, this paper conducts experiments using large language model (LLM) based in-context learning (ICL) methods. Quantitative and qualitative experiments demonstrate that our proposed models achieve a higher macro F1 score compared to the baseline models on two scientific paper datasets, with improvements of 3.71% and 2.67%, respectively. The LLM based ICL methods are found to be not suitable for the task of problem and method extraction.	[Zhang, Yingyi] Soochow Univ, Dept Arch & Egovt, Suzhou, Peoples R China; [Zhang, Chengzhi] Nanjing Univ Sci & Technol, Dept Informat Management, Nanjing, Peoples R China	Soochow University - China; Nanjing University of Science & Technology	Zhang, CZ (corresponding author), Nanjing Univ Sci & Technol, Dept Informat Management, Nanjing, Peoples R China.	yyzhang9@suda.edu.cn; zhangcz@njust.edu.cn		Zhang, Chengzhi/0000-0001-9522-2914	National Natural Science Foundation of China [72074113]; National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by National Natural Science Foundation of China (Grant No.72074113).	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bornmann L, 2015, J ASSOC INF SCI TECH, V66, P2215, DOI 10.1002/asi.23329; Boudin F, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-29; Chao WH, 2023, SCIENTOMETRICS, V128, P3347, DOI 10.1007/s11192-023-04694-6; Chen YN, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104676; Deng M., 2022, PROC EMNLP, P3369; Dernoncourt F., 2016, P 15 C EUR CHAPT ASS, P694; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding BS, 2023, Arxiv, DOI arXiv:2212.10450; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Ferreira Taynan Maier, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P435, DOI 10.1007/978-3-030-61377-8_30; Fisas B., 2015, P 9 LING ANN WORKSH, P42, DOI [10.3115/v1/W15-1605, DOI 10.3115/V1/W15-1605]; Goncalves S, 2020, NEURAL COMPUT APPL, V32, P6793, DOI 10.1007/s00521-019-04334-2; Graça M, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P45; Graves A, 2005, IEEE IJCNN, P2047; Heffernan K, 2018, SCIENTOMETRICS, V116, P1367, DOI 10.1007/s11192-018-2718-6; Iwatsuki K, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3476; Jin D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3100; Kim SN, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S2-S5; Kobayashi S., 2018, P 2018 C N AM CHAPT, P452; Kovacevic A, 2012, COMPUT SPEECH LANG, V26, P105, DOI [10.1016/j.csl.2011.09.001, 10.1016/j.cs1.2011.09.001]; La Quatra M, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109382; Liakata M, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2054; Liu Y., 2013, Computer and Information Science, V6, P125, DOI [10.5539/cis.v6n4p125, DOI 10.5539/CIS.V6N4P125]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Luan Yi, 2017, P 2017 C EMP METH NA, P2641, DOI [DOI 10.48550/ARXIV.1708.06075, DOI 10.18653/V1/D17-1279]; Luo ZR, 2022, J INFORMETR, V16, DOI 10.1016/j.joi.2022.101282; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mutlu B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102359; Neves M, 2019, 6TH WORKSHOP ON ARGUMENT MINING (ARGMINING 2019), P124; Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P314; Oelen A, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P464, DOI 10.1145/3397481.3450685; Pan XL, 2015, J INFORMETR, V9, P860, DOI 10.1016/j.joi.2015.07.012; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Raffel C., 2015, arXiv; Ruping Wang, 2020, Sustainable Digital Communities. 15th International Conference, iConference 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12051), P790, DOI 10.1007/978-3-030-43687-2_66; Safder I, 2019, SCIENTOMETRICS, V119, P257, DOI 10.1007/s11192-019-03025-y; Sakai T., 2012, P 14 INT C INF INT W, P360, DOI [10.1145/2428736.2428803, DOI 10.1145/2428736.2428803]; Shakeel MH, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102204; Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0; Takola YSSS, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13238; Teufel S, 2002, COMPUT LINGUIST, V28, P409, DOI 10.1162/089120102762671936; Vaswani A, 2017, ADV NEUR IN, V30; Wang W.Y., 2015, Association for Computational Linguistics, P2557, DOI DOI 10.18653/V1/D15-1306; Wang ZH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5154; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Wilson EdgarBright., 1952, INTRO SCI RES; Wray A, 2000, APPL LINGUIST, V21, P463, DOI 10.1093/applin/21.4.463; Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7; Xie Q, 2019, ARXIV190412848; Yamamoto Y., 2005, PROC 21 INT C DATA E, P1163, DOI DOI 10.1109/ICDE.2005.170; Yang L, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103038; Yu JF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3342; Zeng XJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7270; Zhang H., 2020, P 14 WORKSH SEM EV, P690, DOI [10.18653/v1/2020.semeval-1.90, DOI 10.18653/V1/2020.SEMEVAL-1.90]; Zhang YY, 2020, J ASSOC INF SCI TECH, V71, P553, DOI 10.1002/asi.24279; Zhao D, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03629-9; Zhao MN, 2018, J ASSOC INF SCI TECH, V69, P32, DOI 10.1002/asi.23919; Zhou Y, 2020, SCIENTOMETRICS, V123, P1, DOI 10.1007/s11192-020-03351-6	62	0	0	3	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0138-9130	1588-2861		SCIENTOMETRICS	Scientometrics	2024 MAY 27	2024										10.1007/s11192-024-05048-6	http://dx.doi.org/10.1007/s11192-024-05048-6		MAY 2024	36	Computer Science, Interdisciplinary Applications; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	SC2J7					2024-07-03	WOS:001232191900005
J	Zheng, XY; Watanabe, I; Paik, J; Li, JJ; Guo, XF; Naito, M				Zheng, Xiaoyang; Watanabe, Ikumu; Paik, Jamie; Li, Jingjing; Guo, Xiaofeng; Naito, Masanobu			Text-to-Microstructure Generation Using Generative Deep Learning	SMALL			English	Article; Early Access						architected material; artificial intelligence; deep generative model; deep learning; inverse design; metamaterial; microstructure	MECHANICAL METAMATERIALS; INVERSE DESIGN; LANGUAGE; BEHAVIOR	Designing novel materials is greatly dependent on understanding the design principles, physical mechanisms, and modeling methods of material microstructures, requiring experienced designers with expertise and several rounds of trial and error. Although recent advances in deep generative networks have enabled the inverse design of material microstructures, most studies involve property-conditional generation and focus on a specific type of structure, resulting in limited generation diversity and poor human-computer interaction. In this study, a pioneering text-to-microstructure deep generative network (Txt2Microstruct-Net) is proposed that enables the generation of 3D material microstructures directly from text prompts without additional optimization procedures. The Txt2Microstruct-Net model is trained on a large microstructure-caption paired dataset that is extensible using the algorithms provided. Moreover, the model is sufficiently flexible to generate different geometric representations, such as voxels and point clouds. The model's performance is also demonstrated in the inverse design of material microstructures and metamaterials. It has promising potential for interactive microstructure design when associated with large language models and could be a user-friendly tool for material design and discovery. What if an AI system can generate material microstructures via chatting? With the text-to-microstructure deep generative network (Txt2Microstruct-Net), users can get diverse and realistic 3D microstructures directly from text prompts without additional optimization procedures. It is also capable of material inverse design when fed with target geometric and mechanical properties. image	[Zheng, Xiaoyang; Watanabe, Ikumu] Natl Inst Mat Sci, Ctr Basic Res Mat, 1-2-1 Sengen, Tsukuba 3050047, Japan; [Zheng, Xiaoyang; Paik, Jamie] Ecole Polytech Fed Lausanne EPFL, Reconfigurable Robot Lab, CH-1015 Lausanne, Switzerland; [Li, Jingjing] Univ Tsukuba, Grad Sch Comprehens Human Sci, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan; [Guo, Xiaofeng] Southwest Univ Sci & Technol, Sch Mat Sci & Engn, Mianyang 621010, Peoples R China; [Naito, Masanobu] Natl Inst Mat Sci, Res Ctr Macromol & Biomat, 1-2-1 Sengen, Tsukuba 3050047, Japan	National Institute for Materials Science; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Tsukuba; Southwest University of Science & Technology - China; National Institute for Materials Science	Zheng, XY; Watanabe, I (corresponding author), Natl Inst Mat Sci, Ctr Basic Res Mat, 1-2-1 Sengen, Tsukuba 3050047, Japan.; Zheng, XY (corresponding author), Ecole Polytech Fed Lausanne EPFL, Reconfigurable Robot Lab, CH-1015 Lausanne, Switzerland.	xyzheng1995@gmail.com; WATANABE.Ikumu@nims.go.jp		Zheng, Xiaoyang/0000-0003-1452-5855; Jingjing, Li/0000-0002-6524-3105	Japan Society for the Promotion of Science [22KJ0407, JP_EG_special_032023_11]; JSPS Fellows PD; Research Support, University of Tsukuba (RSUT)	Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); JSPS Fellows PD; Research Support, University of Tsukuba (RSUT)	This research was supported by a Grant-in-Aid for JSPS Fellows PD (Grant Number 22KJ0407) and Young Researchers' Exchange Programme-Special 2023 Call Japan of Japanese-Swiss Science and Technology Programme (Project no. JP_EG_special_032023_11). The authors acknowledged the support from the university club, Research Support, University of Tsukuba (RSUT) ().	Alderete NA, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00873-w; Anvekar T, 2022, IEEE COMPUT SOC CONF, P2977, DOI 10.1109/CVPRW56347.2022.00336; Bastek J.-H., 2023, Proc. Natl. Acad. Sci, V5, P1466; Bastek JH, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2111505119; Bauer J, 2017, ADV MATER, V29, DOI 10.1002/adma.201701850; Berger JB, 2017, NATURE, V543, P533, DOI 10.1038/nature21075; Brauer C., 2020, Proc. of the 5th Annual ACM Symp. on Computational Fabrication, P1; Brock A, 2016, Arxiv, DOI arXiv:1608.04236; Buehler MJ, 2022, OXF OPEN MATER SCI, V2, DOI 10.1093/oxfmat/itac010; Chen K, 2019, LECT NOTES COMPUT SC, V11363, P100, DOI 10.1007/978-3-030-20893-6_7; Chen S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25264-5; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Choudhary K, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00734-6; Cui HQ, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000138; Dai H., 2023, Adv. Sci, V10; Dawson-Haggerty, Trimesh; Deng BL, 2022, ADV MATER, V34, DOI 10.1002/adma.202206238; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Divilov S, 2024, NATURE, V625, DOI 10.1038/s41586-023-06786-y; Dong GY, 2019, J ENG MATER-T ASME, V141, DOI 10.1115/1.4040555; Fan JX, 2021, MATER TODAY, V50, P303, DOI 10.1016/j.mattod.2021.04.019; Fan K, 2015, MATER TODAY, V18, DOI 10.1016/j.mattod.2014.07.010; Fang X, 2022, NAT MATER, V21, P869, DOI 10.1038/s41563-022-01269-3; Fernandes MC, 2021, NAT MATER, V20, P237, DOI 10.1038/s41563-020-0798-1; Frenzel T, 2017, SCIENCE, V358, P1072, DOI 10.1126/science.aao4640; Fu Rao., 2022, Adv. Neural Inf. Proc. Syst, V35, P8882; Gao Jun., 2022, Advances In Neural Information Processing Systems, V35, P31841; Ge Q, 2016, SCI REP-UK, V6, DOI 10.1038/srep31110; George EP, 2019, NAT REV MATER, V4, P515, DOI 10.1038/s41578-019-0121-4; Gu DD, 2021, SCIENCE, V372, P932, DOI 10.1126/science.abg1487; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; Ha CS, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-40854-1; Hensel M, 2017, ADV NEUR IN, V30; Hsu Y.-C., 2022, APL Mater, V10, P4; Huh W, 2023, ADV MATER, V35, DOI 10.1002/adma.202211525; Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094; Jia ZA, 2022, ADV MATER, V34, DOI 10.1002/adma.202106259; Jiao PC, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-41679-8; Jin LS, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq3248; Jin TQ, 2023, J MECH PHYS SOLIDS, V179, DOI 10.1016/j.jmps.2023.105398; Jochum FD, 2013, CHEM SOC REV, V42, P7468, DOI 10.1039/c2cs35191a; Jun H, 2023, Arxiv, DOI arXiv:2305.02463; Katiyar NK, 2021, NPG ASIA MATER, V13, DOI 10.1038/s41427-021-00322-y; Kench S, 2021, NAT MACH INTELL, V3, P299, DOI 10.1038/s42256-021-00322-1; Khalid NM, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555392; Koh JS, 2015, SCIENCE, V349, P517, DOI 10.1126/science.aab1637; Kollmann HT, 2020, MATER DESIGN, V196, DOI 10.1016/j.matdes.2020.109098; Kuang X, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201805290; Kumar S, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-0341-6; Lee H, 2024, SCIENCE, V383, P70, DOI 10.1126/science.adh0483; Lee XY, 2021, NAT COMPUT SCI, V1, P229, DOI 10.1038/s43588-021-00045-8; Li MH, 2023, PROC CVPR IEEE, P12642, DOI 10.1109/CVPR52729.2023.01216; Li S, 2019, ANGEW CHEM INT EDIT, V58, P11182, DOI 10.1002/anie.201813402; Li Y, 2021, NAT REV MATER, V6, P488, DOI 10.1038/s41578-021-00283-2; Liu K, 2022, SCIENCE, V377, P975, DOI 10.1126/science.abn1459; Liu ZZ, 2022, Arxiv, DOI arXiv:2209.04145; Liu ZZ, 2022, PROC CVPR IEEE, P17875, DOI 10.1109/CVPR52688.2022.01737; Louie SG, 2021, NAT MATER, V20, P728, DOI 10.1038/s41563-021-01015-1; Malinauskas M, 2016, LIGHT-SCI APPL, V5, DOI 10.1038/lsa.2016.133; Mao YW, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz4169; Maurizi M, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00938-w; Nash Charlie, 2020, INT C MACHINE LEARNI, P7220; Nichol A, 2022, Arxiv, DOI arXiv:2212.08751; Oommen V, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00876-7; Oses C, 2020, NAT REV MATER, V5, P295, DOI 10.1038/s41578-019-0170-8; Overvelde JTB, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10929; Peng B, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-42415-y; Radford A, 2021, PR MACH LEARN RES, V139; Ritchie RO, 2022, NAT MATER, V21, P968, DOI 10.1038/s41563-022-01336-9; Sanghi A, 2022, PROC CVPR IEEE, P18582, DOI 10.1109/CVPR52688.2022.01805; Shang X, 2023, MATER TODAY, V70, P71, DOI 10.1016/j.mattod.2023.09.007; Shen S. C.-y., 2022, COMMUN ENG, V1, P1, DOI [DOI 10.1038/S44172-022-00037-0, 10.1038/s44172-022-00037-0]; Silverberg JL, 2014, SCIENCE, V345, P647, DOI 10.1126/science.1252876; Soukoulis CM, 2011, NAT PHOTONICS, V5, P523, DOI [10.1038/NPHOTON.2011.154, 10.1038/nphoton.2011.154]; Sparks TD, 2020, ANNU REV MATER RES, V50, P27, DOI 10.1146/annurev-matsci-110519-094700; Truby RL, 2016, NATURE, V540, P371, DOI 10.1038/nature21003; Vidyasagar A, 2018, P ROY SOC A-MATH PHY, V474, DOI 10.1098/rspa.2018.0535; Wang YZ, 2022, COMPUT METHOD APPL M, V401, DOI 10.1016/j.cma.2022.115571; Watanabe I, 2012, INT J NUMER METH ENG, V89, P829, DOI 10.1002/nme.3264; Watanabe I, 2019, INT J MECH SCI, V150, P314, DOI 10.1016/j.ijmecsci.2018.10.028; Wei JC, 2023, PROC CVPR IEEE, P16805, DOI 10.1109/CVPR52729.2023.01612; Xia YL, 2021, ADV MATER, V33, DOI 10.1002/adma.202000713; Xu JL, 2023, PROC CVPR IEEE, P20908, DOI 10.1109/CVPR52729.2023.02003; Xu R, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30137-6; Yan DJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14996-5; Yang Z., 2023, ADV MATER, V35; Yang ZZ, 2021, FRONT MATER, V8, DOI 10.3389/fmats.2021.740754; Yin FK, 2023, Arxiv, DOI arXiv:2311.17618; Zeng X., 2022, ADV NEURAL INF PROCE, V35, P10021; Zhakypov Z, 2019, NATURE, V571, P381, DOI 10.1038/s41586-019-1388-8; Zhang CQ, 2016, ADV MATER, V28, P6292, DOI 10.1002/adma.201505555; Zhao SW, 2018, POWDER TECHNOL, V323, P323, DOI 10.1016/j.powtec.2017.10.023; Zhao ZB, 2023, Arxiv, DOI arXiv:2306.17115; Zheng X., 2023, Adv. Mater, V35; Zheng XY, 2024, MATER DESIGN, V237, DOI 10.1016/j.matdes.2023.112548; Zheng XY, 2023, SCI TECHNOL ADV MAT, V24, DOI 10.1080/14686996.2022.2157682; Zheng XY, 2021, MATER DESIGN, V211, DOI 10.1016/j.matdes.2021.110178; Zheng XY, 2021, MATER DESIGN, V198, DOI 10.1016/j.matdes.2020.109313; Zheng XY, 2018, J PHYS CHEM C, V122, P16803, DOI 10.1021/acs.jpcc.8b04062; Zheng XY, 2018, J MATER SCI, V53, P10194, DOI 10.1007/s10853-018-2285-5; Zheng XY, 2016, NAT MATER, V15, P1100, DOI [10.1038/NMAT4694, 10.1038/nmat4694]; Zheng XY, 2014, SCIENCE, V344, P1373, DOI 10.1126/science.1252291; Zhou JX, 2022, COMPOS STRUCT, V302, DOI 10.1016/j.compstruct.2022.116200	103	0	0	9	9	WILEY-V C H VERLAG GMBH	WEINHEIM	POSTFACH 101161, 69451 WEINHEIM, GERMANY	1613-6810	1613-6829		SMALL	Small	2024 MAY 21	2024										10.1002/smll.202402685	http://dx.doi.org/10.1002/smll.202402685		MAY 2024	12	Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	RK9L0	38770745				2024-07-03	WOS:001227675000001
J	Liu, ZS; Courant, R; Kalogeiton, V				Liu, Zhi-Song; Courant, Robin; Kalogeiton, Vicky			FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Early Access						Multimodal learning; Vision plus language; Video understanding; Humor detection		Automatically understanding funny moments (i.e., the moments that make people laugh) when watching comedy is challenging, as they relate to various features, such as body language, dialogues and culture. In this paper, we propose FunnyNet-W, a model that relies on cross- and self-attention for visual, audio and text data to predict funny moments in videos. Unlike most methods that rely on ground truth data in the form of subtitles, in this work we exploit modalities that come naturally with videos: (a) video frames as they contain visual information indispensable for scene understanding, (b) audio as it contains higher-level cues associated with funny moments, such as intonation, pitch and pauses and (c) text automatically extracted with a speech-to-text model as it can provide rich information when processed by a Large Language Model. To acquire labels for training, we propose an unsupervised approach that spots and labels funny audio moments. We provide experiments on five datasets: the sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive experiments and analysis show that FunnyNet-W successfully exploits visual, auditory and textual cues to identify funny moments, while our findings reveal FunnyNet-W's ability to predict funny moments in the wild. FunnyNet-W sets the new state of the art for funny moment detection with multimodal cues on all datasets with and without using ground truth information.	[Liu, Zhi-Song] LUT Univ, Comp Vis & Pattern Recognit Lab, Lappeenranta, Finland; [Courant, Robin; Kalogeiton, Vicky] Ecole Polytech, LIX, IP Paris, Palaiseau, France	Lappeenranta-Lahti University of Technology LUT; Institut Polytechnique de Paris; Ecole Polytechnique	Liu, ZS (corresponding author), LUT Univ, Comp Vis & Pattern Recognit Lab, Lappeenranta, Finland.	zhisong.liu@lut.fi			DIM RFSI grant, Hi!Paris collaborative project grant, ANR projects WhyBehindScenes; DIM RFSI grant [ANR-22-CE23-0007, APATE ANR-22-CE39-0016]; ANR	DIM RFSI grant, Hi!Paris collaborative project grant, ANR projects WhyBehindScenes(Agence Nationale de la Recherche (ANR)); DIM RFSI grant; ANR(Agence Nationale de la Recherche (ANR))	This work is supported by a DIM RFSI grant, a Hi!Paris collaborative project grant, the ANR projects WhyBehindScenes ANR-22-CE23-0007 and APATE ANR-22-CE39-0016, and the HPC resources of IDRIS under the allocation 2022-AD011013951 made by GENCI.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Afouras T., 2020, INTERSPEECH; Annamoradnejad I, 2022, Arxiv, DOI [arXiv:2004.12765, DOI 10.48550/ARXIV.2004.12765]; Bain M, 2023, Arxiv, DOI arXiv:2303.00747; Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1708, DOI 10.1109/ICCV48922.2021.00175; Barral O, 2018, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3157730; Bertasius Gedas, 2021, ICML; Bertero D, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P496; Brown A, 2021, IEEE INT CONF COMP V, P3177, DOI 10.1109/ICCVW54120.2021.00357; Castro S., 2019, ACL; Chen S., 2023, ICML; Chen T, 2020, PR MACH LEARN RES, V119; Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19; Chung SW, 2019, INT CONF ACOUST SPEE, P3965, DOI 10.1109/ICASSP.2019.8682524; Davidov D., 2010, ACL; Défossez A, 2021, Arxiv, DOI [arXiv:1911.13254, DOI 10.48550/ARXIV.1911.13254]; Deng D., 2018, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong JF, 2022, IEEE T PATTERN ANAL, V44, P4065, DOI 10.1109/TPAMI.2021.3059295; Dufour N., 2022, ECCV; Epstein D, 2021, PROC CVPR IEEE, P11189, DOI 10.1109/CVPR46437.2021.01104; Fang H., 2021, arXiv; Farrelly P., 1994, Dumb and Dumber (Film); Gabbay A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3051, DOI 10.1109/ICASSP.2018.8462527; Gabeur Valentin, 2020, ECCV, P214, DOI [DOI 10.48550/ARXIV.2007.10639, DOI 10.1007/978-3-030-58548-8_13]; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Gillick J, 2021, INTERSPEECH, P2481, DOI 10.21437/Interspeech.2021-353; Girdhar R, 2023, Arxiv, DOI arXiv:2305.05665; Godfrey J. J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P517, DOI 10.1109/ICASSP.1992.225858; Gong Y., 2023, ICLR; Guzhov A, 2022, INT CONF ACOUST SPEE, P976, DOI 10.1109/ICASSP43922.2022.9747631; Han T., 2023, ICCV; Hasan MK, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2046; Hasan Md Kamrul, 2021, AAAI; Hazarika D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1122, DOI 10.1145/3394171.3413678; Hinton G., 2002, NEURIPS; Hong J., 2023, ICCV; Huber DM., 2012, Modern recording techniques, DOI [10.4324/9780080928036, DOI 10.4324/9780080928036]; Iashin V, 2020, IEEE COMPUT SOC CONF, P4117, DOI 10.1109/CVPRW50498.2020.00487; Jaegle A, 2021, PR MACH LEARN RES, V139; Kalogeiton V., 2020, BMVC; Kalogeiton V, 2016, IEEE T PATTERN ANAL, V38, P2327, DOI 10.1109/TPAMI.2016.2551239; Kayatani Y., 2021, WACV; Kim M., 2023, ICASSP; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Koepke AS, 2023, IEEE T MULTIMEDIA, V25, P2675, DOI 10.1109/TMM.2022.3149712; Koizumi Y, 2020, Arxiv, DOI arXiv:2007.00222; Korbar B., 2018, COTRAINING AUDIO VID; Lee J.T., 2020, ICLR; Li RJ, 2023, Arxiv, DOI arXiv:2307.11636; Liang ZJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3285; Lin K, 2022, PROC CVPR IEEE, P17928, DOI 10.1109/CVPR52688.2022.01742; Lin Z., 2022, ECCV; Liu X., 2023, INTERSPEECH; Liu Z.S., 2022, ACCV; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Lou SY, 2022, INT CONF ACOUST SPEE, P4793, DOI 10.1109/ICASSP43922.2022.9746786; Mei X., 2022, DCASE; Mesaros A, 2018, IEEE-ACM T AUDIO SPE, V26, P379, DOI 10.1109/TASLP.2017.2778423; Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424; Mohla S, 2020, IEEE COMPUT SOC CONF, P416, DOI 10.1109/CVPRW50498.2020.00054; Morgado P., 2021, CVPR; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Narasimhan M., 2021, NeurIPS; Niizumi D, 2023, IEEE-ACM T AUDIO SPE, V31, P137, DOI 10.1109/TASLP.2022.3221007; Niizumi D, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534474; OpenAI, 2021, ChatGPT: Conversational AI model; Owens A, 2018, LECT NOTES COMPUT SC, V11210, P639, DOI 10.1007/978-3-030-01231-1_39; Paszke A, 2019, ADV NEUR IN, V32; Patro B.N., 2021, WACV; Priyasad D, 2020, INT CONF ACOUST SPEE, P3227, DOI [10.1109/ICASSP40776.2020.9054441, 10.1109/icassp40776.2020.9054441]; Radford A, 2021, PR MACH LEARN RES, V139; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214; Rockwell P, 2000, J PSYCHOLINGUIST RES, V29, P483, DOI 10.1023/A:1005120109296; Rouard S., 2023, ICASSP; Rouditchenko A., 2021, INTERSPEECH; Ryokai K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173932; Sablayrolles A., 2019, ICLR; Saeed A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3875, DOI 10.1109/ICASSP39728.2021.9413528; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Senocak A, 2018, PROC CVPR IEEE, P4358, DOI 10.1109/CVPR.2018.00458; Shen X., 2023, CVPR; Shimasaki A., 2017, C HUM FACT COMP SYST; Singer U, 2022, Arxiv, DOI arXiv:2209.14792; Solaiman I., 2019, Release strategies and the social impacts of language models; Sun C., 2021, ADV NEUR IN, V34, P14200; Tan R., 2021, NEURIPS; Tepperman J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1838; Tian YP, 2018, LECT NOTES COMPUT SC, V11206, P252, DOI 10.1007/978-3-030-01216-8_16; Tong Z., 2022, NEURIPS; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Vaswani A, 2017, ADV NEUR IN, V30; Wang LY, 2021, Arxiv, DOI arXiv:2104.12807; Wang T, 2021, IEEE T CIRC SYST VID, V31, P1890, DOI 10.1109/TCSVT.2020.3014606; Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192; Weller O, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6136; Wu HH, 2022, Arxiv, DOI arXiv:2110.11499; Xin Y., 2023, ICASSP; Xue H., 2023, ICLR; Yang A., 2023, CVPR; Yoon S, 2018, IEEE W SP LANG TECH, P112, DOI 10.1109/SLT.2018.8639583; Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634; Zhou H., 2020, ECCV; Zhu W., 2022, ACL	108	0	0	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	2024 FEB 23	2024										10.1007/s11263-024-02000-2	http://dx.doi.org/10.1007/s11263-024-02000-2		FEB 2024	22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IP2V4		hybrid, Green Submitted			2024-07-03	WOS:001167476700002
J	Walker, N; Lee, SH; Dagdelen, J; Cruse, K; Gleason, S; Dunn, A; Ceder, G; Alivisatos, AP; Persson, KA; Jain, A				Walker, Nicholas; Lee, Sanghoon; Dagdelen, John; Cruse, Kevin; Gleason, Samuel; Dunn, Alexander; Ceder, Gerbrand; Alivisatos, A. Paul; Persson, Kristin A.; Jain, Anubhav			Extracting structured seed-mediated gold nanorod growth procedures from scientific text with LLMs	DIGITAL DISCOVERY			English	Article							SHAPE CONTROL; ASPECT RATIO; NANOPARTICLES	Although gold nanorods have been the subject of much research, the pathways for controlling their shape and thereby their optical properties remain largely heuristically understood. Although it is apparent that the simultaneous presence of and interaction between various reagents during synthesis control these properties, computational and experimental approaches for exploring the synthesis space can be either intractable or too time-consuming in practice. This motivates an alternative approach leveraging the wealth of synthesis information already embedded in the body of scientific literature by developing tools to extract relevant structured data in an automated, high-throughput manner. To that end, we present an approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific text. GPT-3 prompt completions are fine-tuned to predict synthesis templates in the form of JSON documents from unstructured text input with an overall accuracy of 86% aggregated by entities and 76% aggregated by papers. The performance is notable, considering the model is performing simultaneous entity recognition and relation extraction. We present a dataset of 11 644 entities extracted from 1137 papers, resulting in 268 papers with at least one complete seed-mediated gold nanorod growth procedure and outcome for a total of 332 complete procedures. The synthesis of gold nanorods remains largely heuristically understood. Large language models provide a route for extracting their structured synthesis procedures from scientific articles to accelerate investigation into synthesis pathways.	[Walker, Nicholas; Lee, Sanghoon; Dagdelen, John; Gleason, Samuel; Dunn, Alexander; Jain, Anubhav] Lawrence Berkeley Natl Lab, Energy Technol Area, 1 Cyclotron Rd, Berkeley, CA 94720 USA; [Cruse, Kevin; Ceder, Gerbrand; Alivisatos, A. Paul] Lawrence Berkeley Natl Lab, Mat Sci Div, 1 Cyclotron Rd, Berkeley, CA USA; [Persson, Kristin A.] Lawrence Berkeley Natl Lab, Mol Foundry, 1 Cyclotron Rd, Berkeley, CA USA; [Lee, Sanghoon; Dagdelen, John; Cruse, Kevin; Dunn, Alexander; Ceder, Gerbrand; Alivisatos, A. Paul; Persson, Kristin A.] Univ Calif Berkeley, Dept Mat Sci & Engn, 210 Hearst Mem Min Bldg, Berkeley, CA USA; [Gleason, Samuel; Alivisatos, A. Paul] Univ Calif Berkeley, Dept Chem, 419 Latimer Hall, Berkeley, CA USA; [Alivisatos, A. Paul; Persson, Kristin A.] Univ Calif Berkeley, Kavli Energy Nanosci Inst, 101C Campbell Hall, Berkeley, CA USA	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley; University of California System; University of California Berkeley; University of California System; University of California Berkeley	Walker, N; Jain, A (corresponding author), Lawrence Berkeley Natl Lab, Energy Technol Area, 1 Cyclotron Rd, Berkeley, CA 94720 USA.	walkernr@lbl.gov; ajain@lbl.gov	Lee, Sanghoon/JJD-8709-2023; Walker, Nicholas/ABA-9007-2020	Walker, Nicholas/0000-0001-6939-953X; Dunn, Alexander/0000-0002-8567-1879; Persson, Kristin A./0000-0003-2495-5509	U.S. Department of Energy [DE-AC02-05CH11231, KCD2S2]; U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division; Toyota Research Institute through the Accelerated Materials Design and Discovery program [DE-AC02-05CH11231]; U.S. Department of Energy Office of Science User Facility	U.S. Department of Energy(United States Department of Energy (DOE)); U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division(United States Department of Energy (DOE)); Toyota Research Institute through the Accelerated Materials Design and Discovery program; U.S. Department of Energy Office of Science User Facility(United States Department of Energy (DOE))	This work was funded and intellectually led by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division under Contract No. DE-AC02-05CH11231 (D2S2 program KCD2S2). Additional funding used for data set generation via the OpenAI API was provided by Toyota Research Institute through the Accelerated Materials Design and Discovery program. This research used resources of the National Energy Research Scientific Computing Center (NERSC), a U.S. Department of Energy Office of Science User Facility operated under Contract No. DE-AC02-05CH11231. This work also used the Extreme Science and Engineering Discovery Environment (XSEDE) GPU resources, specifically the Bridges-2 supercomputer at the Pittsburgh Supercomputing Center, through allocation TG-DMR970008S.89	Agunloye E, 2018, CHEM ENG SCI, V191, P318, DOI 10.1016/j.ces.2018.06.046; Ba LJ., 2016, CORR; Bhagyaraj S.M., 2018, Synthesis of Inorganic Nanomaterials; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burrows ND, 2017, LANGMUIR, V33, P1891, DOI 10.1021/acs.langmuir.6b03606; Chakraborty I, 2017, CHEM REV, V117, P8208, DOI 10.1021/acs.chemrev.6b00769; Colomban P, 2022, MATERIALS, V15, DOI 10.3390/ma15165747; Corbett Peter, 2018, J Cheminform, V10, P59, DOI 10.1186/s13321-018-0313-8; Corbett P, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-S11-S4; Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6; Cruse Kevin, 2021, Figshare, DOI 10.6084/m9.figshare.16614262.v3; De Souza CD, 2019, J ALLOY COMPD, V798, P714, DOI 10.1016/j.jallcom.2019.05.153; Dieb TM, 2015, BEILSTEIN J NANOTECH, V6, DOI 10.3762/bjnano.6.190; Domingo M, 2018, TOP CATAL, V61, P412, DOI 10.1007/s11244-017-0880-3; Dong YC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50332-8; Dreaden EC, 2012, CHEM SOC REV, V41, P2740, DOI 10.1039/c1cs15237h; Dunn A., 2022, arXiv; Dykman LA, 2011, ACTA NATURAE, V3, P34, DOI 10.32607/20758251-2011-3-2-34-56; Eltyeb S, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/1758-2946-6-17; Eustis S, 2006, CHEM SOC REV, V35, P209, DOI 10.1039/b514191e; Feng LL, 2015, J EXP NANOSCI, V10, P258, DOI 10.1080/17458080.2013.824619; Fischer CC, 2006, NAT MATER, V5, P641, DOI 10.1038/nmat1691; García-Remesal M, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/410294; Gaultois MW, 2013, CHEM MATER, V25, P2911, DOI 10.1021/cm400893e; Gou LF, 2005, CHEM MATER, V17, P3668, DOI 10.1021/cm050525w; Grzelczak M., 2020, Colloidal Synthesis of Plasmonic Nanometals, P197; Hatakeyama-Sato K, 2020, COMMUN MATER, V1, DOI 10.1038/s43246-020-00052-8; He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553; Hu EJ., 2021, Lora: Low-rank adaptation of large language models; Huang XH, 2010, J ADV RES, V1, P13, DOI 10.1016/j.jare.2010.02.002; Huang XH, 2009, ADV MATER, V21, P4880, DOI 10.1002/adma.200802789; huggingface.co, About us; Hulteen JC, 1997, J MATER CHEM, V7, P1075, DOI 10.1039/a700027h; Jain PK, 2008, ACCOUNTS CHEM RES, V41, P1578, DOI 10.1021/ar7002804; Ji X, 2022, CANCER MED-US, V11, P4588, DOI 10.1002/cam4.4831; Kanakarajan KR., 2021, P 20 WORKSH BIOM LAN, P143, DOI [DOI 10.18653/V1/2021.BIONLP-1.16, 10.18653/v1, DOI 10.18653/V1]; Kaul S, 2018, J PHARMACEUTICS, V2018, DOI 10.1155/2018/3420204; Kononova O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102155; Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1; Korvigo I, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0280-0; Krallinger M, 2017, CHEM REV, V117, P7673, DOI 10.1021/acs.chemrev.6b00851; Krallinger M, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/1758-2946-7-S1-S2; Lau M, 2015, PHYS CHEM CHEM PHYS, V17, P29311, DOI 10.1039/c5cp04296h; Leaman R, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/1758-2946-7-S1-S3; Liang ZH, 2019, FRONT ARTIF INTELL, V2, DOI 10.3389/frai.2019.00001; Lohse SE, 2013, CHEM MATER, V25, P1250, DOI 10.1021/cm303708p; Ma M, 2012, BIOMATERIALS, V33, P989, DOI 10.1016/j.biomaterials.2011.10.017; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; Materials Hacking, 2022, Figshare, DOI 10.6084/m9.figshare.19719310.v4; Mukhamedzyanova DF, 2012, J PHYS CHEM C, V116, P11507, DOI 10.1021/jp212367z; Ng SA, 2014, J EXP NANOSCI, V9, P64, DOI 10.1080/17458080.2013.813651; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Pang N., 2019, Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with BERT-CRF Model; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Personick ML, 2013, J AM CHEM SOC, V135, P18238, DOI 10.1021/ja408645b; Radford A., 2018, OpenAI Assets Research Covers; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramos MC, 2023, Arxiv, DOI [arXiv:2304.05341, DOI 10.48550/ARXIV.2304.05341]; Ren F, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aaq1566; Requejo KI, 2017, LANGMUIR, V33, P12681, DOI 10.1021/acs.langmuir.7b02942; Rocktäschel T, 2012, BIOINFORMATICS, V28, P1633, DOI 10.1093/bioinformatics/bts183; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Sandeep K, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5138216; Smith KW, 2016, ACS NANO, V10, P6180, DOI 10.1021/acsnano.6b02194; Sniegula A, 2019, PROCEDIA COMPUT SCI, V160, P260, DOI 10.1016/j.procs.2019.09.466; Sutskever I, 2014, ADV NEUR IN, V27; Szunerits S., 2018, Encyclopedia of Interfacial Chemistry, P500; Szymanski NJ, 2021, CHEM MATER, V33, P4204, DOI 10.1021/acs.chemmater.1c01071; Talapin DV, 2001, J PHYS CHEM B, V105, P12278, DOI 10.1021/jp012229m; Touvron H., 2023, Llama: Open and efficient foundation language models; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Towns J, 2014, COMPUT SCI ENG, V16, P62, DOI 10.1109/MCSE.2014.80; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Vigderman L, 2013, CHEM MATER, V25, P1450, DOI 10.1021/cm303661d; Wang XZ, 2021, JACS AU, V1, P316, DOI 10.1021/jacsau.0c00030; Wang Y, 2016, J NANOSCI NANOTECHNO, V16, P1194, DOI 10.1166/jnn.2016.10637; Wang Z., 2021, Dataset of Solution-based Inorganic Materials Synthesis Recipes Extracted from the Scientific Literature; Wei MZ, 2021, ACS OMEGA, V6, P9188, DOI 10.1021/acsomega.1c00510; Weston L, 2019, J CHEM INF MODEL, V59, P3692, DOI 10.1021/acs.jcim.9b00470; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Yan XL, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16413-3; Zareie MH, 2007, SMALL, V3, P139, DOI 10.1002/smll.200600280; Zhang B., 2019, Root mean square layer normalization	84	4	4	8	8	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2635-098X		DIGIT DISCOV	Digit. Discov.	DEC 4	2023	2	6					1768	1782		10.1039/d3dd00019b	http://dx.doi.org/10.1039/d3dd00019b			15	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Chemistry; Computer Science	Z5RW0		gold			2024-07-03	WOS:001112654200001
C	Ukil, A; Gama, J; Jara, AJ; Marin, L			ACM	Ukil, Arijit; Gama, Joao; Jara, Antonio J.; Marin, Leandro			Knowledge-driven Analytics and Systems Impacting Human Quality of Life- Neurosymbolic AI, Explainable AI and Beyond	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Knowledge management; deep learning; neurosymbolic AI; explainable AI; data privacy; human-centric applications		The management of knowledge-driven artificial intelligence technologies is essential in order to evaluate their impact on human life and society. Social networks and tech use can have a negative impact on us physically, emotionally, socially and mentally. On the other hand, intelligent systems can have a positive effect on people's lives. Currently, we are witnessing the power of large language models (LLMs) like chatGPT and its influence towards the society. The objective of the workshop is to contribute to the advancement of intelligent technologies designed to address the human condition. This could include precise and personalized medicine, better care for elderly people, reducing private data leaks, using AI to manage resources better, using AI to predict risks, augmenting human capabilities, and more. The workshop's objective is to present research findings and perspectives that demonstrate how knowledge-enabled technologies and applications improve human well-being. This workshop indeed focuses on the impacts at different granularity levels made by Artificial Intelligence (AI) research on the micro granular level, where the daily or regular functioning of human life is affected, and also the macro granulate level, where the long-term or far-future effects of artificial intelligence on people's lives and the human society could be pretty high. In conclusion, this workshop explores how AI research can potentially address the most pressing challenges facing modern societies, and how knowledge management can potentially contribute to these solutions.	[Ukil, Arijit] TCS Res, Kolkata, India; [Gama, Joao] Univ Porto, Porto, Portugal; [Jara, Antonio J.] Libelium, Zaragoza, Spain; [Marin, Leandro] Univ Murcia, Murcia, Spain	Universidade do Porto; University of Murcia	Ukil, A (corresponding author), TCS Res, Kolkata, India.	arijit.ukil@tcs.com; jgama@fep.up.pt; jara@ieee.org; leandro@um.es	Jara, Antonio J,/Z-4083-2019	Jara, Antonio J,/0000-0002-2651-6684				Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7; Frankle Jonathan, 2020, INT C MACHINE LEARNI, P3259; Monroe D, 2022, COMMUN ACM, V65, P11, DOI 10.1145/3554918; Puri C, 2016, COMPUT CARDIOL CONF, V43, P1125; Sahu Ishan, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P1655, DOI 10.1109/EMBC48229.2022.9871259; Sahu Ishan, 2021, INT C ADV EL COMP CO, P1, DOI DOI 10.1109/ICAECT49130.2021.9392476; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sangroya Amit, 2022, INT FLAIRS C P, V35; Sen Jaydip, 2009, Proceedings 2009 1st International Conference on Wireless Communication, Vehicular Technology, Information Theory and Aerospace & Electronic Systems Technology (Wireless VITAE), P767, DOI 10.1109/WIRELESSVITAE.2009.5172546; Sen J, 2010, LECT NOTES COMPUT SC, V6018, P277, DOI 10.1007/978-3-642-12179-1_25; Sen Jaydip, 2008, P 16 IEEE INT C NETW, P1, DOI DOI 10.1109/ICON.2008.4772624; Ukil Arijit, 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10096437; Ukil A., 2011, Proceedings of the 2011 IEEE 6th International Workshop on Electronic Design, Test and Application (DELTA 2011), P116, DOI 10.1109/DELTA.2011.29; Ukil A., 2010, Proceedings 2010 Second International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2010), P464, DOI 10.1109/CIMSiM.2010.11; Ukil Arijit, 2010, 2010 1st International Conference on Parallel, Distributed and Grid Computing (PDGC 2010), P344, DOI 10.1109/PDGC.2010.5679976; Ukil A., 2010, 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM 2010), P273, DOI 10.1109/CISIM.2010.5643649; Ukil Arijit, 2010, Proceedings 2010 6th International Conference on Wireless and Mobile Communications (ICWMC 2010), P435, DOI 10.1109/ICWMC.2010.77; Ukil A., 2013, INT J NETWORK SECURI, V5, P11, DOI DOI 10.5121/IJNSA.2013.5502; Ukil A, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4884, DOI 10.1145/3459637.3482033; Ukil A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0277975; Ukil A, 2022, IEEE SENS J, V22, P12269, DOI 10.1109/JSEN.2022.3162691; Ukil A, 2021, IEEE ENG MED BIO, P886, DOI 10.1109/EMBC46164.2021.9630348; Ukil A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3555, DOI 10.1109/ICASSP39728.2021.9414647; Ukil A, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2989, DOI 10.1145/3357384.3358799; Ukil A, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292659; Ukil A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122733; Ukil A, 2016, COMPUT CARDIOL CONF, V43, P281; Ukil A, 2016, INT CON ADV INFO NET, P994, DOI 10.1109/AINA.2016.158; Ukil A, 2016, INT CONF ACOUST SPEE, P6260, DOI 10.1109/ICASSP.2016.7472881; Ukil A, 2014, IEEE CONF COMPUT, P123, DOI 10.1109/INFCOMW.2014.6849186; Ukil Arijit, 2023, PROYECTO INVESTIGACI; Ukil Arijit, 2021, CIKM WORKSH; Ukil Arijit, 2022, 2022 INT JOINT C NEU, P1; Ukil Arijit, 2019, MOBILE SOLUTIONS THE, P145	34	0	0	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5296	5299		10.1145/3583780.3615300	http://dx.doi.org/10.1145/3583780.3615300			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549505075
J	Outeiral, C; Deane, CM				Outeiral, Carlos; Deane, Charlotte M.			Codon language embeddings provide strong signals for use in protein engineering	NATURE MACHINE INTELLIGENCE			English	Article							USAGE; PREDICTION	Protein representations from deep language models have yielded state-of-the-art performance across many tasks in computational protein engineering. In recent years, progress has primarily focused on parameter count, with recent models' capacities surpassing the size of the very datasets they were trained on. Here we propose an alternative direction. We show that large language models trained on codons, instead of amino acid sequences, provide high-quality representations that outperform comparable state-of-the-art models across a variety of tasks. In some tasks, such as species recognition, prediction of protein and transcript abundance or melting point estimation, we show that a language model trained on codons outperforms every other published protein language model, including some that contain over 50 times more parameters. These results indicate that, in addition to commonly studied scale and model complexity, the information content of biological data provides an orthogonal direction to improve the power of machine learning in biology. Machine learning methods have made great advances in modelling protein sequences for a variety of downstream tasks. The representation used as input for these models has been primarily the sequence of amino acids. Outeiral and Deane show that using codon sequences instead can improve protein representations and lead to model performance.	[Outeiral, Carlos; Deane, Charlotte M.] Univ Oxford, Dept Stat, Oxford, England; [Deane, Charlotte M.] Exscientia Ltd, Div Biol, Oxford, England	University of Oxford	Outeiral, C; Deane, CM (corresponding author), Univ Oxford, Dept Stat, Oxford, England.; Deane, CM (corresponding author), Exscientia Ltd, Div Biol, Oxford, England.	carlos@outeiral.net; deane@stats.ox.ac.uk	Outeiral Rubiera, Carlos/L-3025-2018	Outeiral Rubiera, Carlos/0000-0003-1408-5554; Deane, Charlotte/0000-0003-1388-2252	RCUK | Engineering and Physical Sciences Research Council (EPSRC); UK's Engineering and Physical Sciences Research Council [EP/T517811/1, EP/W522582/1]; Engineering and Physical Sciences Research Council Doctoral Prize; Eric and Wendy Schmidt AI in Science Postdoctoral Fellowship; Schmidt Futures programme	RCUK | Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); UK's Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council Doctoral Prize(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Eric and Wendy Schmidt AI in Science Postdoctoral Fellowship; Schmidt Futures programme	We thank O. M. Crook and T. H. Olsen for enlightening discussions. C. O. thanks the UK's Engineering and Physical Sciences Research Council for financial support through an Engineering and Physical Sciences Research Council Doctoral Prize (grant no. EP/T517811/1) and a postdoctoral fellowship (grant no. EP/W522582/1). This project is supported by the Eric and Wendy Schmidt AI in Science Postdoctoral Fellowship, a Schmidt Futures programme.	Bernhofer M, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04873-x; Birdsell JA, 2002, MOL BIOL EVOL, V19, P1181, DOI 10.1093/oxfordjournals.molbev.a004176; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Breuza L, 2016, DATABASE-OXFORD, DOI 10.1093/database/bav120; Chaney JL, 2015, ANNU REV BIOPHYS, V44, P143, DOI 10.1146/annurev-biophys-060414-034333; Chowdhury R, 2022, NAT BIOTECHNOL, V40, P1617, DOI 10.1038/s41587-022-01432-w; Cummins C, 2022, NUCLEIC ACIDS RES, V50, pD106, DOI 10.1093/nar/gkab1051; Dallago C., 2021, bioRxiv, DOI DOI 10.1101/2021.11.09.467890; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhindsa RS, 2022, AM J HUM GENET, V109, P2105, DOI 10.1016/j.ajhg.2022.10.016; Elnaggar A., 2021, IEEE Trans. Patern Anal. Mach. Intell, V14, DOI [10.1109/TPAMI.2021.3095381, DOI 10.1109/TPAMI.2021.3095381]; Ferruz N, 2022, NAT MACH INTELL, V4, P521, DOI 10.1038/s42256-022-00499-z; Fu LM, 2012, BIOINFORMATICS, V28, P3150, DOI 10.1093/bioinformatics/bts565; Galperin MY, 2019, BRIEF BIOINFORM, V20, P1063, DOI 10.1093/bib/bbx117; Hendricks LA, 2021, T ASSOC COMPUT LING, V9, P570, DOI 10.1162/tacl_a_00385; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hoie MH, 2022, NUCLEIC ACIDS RES, V50, pW510, DOI 10.1093/nar/gkac439; Ilzhöfer D, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.1019597; Indriani F, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.885929; Jarzab A, 2020, NAT METHODS, V17, P495, DOI 10.1038/s41592-020-0801-4; Jiang Y, 2023, NAT CHEM, V15, P308, DOI 10.1038/s41557-022-01091-z; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Klarner L., 2022, PROC ICML 2022 2 AI; Kruglyak L, 2022, bioRxiv, DOI [10.1101/2022.07.14.500130, 10.1101/2022.07.14.500130, DOI 10.1101/2022.07.14.500130]; Lin BC, 2023, TRENDS PHARMACOL SCI, V44, P73, DOI 10.1016/j.tips.2022.09.008; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Littmann M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03431-4; Littmann M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80786-0; Liu Y, 2021, ANNU REV BIOCHEM, V90, P375, DOI 10.1146/annurev-biochem-071320-112701; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Marquet C, 2022, HUM GENET, V141, P1629, DOI 10.1007/s00439-021-02411-y; Meier J, 2021, ADV NEUR IN, V34; Nakamura Y, 2000, NUCLEIC ACIDS RES, V28, P292, DOI 10.1093/nar/28.1.292; NELSON DL, 2008, LEHNINGER PRINCIPLES; Nijkamp E, 2022, Arxiv, DOI [arXiv:2206.13517, 10.48550/arXiv.2206.13517]; Nissley DA, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30548-5; Nissley DA, 2014, J AM CHEM SOC, V136, P17892, DOI 10.1021/ja510082j; Notin P, 2022, PR MACH LEARN RES; Outeiral C., 2023, Codon adaptation language model (CaLM); Outeiral C, 2022, BIOINFORMATICS, V38, P1881, DOI 10.1093/bioinformatics/btab881; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Rao RS, 2019, ADV NEUR IN, V32; Reeb J, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3439-4; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Rosenberg AA, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30390-9; Ruffolo JA, 2022, BIOPHYS J, V121, p155A; Sander IM, 2014, J AM CHEM SOC, V136, P858, DOI 10.1021/ja411302m; Saunders R, 2010, NUCLEIC ACIDS RES, V38, P6719, DOI 10.1093/nar/gkq495; SHARP PM, 1987, NUCLEIC ACIDS RES, V15, P1281, DOI 10.1093/nar/15.3.1281; Shen XK, 2022, NATURE, V606, DOI 10.1038/s41586-022-04823-w; Sridharan S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09107-y; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Subramanian K, 2022, MOL BIOL EVOL, V39, DOI 10.1093/molbev/msac157; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Suzek BE, 2007, BIOINFORMATICS, V23, P1282, DOI 10.1093/bioinformatics/btm098; Teufel F, 2022, NAT BIOTECHNOL, V40, P1023, DOI 10.1038/s41587-021-01156-3; Thumuluri V, 2022, NUCLEIC ACIDS RES, V50, pW228, DOI 10.1093/nar/gkac278; Thumuluri V, 2022, BIOINFORMATICS, V38, P941, DOI 10.1093/bioinformatics/btab801; Unsal S, 2022, NAT MACH INTELL, V4, P227, DOI 10.1038/s42256-022-00457-9; Wang M, 2012, MOL CELL PROTEOMICS, V11, P492, DOI 10.1074/mcp.O111.014704; Weissenow K, 2022, STRUCTURE, V30, P1169, DOI 10.1016/j.str.2022.05.001; Wu R, 2022, bioRxiv, DOI [10.1101/2022.07.21.500999, 10.1101/2022.07.21.500999, DOI 10.1101/2022.07.21.500999, 10.1101/2022.07.21.500999v1, DOI 10.1101/2022.07.21.500999V1]	62	1	1	6	6	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	FEB	2024	6	2								10.1038/s42256-024-00791-0	http://dx.doi.org/10.1038/s42256-024-00791-0			13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	JZ6J8		hybrid			2024-07-03	WOS:001177016600002
C	Woodrow, J; Malik, A; Piech, C			Assoc Computing Machinery	Woodrow, Juliette; Malik, Ali; Piech, Chris			AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		LLMs; GPT; Deployed at Scale; Real Time; Style Feedback; CS1		Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this "style feedback" in a timely manner has proven difficult to scale. In this paper, we present our experience deploying a novel, real-time style feedback tool in Code in Place, a large-scale online CS1 course. Our tool is based on the latest breakthroughs in large-language models (LLMs) and was carefully designed to be safe and helpful for students. We used our Real-Time Style Feedback tool (RTSF) in a class with over 8,000 diverse students from across the globe and ran a randomized control trial to understand its benefits. We show that students who received style feedback in real-time were five times more likely to view and engage with their feedback compared to students who received delayed feedback. Moreover, those who viewed feedback were more likely to make significant style-related edits to their code, with over 79% of these edits directly incorporating their feedback. We also discuss the practicality and dangers of LLM-based tools for feedback, investigating the quality of the feedback generated, LLM limitations, and techniques for consistency, standardization, and safeguarding against demographic bias, all of which are crucial for a tool utilized by students.	[Woodrow, Juliette; Malik, Ali; Piech, Chris] Stanford Univ, Stanford, CA 94305 USA	Stanford University	Woodrow, J (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	jwoodrow@stanford.edu; malikali@cs.stanford.edu; piech@cs.stanford.edu						Allamanis M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P38, DOI 10.1145/2786805.2786849; BERRY RE, 1985, COMMUN ACM, V28, P80, DOI 10.1145/2465.2469; Birillo A, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P307, DOI 10.1145/3478431.3499294; Breuker J., 2011, ITICSE 11 P 16 ANN C, P13, DOI [10.1145/1999747.1999754, DOI 10.1145/1999747.1999754, 10.1145/1999747.1999754.]; Charitsis Charis, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P93, DOI 10.1145/3491140.3528269; Charitsis Charis, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P113, DOI 10.1145/3491140.3528272; Chen JC., 2006, Frontiers in Education Conference, 36th Annual, IEEE, P13, DOI [10.1109/FIE.2006.322306, DOI 10.1109/FIE.2006.322306]; Code in Place, 2023, About us; Gomes PHD, 2017, PROC FRONT EDUC CONF; Delev Tomche, 2017, 2017 IEEE Global Engineering Education Conference (EDUCON). Proceedings, P825, DOI 10.1109/EDUCON.2017.7942942; Garg Nupur, 2018, P 18 KOL CALL INT C, DOI DOI 10.1145/3279720.3279736; Glassman EL, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P609, DOI 10.1145/2807442.2807495; Goldstein D.S., 2016, ANN M AM ED RES ASS; Green R, 2011, COMMUN ACM, V54, P57, DOI 10.1145/2043174.2043191; Haendler Thorsten, 2020, Computer Supported Education, P236; Hart R, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P799, DOI 10.1145/3545945.3569817; Haughney K, 2020, EDUC SCI, V10, DOI 10.3390/educsci10030060; HF Canonical Model Maintainers, 2022, distilbert-base-uncased-finetuned-sst-2-english, DOI [10.57967/hf/0181, DOI 10.57967/HF/0181]; Jefferson Thomas, 2024, P 55 ACM TECHN S COM; Keuning Hieke, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P562, DOI 10.1145/3408877.3432526; Keuning H, 2023, Arxiv, DOI arXiv:2304.13451; KULIK JA, 1988, REV EDUC RES, V58, P79, DOI 10.3102/00346543058001079; Liu D, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P666, DOI 10.1145/3287324.3287503; Malik Ali, 2023, Code in Place 2023: Understanding learning and teaching at scale through a massive global classroom; Mengel SA, 1999, PROCEEDINGS OF THE THIRTIETH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P78, DOI 10.1145/384266.299689; Moghadam Joseph Bahman, 2015, Proceedings of the Second (2015) ACM Conference on Learning @ Scale, L@S'15, (New York, NY, USA), P261, DOI 10.1145/2724660.2728672; Nutbrown S, 2016, COMPUT SCI EDUC, V26, P104, DOI 10.1080/08993408.2016.1179865; OpenAI, 2022, GPT-3.5-turbo; Piech Christopher, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P973, DOI 10.1145/3408877.3432562; Rose SP, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312871; Ureel LC, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P738, DOI 10.1145/3287324.3287463; Wiese ES, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P41; Zsigmond Imre, 2020, P 15 INT C EV NOV AP, P556, DOI DOI 10.5220/0009579305560563	33	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							1442	1448		10.1145/3626252.3630773	http://dx.doi.org/10.1145/3626252.3630773			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		Green Submitted			2024-07-03	WOS:001181240800209
J	Gill, J; Chetty, M; Lim, S; Hallinan, J				Gill, Jaskaran; Chetty, Madhu; Lim, Suryani; Hallinan, Jennifer			Knowledge-Based Intelligent Text Simplification for Biological Relation Extraction	INFORMATICS-BASEL			English	Article						sentence simplification; named entity recognition; relation extraction; BioBERT; BERN2	NETWORK	Relation extraction from biological publications plays a pivotal role in accelerating scientific discovery and advancing medical research. While vast amounts of this knowledge is stored within the published literature, extracting it manually from this continually growing volume of documents is becoming increasingly arduous. Recently, attention has been focused towards automatically extracting such knowledge using pre-trained Large Language Models (LLM) and deep-learning algorithms for automated relation extraction. However, the complex syntactic structure of biological sentences, with nested entities and domain-specific terminology, and insufficient annotated training corpora, poses major challenges in accurately capturing entity relationships from the unstructured data. To address these issues, in this paper, we propose a Knowledge-based Intelligent Text Simplification (KITS) approach focused on the accurate extraction of biological relations. KITS is able to precisely and accurately capture the relational context among various binary relations within the sentence, alongside preventing any potential changes in meaning for those sentences being simplified by KITS. The experiments show that the proposed technique, using well-known performance metrics, resulted in a 21% increase in precision, with only 25% of sentences simplified in the Learning Language in Logic (LLL) dataset. Combining the proposed method with BioBERT, the popular pre-trained LLM was able to outperform other state-of-the-art methods.	[Gill, Jaskaran; Chetty, Madhu; Lim, Suryani; Hallinan, Jennifer] Federat Univ, Hlth Innovat & Transformat Ctr, Ballarat, Vic 3842, Australia; [Hallinan, Jennifer] BioThink Pty Ltd, Brisbane, Qld 4020, Australia	Federation University Australia	Gill, J; Chetty, M (corresponding author), Federat Univ, Hlth Innovat & Transformat Ctr, Ballarat, Vic 3842, Australia.	jaskarankaurgill@students.federation.edu.au; madhu.chetty@federation.edu.au; suryani.lim@federation.edu.au; j.hallinan@biothink.net		Gill, Jaskaran Kaur/0000-0003-4829-5971; Chetty, Madhu/0000-0001-7052-0413	Federation University; Health Innovative and Transformation Centre (HITC); Federation University Australia	Federation University; Health Innovative and Transformation Centre (HITC); Federation University Australia	The first author acknowledges the support for the tuition fee waiver scholarship from Federation University and the stipend scholarship from Health Innovative and Transformation Centre (HITC), Federation University Australia.	Ahmed M., 2019, P 2019 IEEE 13 INT C; Algamdi S., 2022, P 2022 IEEE INT C BI; Bach N., 2011, P 5 INT JOINT C NAT; bioinformatics, BioCreative BioCreative VI Challenge and Workshop; Chang YC, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw101; Chatterjee N., 2021, P CTTS SEPLN MAL SPA; Corlan AlexandruDan., Medline trend: automated yearly statistics of pubmed results for any query; Devaraj A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4972, DOI 10.18653/v1/2021.naacl-main.395; Fleuren WWM, 2015, METHODS, V74, P97, DOI 10.1016/j.ymeth.2015.01.015; Fundel K, 2007, BIOINFORMATICS, V23, P365, DOI 10.1093/bioinformatics/btl616; Gamage H.N., 2022, P 2022 IEEE C COMP I; Goyal A, 2018, COMPUT SCI REV, V29, P21, DOI 10.1016/j.cosrev.2018.06.001; Habibi M, 2017, BIOINFORMATICS, V33, pI37, DOI 10.1093/bioinformatics/btx228; Hakenberg J, 2010, IEEE ACM T COMPUT BI, V7, P481, DOI 10.1109/TCBB.2010.51; Honnibal M., 2020, spaCy: Industrial-strength Natural Language Processing in Python; Huang CC, 2016, BRIEF BIOINFORM, V17, P132, DOI 10.1093/bib/bbv024; Jonnalagadda S, 2010, Arxiv, DOI arXiv:1001.4277; Kandji A.K., 2023, P IEEE MULT NAT ENG; Kilicoglu H, 2018, BRIEF BIOINFORM, V19, P1400, DOI 10.1093/bib/bbx057; Kononova O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102155; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Mercatelli D, 2020, BBA-GENE REGUL MECH, V1863, DOI 10.1016/j.bbagrm.2019.194430; Miao Q., 2012, P 26 PAC AS C LANG I; Millstein F., 2020, Natural Language Processing With Python: Natural Language Processing Using NLTK; Morshed N, 2012, BMC SYST BIOL, V6, DOI 10.1186/1752-0509-6-62; Nair A, 2015, MOL BIOSYST, V11, P2449, DOI 10.1039/c5mb00122f; Naseem U, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4010023; Nazaruka E., 2019, P INT C EV NOV APPR; Nedellec C., 2005, P LEARN LANG LOG WOR; Okhapkin V.P., 2020, P FUT TRENDS NETW CO; Ondov B, 2022, J AM MED INFORM ASSN, V29, P1976, DOI 10.1093/jamia/ocac149; Panyam NC, 2018, J BIOMED SEMANT, V9, DOI 10.1186/s13326-017-0168-3; Park G, 2022, 2022 IEEE INT C BIG, P2052; Peng YF, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay073; Peng YF, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-285; Percha B, 2018, BIOINFORMATICS, V34, P2614, DOI 10.1093/bioinformatics/bty114; Pyysalo S, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-50; Ramesh S., 2021, P 6 SOC MED MIN HLTH; Raul Garreta G.M.T.H.G.H., 2017, Scikit-Learn: Machine Learning Simplified: Implement Scikit-Learn into Every Step of the Data Science Pipeline; Siddharthan A., 2014, INT J APPL LINGUISTI, P259, DOI DOI 10.1075/ITL.165.2.06SID; Siddharthan A., 2011, P 13 EUR WORKSH NAT; Simon C, 2019, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-019-2607-x; Singhal A, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw161; Sung M, 2022, BIOINFORMATICS, V38, P4837, DOI 10.1093/bioinformatics/btac598; Vacariu A.V., 2017, A High-Throughput Dependency Parser; Vasiliev Y., 2020, Natural language processing with Python and spaCy: A practical introduction; Wang HL, 2022, NEURAL COMPUT APPL, V34, P4781, DOI 10.1007/s00521-021-06667-3; Wang T., 2016, P AAAI C ART INT PHO; Yang X, 2021, arXiv; Zhang H, 2019, IEEE ACCESS, V7, P89354, DOI 10.1109/ACCESS.2019.2927253; Zhang YJ, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103294; Zhang YJ, 2018, J BIOMED INFORM, V81, P83, DOI 10.1016/j.jbi.2018.03.011; Zhao SD, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa057; Zhou DY, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/298473	55	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9709		INFORMATICS-BASEL	Informatics-Basel	DEC	2023	10	4							89	10.3390/informatics10040089	http://dx.doi.org/10.3390/informatics10040089			20	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	DH2P5		gold			2024-07-03	WOS:001131075800001
J	Ekins, S; Lane, TR; Urbina, F; Puhl, AC				Ekins, Sean; Lane, Thomas R.; Urbina, Fabio; Puhl, Ana C.			<i>In silico</i> ADME/tox comes of age: twenty years later	XENOBIOTICA			English	Review; Early Access						ADME/Tox; in silico; de novo	DRUG DISCOVERY; INDUSTRY PERSPECTIVE; METABOLISM; ABSORPTION; EXCRETION; PROGRESS	In the early 2000s pharmaceutical drug discovery was beginning to use computational approaches for absorption, distribution, metabolism, excretion and toxicity (ADME/Tox, also known as ADMET) prediction. This emphasis on prediction was an effort to reduce the risk of later stage failures from ADME/Tox.Much has been written in the intervening twenty plus years and significant expenditure has occurred in companies developing these in silico capabilities which can be gleaned from publications. It is therefore an appropriate time to briefly reflect on what was proposed then and what the reality is today.20 years ago, we tended to optimise bioactivity and perhaps one ADME/Tox property at a time. Previously pharmaceutical companies needed a whole infrastructure for models - in silico and in vitro experts, IT, champions on a project team, educators and management support. Now we are in the age of generative de novo design where bioactivity and many ADME/Tox properties can be optimised and large language model technologies are available.There are also some challenges such as the focus on very large molecules which may be outside of current ADME/Tox models.We provide an opportunity to look forward with the increasing public data for ADME/Tox as well as expanded types of algorithms available.	[Ekins, Sean; Lane, Thomas R.; Urbina, Fabio; Puhl, Ana C.] Collaborat Pharmaceut Inc, Raleigh, NC 27606 USA; [Ekins, Sean] Collaborat Pharmaceut Inc, 840 Main Campus Dr,Lab 3510, Raleigh, NC 27606 USA		Ekins, S (corresponding author), Collaborat Pharmaceut Inc, 840 Main Campus Dr,Lab 3510, Raleigh, NC 27606 USA.	sean@collaborationspharma.com			NIH funding [2R44GM122196-04A1]	NIH funding(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	We kindly acknowledge NIH funding: 2R44GM122196-04A1 from NIGMS and 2R44ES031038-02A1 from NIEHS.	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Beresford AP, 2002, DRUG DISCOV TODAY, V7, P109; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Butina D, 2002, DRUG DISCOV TODAY, V7, pS83, DOI 10.1016/S1359-6446(02)02288-2; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cronin MTD, 2023, REGUL TOXICOL PHARM, V140, DOI 10.1016/j.yrtph.2023.105385; Di Lascio E, 2023, MOL PHARMACEUT, DOI 10.1021/acs.molpharmaceut.2c00962; Dickins M, 2002, DRUG DISCOV TODAY, V7, P755, DOI 10.1016/S1359-6446(02)02357-7; Ekins S, 2000, J PHARMACOL TOX MET, V44, P251, DOI 10.1016/S1056-8719(00)00109-X; Ekins S, 2001, DRUG METAB DISPOS, V29, P936; Ekins S, 2005, TRENDS PHARMACOL SCI, V26, P202, DOI 10.1016/j.tips.2005.02.006; Ekins S, 2002, J COMPUT AID MOL DES, V16, P381, DOI 10.1023/A:1020816005910; Ekins S, 2001, J PHARMACOL TOX MET, V45, P65, DOI 10.1016/S1056-8719(01)00119-8; Ekins S, 2000, J PHARMACOL TOX MET, V44, P313, DOI 10.1016/S1056-8719(00)00110-6; Ekins S, 2014, J PHARMACOL TOX MET, V69, P115, DOI 10.1016/j.vascn.2013.12.003; Ekins S, 2010, LAB CHIP, V10, P13, DOI 10.1039/b917760b; Esposito C, 2020, J CHEM INF MODEL, V60, P4730, DOI 10.1021/acs.jcim.0c00525; Gill J, 2023, CPT-PHARMACOMET SYST, V12, P122, DOI 10.1002/psp4.12884; Göller AH, 2020, DRUG DISCOV TODAY, V25, P1702, DOI 10.1016/j.drudis.2020.07.001; Gupta RR, 2010, DRUG METAB DISPOS, V38, P2083, DOI 10.1124/dmd.110.034918; Hamzic S, 2022, J CHEM INF MODEL, DOI 10.1021/acs.jcim.2c00412; He JZ, 2022, J CHEMINFORMATICS, V14, DOI 10.1186/s13321-022-00599-3; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Ietswaart R, 2020, EBIOMEDICINE, V57, DOI 10.1016/j.ebiom.2020.102837; Irwin R, 2022, MACH LEARN-SCI TECHN, V3, DOI 10.1088/2632-2153/ac3ffb; Isert C, 2023, ACS OMEGA, V8, P2046, DOI 10.1021/acsomega.2c05607; Janssen APA, 2019, J CHEM INF MODEL, V59, P1221, DOI 10.1021/acs.jcim.8b00640; Kennedy T, 1997, DRUG DISCOV TODAY, V2, P436, DOI 10.1016/S1359-6446(97)01099-4; Komura H, 2021, DRUG DISCOV TODAY, V26, P1275, DOI 10.1016/j.drudis.2021.01.024; Konečny J, 2015, Arxiv, DOI arXiv:1511.03575; Landrum G., 2020, ABOUT US; Lane TR, 2023, ACS CHEM HEALTH SAFE, V30, P83, DOI 10.1021/acs.chas.2c00088; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1; Liu XH, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00561-9; Lombardo F, 2017, J MED CHEM, V60, P9097, DOI 10.1021/acs.jmedchem.7b00487; Lu JY, 2022, J CHEM INF MODEL, V62, P1376, DOI 10.1021/acs.jcim.1c01467; Mansouri K, 2021, ENVIRON HEALTH PERSP, V129, DOI 10.1289/EHP10369; Martin MT, 2022, TOXICOL SCI, V188, P208, DOI 10.1093/toxsci/kfac054; Minerali E, 2020, ACS SUSTAIN CHEM ENG, V8, P16020, DOI 10.1021/acssuschemeng.0c06348; Mittone G, 2023, Arxiv, DOI [arXiv:2302.07684, 10.1145/3543873.3587687, DOI 10.1145/3543873.3587687]; Murad N, 2021, DRUG METAB DISPOS, V49, P169, DOI 10.1124/dmd.120.000202; Muster WG, 2008, DRUG DISCOV TODAY, V13, P303, DOI 10.1016/j.drudis.2007.12.007; Obrezanova O, 2022, MOL PHARMACEUT, DOI 10.1021/acs.molpharmaceut.2c00027; Oldenhof M, 2022, Arxiv, DOI [arXiv:2210.08871, DOI 10.48550/ARXIV.2210.08871]; Pillai N, 2022, DRUG DISCOV TODAY, V27, P2209, DOI 10.1016/j.drudis.2022.03.017; Poongavanam V, 2023, ACS OMEGA, V8, P5901, DOI 10.1021/acsomega.2c07717; Ramesh A., 2022, arXiv; Rao M, 2023, CHEM RES TOXICOL, V36, P1129, DOI 10.1021/acs.chemrestox.3c00098; Rao MS, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00025; Schaduangrat N, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-0408-x; Schmidt F, 2019, CHEM RES TOXICOL, V32, P2338, DOI 10.1021/acs.chemrestox.9b00338; Siramshetty V, 2021, SLAS DISCOV, V26, P1326, DOI 10.1177/24725552211017520; Srivastava Aarohi, 2022, arXiv; Stahl M, 2006, DRUG DISCOV TODAY, V11, P326, DOI 10.1016/j.drudis.2006.02.008; Stoyanova R, 2023, J CHEM INF MODEL, V63, P442, DOI 10.1021/acs.jcim.2c01134; Tysinger EP, 2023, J CHEM INF MODEL, V63, P1734, DOI 10.1021/acs.jcim.2c01618; van de Waterbeemd H, 2003, NAT REV DRUG DISCOV, V2, P192, DOI 10.1038/nrd1032; Van Rompaey D, 2023, MOL PHARMACEUT, V20, P2436, DOI 10.1021/acs.molpharmaceut.2c01048; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Volak LP, 2023, DRUG METAB DISPOS, V51, P792, DOI 10.1124/dmd.122.001154; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Willighagen EL, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0220-4; Winiwarter S, 2019, MOL PHARMACEUT, V16, P4755, DOI 10.1021/acs.molpharmaceut.9b00993; Yu HS, 2003, DRUG DISCOV TODAY, V8, P852, DOI 10.1016/S1359-6446(03)02828-9; Zeller A, 2020, CHEM RES TOXICOL, V33, P10, DOI 10.1021/acs.chemrestox.9b00348; Zhang J, 2021, J CHEM INF MODEL, V61, P2648, DOI 10.1021/acs.jcim.1c00208	67	3	3	3	10	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0049-8254	1366-5928		XENOBIOTICA	Xenobiotica	2023 AUG 8	2023										10.1080/00498254.2023.2245049	http://dx.doi.org/10.1080/00498254.2023.2245049		AUG 2023	7	Pharmacology & Pharmacy; Toxicology	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Toxicology	O5FJ2	37539466				2024-07-03	WOS:001044064100001
J	Birenbaum, M				Birenbaum, Menucha			The Chatbots' Challenge to Education: Disruption or Destruction?	EDUCATION SCIENCES			English	Review						LLMs; ChatGPT; assessment for learning (AfL); improving classroom teaching and learning	IMPACT	The article addresses the positive and negative implications of the growing spread of chatbots based on large language models (LLMs) on instruction, learning, and assessment in education. It is based on extensive conversations with ChatGPT regarding pedagogy-related issues and relevant documents. Discussed are the challenges of chatbots like ChatGPT to educators-on the one hand, their potential to advance deep learning and the roles of the instructor and the school context in causing it to happen. On the other hand, it underscores the pedagogical drawbacks of improper usage of such chatbots and the instructional practices and school contexts that could escalate learning. Three school-culture components, namely classroom learning, teacher professional learning, and school leadership, are the essential aspects of pedagogical approaches that, in a particular constellation, could enhance and, in another, impede a chatbot's potential to advance deep learning. The underlying theoretical framework is assessment-driven, contrasting assessment for learning (AfL) and assessment for grading, distinguishing assessment cultures from testing cultures. Patterns of chatbot usage that align with the principles of each culture are discussed. A sample of quotes from the conversations with ChatGPT is presented to support the insights gained from the chatting experience and the conclusions drawn.	[Birenbaum, Menucha] Tel Aviv Univ, Sch Educ, IL-69978 Tel Aviv, Israel	Tel Aviv University	Birenbaum, M (corresponding author), Tel Aviv Univ, Sch Educ, IL-69978 Tel Aviv, Israel.	biren@tauex.tau.ac.il	Birenbaum, Menucha/HPE-7155-2023	Birenbaum, Menucha/0000-0002-1147-8136				[Anonymous], 2002, ASSESSMENT LEARNING; Barten O., 2023, HOMAN LEVEL IS ARRIV; Birenbaum M., 2018, INTEGRATING MULTIUSE, P240, DOI [10.4018/978-1-5225-3719-9.ch011, DOI 10.4018/978-1-5225-3719-9.CH011]; Birenbaum M., 2014, Designing assessment for quality learning. The enabling power of assessment, V1, P285, DOI 10.1007/978-94-007-5902-2; Birenbaum M., 2011, Studies in Educational Evaluation, V37, P35, DOI [DOI 10.1016/J.STUEDUC.2011.04.001, 10.1016/j.stueduc.2011.04.001]; Birenbaum M, 2016, ENABLING POWER ASSES, V4, P275, DOI 10.1007/978-3-319-39211-0_16; Black P., 1998, Assess Educ. Princ. Pol. Pract., V5, P7, DOI DOI 10.1080/0969595980050102; Butler DL, 2015, J EDUC CHANG, V16, P1, DOI 10.1007/s10833-014-9227-z; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Downes P, 2015, INT J EMOT EDUC, V7, P84, DOI 10.1787/9789264226159-en; Dziri N, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204.07931, 10.48550/arXiv.2204.07931]; Elmore R.F., 2014, INTERNAL COHERENCE A; Fullan M., 2010, ALL SYSTEMS GO CHANG; Fullan M., 2015, ED POLICY ANAL ARCH, V23, P2, DOI [10.14507/epaa.v23.1998, DOI 10.14507/EPAA.V23.1998]; Gardner H., 2006, MULTIPLE INTELLIGENC; Hattie J., 2023, Visible learning: The sequel: A synthesis of over 2,100 meta-analyses relating to achievement, DOI DOI 10.4324/9781003380542; Hattie JAC, 2009, VISIBLE LEARNING: A SYNTHESIS OF OVER 800 META-ANALYSES RELATING TO ACHIEVEMENT, P1; Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687; James M, 2007, IMPROV LEARN TLRP, P1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Lutkevich Ben, 2023, Definition: GPT-3; Marcus G., 2022, ROAD WE CAN TRUST; McLaughlin M., 2006, Building school-based teacher learning communities; Mitleton-Kelly E, 2003, ADV SER MANAGE, P23; Narayan J., 2023, Reuters; Nichols S., 2007, COLLATERAL DAMAGE HI; O'Day JA, 2002, HARVARD EDUC REV, V72, P293, DOI 10.17763/haer.72.3.021q742t8182h238; *OECD, 2016, WHAT MAK SCH LEARN O; Okuda T, 2018, FUJITSU SCI TECH J, V54, P4; OpenAI, 2023, API ED CONS CHATGPT; Opfer VD, 2011, REV EDUC RES, V81, P376, DOI 10.3102/0034654311413609; Ridgway J., 2003, Assessment in Education: Principles, Policy and Practice, V10, P309, DOI DOI 10.1080/0969594032000148163; Ruby D., 2023, ChatGPT Statistics for 2023: Comprehensive Facts and Data; Sarason S.B., 1997, SCH MIGHT BE GOVERNE; Scroxotn A., 2023, COMPUT WKLY; Sergiovanni T.J., 2007, SUPERVISION REDEFINI, V8th; Sharan S, 2008, ORGANIZING SCHOOLS FOR PRODUCTIVE LEARNING, P3; Sharples M., 2022, LSE IMPACT BLOG; SHELLEY M, 1984, J AM STAT ASSOC, V79, P240, DOI 10.2307/2288384; Teoli D., 2022, SWOT analysis; The Age of AI Has Begun GatesNotes, 2023, BLOG BILL GAT; Tishman S., 1995, The thinking Classroom: Learning and Teaching in a Culture of Thinking; Tran AD, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102718; Veglis A., 2019, STUD MEDIA COMMUN, V7, P1, DOI [DOI 10.11114/SMC.V7I1.3986, 10.11114/smc.v7i1.3986]; Vescio V, 2008, TEACH TEACH EDUC, V24, P80, DOI 10.1016/j.tate.2007.01.004; WEINER B, 1985, PSYCHOL REV, V92, P548, DOI 10.1037/0033-295X.92.4.548; William D., 2011, STUD EDUC EVAL, V37, P3, DOI [10.1016/j.stueduc.2011.03.001, DOI 10.1016/J.STUEDUC.2011.03.001]	48	7	8	24	75	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7102		EDUC SCI	Educ. Sci.	JUL	2023	13	7							711	10.3390/educsci13070711	http://dx.doi.org/10.3390/educsci13070711			17	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	N1WT9		gold			2024-07-03	WOS:001035005800001
J	Zhang, TZ; Meng, JJ; Yang, YS; Yu, SD				Zhang, Taozheng; Meng, Jiajian; Yang, Yuseng; Yu, Shaode			Contrastive Learning Penalized Cross-Entropy with Diversity Contrastive Search Decoding for Diagnostic Report Generation of Reduced Token Repetition	APPLIED SCIENCES-BASEL			English	Article						diagnostic report generation; contrastive learning; cross entropy; diversity contrastive search; large language model		Medical imaging description and disease diagnosis are vitally important yet time-consuming. Automated diagnosis report generation (DRG) from medical imaging description can reduce clinicians' workload and improve their routine efficiency. To address this natural language generation task, fine-tuning a pre-trained large language model (LLM) is cost-effective and indispensable, and its success has been witnessed in many downstream applications. However, semantic inconsistency of sentence embeddings has been massively observed from undesirable repetitions or unnaturalness in text generation. To address the underlying issue of anisotropic distribution of token representation, in this study, a contrastive learning penalized cross-entropy (CLpCE) objective function is implemented to enhance the semantic consistency and accuracy of token representation by guiding the fine-tuning procedure towards a specific task. Furthermore, to improve the diversity of token generation in text summarization and to prevent sampling from unreliable tail of token distributions, a diversity contrastive search (DCS) decoding method is designed for restricting the report generation derived from a probable candidate set with maintained semantic coherence. Furthermore, a novel metric named the maximum of token repetition ratio (maxTRR) is proposed to estimate the token diversity and to help determine the candidate output. Based on the LLM of a generative pre-trained Transformer 2 (GPT-2) of Chinese version, the proposed CLpCE with DCS (CLpCEwDCS) decoding framework is validated on 30,000 desensitized text samples from the "Medical Imaging Diagnosis Report Generation" track of 2023 Global Artificial Intelligence Technology Innovation Competition. Using four kinds of metrics evaluated from n-gram word matching, semantic relevance, and content similarity as well as the maxTRR metric extensive experiments reveal that the proposed framework effectively maintains semantic coherence and accuracy (BLEU-1, 0.4937; BLEU-2, 0.4107; BLEU-3, 0.3461; BLEU-4, 0.2933; METEOR, 0.2612; ROUGE, 0.5182; CIDER, 1.4339) and improves text generation diversity and naturalness (maxTRR, 0.12). The phenomenon of dull or repetitive text generation is common when fine-tuning pre-trained LLMs for natural language processing applications. This study might shed some light on relieving this issue by developing comprehensive strategies to enhance semantic coherence, accuracy and diversity of sentence embeddings.	[Zhang, Taozheng; Yu, Shaode] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China; [Zhang, Taozheng; Meng, Jiajian; Yang, Yuseng; Yu, Shaode] Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China	Communication University of China; Communication University of China	Yu, SD (corresponding author), Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.; Yu, SD (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China.	zhangtaozheng@cuc.edu.cn; mengjiajian@cuc.edu.cn; 2020211123015@cuc.edu.cn; yushaodemia@163.com		Yu, Shaode/0000-0002-3412-2159	National Key R&D Program of China	National Key R&D Program of China	No Statement Available	Abanoub G.E., 2023, Intell. Method Syst. Appl, P32, DOI [10.1109/IMSA58542.2023.10217636, DOI 10.1109/IMSA58542.2023.10217636]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Allahyari M, 2017, Arxiv, DOI arXiv:1707.02268; Baevski A, 2022, PR MACH LEARN RES; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen T., 2020, INT CONFMACH LEARN, P1597, DOI DOI 10.48550/ARXIV.2002.05709; Chen WL, 2023, Arxiv, DOI arXiv:2310.14981; Chen ZH, 2024, Arxiv, DOI arXiv:2401.12208; Chuang C.-Y., 2020, NeurIPS, V33, P8765; Chuang YN, 2024, J BIOMED INFORM, V151, DOI 10.1016/j.jbi.2024.104606; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong YH, 2021, PR MACH LEARN RES, V139; Du Z., 2019, GPT2-Chinese: Tools for training GPT2 model in Chinese language; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Ethayarajh K, 2019, Arxiv, DOI [arXiv:1909.00512, DOI 10.18653/V1/D19]; Fan AEL, 2018, Arxiv, DOI arXiv:1805.04833; Fu ZH, 2021, AAAI CONF ARTIF INTE, V35, P12848; Hadsell R, 2006, IEEE C COMP VIS PATT, P1735; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Izmailov P, 2019, Arxiv, DOI arXiv:1803.05407; Jones KS, 2007, INFORM PROCESS MANAG, V43, P1449, DOI 10.1016/j.ipm.2007.03.009; Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012; Kryscinski W, 2019, Arxiv, DOI arXiv:1908.08960; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li BH, 2020, Arxiv, DOI [arXiv:2011.05864, DOI 10.48550/ARXIV.2011.05864]; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Liang XB, 2021, ADV NEUR IN, V34; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Mai Tu-Phuong, 2023, 2023 International Conference on Asian Language Processing (IALP), P118, DOI 10.1109/IALP61005.2023.10337087; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pang T, 2023, BIOMED ENG ONLINE, V22, DOI 10.1186/s12938-023-01113-y; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paulus R, 2017, Arxiv, DOI [arXiv:1705.04304, 10.48550/arXiv.1705.04304]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shao YF, 2022, Arxiv, DOI arXiv:2109.05729; Su Y., 2022, arXiv, DOI DOI 10.48550/ARXIV.2211.10797; Su Y., 2022, Advances in Neural Information Processing Systems, V35, P21548; Su YX, 2022, Arxiv, DOI arXiv:2111.04198; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tan C., 2023, P 2023 INT JOINT C N, P1; Tian SB, 2024, BRIEF BIOINFORM, V25, DOI 10.1093/bib/bbad493; Uc-Cetina V, 2023, ARTIF INTELL REV, V56, P1543, DOI 10.1007/s10462-022-10205-5; Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1; Van Veen D, 2024, NAT MED, DOI 10.1038/s41591-024-02855-5; Vaswani A, 2017, ADV NEUR IN, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang Z., 2023, P 2023 INT JOINT C N, P1; Welleck S, 2019, Arxiv, DOI arXiv:1908.04319; Wu XY, 2023, Arxiv, DOI arXiv:2310.06879; Wu ZF, 2020, Arxiv, DOI arXiv:2012.15466; Xu J., 2022, Advances in Neural Information Processing Systems (NIPS), V35, P3082; Zhang Y., 2023, Journal of Natural Language Processing, V30, P401, DOI 10.5715/jnlp.30.401	58	1	1	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	7							2817	10.3390/app14072817	http://dx.doi.org/10.3390/app14072817			18	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	NN8C3		gold			2024-07-03	WOS:001201210800001
J	Ghersin, I; Weisshof, R; Koifman, E; Bar-Yoseph, H; Ben Hur, D; Maza, I; Hasnis, E; Nasser, R; Ovadia, B; Zur, DD; Waterman, M; Gorelik, Y				Ghersin, Itai; Weisshof, Roni; Koifman, Eduard; Bar-Yoseph, Haggai; Ben Hur, Dana; Maza, Itay; Hasnis, Erez; Nasser, Roni; Ovadia, Baruch; Zur, Dikla Dror; Waterman, Matti; Gorelik, Yuri			Comparative evaluation of a language model and human specialists in the application of European guidelines for the management of inflammatory bowel diseases and malignancies	ENDOSCOPY			English	Article; Early Access								Background Society guidelines on colorectal dysplasia screening, surveillance, and endoscopic management in inflammatory bowel disease (IBD) are complex, and physician adherence to them is suboptimal. We aimed to evaluate the use of ChatGPT, a large language model, in generating accurate guideline-based recommendations for colorectal dysplasia screening, surveillance, and endoscopic management in IBD in line with European Crohn's and Colitis Organization (ECCO) guidelines. Methods 30 clinical scenarios in the form of free text were prepared and presented to three separate sessions of ChatGPT and to eight gastroenterologists (four IBD specialists and four non-IBD gastroenterologists). Two additional IBD specialists subsequently assessed all responses provided by ChatGPT and the eight gastroenterologists, judging their accuracy according to ECCO guidelines. Results ChatGPT had a mean correct response rate of 87.8%. Among the eight gastroenterologists, the mean correct response rates were 85.8% for IBD experts and 89.2% for non-IBD experts. No statistically significant differences in accuracy were observed between ChatGPT and all gastroenterologists ( P =0.95), or between ChatGPT and the IBD experts and non-IBD expert gastroenterologists, respectively ( P =0.82). Conclusions This study highlights the potential of language models in enhancing guideline adherence regarding colorectal dysplasia in IBD. Further investigation of additional resources and prospective evaluation in real-world settings are warranted.	[Ghersin, Itai; Weisshof, Roni; Koifman, Eduard; Bar-Yoseph, Haggai; Ben Hur, Dana; Maza, Itay] Rambam Hlth Care Campus, Dept Gastroenterol, HaAliya HaShniya St 8, IL-3109601 Haifa, Israel; [Bar-Yoseph, Haggai] Israel Inst Technol, Rappaport Fac Med, Technion, Haifa, Israel; Hillel Yaffe Med Ctr, Dept Gastroenterol & Hepatol, Hadera, Israel; Galilee Med Ctr, Dept Gastroenterol, Nahariyya, Israel	Rambam Health Care Campus; Technion Israel Institute of Technology; Rappaport Faculty of Medicine; Western Galilee Hospital	Ghersin, I (corresponding author), Rambam Hlth Care Campus, Dept Gastroenterol, HaAliya HaShniya St 8, IL-3109601 Haifa, Israel.	ighersin@gmail.com						Gordon H, 2023, J CROHNS COLITIS, V17, P827, DOI 10.1093/ecco-jcc/jjac187; Gorelik Y, 2023, GASTROINTEST ENDOSC, V98, DOI 10.1016/j.gie.2023.06.025; Henson JB, 2023, AM J GASTROENTEROL, V118, P2276, DOI 10.14309/ajg.0000000000002397; Jackson B, 2019, ALIMENT PHARM THER, V49, P1040, DOI 10.1111/apt.15209; Jackson BD, 2017, SCAND J GASTROENTERO, V52, P536, DOI 10.1080/00365521.2017.1278785; Kanazaki R, 2023, CROHNS COLITIS 360, V5, DOI 10.1093/crocol/otac018; Kucharzik T, 2021, J CROHNS COLITIS, V15, P879, DOI 10.1093/ecco-jcc/jjab052; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Schulman J, 2022, Introducing chatgpt; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Torres J, 2023, J CROHNS COLITIS, V17, P1, DOI 10.1093/ecco-jcc/jjac115; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Yu N, 2022, INFLAMM BOWEL DIS, V28, P1177, DOI 10.1093/ibd/izab247	13	1	1	2	2	GEORG THIEME VERLAG KG	STUTTGART	RUDIGERSTR 14, D-70469 STUTTGART, GERMANY	0013-726X	1438-8812		ENDOSCOPY	Endoscopy	2024 APR 18	2024										10.1055/a-2289-5732	http://dx.doi.org/10.1055/a-2289-5732		APR 2024	4	Gastroenterology & Hepatology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology; Surgery	OD4G6	38499197				2024-07-03	WOS:001205301700001
J	Gaur, M; Sheth, A				Gaur, Manas; Sheth, Amit			Building trustworthy NeuroSymbolic AI Systems: Consistency, reliability, explainability, and safety	AI MAGAZINE			English	Article								Explainability and Safety engender trust. These require a model to exhibit consistency and reliability. To achieve these, it is necessary to use and analyze data and knowledge with statistical and symbolic AI methods relevant to the AI application--neither alone will do. Consequently, we argue and seek to demonstrate that the NeuroSymbolic AI approach is better suited for making AI a trusted AI system. We present the CREST framework that shows how Consistency, Reliability, user-level Explainability, and Safety are built on NeuroSymbolic methods that use data and knowledge to support requirements for critical applications such as health and well-being. This article focuses on Large Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs have garnered substantial attention from researchers due to their versatility in handling a broad array of natural language processing (NLP) scenarios. As examples, ChatGPT and Google's MedPaLM have emerged as highly promising platforms for providing information in general and health-related queries, respectively. Nevertheless, these models remain black boxes despite incorporating human feedback and instruction-guided tuning. For instance, ChatGPT can generate unsafe responses despite instituting safety guardrails. CREST presents a plausible approach harnessing procedural and graph-based knowledge within a NeuroSymbolic framework to shed light on the challenges associated with LLMs.	[Gaur, Manas] Univ Maryland Baltimore Cty, Baltimore, MD 21250 USA; [Sheth, Amit] Univ South Carolina, AI Inst, Columbia, SC USA; Univ Maryland Baltimore Cty, Baltimore, MD USA	University System of Maryland; University of Maryland Baltimore County; University of South Carolina System; University of South Carolina Columbia; University System of Maryland; University of Maryland Baltimore County	Gaur, M (corresponding author), Univ Maryland Baltimore Cty, Baltimore, MD 21250 USA.	manas@umbc.edu	Sheth, Amit/ABC-4600-2020	Sheth, Amit/0000-0002-0021-5293; Gaur, Manas/0000-0002-5411-2230	National Science Foundation [2335967]; NSF EAGER award; UMBC Summer Faculty Fellowship	National Science Foundation(National Science Foundation (NSF)); NSF EAGER award(National Science Foundation (NSF)); UMBC Summer Faculty Fellowship	We express our gratitude to Drs Amitava Das and Valerie L. Shalin for their invaluable reviews and insightful suggestions on the manuscript. We acknowledge partial support from the NSF EAGER award #2335967 and the UMBC Summer Faculty Fellowship. Any opinions, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF or UMBC.	Agarwal A, 2023, LECT NOTES COMPUT SC, V13981, P331, DOI 10.1007/978-3-031-28238-6_22; Allaway S., 2022, P 2022 C EMP METH NA, P2407, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.154; Alyssa, 2021, CAN BENZ CAUS HALL; [Anonymous], NAT SCI FDN MAIN PLA; Bai Y., 2022, Constitutional ai: Harmlessness from ai feedback; Baker D., 2023, EVALUATING SOCIAL IM; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Bostrom N., 2016, CONTROL PROBLEM EXCE, P308; Bowman, 2023, 8 THINGS KNOW LARGE; Brun I., 2023, JERUSALEM POST  1001; Bumgardner V. K., 2023, LOCAL LARGE LANGUAGE; Chang D, 2020, 19TH SIGBIOMED WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2020), P167, DOI 10.18653/v1/2020.bionlp-1.18; Chapman-Rounds M, 2021, AAAI CONF ARTIF INTE, V35, P11433; Chen A., 2023, PURR EFFICIENTLY EDI; Cui L., 2023, SIRENS SONG AI OCEAN; Daws, 2021, AI NEWS; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; Du K, 2023, ACM TRANS MANAG INF, V14, DOI 10.1145/3580480; Dubois Y., 2023, ALPACAFARM SIMULATIO; Gao LY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P16477; Gaur M., 2022, THESIS; Gaur M., 2023, U.S. Patent Application, Patent No. [17/817,778, 17817778]; Gaur M, 2022, AAAI CONF ARTIF INTE, P10672; Gaur M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P753, DOI 10.1145/3269206.3271732; Gautam S, 2017, INDIAN J PSYCHIAT, V59, pS34, DOI 10.4103/0019-5545.196973; Glaese A., 2022, IMPROVING ALIGNMENT; Gupta S., 2022, P 8  WORKSH COMP LIN, P137; Guu K., 2020, INT C MACHINE LEARNI, P3929; Hagendorff T., 2023, MACHINE PSYCHOL INVE; Holohan M., 2023, TODAY; Honovich O, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P161; Hubinger E., 2019, RISKS LEARNED OPTIMI; Iglesias D. D. C., 2022, EVALUATING SUSCEPTIB; Jiang DF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P14165; Jiang ZB, 2021, T ASSOC COMPUT LING, V9, P962, DOI 10.1162/tacl_a_00407; Jie R., 2023, ARXIV; Jin Di., 2023, FINDINGS ASS COMPUTA, P11882; Joyce DW, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00751-9; Kamdar M. R., 2019, KNOWLEDGE GRAPH BASE; Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Kwon M., 2022, 11 INT C LEARN REPR; Lakkaraju H., 2022, RETHINKING EXPLAINAB; Leahy C., 2023, COGNITIVE EMULATION; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li L., GIVE US FACTS ENHANC; Liang Percy., 2023, Transactions on Machine Learning Research; Lin S., 2022, TEACHING MODELS EXPR; Liu Y., 2023, GPTEVAL NLG EVALUATI; LMSYS Org, 2023, VIC OP SOURC CHATB I; Longpre S., 2023, P 40 INT C MACH LEAR, P22631; Lyu X., 2023, IMPROVING RETRIEVAL; MacDonald B. A., 1991, Knowledge Acquisition, V3, P381, DOI 10.1016/S1042-8143(05)80026-3; Manakul P., 2023, CORR, P9004, DOI DOI 10.18653/V1/2023.EMNLP-MAIN.557; Menick J., 2022, TEACHING LANGUAGE MO; Ngo R., 2022, ALIGNMENT PROBLEM DE; Pasunuru R., 2022, P 2022 C EMP METH NA, P11699, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.804; Penedo G., 2023, REFINEDWEB DATASET F; Perez Ethan., 2022, EMNLP, P3419, DOI 10.18653/v1/2022.emnlp-main.225; Perri L., 2023, 4 EXCITING NEW TREND; Petroni F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2523; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Pustejovsky, 2020, ACS 2020 ANN C ADV C; Quach K., 2023, REGISTER; Raffel C, 2020, J MACH LEARN RES, V21; Rawte V., 2023, P 2023 C EMP METH NA, P2541; Rebedea T., 2023, P 2023 C EMP METH NA; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Roy K., 2023, P AAAI S SERIES ASS, DOI [10.1609/aaaiss.v1i1.27494, DOI 10.1609/AAAISS.V1I1.27494]; Sarkar S, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1229805; Sellam T., 2020, P 58 ANN M ASS COMP, P788; Shafran, 2022, 11 INT C LEARN REPR; Shah R., 2022, GOAL MISGENERALIZATI; Shah Raj Sanjay, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555640; Shen L., 2022, P 2022 C EMP METH NA, P3178; Sheth A, 2023, IEEE INTELL SYST, V38, P56, DOI 10.1109/MIS.2023.3268724; Sheth A, 2021, IEEE INTERNET COMPUT, V25, P19, DOI 10.1109/MIC.2021.3101919; Sheth A, 2019, IEEE INTERNET COMPUT, V23, P54, DOI 10.1109/MIC.2019.2960071; Shi N., 2023, EVALUATING MORAL BEL; Shin R., 2023, FORTUNE; Shiri A, 2024, PROCEEDINGS OF 7TH JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA, CODS-COMAD 2024, P592, DOI 10.1145/3632410.3632494; Slack D, 2023, NAT MACH INTELL, V5, P873, DOI 10.1038/s42256-023-00692-8; So David R., 2021, Primer: Searching for efficient transformers for language modeling; Sun J., 2023, THINK ON GRAPH DEEP; Topp CW, 2015, PSYCHOTHER PSYCHOSOM, V84, DOI 10.1159/000376585; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Tyagi N., 2023, ARXIV; Tyagi N, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P4320, DOI 10.1145/3583780.3615273; Wang P., 2023, LARGE LANGUAGE MODEL; Wang X, 2022, 11 INT C LEARN REPR; Wang Y., 2023, PANDALM AUTOMATIC EV; Ward C., 2023, ADHD TEST; Wei JH, 2022, PR MACH LEARN RES; Yang, 2022, ADV NEURAL INFORM PR, V35, P7755; Yang C., 2023, LARGE LANGUAGE MODEL; Yao X., 2023, ARXIV; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Yu Y., 2023, ARXIV; Zhang, 2023, DO ANYTHING NOW CHAR; Zhang T., 2019, INT C LEARNING REPRE; Zheng L., 2023, NEURIPS 2023 DAT BEN; Ziems C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3755	102	0	0	9	9	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602	2371-9621		AI MAG	AI Mag.	MAR	2024	45	1			SI		139	155		10.1002/aaai.12149	http://dx.doi.org/10.1002/aaai.12149		FEB 2024	17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LM0L4		hybrid, Green Submitted			2024-07-03	WOS:001161686400001
J	Benz, C; Riefle, L; Satzger, G				Benz, Carina; Riefle, Lara; Satzger, Gerhard			User Engagement and Beyond: A Conceptual Framework for Engagement in Information Systems Research	COMMUNICATIONS OF THE ASSOCIATION FOR INFORMATION SYSTEMS			English	Article						Engagement; Conceptual Framework; Human-Computer Interaction; Literature Review	CONSUMER BRAND ENGAGEMENT; CUSTOMER ENGAGEMENT; STUDENT ENGAGEMENT; ACTOR ENGAGEMENT; WORK ENGAGEMENT; EMPLOYEE ENGAGEMENT; JOB DEMANDS; RELATIONSHIPS MATTER; SCHOOL ENGAGEMENT; SCALE DEVELOPMENT	Humans are considered "engaged" once they invest personal resources such as energy, time, or attention beyond a required level. This engagement state occurs when feeling connected to another actor or an object. In information systems (IS) research, engagement is recognized in the concept of 'user engagement', which has for many years successfully been employed to understand interaction patterns and user reactions. However, as IS artifacts evolve, we observe contemporary phenomena that are no longer covered by the existing concept: For one, IS have developed from passive resources (such as websites) to human -like actors (such as conversational, nowadays often large language model (LLM)-based, agents) so that a pure 'user engagement' perspective does not capture new affordances for engagement with active counterparts. Secondly, IS increasingly act as intermediaries into other engagement objects (e.g., organizations) that are the ultimate target of engagement. Thus, IS research may benefit from a broader perspective on engagement. Our work systematically draws on a structured literature review across adjacent academic disciplines and an in-depth qualitative analysis to develop a more comprehensive conceptual framework for engagement. With this framework, we contribute a refined and broadened conceptual base for engagement and discuss how it can inform future IS research.	[Benz, Carina; Riefle, Lara; Satzger, Gerhard] Karlsruhe Inst Technol, Inst Informat Syst & Mkt, Karlsruhe Serv Res & Innovat Hub, Karlsruhe, Germany	Helmholtz Association; Karlsruhe Institute of Technology	Benz, C (corresponding author), Karlsruhe Inst Technol, Inst Informat Syst & Mkt, Karlsruhe Serv Res & Innovat Hub, Karlsruhe, Germany.	carina.benz@kit.edu						Alexander MJ, 2018, J SERV MANAGE, V29, P333, DOI 10.1108/JOSM-08-2016-0237; Appleton JJ, 2008, PSYCHOL SCHOOLS, V45, P369, DOI 10.1002/pits.20303; Ayyagari R, 2011, MIS QUART, V35, P831; Bakker A.B., 2008, Career Development International, V13, P209, DOI [DOI 10.1108/13620430810870476, 10.1108/13620430810870476]; Bakker AB, 2008, WORK STRESS, V22, P187, DOI 10.1080/02678370802393649; Bakker Arnold B., 2007, J. Manag. Psychol., V22, P309, DOI [DOI 10.1108/02683940710733115, 10.1108/02683940710733115]; Benbya H, 2021, J ASSOC INF SYST, V22, P281, DOI 10.17705/1jais.00662; Benke I, 2022, COMPUT HUM BEHAV, V129, DOI 10.1016/j.chb.2021.107122; Brodie RJ, 2019, J SERV RES-US, V22, P173, DOI 10.1177/1094670519827385; Brodie RJ, 2013, J BUS RES, V66, P105, DOI 10.1016/j.jbusres.2011.07.029; Brodie RJ, 2011, J SERV RES-US, V14, P252, DOI 10.1177/1094670511411703; Carini RM, 2006, RES HIGH EDUC, V47, P1, DOI 10.1007/s11162-005-8150-9; Cechetti NP, 2019, TELEMAT INFORM, V41, P126, DOI 10.1016/j.tele.2019.04.007; Chapman P., 1999, HAWAII INT C SYSTEM; Chatterjee S, 2021, INFORM SYST J, V31, P550, DOI 10.1111/isj.12320; Chen C., 2019, CiteSpace101-6.4 node selection; Chen CM, 2010, J AM SOC INF SCI TEC, V61, P1386, DOI 10.1002/asi.21309; Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317; Choi BCK, 2006, CLIN INVEST MED, V29, P351; Christian MS, 2011, PERS PSYCHOL, V64, P89, DOI 10.1111/j.1744-6570.2010.01203.x; Chu SC, 2011, INT J ADVERT, V30, P47, DOI 10.2501/IJA-30-1-047-075; Chung M, 2020, J BUS RES, V117, P587, DOI 10.1016/j.jbusres.2018.10.004; Cooper N., 1988, Knowledge in Society, V1, P105; Crawford ER, 2010, J APPL PSYCHOL, V95, P834, DOI 10.1037/a0019364; Csikszentmihalyi M., 1991, FLOW PSYCHOL OPTIMAL, DOI DOI 10.5465/AMR.1991.4279513; Dessart L, 2016, J MARKET MANAG-UK, V32, P399, DOI 10.1080/0267257X.2015.1130738; Dessart L, 2015, J PROD BRAND MANAG, V24, P28, DOI 10.1108/JPBM-06-2014-0635; Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478; Doherty K, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234149; Dwivedi A, 2015, J RETAIL CONSUM SERV, V24, P100, DOI 10.1016/j.jretconser.2015.02.007; Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009; Flavián C, 2019, J TRAVEL TOUR MARK, V36, P847, DOI 10.1080/10548408.2019.1618781; France C, 2016, J BRAND MANAG, V23, P119, DOI 10.1057/bm.2016.4; Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059; Gangale F, 2013, ENERG POLICY, V60, P621, DOI 10.1016/j.enpol.2013.05.031; Gnewuch U., 2017, 38 INT C INFORM SYST; Hakanen JJ, 2006, J SCHOOL PSYCHOL, V43, P495, DOI 10.1016/j.jsp.2005.11.001; Harter JK, 2002, J APPL PSYCHOL, V87, P268, DOI 10.1037/0021-9010.87.2.268; Hemmer P., 2023, 28 INT C INTELLIGENT; Hollebeek LD, 2014, J PROD BRAND MANAG, V23, P62, DOI 10.1108/JPBM-06-2013-0332; Hollebeek LD, 2011, J MARKET MANAG-UK, V27, P785, DOI 10.1080/0267257X.2010.500132; Hollebeek LD, 2022, J SERV RES-US, V25, P328, DOI 10.1177/1094670520977680; Hollebeek LD, 2018, J SERV MARK, V32, P95, DOI 10.1108/JSM-11-2017-0390; Hollebeek LD, 2014, J INTERACT MARK, V28, P149, DOI 10.1016/j.intmar.2013.12.002; Hwang MI, 1999, INFORM MANAGE-AMSTER, V35, P229, DOI 10.1016/S0378-7206(98)00092-5; Jaakkola E, 2019, IND MARKET MANAG, V80, P27, DOI 10.1016/j.indmarman.2018.06.014; Jaakkola E, 2014, J SERV RES-US, V17, P247, DOI 10.1177/1094670514529187; Junco R, 2011, J COMPUT ASSIST LEAR, V27, P119, DOI 10.1111/j.1365-2729.2010.00387.x; Junco R, 2012, COMPUT EDUC, V58, P162, DOI 10.1016/j.compedu.2011.08.004; Jussupow E, 2022, BUS INFORM SYST ENG+, V64, P293, DOI 10.1007/s12599-022-00750-2; KAHN WA, 1990, ACAD MANAGE J, V33, P692, DOI 10.5465/256287; Kim YH, 2013, DECIS SUPPORT SYST, V56, P361, DOI 10.1016/j.dss.2013.07.002; Klein J.T., 2010, The Oxford handbook of interdisciplinarity, P15; Klem AM, 2004, J SCHOOL HEALTH, V74, P262, DOI 10.1111/j.1746-1561.2004.tb08283.x; Kuh GD, 2008, J HIGH EDUC-UK, V79, P540, DOI 10.1353/jhe.0.0019; Kunz W, 2017, J SERV MARK, V31, P161, DOI 10.1108/JSM-10-2016-0352; Larsen KRT, 2003, J MANAGE INFORM SYST, V20, P169, DOI 10.1080/07421222.2003.11045768; Laumer S, 2016, J INF TECHNOL-UK, V31, P67, DOI 10.1057/jit.2015.17; Laurel Brenda., 2013, Computers as Theatre, VSecond; Lehmann J., 2012, P 20 INT C USER MODE; Li LP, 2018, J SERV MANAGE, V29, P491, DOI 10.1108/JOSM-08-2016-0235; Li LP, 2017, J SERV THEOR PRACT, V27, P738, DOI 10.1108/JSTP-04-2016-0066; Louwerse MM, 2005, APPL COGNITIVE PSYCH, V19, P693, DOI 10.1002/acp.1117; Macey WH, 2008, IND ORGAN PSYCHOL-US, V1, P3, DOI 10.1111/j.1754-9434.2007.0002.x; Maedche A, 2019, BUS INFORM SYST ENG+, V61, P535, DOI 10.1007/s12599-019-00600-8; Marks HM, 2000, AM EDUC RES J, V37, P153, DOI 10.3102/00028312037001153; Merriam-Webster, 2019, Affection; Merriam-Webster, 2019, Cooperation; Mollen A, 2010, J BUS RES, V63, P919, DOI 10.1016/j.jbusres.2009.05.014; O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801; O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004; O'Brien HL, 2010, J AM SOC INF SCI TEC, V61, P50, DOI 10.1002/asi.21229; O'Brien HL, 2010, INTERACT COMPUT, V22, P344, DOI 10.1016/j.intcom.2010.04.001; Oh J, 2018, COMMUN RES, V45, P737, DOI 10.1177/0093650215600493; Pansari A, 2017, J ACAD MARKET SCI, V45, P294, DOI 10.1007/s11747-016-0485-6; Peng RZ, 2020, INT J INTERCULT REL, V74, P58, DOI 10.1016/j.ijintrel.2019.10.008; Pfeuffer N, 2019, BUS INFORM SYST ENG+, V61, P523, DOI 10.1007/s12599-019-00599-y; Prior DD, 2016, MARKETING THEOR, V16, P533, DOI 10.1177/1470593116649792; Putnam R., 2000, BOWLING ALONE COLLAP; Reeve J, 2004, MOTIV EMOTION, V28, P147, DOI 10.1023/B:MOEM.0000032312.95499.6f; Rich BL, 2010, ACAD MANAGE J, V53, P617, DOI 10.5465/AMJ.2010.51468988; Riedl R, 2020, DATA BASE ADV INF SY, V51, P13; Riedl R, 2014, J ASSOC INF SYST, V15, pI; Riefle L., 2022, 17 INT C WIRTSCHAFTS; Riefle L., 2023, P 31 EUROPEAN C INFO; Roorda DL, 2011, REV EDUC RES, V81, P493, DOI 10.3102/0034654311421793; Rzepka C., 2018, 39 INT C INFORM SYST; Saks AM, 2019, J ORGAN EFF-PEOPLE P, V6, P19, DOI 10.1108/JOEPP-06-2018-0034; Saks Alan M., 2006, Journal of Managerial Psychology, V21, P600, DOI DOI 10.1108/02683940610690169; Salanova M, 2005, J APPL PSYCHOL, V90, P1217, DOI 10.1037/0021-9010.90.6.1217; Salda├a┬▒a J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004; Sashi CM, 2012, MANAGE DECIS, V50, P253, DOI 10.1108/00251741211203551; Schaufeli VB, 2019, EUR J PSYCHOL ASSESS, V35, P577, DOI 10.1027/1015-5759/a000430; Schaufeli W.B., 2017, Journal of Well-Being Assessment, V1, P9, DOI DOI 10.1007/S41543-017-0001-X; Schaufeli WB, 2002, J CROSS CULT PSYCHOL, V33, P464, DOI 10.1177/0022022102033005003; Schaufeli WB, 2004, J ORGAN BEHAV, V25, P293, DOI 10.1002/job.248; Schaufeli WB, 2006, EDUC PSYCHOL MEAS, V66, P701, DOI 10.1177/0013164405282471; Schaufeli WB, 2009, J ORGAN BEHAV, V30, P893, DOI 10.1002/job.595; Schemmer Max, 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P410, DOI 10.1145/3581641.3584066; Schofer E, 2001, AM SOCIOL REV, V66, P806, DOI 10.2307/3088874; Schuetz S, 2020, J ASSOC INF SYST, V21, P460, DOI 10.17705/1jais.00608; Seeber I, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103174; Shernoff DJ, 2003, SCHOOL PSYCHOL QUART, V18, P158, DOI 10.1521/scpq.18.2.158.21860; Sigerson L, 2018, COMPUT HUM BEHAV, V83, P87, DOI 10.1016/j.chb.2018.01.023; Sinoo C, 2018, PATIENT EDUC COUNS, V101, P1248, DOI 10.1016/j.pec.2018.02.008; SKINNER EA, 1993, J EDUC PSYCHOL, V85, P571, DOI 10.1037/0022-0663.85.4.571; Skinner E, 2008, J EDUC PSYCHOL, V100, P765, DOI 10.1037/a0012840; So KKF, 2014, J HOSP TOUR RES, V38, P304, DOI 10.1177/1096348012451456; Söllner M, 2016, EUR J INFORM SYST, V25, P274, DOI 10.1057/ejis.2015.17; Sonnentag S, 2003, J APPL PSYCHOL, V88, P518, DOI 10.1037/0021-9010.88.3.518; Sprott D, 2009, J MARKETING RES, V46, P92, DOI 10.1509/jmkr.46.1.92; Storbacka K, 2019, IND MARKET MANAG, V80, P4, DOI 10.1016/j.indmarman.2019.04.007; Storbacka K, 2016, J BUS RES, V69, P3008, DOI 10.1016/j.jbusres.2016.02.034; Szafir D., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'12), DOI [10.1145/2207676.2207679, DOI 10.1145/2207676.2207679]; Talwar S, 2011, SCI PUBL POLICY, V38, P379, DOI 10.3152/030234211X12960315267615; Tarafdar M, 2018, J ASSOC INF SYST, V19, P523, DOI 10.17705/1jais.00500; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; van den Broek E, 2021, MIS QUART, V45, P1557, DOI 10.25300/MISQ/2021/16559; van Doorn J, 2010, J SERV RES-US, V13, P253, DOI 10.1177/1094670510375599; Vassilakopoulou P, 2023, EUR J INFORM SYST, V32, P10, DOI 10.1080/0960085X.2022.2096490; Verhoef PC, 2010, J SERV RES-US, V13, P247, DOI 10.1177/1094670510375461; Verleye K, 2014, J SERV RES-US, V17, P68, DOI 10.1177/1094670513494015; Vivek SD, 2012, J MARKET THEORY PRAC, V20, P127, DOI 10.2753/MTP1069-6679200201; Vössing M, 2022, INFORM SYST FRONT, V24, P877, DOI 10.1007/s10796-022-10284-3; vom Brocke J., 2009, Reconstructing the Giant: On the Importance of Rigour in Documenting the Literature Search Process; Weber-Guskar E, 2021, ETHICS INF TECHNOL, V23, P601, DOI 10.1007/s10676-021-09598-8; Webster J, 2002, MIS QUART, V26, pXIII; Wirtz J, 2013, J SERV MANAGE, V24, P223, DOI 10.1108/09564231311326978; Ye N, 2020, J CLEAN PROD, V272, DOI 10.1016/j.jclepro.2020.122679; You S, 2018, J ASSOC INF SYST, V19, P377, DOI 10.17705/1jais.00496; Zhang P., 2009, AIS T HUMAN COMPUTER, V1, P55, DOI [10.17705/1thci.00007, DOI 10.17705/1THCI.00007]	131	0	0	5	5	ASSOC INFORMATION SYSTEMS	ATLANTA	GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA	1529-3181			COMMUN ASSOC INF SYS	Commun. Assoc. Inf. Syst.		2024	54									10.17705/1CAIS.05412	http://dx.doi.org/10.17705/1CAIS.05412			31	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	NE3G8		Bronze			2024-07-03	WOS:001198732300006
J	Younis, HA; Eisa, TAE; Nasser, M; Sahib, TM; Noor, AA; Alyasiri, OM; Salisu, S; Hayder, IM; Younis, HA				Younis, Hussain A.; Eisa, Taiseer Abdalla Elfadil; Nasser, Maged; Sahib, Thaeer Mueen; Noor, Ameen A.; Alyasiri, Osamah Mohammed; Salisu, Sani; Hayder, Israa M.; Younis, Hameed AbdulKareem			A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges	DIAGNOSTICS			English	Review						ChatGPT; cellular imaging; medicine; healthcare; image; dental; disease; radiology and sonar; pharmaceutical	CHATGPT; EDUCATION; PERFORMANCE; CHATBOTS; AI	Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI's potential by generating human-like text through prompts. ChatGPT's adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI's role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI's transformative potential in healthcare, highlighting ChatGPT's versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT's diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.	[Younis, Hussain A.] Univ Basrah, Coll Educ Women, Basrah 61004, Iraq; [Eisa, Taiseer Abdalla Elfadil] King Khalid Univ, Dept Informat Syst, Girls Sect, Mahayil 62529, Saudi Arabia; [Nasser, Maged] Univ Teknol PETRONAS, Comp & Informat Sci Dept, Seri Iskandar 32610, Malaysia; [Sahib, Thaeer Mueen] Al Furat Al Awsat Tech Univ, Kufa Tech Inst, Kufa 54001, Iraq; [Noor, Ameen A.] Univ Almustansirya, Coll Educ, Comp Sci Dept, Baghdad, Iraq; [Alyasiri, Osamah Mohammed] Al Furat Al Awsat Tech Univ, Karbala Tech Inst, Karbala, Iraq; [Salisu, Sani] Fed Univ Dutse, Dept Informat Technol, Dutse 720101, Nigeria; [Hayder, Israa M.] Southern Tech Univ, Qurna Tech Inst, Basrah 61016, Iraq; [Younis, Hameed AbdulKareem] Univ Basrah, Coll Comp Sci & Informat Technol, Dept Cybersecur, Basrah 61016, Iraq	University of Basrah; King Khalid University; Universiti Teknologi Petronas; Al-Furat Al-Awsat Technical University; Al-Furat Al-Awsat Technical University; Southern Technical University; University of Basrah	Younis, HA (corresponding author), Univ Basrah, Coll Educ Women, Basrah 61004, Iraq.	hussain.younis@uobasrah.edu.iq; teisa@kku.edu.sa; maged.nasser@utp.edu.my; kin.thr@atu.edu.iq; a.ameen63@uomustansiriyah.edu.iq; osama.alyasiri@atu.edu.iq; sani.salisu@fud.edu.ng; israa.mh@stu.edu.iq; hameed.younis@uobasrah.edu.iq	Alyasiri, Osamah Mohammed/ACT-2561-2022; NASSER, MAGED/KFA-1475-2024; Eisa, Taiseer/GWC-1476-2022	Alyasiri, Osamah Mohammed/0000-0002-2345-2443; salisu, sani/0000-0001-9196-4507; A. Younis, Hussain/0000-0002-5042-4990	Deanship of Scientific Research at King Khalid University;  [RGP2/52/44]	Deanship of Scientific Research at King Khalid University; 	The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University for funding this work through a large group Research Project under grant number (RGP2/52/44).	Abouammoh N., 2023, Cold Spring Harb. Lab, DOI [10.1101/2023.07.13.23292624, DOI 10.1101/2023.07.13.23292624]; Agathokleous E, 2023, SCI TOTAL ENVIRON, V888, DOI 10.1016/j.scitotenv.2023.164154; Alberts IL, 2023, EUR J NUCL MED MOL I, V50, P1549, DOI 10.1007/s00259-023-06172-w; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Asch D.A., 2023, NEJM Catal, P1; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Busch F, 2023, MED SCI EDUC, V33, P1007, DOI 10.1007/s40670-023-01815-x; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cheng KM, 2023, ANN BIOMED ENG, V51, P1130, DOI 10.1007/s10439-023-03203-3; Choudhary OP, 2023, TRAVEL MED INFECT DI, V54, DOI 10.1016/j.tmaid.2023.102615; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Cohen IG, 2023, AM J BIOETHICS, V23, P8, DOI 10.1080/15265161.2023.2233357; Corsello A, 2023, CHILDREN-BASEL, V10, DOI 10.3390/children10040757; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Currie G, 2023, RADIOGRAPHY, V29, P792, DOI 10.1016/j.radi.2023.05.011; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Ellaway RH, 2023, ADV HEALTH SCI EDUC, V28, P659, DOI 10.1007/s10459-023-10257-4; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Giannos P, 2023, BMJ NEUROL OPEN, V5, DOI 10.1136/bmjno-2023-000451; Gilson A, 2023, JMIR MED EDUC, V9, DOI 10.2196/50336; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Götz S, 2018, 21ST ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS: COMPANION PROCEEDINGS (MODELS-COMPANION '18), P22, DOI 10.1145/3270112.3270117; Grabb D, 2023, ACAD PSYCHIATR, V47, P439, DOI 10.1007/s40596-023-01791-9; Guo AA, 2023, MED TEACH, V45, P1063, DOI 10.1080/0142159X.2023.2198094; Hisan U. K., 2023, Journal of Pedagogy and Education Science, V2, P71, DOI [DOI 10.56741/JPES.V2I01.302, 10.56741/jpes.v2i01.302]; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Hosseini M, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0292216; Hügle T, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003105; Huh S, 2023, J KOREAN MED ASSOC, V66, P218, DOI 10.5124/jkma.2023.66.4.218; Janamala V, 2023, ANN BIOMED ENG, V51, P2337, DOI 10.1007/s10439-023-03257-3; Janamla V, 2023, ANN BIOMED ENG, V51, P2359, DOI 10.1007/s10439-023-03267-1; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Kavian JA, 2023, AM SURGEON, V89, P5102, DOI 10.1177/00031348231175454; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Liao WX, 2023, Arxiv, DOI [arXiv:2304.11567, 10.48550/ARXIV.2304.11567, DOI 10.48550/ARXIV.2304.11567]; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu XN, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04314-0; Lukac S, 2023, ARCH GYNECOL OBSTET, V308, P1831, DOI 10.1007/s00404-023-07130-5; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Mijwil M., 2023, Mesopotamian J Cyber Secur, P18, DOI DOI 10.58496/MJCS/2023/004; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Mohammed A.O., 2023, ChatGPT Revisited: Using ChatGPT-4 for Finding References and Editing Language in Medical Scientific Articles, DOI [10.2139/ssrn.4621581, DOI 10.2139/SSRN.4621581]; Mohammed O., 2023, British Journal of Applied Linguistics, V3, P34; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Mufti F., 2023, Southeast Eur. J. Soft Comput, V12, P13, DOI [10.21533/scjournal, DOI 10.21533/SCJOURNAL]; Ning GC, 2023, BIOSCI TRENDS, V17, P230, DOI 10.5582/bst.2023.01119; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Polonsky MJ, 2023, AUSTRALAS MARK J, V31, P91, DOI 10.1177/14413582231167882; Pozzessere C, 2023, TOMOGRAPHY, V9, P717, DOI 10.3390/tomography9020057; Pratim P., 2023, Ann. Biomed. Eng, V51, P2097, DOI [10.1007/s10439-023-03239-5, DOI 10.1007/S10439-023-03239-5]; Rahimzadeh V, 2023, AM J BIOETHICS, V23, P17, DOI 10.1080/15265161.2023.2233358; Rodigin A., 2023, Eur. J. Transl. Clin. Med, V6, P5, DOI [10.31373/ejtcm/162647, DOI 10.31373/EJTCM/162647]; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sahib Thaeer Mueen, 2023, Mesopotamian Journal of Big Data, V2023, P107, DOI [10.58496/MJBD/2023/014, DOI 10.58496/MJBD/2023/014]; Salisu S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13152593; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Santandreu-Calonge D, 2023, PROF INFORM, V32, DOI 10.3145/epi.2023.mar.19; Sedaghat S, 2023, CLIN MED, V23, P278, DOI 10.7861/clinmed.2023-0078; Sedaghat S, 2023, ANN BIOMED ENG, V51, P2657, DOI 10.1007/s10439-023-03287-x; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Sohail S.S., 2023, SSRN, DOI [10.2139/ssrn.4413921, DOI 10.2139/SSRN.4413921]; Surovková J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085212; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; Urban R, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12071710; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Verhoeven F, 2023, ANN RHEUM DIS, V82, P1015, DOI 10.1136/ard-2023-223936; Wang HY, 2023, DRUG SAFETY, V46, P711, DOI 10.1007/s40264-023-01315-2; Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Wen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1207; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Yang JC, 2023, Arxiv, DOI [arXiv:2306.06767, 10.1016/j.metrad.2023.100007, DOI 10.1016/J.METRAD.2023.100007]; Younis HA, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12132864; Younis HA, 2023, PROCESSES, V11, DOI 10.3390/pr11051488; Zhu ZL, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231184091	93	10	10	56	56	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	JAN	2024	14	1							109	10.3390/diagnostics14010109	http://dx.doi.org/10.3390/diagnostics14010109			38	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	EM1N7	38201418	gold			2024-07-03	WOS:001139253400001
J	Temsah, R; Altamimi, I; Alhasan, K; Temsah, MH; Jamal, A				Temsah, Reem; Altamimi, Ibraheem; Alhasan, Khalid; Temsah, Mohamad-Hani; Jamal, Amr			Healthcare's New Horizon With ChatGPT's Voice and Vision Capabilities: A Leap Beyond Text	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Editorial Material						dalle-3; user-centric interface; image recognition; voice recognition technology; artificial intelligence chatgpt-4		The integration of artificial intelligence (AI) in healthcare is responsible for a paradigm shift in medicine. OpenAI's recent augmentation of their Generative Pre-trained Transformer (ChatGPT) large language model (LLM) with voice and image recognition capabilities (OpenAI, Delaware) presents another potential transformative tool for healthcare. Envision a healthcare setting where professionals engage in dynamic interactions with ChatGPT to navigate the complexities of atypical medical scenarios. In this innovative landscape, practitioners could solicit ChatGPT's expertise for concise summarizations and insightful extrapolations from a myriad of web-based resources pertaining to similar medical conditions. Furthermore, imagine patients using ChatGPT to identify abnormalities in medical images or skin lesions. While the prospects are diverse, challenges such as suboptimal audio quality and ensuring data security necessitate cautious integration in medical practice. Drawing insights from previous ChatGPT iterations could provide a prudent roadmap for navigating possible challenges. This editorial explores some possible horizons and potential hurdles of ChatGPT's enhanced functionalities in healthcare, emphasizing the importance of continued refinements and vigilance to maximize the benefits while minimizing risks. Through collaborative efforts between AI developers and healthcare professionals, another fusion of AI and healthcare can evolve into enriched patient care and enhanced medical experience.	[Temsah, Reem] Alfaisal Univ, Coll Pharm, Riyadh, Saudi Arabia; [Altamimi, Ibraheem; Temsah, Mohamad-Hani; Jamal, Amr] King Saud Univ, Coll Med, Riyadh, Saudi Arabia; [Alhasan, Khalid] King Saud Univ, Pediat Nephrol, Riyadh, Saudi Arabia; [Alhasan, Khalid] King Faisal Specialist Hosp & Res Ctr, Solid Organ Transplant Ctr Excellence, Riyadh, Saudi Arabia; [Temsah, Mohamad-Hani; Jamal, Amr] King Saud Univ, Evidence Based Hlth Care & Knowledge Translat Res, Riyadh, Saudi Arabia	Alfaisal University; King Saud University; King Saud University; King Faisal Specialist Hospital & Research Center; King Saud University	Temsah, MH (corresponding author), King Saud Univ, Coll Med, Riyadh, Saudi Arabia.; Temsah, MH (corresponding author), King Saud Univ, Evidence Based Hlth Care & Knowledge Translat Res, Riyadh, Saudi Arabia.	temsah1@yahoo.com	Jamal, Amr A/B-9495-2009	Jamal, Amr A/0000-0002-4051-6592				Jadczyk T, 2021, J MED INTERNET RES, V23, DOI 10.2196/22959; McCabe R, 2018, TOP COGN SCI, V10, P409, DOI 10.1111/tops.12337; openai, 2023, ChatGPT can now see, hear, and speak; Paul M, 2023, ICT EXPRESS, V9, P571, DOI 10.1016/j.icte.2023.02.007; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812	5	8	8	10	11	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	OCT 22	2023	15	10							e47469	10.7759/cureus.47469	http://dx.doi.org/10.7759/cureus.47469			5	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Z1FJ4	37873042	Green Published, gold			2024-07-03	WOS:001109606100017
J	Karra, R; Lasfar, A				Karra, Rachid; Lasfar, Abdelali			Impact of Data Quality on Question Answering System Performances	INTELLIGENT AUTOMATION AND SOFT COMPUTING			English	Article						DataOps; data quality; QA system; nlp; context simplification	SIMPLIFICATION	In contrast with the research of new models, little attention has been paid to the impact of low or high-quality data feeding a dialogue system. The present paper makes the first attempt to fill this gap by extending our previous work on question-answering (QA) systems by investigating the effect of misspelling on QA agents and how context changes can enhance the responses. Instead of using large language models trained on huge datasets, we propose a method that enhances the model's score by modifying only the quality and structure of the data feed to the model. It is important to identify the features that modify the agent performance because a high rate of wrong answers can make the students lose their interest in using the QA agent as an additional tool for distant learning. The results demonstrate the accuracy of the proposed context simplification exceeds 85%. These findings shed light on the importance of question data quality and context complexity construct as key dimensions of the QA system. In conclusion, the experimental results on questions and contexts showed that controlling and improving the various aspects of data quality around the QA system can significantly enhance his robustness and performance.	[Karra, Rachid; Lasfar, Abdelali] Mohammed V Univ Rabat, Mohammadia Sch Engineers, LASTIMI Lab, Rabat, Morocco	Mohammed V University in Rabat	Karra, R (corresponding author), Mohammed V Univ Rabat, Mohammadia Sch Engineers, LASTIMI Lab, Rabat, Morocco.	rachid.karra@est.um5.ac.ma						Allen D, 2009, SYSTEM, V37, P585, DOI 10.1016/j.system.2009.09.004; [Anonymous], 2018, P 6 INT C LEARN REPR; Azeroual O, 2018, SCIENTOMETRICS, V115, P1271, DOI 10.1007/s11192-018-2735-5; Bradbury B. L, 2020, INTERACTIVE J GLOBAL, P80; Brill E, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P286, DOI 10.3115/1075218.1075255; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chaabi Y., 2021, J KING SAUD UNIV-COM, V34; Costa P, 2018, J SCI TECHNOL ARTS, V10, P59, DOI 10.7559/citarj.v10i3.563; Crossley SA, 2007, MOD LANG J, V91, P15, DOI 10.1111/j.1540-4781.2007.00507.x; Crossley SA, 2012, LANG TEACH RES, V16, P89, DOI 10.1177/1362168811423456; Davis J., 2016, EFFECTIVE DEVOPS, V2nd, P37; Deutsch A, 2007, J COMPUT SYST SCI, V73, P442, DOI 10.1016/j.jcss.2006.10.006; Devlin J., 2018, BERT PRE TRAINING DE; Guo JF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102067; Jia R, 2017, P 2017 C EMPIRICAL M, P2021, DOI [10.18653/v1/D17-1215, DOI 10.18653/V1/D17-1215, DOI 10.18653/V1/D17-1215.URL]; Jin T, 2018, TESOL QUART, V52, P457, DOI 10.1002/tesq.434; Karra Rachid, 2021, Digital Technologies and Applications. Proceedings of ICDTA 21. Lecture Notes in Networks and Systems (LNNS 211), P655, DOI 10.1007/978-3-030-73882-2_59; Lee Y., 2006, JOURNEY DATA QUALITY; Liu Z., 2020, PROC 2020 C EMPIRICA; Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Niu T., 2018, P 22 C COMP NAT LANG, P486, DOI DOI 10.18653/V1/K18-1047; Obasa A.I., 2016, INDIAN J SCI TECHNOL, V8, P1; Osman A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215516; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Rapanta C., 2020, Postdigit. Sci. Educ, P923, DOI [DOI 10.1007/S42438-020-00155-Y, 10.1007/s42438-020-00155-y]; Re C., 2019, ARXIV190905372; Renggli C., 2021, IEEE DATA ENG B, V44, P11; Robinson D., 2007, ASPECT ORIENTED PROG; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Savary Agata., 2001, Implementation and Application of Automata, P251; Schmarje L., 2021, P NEURIPS DAT AI WOR, P7; Trewin S, 2021, DATAOPS REVOLUTION D, V1st, P115; Vilares J, 2016, INFORM PROCESS MANAG, V52, P646, DOI 10.1016/j.ipm.2015.12.010; Vilares J, 2011, INFORM PROCESS MANAG, V47, P263, DOI 10.1016/j.ipm.2010.08.004; Wambsganss T., 2021, 29 EUROPEAN C INFORM, P1; Wang BN, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P85, DOI 10.1145/3331184.3331190; Wang R. Y., 1996, Journal of Management Information Systems, V12, P5; Wint ZZ, 2017, 2017 TWELFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P209, DOI 10.1109/ICDIM.2017.8244677; Young DJ, 1999, MOD LANG J, V83, P350, DOI 10.1111/0026-7902.00027; Zhang WE, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3374217	41	1	1	2	16	TECH SCIENCE PRESS	HENDERSON	871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA	1079-8587	2326-005X		INTELL AUTOM SOFT CO	Intell. Autom. Soft Comput.		2023	35	1					335	349		10.32604/iasc.2023.026695	http://dx.doi.org/10.32604/iasc.2023.026695			15	Automation & Control Systems; Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science	2J7AN		hybrid			2024-07-03	WOS:000815805200007
J	Safranek, C; Liu, C; Richmond, R; Boyi, T; Rimmer, R; Manes, RP				Safranek, Conrad; Liu, Christina; Richmond, Rhys; Boyi, Trinithas; Rimmer, Ryan; Manes, R. Peter			ChatGPT for Automated Cross-Checking of Authors' Conflicts of Interest Against Industry Payments	OTOLARYNGOLOGY-HEAD AND NECK SURGERY			English	Article						artificial intelligence; biologics; ChatGPT; CMS openpayments; conflict of interest; data analysis automation; large language models; nasal polyps; pharmaceutical funding		Objective. The Centers for Medicare & Medicaid Services "OpenPayments" database tracks industry payments to US physicians to improve research conflicts of interest (COIs) transparency, but manual cross-checking of articles' authors against this database is labor-intensive. This study aims to assess the potential of large language models (LLMs) like ChatGPT to automate COI data analysis in medical publications. Study Design. An observational study analyzing the accuracy of ChatGPT in automating the cross-checking of COI disclosures in medical research articles against the OpenPayments database. Setting. Publications regarding Food and Drug Administration-approved biologics for chronic rhinosinusitis with nasal polyposis: omalizumab, mepolizumab, and dupilumab. Methods. First, ChatGPT evaluated author affiliations from PubMed to identify those based in the United States. Second, for author names matching 1 or multiple payment recipients in OpenPayments, ChatGPT undertook a comparative analysis between author affiliation and OpenPayments recipient metadata. Third, ChatGPT scrutinized full article COI statements, producing an intricate matrix of disclosures for each author against each relevant company (Sanofi, Regeneron, Genentech, Novartis, and GlaxoSmithKline). A random subset of responses was manually checked for accuracy. Results. In total, 78 relevant articles and 294 unique US authors were included, leading to 980 LLM queries. Manual verification showed accuracies of 100% (200/200; 95% confidence interval [CI]: 98.1%-100%) for country analysis, 97.4% (113/116; 95% CI: 92.7%-99.1%) for matching author affiliations with OpenPayments metadata, and 99.2% (1091/1100; 95% CI: 98.5%-99.6%) for COI statement data extraction. Conclusion. LLMs have robust potential to automate author-company-specific COI cross-checking against the OpenPayments database. Our findings pave the way for streamlined, efficient, and accurate COI assessment that could be widely employed across medical research.	[Safranek, Conrad; Liu, Christina; Richmond, Rhys; Boyi, Trinithas; Rimmer, Ryan; Manes, R. Peter] Yale Sch Med, Dept Surg, Div Otolaryngol, New Haven, CT USA; [Safranek, Conrad] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT 06519 USA; [Manes, R. Peter] Yale Univ, Sch Med, Div Otolaryngol, 800 Howard Ave, New Haven, CT 06519 USA	Yale University; Yale University; Yale University	Manes, RP (corresponding author), Yale Univ, Sch Med, Div Otolaryngol, 800 Howard Ave, New Haven, CT 06519 USA.	rpeter.manes@yale.edu		Liu, Christina/0000-0001-9380-1007; Boyi, Trinithas/0000-0003-3336-5893; Safranek, Conrad/0000-0003-1985-9432				[Anonymous], 2024, OPEN PAYMENTS DATASE; Bauchner H, 2018, JAMA-J AM MED ASSOC, V320, P2315, DOI 10.1001/jama.2018.17593; Cooper RJ, 2006, J GEN INTERN MED, V21, P1248, DOI 10.1111/j.1525-1497.2006.00598.x; Cuomo RE, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0252656; Dunn Adam G, 2016, Res Integr Peer Rev, V1; Kirschner NM, 2014, ANN INTERN MED, V161, P519, DOI 10.7326/M14-1303; Lelegren MJ, 2022, IMMUNOTHERAPY-UK, V14, P655, DOI 10.2217/imt-2021-0310; OpenAI, 2024, API REFERENCE GUIDE; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sayers E., 2022, ENTREZ PROGRAMMING U; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Smith JE, 2021, NEUROLOGY, V96, pE1913, DOI 10.1212/WNL.0000000000011701; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wayant C, 2018, JAMA ONCOL, V4, P1426, DOI 10.1001/jamaoncol.2018.3738; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776	15	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0194-5998	1097-6817		OTOLARYNG HEAD NECK	Otolaryngol. Head Neck Surg.	JUN	2024	170	6			SI		1512	1518		10.1002/ohn.720	http://dx.doi.org/10.1002/ohn.720		MAR 2024	7	Otorhinolaryngology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology; Surgery	SO7F2	38488302				2024-07-03	WOS:001185424200001
J	Mou, XY; He, CL; Tan, LW; Yu, JJ; Liang, HD; Zhang, JY; Tian, Y; Yang, YF; Xu, T; Wang, Q; Cao, M; Chen, ZJ; Hu, CP; Wang, XD; Liu, QY; Wu, HY				Mou, Xinyu; He, Cuilin; Tan, Liwei; Yu, Junjie; Liang, Huadong; Zhang, Jianyu; Tian, Yan; Yang, Yu-Fang; Xu, Ting; Wang, Qing; Cao, Miao; Chen, Zijiao; Hu, Chuan-Peng; Wang, Xindi; Liu, Quanying; Wu, Haiyan			ChineseEEG: A Chinese Linguistic Corpora EEG Dataset for Semantic Alignment and Neural Decoding	SCIENTIFIC DATA			English	Article							LANGUAGE; SYSTEM	An Electroencephalography (EEG) dataset utilizing rich text stimuli can advance the understanding of how the brain encodes semantic information and contribute to semantic decoding in brain-computer interface (BCI). Addressing the scarcity of EEG datasets featuring Chinese linguistic stimuli, we present the ChineseEEG dataset, a high-density EEG dataset complemented by simultaneous eye-tracking recordings. This dataset was compiled while 10 participants silently read approximately 13 hours of Chinese text from two well-known novels. This dataset provides long-duration EEG recordings, along with pre-processed EEG sensor-level data and semantic embeddings of reading materials extracted by a pre-trained natural language processing (NLP) model. As a pilot EEG dataset derived from natural Chinese linguistic stimuli, ChineseEEG can significantly support research across neuroscience, NLP, and linguistics. It establishes a benchmark dataset for Chinese semantic decoding, aids in the development of BCIs, and facilitates the exploration of alignment between large language models and human cognitive processes. It can also aid research into the brain's mechanisms of language processing within the context of the Chinese natural language.	[Mou, Xinyu; Yu, Junjie; Zhang, Jianyu; Wang, Xindi; Liu, Quanying] Southern Univ Sci & Technol, Dept Biomed Engn, Shenzhen, Peoples R China; [He, Cuilin; Tan, Liwei; Tian, Yan; Wu, Haiyan] Univ Macau, Fac Social Sci, Ctr Cognit & Brain Sci, Dept Psychol, Taipa, Macau, Peoples R China; [Liang, Huadong] iFLYTEK Co LTD, AI Res Inst, Hefei, Peoples R China; [Yang, Yu-Fang] Free Univ Berlin, Dept Educ & Psychol, Div Expt Psychol & Neuropsychol, Berlin, Germany; [Xu, Ting] Child Mind Inst, Ctr Integrat Dev Neurosci, New York, NY USA; [Wang, Qing] Shanghai Jiao Tong Univ, Shanghai Mental Hlth Ctr, Sch Med, 600 S Wanping Rd, Shanghai 200030, Peoples R China; [Cao, Miao] Swinburne Univ Technol, Australian Natl Imaging Facil & Swinburne Neuroima, Melbourne, Vic, Australia; [Chen, Zijiao] Natl Univ Singapore, Ctr Cognit & Cognit, Yong Loo Lin Sch Med, Singapore, Singapore; [Hu, Chuan-Peng] Nanjing Normal Univ, Sch Psychol, Nanjing, Peoples R China	Southern University of Science & Technology; University of Macau; Free University of Berlin; Shanghai Jiao Tong University; Swinburne University of Technology; National University of Singapore; Nanjing Normal University	Liu, QY (corresponding author), Southern Univ Sci & Technol, Dept Biomed Engn, Shenzhen, Peoples R China.; Wu, HY (corresponding author), Univ Macau, Fac Social Sci, Ctr Cognit & Brain Sci, Dept Psychol, Taipa, Macau, Peoples R China.	liuqy@sustech.edu.cn; haiyanwu@um.edu.mo	Yang, Yu-Fang/ABE-6811-2021	Yang, Yu-Fang/0000-0001-9089-6020; Xu, Ting/0000-0002-0065-3832	Natural Science Foundation of Guangdong Province (Guangdong Natural Science Foundation); Chrissy Chen Institute(TCCI) [0127/2020/A3, 0041/2022/A]; Science and Technology Development Fund (FDCT) of Macau [2021A1515012509]; Natural Science Foundation of Guangdong Province [SGDX2020110309280100]; Shenzhen-Hong Kong-Macao Science and Technology Innovation Project [SRG2020-00027-ICI]; SRG of University of Macau	Natural Science Foundation of Guangdong Province (Guangdong Natural Science Foundation)(National Natural Science Foundation of Guangdong Province); Chrissy Chen Institute(TCCI); Science and Technology Development Fund (FDCT) of Macau; Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Shenzhen-Hong Kong-Macao Science and Technology Innovation Project; SRG of University of Macau	This work was mainly supported by the MindD project of Tianqiao and Chrissy Chen Institute(TCCI), the Science and Technology Development Fund (FDCT) of Macau [0127/2020/A3, 0041/2022/A], the Natural Science Foundation of Guangdong Province(2021A1515012509), Shenzhen-Hong Kong-Macao Science and Technology Innovation Project (Category C) (SGDX2020110309280100), and the SRG of University of Macau (SRG2020-00027-ICI). We also thank all research assistants who provided general support in participant recruiting and data collection.	Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1; Appelhoff S., pybv-A lightweight I/O utility for the BrainVision data format; Appelhoff Stefan, 2019, J Open Source Softw, V4, DOI 10.21105/joss.01896; Artemova E, 2020, Arxiv, DOI arXiv:2003.10540; Bhattasali S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P120; Bi YC, 2011, CORTEX, V47, P575, DOI 10.1016/j.cortex.2009.12.002; Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016; Chen K., 2022, Sci. Data., V9; Défossez A, 2023, NAT MACH INTELL, V5, P1097, DOI 10.1038/s42256-023-00714-5; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dietrich A, 2010, PSYCHOL BULL, V136, P822, DOI 10.1037/a0019749; Fedorenko E, 2011, P NATL ACAD SCI USA, V108, P16428, DOI 10.1073/pnas.1112937108; Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4; Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011; Frisby SL, 2023, TRENDS COGN SCI, V27, P258, DOI 10.1016/j.tics.2022.12.006; Fuseda K, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-24319-x; Gifford AT, 2022, NEUROIMAGE, V264, DOI 10.1016/j.neuroimage.2022.119754; Gorgolewski KJ, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.44; Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027; Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25; Grootswagers T, 2022, SCI DATA, V9, DOI 10.1038/s41597-021-01102-7; Herff C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00217; Hollenstein N, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.659410; Hollenstein N, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.291; Jeong J., 2022, IEEE. Trans. Cybern.; Jingyi Liu, 2021, 2021 International Conference on Networking Systems of AI (INSAI), P171, DOI 10.1109/INSAI54028.2021.00040; Li A., 2022, Journal of Open Source Software, V7, P4484, DOI [10.21105/joss.04484, DOI 10.21105/JOSS.04484]; Li JX, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01625-7; Makin JG, 2020, NAT NEUROSCI, V23, P575, DOI 10.1038/s41593-020-0608-8; McClelland JL, 2020, P NATL ACAD SCI USA, V117, P25966, DOI 10.1073/pnas.1910416117; Mou Xinyu, 2024, OpenNeuro, DOI 10.18112/OPENNEURO.DS004952.V1.2.0; Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y; Pereira F, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03068-4; Pernet CR, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0104-8; Po-Ching Y., 2015, Chinese: A comprehensive grammar; Pobric G, 2009, CORTEX, V45, P1104, DOI 10.1016/j.cortex.2009.02.006; Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1; Siok WT, 2004, NATURE, V431, P71, DOI 10.1038/nature02865; Stehwien S., 2020, P 2 WORKSH LING NEUR, P43; Sun JY, 2019, AAAI CONF ARTIF INTE, P7047; Sun PF, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/abc742; Tang JRY, 2023, NAT NEUROSCI, V26, DOI 10.1038/s41593-023-01304-9; Telesford QK, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02458-8; Teplan M., 2002, Meas. Sci. Rev, V2, P1; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Wang J., 1999, Reading Chinese script: A cognitive analysis; Wang SN, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01708-5; Wang Y., 2022, Frontiers in Human Neuroscience, V16; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu Haiyan, 2024, ScienceDB, DOI 10.57760/sciencedb.CHNNeuro.00007; Xu M, 2021, BRAIN LANG, V215, DOI [10.1016/j.bl.2021.104922, 10.1016/j.bandl.2021.104922]; Zock M, 2020, J COGN SCI, V21, P1	52	0	0	3	3	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2052-4463		SCI DATA	Sci. Data	MAY 29	2024	11	1							550	10.1038/s41597-024-03398-7	http://dx.doi.org/10.1038/s41597-024-03398-7			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	SO3B8	38811613	Green Submitted, gold			2024-07-03	WOS:001235342800003
J	Hu, YH; Chen, BY; Lin, J; Wang, YZ; Wang, YK; Mehlman, C; Lipson, H				Hu, Yuhang; Chen, Boyuan; Lin, Jiong; Wang, Yunzhe; Wang, Yingke; Mehlman, Cameron; Lipson, Hod			Human-robot facial coexpression	SCIENCE ROBOTICS			English	Article							EMOTION RECOGNITION; EXPRESSIONS; MIMICRY; AUTISM; SMILES; PERCEPTION; DEFICITS; EMPATHY; YOUNG	Large language models are enabling rapid progress in robotic verbal communication, but nonverbal communication is not keeping pace. Physical humanoid robots struggle to express and communicate using facial movement, relying primarily on voice. The challenge is twofold: First, the actuation of an expressively versatile robotic face is mechanically challenging. A second challenge is knowing what expression to generate so that the robot appears natural, timely, and genuine. Here, we propose that both barriers can be alleviated by training a robot to anticipate future facial expressions and execute them simultaneously with a human. Whereas delayed facial mimicry looks disingenuous, facial coexpression feels more genuine because it requires correct inference of the human's emotional state for timely execution. We found that a robot can learn to predict a forthcoming smile about 839 milliseconds before the human smiles and, using a learned inverse kinematic facial self-model, coexpress the smile simultaneously with the human. We demonstrated this ability using a robot face comprising 26 degrees of freedom. We believe that the ability to coexpress simultaneous facial expressions could improve human-robot interaction.	[Hu, Yuhang; Lin, Jiong; Mehlman, Cameron; Lipson, Hod] Columbia Univ, Dept Mech Engn, Creat Machines Lab, New York, NY 10027 USA; [Chen, Boyuan] Duke Univ, Mech Engn & Mat Dept, Durham, NC 27708 USA; [Chen, Boyuan] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Chen, Boyuan] Duke Univ, Dept Comp Sci, Durham, NC 27708 USA; [Wang, Yunzhe; Wang, Yingke] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Lipson, Hod] Columbia Univ, Data Sci Inst, New York, NY 10027 USA	Columbia University; Duke University; Duke University; Duke University; Columbia University; Columbia University	Hu, YH; Lipson, H (corresponding author), Columbia Univ, Dept Mech Engn, Creat Machines Lab, New York, NY 10027 USA.; Lipson, H (corresponding author), Columbia Univ, Data Sci Inst, New York, NY 10027 USA.	yuhang.hu@columbia.edu; hod.lipson@columbia.edu	Hu, Yuhang/KLD-1665-2024	Mehlman, Cameron/0000-0003-2385-3631; Wang, Yingke/0009-0006-2038-025X	US National Science Foundation (NSF) AI Institute for Dynamical Systems (DynamicsAI.org) [2112085]; Amazon grant through the Columbia Center of AI Technology (CAIT)	US National Science Foundation (NSF) AI Institute for Dynamical Systems (DynamicsAI.org)(National Science Foundation (NSF)); Amazon grant through the Columbia Center of AI Technology (CAIT)	This work was supported by the US National Science Foundation (NSF) AI Institute for Dynamical Systems (DynamicsAI.org) under grant 2112085 and Amazon grant through the Columbia Center of AI Technology (CAIT).	Agarap A.F., 2018, arXiv, DOI DOI 10.48550/ARXIV.1803.08375; Ahn HS, 2012, IEEE-RAS INT C HUMAN, P799, DOI 10.1109/HUMANOIDS.2012.6651611; Arbib MA, 2005, BEHAV BRAIN SCI, V28, P105, DOI 10.1017/S0140525X05000038; ARGYLE M, 1974, EUR J SOC PSYCHOL, V4, P125, DOI 10.1002/ejsp.2420040202; Asheber WT, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/62181; Bailenson J. N., 2021, Technology, Mind, Behaviour, V1, P1, DOI DOI 10.1037/TMB0000030; Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00; Barrett L.F., 2016, Psychology; Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930; Berns K, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3119, DOI 10.1109/IROS.2006.282331; Birdwhistell R. L., 2010, Kinesics and context: Essays on body motion communication; Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1; Breazeal C., 2000, Sociable Machines: Expressive Social Exchange between Humans and Robots; BUSH LK, 1989, MOTIV EMOTION, V13, P31, DOI 10.1007/BF00995543; Calo R., 2017, SSRN ELECT J, DOI [10.2139/ssrn.3015350, DOI 10.2139/SSRN.3015350]; Chartrand TL, 2013, ANNU REV PSYCHOL, V64, P285, DOI 10.1146/annurev-psych-113011-143754; Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893; Chen BY, 2021, IEEE INT CONF ROBOT, P2739, DOI 10.1109/ICRA48506.2021.9560797; Chen C., 2019, 2019 14 IEEE INT C A, P1; Chen C., 2018, 2018 13 IEEE INT C A; Darwin C., 1872, P374; Decety Jean, 2004, Behav Cogn Neurosci Rev, V3, P71, DOI 10.1177/1534582304267187; DIMBERG U, 1982, PSYCHOPHYSIOLOGY, V19, P643, DOI 10.1111/j.1469-8986.1982.tb02516.x; Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351; EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384; Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203; Feng X, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17061941; Floreano D, 2014, CURR BIOL, V24, pR910, DOI 10.1016/j.cub.2014.07.058; Fridlund A.J., 2014, Human Facial Expression: An Evolutionary View; Frijda N. H., 1986, EMOTIONS; Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142; Frith CD, 2006, NEURON, V50, P531, DOI 10.1016/j.neuron.2006.05.001; Garrod S, 2009, TOP COGN SCI, V1, P292, DOI 10.1111/j.1756-8765.2009.01020.x; Gross JJ, 2002, PSYCHOPHYSIOLOGY, V39, P281, DOI 10.1017/S0048577201393198; Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6; Hashimoto Takuya, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P521, DOI 10.1109/ICHR.2008.4756017; Hashimoto T., 2006, 2006 SICE ICASE INT, P3119; Hess U, 2013, PERS SOC PSYCHOL REV, V17, P142, DOI 10.1177/1088868312472607; Jack RE, 2013, VIS COGN, V21, P1248, DOI 10.1080/13506285.2013.835367; Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109; Jack RE, 2009, CURR BIOL, V19, P1543, DOI 10.1016/j.cub.2009.07.051; Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033; Karl KA, 2022, SMALL GR RES, V53, P343, DOI 10.1177/10464964211015286; Kingma D. P., 2017, ARXIV; Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250; Krumhuber E, 2005, J NONVERBAL BEHAV, V29, P3, DOI 10.1007/s10919-004-0887-x; Krumhuber EG, 2009, EMOTION, V9, P807, DOI 10.1037/a0017844; Labrecque LI, 2012, J ACAD MARKET SCI, V40, P711, DOI 10.1007/s11747-010-0245-y; Lakin JL, 2003, J NONVERBAL BEHAV, V27, P145, DOI 10.1023/A:1025389814290; Lakin JL, 2003, PSYCHOL SCI, V14, P334, DOI 10.1111/1467-9280.14481; Loza D., 2013, J. Phys. Agents, V7, P31; Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, 10.48550/ARXIV.1906.08172]; Martin R., 2018, The Psychology of Humor: An Integrative Approach, DOI DOI 10.1016/B978-0-12-812143-6.00004-7; MATSUMOTO D, 1993, J NONVERBAL BEHAV, V17, P231, DOI 10.1007/BF00987239; McIntosh DN, 2006, DEVELOPMENTAL SCI, V9, P295, DOI 10.1111/j.1467-7687.2006.00492.x; Meltzoff AN, 1997, EARLY DEV PARENTING, V6, P179, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<179::AID-EDP157>3.0.CO;2-R; Moody EJ, 2007, EMOTION, V7, P447, DOI 10.1037/1528-3542.7.2.447; Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045; Murphy R. R., 2020, Machine Ethics and Robot Ethics, P405; Niculescu A, 2013, INT J SOC ROBOT, V5, P171, DOI 10.1007/s12369-012-0171-x; Oberman LM, 2007, PSYCHOL BULL, V133, P310, DOI 10.1037/0033-2909.133.2.310; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Paszke A, 2019, ADV NEUR IN, V32; Pennisi P, 2016, AUTISM RES, V9, P165, DOI 10.1002/aur.1527; Peper E., 2021, NeuroRegulation, V8, P47, DOI [DOI 10.15540/NR.8.1.47, 10.15540/nr.8.1.47]; Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Shamay-Tsoory SG, 2009, BRAIN, V132, P617, DOI 10.1093/brain/awn279; Song RT, 2016, EVOL HUM BEHAV, V37, P490, DOI 10.1016/j.evolhumbehav.2016.05.002; Stel M, 2010, BRIT J PSYCHOL, V101, P311, DOI 10.1348/000712609X465424; Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65; Winfield AFT, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2018.0085	74	0	0	68	68	AMER ASSOC ADVANCEMENT SCIENCE	WASHINGTON	1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA	2470-9476			SCI ROBOT	Sci. Robot.	MAR 27	2024	9	88							eadi4724	10.1126/scirobotics.adi4724	http://dx.doi.org/10.1126/scirobotics.adi4724			12	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	MF1R8	38536902	Bronze			2024-07-03	WOS:001192125300003
J	Aguilera, CA; Castro, A; Aguilera, C; Raducanu, B				Aguilera, Cristhian A.; Castro, Angela; Aguilera, Cristhian; Raducanu, Bogdan			Voice-Controlled Robotics in Early Education: Implementing and Validating Child-Directed Interactions Using a Collaborative Robot and Artificial Intelligence	APPLIED SCIENCES-BASEL			English	Article						cobots; education; human-robot interaction; artificial intelligence		This article introduces a voice-controlled robotic system for early education, enabling children as young as four to interact with robots using natural voice commands. Recognizing the challenges posed by programming languages and robot theory for young learners, this study leverages recent advancements in artificial intelligence, such as large language models, to make robots more intelligent and easier to use. This innovative approach fosters a natural and intuitive interaction between the child and the robot, effectively removing barriers to access and expanding the educational possibilities of robotics in the classroom. In this context, a software pipeline is proposed that translates voice commands into robot actions. Each component is tested using different deep learning models and cloud services to determine their suitability, with the best ones being selected. Finally, the chosen setup is validated through an integration test involving children aged 4 to 6 years. Preliminary results demonstrate the system's capability to accurately recognize and execute voice commands, highlighting its potential as a valuable educational tool for early education.	[Aguilera, Cristhian A.] Univ San Sebastian, Fac Ingn Arquitectura & Diseno, Lago Panguipulli 1390, Puerto Montt 5501842, Chile; [Castro, Angela] Univ San Sebastian, Fac Educ, Lago Panguipulli 1390, Puerto Montt 5501842, Chile; [Aguilera, Cristhian] Univ Bio Bio, Fac Ingn, Dept Ingn Electr & Elect, Concepcion 4051381, Chile; [Raducanu, Bogdan] Comp Vis Ctr, Edif O,Campus UAB, Bellaterra 08193, Spain; [Raducanu, Bogdan] Univ Autonoma Barcelona, Comp Sci Dept, Campus UAB, Bellaterra 08193, Spain	Universidad San Sebastian; Universidad San Sebastian; Universidad del Bio-Bio; Centre de Visio per Computador (CVC); Autonomous University of Barcelona; Autonomous University of Barcelona	Aguilera, CA (corresponding author), Univ San Sebastian, Fac Ingn Arquitectura & Diseno, Lago Panguipulli 1390, Puerto Montt 5501842, Chile.	cristhian.aguilera@uss.cl; angela.castro@uss.cl; cristhia@ubiobio.cl; bogdan@cvc.aub.es		Castro Inostroza, Angela/0000-0002-1732-6520	National Research and Development Agency	National Research and Development Agency	No Statement Available	Aguilera-Carrasco CA, 2023, IEEE ACCESS, V11, P100975, DOI 10.1109/ACCESS.2023.3314337; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], Google Cloud Speech-to-Text; Bochkovskiy A, 2020, Arxiv, DOI [arXiv:2004.10934, 10.48550/arxiv.2004.10934, DOI 10.48550/ARXIV.2004.10934]; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Calo Mosquera N., 2021, Ensenanza Cienc. Rev. Investig. Exp. Didacticas, V39, P223, DOI [10.5565/rev/ensciencias.3238, DOI 10.5565/REV/ENSCIENCIAS.3238]; Castro A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010387; Cherti M, 2023, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR52729.2023.00276; Garvis S., 2023, Technological Innovations in Education: Applications in Education and Teaching, P71, DOI [10.1007/978-981-99-2785-2_6, DOI 10.1007/978-981-99-2785-2_6]; github, Vosk Speech Recognition Toolkit: Offline Speech Recognition API for Android, iOS, Raspberry Pi and Servers with Python, Java, C# and Node; He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Jocher G., 2022, Zenodo; Jocher G., 2023, Ultralytics YOLOv8; Kambouri-Danos M, 2019, EARLY CHILD EDUC J, V47, P475, DOI 10.1007/s10643-019-00937-5; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Mendez E, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14020839; Misirli A., 2014, Research on e-Learning and ICT in Education S, P99, DOI [10.1007/978-1-4614-6501-0_8, DOI 10.1007/978-1-4614-6501-0_8]; openai, 2022, OpenAI Introducing ChatGPT OpenAI; picovoice, Leopard-Picovoice Speech-to-Text Engine; Radford A., 2023, P INT C MACHINE LEAR; Radford A, 2021, PR MACH LEARN RES, V139; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Sisman B., 2019, International Journal of Research in Education and Science, V5, P510; Soviany P, 2018, Arxiv, DOI [arXiv:1803.08707, DOI 10.48550/ARXIV.1803.08707, 10.48550/arXiv.1803.08707]; TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770; Unity Technologies, 2020, Unity perception package; Vaswani A, 2017, ADV NEUR IN, V30; Williams R, 2019, AAAI CONF ARTIF INTE, P9729; Zhao Y, 2024, Arxiv, DOI [arXiv:2304.08069, DOI 10.48550/ARXIV.2304.08069]	30	0	0	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	6							2408	10.3390/app14062408	http://dx.doi.org/10.3390/app14062408			13	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	MC8I8		gold			2024-07-03	WOS:001191515700001
J	Kazakov, A; Denisova, S; Barsola, I; Kalugina, E; Molchanova, I; Egorov, I; Kosterina, A; Tereshchenko, E; Shutikhina, L; Doroshchenko, I; Sotiriadi, N; Budennyy, S				Kazakov, A.; Denisova, S.; Barsola, I.; Kalugina, E.; Molchanova, I.; Egorov, I.; Kosterina, A.; Tereshchenko, E.; Shutikhina, L.; Doroshchenko, I.; Sotiriadi, N.; Budennyy, S.			ESGify: Automated Classification of Environmental, Social, and Corporate Governance Risks	DOKLADY MATHEMATICS			English	Article						ESG; sustainability; LLM; NLP		The growing recognition of environmental, social, and governance (ESG) factors in financial decision-making has spurred the need for effective and comprehensive ESG risk assessment tools. In this study, we introduce an open-source Natural Language Processing (NLP) model, "ESGify"1,2, based on MPNet-base architecture and aimed to classify texts within the frames of ESG risks. We also present a hierarchical and detailed methodology for ESG risk classification, leveraging the expertise of ESG professionals and global best practices. Anchored by a manually annotated multilabel dataset of 2000 news articles and domain adaptation with texts of sustainability reports, ESGify is developed to automate ESG risk classification following the established methodology. We compare augmentation techniques based on back translation and Large Language Models (LLMs) to improve the model quality and achieve 0.5 F1-weighted model quality in the dataset with 47 classes. This result outperforms ChatGPT 3.5 with a simple prompt. The model weights and documentation is hosted on Github https://github.com/sb-ai-lab/ESGify under the Apache 2.0 license.	[Kazakov, A.; Denisova, S.; Barsola, I.; Kalugina, E.; Molchanova, I.; Egorov, I.; Kosterina, A.; Tereshchenko, E.; Shutikhina, L.; Doroshchenko, I.; Sotiriadi, N.; Budennyy, S.] Sber AI Lab, Moscow, Russia; [Budennyy, S.] Artificial Intelligence Res Inst AIRI, Moscow, Russia		Budennyy, S (corresponding author), Sber AI Lab, Moscow, Russia.; Budennyy, S (corresponding author), Artificial Intelligence Res Inst AIRI, Moscow, Russia.	sanbudenny@sberbank.ru						Akbik A., 2018, P 27 INT C COMP LING, P1638; [Anonymous], 2023, Consolidated Set of the GRI Standards; [Anonymous], 2016, World Bank Environmental and Social Framework; [Anonymous], 2023, CSA Handbook 2023: Corporate Sustainability Assessment; [Anonymous], 2012, IFC performance standards on environmental and social sustainability; [Anonymous], 2023, ESG Ratings Methodology; [Anonymous], 2023, SASB Standards; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Bell F, 2022, COGENT ECON FINANC, V10, DOI 10.1080/23322039.2022.2148362; Bogatinovski J, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117215; Budennyy SA, 2022, DOKL MATH, V106, pS118, DOI 10.1134/S1064562422060230; EBRD Environmental and Social Risk Management Toolkit for Financial Intermediaries, 2016, The European Bank for Reconstruction and Development; Lee O, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14148745; Marivate Vukosi, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P385, DOI 10.1007/978-3-030-57321-8_21; Nugent T, 2021, LECT NOTES ARTIF INT, V12871, P157, DOI 10.1007/978-3-030-86967-0_12; Park J, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.890435; Pérez-Mayos L, 2021, Arxiv, DOI [arXiv:2109.03160, DOI 10.48550/ARXIV.2109.03160]; Sechidis K, 2011, LECT NOTES ARTIF INT, V6913, P145, DOI 10.1007/978-3-642-23808-6_10; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Song KT, 2020, Arxiv, DOI arXiv:2004.09297; Szymanski Piotr, 2017, PMLR, V74, P22; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; unpri, What are the principles for responsible investment?	23	0	0	8	8	MAIK NAUKA/INTERPERIODICA/SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013-1578 USA	1064-5624	1531-8362		DOKL MATH	Dokl. Math.	DEC	2023	108	SUPPL 2		2			S529	S540		10.1134/S1064562423701673	http://dx.doi.org/10.1134/S1064562423701673			12	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	MC7S1					2024-07-03	WOS:001191499000021
C	Ludan, JM; Meng, YX; Nguyen, T; Shah, S; Lyu, Q; Apidianaki, M; Callison-Burch, C		Rogers, A; Boyd-Graber, J; Okazaki, N		Ludan, Josh Magnus; Meng, Yixuan; Nguyen, Tai; Shah, Saurabh; Lyu, Qing; Apidianaki, Marianna; Callison-Burch, Chris			Explanation-based Finetuning Makes Models More Robust to Spurious Cues	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Large Language Models (LLMs) are so powerful that they sometimes learn correlations between labels and features that are irrelevant to the task, leading to poor generalization on outof-distribution data. We propose explanationbased finetuning as a general approach to mitigate LLMs' reliance on spurious correlations. Unlike standard finetuning where the model only predicts the answer given the input, we finetune the model to additionally generate a free-text explanation supporting its answer. To evaluate our method, we finetune the model on artificially constructed training sets containing different types of spurious cues, and test it on a test set without these cues. Compared to standard finetuning, our method makes GPT-3 (davinci) remarkably more robust against spurious cues in terms of accuracy drop across four classification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC (+6.5). The efficacy generalizes across multiple model families and scales, with greater gains for larger models. Finally, our method also works well with explanations generated by the model, implying its applicability to more datasets without human-written explanations.1,2	[Ludan, Josh Magnus; Meng, Yixuan; Nguyen, Tai; Shah, Saurabh; Lyu, Qing; Apidianaki, Marianna; Callison-Burch, Chris] Univ Penn, Philadelphia, PA 19104 USA	University of Pennsylvania	Ludan, JM (corresponding author), Univ Penn, Philadelphia, PA 19104 USA.	jludan@seas.upenn.edu; yixuanm@seas.upenn.edu; taing@seas.upenn.edu; surb@seas.upenn.edu; lyuqing@seas.upenn.edu; marapi@seas.upenn.edu; ccb@seas.upenn.edu			DARPA KAIROS Program [FA8750-19-2-1004]; DARPA LwLL Program [FA8750-19-2-0201]; IARPA HIATUS Program [2022-22072200005]; NSF [1928631]	DARPA KAIROS Program(United States Department of Defense); DARPA LwLL Program; IARPA HIATUS Program; NSF(National Science Foundation (NSF))	This research is based upon work supported in part by the DARPA KAIROS Program (contract FA8750-19-2-1004), the DARPA LwLL Program (contract FA8750-19-2-0201), the IARPA HIATUS Program (contract 2022-22072200005), and the NSF (Award 1928631). Approved for Public Release, Distribution Unlimited. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, IARPA, NSF, or the U.S. Government.	Bird S., 2009, NATURAL LANGUAGE PRO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camburu OM, 2018, ADV NEUR IN, V31; Chen DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2358; Chen H, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3792; Geva M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1161; Gururangan Suchin, 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-2017; Kaushik D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5010; Kaushik Divyansh, 2019, ARXIV190912434; Kiritchenko S., 2018, P 7 JOINT C LEXICAL, P43, DOI DOI 10.18653/V1/S18-2005; Lampinen Andrew K, 2022, ARXIV220402329; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Liu HC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1797; Lu K., 2020, LOGIC LANGUAGE SECUR, P189, DOI DOI 10.1007/978-3-030-62077-614; Mahabadi Rabeeh Karimi, 2020, P 58 ANN M ASS COMPU, P8706, DOI 10. 18653 / v1 / 2020. acl - main. 769; Marasovic Ana, 2022, FINDINGS ASS COMPUTA, P410, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.31; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Nie Yixin, 2020, P 58 ANN M ASS COMPU, P4885, DOI [10.18653/v1/2020.acl-main.441, DOI 10.18653/V1/2020.ACL-MAIN.441, DOI 10.18653/V1/2020.ACL-MAIN, 10.18653/.v1/2020.acl-main.441]; Onoe Yasumasa, 2021, ARXIV210901653; Poliak Adam, 2018, P 7 JOINT C LEX COMP, P180, DOI DOI 10.18653/V1/S18-2023; Raffel C, 2020, J MACH LEARN RES, V21; Raji Frano, 2022, ARXIV221113331; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ross Alexis, 2022, P 2022 C EMP METH NA; Sanh Victor, 2020, ARXIV201201300; Sap Maarten, 2020, P 58 ANN M ASS COMPU, P5477; Stacey J, 2022, AAAI CONF ARTIF INTE, P11349; Stacey Joe, 2020, THERE IS STRENGTH NU; Wang Boshi, 2022, ARXIV221210001; Wang CX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4020; Wei Jason, 2022, arXiv:2201.11903; Wiegreffe S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10266; Wu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2660; Ye Xi, 2022, ADV NEURAL INFORM PR; Zhang S., 2022, arXiv	35	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							4420	4441						22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086803013
J	Hirano, Y; Hanaoka, S; Nakao, T; Miki, S; Kikuchi, T; Nakamura, Y; Nomura, Y; Yoshikawa, T; Abe, O				Hirano, Yuichiro; Hanaoka, Shouhei; Nakao, Takahiro; Miki, Soichiro; Kikuchi, Tomohiro; Nakamura, Yuta; Nomura, Yukihiro; Yoshikawa, Takeharu; Abe, Osamu			GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination	JAPANESE JOURNAL OF RADIOLOGY			English	Article; Early Access						Artificial intelligence (AI); Large language model (LLM); ChatGPT; GPT-4 Turbo; GPT-4 Turbo with Vision; Japan Diagnostic Radiology Board Examination (JDRBE)		Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI's latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE).Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar's exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test.Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses.Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.	[Hirano, Yuichiro] Int Univ Hlth & Welf, Narita Hosp, Dept Radiol, 852 Hatakeda, Narita, Chiba, Japan; [Nakao, Takahiro; Miki, Soichiro; Kikuchi, Tomohiro; Nakamura, Yuta; Nomura, Yukihiro; Yoshikawa, Takeharu] Univ Tokyo Hosp, Dept Computat Diagnost Radiol & Prevent Med, 7-3-1 Hongo,Bunkyo Ku, Tokyo, Japan; [Kikuchi, Tomohiro] Jichi Med Univ, Sch Med, Dept Radiol, 3311-1 Yakushiji, Shimotsuke, Tochigi, Japan; [Nomura, Yukihiro] Chiba Univ, Ctr Frontier Med Engn, 1-33 Yayoicho,Inage Ku, Chiba, Japan; [Hirano, Yuichiro; Hanaoka, Shouhei; Abe, Osamu] Univ Tokyo Hosp, Dept Radiol, 7-3-1 Hongo,Bunkyo Ku, Tokyo, Japan	International University of Health & Welfare; University of Tokyo; Jichi Medical University; Chiba University; University of Tokyo	Hirano, Y (corresponding author), Int Univ Hlth & Welf, Narita Hosp, Dept Radiol, 852 Hatakeda, Narita, Chiba, Japan.; Hirano, Y (corresponding author), Univ Tokyo Hosp, Dept Radiol, 7-3-1 Hongo,Bunkyo Ku, Tokyo, Japan.	yhirano-tky@umin.ac.jp	Kikuchi, Tomohiro/HZH-6657-2023; Nakamura, Yuta/JCE-1174-2023	Kikuchi, Tomohiro/0000-0002-4222-4569; Hirano, Yuichiro/0000-0003-1564-0513; Abe, Osamu/0000-0002-1180-2629; Nakamura, Yuta/0000-0001-6962-6704	The University of Tokyo; HIMEDIC Inc.; Siemens Healthcare K.K; Japan Diagnostic Radiology Board Examination	The University of Tokyo; HIMEDIC Inc.; Siemens Healthcare K.K; Japan Diagnostic Radiology Board Examination	The Department of Computational Diagnostic Radiology and Preventive Medicine, The University of Tokyo Hospital, is sponsored by HIMEDIC Inc. and Siemens Healthcare K.K. We thank the Japan Radiology Society for granting permission to cite questions from the Japan Diagnostic Radiology Board Examination. We thank Editage (www.editage.jp) for English language editing.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], Models-OpenAI API; [Anonymous], Enterprise privacy at OpenAI; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Fang C., 2023, bioRxiv, DOI [10.1101/2023.05.03.23289443.abstract, DOI 10.1101/2023.05.03.23289443.ABSTRACT]; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; Flores-Cohaila JA, 2023, JMIR MED EDUC, V9, DOI 10.2196/48039; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Nakao T., 2023, bioRxiv, DOI [10.1101/2023.11.07.23298133v1.abstract, DOI 10.1101/2023.11.07.23298133V1.ABSTRACT]; OpenAI, Introducing ChatGPT; Rosol M., 2023, bioRxiv, DOI [10.1101/2023.06.04.23290939.abstract, DOI 10.1101/2023.06.04.23290939.ABSTRACT]; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Tanaka Y., 2023, bioRxiv, DOI [10.1101/2023.04.17.23288603.abstract, DOI 10.1101/2023.04.17.23288603.ABSTRACT]; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2; Yanagita Y, 2023, JMIR FORM RES, V7, DOI 10.2196/48023; Yang Z., 2023, medRxiv, DOI [10.1101/2023.10.26.23297629v3.abstract, DOI 10.1101/2023.10.26.23297629V3.ABSTRACT]	18	1	1	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1867-1071	1867-108X		JPN J RADIOL	Jpn. J. Radiol.	2024 MAY 11	2024										10.1007/s11604-024-01561-z	http://dx.doi.org/10.1007/s11604-024-01561-z		MAY 2024	9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	QL5C8	38733472	hybrid			2024-07-03	WOS:001221032300002
J	Zhao, WJ				Zhao, Weijie			A panel discussion on AI for science: the opportunities, challenges and reflections	NATIONAL SCIENCE REVIEW			English	Editorial Material; Early Access								Artificial intelligence (AI) tools are changing the way we do science. AlphaFold basically solved the conundrum of protein structure prediction; DeepMD greatly improved the efficiency and accuracy of molecular simulations; and the emerging large language models such as ChatGPT are opening up more possibilities for scientific applications. In this panel, five experts from China and the US discussed the concept, development, bottlenecks and opportunities of AI for Science (AI4S), as well as their understanding of the relationship between AI and science. Roberto Car Professor at Department of Chemistry, Princeton University, USA Weinan E Professor at School of Mathematical Sciences, Peking University, China; AI for Science Institute, Beijing, China David Srolovitz Professor at Department of Mechanical Engineering, University of Hong Kong, China Han Wang Professor at the Institute of Applied Physics and Computational Mathematics, Chinese Academy of Sciences, China Linfeng Zhang (Chair) Chief scientific officer of DP Technology, China; AI for Science Institute, Beijing, China Five experts from China and the US discussed the concept, development, bottlenecks and opportunities of AI for Science (AI4S), as well as their understanding of the relationship between AI and science.											0	0	0	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	2095-5138	2053-714X		NATL SCI REV	Natl. Sci. Rev.	2024 MAR 26	2024										10.1093/nsr/nwae119	http://dx.doi.org/10.1093/nsr/nwae119		MAR 2024	5	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	QO1Y2		gold			2024-07-03	WOS:001221734000001
C	Holur, P; Chong, D; Tangherlini, T; Roychowdhury, V		Rogers, A; Boyd-Graber, J; Okazaki, N		Holur, Pavan; Chong, David; Tangherlini, Timothy; Roychowdhury, Vwani			<i>My side</i>, <i>your side and the evidence</i>: Discovering aligned actor groups and the narratives they weave	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			STRUCTURAL BALANCE	News reports about emerging issues often include several conflicting story lines. Individual stories can be conceptualized as samples from an underlying mixture of competing narratives. The automated identification of these distinct narratives from unstructured text is a fundamental yet difficult task in Computational Linguistics since narratives are often intertwined and only implicitly conveyed in text. In this paper, we consider a more feasible proxy task: Identify the distinct sets of aligned story actors responsible for sustaining the issue-specific narratives. Discovering aligned actors, and the groups these alignments create, brings us closer to estimating the narrative that each group represents. With the help of Large Language Models (LLM), we address this task by: (i) Introducing a corpus of text segments rich in narrative content associated with six different current issues; (ii) Introducing a novel two-step graph-based framework that (a) identifies alignments between actors (INCANT) and (b) extracts aligned actor groups using the network structure (TAMPA). Amazon Mechanical Turk evaluations demonstrate the effectiveness of our framework. Across domains, alignment relationships from INCANT are accurate (macro F1 >= 0.75) and actor groups from TAMPA are preferred over 2 non-trivial baseline models (ACC >= 0.75).	[Holur, Pavan; Chong, David; Roychowdhury, Vwani] UCLA, Dept Elect & Comp Engn, Los Angeles, CA 90024 USA; [Tangherlini, Timothy] Univ Calif Berkeley, Dept Scandinavian, Berkeley, CA USA	University of California System; University of California Los Angeles; University of California System; University of California Berkeley	Holur, P (corresponding author), UCLA, Dept Elect & Comp Engn, Los Angeles, CA 90024 USA.	pholur@ucla.edu; davidchong13807@ucla.edu; tango@berkeley.edu; vwani@ucla.edu						Bailey P., 1999, Narrative Intelligence. Papers from the 1999 AAAI Fall Symposium, P157; Beatty J, 2016, STUD HIST PHI PART C, V58, P33, DOI 10.1016/j.shpsc.2015.12.016; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Bondy J. A., 1976, Graph theory with applications; Buck C, 2018, Arxiv, DOI arXiv:1705.07830; CARTWRIGHT D, 1956, PSYCHOL REV, V63, P277, DOI 10.1037/h0046049; DAVIS JA, 1967, HUM RELAT, V20, P181, DOI 10.1177/001872676702000206; Diefenbach D, 2018, KNOWL INF SYST, V55, P529, DOI 10.1007/s10115-017-1100-y; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; He Luheng, 2015, P 2015 C EMP METH NA, P643; Hodges John L., 1958, ARK MAT, V3, P469, DOI DOI 10.1007/BF02589501; Holur P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4975; Holur P, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210797; Honnibal M., 2020, spaCy: Industrial-strength Natural Language Processing in Python; Khanam KZ, 2023, MULTIMED TOOLS APPL, V82, P8811, DOI 10.1007/s11042-021-11857-1; Lee Kenton, 2018, P 2018 C N AM CHAPTE, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]; Liu Y, 2019, ARXIV PREPRINT ARXIV; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Music MG, 2022, CONSCIOUS COGN, V106, DOI 10.1016/j.concog.2022.103428; Pan LM, 2019, Arxiv, DOI arXiv:1905.08949; Pujari R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1353; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250; Richardson L., 2007, Beautiful soup documentation; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Scepanovic Sanja, 2017, Online Social Networks and Media, V2, P1, DOI 10.1016/j.osnem.2017.06.001; Shahsavari S, 2020, PROCEEDINGS OF THE 12TH ACM CONFERENCE ON WEB SCIENCE, WEBSCI 2020, P277, DOI 10.1145/3394231.3397918; Shahsavari S, 2020, J COMPUT SOC SCI, V3, P279, DOI 10.1007/s42001-020-00086-5; Tangherlini TR, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233879; Tkachenko M., 2020, LABEL STUDIO DATA LA; Tredici MD, 2019, Arxiv, DOI arXiv:1909.00412; Whaley III Dewey Lonzo, 2005, Ph.D. thesis; Xiao DL, 2020, Arxiv, DOI arXiv:2001.11314; Yin D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3695; Yu DH, 2022, AAAI CONF ARTIF INTE, P11630; Zhang Y., 2022, P 29 INT C COMP LING, P4212	36	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							8938	8952						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962500029
C	Maceda, LL; Llovido, JL; Artiaga, MB; Abisado, MB			Assoc Computing Machinery	Maceda, Lany L.; Llovido, Jennifer L.; Artiaga, Miles B.; Abisado, Mideth B.			Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study	PROCEEDINGS OF 2023 7TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2023			English	Proceedings Paper	7th International Conference on Natural Language Processing and Information Retrieval (NLPIR)	DEC 15-17, 2023	Seoul, SOUTH KOREA			GPT-4; Sentiment Annotation; LLM Prompting; Social Media Data		In today's digital age, social media has become a hub for people to express their thoughts and feelings. Sentiment classification discerns public opinions and trends to understand their sentiments towards a certain topic. Often, achieving accurate sentiment classifications in large datasets necessitate the use of human-annotated training data which can be costly and time-consuming. Large Language Models (LLMs) like the Generative Pre-trained models by OpenAI have surged in popularity due to its capabilities in understanding the given tasks. In this preliminary study, we report the performance of the latest OpenAI GPT-4 using zero- and one-shot learning approaches on classifying sentiments when fed with social media dataset. Notably, the latter approach written in English which mimics the instructions designed for human annotators, achieved a substantial agreement (k = 0.77) with human annotations, displaying high accuracy, precision, and recall accordingly even without explicit training data. Meanwhile, the fine-tuned mBERT resulted to lower evaluation scores than the GPT-4. Our findings provide foundational insights into the strengths and limitations of GPT-4 for sentiment classification in a social media dataset, setting the groundwork for broad future research in this field.	[Maceda, Lany L.; Llovido, Jennifer L.; Artiaga, Miles B.] Bicol Univ, Legazpi City, Philippines; [Abisado, Mideth B.] Natl Univ, Manila, Philippines	Bicol University; National University Philippines	Maceda, LL (corresponding author), Bicol Univ, Legazpi City, Philippines.			artiaga, miles/0009-0009-5733-8444	Philippine Commission on Higher Education (CHEd) Leading the Advancement of Knowledge in Agriculture and Science (LAKAS) [2021-007]	Philippine Commission on Higher Education (CHEd) Leading the Advancement of Knowledge in Agriculture and Science (LAKAS)	The researchers would like to thank the Philippine Commission on Higher Education (CHEd) Leading the Advancement of Knowledge in Agriculture and Science (LAKAS) Project No. 2021-007, eParticipation 2.1: Harnessing Natural Language Processing (NLP) for Community Participation, for providing the necessary funds to make this research possible. The researchers are truly grateful for their contribution to the research.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agüero-Torales MM, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107373; Arispe M., 2019, International Journal of Research Studies in Education, V8, P21; Austero LD, 2018, INT SYMP COMP CONS, P242, DOI 10.1109/IS3C.2018.00068; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Lingjiao, How Is ChatGPT's Behavior Changing over Time?; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gilardi F, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2305016120; Gundecha Pritam., 2012, 2012 TUTORIALS OPERA, P1, DOI [10.1287/educ.1120.0105, DOI 10.1287/EDUC.1120.0105]; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Kalaivani Adaikkan, 2021, Multilingual Sentiment Analysis in Tamil, Malayalam, and Kannada code-mixed social media posts using MBERT; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; Kheiri K, 2023, Arxiv, DOI [arXiv:2307.10234, DOI 10.48550/ARXIV.2307.10234]; Lee M, 2015, AM J CULT SOCIOL, V3, P1, DOI 10.1057/ajcs.2014.13; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Liyanage Chandreen, GPT-4 as a Twitter Data Annotator: Unraveling Its Performance on a Stance Classification Task, DOI [10.36227/techrxiv.24143706.v1, DOI 10.36227/TECHRXIV.24143706.V1]; Lourentzou I, 2019, Arxiv, DOI arXiv:1904.06100; Maceda LL, 2023, INT J ADV COMPUT SC, V14, P706; Maceda LL, 2018, INT SYMP COMP CONS, P229, DOI 10.1109/IS3C.2018.00065; Nelson LK, 2021, SOCIOL METHOD RES, V50, P202, DOI 10.1177/0049124118769114; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Openai A. R., IMPROVING LANGUAGE U; Pawar Chandrashekhar S., 2022, Futuristic Trends in Networks and Computing Technologies: Select Proceedings of Fourth International Conference on FTNCT 2021. Lecture Notes in Electrical Engineering (936), P563, DOI 10.1007/978-981-19-5037-7_40; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ranara John Patrick, 2023, Philstar Life; Savelka J, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P78, DOI 10.1145/3568813.3600142; Schmidt Thomas, 2019, C LANG DAT KNOWL LDK, P45; Shanmugavadivel K, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101407; Uryupina Olga, P 9 INT C LANG RES E; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754; Yimam Seid Muhie, 2020, P 28 INT C COMP LING, DOI [10.18653/v1/2020.colingmain.91, DOI 10.18653/V1/2020.COLINGMAIN.91]; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	37	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0922-7				2023							19	24		10.1145/3639233.3639353	http://dx.doi.org/10.1145/3639233.3639353			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6NK					2024-07-03	WOS:001179071500003
C	Miller, JA; Barna, NH; Rana, S; Arpinar, IB; Liu, NH			IEEE	Miller, John A.; Barna, Nasid Habib; Rana, Subas; Arpinar, I. Budak; Liu, Ninghao			Knowledge Enhanced Deep Learning: Application to Pandemic Prediction	2023 IEEE 9TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING, CIC			English	Proceedings Paper	IEEE 9th International Conference on Collaboration and Internet Computing (CIC)	NOV 01-04, 2023	Atlanta, GA	IEEE, IEEE Comp Soc		Time series; pandemic; deep learning	REPRESENTATION; INFORMER	Deep Learning has been successfully applied to many problem domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known M Competitions, until recently, hybrids of traditional statistical or machine learning (e.g., gradient boosting) techniques were the top performers. With the recent architectural advances in deep learning being applied to time series forecasting, such as encoder-decoders with attention, transformers, representation learning, and graph neural networks, deep learning has begun to show its advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, ignorance of accumulated scientific knowledge, and interpretability of the model. Today, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject knowledge into deep learning models. The state-of-the-art approaches are reviewed and suggestions for further work are provided. Recommendations for how this can be applied to future pandemics are given.	[Miller, John A.; Barna, Nasid Habib; Rana, Subas; Arpinar, I. Budak; Liu, Ninghao] Univ Georgia, Sch Comp, Athens, GA 30602 USA	University System of Georgia; University of Georgia	Miller, JA (corresponding author), Univ Georgia, Sch Comp, Athens, GA 30602 USA.	jamill@uga.edu; nasidhabib.barna@uga.edu; subas.rana@uga.edu; budak@uga.edu; ninghao.liu@uga.edu						ARMSTRONG JS, 1993, J FORECASTING, V12, P103; Athanasopoulos G, 2008, J BUS ECON STAT, V26, P237, DOI 10.1198/073500107000000313; Bai JG, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P107; Bai SJ, 2018, Arxiv, DOI arXiv:1803.01271; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Box G E., 1967, Models for forecasting seasonal and non-seasonal time series; Box G. E. P., 1970, Time series analysis, forecasting and control; BOX GEP, 1962, J ROY STAT SOC B, V24, P297; Cao D., 2020, Advances in neural information processing systems, V33, P17766, DOI [DOI 10.48550/ARXIV, DOI 10.48550/ARXIV.2103.07719]; Chen T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13137753; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chorowski J, 2014, Arxiv, DOI [arXiv:1412.1602, DOI 10.48550/ARXIV.1412.1602]; Cirstea R.-G., 2022, arXiv; COCHRANE D, 1949, J AM STAT ASSOC, V44, P32, DOI 10.2307/2280349; Dong H, 2024, Arxiv, DOI arXiv:2309.03251; Fritz C, 2021, Arxiv, DOI arXiv:2101.00661; Gilmer J, 2017, PR MACH LEARN RES, V70; Gütebier L, 2022, BIOINFORMATICS, V38, P4843, DOI 10.1093/bioinformatics/btac592; Hamilton WL, 2017, ADV NEUR IN, V30; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Holt CC., 1957, INT J FORECASTING, DOI [DOI 10.1016/J.IJFORECAST.2003.09.015, 10.1016/j.ijforecast.2003.09.015]; Javeri I. Y., 2021, 2021 IEEE 7 INT C BI, P1; Jin M, 2023, Arxiv, DOI [arXiv:2307.03759, 10.48550/arXiv.2307.03759]; Jin XY, 2022, PR MACH LEARN RES, P10280; JONES DA, 1978, P ROY SOC LOND A MAT, V360, P71, DOI 10.1098/rspa.1978.0058; Jung J, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P786, DOI 10.1145/3447548.3467292; Kapoor A, 2020, Arxiv, DOI arXiv:2007.03113; Karagiannakos S, 2021, Best graph neural networks architectures: GCN, GAT, MPNN and more; Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5; Karpatne A, 2017, IEEE T KNOWL DATA EN, V29, P2318, DOI 10.1109/TKDE.2017.2720168; Ke GL, 2017, ADV NEUR IN, V30; Kim S, 2023, KNOWL-BASED SYST, V277, DOI 10.1016/j.knosys.2023.110790; Kitaev N., 2020, arXiv; La Cava W, 2019, Arxiv, DOI arXiv:1807.00981; Lea C, 2016, LECT NOTES COMPUT SC, V9915, P47, DOI 10.1007/978-3-319-49409-8_7; LeCun Y., 1995, Handb Brain Theory Neural Netw, V3361, P1995, DOI [DOI 10.5555/303568.303704, 10.5555/303568.303704]; Li SY, 2019, ADV NEUR IN, V32; Li Z, 2023, Arxiv, DOI arXiv:2302.04501; Li Z, 2023, Arxiv, DOI arXiv:2301.08871; Lim B, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0209; Lin T., 2022, A survey of transformers; Lin X, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2739; [刘尚鹏 Liu Shangpeng], 2022, [高分子通报, Polymer Bulletin], P1; Makridakis S, 2022, INT J FORECASTING, V38, P1346, DOI 10.1016/j.ijforecast.2021.11.013; Makridakis S, 2018, INT J FORECASTING, V34, P802, DOI 10.1016/j.ijforecast.2018.06.001; Meng QW, 2023, Arxiv, DOI arXiv:2308.01578; Michel Franck, 2020, The Semantic Web - ISWC 2020. 19th International Semantic Web Conference. Lecture Notes in Computer Science (LNCS 12507), P294, DOI 10.1007/978-3-030-62466-8_19; Miller JA, 2017, IEEE INT CONGR BIG, P251, DOI 10.1109/BigDataCongress.2017.40; Min B., 2021, ACM Computing Surveys; Muller K.-R., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P999, DOI 10.1007/BFb0020283; Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]; Oreshkin BN, 2020, Arxiv, DOI arXiv:1905.10437; Nie YQ, 2023, Arxiv, DOI [arXiv:2211.14730, DOI 10.48550/ARXIV.2211.14730]; Panagopoulos G, 2021, AAAI CONF ARTIF INTE, V35, P4838; Peng H, 2019, IEEE INT CONF BIG DA, P3803, DOI 10.1109/BigData47090.2019.9005599; Pestryakova S, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01298-2; Qi X., 2021, arXiv; Quenouille M. H., 1957, Tech. Rep.; RAMSAY JO, 1991, J ROY STAT SOC B MET, V53, P539; Rana Subas, 2023, Big Data - BigData 2023: 12th International Conference, Held as Part of the Services Conference Federation, SCF 2023, Proceedings. Lecture Notes in Computer Science (14203), P18, DOI 10.1007/978-3-031-44725-9_2; Rose P., 2020, Peter rose: Covid-19-net: Integrating health, pathogen and environmental data into a knowledge graph for case tracking, analysis, and forecasting; Rossi E, 2020, Arxiv, DOI [arXiv:2006.10637, 10.48550/arXiv.2006.10637, DOI 10.48550/ARXIV.2006.10637]; Salinas D, 2020, INT J FORECASTING, V36, P1181, DOI 10.1016/j.ijforecast.2019.07.001; Shuo Wang, 2020, SIGSPATIAL '20: Proceedings of the 28th International Conference on Advances in Geographic Information Systems, P163, DOI 10.1145/3397536.3422208; Singh R, 2007, PROC WRLD ACAD SCI E, V26, P361; Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261; Smyl S, 2020, INT J FORECASTING, V36, P75, DOI 10.1016/j.ijforecast.2019.03.017; Steenwinckel Bram, 2020, The Semantic Web - ISWC 2020. 19th International Semantic Web Conference. Lecture Notes in Computer Science (LNCS 12507), P344, DOI 10.1007/978-3-030-62466-8_22; Tang PW, 2022, PROC INT C TOOLS ART, P982, DOI 10.1109/ICTAI56018.2022.00150; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic P., stat, V1050, P10; Wang L, 2020, MEDRXIV; Wen QS, 2022, Arxiv, DOI [arXiv:2202.07125, 10.48550/arxiv.2202.07125, DOI 10.48550/ARXIV.2202.07125, 10.48550/arXiv.2202.07125]; Werner L, 2023, Arxiv, DOI arXiv:2303.15487; Whittle P, 1951, Hypothesis Testing in Time Series Analysis; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; WINTERS PR, 1960, MANAGE SCI, V6, P324, DOI 10.1287/mnsc.6.3.324; Woo G., 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.01575; Wu HX, 2021, ADV NEUR IN, V34; Xie JW, 2020, ANNU REV STAT APPL, V7, P303, DOI 10.1146/annurev-statistics-031219-041131; Xu CJ, 2020, Arxiv, DOI arXiv:1911.07893; Xu K., 2018, arXiv; Yang J, 2023, Arxiv, DOI arXiv:2110.00269; Yi-Fan Li, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P61, DOI 10.1145/3462203.3475929; Yue ZH, 2022, AAAI CONF ARTIF INTE, P8980; Yunshan Ma, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P82, DOI 10.1145/3372278.3390677; Zha M., 2022, arXiv; Zhang ZW, 2023, Arxiv, DOI arXiv:2307.01616; Zhao Z., 2023, IEEE Transactions on Knowledge and Data Engineering; Zhao ZQ, 2023, Arxiv, DOI arXiv:2305.14582; Zheng X, 2023, Arxiv, DOI [arXiv:2303.18205, 10.48550/arXiv.2303.18205]; Zhou GB, 2016, INT J AUTOM COMPUT, V13, P226, DOI 10.1007/s11633-016-1006-2; Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106; Zhou T., 2022, Adv. Neural Inf. Process. Syst, V35, P12677; Zhou T, 2022, PR MACH LEARN RES; Zhu QB, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15040951; Zhu R, 2022, AGILE GIScience, V3, DOI 10.5194/agile-giss-3-21-2022	97	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-3912-3				2023							42	51		10.1109/CIC58953.2023.00016	http://dx.doi.org/10.1109/CIC58953.2023.00016			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW6BZ					2024-07-03	WOS:001170790200006
J	Koonchanok, R; Pan, YL; Jang, H				Koonchanok, Ratanond; Pan, Yanling; Jang, Hyeju			Public attitudes toward chatgpt on twitter: sentiments, topics, and occupations	SOCIAL NETWORK ANALYSIS AND MINING			English	Article						ChatGPT; Twitter; Sentiment analysis; Topic modeling; Social media; Public perception		ChatGPT sets a new record with the fastest-growing user base, as a chatbot powered by a large language model (LLM). While it demonstrates state-of-the-art capabilities in a variety of language-generation tasks, it also raises widespread public concerns regarding its societal impact. In this paper, we investigated public attitudes towards ChatGPT by applying natural language processing techniques such as sentiment analysis and topic modeling to Twitter data from December 5, 2022 to June 10, 2023. Our sentiment analysis results indicate that the overall sentiment was largely neutral to positive, and negative sentiments were decreasing over time. Our topic model reveals that the most popular topics discussed were Education, Bard, Google Search, OpenAI, Marketing, and Cybersecurity, but the ranking varies by month. We also analyzed the occupations of Twitter users and found that those with occupations in arts and entertainment tweeted about ChatGPT most frequently. Additionally, people tended to tweet about topics relevant to their occupation. For instance, Cybersecurity is the most discussed topic among those with occupations related to computer and math, and Education is the most discussed topic among those in academic and research. Overall, our exploratory study provides insights into the public perception of ChatGPT, which could be valuable to both the general public and developers of this technology.	[Koonchanok, Ratanond] Indiana Univ Indianapolis, Dept Human Ctr Comp, Indianapolis, IN 46202 USA; [Pan, Yanling] Indiana Univ Indianapolis, Luddy Sch Informat Comp & Engn, Indianapolis, IN USA; [Jang, Hyeju] Indiana Univ Indianapolis, Dept Comp Sci, Indianapolis, IN USA	Indiana University System; Indiana University Indianapolis; Indiana University System; Indiana University Indianapolis; Indiana University System; Indiana University Indianapolis	Koonchanok, R (corresponding author), Indiana Univ Indianapolis, Dept Human Ctr Comp, Indianapolis, IN 46202 USA.	rkoonch@iu.edu		Pan, Yanling/0000-0002-0915-2639				Abdullah MA, 2022, I COMP CONF WAVELET, DOI 10.1109/ICCWAMTIP56608.2022.10016485; Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Barbieri F, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P258; Barbieri F, 2020, Arxiv, DOI [arXiv:2010.12421, DOI 10.48550/ARXIV.2010.12421, 10.48550/ARXIV.2010.12421]; BII PK, 2018, UNIVERSAL J ED RES, V6, P1586, DOI [DOI 10.13189/UJER.2018.060719, 10.13189/ujer.2018.060719]; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900; Buchanan B, 2021, Truth, lies, and automation: How language models could change disinformation; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chen M., 2021, arXiv; Cheng Y, 2022, J PROD BRAND MANAG, V31, P252, DOI 10.1108/JPBM-05-2020-2907; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; de Cosmo LM., 2021, Italian Journal of Marketing, V1, P83, DOI DOI 10.1007/S43039-021-00020-1; Dempere J, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1206936; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Fatouros G, 2023, MACH LEARN APPL, V14, DOI 10.1016/j.mlwa.2023.100508; Frewer L.J., 1998, J RISK RES, V1, P221, DOI [https://doi.org/10.1080/136698798377141, DOI 10.1080/136698798377141]; Frith KH, 2023, NURS EDUC PERSPECT, V44, P198, DOI 10.1097/01.NEP.0000000000001129; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Han SM, 2024, Arxiv, DOI arXiv:2209.00840; Haque M.U., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.05856; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Jakesch M, 2023, arXiv; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Korkmaz A., 2023, Iraqi Journal For Computer Science and Mathematics, V4, P202, DOI 10.52866/ijcsm.2023.02.02.018; Kung TH, 2022, medRxiv, DOI [10.1101/2022.12.19.22283643, 10.1101/2022.12.19.22283643v2, DOI 10.1101/2022.12.19.22283643V2, 10.1101/2022.12.19.22283643, DOI 10.1101/2022.12.19.22283643]; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Leiter C, 2023, Arxiv, DOI [arXiv:2302.13795, DOI 10.48550/ARXIV.2302.13795]; Li LY, 2023, Arxiv, DOI [arXiv:2305.02201, 10.48550/arXiv.2305.02201]; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lin SPN, 2022, Arxiv, DOI [arXiv:2205.14334, 10.48550/ARXIV.2205.14334]; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Loureiro D., 2022, arXiv; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mirowski P., 2022, arXiv; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Okey OD, 2023, COMPUT SECUR, V135, DOI 10.1016/j.cose.2023.103476; Praveen SV, 2023, ANN BIOMED ENG, V51, P1654, DOI 10.1007/s10439-023-03222-0; Shoufan A, 2023, IEEE ACCESS, V11, P38805, DOI 10.1109/ACCESS.2023.3268224; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tounsi A, 2023, 2023 IEEE INT C ADV, P1; Tubishat M, 2023, 2023 INT C SMART APP, P1; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Zhou KTY, 2023, Arxiv, DOI [arXiv:2302.13439, 10.48550/ARXIV.2302.13439]; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	52	0	0	4	4	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA	1869-5450	1869-5469		SOC NETW ANAL MIN	Soc. Netw. Anal. Min.	MAY 20	2024	14	1							106	10.1007/s13278-024-01260-7	http://dx.doi.org/10.1007/s13278-024-01260-7			13	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	RK5G9		Green Submitted			2024-07-03	WOS:001227565700002
C	Hu, HC; Liu, QJ; Li, C; Kan, MY		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Hu, Hengchang; Liu, Qijiong; Li, Chuang; Kan, Min-Yen			Lightweight Modality Adaptation to Sequential Recommendation via Correlation Supervision	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Recommender System; Multimodal Recommendation; Knowledge Distillation		In Sequential Recommenders (SR), encoding and utilizing modalities in an end-to-end manner is costly in terms of modality encoder sizes. Two-stage approaches can mitigate such concerns, but they suffer from poor performance due to modality forgetting, where the sequential objective overshadows modality representation. We propose a lightweight knowledge distillation solution that preserves both merits: retaining modality information and maintaining high efficiency. Specifically, we introduce a novel method that enhances the learning of embeddings in SR through the supervision of modality correlations. The supervision signals are distilled from the original modality representations, including both (1) holistic correlations, which quantify their overall associations, and (2) dissected correlation types, which refine their relationship facets (honing in on specific aspects like color or shape consistency).To further address the issue of modality forgetting, we propose an asynchronous learning step, allowing the original information to be retained longer for training the representation learning module. Our approach is compatible with various backbone architectures and outperforms the top baselines by 6.8% on average. We empirically demonstrate that preserving original feature associations from modality encoders significantly boosts taskspecific recommendation adaptation. Additionally, we find that larger modality encoders (e.g., Large Language Models) contain richer feature sets which necessitate more fine-grained modeling to reach their full performance potential.	[Hu, Hengchang; Li, Chuang; Kan, Min-Yen] Natl Univ Singapore, Singapore, Singapore; [Liu, Qijiong] Hong Kong Polytech Univ, Hong Kong, Peoples R China	National University of Singapore; Hong Kong Polytechnic University	Hu, HC (corresponding author), Natl Univ Singapore, Singapore, Singapore.	huhengc@comp.nus.edu.sg; jyonn.liu@connect.polyu.hk; lichuang@comp.nus.edu.sg; kanmy@comp.nus.edu.sg						Cao Y., 2022, 2022 IEEE 25 INT C C, P1010; Chen XN, 2022, PROC CVPR IEEE, P12042, DOI 10.1109/CVPR52688.2022.01174; Chen X, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3281659; Cohen I., 2009, Speech Process, P1; Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190; Elsayed S, 2023, LECT NOTES ELECTR EN, V981, P109, DOI 10.1007/978-3-031-22192-7_7; Gao QQ, 2019, LECT NOTES COMPUT SC, V11362, P527, DOI 10.1007/978-3-030-20890-5_34; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He RN, 2016, AAAI CONF ARTIF INTE, P144; He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hou Y., 2023, P ACM WEB C 2023 WWW, P1162; Hu H., 2022, P 16 ACM C REC SYST; Hu HC, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P843, DOI 10.1145/3583780.3614775; Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30; Kingma D. P., 2015, ICLR POSTER, P1; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Lee SH, 2018, LECT NOTES COMPUT SC, V11210, P339, DOI 10.1007/978-3-030-01231-1_21; Lee Y, 2022, INTERSPEECH, P3588, DOI 10.21437/Interspeech.2022-11112; Lian DF, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P695, DOI 10.1145/3366423.3380151; Liu C, 2021, AAAI CONF ARTIF INTE, V35, P4249; Liu DG, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P831, DOI 10.1145/3397271.3401083; Liu F, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1526, DOI 10.1145/3343031.3350953; Liu Q., 2022, COLING, P2823; Liu S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3020, DOI 10.1145/3308558.3313513; Liu Y., 2019, End-to-end speech translation with knowledge distillation; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Liu Z, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2022, P99, DOI [10.1145/3512527.3531378, 10.1016/j.procs.2022.08.012]; McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755; Oramas S., 2017, P 2 WORKSH DEEP LEAR, P32, DOI DOI 10.1145/3125486.3125492; Park M, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P229, DOI 10.1145/3523227.3546768; Raffel C, 2020, J MACH LEARN RES, V21; Rajasegaran J., 2021, Self-supervised knowledge distillation for few-shot learning; Rendle S, 2012, Arxiv, DOI arXiv:1205.2618; Sanh Victor, 2019, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Singer U, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P937, DOI 10.1145/3488560.3498453; Song KZ, 2023, Arxiv, DOI arXiv:2304.13277; Su MY, 2023, IEEE T MULTIMEDIA, V25, P662, DOI 10.1109/TMM.2021.3129623; Tan Y.K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17, DOI 10.1145/2988450.2988452; Tikk D., 2016, C TRACK P; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034; Wu CH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1652, DOI 10.1145/3404835.3463069; Wu S, 2019, AAAI CONF ARTIF INTE, P346; Xia X, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P546, DOI 10.1145/3477495.3531775; Xie YQ, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1611, DOI 10.1145/3477495.3531963; Yanning Zhou, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12261), P521, DOI 10.1007/978-3-030-59710-8_51; Yuan Z, 2023, Arxiv, DOI arXiv:2303.13835; Zeng A., 2023, P 11 INT C LEARN REP; Zhang JH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3872, DOI 10.1145/3474085.3475259; Zhang SX, 2015, ADV NEUR IN, V28; Zhang Y, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P735, DOI 10.1145/3336191.3371790; Zhao BR, 2022, PROC CVPR IEEE, P11943, DOI 10.1109/CVPR52688.2022.01165	58	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56026-2; 978-3-031-56027-9	LECT NOTES COMPUT SC			2024	14608						123	139		10.1007/978-3-031-56027-9_8	http://dx.doi.org/10.1007/978-3-031-56027-9_8			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DX		Green Submitted			2024-07-03	WOS:001211830500008
J	Nakamoto, R; Flanagan, B; Yamauchi, T; Dai, YL; Takami, K; Ogata, H				Nakamoto, Ryosuke; Flanagan, Brendan; Yamauchi, Taisei; Dai, Yiling; Takami, Kyosuke; Ogata, Hiroaki			Enhancing Automated Scoring of Math Self-Explanation Quality Using LLM-Generated Datasets: A Semi-Supervised Approach	COMPUTERS			English	Article						self-explanation; automated scoring; semi-supervised learning; language learning model (LLM); data augmentation	ABSOLUTE ERROR MAE; WORKED-EXAMPLES; RMSE	In the realm of mathematics education, self-explanation stands as a crucial learning mechanism, allowing learners to articulate their comprehension of intricate mathematical concepts and strategies. As digital learning platforms grow in prominence, there are mounting opportunities to collect and utilize mathematical self-explanations. However, these opportunities are met with challenges in automated evaluation. Automatic scoring of mathematical self-explanations is crucial for preprocessing tasks, including the categorization of learner responses, identification of common misconceptions, and the creation of tailored feedback and model solutions. Nevertheless, this task is hindered by the dearth of ample sample sets. Our research introduces a semi-supervised technique using the large language model (LLM), specifically its Japanese variant, to enrich datasets for the automated scoring of mathematical self-explanations. We rigorously evaluated the quality of self-explanations across five datasets, ranging from human-evaluated originals to ones devoid of original content. Our results show that combining LLM-based explanations with mathematical material significantly improves the model's accuracy. Interestingly, there is an optimal limit to how many synthetic self-explanation data can benefit the system. Exceeding this limit does not further improve outcomes. This study thus highlights the need for careful consideration when integrating synthetic data into solutions, especially within the mathematics discipline.	[Nakamoto, Ryosuke; Yamauchi, Taisei] Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan; [Flanagan, Brendan] Kyoto Univ, Inst Liberal Arts & Sci, Ctr Innovat Res & Educ Data Sci, Kyoto 6068501, Japan; [Dai, Yiling; Takami, Kyosuke; Ogata, Hiroaki] Kyoto Univ, Acad Ctr Comp & Media Studies, Kyoto 6068501, Japan; [Takami, Kyosuke] Natl Inst Educ Policy Res, Educ Data Sci Ctr, Tokyo 1008951, Japan	Kyoto University; Kyoto University; Kyoto University	Nakamoto, R (corresponding author), Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.; Flanagan, B (corresponding author), Kyoto Univ, Inst Liberal Arts & Sci, Ctr Innovat Res & Educ Data Sci, Kyoto 6068501, Japan.	s0527225@gmail.com; flanagan.brendanjohn.4n@kyoto-u.ac.jp	Takami, Kyosuke/HJA-6523-2022	Takami, Kyosuke/0000-0002-0913-4641; Dai, Yiling/0000-0001-9900-8763; Nakamoto, Ryosuke/0000-0002-3384-7916	JSPS Grant-in-Aid for Scientific Research	JSPS Grant-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	We used LLM for the English proofreading of this paper and this fact has been explicitly mentioned for transparency. As this study involves the use of student data, we acknowledge the importance of obtaining approval from the Institutional Review Board (IRB). We have taken the necessary steps to ensure compliance with ethical guidelines, and the study has been submitted to and approved by the IRB. Consent for using the students' data in our research is obtained from their guardians at the beginning of each academic year. We provide detailed information about the purpose of data collection, how it will be used, and the measures taken to ensure confidentiality and privacy. The guardians have the right to decline consent or withdraw their consent at any time without any negative consequences for the students.	Andonian Alex, 2021, GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch; [Anonymous], 1998, The Mathematics Teacher; [Anonymous], 2023, Hugging Face; Antulov-Fantulin N., 2014, Discovery Science. DS 2014. Lecture Notes in Computer Science, VVolume 8777, DOI [10.1007/978-3-319-11812-3_3, DOI 10.1007/978-3-319-11812-3_3]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Berg Alan M., 2016, Journal of Learning Analytics, V3, P107, DOI DOI 10.18608/JLA.2016.31.7; Berthold K, 2009, J EDUC PSYCHOL, V101, P70, DOI 10.1037/a0013247; Berthold K, 2009, INSTR SCI, V37, P345, DOI 10.1007/s11251-008-9051-z; Bisra K, 2018, EDUC PSYCHOL REV, V30, P703, DOI 10.1007/s10648-018-9434-x; Cascante-Bonilla P., 2020, P AAAI C ART INT NEW; Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014; CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1016/0364-0213(94)90016-7; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Conati C., 2000, INT J ARTIFICIAL INT, V11, P389; Crippen KJ, 2007, COMPUT EDUC, V49, P809, DOI 10.1016/j.compedu.2005.11.018; Crossley S.A., 2019, P INT C ART INT ED C; Dahmen J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051181; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; El Emam K, 2020, IEEE SECUR PRIV, V18, P56, DOI 10.1109/MSEC.2020.2992821; Flanagan B, 2022, IEEE ACCESS, V10, P26230, DOI 10.1109/ACCESS.2022.3156073; Flanagan B, 2018, KNOWL MANAG E-LEARN, V10, P469; Funayama H., 2023, P INT C ART INT ED T; Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91; He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969; Hodds M, 2014, J RES MATH EDUC, V45, P62; Hodson TO, 2022, GEOSCI MODEL DEV, V15, P5481, DOI 10.5194/gmd-15-5481-2022; León JA, 2006, BEHAV RES METHODS, V38, P616, DOI 10.3758/BF03193894; Lightman H, 2023, Arxiv, DOI [arXiv:2305.20050, DOI 10.48550/ARXIV.2305.20050]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; McEldoon KL, 2013, BRIT J EDUC PSYCHOL, V83, P615, DOI 10.1111/j.2044-8279.2012.02083.x; McNamara DS, 2004, BEHAV RES METH INS C, V36, P222, DOI 10.3758/BF03195567; Nakamoto R., 2021, P 29 INT C COMP ED O, VVolume 2021, P22; Nakamoto R, 2024, RES PRACT TECH ENHAN, V19, DOI 10.58459/rptel.2024.19016; Ozsoy MG, 2011, J INF SCI, V37, P405, DOI 10.1177/0165551511408848; Panaite M., 2018, P INT C ART INT ED L; Panaite M., 2019, P EUR C TECHN ENH LE; Peña-Ayala A, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1243; Ping HY, 2017, SSDBM 2017: 29TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, DOI 10.1145/3085504.3091117; Renkl A, 2017, ZDM-MATH EDUC, V49, P571, DOI 10.1007/s11858-017-0859-3; Rittle-Johnson B, 2006, CHILD DEV, V77, P1, DOI 10.1111/j.1467-8624.2006.00852.x; Rittle-Johnson B, 2017, CHILD DEV PERSPECT, V11, P184, DOI 10.1111/cdep.12229; Rittle-Johnson B, 2017, ZDM-MATH EDUC, V49, P599, DOI 10.1007/s11858-017-0834-z; Rubin D.B., 1993, J. Off. Stat, V9, P461; Salazar A, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113819; Suzuki Masatoshi, 2019, Pretrained japanese bert models; Chawla NV, 2011, Arxiv, DOI [arXiv:1106.1813, 10.48550/arxiv.1106.1813, 10.1613/jair.953]; Vaswani A, 2017, ADV NEUR IN, V30; Wang T., 2019, P C EMP METH NAT LAN	49	2	2	9	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2073-431X			COMPUTERS	Computers	NOV	2023	12	11							217	10.3390/computers12110217	http://dx.doi.org/10.3390/computers12110217			18	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	Y9CP3		gold, Green Submitted			2024-07-03	WOS:001108169700001
C	Xu, ZC; Cohen, D			ACM	Xu, Zhichao; Cohen, Daniel			A Lightweight Constrained Generation Alternative for Query-focused Summarization	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Query-focused Summarization; Constrained Generation		Query-focused summarization (QFS) aims to provide a summary of a document that satisfies information need of a given query and is useful in various IR applications, such as abstractive snippet generation. Current QFS approaches typically involve injecting additional information, e.g. query-answer relevance or fine-grained token-level interaction between a query and document, into a finetuned large language model. However, these approaches often require extra parameters & training, and generalize poorly to new dataset distributions. To mitigate this, we propose leveraging a recently developed constrained generation model Neurological Decoding (NLD) as an alternative to current QFS regimes which rely on additional sub-architectures and training. We first construct lexical constraints by identifying important tokens from the document using a lightweight gradient attribution model, then subsequently force the generated summary to satisfy these constraints by directly manipulating the final vocabulary likelihood. This lightweight approach requires no additional parameters or finetuning as it utilizes both an off-the-shelf neural retrieval model to construct the constraints and a standard generative language model to produce the QFS. We demonstrate the efficacy of this approach on two public QFS collections achieving near parity with the state-of-the-art model with substantially reduced complexity.	[Xu, Zhichao] Univ Utah, Salt Lake City, UT 84112 USA; [Cohen, Daniel] Dataminr Inc, Nyc, NY USA	Utah System of Higher Education; University of Utah	Xu, ZC (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.	zhichao.xu@utah.edu; daniel.cohen@dataminr.com	Xu, Zhichao/V-2231-2017	Xu, Zhichao/0000-0002-2370-4487	NSF [DMS-2134223, IIS-2205418]	NSF(National Science Foundation (NSF))	Zhichao Xu is supported partially by NSF IIS-2205418 and NSF DMS-2134223. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.	Ai Qingyao, 2023, ARXIV230407944; Anderson P., 2016, CoRR; [Anonymous], 2017, ARXIV170407138; Bast H, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2590972; Boytsov Leonid, 2022, ARXIV220701262; Chen WF, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1309, DOI 10.1145/3366423.3380206; Dang HT, 2006, P WORKSH TASK FOC SU, P48, DOI DOI 10.3115/1654679.1654689; Deng Yang, 2020, ARXIV201003738; Erdem E, 2022, J ARTIF INTELL RES, V73, P1131; Feng S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3719; Ji Ziwei, 2022, COMPUT SURVEYS; Jin Qiao, 2019, ARXIV190906146; Laskar Md Tahmid Rahman, 2020, Advances in Artificial Intelligence. 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12109), P342, DOI 10.1007/978-3-030-47358-7_35; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Loshchilov I., 2017, CoRR; Lu Ximing, 2020, ARXIV201012884; Lu Ximing, 2021, ARXIV211208726; Luyu Gao, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P280, DOI 10.1007/978-3-030-72240-1_26; Maynez Joshua, 2020, ARXIV200500664; Nema Preksha, 2017, ARXIV170408300; Nguyen Tri, 2016, COCO NIPS; Nogueira R., 2020, Findings of EMNLP; Park C, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2589, DOI 10.1145/3477495.3531901; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Ross Alexis, 2020, ARXIV201213985; Sanchez I., 2015, AAAI SPRING S KNOWL, V1, P4; Selvaggio G, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15299-5; Simonyan Karen, 2014, WORKSH INT C LEARN R, P2; Smilkov D, 2017, Smoothgrad: removing noise by adding noise; Su Dan, 2021, ARXIV210512969; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tombros A., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P2, DOI 10.1145/290941.290947; Turpin Andrew, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P127, DOI 10.1145/1277741.1277766; Vaswani A, 2017, ADV NEUR IN, V30; Wang Junlin, 2020, ARXIV201005419; Xie Yujia, 2020, ARXIV200207338	36	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							1745	1749		10.1145/3539618.3591936	http://dx.doi.org/10.1145/3539618.3591936			5	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		hybrid, Green Submitted			2024-07-03	WOS:001118084001078
J	Gärtner, AE; Göhlich, D				Gaertner, Alexander Elenga; Goehlich, Dietmar			Automated requirement contradiction detection through formal logic and LLMs	AUTOMATED SOFTWARE ENGINEERING			English	Article						Contradiction detection; Requirements engineering; Natural language processing		This paper introduces ALICE (Automated Logic for Identifying Contradictions in Engineering), a novel automated contradiction detection system tailored for formal requirements expressed in controlled natural language. By integrating formal logic with advanced large language models (LLMs), ALICE represents a significant leap forward in identifying and classifying contradictions within requirements documents. Our methodology, grounded on an expanded taxonomy of contradictions, employs a decision tree model addressing seven critical questions to ascertain the presence and type of contradictions. A pivotal achievement of our research is demonstrated through a comparative study, where ALICE's performance markedly surpasses that of an LLM-only approach by detecting 60% of all contradictions. ALICE achieves a higher accuracy and recall rate, showcasing its efficacy in processing real-world, complex requirement datasets. Furthermore, the successful application of ALICE to real-world datasets validates its practical applicability and scalability. This work not only advances the automated detection of contradictions in formal requirements but also sets a precedent for the application of AI in enhancing reasoning systems within product development. We advocate for ALICE's scalability and adaptability, presenting it as a cornerstone for future endeavors in model customization and dataset labeling, thereby contributing a substantial foundation to requirements engineering.	[Gaertner, Alexander Elenga] IAV GmbH, Berlin, Germany; [Goehlich, Dietmar] TU Berlin, Berlin, Germany	IAV GmbH; Technical University of Berlin	Gärtner, AE (corresponding author), IAV GmbH, Berlin, Germany.	a.e.gaertner@outlook.de; dietmar.goehlich@tu-berlin.de			Technische Universitt Berlin (3136)	Technische Universitt Berlin (3136)	We thank IAV GmbH for providing us with the requirements specifications for electric buses.	Ahmad A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217749; [Anonymous], 2019, VDI 2221 Blatt 1:2019-11: design of technical products and systems-model of product design; [Anonymous], 2009, DIN 69901-5:2009-01; [Anonymous], 2018, IEEE/ISO/IEC 29148-2018; Aristotle, 1999, ARISTOTLES METAPHYSI; Bender B., 2021, Pahl/Beitz Konstruktionslehre: Methoden and Anwendung Erfolgreicher Produktentwicklung, P169, DOI [10.1007/978-3-662-57303-77, DOI 10.1007/978-3-662-57303-77]; Chen ZG, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P106; De Marneffe M.C., 2008, Finding Contradictions in Text; Dick J., 2017, Requirements Engineering, V4, DOI DOI 10.1007/978-3-319-61073-3; Frattini J, 2023, REQUIR ENG, V28, P49, DOI 10.1007/s00766-022-00371-x; Friedman L., 2020, Math, Manim, Neural Networks & Teaching with 3Blue1Brown (118); Gärtner AE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157628; Gartner A.E., 2024, INT DES C HG DES 24; Gericke K., 2012, Proceedings of International Design Conference, DESIGN, V70, P171; Gervasi V, 2005, ACM T SOFTW ENG METH, V14, P277, DOI 10.1145/1072997.1072999; Ghlich D., 2008, Forschung fr das Auto von morgen, P129, DOI [10.1007/978-3-540-74151-02, DOI 10.1007/978-3-540-74151-02]; Göhlich D, 2018, DES SCI, V4, DOI 10.1017/dsj.2018.10; Gohlich D., 2021, Pahl/Beitz Konstruktionslehre. Methoden and Anwendung erfolgreicher Produktentwicklung, P211; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Grtner AE., 2023, Proc. Des. Soc, V3, P707, DOI [10.1017/pds.2023.71, DOI 10.1017/PDS.2023.71]; Guo W., 2021, arXiv; Heitmeyer C. L., 1996, ACM Transactions on Software Engineering and Methodology, V5, P231, DOI 10.1145/234426.234431; Horn Laurence R., 2018, The Stanford Encyclopedia of Philosophy; Hunter A., 1998, ACM Transactions on Software Engineering and Methodology, V7, P335, DOI 10.1145/292182.292187; Jang A., 2020, Contradictory, My Dear Watson; Jindal R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2027, DOI 10.1109/ICACCI.2016.7732349; Johnson-Laird PN., 2006, How We Reason, 1; Jurafsky D., 2021, SPEECH LANGUAGE PROC; Karlova-Bourbonus N., 2019, Automatic detection of contradictions in texts; Kim H.K., 2018, 2018 IEEE ACIS 19 IN; Knothe F., 2006, ATZ Automob. Z, V108, P800, DOI [10.1007/BF03221821, DOI 10.1007/BF03221821]; Kurtanovic Z, 2017, INT REQUIR ENG CONF, P490, DOI 10.1109/RE.2017.82; Li LY, 2017, ALGORITHMS, V10, DOI 10.3390/a10020059; Liu Q, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1501; Loucopoulos P., 2005, Design process improvement, P116, DOI [10.1007/978-1-84628-061-05, DOI 10.1007/978-1-84628-061-05]; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Montgomery L, 2022, REQUIR ENG, V27, P183, DOI 10.1007/s00766-021-00367-z; NEWELL A, 1956, IRE T INFORM THEOR, V2, P61, DOI 10.1109/tit.1956.1056797; openai, 2023, GPT-4 Technical Report, P7; openai, openai: ChatGPT-Release Notes. The Latest Update for ChatGPT; openai, 2020, openai: Models. GPT-3. Hg. v. openai; Ritter A., 2008, P 2008 C EMP METH NA, P11; Robertson S., 2013, MASTERING REQUIREMEN, V3rd; Russell SJ., 2016, ARTIF INTELL; Schwitter R., 2010, Coling 2010: Posters, P1113; Sepúlveda-Torres R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073060; Sophist GmbH, 2016, Schablonen fur alle Falle; Surana S., 2022, SN Comput. Sci, V3, P187, DOI [10.1007/s42979-022-01075-3, DOI 10.1007/S42979-022-01075-3]; Ting K.M., 2011, ENCY MACHINE LEARNIN, V1st, P209, DOI 10.1007/978-0-387-30164-8_157; Touvron H., 2023, Llama: Open and efficient foundation language models; Wiegers Karl., 2013, SOFTWARE REQUIREMENT; Wohlin C., 2012, Experimentation in Software Engineering, DOI [10.1007/978-3-642-29044-2, DOI 10.1007/978-3-642-29044-2, 10.1007/978-3-642-29044-2.]; Wu X., P 45 INT ACM SIGIR C; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689	54	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0928-8910	1573-7535		AUTOMAT SOFTW ENG	Automat. Softw. Eng.	NOV	2024	31	2							49	10.1007/s10515-024-00452-x	http://dx.doi.org/10.1007/s10515-024-00452-x			33	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TT0B0		hybrid			2024-07-03	WOS:001243380700003
C	Rajala, J; Hukkanen, J; Hartikainen, M; Niemelä, P			ACM	Rajala, Jaakko; Hukkanen, Jenni; Hartikainen, Maria; Niemela, Pia			"Call me Kiran" - ChatGPT as a Tutoring Chatbot in a Computer Science Course	PROCEEDINGS OF THE 26TH INTERNATIONAL ACADEMIC MINDTREK, MINDTREK 2023			English	Proceedings Paper	26th International Academic Mindtrek Conference Mindtrek)	OCT 03-06, 2023	Tampere, FINLAND	ACM In Cooperat, ACM SIGCHI		artificial intelligence; generative AI; ChatGPT; student perceptions; chatbots; education; tutoring; discussion forum		Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students' perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students' learning processes, but does not replace it.	[Rajala, Jaakko; Hukkanen, Jenni; Hartikainen, Maria; Niemela, Pia] Tampere Univ, Tampere, Finland	Tampere University	Rajala, J (corresponding author), Tampere Univ, Tampere, Finland.	jaakko.rajala@tuni.fi; jenni.j.hukkanen@tuni.fi; maria.hartikainen@tuni.fi; pia.niemela@tuni.fi		Hartikainen, Maria/0000-0001-5997-0368; Niemela, Pia/0000-0002-8673-9089				Anbar Ariel D., 2017, AGU FALL M ABSTRACTS, V2017; Conde MA, 2015, LECT NOTES COMPUT SC, V9192, P50, DOI 10.1007/978-3-319-20609-7_6; [Anonymous], 2009, South China Morning Post; BBC, BBC News; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Embretson S.E., 2013, ITEM RESPONSE THEORY; Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Li LY, 2023, Arxiv, DOI [arXiv:2305.02201, 10.48550/arXiv.2305.02201]; Mayring P., 2014, Qualitative content analysis: Theoretical Foundation, Basic procedures and Software Solution, DOI DOI 10.4135/9781446282243.N12; newsroom.sciencespo, Sciences Po bans the use of ChatGPT without transparent referencing-Espace Presse Sciences Po; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Papadimitriou Alexandros, 2023, International Journal of Research in E-learning, V2023, P1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reiser B.J., 1985, P IJCAI, P8; Roose Kevin, 2022, NEW YORK TIMES; smartsparrow, About Smart Sparrow; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; universityworldnews, Universities adjust to ChatGPT, but the 'real AI' lies ahead; Vaswani A, 2017, ADV NEUR IN, V30	21	0	0	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0874-9				2023							83	94		10.1145/3616961.3616974	http://dx.doi.org/10.1145/3616961.3616974			12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4FM		hybrid			2024-07-03	WOS:001147480500008
C	Wang, LY; Liu, SY; Xu, MZ; Song, LF; Shi, SM; Tu, ZP		Rogers, A; Boyd-Graber, J; Okazaki, N		Wang, Longyue; Liu, Siyou; Xu, Mingzhou; Song, Linfeng; Shi, Shuming; Tu, Zhaopeng			A Survey on Zero Pronoun Translation	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Zero pronouns (ZPs) are frequently omitted in pro-drop languages (e.g. Chinese, Hungarian, and Hindi), but should be recalled in nonpro-drop languages (e.g. English). This phenomenon has been studied extensively in machine translation (MT), as it poses a significant challenge for MT systems due to the difficulty in determining the correct antecedent for the pronoun. This survey paper highlights the major works that have been undertaken in zero pronoun translation (ZPT) after the neural revolution so that researchers can recognize the current state and future directions of this field. We provide an organization of the literature based on evolution, dataset, method, and evaluation. In addition, we compare and analyze competing models and evaluation metrics on different benchmarks. We uncover a number of insightful findings such as: 1) ZPT is in line with the development trend of large language model; 2) data limitation causes learning bias in languages and domains; 3) performance improvements are often reported on single benchmarks, but advanced methods are still far from realworld use; 4) general-purpose metrics are not reliable on nuances and complexities of ZPT, emphasizing the necessity of targeted metrics; 5) apart from commonly-cited errors, ZPs will cause risks of gender bias.	[Wang, Longyue; Liu, Siyou; Xu, Mingzhou; Song, Linfeng; Shi, Shuming; Tu, Zhaopeng] Tencent AI Lab, Shenzhen, Peoples R China	Tencent	Wang, LY (corresponding author), Tencent AI Lab, Shenzhen, Peoples R China.	vinnylywang@tencent.com; lifengjin@tencent.com; shumingshi@tencent.com; zptu@tencent.com						[Anonymous], 2018, EMNLP; [Anonymous], 2016, P 2016 C N AM CHAPT; [Anonymous], 2020, LREC; Bacolini Ilaria, 2017, EXPLORING PARTIAL PR; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Baran Elizabeth, 2012, LREC; Chen Chen, 2013, EMNLP; Chen Chen, 2015, ACL IJCNLP; Chen Chen, 2016, ACL; Chen Mingyang, 2019, EMNLP IJCNLP; Chung Tagyoung, 2010, EMNLP; Farinha Ana C, 2022, P 7 C MACH TRANSL; Freitag Markus, 2019, P 4 C MACH TRANSL; Halliday M. A. K., 1976, COHESION ENGLISH, DOI 10.1677/ERC-09-0254; Huang G., 2021, ARXIV210513072; Hwang Yongkeun, 2021, P 6 C MACH TRANSL; Jwalapuram Prathyusha, 2020, EMNLP; Kimura Ryuichiro, 2019, P MACH TRANSL SUMM 1; Kocmi Tom, 2022, P 7 C MACH TRANSL; Kong Fang, 2010, EMNLP; Koto Fajri, 2021, NAACL; Läubli S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4791; Le Nagard Ronan, 2010, P JOINT 5 WORKSH STA; Li C.N., 1979, DISCOURSE SYNTAX, P311; Lopes Antonio V, 2020, EAMT; Lu Qingyu, 2023, ARAXIV230313809; Lyu Chenyang, 2023, ARXIV230501181; Ma Shuming, 2020, ACL; Mitkov Ruslan, 2014, Anaphora resolution; Moon Jihyung, 2020, EACL; Ohtani Takumi, 2019, DISCOMT; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park Arum, 2015, P 29 PAC AS C LANG I; Peral Jesus, 2003, JAIR; Pereira Simone, 2009, P STUD RES WORKSH; Pradhan Sameer, 2012, CONLL WS; Prasad Rashmi, 2000, DAARC; Rao Sudha, 2015, NAACL; Rei Ricardo, 2020, EMNLP; Ri Ryokan, 2021, WAT; Russo Lorenza, 2012, LREC; Snover M., 2006, P 7 C ASS MACH TRANS, P223; Song Linfeng, 2020, ACL; Sordoni Alessandro., 2015, CIKM; Su Hui, 2019, ACL; Sugiyama Amane, 2019, DISCOMT; Taira Hirotoshi, 2012, P 6 WORKSH SYNT SEM; Tan Xin, 2019, NLPCC; Tan Xin, 2021, EMNLP; Vanmassenhove Eva, 2019, Proceedings of Machine Translation Summit XVIIVolume 1: Research Track, P222; Vaswani A, 2017, ADV NEUR IN, V30; Vincent Sebastian T, 2022, EMNLP; Wang LC, 2018, AAAI CONF ARTIF INTE, P4195; Wang LY, 2017, MACH TRANSL, V31, P65, DOI 10.1007/s10590-016-9184-9; Wang Longyue, 2016, ICASSP; Wang Longyue, 2023, ARXIV230402210; Wang Longyue, 2023, P 8 C MACH TRANSL; Wang Longyue, 2019, EMNLP IJCNLP; Wang Longyue, 2023, Guofeng: A discourse-aware evaluation benchmark for language understanding, translation and generation; Wang Longyue, 2019, THESIS; Wang Longyue, 2016, LREC; Wang Longyue, 2022, EMNLP; Way A., 2017, P 2017 C EMPIRICAL M, DOI [DOI 10.18653/V1/D17-1301, 10.18653/v1/d17-1301]; Werlen Lesly Miculicich, 2017, DISCOMT; Werlen Lesly Miculicich, 2018, EMNLP; Wu Shuangzhi, 2020, P 5 C MACH TRANSL; Xiang Bing, 2013, ACL; Yang JX, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P892; Yang Yaqin, 2010, COLING; Yang Yaqin, 2015, ACL IJCNLP; Yang Z., 2019, ACL; Yin Qingyu, 2018, COLING; Yu Lei, 2020, TACL; Zhan Dong, 2015, P MACH TRANSL SUMM 1; Zhang Weinan, 2019, FRONTIERS COMPUTER S; Zhao Shanheng, 2007, EMNLP CONLL	77	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							3325	3339						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086802003
C	Suraworachet, W; Seon, J; Cukurova, M			Assoc Computing Machinery	Suraworachet, Wannapon; Seon, Jennifer; Cukurova, Mutlu			Predicting challenge moments from students′ discourse: A comparison of GPT-4 to two traditional natural language processing approaches	FOURTEENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, LAK 2024			English	Proceedings Paper	14th Annual International Conference on Learning Analytics and Knowledge (LAK) - Learning Analytics in the Age of Artificial Intelligence	MAR 18-22, 2024	Kyoto, JAPAN	Soc Learning Analyt Res, ACM In Cooperat, SIGWEB, SIGCHI		Collaborative learning; Discourse analysis; Natural language processing; Challenge moments	SOCIALLY SHARED REGULATION; LEARNING SITUATIONS; COLLABORATION; EMOTIONS	Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members ' perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches ' performance for automated detection and support of students' challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.	[Suraworachet, Wannapon; Seon, Jennifer; Cukurova, Mutlu] UCL, London, England	University of London; University College London	Suraworachet, W (corresponding author), UCL, London, England.	wannapon.suraworachet.20@ucl.ac.uk		Suraworachet, Wannapon/0000-0003-3349-4185; Cukurova, Mutlu/0000-0001-5843-4854	UCL AI Co-creator projects	UCL AI Co-creator projects	We would like to thank 2022/2023 DUTE students in MA EdTech at UCL for granting permission to collect data for this study. This work was supported by UCL AI Co-creator projects (summer 2023).	Aggarwal CC., 2012, Mining text data, P1, DOI [DOI 10.1007/978-1-4614-3223-4_1, 10.1007/978-1-4614-3223-4, DOI 10.1007/978-1-4614-3223-4]; [Anonymous], 1999, Collaborative learning: Cognitive and computational approaches pp; [Anonymous], 2011, Assessing 21st century skills: Summary of a workshop. Assessing interpersonal skills; Austin JamesE., 2000, Nonprofit and Voluntary Sector Quarterly, V29, P69, DOI DOI 10.1177/0899764000291S004; Azevedo R, 2005, INSTR SCI, V33, P367, DOI 10.1007/s11251-005-1272-9; Bakhtiar A., 2020, Frontline Learning Research, V8, P1, DOI [10.14786/flr.v8i2.561, DOI 10.14786/FLR.V8I2.561]; Botelho A.F., 2019, Exploring Feature Engineering Methods in Detectors of Student Behavior and Affect; Broadbent J, 2015, INTERNET HIGH EDUC, V27, P1, DOI 10.1016/j.iheduc.2015.04.007; BRUFFEE KA, 1984, COLL ENGL, V46, P635, DOI 10.2307/376924; Bulathwela S., 2023, Artificial Intelligence in Education, P327, DOI [10.1007/978-3-031-36272-9_27, DOI 10.1007/978-3-031-36272-9_27]; Cukurova M, 2020, BRIT J EDUC TECHNOL, V51, P1441, DOI 10.1111/bjet.13015; Damon W., 1984, J APPL DEV PSYCHOL, V5, P331, DOI 10.1016/0193-3973(84)90006-6; Demszky D., 2020, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dowell N., 2022, Handbook of Learning Analytics, V15; Emara M, 2021, J LEARN ANAL, V8, P49, DOI 10.18608/jla.2021.7230; Fernandez-Delgado M., Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?; Forsyth EN, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P19, DOI 10.1109/ICSC.2007.55; Fransen J, 2011, COMPUT HUM BEHAV, V27, P1103, DOI 10.1016/j.chb.2010.05.017; Graesser AC, 2020, LEARN INSTR, V70, DOI 10.1016/j.learninstruc.2019.05.009; Gutwin C., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P411, DOI 10.1023/A:1021271517844; Hadwin A, 2011, TEACH COLL REC, V113, P240; Hadwin AF, 2018, INT J COMP-SUPP COLL, V13, P301, DOI 10.1007/s11412-018-9279-9; Hadwin AF, 2011, EDUC PSYCHOL HANDB, P65; Hur Paul, 2023, LAK2023: LAK23: 13th International Learning Analytics and Knowledge Conference, P630, DOI 10.1145/3576050.3576090; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Järvelä S, 2013, J COGN EDUC PSYCHOL, V12, P267, DOI 10.1891/1945-8959.12.3.267; Järvelä S, 2015, ETR&D-EDUC TECH RES, V63, P125, DOI 10.1007/s11423-014-9358-1; Järvelä S, 2011, TEACH COLL REC, V113, P350; Järvenoja H, 2013, EDUC PSYCHOL-UK, V33, P31, DOI 10.1080/01443410.2012.742334; Järvenoja H, 2009, BRIT J EDUC PSYCHOL, V79, P463, DOI 10.1348/000709909X402811; Kreijns K, 2003, COMPUT HUM BEHAV, V19, P335, DOI 10.1016/S0747-5632(02)00057-2; Lang C., 2017, Handbook of learning analytics, DOI [10.18608/hla17, DOI 10.18608/HLA17]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Ma YB, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P45, DOI 10.1145/3506860.3506865; Malmberg J, 2015, COMPUT HUM BEHAV, V52, P562, DOI 10.1016/j.chb.2015.03.082; Mohammed M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230442; Näykki P, 2021, LEARN CULT SOC INTER, V30, DOI 10.1016/j.lcsi.2021.100536; OpenAI, 2023, ArXiv; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Perry NE, 2006, EDUC PSYCHOL REV, V18, P211, DOI 10.1007/s10648-006-9014-3; Praharaj S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093156; Pugh SL, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P208, DOI 10.1145/3506860.3506894; Rafal CT, 1996, J LEARN SCI, V5, P279, DOI 10.1207/s15327809jls0503_5; Richardson M, 2012, PSYCHOL BULL, V138, P353, DOI 10.1037/a0026838; Romero C, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1355; Roschelle J., 1995, Computer Supported Collaborative Learning. Proceedings NATO Advanced Research Workshop, P69; Rosé C, 2008, INT J COMP-SUPP COLL, V3, P237, DOI 10.1007/s11412-007-9034-0; Rovers SFE, 2019, METACOGN LEARN, V14, P1, DOI 10.1007/s11409-019-09188-6; Schneider B, 2013, INT J COMP-SUPP COLL, V8, P375, DOI 10.1007/s11412-013-9181-4; Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737; Sullivan FR, 2019, BRIT J EDUC TECHNOL, V50, P3047, DOI 10.1111/bjet.12875; Ucan S, 2015, INT J SCI EDUC, V37, P2503, DOI 10.1080/09500693.2015.1083634; Welch M, 1998, J TEACH EDUC, V49, P26, DOI 10.1177/0022487198049001004; Winne P.H., 2002, New directions in measures and methods, Advances in motivation and achievement, V12, P121; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754; Zambrano A.F., 2023, EdArXiv; Zheng J, 2019, COMPUT EDUC, V136, P34, DOI 10.1016/j.compedu.2019.03.005	58	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1618-8				2024							473	485		10.1145/3636555.3636905	http://dx.doi.org/10.1145/3636555.3636905			13	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW6NI		hybrid, Green Submitted			2024-07-03	WOS:001179044200044
C	Li, TL; Ma, XG; Zhuang, A; Gu, Y; Su, Y; Chen, WH		Rogers, A; Boyd-Graber, J; Okazaki, N		Li, Tianle; Ma, Xueguang; Zhuang, Alex; Gu, Yu; Su, Yu; Chen, Wenhu			Few-shot In-context Learning for Knowledge Base Question Answering	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Question answering over knowledge bases is considered a difficult problem due to the challenge of generalizing to a wide variety of possible natural language questions. Additionally, the heterogeneity of knowledge base schema items between different knowledge bases often necessitates specialized training for different knowledge base question-answering (KBQA) datasets. To handle questions over diverse KBQA datasets with a unified training-free framework, we propose KB-BINDER, which for the first time enables few-shot in-context learning over KBQA tasks. Firstly, KB-BINDER leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching. The experimental results on four public heterogeneous KBQA datasets show that KB-BINDER can achieve a strong performance with only a few in-context demonstrations. Especially on GraphQA and 3-hop MetaQA, KB-BINDER can even outperform the state-of-the-art trained models. On GrailQA and WebQSP, our model is also on par with other fully-trained models. We believe KB-BINDER can serve as an important baseline for future research. Our code is available at https://github.com/ltl3A87/KB-BINDER	[Li, Tianle; Ma, Xueguang; Zhuang, Alex; Chen, Wenhu] Univ Waterloo, Waterloo, ON, Canada; [Gu, Yu; Su, Yu] Ohio State Univ, Columbus, OH USA; [Chen, Wenhu] Vector Inst, Toronto, ON, Canada	University of Waterloo; University System of Ohio; Ohio State University; Vector Institute for Artificial Intelligence	Li, TL (corresponding author), Univ Waterloo, Waterloo, ON, Canada.	t29li@uwaterloo.ca; x93ma@uwaterloo.ca; a5zhuang@uwaterloo.ca; gu.826@osu.edu; su.809@osu.edu; wenhuchen@uwaterloo.ca						[Anonymous], 2013, P 2013 C EMPIRICAL M; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Shuang, 2021, ANN M ASS COMP LING; Chen Tworek Jun Yuan Ponde Kaplan Ed- wards Burda Joseph Brockman Ray Puri Krueger Petrov Khlaaf Sastry Mishkin Chan Gray Ryder Pavlov Power Kaiser Bavarian Winter Tillet Mark Jerry Heewoo Qiming Henrique Jared Harrison Yura Nicholas Greg Alex Raul Gretchen Michael Heidy Girish Pamela Brooke Scott Nick Mikhail Alethea Lukasz Moham- mad Clemens Philippe, 2021, ABS210703374 ARXIV; Chen Wenhu, 2022, ABS221112588 ARXIV; Cheng Zhoujun, 2022, ABS221002875 ARXIV; Dong L, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P33; Dunn A., 2022, Structured information extraction from complex scientific text with fine-tuned large language models; Gao Luyu, 2022, ABS221110435 ARXIV; Gu Yu, 2022, INT C COMP LING; Gu Yu, 2020, P WEB C 2021; Gu Yu, 2023, DONT GENERATE DISCRI; Gu Yu, 2022, 4 C AUT KNOWL BAS CO; He Gaole, 2021, P 14 ACM INT C WEB S; Hua Yuncheng, 2020, ABS201015877 ARXIV; Izacard Gautier, 2021, Unsupervised dense information retrieval with contrastive learning; Kojima Takeshi, 2022, Large language models are zero-shot reasoners; Kumar Ananya, 2022, ABS220210054 ARXIV; Lampinen Andrew K., 2022, CAN LANGUAGE MODELS; Lan Yunshi, 2021, INT JOINT C ART INT; Lan Yunshi, 2020, ANN M ASS COMP LING; Lewkowycz Aitor, 2022, Solving quantitative reasoning problems with language models; Liu Jiachang, 2021, ABS210106804 CORR; Miller Alexander H., 2016, ABS160603126 ARXIV; Min Sewon, 2022, EMNLP; Nye M. I., 2021, Show your work: Scratchpads for intermediate computation with language models; Olsson Catherine, 2022, Transformer Circuits; Reddy Siva, 2017, C EMP METH NAT LANG; Saxena Apoorv, 2020, ANN M ASS COMP LING; Shu Yiheng, 2022, ABS221012925 ARXIV; Su Yu, 2016, C EMP METH NAT LANG; Sun Haitian, 2019, ABS190409537 ARXIV; Sun Haitian, 2018, C EMP METH NAT LANG; Sun Yawei, 2020, AAAI C ART INT; Suzgun Mirac, 2022, ABS221009261 ARXIV; Talmor Alon, 2018, N AM CHAPT ASS COMP; Wang Xingyao, 2022, ABS221012810 ARXIV; Wang Xuezhi, 2022, ABS220311171 ARXIV; Wei Jason, 2022, CoRR, abs/2201.11903.; Wei Jason, 2022, ABS220111903 ARXIV; Wu Peiyun, 2019, CHIN C KNOWL GRAPH S; Xie Sang Michael, 2021, ARXIV211102080; Ye Xi, 2021, ABS210908678 ARXIV; Yih Scott Wen-tau, 2015, P JOINT C 53 ANN M A; Yih WT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P201; Yu Donghan, 2022, ABS221000063 ARXIV; Zan Daoguang, 2022, PAC AS C KNOWL DISC; Zhang Yuyu, 2017, AAAI C ART INT; Zhou Denny, 2022, ABS220510625 ARXIV; Zhou Hattie, 2022, ABS221109066 ARXIV	51	1	1	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							6966	6980						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086806004
C	Zuccon, G; Scells, H; Zhuang, SY			ACM	Zuccon, Guido; Scells, Harrisen; Zhuang, Shengyao			Beyond CO<sub>2</sub> Emissions: The Overlooked Impact of Water Consumption of Information Retrieval Models	PROCEEDINGS OF THE 2023 ACM SIGIR INTERNATIONAL CONFERENCE ON THE THEORY OF INFORMATION RETRIEVAL, ICTIR 2023			English	Proceedings Paper	13th ACM SIGIR International Conference on the Theory of Information Retrieval (ICTIR)	JUL 23, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Green IR; Deep Learning; Water Consumption; IR Sustainability		As in other fields of artificial intelligence, the information retrieval community has grown interested in investigating the power consumption associated with neural models, particularly models of search. This interest has become particularly relevant as the energy consumption of information retrieval models has risen with new neural models based on large language models, leading to an associated increase of CO2 emissions, albeit relatively low compared to fields such as natural language processing. Consequently, researchers have started exploring the development of a green agenda for sustainable information retrieval research and operation. Previous work, however, has primarily considered energy consumption and associated CO2 emissions alone. In this paper, we seek to draw the information retrieval community's attention to the overlooked aspect of water consumption related to these powerful models. We supplement previous energy consumption estimates with corresponding water consumption estimates, considering both off-site water consumption (required for operating and cooling energy production systems such as carbon and nuclear power plants) and on-site consumption (for cooling the data centres where models are trained and operated). By incorporating water consumption alongside energy consumption and CO2 emissions, we offer a more comprehensive understanding of the environmental impact of information retrieval research and operation.	[Zuccon, Guido; Zhuang, Shengyao] Univ Queensland, Brisbane, Qld, Australia; [Scells, Harrisen] Univ Leipzig, Leipzig, Germany	University of Queensland; Leipzig University	Zuccon, G (corresponding author), Univ Queensland, Brisbane, Qld, Australia.	g.zuccon@uq.edu.au; harry.scells@uni-leipzig.de; s.zhuang@uq.edu.au		Zhuang, Shengyao/0000-0002-6711-0955; Scells, Harrisen/0000-0001-9578-7157; Zuccon, Guido/0000-0003-0271-5563	Australian Research Council [DP210104043]	Australian Research Council(Australian Research Council)	This research is funded by the Australian Research Council Discovery Project DP210104043.	Albers S, 2010, COMMUN ACM, V53, P86, DOI 10.1145/1735223.1735245; [Anonymous], 2006, ISO 14040 2006 ENV M; Arthington AH, 2018, FRONT ENV SCI-SWITZ, V6, DOI 10.3389/fenvs.2018.00045; Belkhir L, 2018, J CLEAN PROD, V177, P448, DOI 10.1016/j.jclepro.2017.12.239; Blanco R, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P1237, DOI 10.1145/2872427.2883021; Brocklehurst Fiona, 2021, Technical Report; Catena M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1555, DOI 10.1145/3269206.3269263; Catena M, 2017, IEEE T KNOWL DATA EN, V29, P1412, DOI 10.1109/TKDE.2017.2681279; Catena M, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P751, DOI 10.1145/2766462.2767809; Catena Matteo, 2015, 6 BCSIRSG S FUT DIR, V6, P1; Catena Matteo, 2015, P 6 IT INF RETR WORK; Chowdhury G, 2012, INFORM PROCESS MANAG, V48, P1067, DOI 10.1016/j.ipm.2012.02.003; Dai ZY, 2019, Arxiv, DOI arXiv:1910.10687; Finnveden G, 2009, J ENVIRON MANAGE, V91, P1, DOI 10.1016/j.jenvman.2009.06.018; Formal T, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2288, DOI 10.1145/3404835.3463098; Goni LKMO, 2019, Corrosion inhibitors, V30, P4; Hofstätter S, 2020, FRONT ARTIF INTEL AP, V325, P513, DOI 10.3233/FAIA200133; Karimi L, 2022, RESOUR CONSERV RECY, V181, DOI 10.1016/j.resconrec.2022.106194; Li PF, 2023, Arxiv, DOI arXiv:2304.03271; Lin JMY, 2021, Arxiv, DOI arXiv:2106.14807; MacAvaney S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1573, DOI 10.1145/3397271.3401262; Mallia A, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1723, DOI 10.1145/3404835.3463030; Mitra B, 2018, FOUND TRENDS INF RET, V13, P1, DOI 10.1561/1500000061; Mytton D, 2021, NPJ CLEAN WATER, V4, DOI 10.1038/s41545-021-00101-w; Nguyen Tri, 2016, COCO NIPS; Nogueira Rodrigo, 2019, From Doc2query to docTTTTTquery, P3; Qu YQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5835; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Scells H, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2825, DOI 10.1145/3477495.3531766; Spinoni J, 2018, INT J CLIMATOL, V38, P1718, DOI 10.1002/joc.5291; Spinoni J, 2014, INT J CLIMATOL, V34, P2792, DOI 10.1002/joc.3875; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016; Tonellotto N, 2022, Arxiv, DOI arXiv:2207.13443; Wang S., 2023, P 46 INT ACM SIGIR C; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; World Health Organization, 2019, Progress on Household Drinking Water, Sanitation and Hygiene 20002017: Special Focus on Inequalities; Xiong Lee, 2020, INT C LEARNING REPRE; Yates A, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1154, DOI 10.1145/3437963.3441667; Zhang X, 2019, SCI TOTAL ENVIRON, V693, DOI 10.1016/j.scitotenv.2019.07.342; Zhuang SY, 2021, Arxiv, DOI [arXiv:2108.08513, 10.48550/ARXIV.2108.08513, DOI 10.48550/ARXIV.2108.08513]; Zhuang SY, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1483, DOI 10.1145/3404835.3462922; Zhuang Shengyao, 2023, P 46 INT ACM SIGIR C	44	2	2	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0073-6				2023							283	289		10.1145/3578337.3605121	http://dx.doi.org/10.1145/3578337.3605121			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LU		Green Submitted			2024-07-03	WOS:001118823000031
J	Yu, CY; Qin, FB; Watanabe, A; Yao, WQ; Li, Y; Qin, ZC; Liu, YM; Wang, HB; Qigao, JZ; Hsiang, AY; Ma, C; Rayfield, E; Benton, MJ; Xu, X				Yu, Congyu; Qin, Fangbo; Watanabe, Akinobu; Yao, Weiqi; Li, Ying; Qin, Zichuan; Liu, Yuming; Wang, Haibing; Qigao, Jiangzuo; Hsiang, Allison Y.; Ma, Chao; Rayfield, Emily; Benton, Michael J.; Xu, Xing			Artificial intelligence in paleontology	EARTH-SCIENCE REVIEWS			English	Review						Paleontology; Fossil; Artificial intelligence; Machine learning; Deep learning; Classification; Segmentation; Prediction	PHANEROZOIC TAXONOMIC DIVERSITY; NEURAL-NETWORK ANALYSIS; FOURIER SHAPE-ANALYSIS; KINETIC-MODEL; AUTOMATED IDENTIFICATION; PLANKTIC FORAMINIFERA; EXPERT-SYSTEMS; DEEP; RECOGNITION; EVOLUTION	The accumulation of large datasets and increasing data availability have led to the emergence of data-driven paleontological studies, which reveal an unprecedented picture of evolutionary history. However, the fastgrowing quantity and complication of data modalities make data processing laborious and inconsistent, while also lacking clear benchmarks to evaluate data collection and generation, and the performances of different methods on similar tasks. Recently, artificial intelligence (AI) has become widely practiced across scientific disciplines, but not so much to date in paleontology where traditionally manual workflows have been more usual. In this study, we review >70 paleontological AI studies since the 1980s, covering major tasks including micro- and macrofossil classification, image segmentation, and prediction. These studies feature a wide range of techniques such as Knowledge-Based Systems (KBS), neural networks, transfer learning, and many other machine learning methods to automate a variety of paleontological research workflows. Here, we discuss their methods, datasets, and performance and compare them with more conventional AI studies. We attribute the recent increase in paleontological AI studies most to the lowering of the entry bar in training and deployment of AI models rather than innovations in fossil data compilation and methods. We also present recently developed AI implementations such as diffusion model content generation and Large Language Models (LLMs) that may interface with paleontological research in the future. Even though AI has not yet been a significant part of the paleontologist's toolkit, successful implementation of AI is growing and shows promise for paradigm-transformative effects on paleontological research in the years to come.	[Yu, Congyu; Ma, Chao] Chengdu Univ Technol, State Key Lab Oil & Gas Reservoir Geol & Exploitat, Chengdu 610059, Peoples R China; [Yu, Congyu; Ma, Chao] Chengdu Univ Technol, Inst Sedimentary Geol, Chengdu 610059, Peoples R China; [Yu, Congyu; Ma, Chao] Chengdu Univ Technol, Key Lab Deep Time Geog & Environm Reconstruct & Ap, Minist Nat Resources, Chengdu 610059, Peoples R China; [Yu, Congyu; Watanabe, Akinobu] Amer Museum Nat Hist, Div Paleontol, New York, NY 10024 USA; [Qin, Fangbo] Inst Automation, Inst Automat, Beijing 100190, Peoples R China; [Watanabe, Akinobu] New York Inst Technol, Dept Anat, Coll Osteopath Med, Old Westbury, NY 11568 USA; [Watanabe, Akinobu] Life Sci Dept, Nat Hist Museum, London SW7 5BD, England; [Yao, Weiqi] Southern Univ Sci & Technol, Dept Ocean Sci & Engn, Shenzhen 518055, Peoples R China; [Qin, Zichuan; Liu, Yuming; Rayfield, Emily; Benton, Michael J.] Univ Bristol, Sch Earth Sci, Palaeobiol Res Grp, Bristol BS8 1RJ, England; [Qin, Zichuan] Univ Birmingham, Sch Geog Earth & Environm Sci, Birmingham B15 2TT, England; [Wang, Haibing; Qigao, Jiangzuo] Chinese Acad Sci, Inst Vertebrate Paleontol & Paleoanthropol, Key Lab Vertebrate Evolut & Human Origins, Beijing 100044, Peoples R China; [Qigao, Jiangzuo] Peking Univ, Sch Earth & Space Sci, Beijing 100087, Peoples R China; [Hsiang, Allison Y.] Stockholm Univ, Dept Geol Sci, Svante Arrhenius vag 8, S-10691 Stockholm, Sweden; [Xu, Xing] Yunnan Univ, Ctr Vertebrate Evolutionary Biol, Kunming 650091, Peoples R China; [Xu, Xing] Shenyang Normal Univ, Paleontol Museum Liaoning, 253 North Huanghe St, Shenyang 110034, Liaoning, Peoples R China	Chengdu University of Technology; Chengdu University of Technology; Ministry of Natural Resources of the People's Republic of China; Chengdu University of Technology; American Museum of Natural History (AMNH); New York Institute Technology; Natural History Museum London; Southern University of Science & Technology; University of Bristol; University of Birmingham; Chinese Academy of Sciences; Institute of Vertebrate Paleontology & Paleoanthropology, CAS; Peking University; Stockholm University; Yunnan University; Shenyang Normal University	Yu, CY (corresponding author), Chengdu Univ Technol, State Key Lab Oil & Gas Reservoir Geol & Exploitat, Chengdu 610059, Peoples R China.; Yu, CY (corresponding author), Chengdu Univ Technol, Inst Sedimentary Geol, Chengdu 610059, Peoples R China.	congyuyu@cdut.edu.cn	Yao, Weiqi/AAA-5798-2020; Benton, Michael J./A-5639-2008; Wang, Haibing/S-1506-2018; Rayfield, Emily/F-5038-2010	Yao, Weiqi/0000-0002-8177-7035; Benton, Michael J./0000-0002-4323-1824; Yuming, Liu/0000-0001-8003-9607; Wang, Haibing/0000-0001-6811-7262; Rayfield, Emily/0000-0002-2618-750X	National Natural Science Foundation of China [42288201, 42272017]; Youth Innovation Promotion Association, CAS [2021068]; Yunnan Revitalization Talent Support Program [202305AB350006]; Swedish Research Council (Vetenskapsradet) Starting Researcher Grant [AR-NT 2020-03515]; Chengdu University of Technology Zhufeng Starting Grant [10912-KYQD2023-09966]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association, CAS; Yunnan Revitalization Talent Support Program; Swedish Research Council (Vetenskapsradet) Starting Researcher Grant(Swedish Research Council); Chengdu University of Technology Zhufeng Starting Grant	We thank Mark A. Norell and Jin Meng from the American Museum of Natural History for their valuable discussion at an early stage of this project, and Marc Andre Conard for discussion. This work is funded by the National Natural Science Foundation of China (Grant No. 42288201, 42272017) ; the Youth Innovation Promotion Association, CAS (2021068) ; Yunnan Revitalization Talent Support Program (202305AB350006) ; Swedish Research Council (Vetenskapsradet) Starting Researcher Grant (AR-NT 2020-03515) ; Chengdu University of Technology Zhufeng Starting Grant (10912-KYQD2023-09966) . This work is a contribution to the Deep-time Digital Earth (DDE) Big Science Program.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adams DC, 2013, HYSTRIX, V24, P7, DOI 10.4404/hystrix-24.1-6283; Allmon WD, 2018, GEOL SOC AM SPEC PAP, V535, P35, DOI 10.1130/2018.2535(03); Amarathunga DC, 2021, SMART AGR TECHNOL, V1, DOI 10.1016/j.atech.2021.100023; Aneja D, 2015, COMP MED SY, P78, DOI 10.1109/CBMS.2015.86; Anemone R, 2011, EVOL ANTHROPOL, V20, P169, DOI 10.1002/evan.20324; Apostol LA, 2016, INT CONF INFORM INTE; [Anonymous], 2007, Scaling learning algorithms towards ai; Arriaza MC, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063864; ATHERSUCH J, 1994, MATH GEOL, V26, P483, DOI 10.1007/BF02083490; Baraniuk R, 2020, P NATL ACAD SCI USA, V117, P30029, DOI 10.1073/pnas.2020596117; Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448; Beaufort L, 2004, MAR MICROPALEONTOL, V51, P57, DOI 10.1016/j.marmicro.2003.09.003; Beaufort L, 2001, SCIENCE, V293, P2440, DOI 10.1126/science.293.5539.2440; Beaufort L, 2022, NATURE, V601, P79, DOI 10.1038/s41586-021-04195-7; Beightol D.S., 1988, Geobyte; (United States), V3, P1; BELL MZ, 1985, J OPER RES SOC, V36, P613, DOI 10.1057/jors.1985.106; BELYEA PR, 1984, J PALEONTOL, V58, P1026; Bengio Y, 2021, COMMUN ACM, V64, P58, DOI 10.1145/3448250; BENTON MJ, 1995, SCIENCE, V268, P52, DOI 10.1126/science.7701342; Bergen KJ, 2019, SCIENCE, V363, P1299, DOI 10.1126/science.aau0323; Bhullar BAS, 2012, NATURE, V487, P223, DOI 10.1038/nature11146; Bi KF, 2023, NATURE, V619, P533, DOI 10.1038/s41586-023-06185-3; BODDY L, 1994, CYTOMETRY, V15, P283, DOI 10.1002/cyto.990150403; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Bollmann J, 2004, DEV PALEOENVIRON RES, V7, P229; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bookstein F.L., 1992, Morphometric Tools for Landmark Data: Geometry and Biology, DOI DOI 10.1017/CBO9780511573064; Bourel B, 2020, COMPUT GEOSCI-UK, V140, DOI 10.1016/j.cageo.2020.104498; Boyer DM, 2015, ANAT REC, V298, P1816, DOI 10.1002/ar.23202; Bromiley PA, 2014, FRONT ZOOL, V11, DOI 10.1186/s12983-014-0061-1; Brough D. R., 1986, Expert Systems, V3, P76, DOI 10.1111/j.1468-0394.1986.tb00197.x; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Budd GE, 2021, CURR BIOL, V31, pR1181, DOI 10.1016/j.cub.2021.08.040; BURKE CD, 1987, LETHAIA, V20, P307, DOI 10.1111/j.1502-3931.1987.tb00790.x; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carlsson V, 2023, MAR MICROPALEONTOL, V183, DOI 10.1016/j.marmicro.2023.102268; Chen XC, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107826; Chen XJ, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112948; Cheng QM, 2020, GEOL SOC SPEC PUBL, V499, P225, DOI 10.1144/SP499-2019-158; Choiniere JN, 2021, SCIENCE, V372, P610, DOI 10.1126/science.abe7941; Claes P, 2018, NAT GENET, V50, P414, DOI 10.1038/s41588-018-0057-4; Courtenay LA, 2019, PALAEOGEOGR PALAEOCL, V522, P28, DOI 10.1016/j.palaeo.2019.03.007; da Conceiçao DM, 2023, J S AM EARTH SCI, V121, DOI 10.1016/j.jsames.2022.104125; Dai X, 2023, SCIENCE, V379, P567, DOI 10.1126/science.adf1622; Dalmasso G, 2022, DEV CELL, V57, P2140, DOI 10.1016/j.devcel.2022.08.005; Daood A., 2018, Pollen Grains Recognition Based on Computer Vision Methods; Davis R., 1982, AI Mag, P3; Dawson HL, 2023, COMPUT GEOSCI-UK, V171, DOI 10.1016/j.cageo.2022.105284; De Cesaro T, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105784; De Garidel-Thoron T., Automated recognition and picking of foraminifera using the MiSo (microfossil sorter) prototype, DOI DOI 10.5194/EGUSPHERE-EGU2020-18067; de Geus AR, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902735; de Lima RP, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010086; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dollfus D, 1999, NEURAL NETWORKS, V12, P553, DOI 10.1016/S0893-6080(99)00011-8; Dollfus D., 1996, P C NEUR NETW THEIR, P306; Dollfus D., 1997, Reconnaissance de formes naturelles par des reseaux de neurones artificiels: Application au nannoplancton calcaire; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Elharrouss O, 2020, NEURAL PROCESS LETT, V51, P2007, DOI 10.1007/s11063-019-10163-0; Emmings JF, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abj5687; Fan JX, 2020, SCIENCE, V367, P273, DOI 10.1126/science.aax4953; Fan L, 2022, HIST BIOL, V34, P907, DOI 10.1080/08912963.2021.1952199; Ferreira I, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16034-4; Ferreira-Chacua I, 2023, Arxiv, DOI [arXiv:2304.04291, 10.48550/arXiv.2304.04291, DOI 10.48550/ARXIV.2304.04291]; France I, 2004, DEV PALEOENVIRON RES, V7, P253; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Garratt J., 1992, Morphological data from coccolith images, P11; Garratt J.A., 1992, Morphological Data from Coccolith Images Using Fourier Power Spectra; Gaston KJ, 2004, PHILOS T R SOC B, V359, P655, DOI 10.1098/rstb.2003.1442; Ge Q, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI); Goodfellow I. J., 2014, arXiv, DOI DOI 10.48550/ARXIV.1406.2661; Goswami A, 2022, SCIENCE, V378, P377, DOI 10.1126/science.abm7525; Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004; Hammer O., 2008, Paleontological Data Analysis; Hammer Oyvind, 2001, Palaeontologia Electronica, V4, pUnpaginated; Hanson M, 2021, SCIENCE, V372, P601, DOI 10.1126/science.abb4305; He KM, 2016, Arxiv, DOI [arXiv:1603.05027, DOI 10.48550/ARXIV.1603.05027]; Healy-Williams N., 1984, Geobios, V17, P425; HEALYWILLIAMS N, 1983, MAR MICROPALEONTOL, V8, P1, DOI 10.1016/0377-8398(83)90002-6; Hennig W., 1966, P263; HILLS SJ, 1988, COMPUT GEOSCI, V14, P481, DOI 10.1016/0098-3004(88)90030-1; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Holt K, 2011, REV PALAEOBOT PALYNO, V167, P175, DOI 10.1016/j.revpalbo.2011.08.006; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hou CB, 2023, Arxiv, DOI [arXiv:2302.08062, 10.48550/arXiv.2302.08062, DOI 10.48550/ARXIV.2302.08062]; Hou Y., 2023, X ray Spectrometry, V2023, P1; Hou YM, 2021, J MICROPALAEONTOL, V40, P163, DOI 10.5194/jm-40-163-2021; Hou YM, 2020, IEEE ACCESS, V8, P148744, DOI 10.1109/ACCESS.2020.3016267; Hoye TT, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2002545117; Hsiang AY, 2019, PALEOCEANOGR PALEOCL, V34, P1157, DOI 10.1029/2019PA003612; Huang HH, 2024, GEOSCI DATA J, V11, P46, DOI 10.1002/gdj3.215; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Karaderi T., 2021, INT C PATTERN RECOGN, P34; Kasinathan T, 2021, INFORM PROCESS AGR, V8, P446, DOI 10.1016/j.inpa.2020.09.006; Kaya Y, 2013, REV PALAEOBOT PALYNO, V189, P50, DOI 10.1016/j.revpalbo.2012.11.004; Keçeli AS, 2018, SIG PROCESS COMMUN; Keçeli AS, 2017, COMPUT GEOSCI-UK, V109, P67, DOI 10.1016/j.cageo.2017.08.011; Kim YH, 2022, COMPUT ELECTRON AGR, V199, DOI 10.1016/j.compag.2022.107146; Kjær KH, 2022, NATURE, V612, P283, DOI 10.1038/s41586-022-05453-y; Koeshidayatullah A, 2022, J PETROL SCI ENG, V215, DOI 10.1016/j.petrol.2022.110681; Koeshidayatullah A, 2020, MAR PETROL GEOL, V122, DOI 10.1016/j.marpetgeo.2020.104687; Kong QK, 2019, SEISMOL RES LETT, V90, P3, DOI 10.1785/0220180259; Kong S, 2016, IEEE COMPUT SOC CONF, P1305, DOI 10.1109/CVPRW.2016.165; Kopperud BT, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.0022; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lallensack JN, 2022, J R SOC INTERFACE, V19, DOI 10.1098/rsif.2022.0588; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Li JN, 2022, Arxiv, DOI [arXiv:2201.12086, 10.48550/arXiv.2201.12086]; Li P, 2004, J QUATERNARY SCI, V19, P755, DOI 10.1002/jqs.874; Lin ZH, 2024, Arxiv, DOI [arXiv:2401.00434, 10.48550/arXiv.2401.00434]; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu L, 2019, IEEE ACCESS, V7, P45301, DOI 10.1109/ACCESS.2019.2909522; LIU S, 1994, TENTH CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR APPLICATIONS, PROCEEDINGS, P358, DOI 10.1109/CAIA.1994.323653; Liu XK, 2023, PALEOBIOLOGY, V49, P1, DOI 10.1017/pab.2022.14; Liu XK, 2020, SEDIMENT GEOL, V410, DOI 10.1016/j.sedgeo.2020.105790; Lungmus JK, 2019, P NATL ACAD SCI USA, V116, P6903, DOI 10.1073/pnas.1802543116; MacLeod N, 2010, NATURE, V467, P154, DOI 10.1038/467154a; Marchant R, 2020, J MICROPALAEONTOL, V39, P183, DOI 10.5194/jm-39-183-2020; Marmo R, 2006, LECT NOTES ARTIF INT, V2955, P271; Marmo R, 2006, INT C PATT RECOG, P691; Martín-Perea DM, 2020, PEERJ, V8, DOI 10.7717/peerj.8767; Martineau C, 2017, PATTERN RECOGN, V65, P273, DOI 10.1016/j.patcog.2016.12.020; Matthew WD, 1926, Q REV BIOL, V1, P139, DOI 10.1086/394242; McCarthy J, 2006, AI MAG, V27, P12; Mete ÖZ, 2023, EARTH SYST SCI DATA, V15, P4023, DOI 10.5194/essd-15-4023-2023; Mitra R, 2019, MAR MICROPALEONTOL, V147, P16, DOI 10.1016/j.marmicro.2019.01.005; Mousavi SM, 2023, ANNU REV EARTH PL SC, V51, P105, DOI 10.1146/annurev-earth-071822-100323; Musgrave K, 2020, Arxiv, DOI arXiv:2003.08505; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nicholson DB, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128554; O'Leary MA, 2013, SCIENCE, V339, P662, DOI 10.1126/science.1229237; Payne JL, 2007, P NATL ACAD SCI USA, V104, P10506, DOI 10.1073/pnas.0701257104; Pomidor BJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150368; Porto A, 2021, METHODS ECOL EVOL, V12, P2129, DOI 10.1111/2041-210X.13689; Porto A, 2020, METHODS ECOL EVOL, V11, P500, DOI 10.1111/2041-210X.13373; Qin FB, 2023, IEEE-ASME T MECH, V28, P2786, DOI 10.1109/TMECH.2023.3248112; Qin FB, 2023, IEEE T CYBERNETICS, V53, P5202, DOI 10.1109/TCYB.2022.3181054; Qin ZC, 2022, FRONT EARTH SC-SWITZ, V10, DOI 10.3389/feart.2022.783481; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI Blog; Radford A, 2021, PR MACH LEARN RES, V139; Rani P, 2022, ARCH COMPUT METHOD E, V29, P1801, DOI 10.1007/s11831-021-09639-x; RAUP DAVID M., 1966, J PALEONTOL, V40, P1178; RAUP DM, 1982, SCIENCE, V215, P1501, DOI 10.1126/science.215.4539.1501; Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1; Richmond T, 2022, GEOCHEM GEOPHY GEOSY, V23, DOI 10.1029/2022GC010689; RIEDEL WR, 1989, COMPUT GEOSCI, V15, P809, DOI 10.1016/0098-3004(89)90083-6; ROHLF FJ, 1993, TRENDS ECOL EVOL, V8, P129, DOI 10.1016/0169-5347(93)90024-J; Rolfe S, 2021, METHODS ECOL EVOL, V12, P1816, DOI 10.1111/2041-210X.13669; Romera-Paredes B, 2024, NATURE, V625, DOI 10.1038/s41586-023-06924-6; Rosenfeld A, 2018, IEEE COMPUT SOC CONF, P2042, DOI 10.1109/CVPRW.2018.00262; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schiebel R., 2003, EGS AGU EUG Joint Assembly, P12531; Sepkoski D, 2013, J HIST BIOL, V46, P401, DOI 10.1007/s10739-012-9336-6; SEPKOSKI JJ, 1978, PALEOBIOLOGY, V4, P223, DOI 10.1017/S0094837300005972; SEPKOSKI JJ, 1984, PALEOBIOLOGY, V10, P246, DOI 10.1017/S0094837300008186; SEPKOSKI JJ, 1979, PALEOBIOLOGY, V5, P222, DOI 10.1017/S0094837300006539; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]; Shen L, 2009, EVOLUTION, V63, P1003, DOI 10.1111/j.1558-5646.2008.00557.x; Simpson G. G., 1944, P1; Slice DE, 2007, ANNU REV ANTHROPOL, V36, P261, DOI 10.1146/annurev.anthro.34.081804.120613; Smith JA, 2024, PALEOBIOLOGY, V50, P165, DOI 10.1017/pab.2023.33; SNEATH PHA, 1962, NATURE, V193, P855, DOI 10.1038/193855a0; SNEATH PHA, 1979, COMPUT GEOSCI, V5, P41, DOI 10.1016/0098-3004(79)90017-7; SNEATH PHA, 1973, NUMERICAL TAXONOMY; Snyders J., 2014, Technical Report KUL/ESAT/PSI/1401; Soda KJ, 2017, J MORPHOL, V278, P131, DOI 10.1002/jmor.20626; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Sun ZH, 2022, COMPUT GEOSCI-UK, V159, DOI 10.1016/j.cageo.2022.105034; Swaby P.A., 1990, P 2 ANN C INN APPL A, P203; SWABY PA, 1992, IEEE EXPERT, V7, P36, DOI 10.1109/64.129281; Tao F, 2023, NATURE, V618, P981, DOI 10.1038/s41586-023-06042-3; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thomas OO, 2023, PLOS COMPUT BIOL, V19, DOI 10.1371/journal.pcbi.1009061; Tolstikhin I, 2021, ADV NEUR IN, V34; Toosi A, 2021, PET CLIN, V16, P449, DOI 10.1016/j.cpet.2021.07.001; Treloar WJ, 2004, J QUATERNARY SCI, V19, P745, DOI 10.1002/jqs.871; Valan M, 2019, SYST BIOL, V68, P876, DOI 10.1093/sysbio/syz014; van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6; Vandaele R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18993-5; Vaswani A, 2017, ADV NEUR IN, V30; Wang P, 2022, 39 INT C MACHINE LEA; Wang Qi, 2020, Annals of Data Science, P1, DOI DOI 10.1007/S40745-020-00253-5; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wills S, 2023, PAP PALAEONTOL, V9, DOI 10.1002/spp2.1487; Wöber W, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063158; Wong C.M., 2011, Human Based Computation for Microfossil Identification; Wu XM, 2019, GEOPHYSICS, V84, pIM35, DOI 10.1190/GEO2018-0646.1; Xu CP, 2022, GONDWANA RES, V101, P94, DOI 10.1016/j.gr.2021.07.025; Xu YJ, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100179; Xu YX, 2020, IEEE ACCESS, V8, P172972, DOI 10.1109/ACCESS.2020.3024819; Yao FF, 2023, SCIENCE, V380, P743, DOI 10.1126/science.abo2812; Yu CY, 2022, FRONT EARTH SC-SWITZ, V9, DOI 10.3389/feart.2021.805271; Yu CY, 2021, ECOL EVOL, V11, P11689, DOI 10.1002/ece3.7874; Yu H., PREPRINT; Yu S, 1996, J FORAMIN RES, V26, P113, DOI 10.2113/gsjfr.26.2.113; Zhang Y, 2004, J QUATERNARY SCI, V19, P763, DOI 10.1002/jqs.875; Zhang YC, 2023, NATURE, V619, P526, DOI 10.1038/s41586-023-06184-4; Zheng W.-T., 2022, Palaeoworld, DOI DOI 10.1016/J.PALWOR.2022.11.001; Zhong BX, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P3199; Zhou ZH, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2107859118	205	0	0	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0012-8252	1872-6828		EARTH-SCI REV	Earth-Sci. Rev.	MAY	2024	252								104765	10.1016/j.earscirev.2024.104765	http://dx.doi.org/10.1016/j.earscirev.2024.104765			15	Geosciences, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Geology	RI9O2		hybrid			2024-07-03	WOS:001227153700001
C	Papadimitriou, I; Futrell, R; Mahowald, K			Assoc Computa Linguist	Papadimitriou, Isabel; Futrell, Richard; Mahowald, Kyle			When classifying grammatical role, BERT doesn't care about word order. . . except when it matters	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple			EYE-MOVEMENTS	Because meaning can often be inferred from lexical semantics alone, word order is often a redundant cue in natural language. For example, the words chopped, chef, and onion are more likely used to convey "The chef chopped the onion," not "The onion chopped the chef." Recent work has shown large language models to be surprisingly word order invariant, but crucially has largely considered natural prototypical inputs, where compositional meaning mostly matches lexical expectations. To overcome this confound, we probe grammatical role representation in English BERT and GPT-2, on instances where lexical expectations are not sufficient, and word order knowledge is necessary for correct classification. Such non-prototypical instances are naturally occurring English sentences with inanimate subjects or animate objects, or sentences where we systematically swap the arguments to make sentences like "The onion chopped the chef". We find that, while early layer embeddings are largely lexical, word order is in fact crucial in defining the later-layer representations of words in semantically non-prototypical positions. Our experiments isolate the effect of word order on the contextualization process, and highlight how models use context in the uncommon, but critical, instances where it matters.	[Papadimitriou, Isabel] Stanford Univ, Stanford, CA 94305 USA; [Futrell, Richard] Univ Calif Irvine, Irvine, CA 92717 USA; [Mahowald, Kyle] Univ Texas Austin, Austin, TX 78712 USA	Stanford University; University of California System; University of California Irvine; University of Texas System; University of Texas Austin	Papadimitriou, I (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	isabelvp@stanford.edu; rfutrell@uci.edu; mahowald@utexas.edu			National Science Foundation [2104995, 1947307]; Graduate Research Fellowship; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [2104995, 1947307] Funding Source: National Science Foundation	National Science Foundation(National Science Foundation (NSF)); Graduate Research Fellowship; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by National Science Foundation Grants No. 2104995 to KM, No. 1947307 to RF, and a Graduate Research Fellowship to IP. We thank Dan Jurafsky and AdinaWilliams for helpful discussions, and Kaitlyn Zhou, Dallas Card, and J. Adolfo Hermosillo for comments on drafts.	Aissen J, 2003, NAT LANG LINGUIST TH, V21, P435, DOI 10.1023/A:1024109008573; [Anonymous], 1976, NEW APPROACHES LANGU; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Belinkov Yonatan, 2022, COMPUT LINGUIST, P1; Bernard COMRIE., 1989, Language Universals and Linguistic Typology; Chomsky N., 1957, Syntactic Structures; Clouatre Louis, 2021, arXiv; Croft William A., 2001, International Encyclopedia of the Social and Behavioral Sciences, P6323; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DIXON RMW, 1979, LANGUAGE, V55, P59, DOI 10.2307/412519; Erk K, 2012, LANG LINGUIST COMPAS, V6, P635, DOI 10.1002/Inc3.362; FERREIRA F, 1990, J EXP PSYCHOL LEARN, V16, P555, DOI 10.1037/0278-7393.16.4.555; FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1; Gibson E, 2013, PSYCHOL SCI, V24, P1079, DOI 10.1177/0956797612463705; Goodwin E, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1958; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Gupta A, 2021, Arxiv, DOI arXiv:2101.03453; Hessel J, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P204; Hewitt J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1626; Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2733; HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88; Mahowald K, 2023, Arxiv, DOI arXiv:2201.12911; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Maudslay RH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P124; Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x; Mollica F, 2020, NEUROBIOL LANG, V1, P104, DOI 10.1162/nol_a_00005; Pimentel T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4609; RAYNER K, 1983, J VERB LEARN VERB BE, V22, P358, DOI 10.1016/S0022-5371(83)90236-0; Sinha K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2888; Tal S, 2022, COGNITION, V224, DOI 10.1016/j.cognition.2022.105055; Voita Elena, 2020, P 2020 C EMP METH NA, P183	31	3	3	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-22-3				2022							636	643						8	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EN					2024-07-03	WOS:000828732800071
C	Nangi, SR; Tyagi, A; Mundra, J; Mukherjee, S; Raj, S; Garimella, A; Chhaya, N			Assoc Computat Linguist	Nangi, Sharmila Reddy; Tyagi, Athary; Mundra, Jay; Mukherjee, Sagnik; Raj, Snehal; Garimella, Aparna; Chhaya, Niyati			AUTOSUMM: Automatic Model Creation for Text Summarization	2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021)			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing (EMNLP)	NOV 07-11, 2021	Punta Cana, DOMINICAN REP					Recent efforts to develop deep learning models for text generation tasks such as extractive and abstractive summarization have resulted in state-of-the-art performances on various datasets. However, obtaining the best model configuration for a given dataset requires an extensive knowledge of deep learning specifics like model architecture, tuning parameters etc., and is often extremely challenging for a non-expert. In this paper, we propose methods to automatically create deep learning models for the tasks of extractive and abstractive text summarization. Based on the recent advances in Automated Machine Learning and the success of large language models such as BERT and GPT-2 in encoding knowledge, we use a combination of Neural Architecture Search (NAS) and Knowledge Distillation (KD) techniques to perform model search and compression using the vast knowledge provided by these language models to develop smaller, customized models for any given dataset. We present extensive empirical results to illustrate the effectiveness of our model creation methods in terms of inference time and model size, while achieving near state-of-the-art performances in terms of accuracy across a range of datasets.	[Nangi, Sharmila Reddy] Stanford Univ, Stanford, CA 94305 USA; [Nangi, Sharmila Reddy; Tyagi, Athary; Mundra, Jay; Mukherjee, Sagnik; Raj, Snehal] Adobe Res, Bangalore, India; [Garimella, Aparna; Chhaya, Niyati] Indian Inst Technol Kanpur, Kanpur, Uttar Pradesh, India	Stanford University; Adobe Systems Inc.; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kanpur	Nangi, SR (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	srnangi@stanford.edu; atharv@iitk.ac.in; jaym@iitk.ac.in; sagnikm@iitk.ac.in; snehal@iitk.ac.in; garimell@adobe.com; nchhaya@adobe.com						Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen DY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2463; Chen Y.-C., 2020, P 58 ANN M ASS COMP, P7893, DOI DOI 10.18653/V1/2020.ACL-MAIN.705; Chopra S., 2016, P 2016 C N AM CHAPTE, P93, DOI [10.18653/v1/n16-1012, DOI 10.18653/V1/N16-1012]; Cohan Arman, 2018, P 2018 C N AM CHAPTE, V2, P615; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Durrett G, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1998; Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693, DOI DOI 10.48550/ARXIV.1506.03340; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Liu H., 2019, 7 INT C LEARN REPR I; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu Yang, 2019, ARXIV190808345; Manor L, 2019, P NATURAL LEGAL LANG, P1, DOI DOI 10.18653/V1/W19-2201; Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayan Shashi, 2018, P 2018 C N AM CHAPT, P280, DOI [DOI 10.18653/V1/N18-1158, 10.18653/v1/N18-1158]; Pham M., 2018, P MACHINE LEARNING R, P4095; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Real E., 2017, ICML, V70, P2902; Real E, 2019, AAAI, P33; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Song KQ, 2020, AAAI CONF ARTIF INTE, V34, P8902; Suganuma M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5369; Vaswani A, 2017, ADV NEUR IN, V30; Wang YS, 2020, AAAI CONF ARTIF INTE, V34, P6283; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Xie Sirui, 2019, ABS181209926 ARXIV; Zhang Jingqing, 2019, ABS191208777 ARXIV; Zoph Barret, 2017, INT C LEARN REPR	32	1	1	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-09-4				2021							10162	10172						11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9HF					2024-07-03	WOS:000860727004022
J	Becker, C; Conduit, R; Chouinard, PA; Laycock, R				Becker, Casey; Conduit, Russell; Chouinard, Philippe A.; Laycock, Robin			Can deepfakes be used to study emotion perception? A comparison of dynamic face stimuli	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						Face perception; Generative AI; Deepfake; Emotion; Dynamic faces	FACIAL EXPRESSIONS; RECOGNITION; SPEECH; PRIDE	Video recordings accurately capture facial expression movements; however, they are difficult for face perception researchers to standardise and manipulate. For this reason, dynamic morphs of photographs are often used, despite their lack of naturalistic facial motion. This study aimed to investigate how humans perceive emotions from faces using real videos and two different approaches to artificially generating dynamic expressions - dynamic morphs, and AI-synthesised deepfakes. Our participants perceived dynamic morphed expressions as less intense when compared with videos (all emotions) and deepfakes (fearful, happy, sad). Videos and deepfakes were perceived similarly. Additionally, they perceived morphed happiness and sadness, but not morphed anger or fear, as less genuine than other formats. Our findings support previous research indicating that social responses to morphed emotions are not representative of those to video recordings. The findings also suggest that deepfakes may offer a more suitable standardized stimulus type compared to morphs. Additionally, qualitative data were collected from participants and analysed using ChatGPT, a large language model. ChatGPT successfully identified themes in the data consistent with those identified by an independent human researcher. According to this analysis, our participants perceived dynamic morphs as less natural compared with videos and deepfakes. That participants perceived deepfakes and videos similarly suggests that deepfakes effectively replicate natural facial movements, making them a promising alternative for face perception research. The study contributes to the growing body of research exploring the usefulness of generative artificial intelligence for advancing the study of human perception.	[Becker, Casey; Conduit, Russell; Laycock, Robin] RMIT Univ, Melbourne, Australia; [Chouinard, Philippe A.] La Trobe Univ, Melbourne, Australia	Royal Melbourne Institute of Technology (RMIT); La Trobe University	Becker, C (corresponding author), RMIT Univ, Melbourne, Australia.	casey.becker@rmit.edu.au		Becker, Casey/0000-0002-4435-8683; Laycock, Robin/0000-0002-9169-2297; Chouinard, Philippe/0000-0001-9817-0689; Conduit, Russell/0000-0001-9356-6844	Royal Melbourne Institute of Technology; Australian Government Research Training Program Scholarship	Royal Melbourne Institute of Technology; Australian Government Research Training Program Scholarship(Australian GovernmentDepartment of Industry, Innovation and Science)	This research was supported by an Australian Government Research Training Program Scholarship	Abrosoft, 2011, FantaMorph; Agarwal S, 2021, IEEE COMPUT SOC CONF, P981, DOI 10.1109/CVPRW53098.2021.00109; Ajoy Atmik, 2021, 2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA), P1329, DOI 10.1109/ICIRCA51532.2021.9544734; [Anonymous], 2023, JASP (Version 0.17) [Computer software]; Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x; Appel M, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmac008; Atkinson AP, 2004, PERCEPTION, V33, P717, DOI 10.1068/p5096; AX Semantics, 2023, GPT-4: All You Need to Know + Differences To GPT-3 & ChatGPT; Bail CA, 2016, P NATL ACAD SCI USA, V113, P11823, DOI 10.1073/pnas.1607151113; Baldwin Karen Brandt, 2008, J Healthc Qual, V30, P24; Barabanshchikov VA, 2022, J OPT TECHNOL+, V89, P448, DOI 10.1364/JOT.89.000448; Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55; Becker C, 2023, EUR J NEUROSCI, V58, P2657, DOI 10.1111/ejn.16052; Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910; Cheetham Marcus, 2013, Front Psychol, V4, P108, DOI 10.3389/fpsyg.2013.00108; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Cosker D., 2010, P S APPL PERCEPTION, P101, DOI DOI 10.1145/1836248.1836268; Crookes K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141353; Crowston K., 2010, proceedings of the American Society for Information Science and Technology, V47, P1, DOI [10.1002/meet.14504701328, DOI 10.1002/MEET.14504701328]; Crowston K, 2012, INT J SOC RES METHOD, V15, P523, DOI 10.1080/13645579.2011.625764; Curio C., 2006, P 3 S APPL PERC GRAP, DOI 10.1145/1140491.1140508; Dawel A, 2022, BEHAV RES METHODS, V54, P1889, DOI 10.3758/s13428-021-01705-3; Demenescu LR, 2014, FRONT HUM NEUROSCI, V8, DOI [10.3389/tnhurn.2014.00866, 10.3389/fnhum.2014.00866]; Dobber T, 2021, INT J PRESS/POLIT, V26, P69, DOI 10.1177/1940161220944364; Eberl A, 2022, FRONT SOCIOL, V7, DOI 10.3389/fsoc.2022.907199; Engelmann JB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00118; Fang C, 2022, VALUE HEALTH, V25, P1995, DOI 10.1016/j.jval.2022.06.004; Fiorentini C, 2012, PERCEPTION, V41, P532, DOI 10.1068/p7052; Flick C, 2016, Res. Ethics Rev., V12, P14, DOI [10.1177/1747016115599568, DOI 10.1177/1747016115599568]; Forni-Santos L, 2015, WORLD J PSYCHIATR, V5, P342, DOI 10.5498/wjp.v5.i3.342; Gonen H, 2022, Arxiv, DOI arXiv:2212.04037; Groh M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2110013119; Guetterman TC, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9702; Haut K, 2021, Arxiv, DOI [arXiv:2102.08054, 10.48550/arXiv.2102.08054, DOI 10.48550/ARXIV.2102.08054]; Hwang Y, 2021, CYBERPSYCH BEH SOC N, V24, P188, DOI 10.1089/cyber.2020.0174; Jack RE, 2015, CURR BIOL, V25, pR621, DOI 10.1016/j.cub.2015.05.052; Jarosz AF, 2014, J PROBL SOLVING, V7, P2, DOI 10.7771/1932-6246.1167; Jia S, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.580287; Kang IH, 2022, J BEHAV DECIS MAKING, V35, DOI 10.1002/bdm.2281; Kätsyri J, 2020, NEUROIMAGE, V204, DOI 10.1016/j.neuroimage.2019.116216; Kaufman J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091038; Kazak AE., 2018, Journal article reporting standards, DOI [10.3205/psm000072, DOI 10.3205/PSM000072]; Köbis NC, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103364; Korolkova OA, 2018, VISION RES, V143, P42, DOI 10.1016/j.visres.2017.10.007; Korshunov P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2510, DOI 10.1109/ICASSP39728.2021.9414258; Krumhuber E, 2007, EMOTION, V7, P730, DOI 10.1037/1528-3542.7.4.730; Krumhuber EG, 2013, EMOT REV, V5, P41, DOI 10.1177/1754073912451349; Leeson W, 2019, INT J QUAL METH, V18, DOI 10.1177/1609406919887021; Lefler EK, 2023, PSYCHOL REP, DOI 10.1177/00332941231199959; Lennon RP, 2021, FAM MED COMMUNITY HE, V9, DOI 10.1136/fmch-2021-001287; Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391; Livingstone SR, 2016, EMOTION, V16, P365, DOI 10.1037/emo0000106; Martel C, 2020, COGN RES, V5, DOI 10.1186/s41235-020-00252-3; Mateus C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055348; Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182; McHugh D, 2020, J RES TECHNOL EDUC, V52, P391, DOI 10.1080/15391523.2020.1752337; Miller EJ, 2023, COMPUT HUM BEHAV REP, V10, DOI 10.1016/j.chbr.2023.100283; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; Morse J.M., 2002, International Journal of Qualitative Methods, V1, P28, DOI [10.1177/160940690200100404, DOI 10.1177/160940690200100404]; Nguyen D, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00062; Oda Masaomi, 2008, 2008 IEEE International Conference on Systems, Man and Cybernetics (SMC 2008), P1103, DOI 10.1109/ICSMC.2008.4811429; Onwuegbuzie AJ, 2007, QUAL QUANT, V41, P233, DOI 10.1007/s11135-006-9000-3; Otamendi FJ, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.02088; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Pichon S, 2009, NEUROIMAGE, V47, P1873, DOI 10.1016/j.neuroimage.2009.03.084; Pitcher D, 2014, CURR BIOL, V24, P2066, DOI 10.1016/j.cub.2014.07.060; Pitcher D, 2011, NEUROIMAGE, V56, P2356, DOI 10.1016/j.neuroimage.2011.03.067; Ranard BL, 2016, HEALTH AFFAIR, V35, P697, DOI 10.1377/hlthaff.2015.1030; Reinl M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01107; Roberts SO, 2020, PERSPECT PSYCHOL SCI, V15, P1295, DOI 10.1177/1745691620927709; Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225; Rychlowska M, 2017, PSYCHOL SCI, V28, P1259, DOI 10.1177/0956797617706082; Scaccia JP, 2021, IMPLEMENT SCI, V16, DOI 10.1186/s13012-021-01120-4; Sen M., 2023, ChatGPT! Shanlax International Journal of Education, V11, P1; Shao R., 2022, Computer Vision-ECCV 2022, DOI [10.48550/arXiv.2207.02204, DOI 10.48550/ARXIV.2207.02204]; Srinivasan R, 2016, J NEUROSCI, V36, P4434, DOI 10.1523/JNEUROSCI.1704-15.2016; Tahir R., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/3411764.3445699; Thaw N. N., 2021, INT C HUM COMP INT, DOI [10.1007/978-3-030-78635-980, DOI 10.1007/978-3-030-78635-980]; Thepsoonthorn C, 2021, INT J SOC ROBOT, V13, P1443, DOI 10.1007/s12369-020-00726-w; Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748; Tounsi A, 2023, NAT HAZARDS, V116, P2819, DOI 10.1007/s11069-023-05842-0; Tracy JL, 2008, P NATL ACAD SCI USA, V105, P11655, DOI 10.1073/pnas.0802686105; Tracy JL, 2004, PSYCHOL SCI, V15, P194, DOI 10.1111/j.0956-7976.2004.01503008.x; Trawinski T, 2021, COGN RES, V6, DOI 10.1186/s41235-021-00337-7; Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408; Vaitonyte J, 2023, COMPUT HUM BEHAV REP, V9, DOI 10.1016/j.chbr.2022.100263; van der Schalk J, 2011, EMOTION, V11, P907, DOI 10.1037/a0023853; Vijay R. S., 2021, 2021 INT C MULT INT, DOI [10.1145/3461615.3485397, DOI 10.1145/3461615.3485397]; Wallraven C, 2008, ACM T APPL PERCEPT, V4, DOI 10.1145/1278760.1278764; Weisbuch M, 2009, SCIENCE, V326, P1711, DOI 10.1126/science.1178358; Weiss M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18116172; Welker C., 2020, Trading faces: Complete AI face doubles avoid the uncanny valley, DOI [10.31234/osf.io/pykjr, DOI 10.31234/OSF.IO/PYKJR]; Whler L, 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445627; Younus M.A., 2020, 2020 INT C COMP SCI, P186; Yu Y, 2023, IEEE T MULTIMEDIA, V25, P8487, DOI 10.1109/TMM.2023.3237322; Zhao R, 2016, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2016.377; Zloteanu M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01184	97	0	0	3	3	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 JUN 4	2024										10.3758/s13428-024-02443-y	http://dx.doi.org/10.3758/s13428-024-02443-y		JUN 2024	17	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	TA6J7	38834812	hybrid			2024-07-03	WOS:001238572200001
J	Lubitz, M; Latario, L				Lubitz, Marc; Latario, Luke			Performance of Two Artificial Intelligence Generative Language Models on the Orthopaedic In-Training Examination	ORTHOPEDICS			English	Article								Background: Artificial intelligence (AI) generative large language models are powerful and increasingly accessible tools with potential applications in health care education and training. The annual Orthopaedic In-Training Examination (OITE) is widely used to assess resident academic progress and preparation for the American Board of Orthopaedic Surgery Part 1 Examination. Materials and Methods: Open AI's ChatGPT and Google's Bard generative language models were administered the 2022 OITE. Question stems that contained images were input without and then with a text-based description of the imaging findings. Results: ChatGPT answered 69.1% of questions correctly. When provided with text describing accompanying media, this increased to 77.8% correct. In contrast, Bard answered 49.8% of questions correctly. This increased to 58% correct when text describing imaging in question stems was provided (P<.0001). ChatGPT was most accurate in questions within the shoulder category, with 90.9% correct. Bard performed best in the sports category, with 65.4% correct. ChatGPT performed above the published mean of Accreditation Council for Graduate Medical Education orthopedic resident test-takers (66%). Conclusion: There is significant variability in the accuracy of publicly available AI models on the OITE. AI generative language software may play numerous potential roles in the future in orthopedic education, including simulating patient presentations and clinical scenarios, customizing individual learning plans, and driving evidence-based case discussion. Further research and collaboration within the orthopedic community is required to safely adopt these tools and minimize risks associated with their use.	[Lubitz, Marc; Latario, Luke] Univ Massachusetts, Chan Med Sch, Dept Orthoped & Phys Rehabil, 55 Lake Ave North, Worcester, MA 01655 USA	University of Massachusetts System; University of Massachusetts Worcester	Lubitz, M (corresponding author), Univ Massachusetts, Chan Med Sch, Dept Orthoped & Phys Rehabil, 55 Lake Ave North, Worcester, MA 01655 USA.	MarcLubitz@gmail.com						American Academy of Orthopaedic Surgeons, 2023, AAOS Orthopaedic In-Training Examination (OITE); American Academy of Orthopaedic Surgeons, Orthopaedic In-Training Examination (OITE) Technical Report 2022; Baruffati A., ChatGPT Statistics 2023: Trends and Future Perspectives; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Claessen FMAP, 2019, ARCH BONE JT SURG-AB, V7, P478; Dougherty PJ, 2010, CLIN ORTHOP RELAT R, V468, P2797, DOI 10.1007/s11999-010-1327-3; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Flores-Cohaila JA, 2023, JMIR MED EDUC, V9, DOI 10.2196/48039; Google, Bard Experiment; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Gupta R, 2023, AESTHET SURG J, DOI 10.1093/asj/sjad128; Gupta R, 2023, J PLAST RECONSTR AES, V80, P145, DOI 10.1016/j.bjps.2023.03.004; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Maffulli N, 2020, J ORTHOP SURG RES, V15, DOI 10.1186/s13018-020-02002-z; Miyamoto Ryan G Jr, 2007, Am J Orthop (Belle Mead NJ), V36, pE185; Open AI, Introducing ChatGPT; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887	17	0	0	5	5	SLACK INC	THOROFARE	6900 GROVE RD, THOROFARE, NJ 08086 USA	0147-7447	1938-2367		ORTHOPEDICS	Orthopedics	MAY-JUN	2024	47	3					e146	e150		10.3928/01477447-20240304-02	http://dx.doi.org/10.3928/01477447-20240304-02			5	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	RQ5A0	38466827				2024-07-03	WOS:001229126100005
J	Maciejewski, C; Ozieranski, K; Barwiolek, A; Basza, M; Bozym, A; Ciurla, M; Krajsman, MJ; Maciejewska, M; Lodzinski, P; Opolski, G; Grabowski, M; Cacko, A; Balsam, P				Maciejewski, Cezary; Ozieranski, Krzysztof; Barwiolek, Adam; Basza, Mikolaj; Bozym, Aleksandra; Ciurla, Michalina; Krajsman, Maciej Janusz; Maciejewska, Magdalena; Lodzinski, Piotr; Opolski, Grzegorz; Grabowski, Marcin; Cacko, Andrzej; Balsam, Pawel			AssistMED project: Transforming cardiology cohort characterisation from electronic health records through natural language processing - Algorithm design, preliminary results, and field prospects	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						Natural language processing; NLP; Text -mining; Epidemiology; Cardiology	TEXT; CARE	Introduction: Electronic health records (EHR) are of great value for clinical research. However, EHR consists primarily of unstructured text which must be analysed by a human and coded into a database before data analysis- a time-consuming and costly process limiting research efficiency. Natural language processing (NLP) can facilitate data retrieval from unstructured text. During AssistMED project, we developed a practical, NLP tool that automatically provides comprehensive clinical characteristics of patients from EHR, that is tailored to clinical researchers needs. Material and methods: AssistMED retrieves patient characteristics regarding clinical conditions, medications with dosage, and echocardiographic parameters with clinically oriented data structure and provides researcherfriendly database output. We validate the algorithm performance against manual data retrieval and provide critical quantitative and qualitative analysis. Results: AssistMED analysed the presence of 56 clinical conditions, medications from 16 drug groups with dosage and 15 numeric echocardiographic parameters in a sample of 400 patients hospitalized in the cardiology unit. No statistically significant differences between algorithm and human retrieval were noted. Qualitative analysis revealed that disagreements with manual annotation were primarily accounted to random algorithm errors, erroneous human annotation and lack of advanced context awareness of our tool. Conclusions: Current NLP approaches are feasible to acquire accurate and detailed patient characteristics tailored to clinical researchers' needs from EHR. We present an in-depth description of an algorithm development and validation process, discuss obstacles and pinpoint potential solutions, including opportunities arising with recent advancements in the field of NLP, such as large language models.	[Maciejewski, Cezary; Ozieranski, Krzysztof; Bozym, Aleksandra; Ciurla, Michalina; Maciejewska, Magdalena; Lodzinski, Piotr; Opolski, Grzegorz; Grabowski, Marcin; Cacko, Andrzej; Balsam, Pawel] Med Univ Warsaw, Chair & Dept Cardiol 1, PL-02091 Warsaw, Poland; [Barwiolek, Adam] Med Univ Warsaw, Doctoral Sch, PL-02091 Warsaw, Poland; [Basza, Mikolaj] Codifive sp zoo, Lindleya 16, PL-02013 Warsaw, Poland; [Maciejewski, Cezary; Krajsman, Maciej Janusz; Cacko, Andrzej] Med Univ Silesia, PL-40055 Katowice, Poland; [Maciejewski, Cezary] Med Univ Warsaw, Dept Med Informat & Telemed, PL-02091 Warsaw, Poland	Medical University of Warsaw; Medical University of Warsaw; Medical University Silesia; Medical University of Warsaw	Ozieranski, K (corresponding author), Med Univ Warsaw, Chair & Dept Cardiol 1, PL-02091 Warsaw, Poland.	krzysztof.ozieranski@wum.edu.pl	Ozierański, Krzysztof/W-3336-2018	Ozierański, Krzysztof/0000-0002-3848-0922; Maciejewska, Magdalena/0000-0003-1009-6395; Opolski, Grzegorz/0000-0003-4744-2554; Krajsman, Maciej Janusz/0009-0005-5564-2216	Non-commercial research grant: Innovation Incubator 4.0, Medical University of Warsaw [1MF/FS249/ZW/CTT/EK/14]; Ministry of Science and Higher Education	Non-commercial research grant: Innovation Incubator 4.0, Medical University of Warsaw; Ministry of Science and Higher Education	This research was supported by the non-commercial research grant: Innovation Incubator 4.0, Medical University of Warsaw (Grant number: 1MF/FS249/ZW/CTT/EK/14); Ministry of Science and Higher Education.	Cowie MR, 2017, CLIN RES CARDIOL, V106, P1, DOI 10.1007/s00392-016-1025-6; Farmer R, 2018, DIABETOLOGIA, V61, P1241, DOI 10.1007/s00125-017-4518-6; Ford E, 2016, J AM MED INFORM ASSN, V23, P1007, DOI 10.1093/jamia/ocv180; Hemingway H, 2018, EUR HEART J, V39, P1481, DOI 10.1093/eurheartj/ehx487; Karystianis G, 2015, J BIOMED INFORM, V58, pS183, DOI 10.1016/j.jbi.2015.06.013; Klein DO, 2019, BMJ OPEN QUAL, V8, DOI 10.1136/bmjoq-2018-000564; Kormilitzin A, 2021, ARTIF INTELL MED, V118, DOI 10.1016/j.artmed.2021.102086; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lovis C, 2000, INT J MED INFORM, V58, P101, DOI 10.1016/S1386-5056(00)00079-4; Maddox TM, 2017, CIRCULATION, V135, pE826, DOI 10.1161/CIR.0000000000000480; Nath C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153749; Nidorf SM, 2020, NEW ENGL J MED, V383, P1838, DOI 10.1056/NEJMoa2021372; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Sheikhalishahi S, 2019, JMIR MED INF, V7, P15, DOI 10.2196/12239; Singh P, 2022, JMIR MED INF, V10, DOI 10.2196/38178; Small AM, 2017, J BIOMED INFORM, V72, P77, DOI 10.1016/j.jbi.2017.06.016; Sumi E, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-426; Turchioe MR, 2022, HEART, V108, P909, DOI 10.1136/heartjnl-2021-319769; van Dijk WB, 2021, J CLIN EPIDEMIOL, V132, P97, DOI 10.1016/j.jclinepi.2020.11.014; Weissler EH, 2020, CIRC-CARDIOVASC INTE, V13, DOI 10.1161/CIRCINTERVENTIONS.120.009447	20	1	1	2	2	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056	1872-8243		INT J MED INFORM	Int. J. Med. Inform.	MAY	2024	185								105380	10.1016/j.ijmedinf.2024.105380	http://dx.doi.org/10.1016/j.ijmedinf.2024.105380		MAR 2024	9	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Health Care Sciences & Services; Medical Informatics	NR8S8	38447318				2024-07-03	WOS:001202278200001
J	Kiyak, YS; Çoskun, Ö; Budakoglu, II; Uluoglu, C				Kiyak, Yavuz Selim; Coskun, Ozlem; Budakoglu, Isil Irem; Uluoglu, Canan			ChatGPT for generating multiple-choice questions: Evidence on the use of artificial intelligence in automatic item generation for a rational pharmacotherapy exam	EUROPEAN JOURNAL OF CLINICAL PHARMACOLOGY			English	Article						ChatGPT; Artificial intelligence; Automatic item generation; Multiple-choice questions; Rational pharmacotherapy; Medical education	GUIDE	PurposeArtificial intelligence, specifically large language models such as ChatGPT, offers valuable potential benefits in question (item) writing. This study aimed to determine the feasibility of generating case-based multiple-choice questions using ChatGPT in terms of item difficulty and discrimination levels.MethodsThis study involved 99 fourth-year medical students who participated in a rational pharmacotherapy clerkship carried out based-on the WHO 6-Step Model. In response to a prompt that we provided, ChatGPT generated ten case-based multiple-choice questions on hypertension. Following an expert panel, two of these multiple-choice questions were incorporated into a medical school exam without making any changes in the questions. Based on the administration of the test, we evaluated their psychometric properties, including item difficulty, item discrimination (point-biserial correlation), and functionality of the options.ResultsBoth questions exhibited acceptable levels of point-biserial correlation, which is higher than the threshold of 0.30 (0.41 and 0.39). However, one question had three non-functional options (options chosen by fewer than 5% of the exam participants) while the other question had none.ConclusionsThe findings showed that the questions can effectively differentiate between students who perform at high and low levels, which also point out the potential of ChatGPT as an artificial intelligence tool in test development. Future studies may use the prompt to generate items in order for enhancing the external validity of the results by gathering data from diverse institutions and settings.	[Kiyak, Yavuz Selim; Coskun, Ozlem; Budakoglu, Isil Irem] Gazi Univ, Fac Med, Dept Med Educ & Informat, Ankara, Turkiye; [Kiyak, Yavuz Selim] Gazi Univ, Hastanesi E Blok 9, TR-06500 Ankara, Turkiye; [Uluoglu, Canan] Gazi Univ, Fac Med, Dept Med Pharmacol, Ankara, Turkiye	Gazi University; Gazi University; Gazi University	Kiyak, YS (corresponding author), Gazi Univ, Fac Med, Dept Med Educ & Informat, Ankara, Turkiye.; Kiyak, YS (corresponding author), Gazi Univ, Hastanesi E Blok 9, TR-06500 Ankara, Turkiye.	yskiyak@gazi.edu.tr	KIYAK, Yavuz Selim/AAE-5111-2022	KIYAK, Yavuz Selim/0000-0002-5026-3234; COSKUN, OZLEM/0000-0001-8716-1584; budakoglu, irem/0000-0003-1517-3169				Alfertshofer M, 2024, ANN BIOMED ENG, V52, P1542, DOI 10.1007/s10439-023-03338-3; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buchholz K, 2023, STATISTA INFOGRAPHIC; Carrasco JP., 2023, REV ESPANOLA EDUCACI, V4, P55, DOI [10.6018/edumed.556511, DOI 10.6018/EDUMED.556511]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cross J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41399; Downing SM., 2009, ASSESSMENT HLTH PROF, DOI [10.4324/9780203880135, DOI 10.4324/9780203880135]; Falcao F, 2022, ADV HEALTH SCI EDUC, V27, P405, DOI 10.1007/s10459-022-10092-z; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gierl MJ., 2021, Advanced Methods in Automatic Item Generation, V1st edn, DOI [10.4324/9781003025634, DOI 10.4324/9781003025634]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Han ZY, 2024, MED TEACH, V46, P657, DOI 10.1080/0142159X.2023.2271159; Indran IR, 2023, MED TEACH, DOI 10.1080/0142159X.2023.2294703; Kiyak YS, 2023, Rev. esp. educ. med., V4, P98, DOI [10.6018/edumed.587451, DOI 10.6018/EDUMED.587451]; Kiyak YS., 2023, TIP EGITIMI DUNYASI, V22, P72, DOI [10.25282/ted.1225814, DOI 10.25282/TED.1225814]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kurdi G, 2020, INT J ARTIF INTELL E, V30, P121, DOI 10.1007/s40593-019-00186-y; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Masters K, 2019, MED TEACH, V41, P976, DOI 10.1080/0142159X.2019.1595557; Mihalache A, 2024, MED TEACH, V46, P366, DOI 10.1080/0142159X.2023.2249588; Ouyang F, 2022, EDUC INF TECHNOL, V27, P7893, DOI 10.1007/s10639-022-10925-9; Pugh D, 2020, RES PRACT TECH ENHAN, V15, DOI 10.1186/s41039-020-00134-8; Shappell E, 2021, EVAL HEALTH PROF, V44, P315, DOI 10.1177/0163278720908914; Tatla E, 2023, MEDIUM; Tichelaar J, 2020, EUR J CLIN PHARMACOL, V76, P507, DOI 10.1007/s00228-019-02823-w; Wang XY, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01961-0; Westacott R, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04457-0; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhang W, 2024, EDUC INF TECHNOL, V29, P4611, DOI 10.1007/s10639-023-12009-8; Zuckerman M, 2023, MED TEACH, V45, P1224, DOI 10.1080/0142159X.2023.2249239	31	5	5	19	19	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0031-6970	1432-1041		EUR J CLIN PHARMACOL	Eur. J. Clin. Pharmacol.	MAY	2024	80	5					729	735		10.1007/s00228-024-03649-x	http://dx.doi.org/10.1007/s00228-024-03649-x		FEB 2024	7	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	NE0K7	38353690				2024-07-03	WOS:001161812200004
J	Cross, J; Robinson, R; Devaraju, S; Vaughans, A; Hood, R; Kayalackakom, T; Honnavar, P; Naik, S; Sebastian, R				Cross, Joseph; Robinson, Raymond; Devaraju, Sumanth; Vaughans, Andrea; Hood, Ricardo; Kayalackakom, Tarron; Honnavar, Prasanna; Naik, Sheetal; Sebastian, Roopa			Transforming Medical Education: Assessing the Integration of ChatGPT Into Faculty Workflows at a Caribbean Medical School	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						virtual assistant; survey; medical faculty; artificial intelligence; chatgpt; medical education		Introduction: ChatGPT is a Large Language Model (LLM) which allows for natural language processing and interactions with users in a conversational style. Since its release in 2022, it has had a significant impact in many occupational fields, including medical education. We sought to gain insight into the extent and type of usage of ChatGPT at a Caribbean medical school, the American University of Antigua College of Medicine (AUA).Methods: We administered a questionnaire to 87 full-time faculty at the school via email. We quantified and made graphical representations of the results via Qualtrics Experience Management software (QualtricsXM, Qualtrics, Provo, UT). Survey results were investigated using bar graph comparisons of absolute numbers and percentages for various categories related to ChatGPT usage, and descriptive statistics for Likert scale questions.Results: We found an estimated 33% of faculty were currently using ChatGPT. There was broad acceptance of the program by those who were using it and most believed it should be an option for students. The primary task ChatGPT was being used for was multiple choice question (MCQ) generation. The primary concern faculty had was incorrect information being included in ChatGPT output. Conclusion: ChatGPT has been quickly adopted by a subset of the college faculty, demonstrating its growing acceptance. Given the level of approval expressed about the program, we believe ChatGPT will continue to form an important and expanding part of faculty workflows at AUA and in medical education in general.	[Cross, Joseph; Sebastian, Roopa] Amer Univ Antigua, Biochem, Cell Biol & Genet, St Johns, Antigua & Barbu; [Cross, Joseph] Texas A&M Coll Med, Microbial Pathogenesis & Immunol, College Stn, TX 77843 USA; [Robinson, Raymond; Vaughans, Andrea; Hood, Ricardo] Amer Univ Antigua, Clin Sci, St Johns, Antigua & Barbu; [Devaraju, Sumanth] Amer Univ Antigua, Family Med, St Johns, Antigua & Barbu; [Kayalackakom, Tarron] Amer Univ Antigua, Med Educ & Simulat, St Johns, Antigua & Barbu; [Honnavar, Prasanna] Amer Univ Antigua, Microbiol, St Johns, Antigua & Barbu; [Naik, Sheetal] Amer Univ Antigua, Physiol, St Johns, Antigua & Barbu	Texas A&M University System; Texas A&M University College Station; Texas A&M Health Science Center	Cross, J (corresponding author), Amer Univ Antigua, Biochem, Cell Biol & Genet, St Johns, Antigua & Barbu.; Cross, J (corresponding author), Texas A&M Coll Med, Microbial Pathogenesis & Immunol, College Stn, TX 77843 USA.	cross148@gmail.com	Honnavar, Prasanna/GQH-8352-2022; Robinson, Raymond/KOC-1247-2024; CROSS, JOSEPH/JNE-9555-2023	Honnavar, Prasanna/0000-0003-3872-4242; Robinson, Raymond/0009-0000-8600-216X; Cross, Joseph/0000-0002-4680-2186				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, IMP RES IMP RES TEAC; [Anonymous], 2023, OPENAI LAUNCH CHATGP; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Dunn S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35994; Hosseini M, 2023, medRxiv, DOI [10.1101/2023.03.31.23287979, 10.1101/2023.03.31.23287979, DOI 10.1101/2023.03.31.23287979]; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281	14	11	11	19	40	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUL 5	2023	15	7							e41399	10.7759/cureus.41399	http://dx.doi.org/10.7759/cureus.41399			11	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Q2MA0	37426402	Green Published, gold			2024-07-03	WOS:001055896400011
J	Cassano, F; Gouwar, J; Nguyen, D; Nguyen, S; Phipps-Costin, L; Pinckney, D; Yee, MH; Zi, YT; Anderson, CJ; Feldman, MQ; Guha, A; Greenberg, M; Jangda, A				Cassano, Federico; Gouwar, John; Nguyen, Daniel; Nguyen, Sydney; Phipps-Costin, Luna; Pinckney, Donald; Yee, Ming-Ho; Zi, Yangtian; Anderson, Carolyn Jane; Feldman, Molly Q.; Guha, Arjun; Greenberg, Michael; Jangda, Abhinav			MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						B.2.3 reliability; testing; and fault-tolerance; I.5.1.D neural nets		Large language models have demonstrated the ability to generate both natural language and programming language text. Although contemporary code generation models are trained on corpora with several programming languages, they are tested using benchmarks that are typically monolingual. The most widely used code generation benchmarks only target Python, so there is little quantitative evidence of how code generation models perform on other programming languages. We propose MultiPL-E, a system for translating unit test-driven code generation benchmarks to new languages. We create the first massively multilingual code generation benchmark by using MultiPL-E to translate two popular Python code generation benchmarks to 18 additional programming languages. We use MultiPL-E to extend the HumanEval benchmark (Chen et al., 2021) and MBPP benchmark (Austin et al., 2021) to 18 languages that encompass a range of programming paradigms and popularity. Using these new parallel benchmarks, we evaluate the multi-language performance of three state-of-the-art code generation models: Codex (Chen et al., 2021), CodeGen (Nijkamp et al., 2022) and InCoder (Fried et al., 2022). We find that Codex matches or even exceeds its performance on Python for several other languages. The range of programming languages represented in MultiPL-E allow us to explore the impact of language frequency and language features on model performance. Finally, the MultiPL-E approach of compiling code generation benchmarks to new programming languages is both scalable and extensible, making it straightforward to evaluate new models, benchmarks, and languages.	[Cassano, Federico; Gouwar, John; Phipps-Costin, Luna; Pinckney, Donald; Yee, Ming-Ho; Zi, Yangtian; Guha, Arjun] Northeastern Univ, Comp Sci, Boston, MA 02115 USA; [Nguyen, Daniel] Hanover High Sch, Hanover, NH 03755 USA; [Nguyen, Sydney; Anderson, Carolyn Jane] Wellesley Coll, Comp Sci, Wellesley, MA 02481 USA; [Feldman, Molly Q.] Oberlin Coll, Comp Sci, Oberlin, OH 44074 USA; [Greenberg, Michael] Stevens Inst Technol, Comp Sci, Hoboken, NJ 07030 USA; [Jangda, Abhinav] Microsoft Res, Redmond, WA 98052 USA	Northeastern University; Wellesley College; University System of Ohio; Oberlin College; Stevens Institute of Technology; Microsoft	Guha, A (corresponding author), Northeastern Univ, Comp Sci, Boston, MA 02115 USA.	cassano.f@northeastern.edu; gouwar.j@northeastern.edu; dnguyen23@hanoverstudents.org; sn102@wellesley.edu; phipps-costin.l@northeastern.edu; pinckney.d@northeastern.edu; mh@mhyee.com; zi.ya@northeastern.edu; carolyn.anderson@wellesley.edu; mfeldman@oberlin.edu; a.guha@northeastern.edu; michael@greenberg.science; ajangda@microsoft.com		Nguyen, Daniel/0000-0002-4609-0844; Zi, Yangtian/0000-0003-2606-3280; Anderson, Carolyn Jane/0000-0001-5717-4210; Cassano, Federico/0000-0002-9318-7454; Pinckney, Donald/0000-0001-8612-5178; Guha, Arjun/0000-0002-7493-3271	National Science Foundation [CCF-2052696]	National Science Foundation(National Science Foundation (NSF))	This work was supported by the National Science Foundation under Grant CCF-2052696. Recommended for acceptance by M. Pradel.	Aghajanyan A, 2022, Arxiv, DOI [arXiv:2201.07520, 10.48550/arXiv.2201.07520]; Ahmed T, 2022, PROC INT CONF SOFTW, P1443, DOI 10.1145/3510003.3510049; Allal L. B., 2023, PROC DEEP LEARN CODE; Alur R, 2015, NATO SCI PEAC SECUR, V40, P1, DOI 10.3233/978-1-61499-495-4-1; Athiwaratkun B., 2022, P INT C LEARN REPR; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Black S., 2022, PREPRINT; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chaudhuri S, 2021, FOUND TRENDS PROGRAM, V7, P158, DOI 10.1561/2500000049; Chen M., 2021, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clement CB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9052; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Fried D., 2022, PROC INT C LEARN REP; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Hellendoorn VJ, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P152, DOI 10.1145/3236024.3236051; Hendrycks D., 2021, PROC C NEURAL INF PR; Holtzman A., 2020, PROC INT C LEARN REP; Iyer S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1643; Kulal S, 2019, ADV NEUR IN, V32; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lu S., 2021, PROC C NEURAL INF PR; Nijkamp E., 2022, P INT C LEARN REPR; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pradel M, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P209, DOI 10.1145/3368089.3409715; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Tunstall L., 2022, Natural Language Processing with Transformers; Vaswani A, 2017, ADV NEUR IN, V30; Wang B., 2021, GPT J 6B 6 BILL PAR; Wang ZR, 2022, Arxiv, DOI arXiv:2203.08388; Wei J., 2020, PROC INT C LEARN REP; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yin PC, 2018, IEEE WORK CONF MIN S, P476, DOI 10.1145/3196398.3196408; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zhong VC, 2017, Arxiv, DOI arXiv:1709.00103; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	41	1	2	8	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JUL	2023	49	7					3675	3691		10.1109/TSE.2023.3267446	http://dx.doi.org/10.1109/TSE.2023.3267446			17	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M9RA6		hybrid			2024-07-03	WOS:001033501500002
C	Hoq, M; Chilla, SR; Ranjbar, MA; Brusilovsky, P; Akram, B			ACM	Hoq, Muntasir; Chilla, Sushanth Reddy; Ranjbar, Melika Ahmadi; Brusilovsky, Peter; Akram, Bita			SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		program analysis; code representation; static analysis; algorithm detection; program correctness prediction		Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.	[Hoq, Muntasir; Chilla, Sushanth Reddy; Ranjbar, Melika Ahmadi; Akram, Bita] North Carolina State Univ, Raleigh, NC 27695 USA; [Brusilovsky, Peter] Univ Pittsburgh, Pittsburgh, PA USA	North Carolina State University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Hoq, M (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.	mhoq@ncsu.edu; schilla@ncsu.edu; mahmadi@ncsu.edu; peterb@pitt.edu; bakram@ncsu.edu		Hoq, Muntasir/0000-0003-2591-0476; Brusilovsky, Peter/0000-0002-1902-1464				Abdelaziz I, 2022, AAAI CONF ARTIF INTE, P4415; Akram Bita, 2020, P ED DATA MINING COM; Akram Bita, 2020, P 13 INT C EDM, P555; Al Mamun A, 2019, INT CONF RENEW ENERG, P886, DOI [10.1109/ICRERA47325.2019.8996550, 10.1109/icrera47325.2019.8996550]; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; Alon Uri, 2019, ICLR P 7; Ben-Nun T, 2018, ADV NEUR IN, V31; Bodily R, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P41, DOI 10.1145/3170358.3170409; Bui Nghi DQ, 2018, P THEWORKSHOP 32 AAA; Chen M., 2021, arXiv; Edwards SH, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P188, DOI 10.1145/3059009.3059055; Elmishali A, 2019, AAAI CONF ARTIF INTE, P9446; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Filighera A, 2019, LECT NOTES COMPUT SC, V11722, P335, DOI 10.1007/978-3-030-29736-7_25; Frantzeskou G, 2008, J SYST SOFTWARE, V81, P447, DOI 10.1016/j.jss.2007.03.004; Gardner J, 2018, USER MODEL USER-ADAP, V28, P127, DOI 10.1007/s11257-018-9203-z; Guo Daya, 2021, P 9 ICLR; Holland I.H., 1975, ADAPTATION NATURAL A; Hoq Muntasir, 2021, P 2 INCET, P1; Hoq Muntasir, 2021, P INT C COMPUTING SC, P140; Hoq Muntasir, 2023, P 16 INT C EDM; Jiang SY, 2017, IEEE INT CONF AUTOM, P135, DOI 10.1109/ASE.2017.8115626; Lajkó M, 2022, LECT NOTES COMPUT SC, V13380, P79, DOI 10.1007/978-3-031-10542-5_6; Li Y, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360588; Long T, 2022, AAAI CONF ARTIF INTE, P5792; Mao Y, 2022, AAAI CONF ARTIF INTE, P7682; Mao Ye, 2021, P 14 INT C EDM; Marwan S, 2022, IEEE T LEARN TECHNOL, V15, P406, DOI 10.1109/TLT.2022.3180984; Marwan S, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P61, DOI 10.1145/3291279.3339420; Mou LL, 2016, AAAI CONF ARTIF INTE, P1287; Paassen Benjamin, 2021, J ED DATA MINING, V13, P1, DOI DOI 10.5281/ZENODO.5634224; Piech C, 2015, PR MACH LEARN RES, V37, P1093; Pradel M, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276517; Price T.W., 2016, Proceedings of the 9th International Conference on Educational Data Mining pp, P191; Qing Liu, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P2338, DOI 10.1109/CompComm.2018.8780663; Rahman MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082973; Ren YF, 2016, AAAI CONF ARTIF INTE, P3038; Sehgal A, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P596, DOI 10.1109/IRC.2019.00121; Shi Yang, 2021, P 14 EDM INT C; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Su Y, 2018, AAAI CONF ARTIF INTE, P2435; Wang K, 2019, Arxiv, DOI arXiv:1905.05251; White M, 2016, IEEE INT CONF AUTOM, P87, DOI 10.1145/2970276.2970326; Zhang J, 2019, PROC INT CONF SOFTW, P783, DOI 10.1109/ICSE.2019.00086; Zhou YQ, 2019, ADV NEUR IN, V32; Zuo F, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23492	46	1	1	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							783	792		10.1145/3583780.3615047	http://dx.doi.org/10.1145/3583780.3615047			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549500079
J	Mogi, K				Mogi, Ken			Artificial intelligence, human cognition, and conscious supremacy	FRONTIERS IN PSYCHOLOGY			English	Article						conscious supremacy; artificial intelligence; consciousness; large language model; computation	GLOBAL WORKSPACE; QUANTUM; MODEL; PROGRESS; ORCH; MIND; GO	The computational significance of consciousness is an important and potentially more tractable research theme than the hard problem of consciousness, as one could look at the correlation of consciousness and computational capacities through, e.g., algorithmic or complexity analyses. In the literature, consciousness is defined as what it is like to be an agent (i.e., a human or a bat), with phenomenal properties, such as qualia, intentionality, and self-awareness. The absence of these properties would be termed "unconscious." The recent success of large language models (LLMs), such as ChatGPT, has raised new questions about the computational significance of human conscious processing. Although instances from biological systems would typically suggest a robust correlation between intelligence and consciousness, certain states of consciousness seem to exist without manifest existence of intelligence. On the other hand, AI systems seem to exhibit intelligence without consciousness. These instances seem to suggest possible dissociations between consciousness and intelligence in natural and artificial systems. Here, I review some salient ideas about the computational significance of human conscious processes and identify several cognitive domains potentially unique to consciousness, such as flexible attention modulation, robust handling of new contexts, choice and decision making, cognition reflecting a wide spectrum of sensory information in an integrated manner, and finally embodied cognition, which might involve unconscious processes as well. Compared to such cognitive tasks, characterized by flexible and ad hoc judgments and choices, adequately acquired knowledge and skills are typically processed unconsciously in humans, consistent with the view that computation exhibited by LLMs, which are pretrained on a large dataset, could in principle be processed without consciousness, although conversations in humans are typically done consciously, with awareness of auditory qualia as well as the semantics of what are being said. I discuss the theoretically and practically important issue of separating computations, which need to be conducted consciously from those which could be done unconsciously, in areas, such as perception, language, and driving. I propose conscious supremacy as a concept analogous to quantum supremacy, which would help identify computations possibly unique to consciousness in biologically practical time and resource limits. I explore possible mechanisms supporting the hypothetical conscious supremacy. Finally, I discuss the relevance of issues covered here for AI alignment, where computations of AI and humans need to be aligned.	[Mogi, Ken] Sony Comp Sci Labs, Shinagawa, Japan; [Mogi, Ken] Univ Tokyo, Collect Intelligence Res Lab, Meguro, Japan	University of Tokyo	Mogi, K (corresponding author), Sony Comp Sci Labs, Shinagawa, Japan.; Mogi, K (corresponding author), Univ Tokyo, Collect Intelligence Res Lab, Meguro, Japan.	kenmogi@qualia-manifesto.com						Adams SS, 2012, AI MAG, V33, P25, DOI 10.1609/aimag.v33i1.2322; [Anonymous], 1967, HOSP PRACT, DOI DOI 10.1080/21548331.1967.11707799; Araiba S, 2020, PERSPECT BEHAV SCI, V43, P157, DOI 10.1007/s40614-019-00207-0; Aronson E., 1969, Advances in experimental social psychology, V4, P1, DOI DOI 10.1016/S0065-2601(08)60075-1; Aru J, 2023, ARTIF INTELL REV, V56, P9141, DOI 10.1007/s10462-023-10401-x; Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5; Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6; Baars BernardJ., 1997, J CONSCIOUSNESS STUD, V4, P292; Baars BJ, 2005, PROG BRAIN RES, V150, P45, DOI 10.1016/S0079-6123(05)50004-9; Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816; Baron-Cohen S, 2001, INT REV RES MENT RET, V23, P169; Beckman D, 1996, PHYS REV A, V54, P1034, DOI 10.1103/PhysRevA.54.1034; Bengio Y, 2019, Arxiv, DOI arXiv:1709.08568; BENIOFF P, 1980, J STAT PHYS, V22, P563, DOI 10.1007/BF01011339; Blauth TF, 2022, IEEE ACCESS, V10, P77110, DOI 10.1109/ACCESS.2022.3191790; Bostrom N, 2012, MIND MACH, V22, P71, DOI 10.1007/s11023-012-9281-3; BRAY D, 1995, NATURE, V376, P307, DOI 10.1038/376307a0; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cai WZ, 2021, FUND RES-CHINA, V1, P50, DOI 10.1016/j.fmre.2020.12.006; Campbell M, 2002, ARTIF INTELL, V134, P57, DOI 10.1016/S0004-3702(01)00129-1; Chalmers DJ, 1996, FROM ANIM ANIMAT, P5; CHARMAN T, 1992, J CHILD PSYCHOL PSYC, V33, P1105, DOI 10.1111/j.1469-7610.1992.tb00929.x; Chrisley R, 2008, ARTIF INTELL MED, V44, P119, DOI 10.1016/j.artmed.2008.07.011; Crick F, 1998, CEREB CORTEX, V8, P97, DOI 10.1093/cercor/8.2.97; Crowne D.P., 2007, Personality theory; Dehaene S, 1998, P NATL ACAD SCI USA, V95, P14529, DOI 10.1073/pnas.95.24.14529; DEUTSCH D, 1985, P ROY SOC LOND A MAT, V400, P97, DOI 10.1098/rspa.1985.0070; Feldman J, 2013, COGN NEURODYNAMICS, V7, P1, DOI 10.1007/s11571-012-9219-8; FEYNMAN RP, 1986, FOUND PHYS, V16, P507, DOI 10.1007/BF01886518; Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Goertzel Ben, 2014, Journal of Artificial General Intelligence, V5, P1, DOI 10.2478/jagi-2014-0001; Haggard P, 2001, J CONSCIOUSNESS STUD, V8, P47; Hameroff S, 1998, PHILOS T R SOC A, V356, P1869, DOI 10.1098/rsta.1998.0254; Hameroff S. R., 1996, J. Consci. Stud., V3, P36; Hameroff S, 2014, PHYS LIFE REV, V11, P39, DOI 10.1016/j.plrev.2013.08.002; Iriki A, 1996, NEUROREPORT, V7, P2325; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kilroe PA, 2016, DREAMING, V26, P142, DOI 10.1037/drm0000016; Kitano H, 2016, AI MAG, V37, P39, DOI 10.1609/aimag.v37i1.2642; Koch C, 2016, NAT REV NEUROSCI, V17, P307, DOI 10.1038/nrn.2016.22; Kosuru V.S. R., 2023, World Journal of Advanced Research and Reviews, V18, P161, DOI DOI 10.30574/WJARR.2023.18.1.0568; Lau H, 2011, TRENDS COGN SCI, V15, P365, DOI 10.1016/j.tics.2011.05.009; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lisman J, 2013, J COGNITIVE NEUROSCI, V25, P273, DOI 10.1162/jocn_a_00319; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; Long R, 2023, J CONSCIOUSNESS STUD, V30, P143, DOI 10.53765/20512201.30.9.143; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; Mashour GA, 2020, NEURON, V105, P776, DOI 10.1016/j.neuron.2020.01.026; Mccormick Katie, 2022, Physics, V15, DOI 10.1103/Physics.15.19; MCGINN C, 1994, PHILOS STUD, V76, P133, DOI 10.1007/BF00989821; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; Nelson TO, 1996, AM PSYCHOL, V51, P102, DOI 10.1037/0003-066X.51.2.102; Penrose R, 1996, GEN RELAT GRAVIT, V28, P581, DOI 10.1007/BF02105068; Reimao R N, 1980, Brain Dev, V2, P353; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sarbin T.R., 1997, CONT HYPNOSIS, V14, P203, DOI [10.1002/ch.105, DOI 10.1002/CH.105]; Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4; Scott A. C., 2022, Int. J. Artif. Intell. Mach. Learn, V2, P1, DOI [10.51483/IJAIML.2.1.2022.1-37, DOI 10.51483/IJAIML.2.1.2022.1-37]; Seth A., 2021, BEING YOU NEW SCI CO; Shladover SE, 2016, SCI AM, V314, P53, DOI 10.1038/scientificamerican0616-52; SHOR PW, 1994, AN S FDN CO, P124; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Solomon J., 1911, Mind, VXX, P15, DOI [10.1093/mind/XX.77.15, DOI 10.1093/MIND/XX.77.15]; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Tegmark M, 2000, PHYS REV E, V61, P4194, DOI 10.1103/PhysRevE.61.4194; THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133; Tononi G, 2016, NAT REV NEUROSCI, V17, P450, DOI 10.1038/nrn.2016.44; Treisman A, 1999, NEURON, V24, P105, DOI 10.1016/S0896-6273(00)80826-0; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Turing AM, 1937, P LOND MATH SOC, V42, P230, DOI 10.1112/plms/s2-42.1.230; Vaswani A, 2017, ADV NEUR IN, V30; VELMANS M, 1991, BEHAV BRAIN SCI, V14, P651, DOI 10.1017/S0140525X00071776; Velmans M, 2012, J CONSCIOUSNESS STUD, V19, P143; von Glasersfeld E., 1987, PROBLEMS REPRESENTAT, P3; Wiese W., 2021, Philos. Mind Sci, V2, P9, DOI [10.33735/phimisci.2021.81, DOI 10.33735/PHIMISCI.2021.81]; Woolf NJ, 2001, TRENDS COGN SCI, V5, P472, DOI 10.1016/S1364-6613(00)01774-5; Yeung N, 2012, PHILOS T R SOC B, V367, P1310, DOI 10.1098/rstb.2011.0416; Yudkowsky E., 2015, Rationality-from AI to zombies; Yudkowsky E., 2008, Global catastrophic risks, P308; Zeki S, 1998, BRAIN, V121, P1669, DOI 10.1093/brain/121.9.1669; Zhang B., 2021, J ARTIF INTELL RES, V71, DOI DOI 10.1613/JAIR.1.12895	85	0	0	2	2	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	MAY 13	2024	15								1364714	10.3389/fpsyg.2024.1364714	http://dx.doi.org/10.3389/fpsyg.2024.1364714			8	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	SD5V5	38807956	gold			2024-07-03	WOS:001232542300001
J	Long, C; Lowe, K; Zhang, JSC; dos Santos, A; Alanazi, A; O'Brien, D; Wright, E; Cote, D				Long, Cai; Lowe, Kayle; Zhang, Jessica; dos Santos, Andre; Alanazi, Alaa; O'Brien, Daniel; Wright, Erin; Cote, David			A Novel Evaluation Model for Assessing ChatGPT on Otolaryngology-Head and Neck Surgery Certification Examinations: Performance Study	JMIR MEDICAL EDUCATION			English	Article						medical licensing; otolaryngology; otology; laryngology; ear; nose; throat; ENT; surgery; surgical; exam; exams; response; responses; answer; answers; chatbot; chatbots; examination; examinations; medical education; otolaryngology/head and neck surgery; OHNS; artificial intelligence; AI; ChatGPT; medical examination; large language models; language model; LLM; LLMs; wide range information; patient safety; clinical implementation; safety; machine learning; NLP; natural language processing		Background: ChatGPT is among the most popular large language models (LLMs), exhibiting proficiency in various standardized tests, including multiple-choice medical board examinations. However, its performance on otolaryngology-head and neck surgery (OHNS) certification examinations and open-ended medical board certification examinations has not been reported. Objective: We aimed to evaluate the performance of ChatGPT on OHNS board examinations and propose a novel method to assess an AI model's performance on open-ended medical board examination questions. Methods: Twenty-one open-ended questions were adopted from the Royal College of Physicians and Surgeons of Canada's sample examination to query ChatGPT on April 11, 2023, with and without prompts. A new model, named Concordance, Validity, Safety, Competency (CVSC), was developed to evaluate its performance. Results: In an open-ended question assessment, ChatGPT achieved a passing mark (an average of 75% across 3 trials) in the attempts and demonstrated higher accuracy with prompts. The model demonstrated high concordance (92.06%) and satisfactory validity. While demonstrating considerable consistency in regenerating answers, it often provided only partially correct responses. Notably, concerning features such as hallucinations and self-conflicting answers were observed. Conclusions: ChatGPT achieved a passing score in the sample examination and demonstrated the potential to pass the OHNS certification examination of the Royal College of Physicians and Surgeons of Canada. Some concerns remain due to its hallucinations, which could pose risks to patient safety. Further adjustments are necessary to yield safer and more accurate answers for clinical implementation.	[Long, Cai; Alanazi, Alaa; Wright, Erin; Cote, David] Univ Alberta, Div Otolaryngol Head & Neck Surg, 8440-112 St, Edmonton, AB T6G 2B7, Canada; [Lowe, Kayle; Zhang, Jessica] Univ Alberta, Fac Med, Edmonton, AB, Canada; [dos Santos, Andre] Alberta Machine Intelligence Inst, Edmonton, AB, Canada; [O'Brien, Daniel] Creighton Univ, Dept Surg, Omaha, NE USA	University of Alberta; University of Alberta; Creighton University	Long, C (corresponding author), Univ Alberta, Div Otolaryngol Head & Neck Surg, 8440-112 St, Edmonton, AB T6G 2B7, Canada.	cai.long.med@gmail.com	Zhang, Jessica/KHE-4368-2024	Wright, Erin/0000-0001-5601-2754; Lowe, Kayle/0009-0006-7940-333X; O'Brien, Daniel/0000-0002-8394-9902; dos Santos, Andre/0009-0000-0393-3082				Ali R, 2023, medRxiv, DOI [10.1101/2023.04.06.23288265, 10.1101/2023.04.06.23288265, DOI 10.1101/2023.04.06.23288265]; Ali R, 2023, medRxiv, DOI [10.1101/2023.03.25.23287743, 10.1101/2023.03.25.23287743, DOI 10.1101/2023.03.25.23287743]; [Anonymous], Format of the examination in vascular surgery; [Anonymous], GPT-4 is OpenAI's most advanced system, producing safer and more useful responses; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bommineni VL, 2023, medRxiv, DOI [10.1101/2023.03.05.23286533, 10.1101/2023.03.05.23286533, DOI 10.1101/2023.03.05.23286533]; Chen S, 2023, medRxiv, DOI [10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316, DOI 10.1101/2023.03.16.23287316V1, DOI 10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316v1]; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Nastasi AJ, 2023, medRxiv, DOI [10.1101/2023.02.25.23286451, 10.1101/2023.02.25.23286451, DOI 10.1101/2023.02.25.23286451]; Ngrdi B., 2023, SSRN, DOI [10.2139/ssrn.4372965, DOI 10.2139/SSRN.4372965]; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Varanasi Lakshmi ., 2023, Business Insider; Zakka Cyril, 2023, Res Sq, DOI 10.21203/rs.3.rs-2883198/v1	20	4	4	7	7	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e49970	10.2196/49970	http://dx.doi.org/10.2196/49970			8	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IJ8N7	38227351	Green Published, gold			2024-07-03	WOS:001166050200001
J	Dey, L				Dey, Lipika			Knowledge graph-driven data processing for business intelligence	WILEY INTERDISCIPLINARY REVIEWS-DATA MINING AND KNOWLEDGE DISCOVERY			English	Review						business intelligence; business text processing; knowledge graphs; natural language QA	EXTRACTION; ONTOLOGY; TOOL	With proliferation of Big Data, organizational decision making has also become more complex. Business Intelligence (BI) is no longer restricted to querying about marketing and sales data only. It is more about linking data from disparate applications and also churning through large volumes of unstructured data like emails, call logs, social media, News, and so on in an attempt to derive insights that can also provide actionable intelligence and better inputs for future strategy making. Semantic technologies like knowledge graphs have proved to be useful tools that help in linking disparate data sources intelligently and also enable reasoning through complex networks that are created as a result of this linking. Over the last decade the process of creation, storage, and maintenance of knowledge graphs have sufficiently matured, and they are now making inroads into business decision making also. Very recently, these graphs are also seen as a potential way to reduce hallucinations of large language models, by including these during pre-training as well as generation of output. There are a number of challenges also. These include building and maintaining the graphs, reasoning with missing links, and so on. While these remain as open research problems, we present in this article a survey of how knowledge graphs are currently used for deriving business intelligence with use-cases from various domains. This article is categorized under: Algorithmic Development > Text Mining Application Areas > Business and Industry	[Dey, Lipika] Ashoka Univ, Delhi, India	Ashoka University	Dey, L (corresponding author), Ashoka Univ, Delhi, India.	lipikadey@gmail.com						Agrawal G., 2023, CAN KNOWLEDGE GRAPHS; [Anonymous], 2017, An Introduction to Description Logic, DOI DOI 10.1017/9781139025355; [Anonymous], 2013, P 2013 C EMPIRICAL M; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Baek J., 2023, KNOWLEDGE AUGMENTED; Bengio Y, 2001, ADV NEUR IN, V13, P932; Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34; Bhattacharya A, 2018, 2018 IEEE INDIAN CONFERENCE ON ANTENNAS & PROPOGATION (INCAP); Bordes A., 2014, Question Answering with Subgraph Embeddings, P615; Bordes A., 2012, JOINT LEARNING WORDS; Bordes A., 2011, Learning structured embeddings of knowledge bases; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Bordes A, 2014, MACH LEARN, V94, P233, DOI 10.1007/s10994-013-5363-6; Brambilla M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1359, DOI 10.1145/3184558.3191578; Brambilla M, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P795, DOI 10.1145/3038912.3052697; Chang Kai-Wei., 2014, Typed tensor decomposition of knowledge bases for relation extraction; Chithrananda S., 2020, Chemberta: Large-scale self-supervised pretraining for molecular property prediction; Christopoulou F., 2018, WALK BASED MODEL ENT, DOI [10.18653/v1/P18-2014, DOI 10.18653/V1/P18-2014]; Culotta A., 2004, DEPENDENCY TREE KERN; Das R, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P132; Dasgupta T., 2022, P 1 WORKSH COMM REPR; Dasgupta T., 2017, P INT C WEB INT; Dasgupta T, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P306; Dutt R., 2022, PERKGQA QUESTION ANS; Ernst P, 2014, PROC INT CONF DATA, P1254, DOI 10.1109/ICDE.2014.6816754; Etzioni O., 2011, OPEN INFORM EXTRACTI; Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378; Fader Anthony, 2011, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, P1535, DOI DOI 10.1234/12345678; Farber M., 2018, WHICH KNOWLEDGE GRAP; Fellbaum C., 2017, The Oxford handbook of cognitive science, P301; Ferrara E, 2014, KNOWL-BASED SYST, V70, P301, DOI 10.1016/j.knosys.2014.07.007; Finkel J. R., 2005, INCORPORATING NON LO; Forjan M, 2012, 11TH IFAC/IEEE INTERNATIONAL CONFERENCE ON PROGRAMMABLE DEVICES AND EMBEDDED SYSTEMS (PDES 2012); Grenon P., 2003, Foundations and Applications of Spatio-Temporal Reasoning, P27; Haase P, 2019, SEMANT WEB, V10, P1109, DOI 10.3233/SW-190360; Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001; Hoffmann R, 2011, P 49 ANN M ASS COMP, V1, P541, DOI DOI 10.5555/2002472; Kaliyar RK, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P785, DOI 10.1109/CCAA.2015.7148480; Kambhatla Nanda., 2004, P ACL 2004; Köhler S, 2019, NUCLEIC ACIDS RES, V47, pD1018, DOI 10.1093/nar/gky1105; Kolthoff K., 2015, SEMANTIC RELATION CO; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Li X., 2014, FOCUSING DECOMPOSITI; Lin YK, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2124; Liu PK, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.108870; Liu Y, 2019, ARXIV PREPRINT ARXIV; Liu Z., 2021, P 29 INT C INT JOINT; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Mahdisoltani Farzaneh., 2015, YAGO3 - A Knowledge Base from Multilingual Wikipedias; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Miller GA., 1998, Wordnet: an electronic lexical database; Mintz M, 2009, P JOINT C 47 ANN M A, P1003; Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513; Nguyen B., 2007, Lit. Rev. Lang. Stat., V2, P1; Nickel M, 2011, ICML; Pal H., 2016, DEMONYMS COMPOUND RE; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Qin P., 2018, ROBUST DISTANT SUPER; Qin P., 2018, DSGAN GENERATIVE ADV; Ren H., 2021, LEGO LATENT EXECUTIO; Resnik P, 1995, INT JOINT CONF ARTIF, P448; Riedel S., 2010, Modeling relations and their mentions without labeled text; Robinson I., 2015, Graph databases: new opportunities for connected data; Robinson PN, 2010, CLIN GENET, V77, P525, DOI 10.1111/j.1399-0004.2010.01436.x; Robinson PN, 2008, AM J HUM GENET, V83, P610, DOI 10.1016/j.ajhg.2008.09.017; Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4498; Schmitz M., 2012, OPEN LANGUAGE LEARNI; Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62; Singhal Amit, 2012, Official Google Blog, V16; Smirnova A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3241741; Socher R., 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, P1201, DOI [DOI 10.5555/2390948.2391084, DOI 10.1162/153244303322533223, 10.5555/2390948.2391084]; Spitkovsky VI, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3168; Steiner Thomas, 2013, International Journal of Computer Information Systems and Industrial Management Applications, V5, P69; Suchanek F.M., 2007, YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia; Syed MH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136007; Vashishth S., 2018, RESIDE IMPROVING DIS; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wen Y., 2023, PREPRINT; Westbury SK, 2015, GENOME MED, V7, DOI 10.1186/s13073-015-0151-5; Weston J., 2014, OPEN QUESTION ANSWER; Wu Y., 2023, PREPRINT; Yahya M., 2014, RENOUN FACT EXTRACTI; Yang B., 2014, PREPRINT; Yang M. C., 2014, JOINT RELATIONAL EMB; Yang MC, 2015, EXPERT SYST APPL, V42, P9086, DOI 10.1016/j.eswa.2015.07.009; Yasunaga M., 2022, Advances in Neural Information Processing Systems, P37309; Yih WT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P201; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zeng D., 2015, DISTANT SUPERVISION; Zeng D, 2014, RELATION CLASSIFICAT; Zettlemoyer L. S., 2012, PREPRINT; Zhang YY, 2018, AAAI CONF ARTIF INTE, P6069; Zhao S., 2005, EXTRACTING RELATIONS	95	0	0	33	33	WILEY PERIODICALS, INC	SAN FRANCISCO	ONE MONTGOMERY ST, SUITE 1200, SAN FRANCISCO, CA 94104 USA	1942-4787	1942-4795		WIRES DATA MIN KNOWL	Wiley Interdiscip. Rev.-Data Mining Knowl. Discov.	MAY	2024	14	3								10.1002/widm.1529	http://dx.doi.org/10.1002/widm.1529		FEB 2024	25	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PT1N9					2024-07-03	WOS:001160976500001
J	Wahidur, RSM; Tashdeed, I; Kaur, M; Lee, HN				Wahidur, Rahman S. M.; Tashdeed, Ishmam; Kaur, Manjit; Lee, Heung-No			Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering	IEEE ACCESS			English	Article						Cryptocurrency; Social networking (online); Analytical models; Training; Context modeling; Sentiment analysis; Transformers; Zero-shot learning; Supervised learning; in-context learning; supervised fine-tuning; instruction tuned; prompt engineering	NEURAL-NETWORKS	Blockchain technology has revolutionized the financial landscape, witnessing widespread adoption of cryptocurrencies due to their decentralized and transparent nature. As sentiments expressed on social media platforms wield substantial influence over cryptocurrency market dynamics, sentiment analysis has emerged as a crucial tool for gauging public opinion and predicting market trends. This paper explores fine-tuning techniques for large language models to enhance sentiment analysis performance. Experimental results demonstrate a significant average zero-shot performance gain of 40% on unseen tasks after fine-tuning, highlighting its potential. Additionally, the impact of instruction-based fine-tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to complete model capacity utilization. To gain deeper insight into instruction effectiveness, the paper presents experimental investigations under different instruction tuning setups. Results show the model achieves an average accuracy score of 72.38% for short and simple instructions, outperforming long and complex instructions by over 12%. Finally, the paper explores the relationship between fine-tuning corpus size and model performance, identifying an optimal corpus size of 6,000 data points for the highest performance across different models. Microsoft's MiniLM, a distilled version of BERT, excels in efficient data use and performance optimization, while Google's FLAN-T5 demonstrates consistent and reliable performance across diverse datasets.	[Wahidur, Rahman S. M.; Lee, Heung-No] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea; [Tashdeed, Ishmam] Islamic Univ Technol, Dept Comp Sci & Engn, Gazipur 1260, Bangladesh; [Kaur, Manjit] SR Univ, Sch Comp Sci & Artificial Intelligence, Warangal 506371, Telangana, India	Gwangju Institute of Science & Technology (GIST)	Lee, HN (corresponding author), Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.	heungno@gist.ac.kr		, S M WAHIDUR RAHMAN/0009-0008-6092-3962	Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government (MSIT)	Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea)	No Statement Available	Binder Tweet, 2019, Twitter Real Time Monitoring and Twitter Live Analytics.; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buterin V., 2014, Ethereum: A next-generation smart contract and decentralized application platform; Chauhan UA, 2020, WORLD WIDE WEB, V23, P1811, DOI 10.1007/s11280-020-00785-z; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai D., 2023, FINDINGS ASS COMPUTA, P4005; Dennis L., 2023, Prompt Engineering, Leveraging in Context Learning; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Divesh, 2022, 2022 6th International Conference on Computing Methodologies and Communication (ICCMC), P730, DOI 10.1109/ICCMC53470.2022.9753723; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Du H., 2023, arXiv; Dwivedi Himanshu, 2023, 2023 3rd International Conference on Smart Data Intelligence (ICSMDI), P140, DOI 10.1109/ICSMDI57622.2023.00032; Fang F, 2022, FINANC INNOV, V8, DOI 10.1186/s40854-021-00321-6; Gao T., 2020, arXiv; Goularas Dionysis, 2019, 2019 International Conference on Deep Learning and Machine Learning in Emerging Applications (Deep-ML). Proceedings, P12, DOI 10.1109/Deep-ML.2019.00011; Hasan I. D., 2022, P 7 INT C INF COMP I, P1; Hernández-Rubio M, 2019, USER MODEL USER-ADAP, V29, P381, DOI 10.1007/s11257-018-9214-9; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Jagini Achyut, 2023, 2023 3rd International Conference on Smart Data Intelligence (ICSMDI), P32, DOI 10.1109/ICSMDI57622.2023.00015; Jay P, 2020, IEEE ACCESS, V8, P82804, DOI 10.1109/ACCESS.2020.2990659; Kim G, 2023, IEEE ACCESS, V11, P6912, DOI 10.1109/ACCESS.2023.3236032; Kokab ST, 2022, ARRAY-NY, V14, DOI 10.1016/j.array.2022.100157; Kushal S, 2022, Pre-Training, Fine-Tuning and in-Context Learning in Large Language Models (LLMS); Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lopez-Lira A, 2023, Arxiv, DOI arXiv:2304.07619; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Matalon Y, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86510-w; Min SW, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2791; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; Oikonomopoulos S., 2022, P 13 INT C INF INT S, P1; OpenAI Platform, 2023, GPT Best Practices-OpenAI API; Ortu M, 2021, Arxiv, DOI arXiv:2102.08189; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Padmalatha E., 2022, P INT C EL COMP COMM, P1; Parekh R, 2022, IEEE ACCESS, V10, P35398, DOI 10.1109/ACCESS.2022.3163305; Passalis N, 2022, NEURAL COMPUT APPL, V34, P19441, DOI 10.1007/s00521-022-07509-6; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Prajapati P, 2020, Arxiv, DOI arXiv:2001.10343; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Raffel C, 2020, J MACH LEARN RES, V21; Saad M, 2018, IEEE CONF COMPUT, P704, DOI 10.1109/INFCOMW.2018.8406859; Sanh V, 2022, arXiv; Sasmaz Emre, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P613, DOI 10.1109/UBMK52708.2021.9558914; Satrya R. N., 2022, P INT C ADV DAT SCI, P1; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Sebastian R., 2023, Finetuning Large Language Models; Shahbazi Z, 2021, IEEE ACCESS, V9, P162651, DOI 10.1109/ACCESS.2021.3133937; Shankarganesh K, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20779-3; Sharma Sonali, 2022, 2022 3rd International Conference on Intelligent Engineering and Management (ICIEM), P741, DOI 10.1109/ICIEM54221.2022.9853140; Smith S, 2022, arXiv; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Suardi S, 2022, INT REV ECON FINANC, V79, P289, DOI 10.1016/j.iref.2022.02.017; Thangarasa V, 2023, Arxiv, DOI arXiv:2303.10464; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wei CW, 2023, Arxiv, DOI [arXiv:2303.05759, 10.48550/arXiv.2303.05759]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Widianto M. H., 2023, Int. J. Intell. Syst. Appl. Eng., V11, P303; WINSTON PH, 1980, COMMUN ACM, V23, P689, DOI 10.1145/359038.359042; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	69	1	1	17	17	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						10146	10159		10.1109/ACCESS.2024.3350638	http://dx.doi.org/10.1109/ACCESS.2024.3350638			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	GC2E8		gold, Green Submitted			2024-07-03	WOS:001150392400001
J	Sultan, I; Al-Abdallat, H; Alnajjar, Z; Ismail, L; Abukhashabeh, R; Bitar, L; Abu Shanap, M				Sultan, Iyad; Al-Abdallat, Haneen; Alnajjar, Zaina; Ismail, Layan; Abukhashabeh, Razan; Bitar, Layla; Abu Shanap, Mayada			Using ChatGPT to Predict Cancer Predisposition Genes: A Promising Tool for Pediatric Oncologists	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						chatgpt; genes; cancer; oncology; pediatrics	SURVEILLANCE; RECOGNITION	Background: Determining genetic susceptibility for cancer predisposition syndromes (CPS) through cancer predisposition genes (CPGs) testing is critical in facilitating appropriate prevention and surveillance strategies. This study investigates the use of ChatGPT, a large language model, in predicting CPGs using clinical notes.Methods: Our study involved 53 patients with pathogenic CPG mutations. Two kinds of clinical notes were used: the first visit note, containing a thorough history and physical exam, and the genetic clinic note, summarizing the patient's diagnosis and family history. We asked ChatGPT to recommend CPS genes based on these notes and compared these predictions with previously identified mutations.Results: Rb1 was the most frequently mutated gene in our cohort (34%), followed by NF1 (9.4%), TP53 (5.7%), and VHL (5.7%). Out of 53 patients, 30 had genetic clinic notes of a median length of 54 words. ChatGPT correctly predicted the gene in 93% of these cases. However, it failed to predict EPCAM and VHL genes in specific patients. For the first visit notes (median length: 461 words), ChatGPT correctly predicted the gene in 64% of these cases. Conclusion: ChatGPT shows promise in predicting CPGs from clinical notes, particularly genetic clinic notes. This approach may be useful in enhancing CPG testing, especially in areas lacking genetic testing resources. With further training, there is a possibility for ChatGPT to improve its predictive potential and expand its clinical applicability. However, additional research is needed to explore the full potential and applicability of ChatGPT.	[Sultan, Iyad] King Hussein Canc Ctr, Dept Pediat, Amman, Jordan; [Al-Abdallat, Haneen; Ismail, Layan] Univ Jordan, Dept Med, Amman, Jordan; [Alnajjar, Zaina] Hashemite Univ, Dept Med, Zarqa, Jordan; [Abukhashabeh, Razan] King Hussein Canc Ctr, Dept Cell Therapy & Appl Genom, Amman, Jordan; [Bitar, Layla; Abu Shanap, Mayada] King Hussein Canc Ctr, Dept Pediat Oncol, Amman, Jordan	King Hussein Cancer Center; University of Jordan; Hashemite University; King Hussein Cancer Center; King Hussein Cancer Center	Sultan, I (corresponding author), King Hussein Canc Ctr, Dept Pediat, Amman, Jordan.	isultan@khcc.jo	Alnajjar, Zaina/KHD-5969-2024	Alnajjar, Zaina/0000-0002-8421-465X; Ismail, Layan/0000-0003-4566-9595; Bitar, Layla/0009-0008-3804-8348				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Biesecker B, 2020, CSH PERSPECT MED, V10, DOI 10.1101/cshperspect.a038968; Brodeur GM, 2017, CLIN CANCER RES, V23, pE1, DOI 10.1158/1078-0432.CCR-17-0702; Ceyhan-Birsoy O, 2022, GENOME MED, V14, DOI 10.1186/s13073-022-01101-2; Clericuzio CL, 1999, AM J MED GENET, V89, P81, DOI 10.1002/(SICI)1096-8628(19990625)89:2<81::AID-AJMG5>3.0.CO;2-I; Cuppen E, 2022, JCO PRECIS ONCOL, V6, DOI 10.1200/PO.22.00245; Dadhania V, 2022, BMC CANCER, V22, DOI 10.1186/s12885-022-09559-4; Das A, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P285; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goudie C, 2021, JAMA ONCOL, V7, P1806, DOI 10.1001/jamaoncol.2021.4536; Gutierrez BJ., 2022, FIND ASS COMPUT LING, DOI DOI 10.48550/ARXIV.2203.08410; Jongmans MCJ, 2016, EUR J MED GENET, V59, P116, DOI 10.1016/j.ejmg.2016.01.008; Mody RJ, 2015, JAMA-J AM MED ASSOC, V314, P913, DOI 10.1001/jama.2015.10080; Murray AK, 2021, CANCER MED-US, V10, P2026, DOI 10.1002/cam4.3787; Raoa A, 2008, CURR OPIN PEDIATR, V20, P1, DOI 10.1097/MOP.0b013e3282f4249a; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schulte B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37938; Shmatko A, 2022, NAT CANCER, V3, P1026, DOI 10.1038/s43018-022-00436-4; Temsah MH, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39384; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Villani A, 2023, NAT CANCER, V4, P203, DOI 10.1038/s43018-022-00474-y; Zhang JH, 2015, NEW ENGL J MED, V373, P2336, DOI 10.1056/NEJMoa1508054; Zhong A, 2021, GENET MED, V23, P2270, DOI 10.1038/s41436-018-0090-9	25	1	1	3	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	OCT 24	2023	15	10							e47594	10.7759/cureus.47594	http://dx.doi.org/10.7759/cureus.47594			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Z1NK4	38021917	gold, Green Published			2024-07-03	WOS:001109817700029
J	Jaimovitch-López, G; Ferri, C; Hernández-Orallo, J; Martínez-Plumed, F; Ramírez-Quintana, MJ				Jaimovitch-Lopez, Gonzalo; Ferri, Cesar; Hernandez-Orallo, Jose; Martinez-Plumed, Fernando; Ramirez-Quintana, Maria Jose			Can language models automate data wrangling?	MACHINE LEARNING			English	Article						Data science automation; Data wrangling; Language models; Machine learning pipelines		The automation of data science and other data manipulation processes depend on the integration and formatting of 'messy' data. Data wrangling is an umbrella term for these tedious and time-consuming tasks. Tasks such as transforming dates, units or names expressed in different formats have been challenging for machine learning because (1) users expect to solve them with short cues or few examples, and (2) the problems depend heavily on domain knowledge. Interestingly, large language models today (1) can infer from very few examples or even a short clue in natural language, and (2) can integrate vast amounts of domain knowledge. It is then an important research question to analyse whether language models are a promising approach for data wrangling, especially as their capabilities continue growing. In this paper we apply different variants of the language model Generative Pre-trained Transformer (GPT) to five batteries covering a wide range of data wrangling problems. We compare the effect of prompts and few-shot regimes on their results and how they compare with specialised data wrangling systems and other tools. Our major finding is that they appear as a powerful tool for a wide range of data wrangling tasks. We provide some guidelines about how they can be integrated into data processing pipelines, provided the users can take advantage of their flexibility and the diversity of tasks to be addressed. However, reliability is still an important issue to overcome.	[Jaimovitch-Lopez, Gonzalo; Ferri, Cesar; Hernandez-Orallo, Jose; Martinez-Plumed, Fernando; Ramirez-Quintana, Maria Jose] Univ Politecn Valencia, VRAIN, Valencia, Spain	Universitat Politecnica de Valencia	Martínez-Plumed, F (corresponding author), Univ Politecn Valencia, VRAIN, Valencia, Spain.	gonjailo@dsic.upv.es; cferri@dsic.upv.es; jorallo@dsic.upv.es; fmartinez@dsic.upv.es; mramirez@dsic.upv.es	Hernandez-Orallo, Jose/H-9166-2015; Martinez-Plumed, Fernando/I-4076-2015	Martinez-Plumed, Fernando/0000-0003-2902-6477	 [ADS2021]		AcknowledgementsWe thank Lidia Contreras for her help with the Data Wrangling Dataset Repository. We thank the anonymous reviewers from ECMLPKDD Workshop on Automating Data Science (ADS2021) and the anonymous reviewers of this special issue for their comments.	Ashok P, 2016, DEFENCE SCI J, V66, P113; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bellmann P, 2020, IEEE ACCESS, V8, P164380, DOI 10.1109/ACCESS.2020.3021596; Ben-Gal I, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P131, DOI 10.1007/0-387-25465-X_7; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bhupatiraju Surya., 2017, arXiv; Chen YX, 2009, IEEE T PATTERN ANAL, V31, P288, DOI 10.1109/TPAMI.2008.72; Contreras-Ochando L, 2020, COMM COM INF SC, V1167, P17, DOI 10.1007/978-3-030-43823-4_2; Contreras-Ochando L, 2020, LECT NOTES ARTIF INT, V11908, P735, DOI 10.1007/978-3-030-46133-1_44; Cropper A, 2016, LECT NOTES ARTIF INT, V9575, P46, DOI 10.1007/978-3-319-40566-7_4; Das B., 2008, P 14 ACM SIGKDD INT, P169; Das K, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P220; De Bie T, 2022, COMMUN ACM, V65, P76, DOI 10.1145/3495256; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dua Dheeru, 2017, UCI MACHINE LEARNING, DOI DOI 10.1016/J.DSS.2009.05.016; Ellis K, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1638; Fernando MP, 2021, INT J INTELL SYST, V36, P3217, DOI 10.1002/int.22415; Ferrari A., 2016, INTRO MICROSOFT POWE; Furche T., 2016, 19th International Conference on Extending Database Technology, 15-18 March 2016, Bordeaux, France, P473; Gao T., 2020, arXiv; Garcia S., 2016, Big Data Analytics, V1, P9, DOI [10.1186/s41044-016-0014-0, DOI 10.1186/S41044-016-0014-0]; Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282; Gulwani S, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P317, DOI 10.1145/1926385.1926423; Ham K, 2013, J MED LIB ASS JMLA, V101, P233, DOI DOI 10.3163/1536-5050.101.3.020; He Zengyou, 2005, Computer Science and Information Systems, V2, P103, DOI DOI 10.2298/CSIS0501103H; Hendrycks D., 2021, ICLR; Hendrycks Dan, 2021, arXiv; Hulsebos M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1500, DOI 10.1145/3292500.3330993; Izacard G, 2021, Arxiv, DOI arXiv:2007.01282; Jaimovitch-Lopez G., 2021, ECMLPKDD WORKSHOP AU; Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363; Lazarevic A., 2005, P 11 ACM SIGKDD INT, P157, DOI DOI 10.1145/1081870.1081891; Lu Yao, 2021, arXiv; Nazabal A, 2020, Arxiv, DOI arXiv:2004.12929; Noto K, 2012, DATA MIN KNOWL DISC, V25, P109, DOI 10.1007/s10618-011-0234-x; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Petrova-Antonova D., 2020, QUALITY INFORM COMMU, P32; Porwal U, 2018, Arxiv, DOI arXiv:1712.04129; Puri R, 2019, Arxiv, DOI arXiv:1912.10165; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381; Reed S, 2022, Arxiv, DOI arXiv:2205.06175; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.2307/2335739; Schick T, 2021, Arxiv, DOI [arXiv:2001.07676, 10.48550/arXiv.2001.07676]; SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x; Shi Y, 2016, AAAI CONF ARTIF INTE, P2030; Singh R, 2016, ACM SIGPLAN NOTICES, V51, P343, DOI 10.1145/2914770.2837668; Singh R, 2015, LECT NOTES COMPUT SC, V9206, P398, DOI 10.1007/978-3-319-21690-4_23; Sleeper R., 2021, TABLEAU DESKTOP POCK; Smith S, 2022, arXiv; Srivastava Aarohi, 2022, arXiv; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Terrizzano I.G., 2015, CIDR; Trifacta, 2022, TRIFACTA WRANGLER; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wu Bo., 2012, Proceedings of the Ninth International Workshop on Information Integration on the Web, P8; Xu SL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P422; Zeng W., 2021, PREPRINT; Zhang D., 2019, arXiv; Zoph B., 2022, arXiv	62	2	2	5	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125	1573-0565		MACH LEARN	Mach. Learn.	JUN	2023	112	6					2053	2082		10.1007/s10994-022-06259-9	http://dx.doi.org/10.1007/s10994-022-06259-9		DEC 2022	30	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	I6KH7		hybrid			2024-07-03	WOS:000911298300001
C	Bucker, A; Figueredo, L; Haddadin, S; Kapoor, A; Ma, S; Bonatti, R			IEEE	Bucker, Arthur; Figueredo, Luis; Haddadin, Sami; Kapoor, Ashish; Ma, Shuang; Bonatti, Rogerio			Reshaping Robot Trajectories Using Natural Language Commands: A Study of Multi-Modal Data Alignment Using Transformers	2022 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS)	IEEE International Conference on Intelligent Robots and Systems		English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	OCT 23-27, 2022	Kyoto, JAPAN	IEEE, Royal Soc Japan, IEEE Robot & Automat Soc, IES, SICE, New Technol Fdn				Natural language is the most intuitive medium for us to interact with other people when expressing commands and instructions. However, using language is seldom an easy task when humans need to express their intent towards robots, since most of the current language interfaces require rigid templates with a static set of action targets and commands. In this work, we provide a flexible language-based interface for human-robot collaboration, which allows a user to reshape existing trajectories for an autonomous agent. We take advantage of recent advancements in the field of large language models (BERT and CLIP) to encode the user command, and then combine these features with trajectory information using multi-modal attention transformers. We train the model using imitation learning over a dataset containing robot trajectories modified by language commands, and treat the trajectory generation process as a sequence prediction problem, analogously to how language generation architectures operate. We evaluate the system in multiple simulated trajectory scenarios, and show a significant performance increase of our model over baseline approaches. In addition, our real-world experiments with a robot arm show that users significantly prefer our natural language interface over traditional methods such as kinesthetic teaching or cost-function programming. Our study shows how the field of robotics can take advantage of large pre-trained language models towards creating more intuitive interfaces between robots and machines. Project webpage: https://arthurfenderbucker. github.io/NL_trajectory_reshaper/	[Bucker, Arthur; Figueredo, Luis; Haddadin, Sami] Tech Univ Munich, Munich, Germany; [Kapoor, Ashish; Ma, Shuang; Bonatti, Rogerio] Microsoft, Redmond, WA USA	Technical University of Munich; Microsoft	Bucker, A (corresponding author), Tech Univ Munich, Munich, Germany.			Haddadin, Sami/0000-0001-7696-4955; Figueredo, Luis/0000-0002-0759-3000	Lighthouse Initiative Geriatronics by StMWi Bayern [5140951]	Lighthouse Initiative Geriatronics by StMWi Bayern	SH has a potential conflict of interest as shareholder of Franka Emika GmbH. This work was funded by the Lighthouse Initiative Geriatronics by StMWi Bayern (Project X, grant 5140951).	Alwassel H., 2020, Advances in Neural Information Processing Systems, V33, P9758; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Arkin J, 2020, INT J ROBOT RES, V39, P1279, DOI 10.1177/0278364920917755; Ba LJ., 2016, CORR; Bommasani Rishi, 2021, ARXIV210807258; Bonatti R, 2021, IEEE INT CONF ROBOT, P7302, DOI 10.1109/ICRA48506.2021.9560745; Chen A. S., 2021, ARXIV210316817; Chen LL, 2021, ADV NEUR IN, V34; Devlin J., 2019, CoRR, P4171; Fu Justin, 2019, INT C LEARN REPR; GARCIA CE, 1989, AUTOMATICA, V25, P335, DOI 10.1016/0005-1098(89)90002-2; Giuliari F, 2021, INT C PATT RECOG, P10335, DOI 10.1109/ICPR48806.2021.9412190; Goodwin W., 2021, ARXIV211107975; Goyal P., 2021, ARXIV210602972; Hao Weituo, 2020, P IEEECVF C COMPUTER, P13134, DOI DOI 10.1109/CVPR42600.2020.01315; Hong Y., ARXIV201113922; Huang W., 2022, ARXIV220107207; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Janner M., 2021, ADV NEURAL INFORM PR, V34; Kirk NH, 2014, IEEE INT CONF ROBOT, P6667, DOI 10.1109/ICRA.2014.6907843; LaValle S. M., 2006, PLANNING ALGORITHMS; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lu J, 2019, WIRELESS NETW-GER, P33, DOI 10.1007/978-3-030-01150-5_2; Lynch C., 2020, ARXIV200507648; Ma CY, 2019, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR.2019.00689; Ma S., 2022, COMPASS CONTRASTIVE; MACMAHON M, 2006, P NAT C ART INT AAAI, P1475; Majumdar Arjun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P259, DOI 10.1007/978-3-030-58539-6_16; Nguyen K., 2019, HELP ANNA VISUAL NAV; Radford A, 2021, PR MACH LEARN RES, V139; Raman Vasumathi, 2013, Robotics: Science and Systems; Ratliff N, 2009, IEEE INT CONF ROBOT, P4030; Shao L, 2021, INT J ROBOT RES, V40, P1419, DOI 10.1177/02783649211046285; Shridhar M., 2022, C ROBOT LEARNING, P894; Smith S., 2022, arXiv preprint arXiv:2201.11990; Stepputtis S., 2020, Advances in Neural Information Processing Systems, V33, p13 139; Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Szot Andrew, 2021, Advances in Neural Information Processing Systems, V34, P251; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Thomason J., 2020, P C ROBOT LEARNING C, P394; Vaswani A, 2017, ADV NEUR IN, V30; Walter M. R., 2021, ARXIV210510396; You Y., 2019, CoRR; Yuan Lu, 2021, ARXIV211111432; Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041	46	5	5	3	16	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0858		978-1-6654-7927-1	IEEE INT C INT ROBOT			2022							978	984		10.1109/IROS47612.2022.9981810	http://dx.doi.org/10.1109/IROS47612.2022.9981810			7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BU4WN		Green Submitted			2024-07-03	WOS:000908368201008
J	Issaiy, M; Ghanaati, H; Kolahi, S; Shakiba, M; Jalali, AH; Zarei, D; Kazemian, S; Avanaki, MA; Firouznia, K				Issaiy, Mahbod; Ghanaati, Hossein; Kolahi, Shahriar; Shakiba, Madjid; Jalali, Amir Hossein; Zarei, Diana; Kazemian, Sina; Avanaki, Mahsa Alborzi; Firouznia, Kavous			Methodological insights into ChatGPT's screening performance in systematic reviews	BMC MEDICAL RESEARCH METHODOLOGY			English	Article						Systematic review; ChatGPT; AI; Large language model; Article screening; Radiology; GPT		Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data.Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT's performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals.Results ChatGPT completed the screening process within an hour, while GPs took an average of 7-10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs' sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27.Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.	[Issaiy, Mahbod; Ghanaati, Hossein; Kolahi, Shahriar; Shakiba, Madjid; Jalali, Amir Hossein; Zarei, Diana; Avanaki, Mahsa Alborzi; Firouznia, Kavous] Univ Tehran Med Sci, Adv Diagnost & Intervent Radiol Res Ctr ADIR, Tehran, Iran; [Kazemian, Sina] Univ Tehran Med Sci, Cardiovasc Dis Res Inst, Cardiac Primary Prevent Res Ctr, Tehran, Iran	Tehran University of Medical Sciences; Tehran University of Medical Sciences	Firouznia, K (corresponding author), Univ Tehran Med Sci, Adv Diagnost & Intervent Radiol Res Ctr ADIR, Tehran, Iran.	k_firouznia@yahoo.com	Shakiba, Madjid/AEU-1247-2022; Kolahi, Shahriar/GNM-8666-2022	Shakiba, Madjid/0000-0001-5935-5111; Kolahi, Shahriar/0000-0002-7490-1229				Alessandro L, 2009, PLoS Med, V6; Amir V, 2022, BMC Med Res Methodol, V22; Ana Helena Salles dos R, 2023, Syst Rev, V12; Bahdanau D., 2016, ARXIV; Bannach-Brown A, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-0942-7; Booth A, 2006, LIBR HI TECH, V24, P355, DOI 10.1108/07378830610692127; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Byron CW, 2012, Deploying an interactive machine learning system in an evidence-based practice center: abstrackr; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; dos Reis AHS, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02231-3; Efron B., 1994, An Introduction to the Bootstrap, DOI DOI 10.1201/9780429246593; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Gates A, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1222-2; Gates A, 2018, SYST REV-LONDON, V7, DOI 10.1186/s13643-018-0707-8; Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2; Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55; Jaccard index: Wikipedia, 2023, About us; Kahili-Heede M, 2021, J MED LIBR ASSOC, V109, P523, DOI 10.5195/jmla.2021.1263; Kevin EKC, 2021, Syst Rev, V10; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; McKinney W., 2010, P 9 PYTH SCI C, V445, P51, DOI [DOI 10.25080/MAJORA-92BF1922-00A, 10.25080/MAJORA-92BF1922-00A]; Methley AM, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/s12913-014-0579-0; Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rathbone J, 2015, SYST REV-LONDON, V4, DOI 10.1186/s13643-015-0067-6; Schisterman EF, 2005, EPIDEMIOLOGY, V16, P73, DOI 10.1097/01.ede.0000147512.81966.ba; The EndNote Team, 2013, ENDNOTE; Vaswani A, 2017, ADV NEUR IN, V30; Viera AJ, 2005, FAM MED, V37, P360; Wallace BC, 2012, INT HLTH INFORMATICS; Wang B, Iteratively Prompt Pre-trained Language Models for Chain of Thought2022 December; Waskom M., 2021, J OPEN SOURCE SOFTW, V6, P3021, DOI [10.21105/JOSS.03021, DOI 10.21105/JOSS.03021, 10.21105/joss.03021]; Wildridge Valerie, 2002, Health Info Libr J, V19, P113, DOI 10.1046/j.1471-1842.2002.00378.x	37	0	0	2	2	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1471-2288		BMC MED RES METHODOL	BMC Med. Res. Methodol.	MAR 27	2024	24	1							78	10.1186/s12874-024-02203-8	http://dx.doi.org/10.1186/s12874-024-02203-8			11	Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services	MQ4P7	38539117	gold, Green Published			2024-07-03	WOS:001195084100001
J	Rahit, KMTH; Avramovic, V; Chong, JX; Tarailo-Graovac, M				Rahit, K. M. Tahsin Hassan; Avramovic, Vladimir; Chong, Jessica X.; Tarailo-Graovac, Maja			GPAD: a natural language processing-based application to extract the gene-disease association discovery information from OMIM	BMC BIOINFORMATICS			English	Article						Mendelian disorder; NLP; Gene-disease relationship; Gene discovery; Rare disease gene; Trends in gene discovery	RARE-DISEASE; MENDELIAN-INHERITANCE; DEFICIENCY; DIAGNOSIS; DISORDERS; ZEBRAFISH; MODEL	BackgroundThousands of genes have been associated with different Mendelian conditions. One of the valuable sources to track these gene-disease associations (GDAs) is the Online Mendelian Inheritance in Man (OMIM) database. However, most of the information in OMIM is textual, and heterogeneous (e.g. summarized by different experts), which complicates automated reading and understanding of the data. Here, we used Natural Language Processing (NLP) to make a tool (Gene-Phenotype Association Discovery (GPAD)) that could syntactically process OMIM text and extract the data of interest.ResultsGPAD applies a series of language-based techniques to the text obtained from OMIM API to extract GDA discovery-related information. GPAD can inform when a particular gene was associated with a specific phenotype, as well as the type of validation-whether through model organisms or cohort-based patient-matching approaches-for such an association. GPAD extracted data was validated with published reports and was compared with large language model. Utilizing GPAD's extracted data, we analysed trends in GDA discoveries, noting a significant increase in their rate after the introduction of exome sequencing, rising from an average of about 150-250 discoveries each year. Contrary to hopes of resolving most GDAs for Mendelian disorders by now, our data indicate a substantial decline in discovery rates over the past five years (2017-2022). This decline appears to be linked to the increasing necessity for larger cohorts to substantiate GDAs. The rising use of zebrafish and Drosophila as model organisms in providing evidential support for GDAs is also observed.ConclusionsGPAD's real-time analyzing capacity offers an up-to-date view of GDA discovery and could help in planning and managing the research strategies. In future, this solution can be extended or modified to capture other information in OMIM and scientific literature.	[Rahit, K. M. Tahsin Hassan; Avramovic, Vladimir; Tarailo-Graovac, Maja] Univ Calgary, Cumming Sch Med, Dept Biochem Mol Biol & Med Genet, Calgary, AB T2N 4N1, Canada; [Rahit, K. M. Tahsin Hassan; Avramovic, Vladimir; Tarailo-Graovac, Maja] Univ Calgary, Alberta Childrens Hosp Res Inst, Calgary, AB T2N 4N1, Canada; [Chong, Jessica X.] Univ Washington, Dept Pediat, Div Genet Med, Seattle, WA 98195 USA; [Chong, Jessica X.] Brotman Baty Inst, Seattle, WA 98195 USA	University of Calgary; University of Calgary; University of Washington; University of Washington Seattle	Tarailo-Graovac, M (corresponding author), Univ Calgary, Cumming Sch Med, Dept Biochem Mol Biol & Med Genet, Calgary, AB T2N 4N1, Canada.; Tarailo-Graovac, M (corresponding author), Univ Calgary, Alberta Childrens Hosp Res Inst, Calgary, AB T2N 4N1, Canada.	maja.tarailograovac@ucalgary.ca		Avramovic, Vladimir/0000-0002-3579-837X	Eyes High Doctoral Scholarship	Eyes High Doctoral Scholarship	This research was enabled by utilizing the Compute Canada (www.computecanada.ca) computing resources. We thank Dr. Tatiana Maroilley for her valuable comments on the manuscript.	Abbott A, 2011, NATURE, V472, P17, DOI 10.1038/472017a; Amberger JS, 2019, NUCLEIC ACIDS RES, V47, pD1038, DOI 10.1093/nar/gky1151; Amberger JS, 2015, NUCLEIC ACIDS RES, V43, pD789, DOI 10.1093/nar/gku1205; Antonarakis SE, 2006, NAT REV GENET, V7, P277, DOI 10.1038/nrg1826; Arsenault C, 2022, NAT MED, V28, P1314, DOI 10.1038/s41591-022-01750-1; Austin CP, 2018, CTS-CLIN TRANSL SCI, V11, P21, DOI 10.1111/cts.12500; Austin-Tse C, 2013, AM J HUM GENET, V93, P672, DOI 10.1016/j.ajhg.2013.08.015; Bamshad MJ, 2019, AM J HUM GENET, V105, P448, DOI 10.1016/j.ajhg.2019.07.011; Bamshad MJ, 2011, NAT REV GENET, V12, P745, DOI 10.1038/nrg3031; Beck AP, 2020, CELL TISSUE RES, V380, P305, DOI 10.1007/s00441-019-03134-3; Bjornsson HT, 2015, GENOME RES, V25, P1473, DOI 10.1101/gr.190629.115; Bosch E, 2015, Genome-Wide Association Studies, P231; Boycott KM, 2022, HUM MUTAT, V43, P659, DOI 10.1002/humu.24373; Boycott KM, 2017, AM J HUM GENET, V100, P695, DOI 10.1016/j.ajhg.2017.04.003; Boycott KM, 2013, NAT REV GENET, V14, P681, DOI 10.1038/nrg3555; Brasil S, 2019, GENES-BASEL, V10, DOI 10.3390/genes10120978; Carss KJ, 2017, AM J HUM GENET, V100, P75, DOI 10.1016/j.ajhg.2016.12.003; Chakravarti A, 2021, AM J MED GENET A, V185, P3287, DOI 10.1002/ajmg.a.62463; Chiang C, 2017, NAT GENET, V49, P692, DOI 10.1038/ng.3834; Chong JX, 2015, AM J HUM GENET, V97, P199, DOI 10.1016/j.ajhg.2015.06.009; Chung CCY, 2021, ORPHANET J RARE DIS, V16, DOI 10.1186/s13023-021-01766-9; Chung CCY, 2020, EUR J MED GENET, V63, DOI 10.1016/j.ejmg.2020.104062; de Abreu MS, 2020, NEUROSCIENCE, V445, P3, DOI 10.1016/j.neuroscience.2019.08.034; de Bruijn SE, 2020, AM J HUM GENET, V107, P802, DOI 10.1016/j.ajhg.2020.09.002; Ehrhart F, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00905-y; Ferreira CR, 2019, AM J MED GENET A, V179, P885, DOI 10.1002/ajmg.a.61124; Firth HV, 2009, AM J HUM GENET, V84, P524, DOI 10.1016/j.ajhg.2009.03.010; Frederiksen SD, 2022, ORPHANET J RARE DIS, V17, DOI 10.1186/s13023-022-02217-9; Garret P, 2023, EUR J HUM GENET, V31, P761, DOI 10.1038/s41431-022-01250-3; Ghezzi D, 2012, AM J HUM GENET, V90, P1079, DOI 10.1016/j.ajhg.2012.04.011; GUSELLA JF, 1983, NATURE, V306, P234, DOI 10.1038/306234a0; Hahn Udo, 2020, Yearb Med Inform, V29, P208, DOI 10.1055/s-0040-1702001; Haldane V, 2021, NAT MED, V27, P964, DOI 10.1038/s41591-021-01381-y; Horani A., 2013, PLOS ONE, V8; Howe DG, 2018, LAB ANIMAL, V47, P277, DOI 10.1038/s41684-018-0150-4; Ishiura H, 2018, NAT GENET, V50, P581, DOI 10.1038/s41588-018-0067-2; Jin Q, 2019, arXiv; Jones DW, 2004, BRIT J HAEMATOL, V127, P220, DOI 10.1111/j.1365-2141.2004.05180.x; Kremer LS, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15824; Lakshmi KS, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT), P201, DOI 10.1109/ICADIWT.2014.6814699; Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920; Liu ZC, 2019, TRENDS GENET, V35, P852, DOI 10.1016/j.tig.2019.08.006; Lombardi AM, 2003, THROMB HAEMOSTASIS, V90, P1040, DOI 10.1160/TH03-05-0275; Makhija DT, 2014, J PHARMACOL PHARMACO, V5, P39, DOI 10.4103/0976-500X.124422; Maroilley T, 2019, GENES-BASEL, V10, DOI 10.3390/genes10040275; McKusick VA, 2007, AM J HUM GENET, V80, P588, DOI 10.1086/514346; Monasky MM, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21051687; omim, OMIM Entry Symbols; Osmond M, 2022, GENET MED, V24, P100, DOI 10.1016/j.gim.2021.08.014; Philippakis AA, 2015, HUM MUTAT, V36, P915, DOI 10.1002/humu.22858; PubMed, About Us; Rahit KMTH, 2020, GENES-BASEL, V11, DOI 10.3390/genes11030239; Rodrigues ED, 2022, HUM MUTAT, V43, P782, DOI 10.1002/humu.24359; Sanchis-Juan A, 2018, GENOME MED, V10, DOI 10.1186/s13073-018-0606-6; Seaby EG, 2021, FRONT GENET, V12, DOI 10.3389/fgene.2021.674295; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sobreira Nara, 2015, Hum Mutat, V36, P928, DOI 10.1002/humu.22844; Sobreira NLM., 2017, Curr Protocols Hum Genet, V95, P1; Sohrabi C, 2021, INT J SURG, V86, P57, DOI 10.1016/j.ijsu.2020.12.008; SpaCy, ML-based NLP library for Python; Sun XM, 1997, ARTERIOSCL THROM VAS, V17, P3092, DOI 10.1161/01.ATV.17.11.3092; Tarailo-Graovac M, 2017, ORPHANET J RARE DIS, V12, DOI 10.1186/s13023-017-0584-6; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; University of Washington, MyGene2; van Kuilenburg ABP, 2019, NEW ENGL J MED, V380, P1433, DOI 10.1056/NEJMoa1806627; Wangler MF, 2017, GENETICS, V207, P9, DOI 10.1534/genetics.117.203067; Wilczewski CM, 2023, AM J HUM GENET, V110, P3, DOI 10.1016/j.ajhg.2022.12.004; Wright CF, 2018, NAT REV GENET, V19, P253, DOI 10.1038/nrg.2017.116; Zhang P, 2019, GENES-BASEL, V10, DOI 10.3390/genes10100797	69	0	0	2	2	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	FEB 27	2024	25	1							84	10.1186/s12859-024-05693-x	http://dx.doi.org/10.1186/s12859-024-05693-x			21	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	JP2H2	38413851	gold, Green Published			2024-07-03	WOS:001174299000001
J	Albogami, Y; Alfakhri, A; Alaqil, A; Alkoraishi, A; Alshammari, H; Elsharawy, Y; Alhammad, A; Alhossan, A				Albogami, Yasser; Alfakhri, Almaha; Alaqil, Abdulaziz; Alkoraishi, Aljawharah; Alshammari, Heba; Elsharawy, Yasmin; Alhammad, Abdullah; Alhossan, Abdulaziz			Safety and quality of AI chatbots for drug-related inquiries: A real-world comparison with licensed pharmacists	DIGITAL HEALTH			English	Article						Pharmacists; GPT-4; real-world data; artificial intelligence		Introduction Pharmacists play a pivotal role in ensuring patients are administered safe and effective medications; however, they encounter obstacles such as elevated workloads and a scarcity of qualified professionals. Despite the prospective utility of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), in addressing pharmaceutical inquiries, their applicability in real-world cases remains unexplored.Objective To evaluate GPT-based chatbots' accuracy in real-world drug-related inquiries, comparing their performance to licensed pharmacists.Methods In this cross-sectional study, authors analyzed real-world drug inquiries from a Drug Information Inquiry Database. Two independent pharmacists evaluated the performance of GPT-based chatbots (GPT-3, GPT-3.5, GPT-4) against human pharmacists using accuracy, detail, and risk of harm criteria. Descriptive statistics described inquiry characteristics. Absolute proportion comparative analyses assessed accuracy, detail, and risk of harm. Stratified analyses were performed for different inquiry types.Results Seventy inquiries were included. Most inquiries were received from physicians (41%) and pharmacists (44%). Inquiries type included dosage/administration (34.2%), drug interaction (12.8%) and pregnancy/lactation (15.7%). Majority of inquires included adults (83%) and female patients (54.3%). GPT-4 had 64.3% completely accurate responses, comparable to human pharmacists. GPT-4 and human pharmacists provided sufficiently detailed responses, with GPT-4 offering additional relevant details. Both GPT-4 and human pharmacists delivered 95% safe responses; however, GPT-4 provided proactive risk mitigation information in 70% of the instances, whereas similar information was included in 25.7% of human pharmacists' responses.Conclusion Our study showcased GPT-4's potential in addressing drug-related inquiries accurately and safely, comparable to human pharmacists. Current GPT-4-based chatbots could support healthcare professionals and foster global health improvements.	[Albogami, Yasser; Alhammad, Abdullah; Alhossan, Abdulaziz] King Saud Univ, Coll Pharm, Dept Clin Pharm, Riyadh, Saudi Arabia; [Alfakhri, Almaha] Saudi Food & Drug Author, Riyadh, Saudi Arabia; [Alaqil, Abdulaziz] King Faisal Specialist Hosp & Res Ctr, Pharmaceut Care Div, Riyadh, Saudi Arabia; [Alkoraishi, Aljawharah; Alshammari, Heba; Elsharawy, Yasmin] King Saud Univ Med City, Drug & Poison Informat Ctr, Pharm Dept, Riyadh, Saudi Arabia; [Albogami, Yasser] King Saud Univ, Coll Pharm, POB 145111, Riyadh, Saudi Arabia	King Saud University; King Faisal Specialist Hospital & Research Center; King Saud University; King Saud University	Albogami, Y (corresponding author), King Saud Univ, Coll Pharm, POB 145111, Riyadh, Saudi Arabia.	yalbogami@ksu.edu.sa			King Saud University, Riyadh, Saudi Arabia [RSPD2024R1028]	King Saud University, Riyadh, Saudi Arabia(King Saud University)	The authors extend their appreciation to the Researchers Supporting Project number (RSPD2024R1028), King Saud University, Riyadh, Saudi Arabia.	[Anonymous], Potential and Pitfalls of ChatGPT and Natural-Language Artificial Intelligence Models for Diabetes Education | Diabetes Care; [Anonymous], Youcom; [Anonymous], countries face a health worker crunch linked to COVID-19: WHO | UN News; [Anonymous], Healthcare Access in Rural Communities Overview - Rural Health Information Hub; [Anonymous], GPT-4; [Anonymous], OpenAI API; Bates I, 2018, HUM RESOUR HEALTH, V16, DOI 10.1186/s12960-018-0267-y; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dee J, 2023, INT J CLIN PHARM-NET, V45, P1027, DOI 10.1007/s11096-022-01520-6; Ghaibi Shadi, 2015, Am J Health Syst Pharm, V72, P573, DOI 10.2146/sp150002; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Illamola SM, 2018, BRIT J CLIN PHARMACO, V84, P215, DOI 10.1111/bcp.13438; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Koontalay A, 2021, J MULTIDISCIP HEALTH, V14, P3015, DOI 10.2147/JMDH.S330041; Kung TH., 2023, PLOS Digital Health, V2; Mestrovic A, 2022, PHARM EDUC, V22, P100, DOI 10.46542/pe.2022.224.100109; Nelson Taylor, 2020, Mo Med, V117, P510; Okereke M, 2021, INT J HEALTH PLAN M, V36, P13, DOI 10.1002/hpm.3067; OpenAI, 2023, GPT-4 Technical Report; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Terwiesch C., Would Chat GPT3 get a Wharton MBA?; Tukukino C, 2020, BASIC CLIN PHARMACOL, V126, P65, DOI 10.1111/bcpt.13294; Flôres DDV, 2018, EUR J HOSP PHARM, V25, P262, DOI 10.1136/ejhpharm-2017-001417	24	0	0	1	1	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	2055-2076			DIGIT HEALTH	Digit. Health		2024	10								20552076241253523	10.1177/20552076241253523	http://dx.doi.org/10.1177/20552076241253523			11	Health Care Sciences & Services; Health Policy & Services; Public, Environmental & Occupational Health; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health; Medical Informatics	QW0Y9	38757086	gold			2024-07-03	WOS:001223801200001
J	Suwala, S; Szulc, P; Guzowski, C; Kaminska, B; Dorobiala, J; Wojciechowska, K; Berska, M; Kubicka, O; Kosturkiewicz, O; Kosztulska, B; Rajewska, A; Junik, R				Suwala, Szymon; Szulc, Paulina; Guzowski, Cezary; Kaminska, Barbara; Dorobiala, Jakub; Wojciechowska, Karolina; Berska, Maria; Kubicka, Olga; Kosturkiewicz, Oliwia; Kosztulska, Bernadetta; Rajewska, Alicja; Junik, Roman			ChatGPT-3.5 passes Poland's medical final examination-Is it possible for ChatGPT to become a doctor in Poland?	SAGE OPEN MEDICINE			English	Article						ChatGPT; education; medicine; public health	PERFORMANCE	Objectives: ChatGPT is an advanced chatbot based on Large Language Model that has the ability to answer questions. Undoubtedly, ChatGPT is capable of transforming communication, education, and customer support; however, can it play the role of a doctor? In Poland, prior to obtaining a medical diploma, candidates must successfully pass the Medical Final Examination.Methods: The purpose of this research was to determine how well ChatGPT performed on the Polish Medical Final Examination, which passing is required to become a doctor in Poland (an exam is considered passed if at least 56% of the tasks are answered correctly). A total of 2138 categorized Medical Final Examination questions (from 11 examination sessions held between 2013-2015 and 2021-2023) were presented to ChatGPT-3.5 from 19 to 26 May 2023. For further analysis, the questions were divided into quintiles based on difficulty and duration, as well as question types (simple A-type or complex K-type). The answers provided by ChatGPT were compared to the official answer key, reviewed for any changes resulting from the advancement of medical knowledge.Results: ChatGPT correctly answered 53.4%-64.9% of questions. In 8 out of 11 exam sessions, ChatGPT achieved the scores required to successfully pass the examination (60%). The correlation between the efficacy of artificial intelligence and the level of complexity, difficulty, and length of a question was found to be negative. AI outperformed humans in one category: psychiatry (77.18% vs. 70.25%, p = 0.081).Conclusions: The performance of artificial intelligence is deemed satisfactory; however, it is observed to be markedly inferior to that of human graduates in the majority of instances. Despite its potential utility in many medical areas, ChatGPT is constrained by its inherent limitations that prevent it from entirely supplanting human expertise and knowledge.	[Suwala, Szymon; Junik, Roman] Nicolaus Copernicus Univ, Dept Endocrinol & Diabetol, Coll Medicum, 9 Sklodowskiej Curie St, PL-85094 Bydgoszcz, Poland; [Szulc, Paulina; Guzowski, Cezary; Kaminska, Barbara; Dorobiala, Jakub; Wojciechowska, Karolina; Berska, Maria; Kubicka, Olga; Kosturkiewicz, Oliwia; Kosztulska, Bernadetta; Rajewska, Alicja] Nicolaus Copernicus Univ, Dept Endocrinol & Diabetol, Evidence Based Med Students Sci Club, Coll Med, Bydgoszcz, Poland	Nicolaus Copernicus University; Nicolaus Copernicus University	Suwala, S (corresponding author), Nicolaus Copernicus Univ, Dept Endocrinol & Diabetol, Coll Medicum, 9 Sklodowskiej Curie St, PL-85094 Bydgoszcz, Poland.	lekarz.szymon.suwala@gmail.com		Kobus, Oliwia/0009-0000-8135-9055; Suwala, Szymon/0000-0002-5865-8484; Guzowski, Cezary/0000-0002-0022-9943				Ahmadi A., 2023, Asian J Comput Sci Technol, V12, P25; [Anonymous], 2023, Act on the profession of physician and dentist; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; D'Souza RF, 2023, ASIAN J PSYCHIATR, V89, DOI 10.1016/j.ajp.2023.103770; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Ethnologue, 2024, What are the top 200 most spoken languages?; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farhi F, 2023, Comput Educ Artif Intell, V5, DOI [10.1016/j.caeai.2023.100180, DOI 10.1016/J.CAEAI.2023.100180, 10.1016/J.CAEAI.2023.100180]; Gasiorowski J, 2015, ADV HEALTH SCI EDUC, V20, P709, DOI 10.1007/s10459-014-9560-2; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Johari J, 2011, PROCD SOC BEHV, V18, DOI 10.1016/j.sbspro.2011.05.011; Kung TH., 2023, PLOS Digital Health, V2; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; Long MT., 2016, PLoS One, V11; Meyer A, 2024, JMIR MED EDUC, V10, DOI 10.2196/50965; Panthier C, 2023, J FR OPHTALMOL, V46, P706, DOI 10.1016/j.jfo.2023.05.006; Rosol M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46995-z; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sedaghat S, 2024, J AM COLL RADIOL, V21, P344, DOI 10.1016/j.jacr.2023.10.019; Sedaghat S, 2023, ANN BIOMED ENG, V51, P2657, DOI 10.1007/s10439-023-03287-x; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Suwala S, 2023, POL ARCH INTERN MED, V133, DOI 10.20452/pamw.16608; Takagi S., 2023, JMIR Med Educ, V9; The Medical Examinations Center, 2023, Instruction for composing questions in examinations; The Medical Examinations Center, 2023, Information about polish medical final examination; The Medical Examinations Center, 2023, Thematic structure of the test-medical final examination; The Medical Examinations Center, 2023, Question database-medical final examination; Thirunavukarasu AJ., 2023, JMIR Med Educ, V9; Wang XY, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01961-0	35	0	0	0	0	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	2050-3121			SAGE OPEN MED	SAGE Open Med.		2024	12								20503121241257777	10.1177/20503121241257777	http://dx.doi.org/10.1177/20503121241257777			7	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	UW1L8	38895543	gold			2024-07-03	WOS:001251008000001
J	Trivedi, C; Bhattacharya, P; Prasad, VK; Patel, V; Singh, A; Tanwar, S; Sharma, R; Aluvala, S; Pau, G; Sharma, G				Trivedi, Chandan; Bhattacharya, Pronaya; Prasad, Vivek Kumar; Patel, Viraj; Singh, Arunendra; Tanwar, Sudeep; Sharma, Ravi; Aluvala, Srinivas; Pau, Giovanni; Sharma, Gulshan			Explainable AI for Industry 5.0: Vision, Architecture, and Potential Directions	IEEE OPEN JOURNAL OF INDUSTRY APPLICATIONS			English	Article						Fifth Industrial Revolution; Artificial intelligence; Surveys; Fourth Industrial Revolution; Data models; Predictive models; Industries; Automation; cobots; cyber-physical systems (CPSs); digital twins (DTs); explainable artificial intelligence (EXAI); Industry 5.0	ARTIFICIAL-INTELLIGENCE; MANAGEMENT; CLOUD; CHALLENGES; EDUCATION; BOX	The Industrial Revolution has shifted toward Industry 5.0, reinventing the Industry 4.0 operational process by introducing human elements into critical decision processes. Industry 5.0 would present massive customization via transformative technologies, such as cyber-physical systems (CPSs), artificial intelligence (AI), and big data analytics. In Industry 5.0, the AI models must be transparent, valid, and interpretable. AI models employ machine learning and deep learning mechanisms to make the industrial process autonomous, reduce downtime, and improve operational and maintenance costs. However, the models require explainability in the learning process. Thus, explainable AI (EXAI) adds interpretability and improves the diagnosis of critical industrial processes, which augments the machine-to-human explanations and vice versa. Recent surveys of EXAI in industrial applications are mostly oriented toward EXAI models, the underlying assumptions. Still, fewer studies are conducted toward a holistic integration of EXAI with human-centric processes that drives the Industry 5.0 applicative verticals. Thus, to address the gap, we propose a first-of-its-kind survey that systematically untangles EXAI integration and its potential in Industry 5.0 applications. First, we present the background of EXAI in Industry 5.0 and CPSs and a reference EXAI-based Industry 5.0 architecture with insights into large language models. Then, based on the research questions, a solution taxonomy of EXAI in Industry 5.0 is presented, which is ably supported by applicative use cases (cloud, digital twins, smart grids, augmented reality, and unmanned aerial vehicles). Finally, a case study of EXAI in manufacturing cost assessment is discussed, followed by open issues and future directions. The survey is designed to extend novel prototypes and designs to realize EXAI-based real-time Industry 5.0 applications.	[Trivedi, Chandan; Prasad, Vivek Kumar; Patel, Viraj; Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad 382481, India; [Bhattacharya, Pronaya] Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Kolkata 700135, India; [Bhattacharya, Pronaya] Amity Univ, Res & Innovat Cell, Kolkata 700135, India; [Singh, Arunendra] Pranveer Singh Inst Technol, Dept Informat Technol, Kanpur 209305, India; [Sharma, Ravi] Univ Petr & Energy Studies, Ctr Interdisciplinary Res & Innovat, Dehra Dun 248001, India; [Aluvala, Srinivas] SR Univ, Dept Comp Sci & Artificial Intelligence, Warangal 506371, India; [Pau, Giovanni] Kore Univ Enna, Fac Engn & Architecture, I-94100 Enna, Italy; [Sharma, Gulshan] Univ Johannesburg, Dept Elect Engn Technol, ZA-2006 Johannesburg, South Africa	Nirma University; University of Petroleum & Energy Studies (UPES); Universita Kore di ENNA; University of Johannesburg	Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad 382481, India.; Bhattacharya, P (corresponding author), Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Kolkata 700135, India.	chandan.trivedi@nirmauni.ac.in; pbhattacharya@kol.amity.edu; vivek.prasad@nirmauni.ac.in; 19bce201@nirmauni.ac.in; arunendra.singh@psit.ac.in; sudeep.tanwar@nirmauni.ac.in; ravisharmacidri@gmail.com; srinivas.aluvala@sru.edu.in; giovanni.pau@unikore.it; gulshans@uj.ac.za	Alvuala, Srinivas/AAH-4697-2020; Pau, Giovanni/ISU-8786-2023	Alvuala, Srinivas/0000-0002-9864-8184; Pau, Giovanni/0000-0002-5798-398X; Sharma, Dr. Gulshan/0000-0002-4726-0956	Kore University of Enna	Kore University of Enna	No Statement Available	Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Ahmed I, 2022, IEEE T IND INFORM, V18, P5031, DOI 10.1109/TII.2022.3146552; Ali N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1356-9; Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002; Alladi Tejasvi, 2020, Vehicular Communications, V23, DOI 10.1016/j.vehcom.2020.100249; Alufaisan Y, 2021, AAAI CONF ARTIF INTE, V35, P6618; [Anonymous], International Research Journal of Modernization in Engineering Technology and Science, V2023, DOI DOI 10.56726/IRJMETS32980; Askarzadeh A, 2016, IEEE SYS MAN CYBERN, P4626, DOI 10.1109/SMC.2016.7844961; Bao JS, 2019, ENTERP INF SYST-UK, V13, P534, DOI 10.1080/17517575.2018.1526324; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Behara RK, 2022, ENERGIES, V15, DOI 10.3390/en15197164; Bhattacharya Pronaya, 2022, Futuristic Trends in Networks and Computing Technologies: Select Proceedings of Fourth International Conference on FTNCT 2021. Lecture Notes in Electrical Engineering (936), P265, DOI 10.1007/978-981-19-5037-7_18; Bhattacharya Pronaya, 2023, Journal of Optical Communications, P155, DOI 10.1515/joc-2019-0023; Bhattacharya P., 2022, P INT C COMM COMP CY, P1; Bhattacharya P., 2023, P IEEE 15 INT C EL C, P1; Bhattacharya P, 2024, COMPUT STAND INTER, V88, DOI 10.1016/j.csi.2023.103785; Bhattacharya P, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11040941; Bhattacharya P, 2022, J PARALLEL DISTR COM, V168, P1, DOI 10.1016/j.jpdc.2022.05.008; Bhattacharya P, 2022, IEEE T COMPUT SOC SY, V9, P1758, DOI 10.1109/TCSS.2021.3131945; Bhattacharya P, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4410; Bhattarai P., 2022, Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries, P1, DOI DOI 10.1109/CITS55221.2022.9832978; Bhatttacharya P, 2022, 2022 2 INT C INN PRA, V2, P657, DOI [10.1109/ICIPTM54933.2022.9754198, DOI 10.1109/ICIPTM54933.2022.9754198]; Bhuvaneswari P, 2015, PROC MAT SCI, V10, P433, DOI 10.1016/j.mspro.2015.06.077; Binns R., 2018, P CHI C HUM FACT COM, P1; Calegari R, 2020, INTELL ARTIF, V14, P7, DOI 10.3233/IA-190036; Chang Y., 2023, J. ACM, V37, P1, DOI [10.48550/arXiv.2307.03109, DOI 10.48550/ARXIV.2307.03109]; Chaudhary Sachi, 2023, Proceedings of Fourth International Conference on Computing, Communications, and Cyber-Security: IC4S 2022. Lecture Notes in Networks and Systems (664), P857, DOI 10.1007/978-981-99-1479-1_63; Chengoden R, 2022, Arxiv, DOI [arXiv:2209.04160, 10.48550/arXiv.2209.04160]; Choi SH, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P472, DOI 10.1109/VRW55335.2022.00106; Choi TM, 2022, PROD OPER MANAG, V31, P9, DOI 10.1111/poms.13622; Chourasia S., 2023, Surface Engineering, P243; Clinciu M.-A., 2019, P 1 WORKSH INT NAT L, P8, DOI [DOI 10.18653/V1/W19-8403, 10.18653/v1/W19-8403]; Colgate J. E., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P433; Corchado JM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010236; Cyras K., 2021, P 30 INT JOINT C ART, P4392, DOI DOI 10.24963/IJCAI.2021/600; Dafflon B, 2021, INT J ADV MANUF TECH, V113, P2395, DOI 10.1007/s00170-020-06572-4; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; darpa, Explainable artificial intelligence for defense advanced research projects agency; Darwish T, 2021, IEEE WIREL COMMUN, V28, P96, DOI 10.1109/MWC.101.2000367; Defraeye T, 2019, RESOUR CONSERV RECY, V149, P778, DOI 10.1016/j.resconrec.2019.06.002; Dobrev D, 2012, Arxiv, DOI arXiv:1210.1568; Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040; Dutta Biswadeb, 2021, J. ICT Standardization, P147; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; El Houda ZA, 2022, C LOCAL COMPUT NETW, P149, DOI 10.1109/LCN53696.2022.9843645; Elton Daniel C., 2020, Artificial General Intelligence. 13th International Conference, AGI 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12177), P95, DOI 10.1007/978-3-030-52152-3_10; Estebsari A., 2022, Current State of Art in Artificial Intelligence and Ubiquitous Cities, P17; Evgeniou T., 2001, Machine learning and its applications. Advanced lectures, P249; Fashoto S. G., 2013, Aust. J. Basic Appl. Sci., V7, P140; Ferrara S, 2022, J EDUC MEAS, V59, P288, DOI 10.1111/jedm.12333; Fu YC, 2020, IEEE WIREL COMMUN, V27, P197, DOI 10.1109/MNET.001.1900310; Ge Y., 2023, P C COMP COMM WORKSH, P1, DOI DOI 10.1109/INFOCOMWKSHPS57453.2023.10225816; Greif T, 2020, COMPUT IND, V121, DOI 10.1016/j.compind.2020.103264; Griffor E., 2017, working group reports, special publication, V2, DOI [10.6028/NIST.SP.1500-202, DOI 10.6028/NIST.SP.1500-202]; Guembe B, 2022, EXPLAINABLE ARTIFICI; Guo WS, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149151; Guo WS, 2020, IEEE COMMUN MAG, V58, P39, DOI 10.1109/MCOM.001.2000050; Henriksen E., 2022, P INT C SMART EN SYS, P1; Holzinger Andreas, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P55, DOI 10.1109/DISA.2018.8490530; Hussain Bouk S, 2022, IEEE T INTELL TRANSP, V23, P22436, DOI 10.1109/TITS.2022.3212226; Islam SR, 2021, Arxiv, DOI arXiv:2101.09429; Ismail A, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-018-0162-3; Kabir M. H., 2022, Explainable Artificial Intelligence for Cyber Security: Next Generation Artificial Intelligence, P241; Kang JW, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2022), P71, DOI 10.1109/Blockchain55522.2022.00020; Kankanhalli A, 2019, GOV INFORM Q, V36, P304, DOI 10.1016/j.giq.2019.02.003; Kim B, 2018, PR MACH LEARN RES, V80; Kwok PK, 2021, INT J COMPUT INTEG M, V34, P874, DOI 10.1080/0951192X.2020.1803502; Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848; Li XH, 2022, IEEE T KNOWL DATA EN, V34, P29, DOI 10.1109/TKDE.2020.2983930; Lin Z, 2020, ENERGY, V201, DOI 10.1016/j.energy.2020.117693; Liyanage M, 2022, J NETW COMPUT APPL, V203, DOI 10.1016/j.jnca.2022.103362; Luckow A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3759, DOI 10.1109/BigData.2016.7841045; Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9; Machlev R, 2022, ENERGY AI, V9, DOI 10.1016/j.egyai.2022.100169; Maddikunta PKR, 2022, J NETW COMPUT APPL, V206, DOI 10.1016/j.jnca.2022.103464; Matzka S, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2020), P69, DOI 10.1109/AI4I49448.2020.00023; Mehta H., 2017, Int. J. Adv. Res. Comput. Sci., V8, P809; Minerva R, 2022, IEEE INTERNET COMPUT, V26, P61, DOI 10.1109/MIC.2021.3051674; Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166; Monteath I., 2018, P 2 WORKSH EXPL ART, P104; Morimoto T, 2022, J CLIN MED, V11, DOI 10.3390/jcm11020470; Mozo A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114106; Nahavandi S, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164371; Nascita A, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND RESILIENCE (IEEE CSR), P455, DOI 10.1109/CSR51186.2021.9527948; Nguyen VL, 2023, IEEE NETWORK, V37, P44, DOI 10.1109/MNET.010.2100509; Nillmani, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12092132; oecd, Germany's human-centred approach to AI is inclusive, evidence-based and capacity-building; Padhi PK, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4010011; Patel Zankhana, 2023, Smart Energy and Advancement in Power Technologies: Select Proceedings of ICSEAPT 2021. Lecture Notes in Electrical Engineering (927), P69, DOI 10.1007/978-981-19-4975-3_6; Peres RS, 2020, IEEE ACCESS, V8, P220121, DOI 10.1109/ACCESS.2020.3042874; Popovski P, 2018, IEEE ACCESS, V6, P55765, DOI 10.1109/ACCESS.2018.2872781; Prajapati Vishnu Kumar, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P222, DOI 10.1109/ICETCE48199.2020.9091743; Prasad V. K., 2020, Recent Patents Eng., V14, P530; Prasad VK, 2022, IEEE ACCESS, V10, P74131, DOI 10.1109/ACCESS.2022.3190497; Prasad VK, 2021, INT J E-HEALTH MED C, V12, P1, DOI 10.4018/IJEHMC.2021030101; Prasad VK, 2020, INT J E-HEALTH MED C, V11, P54, DOI 10.4018/IJEHMC.2020070104; Prasad VK, 2019, SCALABLE COMPUT-PRAC, V20, P365, DOI 10.12694/scpe.v20i2.1533; Prasad VK., 2021, Advance cloud data analytics for 5G enabled IoT, P159; Qayyum A, 2022, Arxiv, DOI arXiv:2210.13289; Radanliev P, 2021, AI SOC, V36, P783, DOI 10.1007/s00146-020-01049-0; Rader E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173677; Rojat T, 2021, Arxiv, DOI arXiv:2104.00950; Rozanec JM, 2022, INFORM FUSION, V81, P91, DOI 10.1016/j.inffus.2021.11.015; Sahakyan M, 2021, IEEE ACCESS, V9, P135392, DOI 10.1109/ACCESS.2021.3116481; Sahal R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155918; Samuel S., 2022, AUGMENTED INTELLIGEN, P433; Sanghvi J, 2021, INT WIREL COMMUN, P149, DOI 10.1109/IWCMC51323.2021.9498593; Saraswat Deepti, 2021, Proceedings of 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM), P417, DOI 10.1109/ICIEM51511.2021.9445353; Saraswat D, 2022, IEEE ACCESS, V10, P84486, DOI 10.1109/ACCESS.2022.3197671; Sarathy Nikhil, 2020, 2020 IEEE 18th International Symposium on Intelligent Systems and Informatics (SISY), P155, DOI 10.1109/SISY50555.2020.9217095; Senevirathna T, 2023, Arxiv, DOI arXiv:2204.12822; Shah Shail, 2022, 2022 5th International Conference on Contemporary Computing and Informatics (IC3I), P393, DOI 10.1109/IC3I56241.2022.10072544; Shrikumar A., 2016, Not just a black box: Learning important features through propagating activation differences, DOI DOI 10.48550/ARXIV.1605.01713; Shyamsukha S., 2021, P IEEE 13 INT C EL C, P1; Singh Arunendra, 2022, Journal of Optical Communications, V43, P339, DOI 10.1515/joc-2019-0008; Singh P, 2022, VEH COMMUN, V38, DOI 10.1016/j.vehcom.2022.100521; Stumpf S, 2009, INT J HUM-COMPUT ST, V67, P639, DOI 10.1016/j.ijhcs.2009.03.004; Sundararajan M, 2017, PR MACH LEARN RES, V70; SWARTOUT WR, 1983, ARTIF INTELL, V21, P285, DOI 10.1016/S0004-3702(83)80014-9; Tao JR, 2020, IEEE CONF COMPU INTE, P144, DOI 10.1109/CoG47356.2020.9231843; techport.nasa, Explainable artificial intelligence-based verification & validation for increasingly autonomous aviation systems, phase 2e; Terziyan V, 2022, PROCEDIA COMPUT SCI, V200, P216, DOI 10.1016/j.procs.2022.01.220; Timms MJ, 2016, INT J ARTIF INTELL E, V26, P701, DOI 10.1007/s40593-016-0095-y; Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314; Tremblay M., 2020, FORESIGHT, V58, P27; Trivedi C, 2023, SECUR PRIVACY, V6, DOI 10.1002/spy2.308; Trivedi C, 2023, J SUPERCOMPUT, V79, P12492, DOI 10.1007/s11227-023-05144-z; van der Waa J, 2021, ARTIF INTELL, V291, DOI 10.1016/j.artint.2020.103404; van Lent M, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P900; Vanany I, 2009, INT J INF SYST SUPPL, V2, P16, DOI 10.4018/jisscm.2009010102; Vassiliades A, 2021, KNOWL ENG REV, V36, DOI 10.1017/S0269888921000011; Vaswani A, 2017, ADV NEUR IN, V30; Velásquez N, 2018, J COMPUT SCI TECHNOL, V18, P258, DOI 10.24215/16666038.18.e29; Verma A, 2023, DIGIT COMMUN NETW, V9, P33, DOI 10.1016/j.dcan.2022.06.003; Verma A, 2022, IEEE ACCESS, V10, P69160, DOI 10.1109/ACCESS.2022.3186892; Vijayakumar P, 2022, SMART INNOV SYST TEC, V302, P307, DOI 10.1007/978-981-19-2541-2_24; Wang L., 2021, P WINT SIM C PHOEN A, P1; Wang S, 2023, Arxiv, DOI arXiv:2112.04698; Wang XX, 2023, IEEE-CAA J AUTOMATIC, V10, P1692, DOI 10.1109/JAS.2023.123753; Webb G.I., 2010, Encyclopedia of Machine Learning, P713, DOI [10.1007/978-0-387-30164-8_576, DOI 10.1007/978-0-387-30164-8_576, 10.1007/978-1-4899-7502-7_581-1, DOI 10.1007/978-1-4899-7502-7581-1]; Wisdom S, 2016, Arxiv, DOI arXiv:1611.07252; Wolf Christine T., 2020, ACM SIGACCESS Accessibility and Computing, DOI 10.1145/3386296.3386302; Wood-Doughty Z, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), P698, DOI 10.1109/ICMLA52953.2021.00117; Wu YL, 2022, IEEE NETWORK, V36, P16, DOI 10.1109/MNET.005.2100541; xai-project, Science and technology for the explanation of AI decision makingerc-2018-adg grant; Xiaodong Zhang, 2021, 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), P456, DOI 10.1109/DTPI52967.2021.9540104; Xu CC, 2022, ENERGIES, V15, DOI 10.3390/en15124427; Yang SY, 2020, INT CONF PERVAS COMP, DOI 10.1109/percomworkshops48775.2020.9156225; Yang ZB, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108192; Zheng X, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0309-3; Zhu YX, 2023, J PARALLEL DISTR COM, V173, P20, DOI 10.1016/j.jpdc.2022.10.009; Zuhair Mohd, 2021, Proceedings of 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM), P271, DOI 10.1109/ICIEM51511.2021.9445332; Zulfadhilah M, 2016, INT J ADV COMPUT SC, V7, P430	154	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		2644-1241		IEEE OPEN J IND APPL	IEEE Open J. Ind. Appl.		2024	5						177	208		10.1109/OJIA.2024.3399057	http://dx.doi.org/10.1109/OJIA.2024.3399057			32	Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Engineering	RS5B8		gold			2024-07-03	WOS:001229652800002
J	Afzal, M; Li, RYM; Shoaib, M; Ayyub, MF; Tagliabue, LC; Bilal, M; Ghafoor, H; Manta, O				Afzal, Muhammad; Li, Rita Yi Man; Shoaib, Muhammad; Ayyub, Muhammad Faisal; Tagliabue, Lavinia Chiara; Bilal, Muhammad; Ghafoor, Habiba; Manta, Otilia			Delving into the Digital Twin Developments and Applications in the Construction Industry: A PRISMA Approach	SUSTAINABILITY			English	Review						bi-directional interoperability; building information modelling; construction 4.0; digital transformation; digital twin; generative AI; PRISMA; sustainability	BIM; SIMULATION; MANAGEMENT; SYSTEMS; FUTURE; WORLD	Construction 4.0 is witnessing exponential growth in digital twin (DT) technology developments and applications, revolutionizing the adoption of building information modelling (BIM) and other emerging technologies used throughout the built environment lifecycle. BIM provides technologies, procedures, and data schemas representing building components and systems. At the same time, the DT enhances this with real-time data for integrating cyber-physical systems, enabling live asset monitoring and better decision making. Despite being in the early stages of development, DT applications have rapidly progressed in the AEC sector, resulting in a diverse literature landscape due to the various technologies and parameters involved in fully developing the DT technology. The intricate complexities inherent in digital twin advancements have confused professionals and researchers. This confusion arises from the nuanced distinctions between the two technologies, i.e., BIM and DT, causing a convergence that hinders realizing their potential. To address this confusion and lead to a swift development of DT technology, this study provides a holistic review of the existing research focusing on the critical components responsible for developing the applications of DT technology in the construction industry. It highlights five crucial elements: technologies, maturity levels, data layers, enablers, and functionalities. Additionally, it identifies research gaps and proposes future avenues for streamlined DT developments and applications in the AEC sector. Future researchers and practitioners can target data integrity, integration and transmission, bi-directional interoperability, non-technical factors, and data security to achieve mature digital twin applications for AEC practices. This study highlights the growing significance of DTs in construction and provides a foundation for further advancements in this field to harness its potential to transform built environment practices. It also pinpoints the latest developments in AI, namely the large language model (LLM) and retrieval-augmented generation (RAG)'s implications for DT education, policies, and the construction industry's practices.	[Afzal, Muhammad; Shoaib, Muhammad] Politecn Milan, Dept Architecture Built Environm & Construct Engn, I-20133 Milan, Italy; [Li, Rita Yi Man] Hong Kong Shue Yan Univ, Sustainable Real Estate Res Ctr, Dept Econ & Finance, Hong Kong 999077, Peoples R China; [Ayyub, Muhammad Faisal] Univ Bologna, Alma Mater Studiorum, Dept Civil Chem Environm & Mat Engn DICAM, I-40126 Bologna, Italy; [Tagliabue, Lavinia Chiara] Univ Turin, Dept Comp Sci, I-10149 Turin, Italy; [Bilal, Muhammad] Natl Univ Sci & Technol NUST, Dept Construct Engn & Management, Islamabad 44000, Pakistan; [Ghafoor, Habiba] Descon Engn Ltd, Kasur Rd Sufiabad, Lahore 54760, Pakistan; [Manta, Otilia] Romanian Acad, Ctr Financial & Monetary Res, Bucharest 050711, Romania; [Manta, Otilia] Romanian Amer Univ, Res Dept, Bucharest 012101, Romania	Polytechnic University of Milan; Hong Kong Shue Yan University; University of Bologna; University of Turin; National University of Sciences & Technology - Pakistan; Romanian Academy of Sciences	Afzal, M (corresponding author), Politecn Milan, Dept Architecture Built Environm & Construct Engn, I-20133 Milan, Italy.	muhammad.afzal@mail.polimi.it; ymli@hksyu.edu; muhammad1.shoaib@mail.polimi.it; mbilal.cem16nit@student.nust.edu.pk; otilia.manta@rgic.ro	MANTA, Otilia/O-1718-2016	MANTA, Otilia/0000-0002-9411-7925; Tagliabue, Lavinia Chiara/0000-0002-3059-4204; Afzal, Muhammad/0000-0002-0101-5509				Afzal M., 2019, Evaluation and Development of Automated Detailing Design Optimization Framework for RC Slabs Using BIM and Metaheuristics, P137; Afzal M., 2021, Master's Thesis; Afzal M, 2020, J CLEAN PROD, V260, DOI 10.1016/j.jclepro.2020.120623; Agrawal A, 2023, AUTOMAT CONSTR, V148, DOI 10.1016/j.autcon.2023.104749; Al-Ali AR, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12100163; Al-Saeed Y, 2020, CONSTR INNOV-ENGL, V20, P345, DOI 10.1108/CI-12-2019-0141; Al-Sehrawy R., 2020, Lect. Notes Civ. Eng., P924, DOI 10.1007/978-3-030-51295-8_64/FIGURES/3; Alizadehsalehi S, 2023, SMART SUSTAIN BUILT, V12, P200, DOI 10.1108/SASBE-01-2021-0016; Attaran M., 2023, Decis Anal J, V6, P100165, DOI DOI 10.1016/J.DAJOUR.2023.100165; Attaran Mohsen, 2023, Adv Comput Intell, V3, P11, DOI 10.1007/s43674-023-00058-y; Autiosalo J, 2020, IEEE ACCESS, V8, P1193, DOI 10.1109/ACCESS.2019.2950507; Bao JS, 2019, ENTERP INF SYST-UK, V13, P534, DOI 10.1080/17517575.2018.1526324; Batty M, 2018, ENVIRON PLAN B-URBAN, V45, P817, DOI 10.1177/2399808318796416; Baucas MJ, 2021, IEEE SIGNAL PROC MAG, V38, P65, DOI 10.1109/MSP.2021.3075929; Boje C, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103179; Boschert S., 2016, Mechatronic Futures: Challenges and Solutions for Mechatronic Systems and Their Designers, P59, DOI DOI 10.1007/978-3-319-32156-1_5; Botín-Sanabria DM, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061335; Bradley A, 2016, AUTOMAT CONSTR, V71, P139, DOI 10.1016/j.autcon.2016.08.019; Bryant R., 2021, Constr. Eng. Aust, V7, P46; Cheng JCP, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103087; Coupry C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156810; Daniotti B, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12020231; David A, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15129645; Davtalab O, 2017, COMPUTING IN CIVIL ENGINEERING 2017: INFORMATION MODELLING AND DATA ANALYTICS, P202; de Wilde P, 2023, ENERG BUILDINGS, V292, DOI 10.1016/j.enbuild.2023.113171; Delgado JMD, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101332; Demkovich Natalia, 2018, 2018 IEEE Industrial Cyber-Physical Systems (ICPS). Proceedings, P291, DOI 10.1109/ICPHYS.2018.8387674; Deng M, 2021, J INF TECHNOL CONSTR, V26, P58, DOI 10.36680/j.itcon.2021.005; Ding K, 2018, IEEE INT C NETW SENS; Doumbouya L., 2016, Am. J. Civ. Eng. Archit, V4, P74; Durdyev S, 2022, J BUILD ENG, V46, DOI 10.1016/j.jobe.2021.103736; European Commission European Construction Sector Observatory (ECSO), 2021, Digitalisation in the Construction Sector: Analytical Report; Fuller A, 2020, IEEE ACCESS, V8, P108952, DOI 10.1109/ACCESS.2020.2998358; Geng RX, 2022, STRUCT MULTIDISCIP O, V65, DOI 10.1007/s00158-022-03426-3; Glaessgen E., The Digital Twin Paradigm for Future NASA and U.S. Air Force Vehicles, DOI 10.2514/6.2012-1818; Grégorio JL, 2021, J MANUF SYST, V58, P108, DOI 10.1016/j.jmsy.2020.04.020; Grieves M., 2014, White Paper; Grieves M., 2016, Transdisciplinary perspectives on complex systems: new findings and approaches, P85, DOI 10.1007/978-3-319-38756-7_4; Grieves M. W., 2005, International Journal of Product Development, V2, P71, DOI 10.1504/IJPD.2005.006669; Guo JP, 2019, J AMB INTEL HUM COMP, V10, P1189, DOI 10.1007/s12652-018-0953-6; Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378; Hannele K, 2012, WORK, V41, P114, DOI 10.3233/WOR-2012-0144-114; Hochhalter J., 2014, Coupling Damage-Sensing Particles to the Digitial Twin Concept; Hosamo HH, 2022, ENERG BUILDINGS, V261, DOI 10.1016/j.enbuild.2022.111988; Hou L, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010339; Jiang F, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103838; Jiang WG, 2021, ENG CONSTR ARCHIT MA, V28, P788, DOI 10.1108/ECAM-10-2019-0578; Jiang YS, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104397; Jiang YS, 2022, COMPUT IND, V136, DOI 10.1016/j.compind.2021.103594; Julien N, 2021, IFAC PAPERSONLINE, V54, P894, DOI 10.1016/j.ifacol.2021.08.106; Kaewunruen S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12197873; Kaewunruen S, 2019, J CLEAN PROD, V228, P1537, DOI 10.1016/j.jclepro.2019.04.156; Kamari M, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104091; Khudhair A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031232; Kim C, 2013, AUTOMAT CONSTR, V35, P415, DOI 10.1016/j.autcon.2013.05.027; Kim K, 2022, AUTOMAT CONSTR, V138, DOI 10.1016/j.autcon.2022.104247; Kong TX, 2021, J MANUF SYST, V58, P323, DOI 10.1016/j.jmsy.2020.02.003; Kritzinger W, 2018, IFAC PAPERSONLINE, V51, P1016, DOI 10.1016/j.ifacol.2018.08.474; Kugley S., 2017, Campbell Systematic Reviews, V13, P1, DOI [DOI 10.4073/CMG.2016.1, https://doi.org/10.4073/cmg.2016.1]; Lee D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135909; Lee D, 2021, AUTOMAT CONSTR, V127, DOI 10.1016/j.autcon.2021.103688; Legner C, 2017, BUS INFORM SYST ENG+, V59, P301, DOI 10.1007/s12599-017-0484-2; Leygonie R, 2022, DEV BUILT ENVIRON, V11, DOI 10.1016/j.dibe.2022.100075; Li N, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.902576; Li R. Y. M., 2022, Current State of Art in ArtiCcial Intelligence and Ubiquitous Cities; Liang C.-J., 2020, P INT S AUT ROB CONS, P1480, DOI DOI 10.22260/ISARC2020/0205; Liu MN, 2021, J MANUF SYST, V58, P346, DOI 10.1016/j.jmsy.2020.06.017; Liu Q, 2019, AIP CONF PROC, V2073, DOI 10.1063/1.5090745; Liu Y., 2020, P 8 INT C CONSTRUCTI; Liu ZS, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14095179; Liu ZS, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13101927; Lu QC, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103277; Lu QC, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000763; Lu RD, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102837; Lv Z., 2022, Digit. Twin, V1, P12, DOI [10.12688/digitaltwin.17524.2, DOI 10.12688/DIGITALTWIN.17524.2]; Madni AM, 2019, SYSTEMS-BASEL, V7, DOI 10.3390/systems7010007; Mandolla C, 2019, COMPUT IND, V109, P134, DOI 10.1016/j.compind.2019.04.011; Martínez-Olvera C, 2022, AUTOMATION-BASEL, V3, P197, DOI 10.3390/automation3010010; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Mou X., 2022, Current State of Art in Artificial Intelligence and Ubiquitous Cities, P63; NASA, 2010, DRAFT Modeling, Simulation, Information Technology Processing Roadmap-Technology Area 11; Negri E, 2017, PROCEDIA MANUF, V11, P939, DOI 10.1016/j.promfg.2017.07.198; Omrany H, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151410908; Osadcha I, 2023, J BUILD ENG, V73, DOI 10.1016/j.jobe.2023.106704; Ozturk GB, 2021, J BUILD ENG, V40, DOI 10.1016/j.jobe.2021.102730; Pan Y, 2021, AUTOMAT CONSTR, V124, DOI 10.1016/j.autcon.2021.103564; Peng CH, 2016, J CLEAN PROD, V112, P453, DOI 10.1016/j.jclepro.2015.08.078; Peng Y, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/8846667; Pregnolato M, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104421; Qi QL, 2021, J MANUF SYST, V58, P3, DOI 10.1016/j.jmsy.2019.10.001; Qi QL, 2018, IEEE ACCESS, V6, P3585, DOI 10.1109/ACCESS.2018.2793265; Rosen R, 2015, IFAC PAPERSONLINE, V48, P567, DOI 10.1016/j.ifacol.2015.06.141; Sacks R., 2018, BIM handbook: A guide to building information modeling for owners, designers, engineers, contractors, and facility managers, DOI [DOI 10.1002/9781119287568, 10.1002/9781119287568]; Sacks R, 2020, DATA-CENTRIC ENG, V1, DOI 10.1017/dce.2020.16; Scharl S, 2019, INT J ENERG RES, V43, P3891, DOI 10.1002/er.4462; Schluse M, 2016, 2016 IEEE INTERNATIONAL SYMPOSIUM ON SYSTEMS ENGINEERING (ISSE), P273; Schroeder GN, 2016, IFAC PAPERSONLINE, V49, P12, DOI 10.1016/j.ifacol.2016.11.115; Shafto M, 2012, Natl Astronaut Space Adm., V32, P1; Shahinmoghadam M, 2021, BUILD ENVIRON, V199, DOI 10.1016/j.buildenv.2021.107905; Shahzad M, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12020120; Shirowzhan S, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9040240; Shu ZG, 2016, MOBILE NETW APPL, V21, P865, DOI 10.1007/s11036-015-0664-6; Siriwardhana S, 2023, T ASSOC COMPUT LING, V11, P1, DOI 10.1162/tacl_a_00530; Song HH, 2023, AUTOMAT CONSTR, V147, DOI 10.1016/j.autcon.2022.104736; Spudys P, 2023, ENERG BUILDINGS, V290, DOI 10.1016/j.enbuild.2023.113106; Stark R, 2017, CIRP ANN-MANUF TECHN, V66, P169, DOI 10.1016/j.cirp.2017.04.045; Sun H, 2022, ADV CIV ENG, V2022, DOI 10.1155/2022/8273451; Tagliabue LC, 2021, ENERG BUILDINGS, V236, DOI 10.1016/j.enbuild.2021.110782; Tan Y, 2022, ENERG BUILDINGS, V270, DOI 10.1016/j.enbuild.2022.112271; Tao F, 2019, ENGINEERING-PRC, V5, P653, DOI 10.1016/j.eng.2019.01.014; Tao F, 2019, INT J PROD RES, V57, P3935, DOI 10.1080/00207543.2018.1443229; Tao Fei, 2019, Computer Integrated Manufacturing Systems, V25, P1, DOI 10.13196/j.cims.2019.01.001; Tao Fei, 2018, Computer Integrated Manufacturing Systems, V24, P1, DOI 10.13196/j.cims.2018.01.001; Tao F, 2018, INT J ADV MANUF TECH, V94, P3563, DOI 10.1007/s00170-017-0233-1; Tao F, 2017, IEEE ACCESS, V5, P20418, DOI 10.1109/ACCESS.2017.2756069; Teisserenc B, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11120626; Tuhaise VV, 2023, AUTOMAT CONSTR, V152, DOI 10.1016/j.autcon.2023.104931; Tuteja N., 2023, Online: AWS Machine Learning Blog; Uddin SMJ, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097121; Ullah AMMS, 2019, ADV ENG INFORM, V39, P1, DOI 10.1016/j.aei.2018.11.003; Wang WX, 2022, J IND INF INTEGR, V28, DOI 10.1016/j.jii.2022.100351; Wang X., 2020, P 37 ISARC KIT JAP O, P1528, DOI [DOI 10.22260/ISARC2020/0212, 10.22260/ISARC2020/0212]; Weyer S, 2016, IFAC PAPERSONLINE, V49, P97, DOI 10.1016/j.ifacol.2016.12.168; White G, 2021, CITIES, V110, DOI 10.1016/j.cities.2020.103064; Wu YJ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13101882; Xie X, 2020, IFAC PAPERSONLINE, V53, P380, DOI 10.1016/j.ifacol.2020.11.061; Yitmen I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094276; Yuan X., 2020, Cyber-Physical Systems in the Built Environment, P107, DOI [DOI 10.1007/978-3-030-41560-0_7, 10.1007/978-3-030-41560-0_7]; Zhao JF, 2022, J BUILD ENG, V49, DOI 10.1016/j.jobe.2022.104028; Zhao L, 2021, ADV CIV ENG, V2021, DOI 10.1155/2021/6638897; Zhong D, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14534; Zhuang CB, 2018, INT J ADV MANUF TECH, V96, P1149, DOI 10.1007/s00170-018-1617-6; Zhuang D, 2021, AUTOMAT CONSTR, V127, DOI 10.1016/j.autcon.2021.103712	133	3	3	46	55	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2071-1050		SUSTAINABILITY-BASEL	Sustainability	DEC	2023	15	23							16436	10.3390/su152316436	http://dx.doi.org/10.3390/su152316436			37	Green & Sustainable Science & Technology; Environmental Sciences; Environmental Studies	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Science & Technology - Other Topics; Environmental Sciences & Ecology	AD8D9		Green Submitted, gold			2024-07-03	WOS:001116607000001
J	Roberts, RH; Ali, SR; Hutchings, HA; Dobbs, TD; Whitaker, IS				Roberts, Richard H. R.; Ali, Stephen R.; Hutchings, Hayley A.; Dobbs, Thomas D.; Whitaker, Iain S.			Comparative study of ChatGPT and human evaluators on the assessment of medical literature according to recognised reporting standards	BMJ HEALTH & CARE INFORMATICS			English	Article						Artificial intelligence; Medical Informatics		Introduction Amid clinicians' challenges in staying updated with medical research, artificial intelligence (AI) tools like the large language model (LLM) ChatGPT could automate appraisal of research quality, saving time and reducing bias. This study compares the proficiency of ChatGPT3 against human evaluation in scoring abstracts to determine its potential as a tool for evidence synthesis.Methods We compared ChatGPT's scoring of implant dentistry abstracts with human evaluators using the Consolidated Standards of Reporting Trials for Abstracts reporting standards checklist, yielding an overall compliance score (OCS). Bland-Altman analysis assessed agreement between human and AI-generated OCS percentages. Additional error analysis included mean difference of OCS subscores, Welch's t-test and Pearson's correlation coefficient.Results Bland-Altman analysis showed a mean difference of 4.92% (95% CI 0.62%, 0.37%) in OCS between human evaluation and ChatGPT. Error analysis displayed small mean differences in most domains, with the highest in 'conclusion' (0.764 (95% CI 0.186, 0.280)) and the lowest in 'blinding' (0.034 (95% CI 0.818, 0.895)). The strongest correlations between were in 'harms' (r=0.32, p<0.001) and 'trial registration' (r=0.34, p=0.002), whereas the weakest were in 'intervention' (r=0.02, p<0.001) and 'objective' (r=0.06, p<0.001).Conclusion LLMs like ChatGPT can help automate appraisal of medical literature, aiding in the identification of accurately reported research. Possible applications of ChatGPT include integration within medical databases for abstract evaluation. Current limitations include the token limit, restricting its usage to abstracts. As AI technology advances, future versions like GPT4 could offer more reliable, comprehensive evaluations, enhancing the identification of high-quality research and potentially improving patient outcomes.	[Roberts, Richard H. R.; Ali, Stephen R.; Dobbs, Thomas D.; Whitaker, Iain S.] Swansea Univ, Reconstruct Surg & Regenerat Med Res Ctr, Swansea, Wales; [Roberts, Richard H. R.; Hutchings, Hayley A.] Swansea Univ, Swansea Univ Med Sch, Swansea, Wales; [Roberts, Richard H. R.; Ali, Stephen R.; Dobbs, Thomas D.; Whitaker, Iain S.] Morriston Hosp, Welsh Ctr Burns & Plast Surg, Swansea, Wales	Swansea University; Swansea University; Morriston Hospital	Roberts, RH (corresponding author), Swansea Univ, Reconstruct Surg & Regenerat Med Res Ctr, Swansea, Wales.; Roberts, RH (corresponding author), Swansea Univ, Swansea Univ Med Sch, Swansea, Wales.; Roberts, RH (corresponding author), Morriston Hosp, Welsh Ctr Burns & Plast Surg, Swansea, Wales.	838272@swansea.ac.uk	Hutchings, Hayley A/C-9944-2013	Roberts, Richard Henry Randall/0000-0002-9600-5943	Swansea University; Welsh Clinical Academic Training Fellowship; British Association of Plastic, Reconstructive and Aesthetic Surgeons	Swansea University; Welsh Clinical Academic Training Fellowship; British Association of Plastic, Reconstructive and Aesthetic Surgeons	The research conducted herein was funded by Swansea University. SRA and TDD are funded by the Welsh Clinical Academic Training Fellowship (no award number). SRA received a Paton Masser grant from the British Association of Plastic, Reconstructive and Aesthetic Surgeons to support this work (no award number). ISW is the surgical specialty lead for Health and Care Research Wales and the chief investigator for the Scar Free Foundation & Health and Care Research Wales Programme of Reconstructive and Regenerative Surgery Research (no award number). The Scar Free Foundation is the only medical research charity focused on scarring with the mission to achieve scar-free healing within a generation. ISW is an associate editor for the Annals of Plastic Surgery, editorial board member of BMC Medicine and takes numerous other editorial board roles.	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; He N, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231181922; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Menne MC, 2022, J PERIODONTOL, V93, P73, DOI 10.1002/JPER.21-0396; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Sanmarchi F, 2023, medRxiv, DOI [10.1101/2023.02.06.23285514, 10.1101/2023.02.06.23285514, DOI 10.1101/2023.02.06.23285514]; Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.1136/bmj.c332, 10.1016/j.jclinepi.2010.02.005, 10.1136/bmj.c869, 10.4103/0976-500X.72352, 10.1186/1741-7015-8-18, 10.1016/j.ijsu.2011.09.004]; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Zuccon G, 2023, Arxiv, DOI [arXiv:2302.13793, DOI 10.48550/ARXIV.2302.13793]	10	0	0	5	9	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND		2632-1009		BMJ HEALTH CARE INFO	BMJ Health Care Inform.	OCT	2023	30	1							e100830	10.1136/bmjhci-2023-100830	http://dx.doi.org/10.1136/bmjhci-2023-100830			5	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	U5KR3	37827724	Green Published, gold			2024-07-03	WOS:001085193700002
J	Elmarakeby, HA; Trukhanov, PS; Arroyo, VM; Riaz, IB; Schrag, D; Van Allen, EM; Kehl, KL				Elmarakeby, Haitham A.; Trukhanov, Pavel S.; Arroyo, Vidal M.; Riaz, Irbaz Bin; Schrag, Deborah; Van Allen, Eliezer M.; Kehl, Kenneth L.			Empirical evaluation of language modeling to ascertain cancer outcomes from clinical text reports	BMC BIOINFORMATICS			English	Article						Cancer; Natural language processing; Clinical outcomes; Information extraction; Transformer-based language models		BackgroundLongitudinal data on key cancer outcomes for clinical research, such as response to treatment and disease progression, are not captured in standard cancer registry reporting. Manual extraction of such outcomes from unstructured electronic health records is a slow, resource-intensive process. Natural language processing (NLP) methods can accelerate outcome annotation, but they require substantial labeled data. Transfer learning based on language modeling, particularly using the Transformer architecture, has achieved improvements in NLP performance. However, there has been no systematic evaluation of NLP model training strategies on the extraction of cancer outcomes from unstructured text.ResultsWe evaluated the performance of nine NLP models at the two tasks of identifying cancer response and cancer progression within imaging reports at a single academic center among patients with non-small cell lung cancer. We trained the classification models under different conditions, including training sample size, classification architecture, and language model pre-training. The training involved a labeled dataset of 14,218 imaging reports for 1112 patients with lung cancer. A subset of models was based on a pre-trained language model, DFCI-ImagingBERT, created by further pre-training a BERT-based model using an unlabeled dataset of 662,579 reports from 27,483 patients with cancer from our center. A classifier based on our DFCI-ImagingBERT, trained on more than 200 patients, achieved the best results in most experiments; however, these results were marginally better than simpler "bag of words" or convolutional neural network models.ConclusionWhen developing AI models to extract outcomes from imaging reports for clinical cancer research, if computational resources are plentiful but labeled training data are limited, large language models can be used for zero- or few-shot learning to achieve reasonable performance. When computational resources are more limited but labeled training data are readily available, even simple machine learning architectures can achieve good performance for such tasks.	[Elmarakeby, Haitham A.; Trukhanov, Pavel S.; Riaz, Irbaz Bin; Van Allen, Eliezer M.; Kehl, Kenneth L.] Dana Farber Canc Inst, Boston, MA 02215 USA; [Elmarakeby, Haitham A.] Al Azhar Univ, Cairo, Egypt; [Elmarakeby, Haitham A.; Riaz, Irbaz Bin; Van Allen, Eliezer M.; Kehl, Kenneth L.] Harvard Med Sch, Boston, MA 02115 USA; [Elmarakeby, Haitham A.; Van Allen, Eliezer M.] Broad Inst MIT & Harvard, Cambridge, MA 02142 USA; [Arroyo, Vidal M.] Stanford Univ, Stanford, CA USA; [Riaz, Irbaz Bin] Mayo Clin, Rochester, MN USA; [Schrag, Deborah] Mem Sloan Kettering Canc Ctr, New York, NY USA	Harvard University; Dana-Farber Cancer Institute; Egyptian Knowledge Bank (EKB); Al Azhar University; Harvard University; Harvard Medical School; Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute; Stanford University; Mayo Clinic; Memorial Sloan Kettering Cancer Center	Elmarakeby, HA (corresponding author), Dana Farber Canc Inst, Boston, MA 02215 USA.; Elmarakeby, HA (corresponding author), Al Azhar Univ, Cairo, Egypt.; Elmarakeby, HA (corresponding author), Harvard Med Sch, Boston, MA 02115 USA.; Elmarakeby, HA (corresponding author), Broad Inst MIT & Harvard, Cambridge, MA 02142 USA.	haithama_elmarakeby@dfci.harvard.edu		Arroyo, Vidal/0000-0003-4880-8124	Not applicable.	Not applicable.	Not applicable.	Abadi M., 2015, arXiv, DOI DOI 10.48550/ARXIV.1603.04467; André F, 2017, CANCER DISCOV, V7, P818, DOI 10.1158/2159-8290.CD-17-0151; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Chaudhari GR, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210185; Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Garraway LA, 2013, J CLIN ONCOL, V31, P1803, DOI 10.1200/JCO.2013.49.4799; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Huang K, 2020, Clinicalbert: Modeling clinical notes and predicting hospital readmission; Huang XS, 2020, PR MACH LEARN RES, V119; Gutiérrez BJ, 2022, Arxiv, DOI arXiv:2203.08410; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kehl KL, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27358-6; Kehl KL, 2020, JCO CLIN CANCER INFO, V4, P680, DOI 10.1200/CCI.20.00020; Kehl KL, 2019, JAMA ONCOL, V5, P1421, DOI 10.1001/jamaoncol.2019.1800; Kim Y, 2014, Arxiv, DOI [arXiv:1408.5882, 10.48550/arXiv.1408.5882]; Kitaev N., 2020, arXiv; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lehman E, 2023, Arxiv, DOI [arXiv:2302.08091, 10.48550/arXiv.2302.08091, DOI 10.48550/ARXIV.2302.08091]; Lehman E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P946; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lu Q, 2022, Findings of the Association for Computational Linguistics: EMNLP 2022, P5436, DOI DOI 10.18653/V1/2022.FINDINGS-EMNLP; Dai AM, 2015, Arxiv, DOI arXiv:1511.01432; Nakamura Y, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01623-6; Olthof AW, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01761-4; Olthof AW, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106304; Paszke A, 2019, ADV NEUR IN, V32; Phan LN, 2021, Arxiv, DOI arXiv:2106.03598; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sanh V, 2022, arXiv; Sholl LM, 2016, JCI INSIGHT, V1, DOI 10.1172/jci.insight.87062; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	40	1	1	2	5	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	SEP 2	2023	24	1							328	10.1186/s12859-023-05439-1	http://dx.doi.org/10.1186/s12859-023-05439-1			15	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Q6QD6	37658330	gold, Green Published			2024-07-03	WOS:001058741800001
J	Guo, K; Wang, DL				Guo, Kai; Wang, Deliang			To resist it or to embrace it? Examining ChatGPT's potential to support teacher feedback in EFL writing	EDUCATION AND INFORMATION TECHNOLOGIES			English	Article						EFL writing; Automated writing evaluation; Teacher feedback; ChatGPT; Human-machine collaboration	AUTOMATED ESSAY EVALUATION; CORRECTIVE FEEDBACK; STUDENTS; PEER; QUALITY	ChatGPT, the newest pre-trained large language model, has recently attracted unprecedented worldwide attention. Its exceptional performance in understanding human language and completing a variety of tasks in a conversational way has led to heated discussions about its implications for and use in education. This exploratory study represents one of the first attempts to examine the possible role of ChatGPT in facilitating the teaching and learning of writing English as a Foreign Language (EFL). We examined ChatGPT's potential to support EFL teachers' feedback on students' writing. To reach this goal, we first investigated ChatGPT's performance in generating feedback on EFL students' argumentative writing. Fifty English argumentative essays composed by Chinese undergraduate students were collected and used as feedback targets. ChatGPT and five Chinese EFL teachers offered feedback on the content, organisation, and language aspects of the essays. We compared ChatGPT- and teacher-generated feedback in terms of their amount and type. The results showed that ChatGPT produced a significantly larger amount of feedback than teachers and that compared with teacher feedback, which mainly focused on content-related and language-related issues, ChatGPT distributed its attention relatively equally among the three feedback foci (i.e., content, organisation, and language). Our results also indicated that ChatGPT and teachers displayed tendencies towards using different feedback types when evaluating different aspects of students' writing. Additionally, we examined EFL teachers' perceptions of using ChatGPT-generated feedback to support their own feedback. The five teachers reported both positive and negative perceptions of the features of ChatGPT feedback and the relation between ChatGPT and teacher feedback. To foster EFL students' writing skills, we suggest that teachers collaborate with ChatGPT in generating feedback on student writing.	[Guo, Kai; Wang, Deliang] Univ Hong Kong, Fac Educ, Hong Kong, Peoples R China	University of Hong Kong	Wang, DL (corresponding author), Univ Hong Kong, Fac Educ, Hong Kong, Peoples R China.	kaiguo@connect.hku.hk; wdeliang@connect.hku.hk	Guo, Kai/AAD-2448-2022	Guo, Kai/0000-0001-9699-7527; Wang, Deliang/0009-0008-6488-0234				Alshuraidah A, 2019, ELT J, V73, P166, DOI 10.1093/elt/ccy057; Bai LF, 2017, EDUC PSYCHOL-UK, V37, P67, DOI 10.1080/01443410.2016.1223275; Biber D., 2011, The effectiveness of feedback for L1-English and L2 writing development: A meta-analysis; Bitchener J, 2005, J SECOND LANG WRIT, V14, P191, DOI 10.1016/j.jslw.2005.08.001; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burstein F, 2004, AI MAG, V25, P27; Cho K, 2006, WRIT COMMUN, V23, P260, DOI 10.1177/0741088306289261; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duijnhouwer H, 2010, EDUC RES EVAL, V16, P53, DOI 10.1080/13803611003711393; Ferris DR, 1997, TESOL QUART, V31, P315, DOI 10.2307/3588049; Foltz P.W., 2013, Handbook of automated essay evaluation, P68, DOI [10.4324/9780203122761.ch5, DOI 10.4324/9780203122761.CH5, DOI 10.4324/9780203122761]; Fu QK, 2024, COMPUT ASSIST LANG L, V37, P179, DOI 10.1080/09588221.2022.2033787; García-Peñalvo FJ, 2023, EDUC KNOWL SOC, V24, DOI 10.14201/eks.31279; Geng J., 2020, Universal Journal of Educational Research, V8, P8334, DOI [10.13189/ujer.2020.082638, DOI 10.13189/UJER.2020.082638]; Gilson A., 2022, MEDRXIV, DOI [10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; Grimes D., 2010, The Journal of Technology, Learning, and Assessment, V8; Guo K, 2022, RELC J, DOI 10.1177/00336882221143192; Hearst MA, 2000, IEEE INTELL SYST APP, V15, P22, DOI 10.1109/5254.889104; Hyland K., 1990, ELT J, V44, P294, DOI [10.1093/elt/44.4.279, DOI 10.1093/ELT/44.4.279]; Kellogg RT, 2010, J EDUC COMPUT RES, V42, P173, DOI [10.2190/EC.42.2.c, 10.2190/EC.42.2.C]; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Koltovskaia S, 2020, ASSESS WRIT, V44, DOI 10.1016/j.asw.2020.100450; Lee I, 2014, ASSESS WRIT, V19, P1, DOI 10.1016/j.asw.2013.11.009; Li JR, 2015, J SECOND LANG WRIT, V27, P1, DOI 10.1016/j.jslw.2014.10.004; Link S, 2022, COMPUT ASSIST LANG L, V35, P605, DOI 10.1080/09588221.2020.1743323; McMartin-Miller C, 2014, ASSESS WRIT, V19, P24, DOI 10.1016/j.asw.2013.11.003; Medenilla A., 2023, PLoS Digital Health, V2; Miao Y, 2006, J SECOND LANG WRIT, V15, P179, DOI 10.1016/j.jslw.2006.09.004; Nelson MM, 2009, INSTR SCI, V37, P375, DOI 10.1007/s11251-008-9053-x; NEUWIRTH CM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P51, DOI 10.1145/191666.191693; Ouyang L., 2022, CORR; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Peterson S.S., 2004, Assessing Writing, V9, P160, DOI [10.1016/j.asw.2004.07.002, DOI 10.1016/J.ASW.2004.07.002]; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ranalli J, 2018, COMPUT ASSIST LANG L, V31, P653, DOI 10.1080/09588221.2018.1428994; Reynolds L., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2102.07350; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Schulman J, 2022, Introducing chatgpt; Shermis MarkD., 2013, HDB AUTOMATED ESSAY; Stevenson Marie, 2016, Computers and Composition, V42, P1, DOI 10.1016/j.compcom.2016.05.001; Stevenson M, 2014, ASSESS WRIT, V19, P51, DOI 10.1016/j.asw.2013.11.007; Stiennon N., 2020, arXiv; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; TAYLOR WF, 1966, J EDUC RES, V60, P80, DOI 10.1080/00220671.1966.10883440; Wambsganss T, 2022, COMPUT EDUC, V191, DOI 10.1016/j.compedu.2022.104644; Wang EL, 2020, ASSESS WRIT, V44, DOI 10.1016/j.asw.2020.100449; Warschauer M, 2008, PEDAGOGIES, V3, P22, DOI 10.1080/15544800701771580; Wilson J, 2021, COMPUT EDUC, V168, DOI 10.1016/j.compedu.2021.104208; Wilson J, 2016, COMPUT EDUC, V100, P94, DOI 10.1016/j.compedu.2016.05.004; Yau C., 2023, S CHINA MORNING POST; Zhai X., 2022, CHATGPT US EXP IMPL; Zhu MX, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103668	56	15	15	296	552	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1360-2357	1573-7608		EDUC INF TECHNOL	Educ. Inf. Technol.	MAY	2024	29	7					8435	8463		10.1007/s10639-023-12146-0	http://dx.doi.org/10.1007/s10639-023-12146-0		AUG 2023	29	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	QP8U6					2024-07-03	WOS:001060545900006
J	Dorbala, VS; Mullen, JF; Manocha, D				Dorbala, Vishnu Sashank; Mullen, James F.; Manocha, Dinesh			<i>Can an Embodied Agent Find Your "Cat-shaped Mug"?</i> LLM-Based Zero-Shot Object Navigation	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						AI-enabled robotics; autonomous agents; domestic robotics; human-centered robotics		We present language-guided exploration (LGX), a novel algorithm for Language-Driven Zero-Shot Object Goal Navigation (L-ZSON), where an embodied agent navigates to an uniquely described target object in a previously unseen environment. Our approach makes use of large language models (LLMs) for this task by leveraging the LLM's commonsense-reasoning capabilities for making sequential navigational decisions. Simultaneously, we perform generalized target object detection using a pre-trained Vision-Language grounding model. We achieve state-of-the-art zero-shot object navigation results on RoboTHOR with a success rate (SR) improvement of over 27% over the current baseline of the OWL-ViT CLIP on Wheels (OWL CoW). Furthermore, we study the usage of LLMs for robot navigation and present an analysis of various prompting strategies affecting the model output. Finally, we showcase the benefits of our approach via real-world experiments that indicate the superior performance of LGX in detecting and navigating to visually unique objects.	[Dorbala, Vishnu Sashank; Mullen, James F.; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Dorbala, VS (corresponding author), Univ Maryland, College Pk, MD 20742 USA.	vdorbala@umd.edu; mullenj@umd.edu; dmanocha@umd.edu		Manocha, Dinesh/0000-0001-7047-9801; Mullen, James/0000-0002-4117-1741	National Science Foundation Graduate Research Fellowship	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF))	No Statement Available	Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Anderson P, 2018, Arxiv, DOI [arXiv:1807.06757, DOI 10.48550/ARXIV.1807.06757]; Bangalath H., 2022, Advances in Neural Information Processing Systems, V35, P33781; Batra D, 2020, Arxiv, DOI arXiv:2006.13171; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chaplot D. P., 2020, Advances in Neural Information Processing Systems, P4247; Chen SZ, 2022, PROC CVPR IEEE, P16516, DOI 10.1109/CVPR52688.2022.01604; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Deitke M, 2020, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR42600.2020.00323; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding Y, 2023, Arxiv, DOI arXiv:2305.17590; Dorbala V. S., 2022, PROC WORKSHOP LANG R; Dorbala VS, 2021, IEEE INT CONF ROBOT, P3538, DOI 10.1109/ICRA48506.2021.9561983; Gadre SY, 2023, PROC CVPR IEEE, P23171, DOI 10.1109/CVPR52729.2023.02219; Gao XF, 2022, IEEE ROBOT AUTOM LET, V7, P10049, DOI 10.1109/LRA.2022.3193254; Hatori J, 2018, IEEE INT CONF ROBOT, P3774; Hu Z, 2019, IEEE ROBOT AUTOM LET, V4, P753, DOI 10.1109/LRA.2019.2893432; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Huang WL, 2022, PR MACH LEARN RES; Kollar T, 2010, ACMIEEE INT CONF HUM, P259, DOI 10.1109/HRI.2010.5453186; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831; Li J., 2022, International Conference on Machine Learning, V162, P12888, DOI DOI 10.48550/ARXIV.2201.12086; Li Liunian Harold, 2022, P IEEE CVF C COMP VI, P10965, DOI DOI 10.1109/CVPR52688.2022.01069; Majumdar A., 2022, Advances in Neural Information Processing Systems, V35, P32340; Min SY, 2023, Arxiv, DOI arXiv:2212.05923; Minderer M, 2022, LECT NOTES COMPUT SC, V13670, P728, DOI 10.1007/978-3-031-20080-9_42; Mokady A., 2021, arXiv; Park JS, 2019, IEEE INT CONF ROBOT, P6964, DOI [10.1109/ICRA.2019.8794394, 10.1109/icra.2019.8794394]; Quigley M., 2009, ICRA WORKSHOP OPEN S, V3, P5, DOI DOI 10.1109/IECON.2015.7392843; Radford A, 2021, PR MACH LEARN RES, V139; Ramakrishnan SK, 2022, PROC CVPR IEEE, P18868, DOI 10.1109/CVPR52688.2022.01832; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Tellex S., 2011, AAAI, V25; Thomason J., 2020, P C ROBOT LEARNING C, P394; Thomason J, 2019, IEEE INT CONF ROBOT, P6934, DOI 10.1109/icra.2019.8794287; Wu Y., 2019, Detectron 2; Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA '97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851; Gadre SY, 2022, Arxiv, DOI arXiv:2203.10421; Zhao ZR, 2023, Arxiv, DOI arXiv:2305.14078; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	43	1	1	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	MAY	2024	9	5					4083	4090		10.1109/LRA.2023.3346800	http://dx.doi.org/10.1109/LRA.2023.3346800			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	LU7C9					2024-07-03	WOS:001189370400013
J	Kovács, B				Kovacs, Balazs			The Turing test of online reviews: Can we tell the difference between human-written and GPT-4-written online reviews?	MARKETING LETTERS			English	Article; Early Access						Online reviews; Generative AI; GPT-4; Turing test	WORD-OF-MOUTH; MARKETPLACES; REPUTATION; SALES; FAKE	Online reviews serve as a guide for consumer choice. With advancements in large language models (LLMs) and generative AI, the fast and inexpensive creation of human-like text may threaten the feedback function of online reviews if neither readers nor platforms can differentiate between human-written and AI-generated content. In two experiments, we found that humans cannot recognize AI-written reviews. Even with monetary incentives for accuracy, both Type I and Type II errors were common: human reviews were often mistaken for AI-generated reviews, and even more frequently, AI-generated reviews were mistaken for human reviews. This held true across various ratings, emotional tones, review lengths, and participants' genders, education levels, and AI expertise. Younger participants were somewhat better at distinguishing between human and AI reviews. An additional study revealed that current AI detectors were also fooled by AI-generated reviews. We discuss the implications of our findings on trust erosion, manipulation, regulation, consumer behavior, AI detection, market structure, innovation, and review platforms.	[Kovacs, Balazs] Yale Univ, 165 Whitney Ave, New Haven, CT 06520 USA	Yale University	Kovács, B (corresponding author), Yale Univ, 165 Whitney Ave, New Haven, CT 06520 USA.	Balazs.kovacs@yale.edu						Agnihotri A, 2016, PSYCHOL MARKET, V33, P1006, DOI 10.1002/mar.20934; Ahmad W, 2018, INT J HOSP MANAG, V71, P77, DOI 10.1016/j.ijhm.2017.12.005; Ananthakrishnan UM, 2020, INFORM SYST RES, V31, P950, DOI 10.1287/isre.2020.0925; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Archak N, 2011, MANAGE SCI, V57, P1485, DOI 10.1287/mnsc.1110.1370; Brandl R., 2023, Survey: ChatGPT and AI Content Can people tell the difference? tooltester.com; Cheung CMK, 2012, DECIS SUPPORT SYST, V53, P218, DOI 10.1016/j.dss.2012.01.015; Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345; Dellarocas C, 2003, MANAGE SCI, V49, P1407, DOI 10.1287/mnsc.49.10.1407.17308; Dellarocas C, 2007, J INTERACT MARK, V21, P23, DOI 10.1002/dir.20087; Han J., 2022, Data mining: concepts and techniques; He S, 2022, MARKET SCI, V41, P896, DOI 10.1287/mksc.2022.1353; Ippolito D, 2020, Arxiv, DOI arXiv:1911.00650; Jago AS, 2019, ACAD MANAG DISCOV, V5, P38, DOI 10.5465/amd.2017.0002; Jakesch M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208839120; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Kovács B, 2023, ACAD MANAG DISCOV, V9, P549, DOI 10.5465/amd.2022.0025; Kovács B, 2024, SOCIUS, V10, DOI 10.1177/23780231241228917; Kovács B, 2014, ORGAN SCI, V25, P458, DOI 10.1287/orsc.2013.0843; Kozinets RV, 2002, J MARKETING RES, V39, P61, DOI 10.1509/jmkr.39.1.61.18935; Laudon K.C., 2004, MANAGEMENT INFORM SY; Le Mens G, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2309350120; Li XX, 2008, INFORM SYST RES, V19, P456, DOI 10.1287/isre.1070.0154; Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304; Mayzlin D, 2014, AM ECON REV, V104, P2421, DOI 10.1257/aer.104.8.2421; Miller EJ, 2023, PSYCHOL SCI, V34, P1390, DOI 10.1177/09567976231207095; Mudambi SM, 2010, MIS QUART, V34, P185; Netzer O, 2012, MARKET SCI, V31, P521, DOI 10.1287/mksc.1120.0713; Orenstrakh MS, 2023, Arxiv, DOI arXiv:2307.07411; Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015; Pavlou PA, 2006, INFORM SYST RES, V17, P392, DOI 10.1287/isre.1060.0106; Pentina Iryna., 2018, Journal of Marketing Communications, V24, P125, DOI [10.1080/13527266.2015.1005115, DOI 10.1080/13527266.2015.1005115]; Sharkey A, 2023, ACAD MANAG ANN, V17, P1, DOI 10.5465/annals.2021.0025; Tadelis S, 2016, ANNU REV ECON, V8, P321, DOI 10.1146/annurev-economics-080315-015325; Uchendu A., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2109.13296, 10.48550/arXiv.2109.13296]; Wu YY, 2020, DECIS SUPPORT SYST, V132, DOI 10.1016/j.dss.2020.113280; Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907; Zhang T, 2017, INT J PROD ECON, V184, P69, DOI 10.1016/j.ijpe.2016.10.017; Zhao Y, 2013, MARKET SCI, V32, P153, DOI 10.1287/mksc.1120.0755	39	1	1	66	66	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0923-0645	1573-059X		MARKET LETT	Mark. Lett.	2024 APR 12	2024										10.1007/s11002-024-09729-3	http://dx.doi.org/10.1007/s11002-024-09729-3		APR 2024	16	Business	Social Science Citation Index (SSCI)	Business & Economics	NN9E5					2024-07-03	WOS:001201239200001
J	Gao, ZX; Li, LY; Ma, SY; Wang, QY; Hemphill, L; Xu, R				Gao, Zhenxiang; Li, Lingyao; Ma, Siyuan; Wang, Qinyong; Hemphill, Libby; Xu, Rong			Examining the Potential of ChatGPT on Biomedical Information Retrieval: Fact-Checking Drug-Disease Associations	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter; Early Access						Biomedical information retrieval; Drug-disease associations; Generative AI; ChatGPT; Performance evaluation; Prompt design		Large language models (LLMs) such as ChatGPT have recently attracted significant attention due to their impressive performance on many real-world tasks. These models have also demonstrated the potential in facilitating various biomedical tasks. However, little is known of their potential in biomedical information retrieval, especially identifying drug-disease associations. This study aims to explore the potential of ChatGPT, a popular LLM, in discerning drug-disease associations. We collected 2694 true drug-disease associations and 5662 false drug-disease pairs. Our approach involved creating various prompts to instruct ChatGPT in identifying these associations. Under varying prompt designs, ChatGPT's capability to identify drug-disease associations with an accuracy of 74.6-83.5% and 96.2-97.6% for the true and false pairs, respectively. This study shows that ChatGPT has the potential in identifying drug-disease associations and may serve as a helpful tool in searching pharmacy-related information. However, the accuracy of its insights warrants comprehensive examination before its implementation in medical practice.	[Gao, Zhenxiang; Wang, Qinyong; Xu, Rong] Case Western Reserve Univ, Ctr Artificial Intelligence Drug Discovery, Sch Med, Cleveland Hts, OH 44106 USA; [Li, Lingyao; Hemphill, Libby] Univ Michigan, Sch Informat, Ann Arbor, MI USA; [Ma, Siyuan] Vanderbilt Univ Sch Med, Nashville, TN USA	University System of Ohio; Case Western Reserve University; University of Michigan System; University of Michigan; Vanderbilt University	Xu, R (corresponding author), Case Western Reserve Univ, Ctr Artificial Intelligence Drug Discovery, Sch Med, Cleveland Hts, OH 44106 USA.	rxx@case.edu	Ma, Siyuan/IVV-8174-2023		National Institute on Alcohol Abuse and Alcoholism [AA029831]; National Institute on Aging [AG057557, AG061388, AG062272, AG07664]; National Eye Institute [EY029297]; National Institute on Drug Abuse [UG1DA049435, CTN-0114]	National Institute on Alcohol Abuse and Alcoholism(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Alcohol Abuse & Alcoholism (NIAAA)); National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); National Eye Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); National Institute on Drug Abuse(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA))	Funding was provided by National Institute on Alcohol Abuse and Alcoholism (AA029831), National Institute on Aging (AG057557, AG061388, AG062272, AG07664), National Eye Institute (EY029297), and National Institute on Drug Abuse (UG1DA049435, CTN-0114).	[Anonymous], 2023, What is ChatGPT?|OpenAI Help Center; Avram S, 2021, NUCLEIC ACIDS RES, V49, pD1160, DOI 10.1093/nar/gkaa997; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brinkmann A, 2023, Arxiv, DOI [arXiv:2306.14921, 10.48550/arXiv.2306.14921, DOI 10.48550/ARXIV.2306.14921]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Drees J., 2019, Becker's Hospital Review; Dudley JT, 2011, BRIEF BIOINFORM, V12, P303, DOI 10.1093/bib/bbr013; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Google AI, 2023, Google AI PaLM 2; Gu Y, 2023, Arxiv, DOI arXiv:2307.06439; Han RD, 2023, Arxiv, DOI arXiv:2305.14450; Jahan I, 2023, Arxiv, DOI [arXiv:2306.04504, 10.48550/ARXIV.2306.04504, DOI 10.48550/ARXIV.2306.04504]; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Li B, 2023, Arxiv, DOI arXiv:2304.11633; Li LY, 2023, Arxiv, DOI [arXiv:2304.10619, 10.48550/ARXIV.2304.10619]; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Meta A.I., Introducing LLaMA: a foundational, 65-billion-parameter large language model; Miao Hongyu, 2023, Asian Pac Isl Nurs J, V7, pe48136, DOI 10.2196/48136; OpenAI, 2023, Models; Saravia E., Prompt Engineering Guide; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang QY, 2023, Arxiv, DOI arXiv:2307.01137; Wang QuanQiu, 2018, AMIA Annu Symp Proc, V2018, P1300; Wang QuanQiu, 2017, AMIA Annu Symp Proc, V2017, P1724; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Xu R, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-181; Xu RY, 2023, Arxiv, DOI arXiv:2307.01135; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zuccon G, 2023, Arxiv, DOI [arXiv:2302.13793, DOI 10.48550/ARXIV.2302.13793]	39	0	0	13	31	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	2023 OCT 19	2023										10.1007/s10439-023-03385-w	http://dx.doi.org/10.1007/s10439-023-03385-w		OCT 2023	9	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	W1WM7	37855948				2024-07-03	WOS:001089606500001
C	Chen, BY; Xia, F; Ichter, B; Rao, K; Gopalakrishnan, K; Ryoo, MS; Stone, A; Kappler, D			IEEE	Chen, Boyuan; Xia, Fei; Ichter, Brian; Rao, Kanishka; Gopalakrishnan, Keerthana; Ryoo, Michael S.; Stone, Austin; Kappler, Daniel			Open-vocabulary Queryable Scene Representations for Real World Planning	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc				Large language models (LLMs) have unlocked new capabilities of task planning from human instructions. However, prior attempts to apply LLMs to real-world robotic tasks are limited by the lack of grounding in the surrounding scene. In this paper, we develop NLMap, an open-vocabulary and queryable scene representation to address this problem. NLMap serves as a framework to gather and integrate contextual information into LLM planners, allowing them to see and query available objects in the scene before generating a context-conditioned plan. NLMap first establishes a natural language queryable scene representation with Visual Language models (VLMs). An LLM based object proposal module parses instructions and proposes involved objects to query the scene representation for object availability and location. An LLM planner then plans with such information about the scene. NLMap allows robots to operate without a fixed list of objects nor executable options, enabling real robot operation unachievable by previous methods. Project website: https://nlmap-saycan.github.io	[Chen, Boyuan; Kappler, Daniel] Everyday Robots, San Francisco, CA 94107 USA; [Xia, Fei; Ichter, Brian; Rao, Kanishka; Gopalakrishnan, Keerthana; Ryoo, Michael S.; Stone, Austin] Google, Robot, Mountain View, CA USA; [Chen, Boyuan] MIT, Cambridge, MA 02139 USA	Google Incorporated; Massachusetts Institute of Technology (MIT)	Chen, BY (corresponding author), Everyday Robots, San Francisco, CA 94107 USA.; Chen, BY (corresponding author), MIT, Cambridge, MA 02139 USA.	boyuanc@mit.edu; xiafei@google.com	Chen, Bo Yuan/B-7817-2018	Chen, Bo Yuan/0000-0003-1336-2812				Ahn M., 2022, arXiv preprint arXiv:2204.01691; Anderson, 2018, ARXIV180706757; Armeni I., 2019, P IEEE CVF INT C COM; Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203; Chaplot D. S., 2020, IEEE C COMP VIS PATT, P12875; Chaplot D.S., 2020, P INT C LEARN REPR; Chaplot D. S., 2020, Neural Information Processing Systems (NeurIPS); Chen K., 2021, P IEEE CVF C COMP VI; Chen Tao, 2019, ICLR; Chowdhery A., 2022, ARXIV220402311; Civera J., 2011, 2011 IEEE RSJ INT C; Fang K., 2019, CVPR 2019; Gadre S. Y., 2022, ARXIV220310421; Garrett C. R., ALGORITHMIC FDN ROBO, VXI; Garrett C. R., 2020, P INT C AUTOMATED PL, V30, P440; Gu Xiuye, 2021, ARXIV210413921; Huang Chenguang, 2022, ARXIV221005714; Huang W., 2022, ARXIV220107207; Huang Wenlong, 2022, ARXIV220705608; Keswani M, 2022, PROC CVPR IEEE, P10223, DOI 10.1109/CVPR52688.2022.00999; Majumdar A., 2022, ARXIV220612403; McCormac J., 2018, 2018 INT C 3D VIS 3D; Mousavian A, 2019, IEEE INT CONF ROBOT, P8846, DOI 10.1109/icra.2019.8793493; Qi C.R., 2020, P IEEE CVF C COMP VI; Radford A, 2021, PR MACH LEARN RES, V139; Runz M., 2018, 2018 IEEE INT S MIX; Santos-Victor J., 1995, P INT C INT AUT SYST; Seiwald P, 2021, IEEE-RAS INT C HUMAN, P9, DOI 10.1109/HUMANOIDS47582.2021.9555790; Shah D., 2022, ARXIV220704429; Talukder A., 2003, P 2003 IEEE RSJ INT; Wahid A., 2020, CORR; Xia F., 2019, ARXIV190300445; Xia F, 2018, PROC CVPR IEEE, P9068, DOI 10.1109/CVPR.2018.00945; Xu DX, 2018, SACMAT'18: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON ACCESS CONTROL MODELS & TECHNOLOGIES, P3, DOI 10.1145/3205977.3205979; Yamauchi B., 1998, P 5 INT C AUT AG; Zeng Andy, 2022, ARXIV220400598; Zhang LY, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2810810; Zhu Y., 2021, 2021 IEEE INT C ROB	38	3	3	3	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							11509	11522		10.1109/ICRA48891.2023.10161534	http://dx.doi.org/10.1109/ICRA48891.2023.10161534			14	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371103089
C	Gehring, J			IEEE	Gehring, Justine			Deterministic Automatic Refactoring at Scale	2023 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE AND EVOLUTION, ICSME	Proceedings-IEEE International Conference on Software Maintenance		English	Proceedings Paper	39th IEEE International Conference on Software Maintenance and Evolution (ICSME)	OCT 01-06, 2023	Univ Andes, Bogota, COLOMBIA	IEEE, IEEE Comp Soc Tech Community Software Engn, IEEE Tech Council Software Engn, Fundac GCF Aprende Libre	Univ Andes	Automatic code refactoring; AST; LST; JUnit; Vulnerabilities; Code Migration; Static Code Analysis; Generative AI		In the context of continually growing large code repositories where code refactoring is an ongoing requirement, we highlight the effectiveness of OpenRewrite as a tool for conducting large-scale code refactoring. OpenRewrite leverages Lossless Semantic Trees (LST) to represent code and applies recipes to search and implement changes. These recipes are openly available and can be executed locally or accessed through the Moderne platform for public repositories. We provide a concise overview of the underlying technology, instructions for utilizing the tool, and we compare its performance against a manual approach and two prominent large language models (LLM): ChatGPT and StarChat-beta. Our comparison is based on the execution time of the tool and the accuracy of the implemented changes. Additionally, we present three distinct use cases that demonstrate the versatile applications of the tool. A demonstration of OpenRewrite's recipe which detects vulnerabilities and automatically fixes them is available at the following link: https://www.youtube.com/watch?v=L1-_cQUX-JA.	[Gehring, Justine] Moderne, Noida, India		Gehring, J (corresponding author), Moderne, Noida, India.	justine@moderne.io						app.moderne.io, About us; chat.openai, ChatGPT; docs.sonarsource, SonarQube 10.1; Grams C., 2019, How Much Time Do Developers Spend Actually Writing Code?; huggingface, HuggingFaceH4/starchat-beta Hugging Face; javaparser, JavaParser-Home; Kashyap N., 2020, GitHub's Path to 128M Public Repositories; mend.io/, Mend.io (formerly WhiteSource) | Improving AppSec Outcomes; nvd.nist, NVD-NVD Dashboard; octoverse.github, GitHub State of the Octoverse: 2016; OpenAI Help Center, What is ChatGPT?; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pawlak R, 2016, SOFTWARE PRACT EXPER, V46, P1155, DOI 10.1002/spe.2346; platform.openai, OpenAI platform; Saeed L., 2022, Pro Cloud Native Java EE Apps: DevOps with MicroProfile, Jakarta EE 10 APIs, and Kubernetes, P25, DOI [10.1007/978-1-4842-8900-6, DOI 10.1007/978-1-4842-8900-6]; snyk, Snyk | Developer security | Develop fast. Stay secure; sonarsource.atlassian, RSPEC-4524] "default"clauses should be first or last-Jira; Tsantalis N, 2022, IEEE T SOFTWARE ENG, V48, P930, DOI 10.1109/TSE.2020.3007722; ttpsc, About us; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922	20	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6773		979-8-3503-2783-0	PROC IEEE INT CONF S			2023							541	546		10.1109/ICSME58846.2023.00069	http://dx.doi.org/10.1109/ICSME58846.2023.00069			6	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2UF					2024-07-03	WOS:001125977500057
J	Miah, MSU; Kabir, MM; Bin Sarwar, T; Safran, M; Alfarhood, S; Mridha, MF				Miah, Md Saef Ullah; Kabir, Md Mohsin; Bin Sarwar, Talha; Safran, Mejdl; Alfarhood, Sultan; Mridha, M. F.			A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM	SCIENTIFIC REPORTS			English	Article						Cross-lingual communication; Sentiment analysis; Neural machine translation; Pretrained sentiment analyzer model; Ensemble with LLM		Sentiment analysis is an essential task in natural language processing that involves identifying a text's polarity, whether it expresses positive, negative, or neutral sentiments. With the growth of social media and the Internet, sentiment analysis has become increasingly important in various fields, such as marketing, politics, and customer service. However, sentiment analysis becomes challenging when dealing with foreign languages, particularly without labelled data for training models. In this study, we propose an ensemble model of transformers and a large language model (LLM) that leverages sentiment analysis of foreign languages by translating them into a base language, English. We used four languages, Arabic, Chinese, French, and Italian, and translated them using two neural machine translation models: LibreTranslate and Google Translate. Sentences were then analyzed for sentiment using an ensemble of pre-trained sentiment analysis models: Twitter-Roberta-Base-Sentiment-Latest, bert-base-multilingual-uncased-sentiment, and GPT-3, which is an LLM from OpenAI. Our experimental results showed that the accuracy of sentiment analysis on translated sentences was over 86% using the proposed model, indicating that foreign language sentiment analysis is possible through translation to English, and the proposed ensemble model works better than the independent pre-trained models and LLM.	[Miah, Md Saef Ullah; Bin Sarwar, Talha; Mridha, M. F.] Amer Int Univ Bangladesh, Dept Comp Sci, Dhaka 1229, Bangladesh; [Kabir, Md Mohsin] Eotvos Lorand Univ, Fac Informat, H-1117 Budapest, Hungary; [Safran, Mejdl] King Saud Univ, Coll Comp & Informat Sci, Res Chair Online Dialogue & Cultural Commun, Dept Comp Sci, Riyadh 11543, Saudi Arabia; [Alfarhood, Sultan] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 51178, Riyadh 11543, Saudi Arabia	American International University Bangladesh (AIUB); Eotvos Lorand University; King Saud University; King Saud University	Mridha, MF (corresponding author), Amer Int Univ Bangladesh, Dept Comp Sci, Dhaka 1229, Bangladesh.; Safran, M (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Res Chair Online Dialogue & Cultural Commun, Dept Comp Sci, Riyadh 11543, Saudi Arabia.	mejdl@ksu.edu.sa; firoz.mridha@aiub.edu		Miah, M. Saef Ullah/0000-0003-4587-4636; Sarwar, Talha Bin/0000-0001-5974-1282	King Saud University, Saudi Arabia; Research Chair of Online Dialogue and Cultural Communication at King Saud University, Riyadh, Saudi Arabia	King Saud University, Saudi Arabia(King Saud University); Research Chair of Online Dialogue and Cultural Communication at King Saud University, Riyadh, Saudi Arabia	The authors thank the Research Chair of Online Dialogue and Cultural Communication at King Saud University, Riyadh, Saudi Arabia, for funding this research.	Alshaabi T, 2021, EPJ DATA SCI, V10, DOI 10.1140/epjds/s13688-021-00271-0; [Anonymous], 2023, Semiocast-Top languages on Twitter-stats-Semiocast; [Anonymous], 2023, Hugging Face; Barbieri F, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P258; Barriere V, 2020, Arxiv, DOI arXiv:2010.03486; Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1; Chan JYL, 2023, ARTIF INTELL REV, V56, P749, DOI 10.1007/s10462-022-10183-8; Daems J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01282; Das R, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3586075; Demirtas E., 2013, Cross-Lingual Sentiment Analysis with Machine Translation; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dewaele JM, 2008, LANG LEARN, V58, P911, DOI 10.1111/j.1467-9922.2008.00482.x; Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025; GoimilVilacoba V., 2014, James Joyce in translation: Colloquialisms, vulgarisms and idiomatic and cultural expressions in the Spanish and Galician versions of 'Ulysses'; google, Google Translate; Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420; Kashgary A D., 2011, Journal of King Saud University-Languages and Translation, V23, P47, DOI DOI 10.1016/J.JKSULT.2010.03.001; Keung P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4563; Khanuja S, 2020, Arxiv, DOI arXiv:2004.12376; Klubicka F, 2018, MACH TRANSL, V32, P195, DOI 10.1007/s10590-018-9214-x; Li D., 2019, 5 INT C ARTS DESIGN, P271; Libre Translate, 2021, Libre translate API; Lingua, 2022, The 20 most spoken languages in the world in 2022; Loureiro D., 2022, arXiv; Mercha E, 2023, NEUROCOMPUTING, V531, P195, DOI 10.1016/j.neucom.2023.02.015; Mohammad S. M., 2021, Emotion measurement, P323, DOI [10.1016/B978-0-12-821124-3.00011-9, DOI 10.1016/B978-0-12-821124-3.00011-9]; Mohammad SM, 2016, J ARTIF INTELL RES, V55, P95, DOI 10.1613/jair.4787; nlptown, Hugging Face; Novielli N., 2021, SENTIPOLC 2016 dataset, DOI [10.57771/N279-Q780, DOI 10.57771/N279-Q780]; Oueslati O, 2020, FUTURE GENER COMP SY, V112, P408, DOI 10.1016/j.future.2020.05.034; Radford A., 2020, Adv. Neural Inf. Process. Syst., V33; Rehan M, 2023, IEEE ACCESS, V11, P106503, DOI 10.1109/ACCESS.2023.3320062; Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x; Rosenthal S., 2017, P 11 INT WORKSHOP SE, P502; Salameh M., 2015, P N AM CHAPTER ASS C, P767, DOI 10.3115/v1/N15-1078; Sarker Iqbal H, 2021, SN Comput Sci, V2, P160, DOI 10.1007/s42979-021-00592-x; Schmidt S, 2023, INFORMATION, V14, DOI 10.3390/info14020071; Singh M, 2021, ARCH COMPUT METHOD E, V28, P2165, DOI 10.1007/s11831-020-09449-7; Uddin MA, 2024, Arxiv, DOI arXiv:2402.13871; Vanroy B., 2021, Syntactic difficulties in translation; Vinayakumar R., 2017, Defi Fouille de Textes; Wahidur RSM, 2024, IEEE ACCESS, V12, P10146, DOI 10.1109/ACCESS.2024.3350638; Wiriyathammabhum P., 2023, arXiv; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xing F, 2024, Arxiv, DOI arXiv:2401.05799; Xu SC, 2024, Arxiv, DOI arXiv:2402.11398; Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5; Zhang C., 2017, MACHINE TRANSLATION	48	0	0	17	17	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 26	2024	14	1							9603	10.1038/s41598-024-60210-7	http://dx.doi.org/10.1038/s41598-024-60210-7			18	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	OZ1Y0	38671064				2024-07-03	WOS:001211019400071
J	Dang, TH; Vu, TA				Dang, Thanh Hai; Vu, Tien Anh			xCAPT5: protein-protein interaction prediction using deep and wide multi-kernel pooling convolutional neural networks with protein language model	BMC BIOINFORMATICS			English	Article						Protein-protein interactions; Convolutional neural networks; Protein language models		BackgroundPredicting protein-protein interactions (PPIs) from sequence data is a key challenge in computational biology. While various computational methods have been proposed, the utilization of sequence embeddings from protein language models, which contain diverse information, including structural, evolutionary, and functional aspects, has not been fully exploited. Additionally, there is a significant need for a comprehensive neural network capable of efficiently extracting these multifaceted representations.ResultsAddressing this gap, we propose xCAPT5, a novel hybrid classifier that uniquely leverages the T5-XL-UniRef50 protein large language model for generating rich amino acid embeddings from protein sequences. The core of xCAPT5 is a multi-kernel deep convolutional siamese neural network, which effectively captures intricate interaction features at both micro and macro levels, integrated with the XGBoost algorithm, enhancing PPIs classification performance. By concatenating max and average pooling features in a depth-wise manner, xCAPT5 effectively learns crucial features with low computational cost.ConclusionThis study represents one of the initial efforts to extract informative amino acid embeddings from a large protein language model using a deep and wide convolutional network. Experimental results show that xCAPT5 outperforms recent state-of-the-art methods in binary PPI prediction, excelling in cross-validation on several benchmark datasets and demonstrating robust generalization across intra-species, cross-species, inter-species, and stringent similarity contexts.	[Dang, Thanh Hai] VNU Univ Engn & Technol, Fac Informat Technol, 144 Xuan Thuy, Hanoi 10000, Vietnam; [Vu, Tien Anh] VNU Univ Sci, Fac Biol, 334 Nguyen Trai, Hanoi 10000, Vietnam	Vietnam National University Hanoi; Vietnam National University Hanoi	Dang, TH (corresponding author), VNU Univ Engn & Technol, Fac Informat Technol, 144 Xuan Thuy, Hanoi 10000, Vietnam.	hai.dang@vnu.edu.vn			National Foundation for Science and Technology Development	National Foundation for Science and Technology Development	We would like to thank Miss Mai-Anh Hang Vo at VNU University of Science for her contributions to scientific illustration.	Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Chen C, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103899; Chen MH, 2019, BIOINFORMATICS, V35, pI305, DOI 10.1093/bioinformatics/btz328; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Elnaggar A., 2021, arXiv; Gao HL, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106471; Guo YZ, 2008, NUCLEIC ACIDS RES, V36, P3025, DOI 10.1093/nar/gkn159; Hashemifar S, 2018, BIOINFORMATICS, V34, P802, DOI 10.1093/bioinformatics/bty573; Hu XT, 2022, BIOINFORMATICS, V38, P694, DOI 10.1093/bioinformatics/btab737; Reddi SJ, 2019, Arxiv, DOI arXiv:1904.09237; Jha K, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31612-w; Kingma D. P., 2017, ARXIV; Li H, 2018, MOLECULES, V23, DOI 10.3390/molecules23081923; Li X, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbac524; Mahapatra S, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab255; Martin S, 2005, BIOINFORMATICS, V21, P218, DOI 10.1093/bioinformatics/bth483; Min S, 2021, IEEE ACCESS, V9, P123912, DOI 10.1109/ACCESS.2021.3110269; Pan XY, 2010, J PROTEOME RES, V9, P4992, DOI 10.1021/pr100618t; Ramachandran P, 2017, Arxiv, DOI [arXiv:1710.05941, DOI 10.48550/ARXIV.1710.05941]; Singh R, 2022, BIOINFORMATICS, V38, P264, DOI 10.1093/bioinformatics/btac258; Sledzieski S, 2021, CELL SYST, V12, P969, DOI 10.1016/j.cels.2021.08.010; Song BS, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab558; WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28; Xie S., 2023, Brief Bioinform, Vbbad2261, P61; Yang XD, 2021, BIOINFORMATICS, V37, P4771, DOI 10.1093/bioinformatics/btab533; Yu B, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114876	27	0	0	5	5	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 10	2024	25	1							106	10.1186/s12859-024-05725-6	http://dx.doi.org/10.1186/s12859-024-05725-6			20	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	KQ0G2	38461247	Green Published, gold, Green Submitted			2024-07-03	WOS:001181308400001
C	Kejriwal, M			IEEE	Kejriwal, Mayank			Designing Social Good Semantic Computing Architectures for the Long Tail: Case Studies, Evaluation, and Challenges	18TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC 2024	IEEE International Conference on Semantic Computing		English	Proceedings Paper	18th IEEE International Conference on Semantic Computing (ICSC)	FEB 05-07, 2024	Laguna Hills, CA	IEEE, IEEE Comp Soc		Long tail; social good; crisis response; human trafficking		Many real-world systems, especially systems characterized by high social activity (such as the Web), tend to obey power law distributions and thereby have a significant 'long tail'. We argue that researching, developing and designing semantic computing systems for the long tail, especially dependent on inductive AI, constitutes an important class of problems, not least because the long tail is challenging both technically and socially. By its very nature, the long tail is irregular, testing the generalization capabilities of the state-of-the-art, especially in architectures and interfaces that are built on some form of machine learning or statistical inference (including large language models). As machine learning and generative AI continues to be integrated into more front facing systems, the issue of the long tail cannot be ignored by either the systems engineering or the AI communities. We present two case studies with important social consequences (fighting human trafficking online, and managing information effectively and in real-time during humanitarian crises) where semantic computing and AI platforms specifically designed to handle long-tail challenges find critical application, and sometimes with drastically different design choices compared to designing only for the short tail (with the main goal of maximizing average accuracy).	[Kejriwal, Mayank] Univ Southern Calif, Informat Sci Inst, Los Angeles, CA 90089 USA	University of Southern California	Kejriwal, M (corresponding author), Univ Southern Calif, Informat Sci Inst, Los Angeles, CA 90089 USA.	kejriwal@isi.edu			Defense Advanced Research Projects Agency (DARPA) MEMEX program; Defense Advanced Research Projects Agency (DARPA) LORELEI program	Defense Advanced Research Projects Agency (DARPA) MEMEX program(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Defense Advanced Research Projects Agency (DARPA) LORELEI program(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	The research presented in this paper was funded by various sources over 2016-2020, most notably through the Defense Advanced Research Projects Agency (DARPA) MEMEX and LORELEI programs. Also acknowledged is the aid of partner collaborators and users in providing detailed analysis, where applicable. The views and conclusions contained herein are those of the author, and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, AFRL, or the US Government.	[Anonymous], 2018, P AAAI C ARTIFICIAL, V32; Belle V, 2022, FRONT ARTIF INTEL AP, V342, P78, DOI [10.3233/FAIA210350, 10.3233/FAIA210363]; Boghosian BM, 2014, PHYS REV E, V89, DOI 10.1103/PhysRevE.89.042804; Chaudhuri S, 2011, COMMUN ACM, V54, P88, DOI 10.1145/1978542.1978562; Cho MLK, 2021, NAT MED, V27, P2079, DOI 10.1038/s41591-021-01577-2; Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111; Diamond ESA, 2007, IEEE INTL CONF IND I, P317; Gu Y, 2018, Arxiv, DOI arXiv:1801.05906; Huang QY, 2015, ISPRS INT J GEO-INF, V4, P1549, DOI 10.3390/ijgi4031549; Hundman K, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P137, DOI 10.1145/3278721.3278782; Kejriwal M., 2019, Domainspecific Knowledge Graph Construction, DOI DOI 10.1007/978-3-030-12375-8; Kejriwal M., 2018, 2018 CHI C HUMAN FAC, DOI [10.1145/3170427, DOI 10.1145/3170427]; Kejriwal M., 2023, Artificial Intelligence for Industries of the Future-Beyond Facebook, Amazon, Microsoft and Google, DOI DOI 10.1007/978-3-031-19039-1; Kejriwal M., 2017, Proceedings, Part II, ser. Lecture Notes in Computer Science; Kejriwal M., 2018, Proceedings, Part I, ser. Lecture Notes in Computer Science; Kejriwal M, 2021, SOFTW IMPACTS, V7, DOI 10.1016/j.simpa.2020.100052; Kejriwal M, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.779792; Kejriwal M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P147, DOI 10.1145/3184558.3186965; Kejriwal M, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P705, DOI 10.1145/3341161.3343703; Kejriwal M, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0154-z; Kejriwal M, 2022, IEEE T BIG DATA, V8, P592, DOI 10.1109/TBDATA.2017.2763164; Kejriwal M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11030059; Kejriwal M, 2018, IEEE INTELL SYST, V33, P53, DOI 10.1109/MIS.2018.111144556; Kenthapadi K, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P5805, DOI 10.1145/3580305.3599557; Pagan N, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27089-8; Szekely P, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P433, DOI 10.1145/3184558.3185983	26	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2325-6516		979-8-3503-8535-9	IEEE INT C SEMANT CO			2024							253	260		10.1109/ICSC59802.2024.00047	http://dx.doi.org/10.1109/ICSC59802.2024.00047			8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7TH					2024-07-03	WOS:001196221400041
C	Phung, T; Padurean, VA; Singh, A; Brooks, C; Cambronero, J; Gulwani, S			Assoc Computing Machinery	Phung, Tung; Padurean, Victor-Alexandru; Singh, Anjali; Brooks, Christopher; Cambronero, Jose; Gulwani, Sumit			Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation	FOURTEENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, LAK 2024			English	Proceedings Paper	14th Annual International Conference on Learning Analytics and Knowledge (LAK) - Learning Analytics in the Age of Artificial Intelligence	MAR 18-22, 2024	Kyoto, JAPAN	Soc Learning Analyt Res, ACM In Cooperat, SIGWEB, SIGCHI		Programming Education; Feedback Generation; Generative AI; GPT4; ChatGPT		Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a first step, our technique leverages GPT-4 as a '' tutor '' model to generate hints - it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a '' student '' model to further validate the hint quality - it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.	[Phung, Tung; Padurean, Victor-Alexandru] MPI SWS, Saarbrucken, Germany; [Singh, Anjali; Brooks, Christopher] Univ Michigan, Ann Arbor, MI 48109 USA; [Cambronero, Jose; Gulwani, Sumit] Microsoft, Redmond, WA USA	University of Michigan System; University of Michigan; Microsoft	Phung, T (corresponding author), MPI SWS, Saarbrucken, Germany.	mphung@mpi-sws.org; vpadurea@mpi-sws.org; singhanj@umich.edu; brooksch@umich.edu; jcambronero@microsoft.com; sumitg@microsoft.com		Brooks, Christopher/0000-0003-0875-0204; Gulwani, Sumit/0000-0002-9226-9634	European Union (ERC) [101039090]	European Union (ERC)(European Union (EU)European Research Council (ERC))	Funded/Co-funded by the European Union (ERC, TOPS, 101039090). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them.	Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Brandl Georg, 2006, Pygments; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; COCHRAN WG, 1952, ANN MATH STAT, V23, P315, DOI 10.1214/aoms/1177729380; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; geeksforgeeks.org, 2009, GeeksforGeeks: A Computer Science Portal for Geeks; GitHub, 2022, GitHub Copilot: Your AI Pair Programmer; Gulwani S, 2018, PROCEEDINGS OF THE 39TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, PLDI 2018, P465, DOI [10.1145/3192366.3192387, 10.1145/3296979.3192387]; Head Andrew, 2017, Learning @ Scale; Khan Academy, 2023, Khanmigo; Kiesler Natalie, 2023, FIE; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Li Tiffany Wenting, 2023, ICER; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; McKinney W., 2011, Python for high performance and scientific computing, V14, P1, DOI DOI 10.1002/MMCE.20381; Mirhosseini S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P291, DOI 10.1145/3545945.3569816; Mozannar H, 2024, Arxiv, DOI arXiv:2210.14306; Olausson TX, 2024, Arxiv, DOI arXiv:2306.09896; OpenAI, 2023, CHATGPT; OpenAI, 2022, Codex-Edit; OpenAl, 2023, GPT-4 technical report; Padurean VA, 2024, Arxiv, DOI arXiv:2305.18342; Pankiewicz M, 2023, Arxiv, DOI arXiv:2307.00150; Phung Tung, 2023, ICER V.2; Phung Tung, 2023, EDM; Quizlet, 2023, Q-Chat; Sarsa Sami, 2022, ICER; Savelka Jaromir, 2023, ITiCSE; Singh R, 2013, ACM SIGPLAN NOTICES, V48, P15, DOI 10.1145/2499370.2462195; Singla Adish, 2023, ICER V. 2; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wei J., 2022, NEURIPS; Zhang J., 2022, arXiv	35	0	0	13	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1618-8				2024							12	23		10.1145/3636555.3636846	http://dx.doi.org/10.1145/3636555.3636846			12	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW6NI		Green Submitted, hybrid			2024-07-03	WOS:001179044200002
C	Trivedi, H; Balasubramanian, N; Khot, T; Sabharwal, A		Rogers, A; Boyd-Graber, J; Okazaki, N		Trivedi, Harsh; Balasubramanian, Niranjan; Khot, Tushar; Sabharwal, Ashish			Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Prompting-based large language models (LLMs) are surprisingly powerful at generating natural language reasoning steps or Chains-of-Thoughts (CoT) for multi-step question answering (QA). They struggle, however, when the necessary knowledge is either unavailable to the LLM or not up-to-date within its parameters. While using the question to retrieve relevant text from an external knowledge source helps LLMs, we observe that this one-step retrieve-and-read approach is insufficient for multi-step QA. Here, what to retrieve depends on what has already been derived, which in turn may depend on what was previously retrieved. To address this, we propose IRCoT, a new approach for multi-step QA that interleaves retrieval with steps (sentences) in a CoT, guiding the retrieval with CoT and in turn using retrieved results to improve CoT. Using IRCoT with GPT3 substantially improves retrieval (up to 21 points) as well as downstream QA (up to 15 points) on four datasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar substantial gains in out-of-distribution (OOD) settings as well as with much smaller models such as Flan-T5-large without additional training. IRCoT reduces model hallucination, resulting in factually more accurate CoT reasoning.	[Trivedi, Harsh; Balasubramanian, Niranjan] SUNY Stony Brook, Stony Brook, NY 11794 USA; [Khot, Tushar; Sabharwal, Ashish] Allen Inst AI, Seattle, WA USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Trivedi, H (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.	hjtrivedi@cs.stonybrook.edu; niranjan@cs.stonybrook.edu; tushark@allenai.org; ashishs@allenai.org			Air Force Research Laboratory (AFRL), DARPA [19-2-1003]; National Science Foundation [2007290]; Stony Brook Trustees Faculty Awards Program	Air Force Research Laboratory (AFRL), DARPA; National Science Foundation(National Science Foundation (NSF)); Stony Brook Trustees Faculty Awards Program	We thank the reviewers for their valuable feedback and suggestions. We also thank OpenAI for providing access to the code-davinci-002 API. This material is based on research supported in part by the Air Force Research Laboratory (AFRL), DARPA, for the KAIROS program under agreement number FA8750-19-2-1003, in part by the National Science Foundation under the award IIS #2007290, and in part by an award from the Stony Brook Trustees Faculty Awards Program.	[Anonymous], 2023, 11 INT C LEARN REPR; Asai A., 2020, ICLR; Borgeaud S, 2022, PR MACH LEARN RES; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chung Hyung Won, 2022, ARXIV221011416; Das Rajarshi, 2019, INT C LEARN REPR; Feldman Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2296; Ferguson James, 2020, EMNLP; Guu K, 2020, PR MACH LEARN RES, V119; Ho Namgyu, 2022, ARXIV221210071; Ho Xanh, 2020, COLING; Izacard Gautier, 2022, arXiv preprint arXiv:2208.03299; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kasai Jungo, 2022, ARXIV220713332; Khattab O, 2021, ADV NEUR IN, V34; Khattab Omar, 2023, Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp; Khot Tushar, 2023, 11 INT C LEARN REPR; Khot Tushar, 2022, Decomposed prompting: A modular approach for solving complex tasks; Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Lazaridou Angeliki, 2022, ARXIV220305115; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Magister Lucie Charlotte, 2022, ARXIV221208410; Nakano R., 2021, CoRR; Ouyang L., 2022, Advances in Neural Information Processing Systems; Press Ofir, 2022, ARXIV221003350; Qi P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2590; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Sun Zhiqing, 2022, ARXIV221001296; Trivedi H, 2022, T ASSOC COMPUT LING, V10, P539, DOI 10.1162/tacl_a_00475; Wei Jason, 2022, ADV NEURAL INFORM PR; Xiong Wenhan, 2021, INT C LEARN REPR; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Yao Shunyu, 2022, ARXIV221003629; Yu Wenhao, 2023, 11 INT C LEARN REPR; Zhu Fengbin, 2021, arXiv preprint arXiv:2101.00774	36	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							10014	10037						24	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962501042
C	Al Madi, N			ASSOC COMPUTING MACHINERY	Al Madi, Naser			How Readable is Model-generated Code? Examining Readability and Visual Inspection of GitHub Copilot	PROCEEDINGS OF THE 37TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE 2022	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	37th IEEE/ACM International Conference on Automated Software Engineering (ASE)	OCT 10-14, 2022	Oakland Univ, MI	IEEE, Assoc Comp Machinery, Meta, IBM, Ford, Huawei, Google, IEEE Comp Soc, IEEE Tech Council Software Engn, Special Interest Grp Software Engn, ACM SIGAI, Oakland Univ, Sch Engn & Comp Sci	Oakland Univ	GitHub; Copilot; Readability; Eye Tracking; Empirical Study		Background: Recent advancements in large language models have motivated the practical use of such models in code generation and program synthesis. However, little is known about the effects of such tools on code readability and visual attention in practice. Objective: In this paper, we focus on GitHub Copilot to address the issues of readability and visual inspection of model generated code. Readability and low complexity are vital aspects of good source code, and visual inspection of generated code is important in light of automation bias. Method: Through a human experiment (n=21) we compare model generated code to code written completely by human programmers. We use a combination of static code analysis and human annotators to assess code readability, and we use eye tracking to assess the visual inspection of code. Results: Our results suggest that model generated code is comparable in complexity and readability to code written by human pair programmers. At the same time, eye tracking data suggests, to a statistically significant level, that programmers direct less visual attention to model generated code. Conclusion: Our findings highlight that reading code is more important than ever, and programmers should beware of complacency and automation bias with model generated code.	[Al Madi, Naser] Colby Coll, Waterville, ME 04901 USA	Colby College	Al Madi, N (corresponding author), Colby Coll, Waterville, ME 04901 USA.	nsalmadi@colby.edu						Al Madi N, 2021, INT C PROGRAM COMPRE, P172, DOI 10.1109/ICPC52881.2021.00025; Al Madi Naser, 2021, ACM S EYE TRACK RES, P1; Barenkamp Marco, 2020, AI Perspectives, V2, DOI 10.1186/s42467-020-00005-4; Boehm B., 1981, Software Engineering Economics; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Crosby Martha E, 2002, PPIG. 5; CROSBY ME, 1990, COMPUTER, V23, P24, DOI 10.1109/2.48797; Kaner Cem., 2004, METRICS 2004; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; Nunez-Varela AS, 2017, J SYST SOFTWARE, V128, P164, DOI 10.1016/j.jss.2017.03.044; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Peitek N, 2021, PROC INT CONF SOFTW, P524, DOI 10.1109/ICSE43902.2021.00056; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372; Reichle ED, 2003, BEHAV BRAIN SCI, V26, P445, DOI 10.1017/S0140525X03000104; Scalabrino S, 2017, IEEE INT CONF AUTOM, P417, DOI 10.1109/ASE.2017.8115654; Schacher Ritchie, Program in Pairs; Sharafi Z, 2020, EMPIR SOFTW ENG, V25, P3128, DOI 10.1007/s10664-020-09829-4; Sharif B, 2016, PROC IEEE INT CONF S, P647, DOI 10.1109/ICSME.2016.61; Sobania D, 2021, Arxiv, DOI arXiv:2111.07875; Uwano H., 2005, Eye Tracking Research and Applications Symposium (ETRA), V2005, P133; Vaithilingam Priyan, 2022, CHI C HUM FACT COMP, P1; Van Rossum G., 2001, Python org, V1565, P28; Williams L, 2001, 14TH CONFERENCE ON SOFTWARE ENGINEERING EDUCATION AND TRAINING, PROCEEDINGS, P27, DOI 10.1109/CSEE.2001.913816; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	28	4	4	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES	1527-1366		978-1-4503-9475-8	IEEE INT CONF AUTOM			2022									205	10.1145/3551349.3560438	http://dx.doi.org/10.1145/3551349.3560438			5	Automation & Control Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BV6UR		Bronze, Green Submitted			2024-07-03	WOS:001062775200179
C	Dobslaw, F; Bergh, P			ACM	Dobslaw, Felix; Bergh, Peter			Experiences with Remote Examination Formats in Light of GPT-4	PROCEEDINGS OF THE 5TH EUROPEAN CONFERENCE ON SOFTWARE ENGINEERING EDUCATION, ECSEE 2023			English	Proceedings Paper	5th European Conference on Software Engineering Education (ECSEE)	JUN 19-21, 2023	Seeon Monastery, GERMANY			Software Engineering Education; Examination Formats; Oral Examinations; ChatGPT		Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.	[Dobslaw, Felix; Bergh, Peter] Mid Sweden Univ, Dept Qual Management Commun & Informat Sci, Ostersund, Sweden	Mid-Sweden University	Dobslaw, F (corresponding author), Mid Sweden Univ, Dept Qual Management Commun & Informat Sci, Ostersund, Sweden.	felix.dobslaw@miun.se; peter.bergh@miun.se		Dobslaw, Felix/0000-0001-9372-3416				Alin P, 2023, ASSESS EVAL HIGH EDU, V48, P262, DOI 10.1080/02602938.2022.2075317; Chen M., 2021, arXiv; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Gharibyan H., 2005, SIGCSE Bulletin, V37, P143, DOI 10.1145/1151954.1067487; Graf Stefan Ting, 2021, Tidsskriftet Laering og Medier (LOM), V14, P24; Hatzipanagos S., 2020, EUR DIST E LEARN NET, P59; Huxham M, 2012, ASSESS EVAL HIGH EDU, V37, P125, DOI 10.1080/02602938.2010.515012; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Lapakko David, 2007, Communication and Theater Association of Minnesota Journal, V34, P1; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Sanh V, 2022, arXiv; Scaffidi C., 2018, Int. J. Comput. Sci. Eng. Inf. Technol., V8, P1, DOI [10.5121/ijeseit2018.8101, DOI 10.5121/IJESEIT2018.8101]; Stray C., 2001, Assessment in Education: Principles, Policy Practice, V8, P33, DOI [https://doi.org/10.1080/09695940120033243, DOI 10.1080/09695940120033243]	14	1	1	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9956-2				2023							220	225		10.1145/3593663.3593695	http://dx.doi.org/10.1145/3593663.3593695			6	Computer Science, Software Engineering; Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW2RW		Green Submitted, Bronze			2024-07-03	WOS:001124146500029
C	Li, S; Zhao, RN; Li, ML; Ji, H; Callison-Burch, C; Han, JW		Rogers, A; Boyd-Graber, J; Okazaki, N		Li, Sha; Zhao, Ruining; Li, Manling; Ji, Heng; Callison-Burch, Chris; Han, Jiawei			Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Event schemas are a form of world knowledge about the typical progression of events. Recent methods for event schema induction use information extraction systems to construct a large number of event graph instances from documents, and then learn to generalize the schema from such instances. In contrast, we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs). This new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way. Since event schemas have complex graph structures, we design an incremental prompting and verification method INCSCHEMA to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification. Compared to directly using LLMs to generate a linearized graph, INCSCHEMA can generate large and complex schemas with 7.2% F1 improvement in temporal relations and 31.0% F1 improvement in hierarchical relations. In addition, compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover similar to 10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability. 1	[Li, Sha; Zhao, Ruining; Li, Manling; Ji, Heng; Han, Jiawei] Univ Illinois, Champaign, IL 61820 USA; [Callison-Burch, Chris] Univ Penn, Philadelphia, PA 19104 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Pennsylvania	Li, S (corresponding author), Univ Illinois, Champaign, IL 61820 USA.	shal2@illinois.edu; ruining9@illinois.edu; manling2@illinois.edu; hengji@illinois.edu; ccb@seas.upenn.edu; hanj@illinois.edu			U.S. DARPA KAIROS Program [FA8750-19-2-1004]; DARPA LwLL Program [FA8750-19-2-0201]; IARPA HIATUS Program [2022-22072200005]; NSF [1928631]	U.S. DARPA KAIROS Program(United States Department of Defense); DARPA LwLL Program; IARPA HIATUS Program; NSF(National Science Foundation (NSF))	We thank the anonymous reviewers for their helpful suggestions. This research is based upon work supported by U.S. DARPA KAIROS Program No. FA8750-19-2-1004, the DARPA LwLL Program (contract FA8750-19-2-0201), the IARPA HIATUS Program (contract 2022-22072200005), and the NSF (Award 1928631). Approved for Public Release, Distribution Unlimited. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.	Ahrendt Simon, 2016, HLT NAACL, P546; ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Campos Daniel Fernando, 2016, ABS161109268 ARXIV; Chambers N., 2009, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, P602; Chambers Nathanael., 2008, P ACL 08 HLT, P789; Chowdhery Aakanksha, 2022, ABS220402311 ARXIV; Dror Rotem, 2022, ZERO SHOT ON THE FLY; Du XY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54; EADES P, 1993, INFORM PROCESS LETT, V47, P319, DOI 10.1016/0020-0190(93)90079-O; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Glavas G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3678; Granroth-Wilding M, 2016, AAAI CONF ARTIF INTE, P2727; Jans Bram, 2012, P 13 C EUR CHAPT ASS, P336; Ji Heng, 2008, P ANN M ASS COMP LIN; Jin XM, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2013; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Lampinen Andrew Kyle, 2022, ABS220402329 ARXIV; Li ML, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5203; Li M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P684; Li ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4201; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Lin SC, 2021, REPL4NLP 2021: PROCEEDINGS OF THE 6TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P163; Lin Ying, 2021, P ACL IJCNLP 2021 WO; Pichotta K., 2014, P 14 C EUR CHAPT ASS, V14, P220, DOI [DOI 10.3115/V1/E14-1024, 10.3115/v1/e14-1024]; Pichotta Karl, 2016, Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods, P11, DOI DOI 10.18653/V1/W16-6003; Rae Jack W., 2021, ABS211211446 ARXIV; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Rudinger Rachel, 2015, P 2015 C EMP METH NA, P1681; Sakaguchi K, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2138; Sancino A, 2023, PUBLIC MANAG REV, V25, P1730, DOI 10.1080/14719037.2022.2039274; Schank R. C., 1975, ADV PAPERS 4 INT JOI, V75, P151, DOI DOI 10.1016/B978-1-4832-1446-7.50019-4; Wang Xuezhi, 2022, ABS220700747 ARXIV; Wang Z., 2017, P 2017 C EMP METH NA, P57; Weber Noah, 2018, AAAI; Wei Jiaheng, 2022, ICLR; Winkler W.E., 1990, STRING COMP METRICS; Zhang L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4630; Zhou B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1361; Zhou Chunting, 2022, ABS220500049 ARXIV; Zhou SY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2998	41	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							5677	5697						21	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086804036
J	Cheungpasitporn, W; Thongprayoon, C; Kashani, KB				Cheungpasitporn, Wisit; Thongprayoon, Charat; Kashani, Kianoush B.			Artificial Intelligence in Heart Failure and Acute Kidney Injury: Emerging Concepts and Controversial Dimensions	CARDIORENAL MEDICINE			English	Review						Heart failure; Acute kidney injury; Artificial intelligence; Machine learning; Analytical approaches; Care enhancement; Transformative potential; Multifaceted technologies	RENAL-FUNCTION; EPIDEMIOLOGY; DYSFUNCTION; PREDICTION; OUTCOMES; IMPACT	Background: The growing complexity of patient data and the intricate relationship between heart failure (HF) and acute kidney injury (AKI) underscore the potential benefits of integrating artificial intelligence (AI) and machine learning into healthcare. These advanced analytical tools aim to improve the understanding of the pathophysiological relationship between kidney and heart, provide optimized, individualized, and timely care, and improve outcomes of HF with AKI patients. Summary: This comprehensive review article examines the transformative potential of AI and machine-learning solutions in addressing the challenges within this domain. The article explores a range of methodologies, including supervised and unsupervised learning, reinforcement learning, and AI-driven tools like chatbots and large language models. We highlight how these technologies can be tailored to tackle the complex issues prevalent among HF patients with AKI. The potential applications identified span predictive modeling, personalized interventions, real-time monitoring, and collaborative treatment planning. Additionally, we emphasize the necessity of thorough validation, the importance of collaborative efforts between cardiologists and nephrologists, and the consideration of ethical aspects. These factors are critical for the effective application of AI in this area. Key Messages: As the healthcare field evolves, the synergy of advanced analytical tools and clinical expertise holds significant promise to enhance the care and outcomes of individuals who deal with the combined challenges of HF and AKI.	[Cheungpasitporn, Wisit; Thongprayoon, Charat; Kashani, Kianoush B.] Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55902 USA; [Kashani, Kianoush B.] Mayo Clin, Dept Med, Div Pulm & Crit Care Med, Rochester, MN 55902 USA	Mayo Clinic; Mayo Clinic	Kashani, KB (corresponding author), Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55902 USA.; Kashani, KB (corresponding author), Mayo Clin, Dept Med, Div Pulm & Crit Care Med, Rochester, MN 55902 USA.	kashani.kianoush@mayo.edu						Bart NK, 2023, HEART LUNG CIRC, V32, P883, DOI 10.1016/j.hlc.2023.07.005; Breidthardt T, 2011, AM J CARDIOL, V107, P730, DOI 10.1016/j.amjcard.2010.10.056; Cassol C, 2021, KIDNEY MED, V3, P693, DOI 10.1016/j.xkme.2021.08.004; Chahal RS, 2020, CLIN MED, V20, P146, DOI 10.7861/clinmed.2019-0422; Chen JJ, 2022, KIDNEY INT REP, V7, P526, DOI 10.1016/j.ekir.2021.12.033; Doshi R, 2020, INTERN EMERG MED, V15, P421, DOI 10.1007/s11739-019-02188-z; Elul Y, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2020620118; Forman DE, 2004, J AM COLL CARDIOL, V43, P61, DOI 10.1016/j.jacc.2003.07.031; Gala Dhir, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20156438; Go AS, 2018, CLIN J AM SOC NEPHRO, V13, P833, DOI 10.2215/CJN.12591117; Holgado JL, 2020, ESC HEART FAIL, V7, P415, DOI 10.1002/ehf2.12595; Hong CG, 2022, JMIR MED INF, V10, DOI 10.2196/37484; Kaur A, 2021, DIGIT HEALTH, V7, DOI 10.1177/20552076211038151; Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5; Krisanapan P, 2023, J CLIN MED, V12, DOI 10.3390/jcm12083018; Kuno T, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04372-8; Lassus JPE, 2010, EUR HEART J, V31, P2791, DOI 10.1093/eurheartj/ehq293; Lee TH, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90756-9; Li Q., 2023, J Clin Med, P12; Liu WT, 2022, FRONT CARDIOVASC MED, V9, DOI 10.3389/fcvm.2022.911987; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; Miao J, 2023, KIDNEY INT REP, V8, P1657, DOI 10.1016/j.ekir.2023.05.014; Mortazavi BJ, 2016, CIRC-CARDIOVASC QUAL, V9, P629, DOI 10.1161/CIRCOUTCOMES.116.003039; Nakaya Y, 2023, EUR HEART J-DIGIT HL, V4, P141, DOI 10.1093/ehjdh/ztad026; Odutayo A, 2017, J AM SOC NEPHROL, V28, P377, DOI 10.1681/ASN.2016010105; Rewa O, 2014, NAT REV NEPHROL, V10, P193, DOI 10.1038/nrneph.2013.282; Roggeveen L, 2021, ARTIF INTELL MED, V112, DOI 10.1016/j.artmed.2020.102003; Rumsfeld JS, 2016, NAT REV CARDIOL, V13, P350, DOI 10.1038/nrcardio.2016.42; Schefold JC, 2016, NAT REV NEPHROL, V12, P610, DOI 10.1038/nrneph.2016.113; Shouval R, 2017, INT J CARDIOL, V246, P7, DOI 10.1016/j.ijcard.2017.05.067; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Son HE, 2022, KIDNEY RES CLIN PRAC, V41, P188, DOI 10.23876/j.krcp.21.111; Song Z, 2022, FRONT CARDIOVASC MED, V9, DOI 10.3389/fcvm.2022.951881; Soranno DE, 2022, KIDNEY360, V3, P376, DOI 10.34067/KID.0003472021; Suppadungsuk Supawadee, 2023, Medicines (Basel), V10, DOI 10.3390/medicines10100058; Thongprayoon Charat, 2021, Med Sci (Basel), V9, DOI 10.3390/medsci9040060; Thongprayoon C, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061767; Tseng PY, 2020, CRIT CARE, V24, DOI 10.1186/s13054-020-03179-9; Urban S, 2022, BIOMOLECULES, V12, DOI 10.3390/biom12111616; Verdiani V., 2010, Int J Nephrol; Wang L, 2021, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.719307; Wang YN, 2013, NEPHROLOGY, V18, P489, DOI 10.1111/nep.12092; Zhou LZ., 2016, J Am Heart Assoc, V5	43	1	1	2	2	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	1664-3828	1664-5502		CARDIORENAL MED	CardioRenal Med.		2024	14	1					147	159		10.1159/000537751	http://dx.doi.org/10.1159/000537751			13	Cardiac & Cardiovascular Systems; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology; Urology & Nephrology	OD6B2	38350433	gold			2024-07-03	WOS:001205348900001
J	Hadar-Shoval, D; Elyoseph, Z; Lvovsky, M				Hadar-Shoval, Dorit; Elyoseph, Zohar; Lvovsky, Maya			The plasticity of ChatGPT's mentalizing abilities: personalization for personality structures	FRONTIERS IN PSYCHIATRY			English	Article						artificial intelligence; borderline personality disorder; emotional intelligence; empathy; emotional awareness; Schizoid Personality Disorder	EMOTIONAL AWARENESS; ALEXITHYMIA; DISORDERS	This study evaluated the potential of ChatGPT, a large language model, to generate mentalizing-like abilities that are tailored to a specific personality structure and/or psychopathology. Mentalization is the ability to understand and interpret one's own and others' mental states, including thoughts, feelings, and intentions. Borderline Personality Disorder (BPD) and Schizoid Personality Disorder (SPD) are characterized by distinct patterns of emotional regulation. Individuals with BPD tend to experience intense and unstable emotions, while individuals with SPD tend to experience flattened or detached emotions. We used ChatGPT's free version 23.3 and assessed the extent to which its responses akin to emotional awareness (EA) were customized to the distinctive personality structure-character characterized by Borderline Personality Disorder (BPD) and Schizoid Personality Disorder (SPD), employing the Levels of Emotional Awareness Scale (LEAS). ChatGPT was able to accurately describe the emotional reactions of individuals with BPD as more intense, complex, and rich than those with SPD. This finding suggests that ChatGPT can generate mentalizing-like responses consistent with a range of psychopathologies in line with clinical and theoretical knowledge. However, the study also raises concerns regarding the potential for stigmas or biases related to mental diagnoses to impact the validity and usefulness of chatbot-based clinical interventions. We emphasize the need for the responsible development and deployment of chatbot-based interventions in mental health, which considers diverse theoretical frameworks.	[Hadar-Shoval, Dorit; Elyoseph, Zohar] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Emek Yezreel, Israel; [Elyoseph, Zohar] Imperial Coll London, Fac Med, Dept Brain Sci, London, England; [Elyoseph, Zohar; Lvovsky, Maya] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Psychol Dept, Emek Yezreel, Israel	Imperial College London	Hadar-Shoval, D (corresponding author), Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Emek Yezreel, Israel.	Dorith@yvc.ac.il						Aival-Naveh E, 2019, CLIN PSYCHOL-SCI PR, V26, DOI 10.1111/cpsp.12300; American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU; Arboleda-Flórez J, 2012, CAN J PSYCHIAT, V57, P457, DOI 10.1177/070674371205700803; Baslet G, 2009, J NERV MENT DIS, V197, P655, DOI 10.1097/NMD.0b013e3181b3b20f; Burr V., 2017, The Palgrave handbook of critical social psychology; Bzdok D, 2018, BIOL PSYCHIAT-COGN N, V3, P223, DOI 10.1016/j.bpsc.2017.11.007; Carla S., 2008, SOCIAL COGNITION DEV; Carton S, 2008, J SMOK CESS, V3, P81, DOI 10.1375/jsc.3.2.81; Coolidge FL, 2013, COMPR PSYCHIAT, V54, P141, DOI 10.1016/j.comppsych.2012.07.005; Danieli M, 2022, JMIR MENT HEALTH, V9, DOI 10.2196/38067; Daros AR, 2019, HARVARD REV PSYCHIAT, V27, P217, DOI 10.1097/HRP.0000000000000212; De la Peña-Arteaga V, 2021, EUR PSYCHIAT, V64, DOI 10.1192/j.eurpsy.2021.2231; De Panfilis C, 2019, J ABNORM PSYCHOL, V128, P162, DOI 10.1037/abn0000404; Elyoseph Z, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1213141; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Elyoseph Z, 2023, CEREBELLUM, DOI 10.1007/s12311-023-01536-2; Eylem O, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-020-08964-3; Fariba KA, 2022, StatPearls; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Fonagy P., 2016, Developmental Psychopathology. Maladaptation Psychopathology, P726, DOI DOI 10.1002/9781119125556.DEVPSY317; Freeman C, 2016, BRIT J PSYCHOTHER, V32, P189, DOI 10.1111/bjp.12220; Frewen P, 2008, PSYCHOSOM MED, V70, P27, DOI 10.1097/PSY.0b013e31815f66d4; Gough B., 2017, The Palgrave handbook of critical social psychology; Hall NT, 2023, PSYCHOL MED, V53, P3533, DOI 10.1017/S0033291722000101; Kohling J., 2019, J PERSONAL DISORD, P35, DOI [10.1521/pedi, DOI 10.1521/PEDI]; LANE RD, 1990, J PERS ASSESS, V55, P124, DOI 10.1207/s15327752jpa5501&2_12; Lee ELE, 2021, BIOL PSYCHIAT-COGN N, V6, P856, DOI 10.1016/j.bpsc.2021.02.001; Lingiardi V., 2017, Psychodynamic diagnostic manual: PDM-2, V2nd ed.; Luyten P, 2020, ANNU REV CLIN PSYCHO, V16, P297, DOI 10.1146/annurev-clinpsy-071919-015355; Luyten P, 2018, CLIN PSYCHOL REV, V64, P87, DOI 10.1016/j.cpr.2017.09.008; Luyten P, 2017, PSYCHOANAL STUD CHIL, V70, P174, DOI 10.1080/00797308.2016.1277901; McWilliams Nancy, 2006, Psychoanal Rev, V93, P1, DOI 10.1521/prev.2006.93.1.1; Nolte T, 2011, FRONT BEHAV NEUROSCI, V5, DOI 10.3389/fnbeh.2011.00055; Pham KT, 2022, PSYCHIAT QUART, V93, P249, DOI 10.1007/s11126-022-09973-8; Reed GM, 2018, WORLD PSYCHIATRY, V17, P227, DOI 10.1002/wps.20533; Robinson P., 2018, HUNGER MENTALIZATION, P35; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Shedler J, 2010, AM J PSYCHIAT, V167, P1026, DOI 10.1176/appi.ajp.2010.10050746; Shedlosky-Shoemaker R., 2022, SCHOLARSH TEACH LEAR, DOI [10.1037/stl0000329, DOI 10.1037/STL0000329]; Timmons AC, 2023, PERSPECT PSYCHOL SCI, V18, P1062, DOI 10.1177/17456916221134490; Topol E., 2019, DEEP MED ARTIFICIAL; van Zutphen L, 2020, BRAIN IMAGING BEHAV, V14, P2107, DOI 10.1007/s11682-019-00161-0; Walsh DAB, 2021, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.569539; Watson N., 2019, Routledge Handbook of Disability Studies	45	8	8	13	36	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-0640			FRONT PSYCHIATRY	Front. Psychiatry	SEP 1	2023	14								1234397	10.3389/fpsyt.2023.1234397	http://dx.doi.org/10.3389/fpsyt.2023.1234397			7	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	R7SW6	37720897	Green Published, gold			2024-07-03	WOS:001066327400001
J	Bergman, S; Marchal, N; Mellor, J; Mohamed, S; Gabriel, I; Isaac, W				Bergman, Stevie; Marchal, Nahema; Mellor, John; Mohamed, Shakir; Gabriel, Iason; Isaac, William			STELA: a community-centred approach to norm elicitation for AI alignment	SCIENTIFIC REPORTS			English	Article								Value alignment, the process of ensuring that artificial intelligence (AI) systems are aligned with human values and goals, is a critical issue in AI research. Existing scholarship has mainly studied how to encode moral values into agents to guide their behaviour. Less attention has been given to the normative questions of whose values and norms AI systems should be aligned with, and how these choices should be made. To tackle these questions, this paper presents the STELA process (SocioTEchnical Language agent Alignment), a methodology resting on sociotechnical traditions of participatory, inclusive, and community-centred processes. For STELA, we conduct a series of deliberative discussions with four historically underrepresented groups in the United States in order to understand their diverse priorities and concerns when interacting with AI systems. The results of our research suggest that community-centred deliberation on the outputs of large language models is a valuable tool for eliciting latent normative perspectives directly from differently situated groups. In addition to having the potential to engender an inclusive process that is robust to the needs of communities, this methodology can provide rich contextual insights for AI alignment.	[Bergman, Stevie; Marchal, Nahema; Mellor, John; Mohamed, Shakir; Gabriel, Iason; Isaac, William] Google DeepMind, London, England	Google Incorporated	Marchal, N (corresponding author), Google DeepMind, London, England.	nahemamarchal@google.com						Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], What Is Hate Speech; Anthropic, 2023, Claude's constitution; Arnstein SR, 2019, J AM PLANN ASSOC, V85, P24, DOI 10.1080/01944363.2018.1559388; Arun C., 2019, The Oxford Handbook of Ethics of AI; Askell A, 2021, Arxiv, DOI [arXiv:2112.00861, DOI 10.48550/ARXIV.2112.00861]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Balaram B., 2018, Artificial Intelligence: Real Public Engagement; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin R., 2020, SOC FORCES, DOI DOI 10.1093/sf/soz162; Bicchieri C, 2014, COMPUT SOC SCI, P37, DOI 10.1007/978-3-319-05308-0_3; Birhane A, 2022, ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2022, DOI 10.1145/3551624.3555290; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bruhn JG, 2011, SOCIOLOGY OF COMMUNITY CONNECTIONS, SECOND EDITION, P1, DOI 10.1007/978-94-007-1633-9; Cave Stephen, 2020, Philosophy & Technology, V33, P685, DOI [10.1007/s13347-020-00415-6, DOI 10.1007/S13347-020-00415-6]; CHAMBERS R, 1994, WORLD DEV, V22, P953, DOI 10.1016/0305-750X(94)90141-4; Chambers S., 2018, Reasonable democracy: Jurgen Habermas and the politics of discourse, DOI DOI 10.7591/9781501722547; Christian B., 2021, The alignment problem: How can machines learn human values?; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; COLLINS PH, 1989, SIGNS, V14, P745, DOI 10.1086/494543; Crenshaw K., 2019, INTERSECTIONALITY ES; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Ensign Danielle, 2018, P 1 C FAIRNESS ACCOU, P160; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; Ferri G, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3603751; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Fishkin JS, 2005, ACTA POLIT, V40, P284, DOI 10.1057/palgrave.ap.5500121; Fletcher-Watson S, 2019, AUTISM, V23, P943, DOI 10.1177/1362361318786721; Freire P., 1970, PEDAGOGY OPPRESSED; Friedman Batya., 1996, INTERACTIONS, Vvol. 3, P17, DOI [DOI 10.1145/242485.242493, 10.1145/242485.242493]; Gabriel I., 2022, The Oxford Handbook of Digital Ethics (1st edition); Gabriel I, 2020, MIND MACH, V30, P411, DOI 10.1007/s11023-020-09539-2; Gadiraju V, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P205, DOI 10.1145/3593013.3593989; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Glaese A, 2022, arXiv; Glaser B. G., 1967, Discovery of grounded theory: Strategies for qualitative research; Haidt Jonathan, 2013, The righteous mind: Why good people are divided by politics and religion; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hughes D.L., 2002, ECOLOGICAL RES PROMO, P257, DOI DOI 10.1007/978-1-4615-0565-5_11; Jakesch Maurice, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P310, DOI 10.1145/3531146.3533097; JohannesWelbl Amelia Glaese, 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2109.07445; Katell M, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P45, DOI 10.1145/3351095.3372874; Kroes P., 2014, The Moral Status of Technical Artefacts, DOI [10.1007/978-94-007-7914-3, DOI 10.1007/978-94-007-7914-3]; Leike Jan, 2022, Our approach to alignment research; Leslie D, 2019, NATURE, V574, P32, DOI 10.1038/d41586-019-02939-0; Lima L, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P533, DOI 10.1145/3308560.3317597; Lum K., 2016, Significance, V13, P14, DOI [10.1111/j.1740-9713.2016.00960.x, DOI 10.1111/J.1740-9713.2016.00960.X]; Marr B., 2023, Forbes; Mendelberg T., 2002, Political Decision Making, Deliberation and Participation, V6, P151; Mengesha Z, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.725911; Miles M. B., 1994, Qualitative data analysis: A methods sourcebook, DOI DOI 10.1016/0149-7189(96)88232-2; Min Kyung Lee, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359283; Morgan D. L., 1996, FOCUS GROUPS QUALITA, V16; National Institute of Standards and Technology, 2023, Artificial Intelligence Risk Management Framework (AI RMF 1.0), DOI DOI 10.6028/NIST.AI.100-1; Onwuegbuzie AJ, 2022, International Journal of Qualitative Methods, V8, P1, DOI [10.1177/160940690900800301, DOI 10.1177/160940690900800301]; OpenAI, 2023, GPT 4 SYST CARD; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Perez Ethan, 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.03286; Prabhakaran V, 2020, Arxiv, DOI [arXiv:2005.07572, DOI 10.48550/ARXIV.2005.07572]; Prabhakaran V, 2020, HEALTH HUM RIGHTS, V22, P71; Prabhakaran Vinodkumar, 2022, arXiv, DOI DOI 10.48550/ARXIV.2211.13069; Raji ID, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P429, DOI 10.1145/3306618.3314244; Rigot A., 2022, Design From the Margins: Centering the most marginalized and impacted in design processes - from ideation to production; Röttger P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P175; Rothwell E, 2016, QUAL HEALTH RES, V26, P734, DOI 10.1177/1049732315591150; Santy S, 2023, P 61 ANN M ASS COMP, V1, DOI [10.18653/v1/2023.acl-long.505, DOI 10.18653/V1/2023.ACL-LONG.505]; Scott J., 2014, DICT SOCIOLOGY; Shanahan M, 2023, NATURE, V623, P493, DOI 10.1038/s41586-023-06647-8; Shen TH, 2023, Arxiv, DOI arXiv:2309.15025; Sloane M, 2022, ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2022, DOI 10.1145/3551624.3555285; Solaiman I., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.10328; Spivak G.C., 2010, PODE SUBALTERNO FALA, DOI DOI 10.7312/MORR14384.5; Stiennon N, 2022, Arxiv, DOI arXiv:2009.01325; The British Psychological Society, 2021, Ethics guidelines for internet-mediated research, DOI [10.53841/bpsrep.2021.rep155, DOI 10.53841/BPSREP.2021.REP155]; The Collective Intelligence Project, 2023, Whitepaper. The Collective Intelligence Project; The Value Alignment Project, The value alignment problem; Tonnies F., 2017, Community and Society, DOI [10.4324/9781315080871, DOI 10.4324/9781315080871]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tronto Joan., 1993, MORAL BOUNDARIES POL; Uesato J., 2022, Advances in Neural Information Processing Systems, V35, P24720; Uma A, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.818451; van de Poel I., 2013, PHILOS ENG REFLECTIO, P253, DOI [DOI 10.1007/978-94-007-7762-0_20, 10.1007/978-94-007-7762-0_20]; van der Veer SN, 2021, J AM MED INFORM ASSN, V28, P2128, DOI 10.1093/jamia/ocab127; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Weidinger L, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2213709120; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Whyte W.F., 1991, PARTICIPATORY ACTION, P19, DOI 10.4135/9781412985383; WINNER L, 1980, DAEDALUS, V109, P121; Ziegler DM., 2022, PREPRINT	91	0	0	3	3	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAR 19	2024	14	1							6616	10.1038/s41598-024-56648-4	http://dx.doi.org/10.1038/s41598-024-56648-4			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	LQ5H8	38503818	gold, Green Accepted			2024-07-03	WOS:001188276500070
J	Stribling, D; Xia, YX; Amer, MK; Graim, KS; Mulligan, CJ; Renne, R				Stribling, Daniel; Xia, Yuxing; Amer, Maha K.; Graim, Kiley S.; Mulligan, Connie J.; Renne, Rolf			The model student: GPT-4 performance on graduate biomedical science exams	SCIENTIFIC REPORTS			English	Article							ARTIFICIAL-INTELLIGENCE; EUROPEAN EXAM; CHATGPT	The GPT-4 large language model (LLM) and ChatGPT chatbot have emerged as accessible and capable tools for generating English-language text in a variety of formats. GPT-4 has previously performed well when applied to questions from multiple standardized examinations. However, further evaluation of trustworthiness and accuracy of GPT-4 responses across various knowledge domains is essential before its use as a reference resource. Here, we assess GPT-4 performance on nine graduate-level examinations in the biomedical sciences (seven blinded), finding that GPT-4 scores exceed the student average in seven of nine cases and exceed all student scores for four exams. GPT-4 performed very well on fill-in-the-blank, short-answer, and essay questions, and correctly answered several questions on figures sourced from published manuscripts. Conversely, GPT-4 performed poorly on questions with figures containing simulated data and those requiring a hand-drawn answer. Two GPT-4 answer-sets were flagged as plagiarism based on answer similarity and some model responses included detailed hallucinations. In addition to assessing GPT-4 performance, we discuss patterns and limitations in GPT-4 capabilities with the goal of informing design of future academic examinations in the chatbot era.	[Stribling, Daniel; Amer, Maha K.; Renne, Rolf] Univ Florida, Dept Mol Genet & Microbiol, Gainesville, FL 32610 USA; [Stribling, Daniel; Mulligan, Connie J.; Renne, Rolf] Univ Florida, UF Genet Inst, Gainesville, FL 32610 USA; [Stribling, Daniel; Renne, Rolf] Univ Florida, UF Hlth Canc Ctr, Gainesville, FL 32610 USA; [Xia, Yuxing] Univ Florida, Coll Med, Ctr Translat Res Neurodegenerat Dis, Dept Neurosci, Gainesville, FL 32610 USA; [Graim, Kiley S.] Univ Florida, Herbert Wertheim Coll Engn, Dept Comp & Informat Sci & Engn, Gainesville, FL 32610 USA; [Mulligan, Connie J.] Univ Florida, Dept Anthropol, Gainesville, FL 32610 USA; [Xia, Yuxing] UCLA, Dept Neurol, Los Angeles, CA 90095 USA	State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida; State University System of Florida; University of Florida; University of California System; University of California Los Angeles	Stribling, D; Renne, R (corresponding author), Univ Florida, Dept Mol Genet & Microbiol, Gainesville, FL 32610 USA.; Stribling, D; Renne, R (corresponding author), Univ Florida, UF Genet Inst, Gainesville, FL 32610 USA.; Stribling, D; Renne, R (corresponding author), Univ Florida, UF Hlth Canc Ctr, Gainesville, FL 32610 USA.	ds@ufl.edu; rrenne@ufl.edu		Xia, MD, PhD, Yuxing/0000-0002-8415-8256; Stribling, Daniel/0000-0002-0649-9506; Mulligan, Connie/0000-0002-4360-2402	National Institutes of Health [T32 CA257923]; University of Florida Cancer Center; University of Florida Informatics Institute [00130153]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); University of Florida Cancer Center; University of Florida Informatics Institute(University of Florida)	Study staff conducting this work were supported by grants from National Institutes of Health ( NIH T32 CA257923 to D.S.), the University of Florida Cancer Center (UFHCC Pilot funding to R.R.), and the University of Florida Informatics Institute (UFII Graduate Fellowship Project 00130153 to D.S.).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Azizoglu M., 2023, A randomized comparative study, DOI [10.21203/rs.3.rs-3018641/v1, DOI 10.21203/RS.3.RS-3018641/V1]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Birkett L, 2023, BRIT J ANAESTH, V131, pe34, DOI 10.1016/j.bja.2023.04.025; Blum M, 2023, J CARD FAIL, V29, P1332, DOI 10.1016/j.cardfail.2023.06.015; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Bruner KM, 2016, NAT MED, V22, P1043, DOI 10.1038/nm.4156; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Deebel NA, 2023, UROLOGY, V177, P29, DOI 10.1016/j.urology.2023.05.010; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Foundation T. C. C., Common Crawl; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Google, 2023, Bard; Hu K., 2023, Reuters; Huang Y., 2023, Benchmarking ChatGPT-4 on ACR radiation oncology in-training (TXIT) exam and red journal gray zone cases: Potentials and challenges for AI-assisted medical education and decision making in radiation oncology, DOI [10.2139/ssrn.4457218, DOI 10.2139/SSRN.4457218]; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Ibrahim H, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38964-3; Intelligent, 2023, Nearly 1 in 3 college students have used ChatGPT on written assignments; Jimenez K., 2023, ChatGPT in the classroom: Here's what teachers and students are saying; Katz DM, 2024, PHILOS T R SOC A, V382, DOI 10.1098/rsta.2023.0254; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Merken S., 2023, Reuters; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2022, Introducing chatgpt; OpenAi, 2022, Chatgpt; OpenAI, 2023, Gpt-4v(ision) system card; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Perplexity, 2023, Perplexity AI; Plummer C, 2023, EUR HEART J-DIGIT HL, V4, P362, DOI 10.1093/ehjdh/ztad040; Shay D, 2023, BRIT J ANAESTH, V131, DOI 10.1016/j.bja.2023.04.017; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Spitale G, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adh1850; Stribling Daniel, 2023, Zenodo, DOI 10.5281/ZENODO.8132918; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Taloni A, 2023, EYE, DOI 10.1038/s41433-023-02678-7; Terry O. K., 2023, I'm a Student. You Have No Idea How Much We're Using ChatGPT; Walters WH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41032-5; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wong B, 2011, NAT METHODS, V8, P441, DOI 10.1038/nmeth.1618	54	1	1	14	14	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAR 7	2024	14	1							5670	10.1038/s41598-024-55568-7	http://dx.doi.org/10.1038/s41598-024-55568-7			11	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	LE4F0	38453979	Green Published, gold			2024-07-03	WOS:001185083700100
C	An, RZ; Zhang, C; Song, DW		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		An, Ruize; Zhang, Chen; Song, Dawei			Eliminating Contextual Bias in Aspect-Based Sentiment Analysis	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		aspect-based sentiment analysis; counterfactual inference; implicit sentiment		Pretrained language models (LMs) have made remarkable achievements in aspect-based sentiment analysis (ABSA). However, it is discovered that these models may struggle in some particular cases (e.g., to detect sentiments expressed towards targeted aspects with only implicit or adversarial expressions). Since it is hard for models to align implicit or adversarial expressions with their corresponding aspects, the sentiments of the targeted aspects would largely be impacted by the expressions towards other aspects in the sentence. We name this phenomenon as contextual bias. To tackle the problem, we propose a flexible aspect-oriented debiasing method (Arde) to eliminate the harmful contextual bias without the need of adjusting the underlying LMs. Intuitively, Arde calibrates the prediction towards the targeted aspect by subtracting the bias towards the context. Favorably, Arde can get theoretical support from counterfactual reasoning theory. Experiments are conducted on SemEval benchmark, and the results show that Arde can empirically improve the accuracy on contextually biased aspect sentiments without degrading the accuracy on unbiased ones. Driven by recent success of large language models (LLMs, e.g., ChatGPT), we further uncover that even LLMs can fail to address certain contextual bias, which yet can be effectively tackled by Arde.	[An, Ruize; Zhang, Chen; Song, Dawei] Beijing Inst Technol, Beijing, Peoples R China; [Song, Dawei] Open Univ, Milton Keynes, Bucks, England	Beijing Institute of Technology; Open University - UK	Song, DW (corresponding author), Beijing Inst Technol, Beijing, Peoples R China.; Song, DW (corresponding author), Open Univ, Milton Keynes, Bucks, England.	rz.an@bit.edu.cn; czhang@bit.edu.cn; dwsong@bit.edu.cn			Natural Science Foundation of China [62376027]; Beijing Municipal Natural Science Foundation [4222036, IS23061]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Municipal Natural Science Foundation(Beijing Natural Science Foundation)	This work is funded in part by the Natural Science Foundation of China (grant no: 62376027) and Beijing Municipal Natural Science Foundation (grant no: 4222036 and IS23061).	Cao JH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1599; Chen P, 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047; Chen SW, 2021, AAAI CONF ARTIF INTE, V35, P12666; Chen X, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3667; Dai JQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1816; Deng PF, 2022, Arxiv, DOI [arXiv:2209.02276, 10.48550/arXiv.2209.02276, DOI 10.48550/ARXIV.2209.02276]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng FL, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2226; Gao L, 2021, AAAI CONF ARTIF INTE, V35, P12875; He M, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4014, DOI 10.1145/3511808.3557558; Hou XC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2884; Hovy Eduard, 2020, ICLR; Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22; Li X, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P946; Li ZY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P246; Liu R, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1577, DOI 10.1145/3477495.3531938; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ma DH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4068; Ma F, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1352; Ma F, 2022, LECT NOTES ARTIF INT, V13551, P513, DOI 10.1007/978-3-031-17120-8_40; Mao Y, 2021, AAAI CONF ARTIF INTE, V35, P13543; Phan MH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3211; Pearl J, 2009, STAT SURV, V3, P96, DOI 10.1214/09-SS057; Peng HY, 2020, AAAI CONF ARTIF INTE, V34, P8600; Peper J., 2022, FINDINGS ASS COMPUTA, P6089; Pontiki M, 2014, P 8 INT WORKSH SEM E, P27, DOI [DOI 10.3115/V1/S14-2004, 10.3115/v1/s14-2004]; Qian Chen, 2021, P 59 ANN M ASS COMPU, V1, P5434, DOI DOI 10.18653/V1/2021.ACL-LONG.422; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Rietzler A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4933; Song YW, 2019, Arxiv, DOI arXiv:1902.09314; Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380; Sun T, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548211; Tang D., 2016, P 2016 C EMPIRICAL M, P214, DOI [DOI 10.18653/V1/D16-1021, 10.18653/v1/D16-1021]; Tang Hao, 2020, P 58 ACL, P6578, DOI DOI 10.18653/V1/2020.ACL-MAIN.588; Wang B, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P3002; Wang S., 2022, P 29 INT C COMP LING, P6966; Wang S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P957; Wei TX, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1791, DOI 10.1145/3447548.3467289; Wu Z, 2020, Arxiv, DOI arXiv:2010.04640; Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4166; Xing X, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3594; Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324; Xu M., 2022, P 29 INT C COMP LING, P6906; Xu WW, 2023, Arxiv, DOI [arXiv:2210.08855, 10.48550/arXiv.2210.08855, DOI 10.48550/ARXIV.2210.08855]; Xue W, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2514; Zhang C., 2022, P 29 INT C COMP LING, P6736; Zhang C, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P819; Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568; Zhang C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1145, DOI 10.1145/3331184.3331351	49	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56026-2; 978-3-031-56027-9	LECT NOTES COMPUT SC			2024	14608						90	107		10.1007/978-3-031-56027-9_6	http://dx.doi.org/10.1007/978-3-031-56027-9_6			18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DX					2024-07-03	WOS:001211830500006
J	Han, CL; Feng, JZ; Qi, HT				Han, Chunlong; Feng, Jianzhou; Qi, Haotian			Topic model for long document extractive summarization with sentence-level features and dynamic memory unit	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Extractive summarization; Long documents; Topic model; Long-range dependency		The Transformer-based summarization models rely solely on the attention mechanism for document encoding, making it difficult to accurately capture long-range dependencies in long documents due to the presence of attention redundancy. To address this issue, we propose an extractive summarization framework guided by a topic model (TopicSum) that utilizes a heterogeneous graph neural network to leverage the topic information as document-level features during the sentence selection process, thereby capturing the long-range dependencies among sentences. The sentence-level features in this topic model align with the basic unit of the extractive summarization task. Additionally, a memory mechanism is employed to dynamically store and update the memory module, reducing the potential of repetitive information guiding sentence selection. We evaluated the model on three large document datasets, namely Pubmed, arXiv, and GovReport, and achieved significantly higher Rouge scores than previous works, including extractive and abstractive models. Furthermore, our experiments demonstrate that recent highly regarded large language models such as ChatGPT are insufficient to handle the long document summarization task directly. The proposed approach in this paper exhibits sufficient competitiveness in terms of both generation quality and deployment conditions.	[Feng, Jianzhou] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China; Yanshan Univ, Key Lab Software Engn Hebei Prov, Qinhuangdao 066000, Hebei, Peoples R China	Yanshan University; Yanshan University	Feng, JZ (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066000, Hebei, Peoples R China.	202022040115@stumail.ysu.edu.cn; fjzwxh@ysu.edu.cn; qht666@stumail.ysu.edu.cn			National Natural Science Foundation of China [62172352]; Nature Scientist Foundation of Hebei Province, China [F2022203028]; Central Guidance on Local Sci-ence and Technology Development Fund, China [226Z0305G]; Key Laboratory for Software Engineering of Hebei Province, China [22567637H]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Nature Scientist Foundation of Hebei Province, China; Central Guidance on Local Sci-ence and Technology Development Fund, China; Key Laboratory for Software Engineering of Hebei Province, China	This work is supported by the National Natural Science Foundation of China (62172352) , the Nature Scientist Foundation of Hebei Province, China (F2022203028) , the Central Guidance on Local Science and Technology Development Fund, China (226Z0305G) and the Key Laboratory for Software Engineering of Hebei Province, China (22567637H) .	Bertsch A, 2023, Arxiv, DOI [arXiv:2305.01625, 10.48550/arXiv.2305.01625]; Bi K, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P281; Bian YC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P930; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cao S, 2023, arXiv, DOI [10.48550/arXiv.2305.14806, DOI 10.48550/ARXIV.2305.14806]; Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828; Clarke J, 2010, COMPUT LINGUIST, V36, P411, DOI 10.1162/coli_a_00004; Cohan Arman, 2018, P 2018 C N AM CHAPTE, V2, P615; Cui P, 2020, INT C COMP LING, DOI [10.48550/arXiv.2010.06253, DOI 10.48550/ARXIV.2010.06253]; Cui P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5881; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Dieng AB, 2020, T ASSOC COMPUT LING, V8, P439, DOI 10.1162/tacl_a_00325; Dong Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3739; Frermann L, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6263; Gidiotis A, 2020, IEEE-ACM T AUDIO SPE, V28, P3029, DOI 10.1109/TASLP.2020.3037401; Gu NL, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6507; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang L, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1419; Jia RP, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P366; Koh HY, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3545176; Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li W., 2020, P 58 ANN M ASS COMP, P6232, DOI 10.18653/v1/2020.acl-main.555; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu P, 2020, P 58 ANN M ASS COMPU, P6209, DOI DOI 10.18653/V1/2020.ACL-MAIN.553; Liu Y., 2021, Simcls: A simple framework for contrastive learning of abstractive summarization, P1065, DOI [10.48550/arXiv.1910.12840, DOI 10.48550/ARXIV.1910.12840]; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P146; Liu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2890; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mao ZM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1687; Miao YS, 2017, 34 INT C MACHINE LEA, V70; Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075; Nan Feng, 2021, Long Papers, V1, P6881; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayan Shashi, 2018, P 2018 C N AM CHAPT, P280, DOI [DOI 10.18653/V1/N18-1158, 10.18653/v1/N18-1158]; Parnell J, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5112; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pilault J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9308; Shao L., 2017, INT C LEARN REPR; Tas O., 2007, PressAcademia Procedia, V5, P205; Xiao W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5245; Xiao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3011; Xie Q., 2022, INT C COMP LING, DOI [10.48550/arXiv.2208.09982, DOI 10.48550/ARXIV.2208.09982]; Xu J, 2019, P 58 ANN M ASS COMP, P5021, DOI [10.18653/v1/2020.aclmain.451, DOI 10.18653/V1/2020]; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174; Zeng Z., 2023, arXiv, DOI [10.48550/arXiv.2305.04241, DOI 10.48550/ARXIV.2305.04241]; Zhang J., 2020, PMLR, P11328; Zhang NY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P15; Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P779; Zheng X, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3153; Zhong Ming, 2020, P 58 ANN M ASS COMPU, P6197, DOI [10.18653/v1/2020.acl-main.552, DOI 10.18653/V1/2020.ACL-MAIN.552]; Zhou QY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P654	54	0	0	6	12	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	MAR 15	2024	238		B						121873	10.1016/j.eswa.2023.121873	http://dx.doi.org/10.1016/j.eswa.2023.121873		OCT 2023	11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	X5HM2					2024-07-03	WOS:001098759200001
C	Sato, A; Chikazoe, J; Funai, S; Mochihashi, D; Shikano, Y; Asahara, M; Iso, S; Kobayashi, I		Iliadis, L; Papaleonidas, A; Angelov, P; Jayne, C		Sato, Anna; Chikazoe, Junichi; Funai, Shotaro; Mochihashi, Daichi; Shikano, Yutaka; Asahara, Masayuki; Iso, Satoshi; Kobayashi, Ichiro			Investigation of Information Processing Mechanisms in the Human Brain During Reading Tanka Poetry	ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, ICANN 2023, PT VIII	Lecture Notes in Computer Science		English	Proceedings Paper	32nd International Conference on Artificial Neural Networks (ICANN)	SEP 26-29, 2023	Heraklion, GREECE			Language Processing; Deep learning models; Neuroscience; fMRI; Emotion		Recent advances in non-invasive brain function measurement technologies, such as functional magnetic resonance imaging (fMRI) and magnetoencephalography (MEG), and the development of machine learning techniques, including deep learning, have led to increased research on the elucidation and quantitative understanding of information processing processes in the human brain. Since the emergence of word2vec, which represents the meaning of natural language words as vectors, features of language stimuli given to the human brain have been represented using large language models in natural language processing and used to estimate brain states. In this study, we used GPT-2, which is known to perform well as a feature for predicting brain states, and investigated the information processing processes in the human brain when reading Japanese short poems, i.e., tanka poetry. In particular, we investigated the hubness of the regions of interest in the brain by applying the PageRank algorithm. As a result, we have found that the cingulate cortex and the insula, which are said to be related to emotion, have hubness in brain regions, while occipital lobe, which are not said to be related to emotion, have also hubness.	[Sato, Anna; Kobayashi, Ichiro] Ochanomizu Univ, Tokyo, Japan; [Chikazoe, Junichi; Funai, Shotaro] Araya Inc, Tokyo, Japan; [Mochihashi, Daichi] Inst Stat Math, Tokyo, Japan; [Shikano, Yutaka] Gunma Univ, Maebashi, Gunma, Japan; [Shikano, Yutaka] Chapman Univ, Inst Quantum Studies, Orange, CA USA; [Asahara, Masayuki] Natl Inst Japanese Language & Linguist, Tokyo, Japan; [Iso, Satoshi] High Energy Accelerator Res Org, Tsukuba, Ibaraki, Japan	Ochanomizu University; Research Organization of Information & Systems (ROIS); Institute of Statistical Mathematics (ISM) - Japan; Gunma University; Chapman University System; Chapman University; High Energy Accelerator Research Organization (KEK)	Sato, A (corresponding author), Ochanomizu Univ, Tokyo, Japan.	g1920519@is.ocha.ac.jp; chikazoe_junichi@araya.org; funai_shotaro@araya.org; daichi@ism.ac.jp; yshikano@gunma-u.ac.jp; masayu-a@ninjal.ac.jp; iso@post.kek.jp; koba@is.ocha.ac.jp	Asahara, Masayuki/KMA-5183-2024; Shikano, Yutaka/D-5095-2009	Asahara, Masayuki/0000-0002-5178-7275; Shikano, Yutaka/0000-0003-2107-7536; Chikazoe, Junichi/0000-0003-4155-1370	Inter-University Research Institute Corporation (I-URIC); Cooperative Study Program of National Institute for Physiological Sciences (NIPS) [20-640, 21-543, 22NIPS630]; JSPS KAKENHI [21H05060, 21H05061]; JST MOONSHOT [JPMJMS2012]; JST PRESTO [JPMJPR20M4]	Inter-University Research Institute Corporation (I-URIC); Cooperative Study Program of National Institute for Physiological Sciences (NIPS)(National Institutes of Natural Sciences (NINS) - JapanNational Institute for Physiological Sciences (NIPS)); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); JST MOONSHOT; JST PRESTO(Japan Science & Technology Agency (JST))	This study was supported by Inter-University Research Institute Corporation (I-URIC) and the Cooperative Study Program (20-640, 21-543 and 22NIPS630) of National Institute for Physiological Sciences (NIPS). It was also supported by JSPS KAKENHI (21H05060 and 21H05061), JST MOONSHOT (JPMJMS2012) and JST PRESTO (JPMJPR20M4).	Amodei D., 2015, DEEP SPEECH 2 END TO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bush G, 2000, TRENDS COGN SCI, V4, P215, DOI 10.1016/S1364-6613(00)01483-2; Caucheteux C, 2021, bioRxiv, DOI [10.1101/2021.04.20.440622, 10.1101/2021.04.20.440622, DOI 10.1101/2021.04.20.440622]; Caucheteux C, 2020, bioRxiv, DOI [10.1101/2020.07.03.186288, 10.1101/2020.07.03.186288, DOI 10.1101/2020.07.03.186288]; Caucheteux C, 2023, NAT HUM BEHAV, DOI 10.1038/s41562-022-01516-2; Caucheteux C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20460-9; Caucheteux C, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03036-1; clrd.ninjal.ac, The balanced corpus of contemporary written Japanese; Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010; Dosovitskiy A, 2021, ICLR; Eickenberg M, 2017, NEUROIMAGE, V152, P184, DOI 10.1016/j.neuroimage.2016.10.001; Goldstein A., 2021, bioRxiv, DOI [10.1101/2020.12.02.403477, DOI 10.1101/2020.12.02.403477]; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Holdgraf CR, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00061; Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637; Jiang BB, 2017, BIOINFORMATICS, V33, P1829, DOI 10.1093/bioinformatics/btx029; Kawasaki H., 2022, FINDINGS ASS COMPUTA, P405; Kriegeskorte N, 2013, TRENDS COGN SCI, V17, P401, DOI 10.1016/j.tics.2013.06.007; Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008; Kurth F, 2010, BRAIN STRUCT FUNCT, V214, P519, DOI 10.1007/s00429-010-0255-z; Liu B, 2020, BRIEF BIOINFORM, V21, P298, DOI 10.1093/bib/bby104; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073; Page L., 1999, Technical report, DOI [10.1007/978-3-319-08789-4_10, DOI 10.1109/IISWC.2012.6402911]; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Schrimpf M, 2020, bioRxiv, DOI [10.1101/2020.06.26.174482, 10.1101/2020.06.26.174482, DOI 10.1101/2020.06.26.174482]; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Schwartz D, 2019, ADV NEUR IN, V32; Shackman AJ, 2011, NAT REV NEUROSCI, V12, P154, DOI 10.1038/nrn2994; Sutskever Ilya, 2022, OpenAI Blog; Tang J., 2022, bioRxiv, DOI [DOI 10.1101/2022.09.29.509744, 10.1101/2022.09.29.509744v1]; Thummerer A, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/abb1d6; Toneva M, 2020, Advances in neural information processing systems, V33, P5284; Uddin LQ, 2017, J CLIN NEUROPHYSIOL, V34, P300, DOI 10.1097/WNP.0000000000000377; Yu T., 2022, bioRxiv; Zeman A, 2013, J CONSCIOUSNESS STUD, V20, P132; Zhu Q, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.734711	41	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-44197-4; 978-3-031-44198-1	LECT NOTES COMPUT SC			2023	14261						407	418		10.1007/978-3-031-44198-1_34	http://dx.doi.org/10.1007/978-3-031-44198-1_34			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4YU					2024-07-03	WOS:001157297600034
J	Ly, CO; Unnikrishnan, B; Tadic, T; Patel, T; Duhamel, J; Kandel, S; Moayedi, Y; Brudno, M; Hope, A; Ross, H; Mcintosh, C				Ong Ly, Cathy; Unnikrishnan, Balagopal; Tadic, Tony; Patel, Tirth; Duhamel, Joe; Kandel, Sonja; Moayedi, Yasbanoo; Brudno, Michael; Hope, Andrew; Ross, Heather; Mcintosh, Chris			Shortcut learning in medical AI hinders generalization: method for estimating AI model generalization without external data	NPJ DIGITAL MEDICINE			English	Article								Healthcare datasets are becoming larger and more complex, necessitating the development of accurate and generalizable AI models for medical applications. Unstructured datasets, including medical imaging, electrocardiograms, and natural language data, are gaining attention with advancements in deep convolutional neural networks and large language models. However, estimating the generalizability of these models to new healthcare settings without extensive validation on external data remains challenging. In experiments across 13 datasets including X-rays, CTs, ECGs, clinical discharge summaries, and lung auscultation data, our results demonstrate that model performance is frequently overestimated by up to 20% on average due to shortcut learning of hidden data acquisition biases (DAB). Shortcut learning refers to a phenomenon in which an AI model learns to solve a task based on spurious correlations present in the data as opposed to features directly related to the task itself. We propose an open source, bias-corrected external accuracy estimate, P E s t , that better estimates external accuracy to within 4% on average by measuring and calibrating for DAB-induced shortcut learning.	[Ong Ly, Cathy; Duhamel, Joe; Moayedi, Yasbanoo; Ross, Heather; Mcintosh, Chris] Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada; [Ong Ly, Cathy; Duhamel, Joe; Moayedi, Yasbanoo; Ross, Heather; Mcintosh, Chris] Univ Hlth Network, Ted Rogers Ctr Heart Res, Toronto, ON, Canada; [Ong Ly, Cathy; Mcintosh, Chris] Univ Toronto, Dept Med Biophys, Toronto, ON, Canada; [Ong Ly, Cathy; Unnikrishnan, Balagopal; Mcintosh, Chris] Univ Hlth Network, Toronto Gen Hosp Res Inst, Toronto, ON, Canada; [Unnikrishnan, Balagopal; Brudno, Michael; Mcintosh, Chris] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Unnikrishnan, Balagopal; Kandel, Sonja; Mcintosh, Chris] Univ Hlth Network, Joint Dept Med Imaging, Toronto, ON, Canada; [Unnikrishnan, Balagopal; Brudno, Michael; Mcintosh, Chris] Vector Inst, Toronto, ON, Canada; [Tadic, Tony; Patel, Tirth; Hope, Andrew; Mcintosh, Chris] Univ Hlth Network, Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON, Canada; [Tadic, Tony; Hope, Andrew] Univ Toronto, Dept Radiat Oncol, Toronto, ON, Canada; [Brudno, Michael] Univ Hlth Network, Princess Margaret Canc Ctr, Toronto, ON, Canada; [Mcintosh, Chris] Univ Toronto, Dept Med Imaging, Toronto, ON, Canada	University of Toronto; University Health Network Toronto; Peter Munk Cardiac Centre; University of Toronto; University Health Network Toronto; University of Toronto; University of Toronto; University Health Network Toronto; University of Toronto; University of Toronto; University Health Network Toronto; Vector Institute for Artificial Intelligence; University of Toronto; University Health Network Toronto; Princess Margaret Cancer Centre; University of Toronto; University of Toronto; University Health Network Toronto; Princess Margaret Cancer Centre; University of Toronto	Mcintosh, C (corresponding author), Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Hlth Network, Ted Rogers Ctr Heart Res, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Toronto, Dept Med Biophys, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Hlth Network, Toronto Gen Hosp Res Inst, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Hlth Network, Joint Dept Med Imaging, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Vector Inst, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Hlth Network, Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON, Canada.; Mcintosh, C (corresponding author), Univ Toronto, Dept Med Imaging, Toronto, ON, Canada.	chris.mcintosh@uhn.ca		McIntosh, Chris/0000-0003-1371-1250	CM NSERC [RGPIN-2022-05117, DGECR-2022-00137]; Chair in Medical Imaging at the Joint Department of Medical Imaging at the University Health Network; CIFAR AI Chair; Loretta Rogers Chair in Heart Function	CM NSERC; Chair in Medical Imaging at the Joint Department of Medical Imaging at the University Health Network; CIFAR AI Chair; Loretta Rogers Chair in Heart Function	This study was funded in part by CM NSERC funding RGPIN-2022-05117 and DGECR-2022-00137. CM holds the Chair in Medical Imaging at the Joint Department of Medical Imaging at the University Health Network, and the Department of Medical Imaging at the University of Toronto. MB is a CIFAR AI Chair. HR is the Loretta Rogers Chair in Heart Function. No funding entity was involved with the study design; the data collection, analysis, or interpretation; the writing of the report; or in the decision to submit this paper for publication.	[Anonymous], COVID 19 RADIOGRAPHY; [Anonymous], ROC-Utils python package provides tools to compute and visualize roc curves; Brown A, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-39902-7; DeGrave AJ, 2021, NAT MACH INTELL, V3, P610, DOI 10.1038/s42256-021-00338-7; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dou Q, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00431-6; Flores Mona., 2021, Federated learning used for predicting outcomes in sars-cov-2 patients; Fraiwan M, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106913; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Glocker B., 2019, P ABSTR MED IM MEETS; Honnibal M., 2017, IN PRESS, DOI DOI 10.1145/2566486.2568003; Howard FM, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24698-1; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang K, 2020, Clinicalbert: Modeling clinical notes and predicting hospital readmission; Irvin J, 2019, AAAI CONF ARTIF INTE, P590; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Johnson TS, 2019, BIOINFORMATICS, V35, P4696, DOI 10.1093/bioinformatics/btz295; Johnson WE, 2007, BIOSTATISTICS, V8, P118, DOI 10.1093/biostatistics/kxj037; Kalyakulina AI, 2020, IEEE ACCESS, V8, P186181, DOI 10.1109/ACCESS.2020.3029211; Kulinski D., 2023, INT C MACHINE LEARNI, P17931; Leek JT, 2012, BIOINFORMATICS, V28, P882, DOI 10.1093/bioinformatics/bts034; Leek JT, 2010, NAT REV GENET, V11, P733, DOI 10.1038/nrg2825; Olivetti E, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00070; Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319; Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0; Rocha BM, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab03ea; Schmitt M, 2021, J MED INTERNET RES, V23, DOI 10.2196/23436; Seyyed-Kalantari L, 2021, NAT MED, V27, P2176, DOI 10.1038/s41591-021-01595-0; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Solanes A, 2021, PSYCHIAT RES-NEUROIM, V314, DOI 10.1016/j.pscychresns.2021.111313; U.S. Food and Drug Administration Health Canada & United Kingdom's Medicines and Healthcare products Regulatory Agency, 2021, Good Machine Learning Practice for Medical Device Development: Guiding Principles; Wagner P, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0495-6; Wang X., ChestX-ray8: Hospital-Scale Chest XRay Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases; Wong A, 2021, JAMA INTERN MED, V181, P1065, DOI 10.1001/jamainternmed.2021.2626; Yu AC, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210064; Zhang YQ, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2263-6	37	0	0	2	2	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	MAY 14	2024	7	1							124	10.1038/s41746-024-01118-4	http://dx.doi.org/10.1038/s41746-024-01118-4			10	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	QR5X0	38744921	gold			2024-07-03	WOS:001222621300001
J	Lin, KC; Chen, TA; Lin, MH; Chen, YC; Chen, TJ				Lin, Kuan-Chen; Chen, Tsung-An; Lin, Ming-Hwai; Chen, Yu-Chun; Chen, Tzeng-Ji			Integration and Assessment of ChatGPT in Medical Case Reporting: A Multifaceted Approach	EUROPEAN JOURNAL OF INVESTIGATION IN HEALTH PSYCHOLOGY AND EDUCATION			English	Article						artificial intelligence; case reports; LLM; clinical thinking; medical writing; health science		ChatGPT, a large language model, has gained significance in medical writing, particularly in case reports that document the course of an illness. This article explores the integration of ChatGPT and how ChatGPT shapes the process, product, and politics of medical writing in the real world. We conducted a bibliometric analysis on case reports utilizing ChatGPT and indexed in PubMed, encompassing publication information. Furthermore, an in-depth analysis was conducted to categorize the applications and limitations of ChatGPT and the publication trend of application categories. A total of 66 case reports utilizing ChatGPT were identified, with a predominant preference for the online version and English input by the authors. The prevalent application categories were information retrieval and content generation. Notably, this trend remained consistent across different months. Within the subset of 32 articles addressing ChatGPT limitations in case report writing, concerns related to inaccuracies and a lack of clinical context were prominently emphasized. This pointed out the important role of clinical thinking and professional expertise, representing the foundational tenets of medical education, while also accentuating the distinction between physicians and generative artificial intelligence.	[Lin, Kuan-Chen; Chen, Tsung-An; Lin, Ming-Hwai; Chen, Yu-Chun] Taipei Vet Gen Hosp, Dept Family Med, 201,Sec 2,Shih Pai Rd, Taipei 11217, Taiwan; [Lin, Ming-Hwai; Chen, Yu-Chun] Natl Yang Ming Chiao Tung Univ, Sch Med, Taipei 30010, Taiwan; [Chen, Yu-Chun] Natl Yang Ming Chiao Tung Univ, Inst Hosp & Hlth Care Adm, Sch Med, Taipei 30010, Taiwan; [Chen, Yu-Chun] Taipei Vet Gen Hosp, Big Data Ctr, Taipei 11217, Taiwan; [Chen, Tzeng-Ji] Taipei Vet Gen Hosp, Hsinchu Branch, Dept Family Med, 81,Sec 1,Zhongfeng Rd, Hsinchu 310403, Taiwan; [Chen, Tzeng-Ji] Natl Chung Hsing Univ, Dept Postbaccalaureate Med, 145 Xingda Rd, Taichung 402202, Taiwan	Taipei Veterans General Hospital; National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung University; Taipei Veterans General Hospital; Taipei Veterans General Hospital; National Chung Hsing University	Chen, YC (corresponding author), Taipei Vet Gen Hosp, Dept Family Med, 201,Sec 2,Shih Pai Rd, Taipei 11217, Taiwan.; Chen, YC (corresponding author), Natl Yang Ming Chiao Tung Univ, Sch Med, Taipei 30010, Taiwan.; Chen, YC (corresponding author), Natl Yang Ming Chiao Tung Univ, Inst Hosp & Hlth Care Adm, Sch Med, Taipei 30010, Taiwan.; Chen, YC (corresponding author), Taipei Vet Gen Hosp, Big Data Ctr, Taipei 11217, Taiwan.; Chen, TJ (corresponding author), Taipei Vet Gen Hosp, Hsinchu Branch, Dept Family Med, 81,Sec 1,Zhongfeng Rd, Hsinchu 310403, Taiwan.; Chen, TJ (corresponding author), Natl Chung Hsing Univ, Dept Postbaccalaureate Med, 145 Xingda Rd, Taichung 402202, Taiwan.	s10001002@gm.ym.edu.tw; firen8056@gmail.com; minghwai@gmail.com; yuchn.chen@gmail.com; tjchen@vhct.gov.tw	Chen, TJ/AAH-8430-2021; Chen, Yu-Chun/B-1227-2012	Chen, TJ/0000-0002-8350-0232; Lin, Ming-Hwai/0000-0001-6825-6692; Chen, Yu-Chun/0000-0002-4124-1949	Taipei Veterans General Hospital	Taipei Veterans General Hospital(Taipei Veterans General Hospital)	No Statement Available	Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Barrot JS, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100745; Bosbach WA, 2024, CURR PROBL DIAGN RAD, V53, P102, DOI 10.1067/j.cpradiol.2023.04.001; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Fournier-Tombs E, 2023, J MED INTERNET RES, V25, DOI 10.2196/43068; Gupta R, 2023, J PLAST RECONSTR AES, V80, P145, DOI 10.1016/j.bjps.2023.03.004; Haque M.A., 2023, EAI Endorsed Trans. AI Robot, V1, pe15, DOI [10.4108/airo.v1i1.2983, DOI 10.4108/AIRO.V1I1.2983]; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Lingard L, 2023, PERSPECT MED EDUC, V12, P261, DOI 10.5334/pme.1072; Liu HH, 2023, HEALTH INFO LIBR J, V40, P440, DOI 10.1111/hir.12509; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Loh E, 2024, BMJ LEAD, V8, P51, DOI 10.1136/leader-2023-000797; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mijwil M. M., 2023, Al-Salam Journal for Engineering and Technology, V2, P116, DOI DOI 10.55145/AJEST.2023.02.02.015; Nakagawa K, 2023, SEMIN DIAGN PATHOL, V40, P100, DOI 10.1053/j.semdp.2023.02.006; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Preiksaitis C, 2023, NAT MED, V29, P1296, DOI 10.1038/s41591-023-02341-4; Rahman M., 2023, Journal of Education, Management and Development Studies, V3, P1, DOI [10.52631/jemds.v3i1.175, DOI 10.52631/JEMDS.V3I1.175]; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Ricci FL, 2022, IEEE T LEARN TECHNOL, V15, P167, DOI 10.1109/TLT.2022.3157391; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Seth I, 2023, J Orthop Sports Med., V5, P112, DOI [10.26502/josm.511500088, DOI 10.26502/JOSM.511500088]; Singh H, 2023, J CHIN ECON BUS STUD, V21, P193, DOI 10.1080/14765284.2023.2210482; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Sirrianni J, 2022, METHOD INFORM MED, V61, P195, DOI 10.1055/a-1900-7351; Srivastava M., 2023, OSF Prepr, DOI [10.31219/osf.io/wydct, DOI 10.31219/OSF.IO/WYDCT]; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Su YF, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100752; Tenhundfeld N.L., Two Birds with One Stone: Writing a Paper Entitled 'ChatGPT as a Tool for Studying Human-AI Interaction in the Wild' with ChatGPT; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Waisberg E, 2023, ANN BIOMED ENG, V51, P2353, DOI 10.1007/s10439-023-03263-5; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Yang J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116355; Zheng HY, 2023, AM J MED, V136, P725, DOI 10.1016/j.amjmed.2023.02.011; Zohery M., 2023, Artificial Intelligence in Academia, Research and Science: ChatGPT as a Case Study, P10	43	0	0	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2254-9625		EUR J INVEST HEALTH	Eur. J. Invest. Health Psychol. Educ.	APR	2024	14	4					888	901		10.3390/ejihpe14040057	http://dx.doi.org/10.3390/ejihpe14040057			14	Psychology, Clinical	Emerging Sources Citation Index (ESCI)	Psychology	OV2G3	38667812	Green Published, gold			2024-07-03	WOS:001209983500001
C	Joshi, I; Budhiraja, R; Dev, H; Kadia, J; Ataullah, MO; Mitra, S; Akolekar, HD; Kumar, D			Assoc Computing Machinery	Joshi, Ishika; Budhiraja, Ritvik; Dev, Harshal; Kadia, Jahnvi; Ataullah, Mohammad Osama; Mitra, Sayan; Akolekar, Harshal D.; Kumar, Dhruv			ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		ChatGPT; computer science; education		This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.	[Joshi, Ishika; Budhiraja, Ritvik; Dev, Harshal; Kadia, Jahnvi; Ataullah, Mohammad Osama; Mitra, Sayan; Kumar, Dhruv] IIIT Delhi, New Delhi, India; [Akolekar, Harshal D.] IIT Jodhpur, Dept Mech Eng, Jodhpur, Rajasthan, India; [Akolekar, Harshal D.] IIT Jodhpur, Sch AIDE, Jodhpur, Rajasthan, India	Indraprastha Institute of Information Technology Delhi; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Jodhpur; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Jodhpur	Joshi, I (corresponding author), IIIT Delhi, New Delhi, India.	ishika19310@iiitd.ac.in; ritvik19322@iiitd.ac.in; harshal19306@iiitd.ac.in; jahnvi21123@iiitd.ac.in; osama21127@iiitd.ac.in; sayan21142@iiitd.ac.in; harshal.akolekar@iitj.ac.in; dhruv.kumar@iiitd.ac.in		Dev, Harshal/0009-0008-5176-6205; Akolekar, Harshal/0000-0002-3178-2987; Joshi, Ishika/0009-0000-8384-2155; Kumar, Dhruv/0000-0003-4831-1847				[Anonymous], 2023, The Economic Times ,Mar.; Balse R, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P292, DOI 10.1145/3587102.3588852; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Cipriano BP, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P61, DOI 10.1145/3587102.3588814; Daun M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P110, DOI 10.1145/3587102.3588815; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; GUPTA P., 2023, Chatgpt for Designing Course Outlines: A Boon or Bane to Modern Technology; KABIR S., 2023, Who answers it better? an in-depth analysis of chatgpt and stack overflow answers to software engineering questions; Kangas V, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P106, DOI 10.1145/3300115.3309516; Leinonen J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P124, DOI 10.1145/3587102.3588785; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Malinka K, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P47, DOI 10.1145/3587102.3588827; Oh LB, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P239, DOI 10.1145/3300115.3312516; OpenAI, 2022, Introducing chatgpt; Ouh EL, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P54, DOI 10.1145/3587102.3588794; Reactions, 2023, Princeton faculty discuss ChatGPT in the classroom; Reeves B, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P299, DOI 10.1145/3587102.3588805; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P117, DOI 10.1145/3587102.3588792; SHANKLAND S., 2023, AI Chatbot; Sharmin S, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P215, DOI 10.1145/3300115.3309532; Shen RQ, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P2, DOI 10.1145/3300115.3309506; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; THE LEARNING NETWORK N. Y. T, 2023, The New York Times ,Feb.; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830; Zhang JH, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P241, DOI 10.1145/3300115.3312511	30	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							625	631		10.1145/3626252.3630803	http://dx.doi.org/10.1145/3626252.3630803			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		hybrid, Green Submitted			2024-07-03	WOS:001181240800092
C	Markovic, D		Vilka, L; Krumina, J		Markovic, Daniel			Current options and limits of digital technologies and artificial intelligence in social work	9TH INTERNATIONAL MULTIDISCIPLINARY RESEARCH CONFERENCE SOCIETY. HEALTH. WELFARE	SHS Web of Conferences		English	Proceedings Paper	9th International Multidisciplinary Research Conference - Society Health Welfare	MAR 29-31, 2023	Riga Stradins Univ, Riga, LATVIA		Riga Stradins Univ	chatbot; social work; digital technologies; Chat GPT		At the end of the second decade of the 21st century, it was accepted that robots and technology would replace mainly blue-collar and routine jobs, while professionals in human well-being and creativity would be needed in greater numbers. New tools like AI large language models, which are at the beginning of an exponential trajectory of their development, have changed the way digitization is viewed; people employed in activities such as writing as well as administrative and clerical work have started to lose their jobs. Will technologies become aids and supplements to services, or can they replace social workers? The paper aims to analyse the current limits of artificial intelligence in social work and summarize digital platforms useful for social work practice. The methods used are the analysis of literature and statistics and an experiment with artificial intelligence. Language model Chat GPT passed the state final examination for the bachelor's degree in social work in Slovakia. It received a grade of B on the ECTS grading scale.	[Markovic, Daniel] Catholic Univ Ruzomberok, Ruzomberok, Slovakia	Catholic University Ruzomberok	Markovic, D (corresponding author), Catholic Univ Ruzomberok, Ruzomberok, Slovakia.	daniel.markovic@ku.sk	Markovic, Daniel/ABF-4801-2020	Markovic, Daniel/0000-0002-3526-903X				Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Berzin S.C., 2015, Practice innovation through technology in the digital age: A grand challenge for social work; Brown JEH, 2021, SSM-MENT HEALTH, V1, DOI 10.1016/j.ssmmh.2021.100017; Castillo De Mesa J., 2021, Groupwork, V29, P5; Coghlan S, 2022, INT J SOC ROBOT, V14, P2095, DOI 10.1007/s12369-021-00804-7; Robles YMD, 2019, EUR J SOC WORK, V22, P623, DOI 10.1080/13691457.2018.1423550; Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019; Gdovinova D., 2020, Dennik NSep. 18,; Gloss A, 2012, HUMANITARIAN WORK PSYCHOLOGY, P293; Haque MDR, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/44838; ISSA, 2021, The application of chatbots in social security: Experiences from Latin America; Jackson R., 2019, Social media and social service workers; Marquart M. S., 2023, VIRTUAL SESSION 2023, DOI [10.7916/axhj-x577, DOI 10.7916/AXHJ-X577]; Parrish DE, 2016, RES SOCIAL WORK PRAC, V26, P825, DOI 10.1177/1049731514568897; Rafferty J., 2007, Social Work: A Companion to Learning, P165; Reamer FG, 2013, SOC WORK, V58, P163, DOI 10.1093/sw/swt003; Singer JB, 2023, J SOC WORK EDUC, V59, P294, DOI 10.1080/10437797.2023.2189878; Smutek M., 17 HRADECKE DNY SOCI; Sweeney Colm, 2021, ACM Transactions on Computing and Healthcare, V2, DOI 10.1145/3453175; van Dijk JAGM, 2006, POETICS, V34, P221, DOI 10.1016/j.poetic.2006.05.004; Victor BG, 2023, RES SOCIAL WORK PRAC, V33, P511, DOI 10.1177/10497315231166125	21	0	0	3	3	E D P SCIENCES	CEDEX A	17 AVE DU HOGGAR PARC D ACTIVITES COUTABOEUF BP 112, F-91944 CEDEX A, FRANCE	2261-2424			SHS WEB CONF			2024	184								05003	10.1051/shsconf/202418405003	http://dx.doi.org/10.1051/shsconf/202418405003			9	Health Policy & Services; Public, Environmental & Occupational Health; Social Work	Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Health Care Sciences & Services; Public, Environmental & Occupational Health; Social Work	BW7TL		gold			2024-07-03	WOS:001196331000028
J	Medeiros, T; Medeiros, M; Azevedo, M; Silva, M; Silva, I; Costa, DG				Medeiros, Thais; Medeiros, Morsinaldo; Azevedo, Mariana; Silva, Marianne; Silva, Ivanovitch; Costa, Daniel G.			Analysis of Language-Model-Powered Chatbots for Query Resolution in PDF-Based Automotive Manuals	VEHICLES			English	Article						chatbot; vehicle manuals; PDFs; generative AI		In the current scenario of fast technological advancement, increasingly characterized by widespread adoption of Artificial Intelligence (AI)-driven tools, the significance of autonomous systems like chatbots has been highlighted. Such systems, which are proficient in addressing queries based on PDF files, hold the potential to revolutionize customer support and post-sales services in the automotive sector, resulting in time and resource optimization. Within this scenario, this work explores the adoption of Large Language Models (LLMs) to create AI-assisted tools for the automotive sector, assuming three distinct methods for comparative analysis. For them, broad assessment criteria are considered in order to encompass response accuracy, cost, and user experience. The achieved results demonstrate that the choice of the most adequate method in this context hinges on the selected criteria, with different practical implications. Therefore, this work provides insights into the effectiveness and applicability of chatbots in the automotive industry, particularly when interfacing with automotive manuals, facilitating the implementation of productive generative AI strategies that meet the demands of the sector.	[Medeiros, Thais; Medeiros, Morsinaldo; Azevedo, Mariana; Silva, Marianne; Silva, Ivanovitch] Univ Fed Rio Grande do Norte, Postgrad Program Elect & Comp Engn, UFRN PPgEEC, BR-59078970 Natal, Brazil; [Costa, Daniel G.] Univ Porto, Fac Engn, INEGI, P-4200465 Porto, Portugal	Universidade Federal do Rio Grande do Norte; Universidade do Porto	Silva, M; Silva, I (corresponding author), Univ Fed Rio Grande do Norte, Postgrad Program Elect & Comp Engn, UFRN PPgEEC, BR-59078970 Natal, Brazil.	thais.araujo.707@ufrn.edu.br; morsinaldo.medeiros.075@ufrn.edu.br; mariana.brito110@ufrn.edu.br; marianne.silva@ufrn.br; ivanovitch.silva@ufrn.br; danielgcosta@fe.up.pt	Silva, Ivanovitch/N-8075-2019; Costa, Daniel G./I-4928-2013; Medeiros, Morsinaldo/KFR-6834-2024	Silva, Ivanovitch/0000-0002-0116-6489; Costa, Daniel G./0000-0003-3988-8476; Medeiros, Morsinaldo/0000-0001-7624-5301; de Araujo de Medeiros, Thais/0000-0002-6447-3806; Silva, Marianne/0000-0002-8277-7571; Azevedo, Mariana/0000-0003-4609-8800	Brazilian fostering agency CNPq (National Council for Scientific and Technological Development); National Council for Scientific and Technological Development (CNPq)	Brazilian fostering agency CNPq (National Council for Scientific and Technological Development)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); National Council for Scientific and Technological Development (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ))	We thank National Council for Scientific and Technological Development (CNPq).	Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Aljelawy Q.M., 2023, Bull. Electr. Eng. Inform, V12, P2236, DOI [10.11591/eei.v12i4.4990, DOI 10.11591/EEI.V12I4.4990]; Allahyari M., Leveraging LangChain and Large Language Models for Accurate PDF-Based Question Answering; API O, OpenAI API; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Boukhers Z, 2022, ACM-IEEE J CONF DIG, DOI 10.1145/3529372.3533295; Celsi LR, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2145639; Channabasamma, 2021, Inventive Computation and Information Technologies. Proceedings of ICICIT 2020. Lecture Notes in Networks and Systems (LNNS 173), P395, DOI 10.1007/978-981-33-4305-4_30; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; da Silva MBD, 2018, IEEE SYMP COMP COMMU, P1249, DOI 10.1109/ISCC.2018.8538554; Documentation S, Streamlit Documentation; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Francis J, 2023, TRANSPORT RES REC, V2677, P1579, DOI 10.1177/03611981221125744; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Ghosh Ramyani, 2022, ICT Systems and Sustainability: Proceedings of ICT4SD 2021. Lecture Notes in Networks and Systems (321), P327, DOI 10.1007/978-981-16-5987-4_33; Gill Sukhpal Singh, 2023, Internet Things Cyber-Phys. Syst, V3, P262, DOI DOI 10.1016/J.IOTCPS.2023.05.004; github, AO A., Langchain Ask PDF (Tutorial); Hong D, 2023, INT J HUM-COMPUT INT, V39, P2557, DOI 10.1080/10447318.2022.2080899; Huang Y., How To Create A Doc ChatBot That Learns Everything For You, In 15 Minutes; huggingface, Documentation H.F., All-Mpnet-Base-v2; Jiménez S, 2022, LECT NOTE NETW SYST, V468, P336, DOI 10.1007/978-3-031-04826-5_33; Jindal A, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120127; langchain, Documentation L., Introduction; Lee PL, 2023, J BUS PSYCHOL, V38, P163, DOI 10.1007/s10869-022-09864-6; Liu J., LlamaIndex; Muñoz-Basols J, 2023, HISPANIA-J DEV INTER, V106, P171; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Peyton K, 2023, RESULTS ENG, V17, DOI 10.1016/j.rineng.2022.100856; Pricing O., OpenAI Pricing; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rubleva O., 2023, Proceedings of the AIP Conference Proceedings, V2700; Shinde PP, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA); Silva M., 2022, P IECON 2022 48 ANN, P1	35	0	0	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2624-8921		VEHICLES-BASEL	Vehicles	DEC	2023	5	4					1384	1399		10.3390/vehicles5040076	http://dx.doi.org/10.3390/vehicles5040076			16	Engineering, Mechanical; Transportation Science & Technology	Emerging Sources Citation Index (ESCI)	Engineering; Transportation	DH3A7		gold			2024-07-03	WOS:001131087100001
J	Wiemken, TL; Carrico, RM				Wiemken, Timothy L.; Carrico, Ruth M.			Assisting the infection preventionist: Use of artificial intelligence for health care-associated infection surveillance	AMERICAN JOURNAL OF INFECTION CONTROL			English	Article						Machine learning; AI agent; GPT; Mistral; Case definition		Background: Health care-associated infection (HAI) surveillance is vital for safety in health care settings. It helps identify infection risk factors, enhancing patient safety and quality improvement. However, HAI surveillance is complex, demanding specialized knowledge and resources. This study investigates the use of artificial intelligence (AI), particularly generative large language models, to improve HAI surveillance. Methods: We assessed 2 AI agents, OpenAI's chatGPT plus (GPT-4) and a Mixtral 8x7b -based local model, for their ability to identify Central Line -Associated Bloodstream Infection (CLABSI) and Catheter -Associated Urinary Tract Infection (CAUTI) from 6 National Health Care Safety Network training scenarios. The complexity of these scenarios was analyzed, and responses were matched against expert opinions. Results: Both AI models accurately identified CLABSI and CAUTI in all scenarios when given clear prompts. Challenges appeared with ambiguous prompts including Arabic numeral dates, abbreviations, and special characters, causing occasional inaccuracies in repeated tests. Discussion: The study demonstrates AI's potential in accurately identifying HAIs like CLABSI and CAUTI. Clear, specific prompts are crucial for reliable AI responses, highlighting the need for human oversight in AIassisted HAI surveillance. Conclusions: AI shows promise in enhancing HAI surveillance, potentially streamlining tasks, and freeing health care staff for patient -focused activities. Effective AI use requires user education and ongoing AI model refinement. (c) 2024 Association for Professionals in Infection Control and Epidemiology, Inc. Published by Elsevier Inc. All rights reserved.	[Wiemken, Timothy L.] St Louis Univ, Sch Med, Dept Med, Div Infect Dis Allergy & Immunol, St Louis, MO USA; [Carrico, Ruth M.] Univ Louisville, Sch Med, Dept Med, Div Infect Dis, Louisville, KY USA; [Wiemken, Timothy L.] Dept Med, Div Infect Dis Allergy & Immunol, 1100 S Grand Blvd, St Louis, MO 63104 USA	Saint Louis University; University of Louisville	Wiemken, TL (corresponding author), Dept Med, Div Infect Dis Allergy & Immunol, 1100 S Grand Blvd, St Louis, MO 63104 USA.	tim.wiemken@gmail.com						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], NATL HEALTHCARE SAFE; Barchitta M, 2021, J HOSP INFECT, V112, P77, DOI 10.1016/j.jhin.2021.02.025; Beeler C, 2018, AM J INFECT CONTROL, V46, P986, DOI 10.1016/j.ajic.2018.02.021; Centers for Medicare and Medicaid Services, 2024, Find & compare providers near you.; chroma. chroma, the AInative open-source embedding database; DNV, Healthcare Standards & Requirements; dos Santos RP, 2021, INFECT PREV PRACT, V3, DOI 10.1016/j.infpip.2021.100167; Gilmartin H, 2021, AM J INFECT CONTROL, V49, P70, DOI 10.1016/j.ajic.2020.07.024; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Knighton SC, 2024, AM J INFECT CONTROL, V52, P91, DOI 10.1016/j.ajic.2023.06.017; Lewis P., 2020, arXiv; Liao YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081866; Medicine NEJo, NEJM AI; Microsoft, 2024, Artificial intelligence (AI) vs. machine learning (ML); Montella E, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19052498; Morgan J., Ollama.; Pai KC, 2021, J CLIN MED, V10, DOI 10.3390/jcm10132901; Scardoni A, 2020, J INFECT PUBLIC HEAL, V13, P1061, DOI 10.1016/j.jiph.2020.06.006; Shenoy ES, 2023, Antimicrob Steward Healthc Epidemiol., V3, P25; Streamlit, Streamlit: a faster way to build and share data apps; Tariq A, 2023, J AM MED INFORM ASSN, V30, P1056, DOI 10.1093/jamia/ocad045; The Joint Commission, New and Revised Requirements for the "Infection Prevention and Control; USAID Medicines T and Pharmaceutical Services (MTaPS) Program., 2021, A Technical Guide to Implementing a Continuous Quality Improvement Approach to Strengthen Infection Prevention and Control Programs at Health Facilities in MTaPS Program Countries; VR G., 2023, FL DJ. Python.; Wiemken T, 2024, HAI Assist., V1	26	0	0	3	3	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0196-6553	1527-3296		AM J INFECT CONTROL	Am. J. Infect. Control	JUN	2024	52	6					625	629		10.1016/j.ajic.2024.02.007	http://dx.doi.org/10.1016/j.ajic.2024.02.007			5	Public, Environmental & Occupational Health; Infectious Diseases	Science Citation Index Expanded (SCI-EXPANDED)	Public, Environmental & Occupational Health; Infectious Diseases	TH8Q7	38483430				2024-07-03	WOS:001240471100001
J	Michaelov, JA; Bergen, BK				Michaelov, James A.; Bergen, Benjamin K.			Special Issue "Strengthening Derivation Chains in Cognitive Neuroscience": Ignoring the alternatives: The N400 is sensitive to stimulus preactivation alone	CORTEX			English	Article						Human language comprehension; Cognitive modeling; Event-related brain potentials; Natural language processing	EVENT KNOWLEDGE ACTIVATION; LANGUAGE COMPREHENSION; SENTENCE CONTEXT; BRAIN POTENTIALS; SEMANTIC CONTEXT; WORD-FREQUENCY; PREDICTION; INFORMATION; ERP; MEMORY	The N400 component of the event-related brain potential is a neural signal of processing difficulty. In the language domain, it is widely believed to be sensitive to the degree to which a given word or its semantic features have been preactivated in the brain based on the preceding context. However, it has also been shown that the brain often preactivates many words in parallel. It is currently unknown whether the N400 is also affected by the preactivations of alternative words other than the stimulus that is actually presented. This leaves a weak link in the derivation chaindhow can we use the N400 to understand the mechanisms of preactivation if we do not know what it indexes? This study directly addresses this gap. We estimate the extent to which all words in a lexicon are preactivated in a given context using the predictions of contemporary large language models. We then directly compare two competing possibilities: that the amplitude of the N400 is sensitive only to the extent to which the stimulus is preactivated, and that it is also sensitive to the preactivation states of the alternatives. We find evidence of the former. This result allows for better grounded inferences about the mechanisms underlying the N400, lexical pre activation in the brain, and language processing more generally.(c) 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	[Michaelov, James A.; Bergen, Benjamin K.] Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Michaelov, JA (corresponding author), Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA.	j1michae@ucsd.edu; bkbergen@ucsd.edu		Michaelov, James/0000-0003-2913-1103	Center for Academic Research and Training in Anthropogeny	Center for Academic Research and Training in Anthropogeny	<B>Acknowledgments</B> This work was partially supported by the Center for Academic Research and Training in Anthropogeny [Annette Merle-Smith Fellowship] .	Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Akaike H., 1973, P 2 INT S INFORM THE, P267, DOI [10.1007/978-1-4612-0919-5_38, 10.1007/978-1-4612-1694-0, DOI 10.1007/978-1-4612-1694-0_15]; Ambridge B, 2014, LANGUAGE, V90, pE53, DOI 10.1353/lan.2014.0051; Amsel BD, 2015, J MEM LANG, V82, P118, DOI 10.1016/j.jml.2015.03.009; [Anonymous], 2019, Language Models are Unsupervised Multitask Learners, DOI DOI 10.18653/V1/W18-5019; [Anonymous], 2011, Predictions in the brain: Using our past to generate a future, DOI DOI 10.1093/ACPROF:OSO/9780195395518.003.0065; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Biderman S., 2023, arXiv; Bolukbasi T, 2016, ADV NEUR IN, V29; Bornkessel-Schlesewsky I, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00298; Brodbeck C, 2022, ELIFE, V11, DOI [10.7554/eLife.72056, 10.7554/eLife.72056.sa0, 10.7554/eLife.72056.sa1, 10.7554/eLife.72056.sa2]; Brothers T, 2021, J MEM LANG, V116, DOI 10.1016/j.jml.2020.104174; Brouwer H, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00758; Brouwer H, 2012, BRAIN RES, V1446, P127, DOI 10.1016/j.brainres.2012.01.055; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brysbaert M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01116; Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644; Christoph A, 2019, NEUROPSYCHOLOGIA, V134, DOI 10.1016/j.neuropsychologia.2019.107198; Chwilla DJ, 2005, COGNITIVE BRAIN RES, V25, P589, DOI 10.1016/j.cogbrainres.2005.08.011; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Dambacher M, 2006, BRAIN RES, V1084, P89, DOI 10.1016/j.brainres.2006.02.010; de Lange FP, 2018, TRENDS COGN SCI, V22, P764, DOI 10.1016/j.tics.2018.06.002; de Marneffe MC, 2012, LANG COGNITIVE PROC, V27, P25, DOI 10.1080/01690965.2010.542651; Debruille JB, 2007, BRAIN RES REV, V56, P472, DOI 10.1016/j.brainresrev.2007.10.001; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Delogu F, 2019, BRAIN COGNITION, V135, DOI 10.1016/j.bandc.2019.05.007; DeLong KA, 2020, LANG COGN NEUROSCI, V35, P1044, DOI 10.1080/23273798.2019.1708960; DeLong KA, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13312; DeLong KA, 2014, LANG LINGUIST COMPAS, V8, P631, DOI 10.1111/lnc3.12093; Dey N., 2023, arXiv; Dumais S. T., 1988, P SIGCHI C HUM FACT, P281, DOI DOI 10.1145/57167.57214; Elman JL, 2009, COGNITIVE SCI, V33, P547, DOI 10.1111/j.1551-6709.2009.01023.x; Ettinger A., 2016, Proceedings of the 38th annual conference of the Cognitive Science Society; Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101; Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x; Federmeier KD, 2022, PSYCHOPHYSIOLOGY, V59, DOI 10.1111/psyp.13940; Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660; Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133; Fischer-Baum S, 2014, LANG COGN NEUROSCI, V29, P1342, DOI 10.1080/23273798.2014.927067; Fitz H, 2019, COGNITIVE PSYCHOL, V111, P15, DOI 10.1016/j.cogpsych.2019.03.002; Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006; Gerken L, 2006, COGNITION, V98, pB67, DOI 10.1016/j.cognition.2005.03.003; Gerken LuAnn., 2007, The Blackwell Handbook of Language Development, P173; Gibbs AL, 2002, INT STAT REV, V70, P419, DOI 10.2307/1403865; Gómez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Halgren E, 2002, NEUROIMAGE, V17, P1101, DOI 10.1006/nimg.2002.1268; Hodapp A., 2021, bioRxiv, DOI [10.1101/2021.03.25.436922,2021.03.25.436922, DOI 10.1101/2021.03.25.436922,2021.03.25.436922]; Hoeks JCJ, 2004, COGNITIVE BRAIN RES, V19, P59, DOI 10.1016/j.cogbrainres.2003.10.022; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; Hubbard RJ, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00291; Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014; Huizeling E, 2022, NEUROBIOL LANG, V3, P149, DOI 10.1162/nol_a_00054; Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007; JAIN AK, 1976, IEEE T SYST MAN CYB, V6, P763; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Kim A, 2005, J MEM LANG, V52, P205, DOI 10.1016/j.jml.2004.10.002; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kuperberg GR, 2007, BRAIN RES, V1146, P23, DOI 10.1016/j.brainres.2006.12.063; Kuperberg GR, 2020, J COGNITIVE NEUROSCI, V32, P12, DOI 10.1162/jocn_a_01465; Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299; Kuperberg GR, 2003, COGNITIVE BRAIN RES, V17, P117, DOI 10.1016/S0926-6410(03)00086-7; KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657; KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0; Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014; MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Merkx D., 2021, P WORKSH COGN MOD CO, P12, DOI [10.18653/v1/2021.cmcl-1.2, DOI 10.18653/V1/2021.CMCL-1.2]; Metusalem R, 2012, J MEM LANG, V66, P545, DOI 10.1016/j.jml.2012.01.001; Michaelov J. A., 2022, P 26 C COMPUTATIONAL, P13; Michaelov J. A., 2021, P 43 ANN M COGNITIVE, P300; Michaelov J. A., 2022, NEURIPS 2022 WORKSH; Michaelov J. A., 2020, Proceedings of the 24th conference on computational natural language learning, P652, DOI DOI 10.18653/V1/2020.CONLL-1.53; Michaelov JA, 2024, NEUROBIOL LANG, V5, P107, DOI 10.1162/nol_a_00105; Michaelov JA, 2023, IEEE T COGN DEV SYST, V15, P1033, DOI 10.1109/TCDS.2022.3176783; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2; Nicenboim B, 2020, NEUROPSYCHOLOGIA, V142, DOI 10.1016/j.neuropsychologia.2020.107427; Nie Yixin, 2020, P 58 ANN M ASS COMPU, P4885, DOI [10.18653/v1/2020.acl-main.441, DOI 10.18653/V1/2020.ACL-MAIN.441, DOI 10.18653/V1/2020.ACL-MAIN, 10.18653/.v1/2020.acl-main.441]; Nieuwand MS, 2005, COGNITIVE BRAIN RES, V24, P691, DOI 10.1016/j.cogbrainres.2005.04.003; Nieuwland MS, 2013, BRAIN LANG, V126, P151, DOI 10.1016/j.bandl.2013.04.005; Otten M, 2008, DISCOURSE PROCESS, V45, P464, DOI 10.1080/01638530802356463; Paczynski M, 2012, J MEM LANG, V67, P426, DOI 10.1016/j.jml.2012.07.003; Paczynski M, 2011, LANG COGNITIVE PROC, V26, P1402, DOI 10.1080/01690965.2011.580143; Parviz M., 2011, Proceedings of the Australasian Language Technology Association workshop 2011, P38; Paszke A, 2019, ADV NEUR IN, V32; Payne BR, 2015, PSYCHOPHYSIOLOGY, V52, P1456, DOI 10.1111/psyp.12515; Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002; Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78; Rommers J, 2018, NEUROIMAGE, V183, P263, DOI 10.1016/j.neuroimage.2018.08.023; RUGG MD, 1990, MEM COGNITION, V18, P367, DOI 10.3758/BF03197126; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Seidenberg MS, 1997, SCIENCE, V275, P1599, DOI 10.1126/science.275.5306.1599; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Sherman BE, 2020, P NATL ACAD SCI USA, V117, P22760, DOI 10.1073/pnas.2013291117; Sherman BE, 2020, CURR OPIN BEHAV SCI, V32, P15, DOI 10.1016/j.cobeha.2020.01.015; Smith N. J., 2011, P 33 ANN M COGN SCI, V33, P7; Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013; Srivastava Aarohi, 2022, arXiv; Stability AI, 2023, StableLM-Base-Alpha 7B; Staub A, 2015, J MEM LANG, V82, P1, DOI 10.1016/j.jml.2015.02.004; Stone K., 2021, Data and code, DOI [10.17605/OSF.IO/h75jm, DOI 10.17605/OSF.IO/H75JM]; Stone K, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0267813; Szewczyk JM, 2022, J MEM LANG, V123, DOI 10.1016/j.jml.2021.104311; Szewczyk JM, 2022, J EXP PSYCHOL LEARN, V48, P856, DOI 10.1037/xlm0001091; Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002; Szewczyk JM, 2011, BRAIN RES, V1368, P208, DOI 10.1016/j.brainres.2010.10.070; Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401; TAYLOR WL, 1957, J APPL PSYCHOL, V41, P19, DOI 10.1037/h0040591; Team R., 2020, RStudio: Integrated development environment for R. Version 1.4.1103, DOI DOI 10.1145/3132847.3132886; Thornhill DE, 2012, INT J PSYCHOPHYSIOL, V83, P382, DOI 10.1016/j.ijpsycho.2011.12.007; van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500; Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394; Van Petten C, 2014, INT J PSYCHOPHYSIOL, V94, P407, DOI 10.1016/j.ijpsycho.2014.10.012; Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015; Van Rossum G., 2009, PYTHON 3 REFERENCE M; VANPETTEN C, 1993, LANG COGNITIVE PROC, V8, P485, DOI 10.1080/01690969308407586; VANPETTEN C, 1990, MEM COGNITION, V18, P380, DOI 10.3758/BF03197127; VANPETTEN C, 1991, MEM COGNITION, V19, P95, DOI 10.3758/BF03198500; Vega-Mendoza M, 2021, NEUROPSYCHOLOGIA, V152, DOI 10.1016/j.neuropsychologia.2020.107724; Vissers CTWM, 2006, BRAIN RES, V1106, P150, DOI 10.1016/j.brainres.2006.05.012; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang L, 2020, J NEUROSCI, V40, P3278, DOI 10.1523/JNEUROSCI.1733-19.2020; Wickham H., 2019, JOSS, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]; Wlotko EW, 2007, NEUROPSYCHOLOGIA, V45, P3001, DOI 10.1016/j.neuropsychologia.2007.05.013; Wlotko EW, 2012, NEUROIMAGE, V62, P356, DOI 10.1016/j.neuroimage.2012.04.054; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yan SR, 2020, LANG COGN NEUROSCI, V35, P658, DOI 10.1080/23273798.2019.1597979	138	1	1	1	3	ELSEVIER MASSON, CORP OFF	PARIS	65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE	0010-9452	1973-8102		CORTEX	Cortex	NOV	2023	168						82	101		10.1016/j.cortex.2023.08.001	http://dx.doi.org/10.1016/j.cortex.2023.08.001		SEP 2023	20	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	T2EJ7	37678069	hybrid			2024-07-03	WOS:001076162600001
J	De Haro, LP				De Haro, Leyma P.			Biosecurity Risk Assessment for the Use of Artificial Intelligence in Synthetic Biology	APPLIED BIOSAFETY			English	Article; Early Access						biosecurity; risk assessment; artificial intelligence; synthetic biology; biorisk management		Background: The integration of Artificial Intelligence (AI) with synthetic biology is driving unprecedented progress in both fields. However, this integration introduces complex biosecurity challenges. Addressing these concerns, this article proposes a specialized biosecurity risk assessment process designed to evaluate the incorporation of AI in synthetic biology.Methods: A set of tailored tools and methodology was developed for conducting biosecurity risk assessments of AI language models used for synthetic biology. These resources were developed to guide risk management professionals through a systematic process of identifying, evaluating, and mitigating potential risks.Results: The tools and methodology provided offer a structured approach to risk assessment, enabling risk management professionals to comprehensively analyze the biosecurity implications of AI applications in synthetic biology. They facilitate the identification of potential risks and the development of effective mitigation strategies. An example of a risk assessment performed on the large language model "ChatGPT 4.0" is provided here.Conclusion: AI's role in synthetic biology is rapidly expanding; thus, establishing proactive and secure practices is crucial. The biosecurity risk assessment tools and methodology presented here are the first provided in the literature and will be instrumental steps toward the responsible integration of AI in synthetic biology. By adopting these resources, the biorisk management community can effectively navigate and manage the biosecurity challenges posed by AI, ensuring its responsible and secure application in the field of synthetic biology.	[De Haro, Leyma P.] CALTECH, Environm Hlth & Safety, 1200 E Calif Blvd, Pasadena, CA 91125 USA	California Institute of Technology	De Haro, LP (corresponding author), CALTECH, Environm Hlth & Safety, 1200 E Calif Blvd, Pasadena, CA 91125 USA.	deharoLP@gmail.com	De Haro, Leyma P/B-1019-2009					Alabdulatif A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111039; anl, Autonomous Discovery | Argonne National Laboratory; [Anonymous], ChatGPT may reveal private training data-Google DeepMind; [Anonymous], 2018, Biodefense in the Age of Synthetic Biology, DOI [10.17226/24890, DOI 10.17226/24890]; [Anonymous], Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence; API, 2024, Wikipedia; Callaway Ewen, 2023, Nature, DOI 10.1038/d41586-023-01516-w; Cheng Y, 2020, COMMUN ACM, V63, P33, DOI 10.1145/3387107; Collins C, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102383; Eisenstein M, 2023, NAT BIOTECHNOL, V41, P303, DOI 10.1038/s41587-023-01705-y; Foss-Solbrekk K, 2021, J INTELLET PROP LAW, V16, P247, DOI 10.1093/jiplp/jpab033; Gentile F, 2022, NAT PROTOC, V17, P672, DOI 10.1038/s41596-021-00659-2; Giudici P, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121220; Hartmann K, 2020, INT CONF CYBER CONFL, P327, DOI [10.23919/cycon49761.2020.9131724, 10.23919/CyCon49761.2020.9131724]; Hohma E, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1073686; Ichikawa DM, 2023, NAT BIOTECHNOL, V41, P1117, DOI 10.1038/s41587-022-01624-4; ISO, 14:00-17:00.; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Maserat E, 2022, CANCER INFORM, V21, DOI 10.1177/11769351221140102; Maxmen A., 2022, The New York Times; Méndez-Lucio O, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13807-w; Myllyaho L, 2021, J SYST SOFTWARE, V181, DOI 10.1016/j.jss.2021.111050; nature, Unseating big pharma: the radical plan for vaccine equity; not-just-memorization.github.io, Extracting Training Data from ChatGPT; O'Brien JT, 2020, HEALTH SECUR, V18, P219, DOI 10.1089/hs.2019.0122; Prasad K, 2023, MOL ONCOL, V17, P946, DOI 10.1002/1878-0261.13420; Radivojevic T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18008-4; Rudin C., 2019, Harvard Data Science Review, V1, P2, DOI [10.1162/99608f92.5a8a3a3d, DOI 10.1162/99608F92.5A8A3A3D]; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sandbrink JB, 2023, Arxiv, DOI arXiv:2306.13952; science, Pandemic preparedness in a changing world: Fostering global collaboration to strengthen public health and response to viral threats; Sharma A, 2022, BIOMED RES INT-UK, V2022, DOI 10.1155/2022/7205241; Steimers A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19063641; Ziller A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93030-0	34	0	0	7	7	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	1535-6760	2470-1246		APPL BIOSAF	Appl. Biosaf.-J. Am. Biol. Saf. Assoc.	2024 MAR 27	2024										10.1089/apb.2023.0031	http://dx.doi.org/10.1089/apb.2023.0031		MAR 2024	12	Public, Environmental & Occupational Health	Emerging Sources Citation Index (ESCI)	Public, Environmental & Occupational Health	MB8V0		hybrid			2024-07-03	WOS:001191267100001
J	Isaksson, LJ; Summers, P; Mastroleo, F; Marvaso, G; Corrao, G; Vincini, MG; Zaffaroni, M; Ceci, F; Petralia, G; Orecchia, R; Jereczek-Fossa, BA				Isaksson, Lars Johannes; Summers, Paul; Mastroleo, Federico; Marvaso, Giulia; Corrao, Giulia; Vincini, Maria Giulia; Zaffaroni, Mattia; Ceci, Francesco; Petralia, Giuseppe; Orecchia, Roberto; Jereczek-Fossa, Barbara Alicja			Automatic Segmentation with Deep Learning in Radiotherapy	CANCERS			English	Review						radiotherapy; segmentation; automatic; deep learning; artificial intelligence; artificial neural networks	MEDICAL IMAGE SEGMENTATION; BRAIN SEGMENTATION; MRI; DELINEATION; LESIONS; CANCER	Simple Summary Automatic segmentation of organs and other regions of interest is a promising approach for reducing the workload of doctors in radiotherapeutic planning, but it can be hard for doctors and researchers to keep up with current developments. This review evaluates 807 papers and reveals trends, commonalities, and gaps in the existing corpus. A set of recommendations for conducting effective segmentation studies is also provided.Abstract This review provides a formal overview of current automatic segmentation studies that use deep learning in radiotherapy. It covers 807 published papers and includes multiple cancer sites, image types (CT/MRI/PET), and segmentation methods. We collect key statistics about the papers to uncover commonalities, trends, and methods, and identify areas where more research might be needed. Moreover, we analyzed the corpus by posing explicit questions aimed at providing high-quality and actionable insights, including: "What should researchers think about when starting a segmentation study?", "How can research practices in medical image segmentation be improved?", "What is missing from the current corpus?", and more. This allowed us to provide practical guidelines on how to conduct a good segmentation study in today's competitive environment that will be useful for future research within the field, regardless of the specific radiotherapeutic subfield. To aid in our analysis, we used the large language model ChatGPT to condense information.	[Isaksson, Lars Johannes; Mastroleo, Federico; Marvaso, Giulia; Corrao, Giulia; Vincini, Maria Giulia; Zaffaroni, Mattia; Jereczek-Fossa, Barbara Alicja] IEO European Inst Oncol IRCCS, Div Radiat Oncol, I-20141 Milan, Italy; [Isaksson, Lars Johannes; Ceci, Francesco; Petralia, Giuseppe; Jereczek-Fossa, Barbara Alicja] Univ Milan, Dept Oncol & Hematooncol, I-20141 Milan, Italy; [Summers, Paul] IEO European Inst Oncol IRCCS, Div Radiol, I-20141 Milan, Italy; [Mastroleo, Federico] Univ Piemonte Orientale UPO, Dept Translat Med, I-20188 Novara, Italy; [Ceci, Francesco] IEO European Inst Oncol IRCCS, Div Nucl Med, I-20141 Milan, Italy; [Petralia, Giuseppe] IEO European Inst Oncol IRCCS, Dept Med Imaging & Radiat Sci, Precis Imaging & Res Unit, I-20141 Milan, Italy; [Orecchia, Roberto] IEO European Inst Oncol IRCCS, Sci Directorate, I-20141 Milan, Italy	University of Milan; University of Eastern Piedmont Amedeo Avogadro	Marvaso, G (corresponding author), IEO European Inst Oncol IRCCS, Div Radiat Oncol, I-20141 Milan, Italy.	larsjohannes.isaksson@ieo.it; paul.summers@ieo.it; federico.mastroleo@ieo.it; giulia.marvaso@ieo.it; giulia.corrao@ieo.it; mariagiulia.vincini@ieo.it; mattia.zaffaroni@ieo.it; francesco.ceci@ieo.it; giuseppe.petralia@ieo.it; roberto.orecchia@ieo.it; barbara.jereczek@ieo.it	Mastroleo, Federico/ABD-5902-2020; Marvaso, Giulia/AAC-1540-2019; Summers, Paul/D-5211-2016	Mastroleo, Federico/0000-0001-6580-6767; Marvaso, Giulia/0000-0002-5339-8038; Vincini, Maria Giulia/0000-0001-7830-3149; Summers, Paul/0000-0002-5085-1095; Corrao, Giulia/0000-0002-5757-6073; Zaffaroni, Mattia/0000-0003-4655-4634	Italian Ministry of Health; Accuray Inc.; Ion Beam Applications (IBA)	Italian Ministry of Health(Ministry of Health, Italy); Accuray Inc.; Ion Beam Applications (IBA)	IEO: the European Institute of Oncology, is partially supported by the Italian Ministry of Health (with "Ricerca Corrente" and "5 x 1000" funds) and by Institutional grants from Accuray Inc. and Ion Beam Applications (IBA).	Ali HM, 2019, LECT NOTES ARTIF INT, V11976, P136, DOI 10.1007/978-3-030-37078-7_14; Altini N, 2022, NEUROCOMPUTING, V490, P30, DOI 10.1016/j.neucom.2021.08.157; Badrigilan S, 2021, INT J COMPUT ASS RAD, V16, P529, DOI 10.1007/s11548-021-02326-z; Becker AS, 2019, EUR J RADIOL, V121, DOI 10.1016/j.ejrad.2019.108716; Brouwer CL, 2012, RADIAT ONCOL, V7, DOI 10.1186/1748-717X-7-32; Chen RJ, 2022, CANCER CELL, V40, P865, DOI 10.1016/j.ccell.2022.07.004; Covert EC, 2022, EJNMMI PHYS, V9, DOI 10.1186/s40658-022-00515-6; Deng YS, 2022, J MED BIOL ENG, V42, P604, DOI 10.1007/s40846-022-00710-x; El Jurdi R, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103248; Fernando KRM, 2023, INFORM FUSION, V92, P450, DOI 10.1016/j.inffus.2022.12.013; Fu YB, 2021, PHYS MEDICA, V85, P107, DOI 10.1016/j.ejmp.2021.05.003; Graffy PM, 2019, ABDOM RADIOL, V44, P2921, DOI 10.1007/s00261-019-02014-2; Gu J., arXiv; Habijan M, 2020, CARDIOVASC ENG TECHN, V11, P725, DOI 10.1007/s13239-020-00494-8; Hager Paul, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P23924, DOI 10.1109/CVPR52729.2023.02291; Heller N, 2020, Arxiv, DOI arXiv:1904.00445; Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x; Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820; Huang L, 2023, INFORM FUSION, V91, P737, DOI 10.1016/j.inffus.2022.11.008; Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z; Islam MZ, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106276; Ji Y., 2022, NeurIPS, V35, P36722; Kalantar R, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11111964; Koss JE, 1999, IEEE T MED IMAGING, V18, P640, DOI 10.1109/42.790463; Latif G, 2021, CURR MED IMAGING, V17, P917, DOI 10.2174/1573405616666210104111218; Li ZJ, 2019, LECT NOTES COMPUT SC, V11766, P402, DOI 10.1007/978-3-030-32248-9_45; Lin XB, 2019, CURR MED IMAGING, V15, P443, DOI 10.2174/1573405614666180817125454; Litjens G, 2014, MED IMAGE ANAL, V18, P359, DOI 10.1016/j.media.2013.12.002; Liu X, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.717039; Luo W, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5870; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Mohammed YMA, 2023, J COMPUT DES ENG, V10, P266, DOI 10.1093/jcde/qwac141; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; openai, OpenAI Introducing ChatGPT; Popple RA, 2006, TECHNOL CANCER RES T, V5, P15, DOI 10.1177/153303460600500103; Punn NS, 2022, ARTIF INTELL REV, V55, P5845, DOI 10.1007/s10462-022-10152-1; Qureshi I, 2023, INFORM FUSION, V90, P316, DOI 10.1016/j.inffus.2022.09.031; Ranjbarzadeh R, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106443; Rasch C, 2002, INT J RADIAT ONCOL, V52, P120, DOI 10.1016/S0360-3016(01)01751-5; Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249; Sakshi, 2023, ARCH COMPUT METHOD E, V30, P457, DOI 10.1007/s11831-022-09805-9; Senan S, 1999, RADIOTHER ONCOL, V53, P247, DOI 10.1016/S0167-8140(99)00143-7; Shao JQ, 2023, CMES-COMP MODEL ENG, V136, P2173, DOI 10.32604/cmes.2023.025499; Sharif MS, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/105610; Sharif MS, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P596, DOI 10.1109/APCCAS.2010.5774870; Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777; Sharma N, 2008, J MED PHYS, V33, P119, DOI 10.4103/0971-6203.42763; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Trimpl MJ, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac6d9c; Vale-Silva LA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92799-4; Van de Steene J, 2002, RADIOTHER ONCOL, V62, P37, DOI 10.1016/S0167-8140(01)00453-4; Veiga-Canuto D, 2022, CANCERS, V14, DOI 10.3390/cancers14153648; Venugopalan J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-74399-w; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Xie EZ, 2021, ADV NEUR IN, V34; Yang CZ, 2022, RADIAT ONCOL, V17, DOI 10.1186/s13014-022-02148-6; Zeleznik R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00416-5; Zöllner FG, 2021, IEEE ACCESS, V9, P71577, DOI 10.1109/ACCESS.2021.3078430	58	3	3	5	15	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2072-6694		CANCERS	Cancers	SEP	2023	15	17							4389	10.3390/cancers15174389	http://dx.doi.org/10.3390/cancers15174389			14	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	Q9FZ9	37686665	gold, Green Published			2024-07-03	WOS:001060516700001
C	Gao, S; Li, YL; Ge, FP; Lin, M; Yu, HQ; Wang, SK; Miao, ZY		Pedrycz, W; Wang, J; He, Y; Dinh, TN; Grant, C; Qiu, M		Gao, Shang; Li, Yanling; Ge, Fengpei; Lin, Min; Yu, Haiqing; Wang, Sukun; Miao, Zhongyi			Match and Retrieval: Legal Similar Case Retrieval via Graph Matching Network	2023 23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW 2023	International Conference on Data Mining Workshops		English	Proceedings Paper	23rd IEEE International Conference on Data Mining (IEEE ICDM)	DEC 01-04, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, US National Science Foundation, Technology Innovation Institute, TWO SIGMA		legal case retrieval; legal intelligence; graph neural network; graph matching network; text similarity		Legal document retrieval is a crucial application in the field of legal Artificial Intelligence (AI). It involves retrieving the most relevant legal cases from a legal document database when inputting a query. Mainstream solutions typically employ pretrained language models or large language models for retrieval. However, both of these methods rely on black-box models trained on unlabeled data, resulting in a lack of interpretability in the model's retrieval outcomes. Graph Neural Networks (GNNs) possess strong representational and interpretable capabilities. Therefore, representing legal cases using graph-structured data and performing the Legal Similar Case Retrieval (LSCR) task through GNNs is a promising approach. Nevertheless, typical GNNs primarily focus on node information within graph-structured data and overlook edge and inter-graph interaction information, leading to lower retrieval accuracy. To address these issues, in this paper, we propose a Legal case retrieval model utilizing a Graph Matching Network, called Legal-GMN. We evaluate the model on a dataset composed of real legal judgment cases. Experimental results demonstrate that Legal-GMN effectively enhances the retrieval accuracy for the LSCR task. Compared with baseline methods, Legal-GMN improves retrieval precision by approximately 15% and enhances retrieval efficiency by approximately 90%. Remarkably, while maintaining State-Of-The-Art (SOTA) performance, Legal-GMN can also generate visualized graphs of the retrieval process, significantly enhancing its interpretability.	[Gao, Shang; Li, Yanling] Inner Mongolia Normal, Coll Comp Sci & Technol, Key Lab Infinite Dimens Hamiltonian Syst & Its Al, Minist Educ, Hohhot, Peoples R China; [Ge, Fengpei] Beijing Univ Posts & Telecommun, Beijing, Peoples R China; [Lin, Min; Yu, Haiqing; Wang, Sukun; Miao, Zhongyi] Inner Mongolia Normal Univ, Coll Comp Sci & Technol, Hohhot, Peoples R China	Beijing University of Posts & Telecommunications; Inner Mongolia Normal University	Gao, S (corresponding author), Inner Mongolia Normal, Coll Comp Sci & Technol, Key Lab Infinite Dimens Hamiltonian Syst & Its Al, Minist Educ, Hohhot, Peoples R China.	wdmxsyf_gs@163.com; cieclyl@imnu.edu.cn; gefengpei@bupt.edu.cn; linmin@imnu.edu.cn; ciecyhq@imnu.edu.cn; ciecwsk@imnu.edu.cn; ciecmzy@imnu.edu.cn			National Natural Science Foundation of China [62266033, 12204062, 61806103, 61562068]; Key Laboratory of Infinite-dimensional Hamiltonian System and Its Algorithm Application; Ministry of Education [2023KFZD03]; National Natural Science Foundation of Inner Mongolia, China [2022LHMS06001]; Basic Scientific Research Business Project of Inner Mongolia Normal University [2022JBQN106, 2022JBQN111]; Innovation Fund for Postgraduates of Inner Mongolia Normal University [CXJJS23066]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Laboratory of Infinite-dimensional Hamiltonian System and Its Algorithm Application; Ministry of Education; National Natural Science Foundation of Inner Mongolia, China; Basic Scientific Research Business Project of Inner Mongolia Normal University; Innovation Fund for Postgraduates of Inner Mongolia Normal University	This work was supported by the National Natural Science Foundation of China (62266033, 12204062, 61806103, 61562068), Key Laboratory of Infinite-dimensional Hamiltonian System and Its Algorithm Application (Inner Mongolia Normal University), Ministry of Education (2023KFZD03), National Natural Science Foundation of Inner Mongolia, China (2022LHMS06001), Basic Scientific Research Business Project of Inner Mongolia Normal University (2022JBQN106, 2022JBQN111), the Innovation Fund for Postgraduates of Inner Mongolia Normal University (CXJJS23066), "One district, two bases" construction project (Joint Innovation Laboratory of Computing Science).	Ashley KD, 2013, FRONT ARTIF INTEL AP, V259, P29, DOI 10.3233/978-1-61499-359-9-29; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Hou Yupeng., 2022, PROC SDM, P172; Hu WF, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/2511147; [黄治纲 Huang Zhigang], 2021, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V57, P1053; Ling X, 2023, IEEE T NEUR NET LEAR, V34, P799, DOI 10.1109/TNNLS.2021.3102234; Liu B, 2022, IEEE T CYBERNETICS, V52, P11834, DOI 10.1109/TCYB.2021.3073023; Liu BL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103051; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ma YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2342, DOI 10.1145/3404835.3463250; Mandal A, 2017, COMPUTE'17: PROCEEDINGS OF THE 10TH ANNUAL ACM INDIA COMPUTE CONFERENCE, P1, DOI 10.1145/3140107.3140119; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shao YQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3501; Xiao CJ, 2021, AI OPEN, V2, P79, DOI 10.1016/j.aiopen.2021.06.003	16	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2375-9232		979-8-3503-8164-1	INT CONF DAT MIN WOR			2023							227	234		10.1109/ICDMW60847.2023.00035	http://dx.doi.org/10.1109/ICDMW60847.2023.00035			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5OA					2024-07-03	WOS:001164077500027
C	Muennighoff, N; Wang, T; Sutawika, L; Roberts, A; Biderman, S; Le Scao, T; Bari, MS; Shen, S; Yong, ZX; Schoelkopf, H; Tang, XR; Radev, D; Aji, AF; Almubarak, K; Albanie, S; Alyafeai, Z; Webson, A; Raff, E; Raffel, C		Rogers, A; Boyd-Graber, J; Okazaki, N		Muennighoff, Niklas; Wang, Thomas; Sutawika, Lintang; Roberts, Adam; Biderman, Stella; Le Scao, Teven; Bari, M. Saiful; Shen, Sheng; Yong, Zheng-Xin; Schoelkopf, Hailey; Tang, Xiangru; Radev, Dragomir; Aji, Alham Fikri; Almubarak, Khalid; Albanie, Samuel; Alyafeai, Zaid; Webson, Albert; Raff, Edward; Raffel, Colin			Crosslingual Generalization through Multitask Finetuning	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models. We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results. We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages. Surprisingly, we find models are capable of zero-shot generalization to tasks in languages they have never intentionally seen. We conjecture that the models are learning higher-level capabilities that are both task- and language-agnostic. In addition, we introduce xP3, a composite of supervised datasets in 46 languages with English and machine-translated prompts. Our code, datasets and models are freely available at https://github.com/bigscience-workshop/xmtf.	[Muennighoff, Niklas; Wang, Thomas; Raffel, Colin] Hugging Face, Brooklyn, NY 11201 USA; [Sutawika, Lintang] Datasaur Ai, Sunnyvale, CA USA; [Sutawika, Lintang; Biderman, Stella; Schoelkopf, Hailey] EleutherAI, Washington, DC USA; [Roberts, Adam] Google Res, Brain Team, Mountain View, CA USA; [Biderman, Stella; Raff, Edward] Booz Allen Hamilton, Mclean, VA USA; [Bari, M. Saiful] Nanyang Technol Univ, Singapore, Singapore; [Shen, Sheng] Univ Calif Berkeley, Berkeley, CA USA; [Yong, Zheng-Xin; Webson, Albert] Brown Univ, Providence, RI USA; [Schoelkopf, Hailey; Tang, Xiangru; Radev, Dragomir] Yale Univ, New Haven, CT USA; [Aji, Alham Fikri] MBZUAI, Abu Dhabi, U Arab Emirates; [Almubarak, Khalid] PSAU, Pampanga, Philippines; [Albanie, Samuel] Univ Cambridge, Cambridge, England; [Alyafeai, Zaid] KFUPM, Dhahran, Saudi Arabia	Google Incorporated; Booz Allen Hamilton Holding Corporation; Nanyang Technological University; University of California System; University of California Berkeley; Brown University; Yale University; Mohamed Bin Zayed University of Artificial Intelligence; University of Cambridge; King Fahd University of Petroleum & Minerals	Muennighoff, N (corresponding author), Hugging Face, Brooklyn, NY 11201 USA.	niklas@hf.co						Allal Loubna Ben, 2023, ARXIV230103988; [Anonymous], 2018, ARXIV190809804 CS SE; Aribandi Vamsi, 2021, ABS211110952 CORR; Artetxe Mikel, 2019, ABS191011856 CORR; Austin Jacob, 2021, ARXIV210807732; Bach Stephen H., 2022, Promptsource: An integrated development environment and repository for natural language prompts.; Biderman Stella, 2023, ARXIV230401373; Black Sid, 2022, ARXIV220406745; Black Sid, 2021, YOU USE THIS SOFTWAR, P58; Bommasani Rishi, 2021, ARXIV210807258; Cahyawijaya Samuel, 2023, ARXIV230513627; Chalkidis Ilias, 2021, ARXIV210900904; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, ARXIV220402311; Chung Hyung Won, 2022, ARXIV221011416; Chung Hyung Won, 2023, ARXIV230409151; Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475; Conneau Alexis, 2019, Unsupervised cross-lingual representation learning at scale; Costa-jussa Marta R, 2022, ARXIV220704672; Cui Y., 2018, ARXIV PREPRINT ARXIV; Dettmers T., 2023, arXiv preprint arXiv:2305.14314; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhole Kaustubh D, 2021, ARXIV211202721; Ding Ning, 2022, ARXIV220306904; Ennen Philipp, 2023, ARXIV230304715; Fan A, 2021, J MACH LEARN RES, V22; Fried Daniel, 2022, ARXIV220405999; Fries Jason Alan, 2022, ARXIV220615076; Gao Leo, 2021, A framework for few-shot language model evaluation; Goyal Naman, 2021, The flores-101 evaluation benchmark for low-resource and multilingual machine translation; Goyal Naman, 2021, ARXIV210500572; Guzman Francisco, 2019, Two new evaluation datasets for low-resource machine translation: Nepali-english and sinhala-english; Hasan T, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4693; Hellendoorn V.J., 2019, ICLR, P1; Hendrycks Dan, 2021, NeurIPS; Hoffmann Jordan, 2022, arXiv; Honovich Or, 2022, ARXIV221209689; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Iyer Srinivasan, 2022, ARXIV221212017; Kim J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6193; Komatsuzaki Aran, 2022, ARXIV221205055; Kosec Matej, 2021, ARXIV210702027; Lample Guillaume, 2019, CROSSLINGUAL LANGUAG; Laurencon Hugo, 2022, 36 C NEUR INF PROC S; Le Scao Teven, 2022, ARXIV221015424; Le Scao Teven, 2021, ARXIV210308493; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lewis Patrick, 2019, ARXIV191007475; Li RC, 2020, IEEE POSITION LOCAT, P798, DOI [10.1109/PLANS46316.2020.9109908, 10.1109/plans46316.2020.9109908]; Liang Xu., 2020, P 28 INT C COMPUTATI, P4762, DOI [10.18653/v1/2020.coling-main.419, DOI 10.18653/V1/2020.COLING-MAIN.419]; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin Xi Victoria, 2021, ARXIV211210668; Liu HL, 2013, ADV MATER, V25, P6607, DOI 10.1002/adma.201302660; Liu Qian, 2023, ARXIV230407995; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; Logan Robert L, 2021, ARXIV210613353; Longpre Shayne, 2023, ARXIV230513169; Longpre Shayne, 2023, ARXIV230113688; Min Sewon, 2021, arXiv preprint arXiv:2110.15943; Mishra Swaroop, 2021, ARXIV210408773; Mishra Swaroop, 2021, ABS210408773 CORR; Muennighoff N., 2022, ARXIV221007316; Muennighoff Niklas, 2023, SCALING DATA CONSTRA; Muennighoff Niklas, 2022, ARXIV220208904; Ouyang Long, 2022, ARXIV220302155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Patel Ajay, 2022, ARXIV220914500; Perez Ethan, 2021, ABS210511447 CORR; Perez Ethan, 2021, ADV NEURAL INFORM PR, V34, P11054; Phang J, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P557; Ponti Edoardo M., 2020, XCOPA MULTILINGUAL D; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae Jack W, 2021, arXiv:2112.11446; Raffel C, 2020, J MACH LEARN RES, V21; Raganato A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7193; Roberts Adam, 2022, arXiv preprint arXiv:2203.17189; Roemmele M., 2011, 2011 AAAI SPRING S S; Sanh Victor., 2022, 10 INT C LEARN REPR; Scao T. L., 2022, arXiv preprint arXiv:2211.05100; Schick Timo, 2020, arXiv; Schick Timo, 2020, ABS200107676 CORR; Scialom Thomas, 2022, ARXIV220512393; Shen Sheng, 2023, ARXIV230514705; Shliazhko Oleh, 2022, ARXIV220407580; Smith S., 2022, arXiv preprint arXiv:2201.11990; Soltan Saleh, 2022, Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model; Srivastava Aarohi, 2022, ARXIV220604615; Su Hui, 2022, ARXIV220910372; Sun K, 2020, T ASSOC COMPUT LING, V8, P141, DOI 10.1162/tacl_a_00305; Suzgun Mirac, 2022, ARXIV221009261; Tay Yi, 2022, ARXIV221011399; Tay Yi, 2022, 11 INT C LEARN REPR; Tay Yi, 2022, ARXIV220505131; Taylor Ross, 2022, ARXIV221109085; Tiedemann Jorg, 2020, P 5 C MACHINE TRANSL, P1174; Tikhonov Alexey, 2021, ITS ALL HEADS USING; Touvron Hugo, 2023, ARXIV230213971; Vaswani A, 2017, ADV NEUR IN, V30; Vu Tu, 2022, ARXIV220512647; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang Thomas, 2022, ARXIV220405832; Wang Y., 2022, ARXIV220407705; Wang Zhenhailong, 2022, ARXIV221000185; Webson Albert, 2021, PROMPT BASED MODELS; Wei Jason, 2021, arXiv preprint arXiv:2109.01652; Wikilingua, 2020, ARXIV201003093; Williams A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173662; Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833; Xue Linting, 2020, ARXIV201011934; Yang Yinfei, 2019, P EMNLP; Yin Da, 2023, ARXIV230514327; YizhongWang Yeganeh Kordi, 2022, arXiv; Yong Zheng-Xin, 2022, ARXIV220404873; Yong Zheng-Xin, 2022, ARXIV221209535; Zaken Elad Ben, 2021, ARXIV210610199; Zeng A., 2022, ARXIV221002414; Zhang S., 2022, arXiv; Zhang Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1298; Zhong Ruiqi, 2021, ABS210404670 CORR; Zhu Ming, 2022, XLCOST BENCHMARK DAT	120	20	21	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15991	16111						121	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962507044
J	Dalakoti, M; Wong, S; Lee, W; Lee, J; Yang, H; Loong, S; Loh, PH; Tyebally, S; Djohan, A; Ong, J; Yip, J; Ngiam, KY; Foo, R				Dalakoti, Mayank; Wong, Scott; Lee, Wayne; Lee, James; Yang, Hayang; Loong, Shaun; Loh, Poay Huan; Tyebally, Sara; Djohan, Andie; Ong, Jeanne; Yip, James; Ngiam, Kee Yuan; Foo, Roger			Incorporating AI into cardiovascular diseases prevention - insights from Singapore	LANCET REGIONAL HEALTH-WESTERN PACIFIC			English	Article						Artificial intelligence; Preventive cardiology; Primary care; Primary prevention; Cardiovascular disease; Cardiovascular risk factors; Population health		Improved upstream primary prevention of cardiovascular disease (CVD) would enable more individuals to lead lives free of CVD. However, there remain limitations in the current provision of CVD primary prevention, where arti fi cial intelligence (AI) may help to fi ll the gaps. Using the data informatics capabilities at the National University Health System (NUHS), Singapore, empowered by the Endeavour AI system, and combined large language model (LLM) tools, our team has created a real-time dashboard able to capture and showcase information on cardiovascular risk factors at both individual and geographical level- CardioSight. Further insights such as medication records and data on area -level socioeconomic determinants allow a whole -of -systems approach to promote healthcare delivery, while also allowing for outcomes to be tracked effectively. These are paired with interventions, such as the CHronic diseAse Management Program (CHAMP), to coordinate preventive cardiology care at a pilot stage within our university health system. AI tools in synergy allow the identi fi cation of at -risk patients and actionable steps to mitigate their health risks, thereby closing the gap between risk identi fi cation and effective patient care management in a novel CVD prevention work fl ow. Copyright (c) 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY -NC -ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	[Dalakoti, Mayank; Yang, Hayang; Loong, Shaun; Loh, Poay Huan; Tyebally, Sara; Djohan, Andie; Ong, Jeanne; Yip, James; Foo, Roger] Natl Univ Heart Ctr, Cardiovasc Res Inst, Singapore, Singapore; [Dalakoti, Mayank; Yang, Hayang; Loong, Shaun; Loh, Poay Huan; Tyebally, Sara; Djohan, Andie; Ong, Jeanne; Yip, James; Foo, Roger] NUS Yong Loo Lin Sch Med, Cardiovasc Metab Dis Translat Res Programme, Singapore, Singapore; [Dalakoti, Mayank; Loh, Poay Huan; Tyebally, Sara; Djohan, Andie; Ong, Jeanne] Ng Teng Fong Gen Hosp, Singapore, Singapore; [Wong, Scott; Lee, Wayne; Lee, James; Yip, James; Ngiam, Kee Yuan] Natl Univ Hlth Syst, Grp Chief Technol, Singapore, Singapore; [Dalakoti, Mayank] Natl Univ Heart Ctr, Lower Kent Ridge Rd, S-119074 Singapore, Singapore	National University of Singapore; National University of Singapore; National University of Singapore	Dalakoti, M (corresponding author), Natl Univ Heart Ctr, Lower Kent Ridge Rd, S-119074 Singapore, Singapore.	mayank_dalakoti@nuhs.edu.sg		Wong, Scott/0000-0001-5191-154X				[Anonymous], 2020, Singapore smartphone penetration 2017-2023; [Anonymous], The white paper on healthier SG; Chan CQH, 2018, INT J EQUITY HEALTH, V17, DOI 10.1186/s12939-018-0751-y; Dalakoti M, 2023, LANCET REG HEALTH-W, V37, DOI 10.1016/j.lanwpc.2023.100879; Gilmore B, 2023, BMJ-BRIT MED J, V381, DOI 10.1136/bmj-2022-072638; Low LL, 2016, FRONT PUBLIC HEALTH, V4, DOI 10.3389/fpubh.2016.00109; myheritage, US; Schultz WM, 2018, CIRCULATION, V137, P2166, DOI 10.1161/CIRCULATIONAHA.117.029652	8	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2666-6065		LANCET REG HEALTH-W	Lancet Reg. Health-W. Pac.	JUL	2024	48								101102	10.1016/j.lanwpc.2024.101102	http://dx.doi.org/10.1016/j.lanwpc.2024.101102			8	Health Care Sciences & Services; Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	UH0S8	38855631	hybrid			2024-07-03	WOS:001247054700001
J	Xiao, XY; Liang, JG; Tong, JJ; Wang, HT				Xiao, Xingyu; Liang, Jingang; Tong, Jiejuan; Wang, Haitao			Emergency Decision Support Techniques for Nuclear Power Plants: Current State, Challenges, and Future Trends	ENERGIES			English	Review						crisis management; extreme events; decision support systems; emergency management; risk assessment; data analysis	FAULT-TREE ANALYSIS; PROBABILISTIC SAFETY ASSESSMENT; ANALYTIC HIERARCHY PROCESS; RADIATION-DOSE RATES; OF-THE-ART; VIRTUAL-REALITY; EXPERT SYSTEM; TRAINING SIMULATORS; FAILURE DIAGNOSIS; NORMAL OPERATION	Emergency decision support techniques play an important role in complex and safety-critical systems such as nuclear power plants (NPPs). Emergency decision-making is not a single method but a framework comprising a combination of various technologies. This paper presents a review of various methods for emergency decision support systems in NPPs. We first discuss the theoretical foundations of nuclear power plant emergency decision support technologies. Based on this exposition, the key technologies of emergency decision support systems in NPPs are presented, including training operators in emergency management, risk assessment, fault detection and diagnosis, multi-criteria decision support, and accident consequence assessment. The principles, application, and comparative analysis of these methods are systematically described. Additionally, we present an overview of emergency decision support systems in NPPs across different countries and feature profiles of prominent systems like the Real-Time Online Decision Support System for Nuclear Emergencies (RODOS), the Accident Reporting and Guiding Operational System (ARGOS), and the Decision Support Tool for Severe Accidents (Severa). Then, the existing challenges and issues in this field are summarized, including the need for better integration of risk assessment, methods to enhance education and training, the acceleration of simulation calculations, the application of large language models, and international cooperation. Finally, we propose a new decision support system that integrates Level 1, 2, and 3 probabilistic safety assessment for emergency management in NPPs.	[Xiao, Xingyu; Liang, Jingang; Tong, Jiejuan; Wang, Haitao] Tsinghua Univ, Inst Nucl & New Energy Technol, Beijing 100084, Peoples R China	Tsinghua University	Liang, JG (corresponding author), Tsinghua Univ, Inst Nucl & New Energy Technol, Beijing 100084, Peoples R China.	xxy23@mails.tsinghua.edu.cn; jingang@tsinghua.edu.cn; tongjj@tsinghua.edu.cn; wanght@tsinghua.edu.cn	Liang, Jingang/D-1870-2018	Liang, Jingang/0000-0003-2632-8613	Innovation Funds of CNNC-Tsinghua Joint Center for Nuclear Energy RD	Innovation Funds of CNNC-Tsinghua Joint Center for Nuclear Energy RD	No Statement Available	Abdelgawad M.A.M., 2011, Ph.D. Thesis; Abdullah AG, 2023, ENERGY AI, V14, DOI 10.1016/j.egyai.2023.100263; Abudeif AM, 2015, ANN NUCL ENERGY, V75, P682, DOI 10.1016/j.anucene.2014.09.024; Adali Esra Aytac., 2017, European Journal of Multidisciplinary Studies, V2, P88, DOI [10.26417/ejms.v5i1.p93-101, DOI 10.26417/EJMS.V5I1.P93-101]; Aggarwal R, 2006, EUR J VASC ENDOVASC, V31, P588, DOI 10.1016/j.ejvs.2005.11.009; Alaraj Ali, 2011, Surg Neurol Int, V2, P52, DOI 10.4103/2152-7806.80117; Alfonsi A., 2013, Dynamic event tree analysis through raven; Antoniou Y., 1999, International Journal of Global Energy Issues, V12, P92; Argyris N, 2017, EUR J OPER RES, V262, P180, DOI 10.1016/j.ejor.2017.03.059; Arnott D, 2005, J INF TECHNOL-UK, V20, P67, DOI 10.1057/palgrave.jit.2000035; Astrup P., 2004, Forskningscenter Risoe. Risoe-R; Atici KB, 2011, TECHNOL ECON DEV ECO, V17, P219, DOI 10.3846/20294913.2011.580563; Ayodeji A, 2018, PROG NUCL ENERG, V105, P42, DOI 10.1016/j.pnucene.2017.12.013; Badida P, 2019, J NAT GAS SCI ENG, V66, P284, DOI 10.1016/j.jngse.2019.04.010; Baek S, 2021, ENERGIES, V14, DOI 10.3390/en14144119; Balanya SA, 2022, CHEMOMETR INTELL LAB, V230, DOI 10.1016/j.chemolab.2022.104652; Banerjee Shohan, 2020, 2020 8th International Conference on Control, Mechatronics and Automation (ICCMA), P88, DOI 10.1109/ICCMA51325.2020.9301579; Bednár D, 2019, ANN NUCL ENERGY, V134, P67, DOI 10.1016/j.anucene.2019.06.003; Bertsch V, 2008, INT J EMERG MANAG, V5, P7, DOI 10.1504/IJEM.2008.019905; Bogue R, 2011, IND ROBOT, V38, P113, DOI 10.1108/01439911111106327; Bohanec M., 2019, Ph.D. Thesis; Bohanec M, 2020, J DECIS SYST, V29, P438, DOI 10.1080/12460125.2020.1854426; BONCZEK RH, 1981, OPER RES, V29, P263, DOI 10.1287/opre.29.2.263; BRANS J.P., 2016, Multiple criteria Decision Analysis: State of the Art Surveys, V233, DOI [10.1007/978-1-4939-3094-4_6, DOI 10.1007/978-1-4939-3094-4_6]; Breznik B, 2003, INT J ENVIRON POLLUT, V20, P278, DOI 10.1504/IJEP.2003.004291; BRILL ED, 1990, IEEE T SYST MAN CYB, V20, P745, DOI 10.1109/21.105076; Bromet EJ, 2014, HEALTH PHYS, V106, P206, DOI 10.1097/HP.0000000000000012; Cao B, 2016, SCI TECHNOL NUCL INS, V2016, DOI 10.1155/2016/3105878; Cardis E, 2011, CLIN ONCOL-UK, V23, P251, DOI 10.1016/j.clon.2011.01.510; Carl B., 2004, P INT COMM INF SYST; Cates Christopher U, 2016, BMJ Simul Technol Enhanc Learn, V2, P1, DOI 10.1136/bmjstel-2015-000090; Cepin M, 2002, RELIAB ENG SYST SAFE, V75, P83, DOI 10.1016/S0951-8320(01)00121-1; Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004; Chakraborty PR, 2000, MINER RESOUR ENG, V9, P437, DOI 10.1142/S0950609800000378; Chatzimouratidis AI, 2012, ENERG CONVERS MANAGE, V64, P182, DOI 10.1016/j.enconman.2012.05.006; Chen P, 2023, Arxiv, DOI arXiv:2311.16565; Chen YZ, 2021, ENERG CONVERS MANAGE, V237, DOI 10.1016/j.enconman.2021.114107; Choi JB, 2010, INT J PRES VES PIP, V87, P33, DOI 10.1016/j.ijpvp.2009.11.007; Coble J.B., 2012, A Review of Sensor Calibration Monitoring for Calibration Interval Extension in Nuclear Power Plants, P73; Cohn B, 2023, NUCL SCI ENG, DOI 10.1080/00295639.2023.2177076; Collins HE., 1978, Planning basis for the development of state and local government radiological emergency response plans in support of light water nuclear power plants; Colombo Simone., 2014, SPE Econ. Manag, V6, P165, DOI [DOI 10.2118/164993-PA, 10.2118/164993-PA]; Colt HG, 2001, CHEST, V120, P1333, DOI 10.1378/chest.120.4.1333; Copson H.R., 1960, NACE Corrosion, V16, p79t, DOI DOI 10.5006/0010-9312-16.2.123; Corcoran W.R., 1996, Windsor; Cox PG, 1996, AGR SYST, V52, P355, DOI 10.1016/0308-521X(96)00063-7; Damoom MM, 2019, PROG NUCL ENERG, V110, P110, DOI 10.1016/j.pnucene.2018.09.018; de Silva FN, 2000, J OPER RES SOC, V51, P423, DOI 10.2307/254169; Dhalmahapatra K, 2021, SAFETY SCI, V139, DOI 10.1016/j.ssci.2021.105241; Djokic D., 1996, GIS Environ. Model, P353; Duan QZ, 2020, IEEE ACCESS, V8, P222274, DOI 10.1109/ACCESS.2020.3043398; Ehrhardt J, 1997, RADIAT PROT DOSIM, V73, P35, DOI 10.1093/oxfordjournals.rpd.a032160; Ekmekçioglu M, 2011, INT J COMPUT INT SYS, V4, P583; Eom SB, 1998, J OPER RES SOC, V49, P109, DOI 10.2307/3009977; Ericson C.A., 1999, P SYST SAF C ORL FL, VVolume 1, P1; Espinosa-Paredes G, 2008, ANN NUCL ENERGY, V35, P2387, DOI 10.1016/j.anucene.2008.07.007; Evangeliou N, 2014, ENVIRON INT, V64, P17, DOI 10.1016/j.envint.2013.11.020; Evangeliou N, 2013, ENVIRON SCI TECHNOL, V47, P5803, DOI 10.1021/es400372u; Ezuma M., 2019, AEROSP CONF PROC, P1, DOI DOI 10.1109/aero.2019.8741970; Feyzinejad M, 2019, POLLUTION, V5, P429, DOI 10.22059/poll.2018.255275.428; Franki V, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101286; French S, 1997, RADIAT PROT DOSIM, V73, P11, DOI 10.1093/oxfordjournals.rpd.a032110; French S., 1996, J MULTI CRITERIA DEC, V5, P39, DOI DOI 10.1002/(SICI)1099-1360(199603)5:1ANDLT;39::AID-MCDA109ANDGT;3.0.CO;2-Q; Funk R K., 2016, Clinical Cardio-Oncology, P39, DOI DOI 10.1016/B978-0-323-44227-5.00003-X; Gallagher AG, 2004, LANCET, V364, P1538, DOI 10.1016/S0140-6736(04)17278-4; Gallanti M., 1986, Intelligent Decision Support in Process Environments, P373; Gao ZW, 2015, IEEE T IND ELECTRON, V62, P3768, DOI [10.1109/TIE.2015.2417501, 10.1109/TIE.2015.2419013]; Garoudja E, 2017, ENERG CONVERS MANAGE, V151, P496, DOI 10.1016/j.enconman.2017.09.019; Garrick B.J., 1967, RELIABILITY ANALYSIS OF NUCLEAR POWER PLANT PROTECTIVE SYSTEMS: Holmes and Narver; Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221; Geldermann J, 2009, OMEGA-INT J MANAGE S, V37, P238, DOI 10.1016/j.omega.2006.11.006; GEYMAYR JAB, 1995, IEEE T RELIAB, V44, P37, DOI 10.1109/24.376519; GLOUCESTER UK, 1996, P SPEC M MON DIAGN S; Goble R, 2013, RISK ANAL, V33, P1942, DOI 10.1111/risa.12055; Griffiths MP, 1997, RADIAT PROT DOSIM, V73, P131, DOI 10.1093/oxfordjournals.rpd.a032116; Gu HX, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15076310; Gupta A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25874-z; Haque S, 2006, IEEE T INF TECHNOL B, V10, P51, DOI 10.1109/TITB.2005.855529; Harada KH, 2014, P NATL ACAD SCI USA, V111, pE914, DOI 10.1073/pnas.1315684111; Hasan R.B., 2017, J. Adv. Rev. Sci. Res, V29, P20; HASSBERGER JA, 1989, NUCL SCI ENG, V102, P153, DOI 10.13182/NSE89-A23640; Heo G, 2021, NUCL ENG TECHNOL, V53, P3465, DOI 10.1016/j.net.2021.05.015; Hill MJ, 2005, ENVIRON MODELL SOFTW, V20, P955, DOI 10.1016/j.envsoft.2004.04.014; Himanshukumar R. P., 2018, J ENERGY MANAGEMENT, V2, P31; Hiraoka K, 2015, J OCCUP HEALTH, V57, P497, DOI 10.1539/joh.15-0084-RA; Hoe S., 2008, P 12 INT C INT RAD P; Högberg L, 2013, AMBIO, V42, P267, DOI 10.1007/s13280-013-0382-x; Hussain M, 2023, SAFETY SCI, V164, DOI 10.1016/j.ssci.2023.106158; Ipatyev V, 1999, J ENVIRON RADIOACTIV, V42, P9, DOI 10.1016/S0265-931X(98)00042-3; Iqbal R, 2019, IEEE T IND INFORM, V15, P3077, DOI 10.1109/TII.2019.2902274; Jensen JR, 2009, PHOTOGRAMM ENG REM S, V75, P169, DOI 10.14358/PERS.75.2.169; Joskow PL, 2012, ECON ENERGY ENV POL, V1, P99, DOI 10.5547/2160-5890.1.2.7; Jow H.N., 1990, MELCOR Accident Consequence Code System (MACCS); JUNGTHIRAPANICH C, 1995, IIE TRANS, V27, P789, DOI 10.1080/07408179508936796; Kang DG, 2014, NUCL ENG DES, V275, P142, DOI 10.1016/j.nucengdes.2014.05.009; Kang DG, 2013, NUCL ENG DES, V260, P165, DOI 10.1016/j.nucengdes.2013.03.033; Kang HG, 2006, RELIAB ENG SYST SAFE, V91, P627, DOI 10.1016/j.ress.2005.04.007; Katata G, 2012, J ENVIRON RADIOACTIV, V111, P2, DOI 10.1016/j.jenvrad.2011.09.011; Keeney R., 1977, Conflicting objectives in decisions, P298; Keeney R.L., 1976, IIASA Prof. Pap, p76; KEENEY RL, 1977, J ENVIRON ECON MANAG, V4, P153, DOI 10.1016/0095-0696(77)90039-0; KEENEY RL, 1975, P IEEE, V63, P494, DOI 10.1109/PROC.1975.9776; Keller W, 2005, RELIAB ENG SYST SAFE, V89, P271, DOI 10.1016/j.ress.2004.08.022; King W R, 1983, J Bus Strategy, V3, P84; Kiser L, 2023, PROG NUCL ENERG, V159, DOI 10.1016/j.pnucene.2023.104647; Klein SJW, 2015, ENERG POLICY, V79, P127, DOI 10.1016/j.enpol.2015.01.007; Klint P, 2009, IEEE INT WORK C SO, P168, DOI 10.1109/SCAM.2009.28; Korosec D., 1997, P TECHN COMM M NUCL; Kraujaliene L, 2019, BUS MANAGE ED, V17, P72, DOI 10.3846/bme.2019.11014; Kubota Y, 2015, J ENVIRON RADIOACTIV, V142, P124, DOI 10.1016/j.jenvrad.2015.01.014; Lamberti F, 2021, P INT COMP SOFTW APP, P133, DOI 10.1109/COMPSAC51774.2021.00030; Landry M.D., 1985, Decision Support Systems, V1, P25, DOI DOI 10.1016/0167-9236(85)90195-2; Lau N., 2011, SITUATION AWARENESS; Lavasani SM, 2015, PROCESS SAF ENVIRON, V93, P75, DOI 10.1016/j.psep.2014.05.001; Lechtenbörger C, 2006, PROC MONOGR ENG WATE, P139, DOI 10.1201/9780203963562.ch14; Lee GM, 2024, NUCL ENG TECHNOL, V56, P1225, DOI 10.1016/j.net.2023.11.024; Lee T, 2000, SAFETY SCI, V34, P61, DOI 10.1016/S0925-7535(00)00007-2; Lei JC, 2022, INT J ENERG RES, V46, P21467, DOI 10.1002/er.7873; Lenzen M, 2010, ENERGIES, V3, P462, DOI 10.3390/en3030462; Li C, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060895; LIGEZA A, 1988, EUR J OPER RES, V37, P100, DOI 10.1016/0377-2217(88)90284-6; Lindell M.K., 1983, Nuclear Power Plant Emergency Warning: How Would the Public; Lipol LS., 2011, International Journal of Basic Applied Sciences, V11, P74; Liu HC, 2013, EXPERT SYST APPL, V40, P828, DOI 10.1016/j.eswa.2012.08.010; Lu LX, 2004, J NUCL SCI TECHNOL, V41, P323, DOI 10.3327/jnst.41.323; Ma JP, 2011, PROG NUCL ENERG, V53, P255, DOI 10.1016/j.pnucene.2010.12.001; Mahmood YA, 2013, INT J SYST ASSUR ENG, V4, P19, DOI 10.1007/s13198-013-0145-x; Malizia A., 2014, WSEAS Trans. Environ. Dev, V10, P453; Mamdikar MR, 2022, NUCL ENG TECHNOL, V54, P1213, DOI 10.1016/j.net.2021.09.038; Martorell S, 2017, RELIAB ENG SYST SAFE, V167, P474, DOI 10.1016/j.ress.2017.06.020; Masullo M, 2022, PROCEDIA COMPUT SCI, V200, P205, DOI 10.1016/j.procs.2022.01.219; Mayo L.H., 1961, Notre Dame Law, V37, P33; McNamara K, 2018, ANN WORK EXPOS HEAL, V62, P808, DOI 10.1093/annweh/wxy057; Mendonça D, 2006, SAFETY SCI, V44, P523, DOI 10.1016/j.ssci.2005.12.006; Meng LH, 2023, INT J DISAST RISK RE, V95, DOI 10.1016/j.ijdrr.2023.103842; Metzroth K.G., 2011, Ph.D. Thesis; Meyer TS, 2011, 2011 IEEE SYSTEMS AND INFORMATION ENGINEERING DESIGN SYMPOSIUM (SIEDS), P146, DOI 10.1109/SIEDS.2011.5876861; Miao HF, 2023, ENERGIES, V16, DOI 10.3390/en16176338; Miller I.M., 2015, Ph.D. Thesis; Miranda S., 2022, ASME Open J. Eng, V1, P0110, DOI [10.1115/1.4053988, DOI 10.1115/1.4053988]; Mól ACA, 2009, PROG NUCL ENERG, V51, P382, DOI 10.1016/j.pnucene.2008.04.003; Mouelhi S., 2013, P 16 INT C HYBR SYST, P83; Mowrer HT, 2000, COMPUT ELECTRON AGR, V27, P139, DOI 10.1016/S0168-1699(00)00113-7; Mu RM, 2015, ENERG POLICY, V76, P161, DOI 10.1016/j.enpol.2014.11.009; Mukhamediev R., 2018, P 2018 IEEE 12 INT C, P1; Mumaw R.J., 1994, NUREG/CR6127; NAITO N, 1987, NUCL TECHNOL, V79, P284, DOI 10.13182/NT87-A34018; Nasstrom JS, 2007, INT J EMERG MANAG, V4, P524, DOI 10.1504/IJEM.2007.014301; Nazari Mohammad Alhuyi, 2018, International Journal of Social Ecology and Sustainable Development, V9, P12, DOI 10.4018/IJSESD.2018010102; Nelson W.R., 1982, Proceedings of the Second National Conference on Artificial Intelligence, Los Altos, California, P296; Newmark N.M., 1978, NUREG/CR-0098; Ohba T, 2021, ENVIRON INT, V148, DOI 10.1016/j.envint.2021.106379; Omitaomu OA, 2012, APPL ENERG, V96, P292, DOI 10.1016/j.apenergy.2011.11.087; Opricovic S, 2007, EUR J OPER RES, V178, P514, DOI 10.1016/j.ejor.2006.01.020; Orhan E., 2022, Journal of International Trade, Logistics and Law, V8, P141, DOI DOI 10.1016/J.ECONLET.2023.111075; Papamichail KN, 2005, DECIS SUPPORT SYST, V41, P84, DOI 10.1016/j.dss.2004.04.014; Parhizkar T, 2021, OCEAN ENG, V237, DOI 10.1016/j.oceaneng.2021.109653; Park WJ, 1997, RADIAT PROT DOSIM, V73, P103, DOI 10.1093/oxfordjournals.rpd.a032108; Pasaoglu G, 2018, ENERG POLICY, V119, P654, DOI 10.1016/j.enpol.2018.04.044; Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3; Pence J, 2019, RISK ANAL, V39, P1262, DOI 10.1111/risa.13241; Peng HM, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8020252; Peng MJ, 2018, NUCL ENG TECHNOL, V50, P396, DOI 10.1016/j.net.2017.11.014; Perko T, 2013, RISK ANAL, V33, P1987, DOI 10.1111/risa.12048; PERROW C, 1981, SOCIETY, V18, P17, DOI 10.1007/BF02701322; Pirouzmand A, 2015, INT J HYDROGEN ENERG, V40, P15198, DOI 10.1016/j.ijhydene.2015.06.043; Podvezko V, 2011, INZ EKON, V22, P134; Power DJ, 2007, DECIS SUPPORT SYST, V43, P1044, DOI 10.1016/j.dss.2005.05.030; Purba JH, 2020, PROG NUCL ENERG, V125, DOI 10.1016/j.pnucene.2020.103376; Qi B, 2023, ENERGIES, V16, DOI 10.3390/en16041850; Qi B, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01879-1; Qi B, 2022, FRONT ENERGY RES, V10, DOI 10.3389/fenrg.2022.920194; Qiyi Chen, 2021, Journal of Physics: Conference Series, V1827, DOI 10.1088/1742-6596/1827/1/012006; Rääf CL, 2019, J RADIOL PROT, V39, P522, DOI 10.1088/1361-6498/ab0577; Rääf C, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228549; Ramuhalli P., 2014, Uncertainty Quantification Techniques for Sensor Calibration Monitoring in Nuclear Power Plants; Rao KD, 2009, RELIAB ENG SYST SAFE, V94, P872, DOI 10.1016/j.ress.2008.09.007; Raskob W, 2010, RADIOPROTECTION, V45, pS9, DOI 10.1051/radiopro/2010013; Raskob W., 2005, P 2 INT ISCRAM C CHA; RASMUSSEN J, 1985, IEEE T SYST MAN CYB, V15, P234, DOI 10.1109/TSMC.1985.6313353; Razavi-Far R, 2009, NEUROCOMPUTING, V72, P2939, DOI 10.1016/j.neucom.2009.04.004; Razmak J, 2015, J MULTI-CRITERIA DEC, V22, P101, DOI 10.1002/mcda.1530; Rios-Insua S, 2006, ECOL MODEL, V196, P195, DOI 10.1016/j.ecolmodel.2005.11.034; ROSS J, 1993, ACAD MANAGE J, V36, P701, DOI 10.5465/256756; Ruijters E, 2015, COMPUT SCI REV, V15-16, P29, DOI 10.1016/j.cosrev.2015.03.001; Saeed A, 2020, ANN NUCL ENERGY, V144, DOI 10.1016/j.anucene.2020.107513; Saeed HA, 2020, PROG NUCL ENERG, V121, DOI 10.1016/j.pnucene.2019.103236; Sakurahara T., 2017, P INT TOP M PROB SAF; Salahshoor K, 2010, ENERGY, V35, P5472, DOI 10.1016/j.energy.2010.06.001; Sangiorgi M, 2020, EARTH SYST SCI DATA, V12, P109, DOI 10.5194/essd-12-109-2020; Saunier O, 2013, ATMOS CHEM PHYS, V13, P11403, DOI 10.5194/acp-13-11403-2013; Schlenzig C., 1999, International Journal of Global Energy Issues, V12, P81; Schroer S, 2013, RELIAB ENG SYST SAFE, V117, P40, DOI 10.1016/j.ress.2013.03.005; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Shalev DM, 2007, RELIAB ENG SYST SAFE, V92, P1231, DOI 10.1016/j.ress.2006.05.015; SILVER MS, 1988, OPER RES, V36, P904, DOI 10.1287/opre.36.6.904; Simsek V, 2014, SCI TOTAL ENVIRON, V499, P74, DOI 10.1016/j.scitotenv.2014.08.038; Stamatis DH., 2003, FAILURE MODE EFFECT; Steinhauser G, 2014, SCI TOTAL ENVIRON, V470, P800, DOI 10.1016/j.scitotenv.2013.10.029; Stohl A, 2012, ATMOS CHEM PHYS, V12, P2313, DOI 10.5194/acp-12-2313-2012; Strubelj L., 2018, P 12 INT C CROAT NUC; Sui Y, 2018, J CLEAN PROD, V183, P261, DOI 10.1016/j.jclepro.2018.02.101; Sun DB, 2021, NUCL ENG DES, V385, DOI 10.1016/j.nucengdes.2021.111514; Swaton E., 1987, International Atomic Energy Agency Bulletin, V29, P27; Takahara S, 2020, HEALTH PHYS, V118, P664, DOI 10.1097/HP.0000000000001176; Tamilselvan P, 2013, RELIAB ENG SYST SAFE, V115, P124, DOI 10.1016/j.ress.2013.02.022; TANAKA H, 1983, IEEE T RELIAB, V32, P453, DOI 10.1109/TR.1983.5221727; Tang SN, 2020, IEEE ACCESS, V8, P9335, DOI 10.1109/ACCESS.2019.2963092; Nguyen TN, 2020, ANN NUCL ENERGY, V149, DOI 10.1016/j.anucene.2020.107767; Triantaphyllou E., 2000, APPL OPTIMIZAT, DOI 10.1007/978-1-4757-3157-62; Tsai TL, 2008, J RADIOL PROT, V28, P347, DOI 10.1088/0952-4746/28/3/005; Tsujimura N., 2012, IRPA, P13; Bekar ET, 2016, J BUS ECON MANAG, V17, P663, DOI 10.3846/16111699.2016.1202314; Vamanu D, 2004, RADIAT PROT DOSIM, V112, P209, DOI 10.1093/rpd/nch399; Van de Walle B, 2008, INF SYST E-BUS MANAG, V6, P295, DOI 10.1007/s10257-008-0087-z; van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3; Vaughan N, 2016, MED ENG PHYS, V38, P59, DOI 10.1016/j.medengphy.2015.11.021; VEDDER RG, 1987, DECISION SCI, V18, P400, DOI 10.1111/j.1540-5915.1987.tb01532.x; Venkatsubramanian V, 2003, COMPUT CHEM ENG, V27, P293, DOI 10.1016/S0098-1354(02)00160-6; Vesely W.E., 1981, Fault Tree Handbook, P154; Volkart K, 2017, ENERG POLICY, V106, P155, DOI 10.1016/j.enpol.2017.03.026; Wadsworth RA, 1995, WATER AIR SOIL POLL, V85, P2649, DOI 10.1007/BF01186234; WALLACE WA, 1985, PUBLIC ADMIN REV, V45, P134, DOI 10.2307/3135008; Wang H, 2021, ANN NUCL ENERGY, V151, DOI 10.1016/j.anucene.2020.107934; Wang H, 2021, ANN NUCL ENERGY, V150, DOI 10.1016/j.anucene.2020.107786; Wang L, 2006, 2006 INTERNATIONAL CONFERENCE ON HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P514; Wang W, 2024, Arxiv, DOI arXiv:2312.10225; Watkins SM, 2011, DISASTER MED PUBLIC, V5, pS134, DOI 10.1001/dmp.2011.26; Winter D, 1997, RADIAT PROT DOSIM, V73, P95, DOI 10.1093/oxfordjournals.rpd.a032172; Wu CY, 2018, IEEE T IND ELECTRON, V65, P9646, DOI 10.1109/TIE.2018.2813991; Wu XH, 2023, MAR POLLUT BULL, V192, DOI 10.1016/j.marpolbul.2023.115067; Xiao XY, 2024, ENERGIES, V17, DOI 10.3390/en17010159; YANG JO, 1989, IEEE T NUCL SCI, V36, P2450, DOI 10.1109/23.45462; Yatsalo Boris, 2012, International Journal of Risk Assessment & Management, V16, P175; Yazdi M, 2017, INT J SYST ASSUR ENG, V8, P1177, DOI 10.1007/s13198-017-0583-y; Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014; Yim HB, 2013, NUCL ENG DES, V255, P212, DOI 10.1016/j.nucengdes.2012.09.027; Yue SB, 2023, Arxiv, DOI arXiv:2309.11325; Yumashev D, 2017, EUR J OPER RES, V261, P368, DOI 10.1016/j.ejor.2017.01.054; Zeman EM., 2020, Abeloff's Clinical Oncology, VSixth, P431, DOI [10.1016/B978-0-323-47674-4.00027-X, DOI 10.1016/B978-0-323-47674-4.00027-X]; Zeng YR, 2007, ADV SOFT COMP, V40, P601; Zeng YR, 2010, INT J COMPUT APPL T, V37, P287, DOI 10.1504/IJCAT.2010.031944; Zerger A., 2003, Computers, Environment and Urban Systems, V27, P123, DOI 10.1016/S0198-9715(01)00021-7; Zhang XH, 2015, SCI TECHNOL NUCL INS, V2015, DOI 10.1155/2015/460131; Zhang YJ, 2022, ANN NUCL ENERGY, V168, DOI 10.1016/j.anucene.2021.108871; Zhang ZH, 2021, ANN NUCL ENERGY, V156, DOI 10.1016/j.anucene.2021.108179; Zhao JQ, 2023, INT J DISAST RISK RE, V86, DOI 10.1016/j.ijdrr.2023.103543; Zhao K., 2005, An Integrated Approach to Performance Monitoring and Fault Diagnosis of Nuclear Power Systems; Zhou TT, 2024, RELIAB ENG SYST SAFE, V245, DOI 10.1016/j.ress.2024.110009; Zhu YM, 2014, ANN NUCL ENERGY, V65, P207, DOI 10.1016/j.anucene.2013.11.016; Zografos KG, 2008, TRANSPORT RES C-EMER, V16, P684, DOI 10.1016/j.trc.2008.01.004	251	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1996-1073		ENERGIES	Energies	MAY	2024	17	10							2439	10.3390/en17102439	http://dx.doi.org/10.3390/en17102439			35	Energy & Fuels	Science Citation Index Expanded (SCI-EXPANDED)	Energy & Fuels	SC7Y9		gold			2024-07-03	WOS:001232337100001
J	Raman, R; Calyam, P; Achuthan, K				Raman, Raghu; Calyam, Prasad; Achuthan, Krishnashree			ChatGPT or Bard: Who is a better Certified Ethical Hacker?	COMPUTERS & SECURITY			English	Article						Ethical hacking; Policy; Social behavior; Readability; Similarity analysis; Cybersecurity generative ai		In this study, we compare two leading Generative AI (GAI) tools, ChatGPT and Bard, specifically in Cybersecurity, using a robust set of standardized questions from a validated Certified Ethical Hacking (CEH) dataset. In the rapidly evolving domain of Generative AI (GAI) and large language models (LLM), a comparative analysis of tools becomes essential to measure their performance. We determine the Comprehensiveness, Clarity, and Conciseness of the AI -generated responses through a detailed questioning -based framework. The study revealed an overall accuracy rate of 80.8 % for ChatGPT and 82.6 % for Bard, indicating comparable capabilities and specific differences. Bard slightly outperformed ChatGPT in accuracy, while ChatGPT exhibited superiority in Comprehensiveness, Clarity, and Conciseness of responses. Introducing a confirmation query like "Are you sure?" increased accuracy for both generative AI tools, illustrating the potential of iterative query processing in enhancing GAI tools' effectiveness. The readability evaluation placed both tools at a college reading level, with Bard marginally more accessible. While evaluating certain questions, a distinct pattern emerged where Bard provided generic denials of assistance while ChatGPT referenced "ethics." This discrepancy illustrates the contrasting philosophies of the developers of these tools, with Bard possibly following stricter guidelines, especially in sensitive topics like Cybersecurity. We explore the implications and identify key areas for future research that become increasingly relevant as GAI tools see broader adoption.	[Raman, Raghu] Amrita Vishwa Vidyapeetham, Amrita Sch Business, Amritapuri 690525, Kerala, India; [Calyam, Prasad] Univ Missouri, Columbia, MO 65211 USA; [Achuthan, Krishnashree] Amrita Vishwa Vidyapeetham, Ctr Cybersecur Syst & Networks, Amritapuri 690525, Kerala, India	Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri; University of Missouri System; University of Missouri Columbia; Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri	Raman, R (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Business, Amritapuri 690525, Kerala, India.	raghu@amrita.edu						Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40977; Alazab M., 2020, Cybersecurity Machine Learning Techniques, P1; Ali R., 2022, Neurosurgery, P10; Alnemari A.M., 2017, App. Comput. Inform., V13, P34; Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502; Caramancion KM, 2023, Arxiv, DOI arXiv:2306.17176; Carlin D., 2021, Cybersecurity Machine Learning Techniques, P27; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Dadkhah M, 2024, ADV PHARM BULL, V14, P1, DOI 10.34172/apb.2024.020; Dao XQ, 2023, Arxiv, DOI [arXiv:2307.02288, DOI 10.48550/ARXIV.2307.02288]; Dos Santos R.P., 2023, arXiv, DOI 10.2139/ssrn.4478305; Doshi R., 2023, medRxiv; El Baz D, 2023, Arxiv, DOI arXiv:2304.11852; Garuba M., 2018, Int. J. Data Sci. Anal., V6, P179; Gaur R., 2019, Advances in Data; Gharib M., 2019, P 16 INT C MOB SYST, P122; Gupta A., 2021, Comput. Secur., V104; Holmes J, 2023, Arxiv, DOI arXiv:2304.01938; Javaid M., 2023, Journal of Economy and Technology, V1, P127, DOI [DOI 10.1016/J.JECT.2023.08.001, 10.1016/j.ject.2023.08.001]; Khademi A, 2023, Arxiv, DOI [arXiv:2304.05372, 10.48550/arXiv.2304.05372]; Kim J., 2019, P 34 ANN ACM S APPL, P842; Lakkaraju Kausik, 2023, PREPRINT; Levinstein B.A., 2023, arXiv; Mansfield-Devine S., 2018, Netw. Secur., V2018, P12; Martin C., 2018, Cyber resilience playbook for public private collaboration; Messier R., 2019, CEH V10 Certified Ethical Hacker Study Guide; Mohamadi S, 2023, Arxiv, DOI arXiv:2307.04251; Naser MZ, 2023, Arxiv, DOI arXiv:2303.18149; Noda R., 2023, medRxiv; Ochieng P, 2023, Arxiv, DOI arXiv:2305.10645; Okey OD, 2023, COMPUT SECUR, V135, DOI 10.1016/j.cose.2023.103476; Patnaik S.S., 2023, medRxiv; Plevris V., 2023, arXiv; Radford A., 2021, Improving language understanding by generative pre-training; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Raman R, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2273377; Soman S, 2023, Arxiv, DOI arXiv:2305.13102; Soomro T.R., 2016, Int. J. Adv. Comput. Sci. Appl., V7, P66; Talboy AN, 2023, Arxiv, DOI [arXiv:2304.01358, 10.48550/arXiv.2304.01358]; Tittel E., 2019, Certif. Mag., V21, P24; Turpin M, 2023, Arxiv, DOI [arXiv:2305.04388, DOI 10.48550/ARXIV.2305.04388]; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Yadav A., 2019, Cyber Security, P1; Zahidi S., The global risks report 2023, V18th	44	2	2	2	2	ELSEVIER ADVANCED TECHNOLOGY	OXFORD	OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0167-4048	1872-6208		COMPUT SECUR	Comput. Secur.	MAY	2024	140								103804	10.1016/j.cose.2024.103804	http://dx.doi.org/10.1016/j.cose.2024.103804		MAR 2024	14	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QQ2O6		hybrid			2024-07-03	WOS:001222271600001
C	Armengol-Estapé, J; Woodruff, J; Cummins, C; O'Boyle, MFP		Grosser, T; Dubach, C; Steuwer, M; Xue, J; Ottoni, G; Pereira, FMQ		Armengol-Estape, Jordi; Woodruff, Jackson; Cummins, Chris; O'Boyle, Michael F. P.			SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly	2024 IEEE/ACM INTERNATIONAL SYMPOSIUM ON CODE GENERATION AND OPTIMIZATION, CGO	International Symposium on Code Generation and Optimization		English	Proceedings Paper	22nd IEEE/ACM International Symposium on Code Generation and Optimization (CGO)	MAR 02-06, 2024	Edinburgh, SCOTLAND	IEEE, Assoc Comp Machinery, IEEE Comp Soc, ACM SIGPLAN, ACM SIGMICRO, Huawei, Amazon, CodePlay, ANT Res, ARM, Rebellions, Google, Furiosa, Moreh, IBM, Qualcomm, AMD, Mangoboost		decompilation; neural decompilation; Transformer; language models; type inference		Decompilation is a well-studied area with numerous high-quality tools available. These are frequently used for security tasks and to port legacy code. However, they regularly generate difficult-to-read programs and require a large amount of engineering effort to support new programming languages and ISAs. Recent interest in neural approaches has produced portable tools that generate readable code. Nevertheless, to-date such techniques are usually restricted to synthetic programs without optimization, and no models have evaluated their portability. Furthermore, while the code generated may be more readable, it is usually incorrect. This paper presents SLaDe, a Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real-world code and augmented with a type inference engine. We utilize a novel tokenizer, dropout-free regularization, and type inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches. Unlike standard approaches, SLaDe can infer out-of-context types and unlike neural approaches, it generates correct code. yWe evaluate SLaDe on over 4,000 ExeBench functions on two ISAs and at two optimization levels. SLaDe is up to 6x more accurate than Ghidra, a state-of-the-art, industrial-strength decompiler and up to 4x more accurate than the large language model ChatGPT and generates significantly more readable code than both.	[Armengol-Estape, Jordi; Woodruff, Jackson; O'Boyle, Michael F. P.] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland; [Cummins, Chris] Meta AI Res, Menlo Pk, CA USA	University of Edinburgh	Armengol-Estapé, J (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.	jordi.armengol.estape@ed.ac.uk; j.c.woodruff@sms.ed.ac.uk; cummins@fb.com; mob@inf.ed.ac.uk			Canada CIFAR AI Chair Program; Canada Excellence Research Chairs Program	Canada CIFAR AI Chair Program; Canada Excellence Research Chairs Program(Canada Research Chairs)	We thank Irina Rish, supported by the Canada CIFAR AI Chair Program and the Canada Excellence Research Chairs Program, and Compute Canada, for the help with part of the compute. We thank the reviewers for their insightful comments.	Anand K., 2010, Decompilation to compiler high IR in a binary rewriter; [Anonymous], 2022, Hex-Rays; Armengol-estape Jordi, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P50, DOI 10.1145/3520312.3534867; Armengol-Estape J., 2021, ADV PROGRAMMING LANG; Artetxe M, 2019, Arxiv, DOI arXiv:1902.01313; Austin J., 2021, arXiv; Ba LJ., 2016, CORR; Bostrom K, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4617; Campbell J. C., 2014, P 11 WORKING C MININ, P252; Cao Y, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P508, DOI 10.1145/3564625.3567998; Chen GBA, 2013, SOFTWARE PRACT EXPER, V43, P1337, DOI 10.1002/spe.2138; Chen M., 2021, arXiv; Chen XY, 2018, 32 C NEURAL INFORM P, V31; CIFUENTES C, 1995, SOFTWARE PRACT EXPER, V25, P811, DOI 10.1002/spe.4380250706; Collie B, 2020, GPCE '2020: PROCEEDINGS OF THE 19TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON GENERATIVE PROGRAMMING: CONCEPTS AND EXPERIENCES, P1, DOI 10.1145/3425898.3426952; da Silva AF, 2021, INT SYM CODE GENER, P378, DOI 10.1109/CGO51591.2021.9370322; Dasgupta S, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P655, DOI 10.1145/3385412.3385964; Drissi M., 2018, Program language translation using a grammar-driven tree-to-tree model; Flores-Montoya A, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1075; Fu C, 2019, ADV NEUR IN, V32; Ghidra, 2022, about us; Gui Y, 2022, EUR CON SFTWR MTNCE, P601, DOI 10.1109/SANER53432.2022.00077; Guo Z. C., 2022, IEEE HIGH PERF EXTR, P1, DOI DOI 10.1109/HPEC55821.2022.9926313; He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]; Hong HW, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3495; Hosseini I., 2022, WORKSHOP BINARY ANAL; HOUSEL III B. C, 1973, A study of decompiling machine languages into high-Level machine independent languages; Kang Y., 2021, EMNLP; Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222; Katz O., 2019, Towards neural decompilation; Katz O., 2019, arXiv; Katz O, 2019, Arxiv, DOI arXiv:1905.08325; Kingma D. P., 2017, ARXIV; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lachaux M.-A., 2020, Unsupervised translation of programming languages; Lachaux MA, 2020, Arxiv, DOI arXiv:2006.03511; Lacomis J, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P640, DOI 10.1109/ASE.2019.00064; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Liu Z., 2020, P 29 ACM SIGSOFT INT, P475, DOI DOI 10.1145/3395363.3397370; Lu S, 2021, ARXIV; Maarif HA, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING (ICCCE), P135, DOI 10.1109/ICCCE.2014.48; Mandal S, 2023, Arxiv, DOI arXiv:2304.09181; Melo L. T. C., 2018, POPL; Muffo M, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P291; OpenAi, ChatGPT; Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48; Paszke A., 2017, NEURAL INFORM PROCES; Pizzolotto D, 2021, Identifying compiler and optimization level in binary code from multipler architectures; Retdec, 2017, Retargetable decompiler; Roziere B., 2020, NeurIPs; Santos EA, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P311, DOI 10.1109/SANER.2018.8330219; Schulte E., 2018, WORKSHOP BINARY ANAL; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; SLaDe authors, 2023, Artifact for SLaDe: A Portable Small Language Model Decompiler for Optimized Assembler (CGO 24), DOI DOI 10.5281/ZENODO.10205121; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stitt G, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255471; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Tan Zujun, 2023, ASPLOS 2023: Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, P679, DOI 10.1145/3582016.3582058; Vaswani A, 2017, ADV NEUR IN, V30; Le V, 2014, ACM SIGPLAN NOTICES, V49, P216, DOI [10.1145/2666356.2594334, 10.1145/2594291.2594334]; Winskel G., 1993, The Formal Semantics of Programming Languages: An Introduction; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yadavalli S.B., 2019, P 20 ACM SIGPLAN SIG, P213, DOI DOI 10.1145/3316482.3326354; Yakdan K, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23185	65	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2164-2397		979-8-3503-9509-9	INT SYM CODE GENER			2024							67	80						14	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6NS		Green Submitted			2024-07-03	WOS:001179185400006
J	Robinson, A; Aggarwal, S				Robinson, Alexander; Aggarwal Jr, Shaurya			When Precision Meets Penmanship: ChatGPT and Surgery Documentation	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						laparoscopic surgery; appendicectomy; nhs; chatgpt; surgical documentation		ChatGPT (Chatbot Generative Pre-Trained Transformer) is an artificial intelligence with several potential applications in the field of medicine. As a large language model, it is particularly good at generating text. This study investigates the use of ChatGPT in constructing operation notes for laparoscopic appendicectomy, one of the most common surgical procedures in the UK. We prompted ChatGPT-4, the latest generation of ChatGPT, to produce operation notes for laparoscopic appendicectomy, which were then evaluated against 'Getting It Right First Time' (GIRFT) recommendations. GIRFT is an organisation that has collaborated with the National Health Service (NHS) to improve surgical documentation guidelines. Excluding certain items documented elsewhere in patient records, the generated notes were assessed against 30 key points in GIRFT recommendations. This process was repeated three times to obtain an average score. Our results showed that ChatGPT generated operation notes in seconds, with an average coverage of 78.8% (23.66 out of 30 points) of the GIRFT guidelines, surpassing average compliance with similar guidelines from the Royal College of Surgeons (RCS). However, the quality of ChatGPT's output was found to be dependent on the quality of the prompt, highlighting the need for verification of the generated content. Additionally, secure integration with electronic health records is required before ChatGPT can be adopted into the NHS.	[Robinson, Alexander; Aggarwal Jr, Shaurya] Mid & South Essex NHS Nat Hlth Serv Fdn Trust, Gen Surg, Chelmsford, England		Robinson, A (corresponding author), Mid & South Essex NHS Nat Hlth Serv Fdn Trust, Gen Surg, Chelmsford, England.	alexander.robinson2@nhs.net						Abbas SH, 2016, INT J SURG OPEN, V2, P1, DOI 10.1016/j.ijso.2016.03.002; [Anonymous], 2022, RESOLUTION NHS NHS R; GIRFT, 2022, GIRFT RCS ASGBI BEST; GIRFT, 2022, NEW RANGE GUIDANCE B; NHS England, 2023, US AI DRIV DICT PLAT; O'Neill A, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2022-062469; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Shah S, 2022, IRISH J MED SCI, V191, P825, DOI 10.1007/s11845-021-02567-6	8	2	2	3	8	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUN 17	2023	15	6								10.7759/cureus.40546	http://dx.doi.org/10.7759/cureus.40546			8	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	N3BM0	37465809	Green Published, gold			2024-07-03	WOS:001035807800015
J	Sap, M; Jafarpour, A; Choi, Y; Smith, NA; Pennebaker, JW; Horvitz, E				Sap, Maarten; Jafarpour, Anna; Choi, Yejin; Smith, Noah A.; Pennebaker, James W.; Horvitz, Eric			Quantifying the narrative flow of imagined versus autobiographical stories	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						natural language processing; imagination; narrative; memory; deep neural networks	MEMORY; COMPREHENSION; PERCEPTION; SELF	Lifelong experiences and learned knowledge lead to shared expectations about how common situations tend to unfold. Such knowledge of narrative event flow enables people to weave together a story. However, comparable computational tools to evaluate the flow of events in narratives are limited. We quantify the differences between autobiographical and imagined stories by introducing sequentiality, a measure of narrative flow of events, drawing probabilistic inferences from a cutting-edge large language model (GPT-3). Sequentiality captures the flow of a narrative by comparing the probability of a sentence with and without its preceding story context. We applied our measure to study thousands of diary-like stories, collected from crowdworkers, about either a recent remembered experience or an imagined story on the same topic. The results show that imagined stories have higher sequentiality than autobiographical stories and that the sequentiality of autobiographical stories increases when the memories are retold several months later. In pursuit of deeper understandings of how sequentiality measures the flow of narratives, we explore proportions of major and minor events in story sentences, as annotated by crowdworkers. We find that lower sequentiality is associated with higher proportions of major events. The methods and results highlight opportunities to use cutting-edge computational analyses, such as sequentiality, on large corpora of matched imagined and autobiographical stories to investigate the influences of memory and reasoning on language generation processes.	[Sap, Maarten] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA; [Sap, Maarten; Choi, Yejin; Smith, Noah A.; Horvitz, Eric] Univ Washington, Paul G Allen Sch Comp Sci & Amp Engn, Seattle, WA 98195 USA; [Sap, Maarten; Horvitz, Eric] Microsoft, Redmond, WA 98052 USA; [Jafarpour, Anna] Univ Washington, Dept Physiol & Biophys, Seattle, WA 98195 USA; [Choi, Yejin; Smith, Noah A.] Allen Inst AI, Seattle, WA 98103 USA; [Pennebaker, James W.] Univ Texas Austin, Dept Psychol, Austin, TX 78712 USA	Carnegie Mellon University; University of Washington; University of Washington Seattle; Microsoft; University of Washington; University of Washington Seattle; University of Texas System; University of Texas Austin	Sap, M (corresponding author), Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.; Sap, M; Horvitz, E (corresponding author), Univ Washington, Paul G Allen Sch Comp Sci & Amp Engn, Seattle, WA 98195 USA.; Sap, M; Horvitz, E (corresponding author), Microsoft, Redmond, WA 98052 USA.; Jafarpour, A (corresponding author), Univ Washington, Dept Physiol & Biophys, Seattle, WA 98195 USA.	maartensap@cmu.edu; annaja@uw.edu; horvitz@microsoft.com	Pennebaker, James/GLR-6058-2022	Pennebaker, James/0000-0001-9091-214X; Horvitz, Eric/0000-0002-8823-0614	NIH [K99MH120048]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Microsoft provided an internship for M.S, support for crowdworkers, and computing resources for running the GPT-3 neural language model on HIPPOCORPUS. A.J. was supported by NIH Brain Initiative Grant K99MH120048. We are indebted to Paul Koch at the Office of the Chief Scientific Officer for for running the GPT-3 computation. We thank Zhilin Wang and members of the Buffalo Lab at the University of Washington for valuable discussions.	Bartlett F.C., 1932, Remembering: A Study in Experimental and Social Psychology, DOI 10.1111/j.2044-8279.1933.tb02913.x; BLACK JB, 1981, J VERB LEARN VERB BE, V20, P267, DOI 10.1016/S0022-5371(81)90417-5; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; BOWER GH, 1979, COGNITIVE PSYCHOL, V11, P177, DOI 10.1016/0010-0285(79)90009-4; Boyd RL, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba2196; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Clewett D, 2019, HIPPOCAMPUS, V29, P162, DOI 10.1002/hipo.23074; Conway MA, 1996, J EXP PSYCHOL GEN, V125, P69, DOI 10.1037/0096-3445.125.1.69; Conway MA, 2003, NEUROPSYCHOLOGIA, V41, P334, DOI 10.1016/S0028-3932(02)00165-3; Devlin J., 2019, CoRR, P4171; Franklin NT, 2020, PSYCHOL REV, V127, P327, DOI 10.1037/rev0000177; Gilboa A, 2018, NEUROPSYCHOLOGIA, V110, P1, DOI 10.1016/j.neuropsychologia.2017.12.020; Gordon Jonathan, 2013, P 2013 WORKSHOP AUTO, P25, DOI [10.1145/2509558.2509563, DOI 10.1145/2509558.2509563]; GRAESSER AC, 1981, COGNITIVE PSYCHOL, V13, P1, DOI 10.1016/0010-0285(81)90002-5; Greenberg MA, 1996, J PERS SOC PSYCHOL, V71, P588, DOI 10.1037/0022-3514.71.3.588; Grysman A, 2011, MEMORY, V19, P501, DOI 10.1080/09658211.2011.590502; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Hyman IE, 1998, CLIN PSYCHOL REV, V18, P933, DOI 10.1016/S0272-7358(98)00041-5; Jafarpour A, 2019, J COGNITIVE NEUROSCI, V31, P874, DOI 10.1162/jocn_a_01392; Jaidka K, 2020, P NATL ACAD SCI USA, V117, P10165, DOI 10.1073/pnas.1906364117; KINTSCH W, 1988, PSYCHOL REV, V95, P163, DOI 10.1037/0033-295X.95.2.163; Kintsch W., 1978, DISCOURSE PROCESS, V1, P1, DOI DOI 10.1080/01638537809544425; Kurby CA, 2008, TRENDS COGN SCI, V12, P72, DOI 10.1016/j.tics.2007.11.004; Laban P, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P1058; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Li B, 2013, P 27 AAAI C ART INT, P598; Marsh EJ, 2007, CURR DIR PSYCHOL SCI, V16, P16, DOI 10.1111/j.1467-8721.2007.00467.x; Michaelian K, 2018, AM J PSYCHOL, V131, P99, DOI 10.5406/amerjpsyc.131.1.0099; Nabi RL, 2015, MEDIA PSYCHOL, V18, P137, DOI 10.1080/15213269.2014.912585; Nastase SA, 2020, BIORXIV, DOI 10.1101/2020.12.02.403477; NLTK Project, NLTK DOC; NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39; Pennebaker JW., 2015, LINGUISTIC INQUIRY W; Piper A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P298; Radford A., 2018, IMPROVING LANGUAGE U; Reagan AJ, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0093-1; Reichardt R, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00152; Sap M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1970; Schacter DL, 2007, PHILOS T R SOC B, V362, P773, DOI 10.1098/rstb.2007.2087; Schank R.C., 1977, SCRIPTS PLANS GOALS; Sims M., 2019, LIT EVENT DETECTION; Smorti A, 2016, INTEGR PSYCHOL BEHAV, V50, P296, DOI 10.1007/s12124-015-9330-6; SQUIRE LR, 1981, J NEUROSCI, V1, P635; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; THORNDYKE PW, 1977, COGNITIVE PSYCHOL, V9, P77, DOI 10.1016/0010-0285(77)90005-6; Toubia O, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2011695118; Tulving E., 1972, Organization of memory, V1, P1, DOI DOI 10.1017/S0140525X00047257; Underwood T., 2013, INVENTION HIST PERSP, P55; Underwood T, 2020, PMLA, V135, P92; van Kesteren MTR, 2012, TRENDS NEUROSCI, V35, P211, DOI 10.1016/j.tins.2012.02.001; van Laer T, 2019, J CONSUM RES, V46, P267, DOI 10.1093/jcr/ucy067; Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273; Zwaan RA, 1998, PSYCHOL BULL, V123, P162, DOI 10.1037/0033-2909.123.2.162	55	5	5	7	26	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	NOV 8	2022	119	45							e2211715119	10.1073/pnas.2211715119	http://dx.doi.org/10.1073/pnas.2211715119			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	7N9GJ	36322749	Green Published, hybrid			2024-07-03	WOS:000907643500053
J	Kalluri, B; Prasad, P; Sharma, P; Chippa, D				Kalluri, Balaji; Prasad, Prajish; Sharma, Prakrati; Chippa, Divyaansh			Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India	IEEE TRANSACTIONS ON EDUCATION			English	Article; Early Access						Education; Sustainable development; Computational modeling; Systems thinking; Programming profession; Software systems; Green products; 21st-century skills; computer science (CS); creative pedagogy; foundational education; future thinking		Contribution: This article proposes a new theoretical model with a goal to develop future human computational thinking (CT) in foundational computer science (CS) education. The model blends six critical types of thinking, i.e., logical thinking, systems thinking, sustainable thinking, strategic thinking, creative thinking, and responsible thinking into the design of a first-year undergraduate programming course. The study describes a creative blended pedagogy that embeds the proposed model into the course plan. Background: The emergence of artificial intelligent systems such as large language models from a knowledge provider perspective, coupled with a gradual change in post-pandemic outlook of education challenge the relevance and raises concerns about the future of education. The 21st-century human CT requirements, viz., learning to code (skill) and thinking computationally (competency), will be inadequate in the future. Moreover, there is substantial evidence which shows that most introductory programming courses fail to integrate critical elements like ethics and responsibility as part of the course. Intended Outcomes: The authors anticipate experiential learning models such as this has immense potential to future-proof CS education, as well as make future software engineers responsible citizens. Application Design: The proposed model blends six types of thinking into the design and activities of the course. The underlying theoretical basis of these activities revolve around three key principles: 1) experiential learning; 2) self-reflection; and 3) peer learning. Findings: This case study from a liberal educational institution in India qualitatively shows evidence of students developing six critical elements of thinking that shapes their future CT ability.	[Kalluri, Balaji; Prasad, Prajish; Sharma, Prakrati; Chippa, Divyaansh] FLAME Univ, Sch Comp & Data Sci, Pune 412115, India		Kalluri, B (corresponding author), FLAME Univ, Sch Comp & Data Sci, Pune 412115, India.	balaji.kalluri@flame.edu.in			seed fund given to Kalluri's Urban Design and Open-innovation Studio (KUDOS) at FLAME University	seed fund given to Kalluri's Urban Design and Open-innovation Studio (KUDOS) at FLAME University	No Statement Available	Boden Margaret A., 2004, The creative mind: Myths and mechanisms, DOI DOI 10.4324/9780203508527; Cohen Lena, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P858, DOI 10.1145/3408877.3432456; Daniel Pargman, 2016, P 8 INT C ENG ED SUS, P302; Dieleman H, 2006, J CLEAN PROD, V14, P837, DOI 10.1016/j.jclepro.2005.11.031; Ding Y., 2018, M.S. thesis; Easterbrook S, 2014, PROCEEDINGS OF THE 2014 CONFERENCE ICT FOR SUSTAINABILITY, P235; Fiesler Casey, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P1027, DOI 10.1145/3408877.3432510; FORRESTER JW, 1968, MANAGE SCI, V14, P398, DOI 10.1287/mnsc.14.7.398; Furber S., 2012, Shut down or restart? The way forward for computing in UK schools; Gautam A, 2024, Arxiv, DOI arXiv:2401.01285; Hemmendinger D., 2010, ACM Inroads, V1, P4; HIGGINS L, 1992, WRIT COMMUN, V9, P48, DOI 10.1177/0741088392009001002; Indo-Asian News Service, 2016, India TodayAug. 17; Kafai Y, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P101, DOI 10.1145/3291279.3339400; Kolb DA., 2015, EXPERIENTIAL LEARNIN, DOI DOI 10.1016/B978-0-7506-7223-8.50017-4; Krogstie B, 2020, PROC FRONT EDUC CONF; Laszlo E., 1996, A systems view of the world: A holistic vision for our time; Leifler O, 2020, PROC FRONT EDUC CONF; Lewis L., 1994, New Directions for Adult and Continuing Education, V62, P5, DOI DOI 10.1002/ACE.36719946203; Lin K, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P265, DOI 10.1145/3478431.3499291; Palm J, 2023, ENERGY SUSTAIN SOC, V13, DOI 10.1186/s13705-023-00393-5; Park W., 2021, CREATIVITY STUDIES, V14, P160, DOI DOI 10.3846/CS.2021.13700; Peters AK, 2024, ACM T COMPUT EDUC, V24, DOI 10.1145/3639060; Pollock I, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P1, DOI 10.1145/3344429.3372500; Romero M, 2017, INT J EDUC TECHNOL H, V14, DOI 10.1186/s41239-017-0080-z; Schon D. A., 1987, ED REFLECTIVE PRACTI; Selby C. C., 2013, 18 ANN C INN TECHN C; Shute VJ, 2017, EDUC RES REV-NETH, V22, P142, DOI 10.1016/j.edurev.2017.09.003; Sternberg Robert J., 1999, Handbook of Creativity, V1; Thomas I, 2009, J TRANSFORM EDUC, V7, P245, DOI 10.1177/1541344610385753; Tilbury D., 2016, Education for Sustainable Development: An Expert Review of Processes and Learning, P42; Veenman K, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.956901; Weintrop D, 2016, J SCI EDUC TECHNOL, V25, P127, DOI 10.1007/s10956-015-9581-5; Wing J., 2014, 40 ANNIVERSARY BLOG, V26; Zainuddin Z, 2018, COMPUT EDUC, V126, P75, DOI 10.1016/j.compedu.2018.07.003	35	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9359	1557-9638		IEEE T EDUC	IEEE Trans. Educ.	2024 MAY 15	2024										10.1109/TE.2024.3394060	http://dx.doi.org/10.1109/TE.2024.3394060		MAY 2024	10	Education, Scientific Disciplines; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Engineering	RF1R7		Green Submitted			2024-07-03	WOS:001226166900001
J	Kejriwal, M; Santos, H; Shen, K; Mulvehill, AM; Mcguinness, DL				Kejriwal, Mayank; Santos, Henrique; Shen, Ke; Mulvehill, Alice M.; Mcguinness, Deborah L.			A noise audit of human-labeled benchmarks for machine commonsense reasoning	SCIENTIFIC REPORTS			English	Article								With the advent of large language models, evaluating and benchmarking these systems on important AI problems has taken on newfound importance. Such benchmarking typically involves comparing the predictions of a system against human labels (or a single 'ground-truth'). However, much recent work in psychology has suggested that most tasks involving significant human judgment can have non-trivial degrees of noise. In his book, Kahneman suggests that noise may be a much more significant component of inaccuracy compared to bias, which has been studied more extensively in the AI community. This article proposes a detailed noise audit of human-labeled benchmarks in machine commonsense reasoning, an important current area of AI research. We conduct noise audits under two important experimental conditions: one in a smaller-scale but higher-quality labeling setting, and another in a larger-scale, more realistic online crowdsourced setting. Using Kahneman's framework of noise, our results consistently show non-trivial amounts of level, pattern, and system noise, even in the higher-quality setting, with comparable results in the crowdsourced setting. We find that noise can significantly influence the performance estimates that we obtain of commonsense reasoning systems, even if the 'system' is a human; in some cases, by almost 10 percent. Labeling noise also affects performance estimates of systems like ChatGPT by more than 4 percent. Our results suggest that the default practice in the AI community of assuming and using a 'single' ground-truth, even on problems requiring seemingly straightforward human judgment, may warrant empirical and methodological re-visiting.	[Kejriwal, Mayank; Shen, Ke] Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA; [Santos, Henrique; Mulvehill, Alice M.; Mcguinness, Deborah L.] Rensselaer Polytech Inst, Tetherless World Constellat, Troy, NY USA	University of Southern California; Rensselaer Polytechnic Institute	Kejriwal, M (corresponding author), Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA.	kejriwal@isi.edu			Defense Advanced Research Projects Agency [N660011924033]; DARPA Machine Common Sense (MCS) program	Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); DARPA Machine Common Sense (MCS) program	This work was funded under the DARPA Machine Common Sense (MCS) program under award number N660011924033.	[Anonymous], 2007, The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future; Aroyo L, 2015, AI MAG, V36, P15, DOI 10.1609/aimag.v36i1.2564; Bartolomeo J., 1981, Sentence Decision Making: The Logic of Sentence Decisions and the Extent and Sources of Sentence Disparity; Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432; Bruce R., 1998, P 3 C EMP METH NAT L, P53; Chakraborty J, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P429, DOI 10.1145/3468264.3468537; Chen D. L., 2016, Contemp. Acc. Res., V33, P172; Chung John Joon Young, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359164; CLANCY K, 1981, J CRIM LAW CRIM, V72, P524, DOI 10.2307/1143005; Davis E, 2023, Arxiv, DOI [arXiv:2302.04752, DOI 10.48550/ARXIV.2302.04752]; Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fadel A., 2020, P 14 WORKSH SEM EV I, P535; Feitelson DG, 2015, Arxiv, DOI [arXiv:1512.08409, DOI 10.48550/ARXIV.1512.08409, 10.48550/arXiv.1512.08409]; Gordon A.S., 2017, A Formal Theory of Commonsense Psychology: How People Think People Think, DOI [DOI 10.1017/9781316584705, doi: 10.1017/9781316584705]; Gordon M.L., 2021, P 2021 CHI C HUM FAC, P1, DOI DOI 10.1145/3411764.3445423; Gunning D, 2018, Arxiv, DOI arXiv:1810.07528; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Huang L., 2019, Cosmos qa: Machine reading comprehension with contextual commonsense reasoning; Johnston L.W., 1970, J. Qual. Technol, V2, P243, DOI [DOI 10.1080/00224065.1970.11980443, 10.1080/00224065.1970.11980443]; Kejriwal M, 2022, NAT MACH INTELL, V4, P318, DOI 10.1038/s42256-022-00478-4; Kim JY, 2022, INFORM TECHNOL PEOPL, V35, P861, DOI 10.1108/ITP-04-2019-0173; Kluver Daniel., 2012, Proceedings of the sixth ACM conference on Recommender systems. RecSys '12, P99, DOI DOI 10.1145/2365952.2365974; KVALSETH TO, 1989, PSYCHOL REP, V65, P223, DOI 10.2466/pr0.1989.65.1.223; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Leivada E., 2023, Soc. Sci. Hum. Open, V8; Levesque H., 2012, 13 INT C PRINCIPLES; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Paolacci G, 2010, JUDGM DECIS MAK, V5, P411; Pisani B., 2021, Nobel Prize winner Daniel Kahneman is out with a new book on why we all make such bad judgments; Plank B., 2022, P 2022 C EMPIRICAL M, p10,671, DOI 10.18653/v1/2022.emnlp-main.731; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Dash SR, 2020, Arxiv, DOI arXiv:2007.10830; Salganik MJ, 2020, P NATL ACAD SCI USA, V117, P8398, DOI 10.1073/pnas.1915006117; Santos H., 2021, Exp. Results, V2, DOI [DOI 10.1017/EXP.2021.9, 10.1017/exp.2021.9]; Santos H, 2022, Arxiv, DOI [arXiv:2203.12184, DOI 10.48550/ARXIV.2203.12184, 10.48550/arXiv.2203.12184]; Sap M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4463; Shen K, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13243; Sonis J, 1998, Fam Med, V30, P584; Sorokin A, 2008, PROC CVPR IEEE, P23; Storks S, 2020, Arxiv, DOI [arXiv:1904.01172, DOI 10.48550/ARXIV.1904.01172]; Sunstein CR, 2022, DUKE LAW J, V71, P1175; Teruel M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P4061; Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Wais P., 2011, 3 AAAI C HUMAN COMPU; Wang C., 2020, P 14 INT WORKSHOP SE; Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791; Zhan XL, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109964	50	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 14	2024	14	1							8609	10.1038/s41598-024-58937-4	http://dx.doi.org/10.1038/s41598-024-58937-4			18	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	NW2A9	38615039	Green Submitted, gold, Green Published			2024-07-03	WOS:001203415400001
J	Ross, J; Belgodere, B; Chenthamarakshan, V; Padhi, I; Mroueh, Y; Das, P				Ross, Jerret; Belgodere, Brian; Chenthamarakshan, Vijil; Padhi, Inkit; Mroueh, Youssef; Das, Payel			Large-scale chemical language representations capture molecular structure and properties	NATURE MACHINE INTELLIGENCE			English	Article								Large language models have recently emerged with extraordinary capabilities, and these methods can be applied to model other kinds of sequence, such as string representations of molecules. Ross and colleagues have created a transformer-based model, trained on a large dataset of molecules, which provides good results on property prediction tasks. Models based on machine learning can enable accurate and fast molecular property predictions, which is of interest in drug discovery and material design. Various supervised machine learning models have demonstrated promising performance, but the vast chemical space and the limited availability of property labels make supervised learning challenging. Recently, unsupervised transformer-based language models pretrained on a large unlabelled corpus have produced state-of-the-art results in many downstream natural language processing tasks. Inspired by this development, we present molecular embeddings obtained by training an efficient transformer encoder model, MoLFormer, which uses rotary positional embeddings. This model employs a linear attention mechanism, coupled with highly distributed training, on SMILES sequences of 1.1 billion unlabelled molecules from the PubChem and ZINC datasets. We show that the learned molecular representation outperforms existing baselines, including supervised and self-supervised graph neural networks and language models, on several downstream tasks from ten benchmark datasets. They perform competitively on two others. Further analyses, specifically through the lens of attention, demonstrate that MoLFormer trained on chemical SMILES indeed learns the spatial relationships between atoms within a molecule. These results provide encouraging evidence that large-scale molecular language models can capture sufficient chemical and structural information to predict various distinct molecular properties, including quantum-chemical properties.	[Ross, Jerret; Belgodere, Brian; Chenthamarakshan, Vijil; Padhi, Inkit; Mroueh, Youssef; Das, Payel] IBM Res, Yorktown Hts, NY 10598 USA	International Business Machines (IBM)	Ross, J; Das, P (corresponding author), IBM Res, Yorktown Hts, NY 10598 USA.	rossja@us.ibm.com; daspa@us.ibm.com		Chenthamarakshan, Vijil/0000-0001-7830-5777				Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367; [Anonymous], 2016, arXiv preprint arXiv:1609.02907; [Anonymous], 2007, DAYLIGHT CHEM INFORM; [Anonymous], 2017, ADV NEURAL INFORM PR; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Chen PF, 2019, Arxiv, DOI arXiv:1906.05488; Chen T, 2020, PR MACH LEARN RES, V119; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Choromanski K, 2021, PROC 9 INT C LEARNIN; Defferrard M, 2016, ADV NEUR IN, V29; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duvenaudt D, 2015, ADV NEUR IN, V28; Fang XM, 2022, NAT MACH INTELL, V4, P127, DOI 10.1038/s42256-021-00438-4; Gao W., 2022, Thirty-Sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track; Gilmer J, 2017, PR MACH LEARN RES, V70; Goh G. B., 2017, PREPRINT, DOI [10.48550/arXiv.1712.02034, DOI 10.48550/ARXIV.1712.02034]; Hamilton WL, 2017, ADV NEUR IN, V30; Hu W, 2020, 8 INT C LEARNING REP; Irwin JJ, 2005, J CHEM INF MODEL, V45, P177, DOI 10.1021/ci049714+; Jo J, 2020, METHODS, V179, P65, DOI 10.1016/j.ymeth.2020.05.009; Katharopoulos A, 2020, PR MACH LEARN RES, V119; Ke G., 2021, 9 INT C LEARNING REP; Kim Sunghwan, 2019, Nucleic Acids Res, V47, pD1102, DOI 10.1093/nar/gky1033; Kirkpatrick P, 2004, NATURE, V432, P823, DOI 10.1038/432823a; Kitaev N, 2020, REFORMER EFFICIENT T; Klicpera Johannes, 2020, INT C LEARN REPR; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Li Y., 2016, 4 INT C LEARNING REP; Liao R., 2019, 7 INT C LEARNING REP; Liu S., 2022, INT C LEARNING REPRE; Liu SC, 2019, 33 C NEURAL INFORM P, V32; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu CQ, 2019, AAAI CONF ARTIF INTE, P1052; Öztürk H, 2018, BIOINFORMATICS, V34, P821, DOI 10.1093/bioinformatics/bty593; Paul A, 2018, Arxiv, DOI arXiv:1811.08283; Raffel C, 2020, J MACH LEARN RES, V21; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Rupp M, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.058301; Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38; Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576; Shaw P., 2018, P 2018 C N AM CHAPT, P464, DOI DOI 10.48550/ARXIV.1803.02155; Shin B., 2019, MACHINE LEARNING HEA, P230, DOI DOI 10.48550/ARXIV.1908.06760; Shiwei Wang, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P29, DOI 10.1109/ICIVC50857.2020.9177456; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic G., 2018, 6 INT C LEARNING REP; Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Xiong ZP, 2020, J MED CHEM, V63, P8749, DOI 10.1021/acs.jmedchem.9b00959; Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237; You Y., 2020, PROC INT C LEARNING	56	40	42	28	72	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	DEC	2022	4	12								10.1038/s42256-022-00580-7	http://dx.doi.org/10.1038/s42256-022-00580-7			13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	7Z6CX		Green Submitted			2024-07-03	WOS:000915646400002
J	Malhotra, A; Jindal, R				Malhotra, Anshu; Jindal, Rajni			XAI Transformer based Approach for Interpreting Depressed and Suicidal User Behavior on Online Social Networks	COGNITIVE SYSTEMS RESEARCH			English	Article						Deep Learning; Transformers; Large Language Models; Explainable Artificial Intelligence (XAI); Natural Language Processing; Affective Computing; Cognitive Systems; Online Social Networks; Depression; Suicide; Mental Health		Online social networks can be used for mental healthcare monitoring using Artificial Intelligence and Machine Learning techniques for detecting various mental health disorders and corresponding risk assessment. Recent research in this domain has primarily been focused on leveraging deep neural networks and various Transformer based Large Language Models, which have now become state-of-the-art for most natural language processing and computational linguistic tasks due to their unmatched prediction accuracy. Unlike conventional machine learning algorithms, these deep neural networks are black box architectures, where it is difficult to interpret and explain their predicted outcome. However, a black box classification outcome is insufficient for healthcare applications. Such systems will not be widely adopted and trusted by healthcare practitioners if they are not able to understand and explain the reasoning behind the predicted decisions made by an AI and ML based healthcare diagnostic system. The key objective of our research is to demonstrate the applications of model agnostic, post hoc surrogate XAI techniques for providing explainability to classification decisions of pretrained LLMs (Transformers) based mental healthcare diagnostic systems fine-tuned (or trained) to detect depressive and suicidal behavior using UGC from online social networks. For this, we have used the two most recent and popular techniques, SHAP and LIME. We have conducted extensive and in-depth experiments with four datasets and six pretrained LLMs, three of which have already been domain-adapted using mental health related datasets. We have also performed Few Shot Learning experiments with these three pretrained mental health domain-adapted LLMs. The results of qualitative and descriptive data analysis in this paper demonstrate that in order to build a comprehensive understanding of a person's psychological state, emotion, and behavior and to discover the causes, symptoms, and triggers of mental health issues, it is essential to utilize eXplAInable (XAI) techniques with Transformer based LLMs (supervised). Alternatively, Transformer based unsupervised topic modeling technique BERTopic may be used for mental health risk monitoring and cause or symptom extraction when supervised training of LLMs is not feasible due to dataset annotation or availability challenges.	[Malhotra, Anshu; Jindal, Rajni] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India	Delhi Technological University	Malhotra, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.	anshumalhotra5@gmail.com						Alam L, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01542-6; Alex N., 2021, 35 C NEUR INF PROC S; Alhamadani A, 2022, P 2022 IEEE ACM INT, P427, DOI [DOI 10.1109/ASONAM55673, 10.1109/ASONAM55673.2022.10068655]; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; Ambalavanan A.K., 2019, P 6 WORKSH COMP LING, P172; American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU; Angelov D, 2020, Arxiv, DOI [arXiv:2008.09470, DOI 10.48550/ARXIV.2008.09470, 10.48550/arXiv.2008.09470]; Balasubramaniam N, 2023, INFORM SOFTWARE TECH, V159, DOI 10.1016/j.infsof.2023.107197; Banerjee S, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100506; Bayram U., 2021, NAACL HLT, V2021, P81; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carbonell J.G., 1983, Mach. Learn, V1, P3, DOI [DOI 10.1007/978-3-662-12405-5, 10.1007/978-3-662-12405-5]; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chung J., 2014, NIPS 2014 WORKSHOP D; Cinà G, 2022, Arxiv, DOI [arXiv:2206.15363, DOI 10.48550/ARXIV.2206.15363]; Cloudera Fast Forward Lab, 2017, Interpretability; Combi C, 2022, ARTIF INTELL MED, V133, DOI 10.1016/j.artmed.2022.102423; Coppersmith G., 2014, ICWSM, P579, DOI [10.1609/icwsm.v8i1.14574, DOI 10.1609/ICWSM.V8I1.14574]; Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]; Cutillo CM, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0254-2; Das A., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2006.11371; De Choudhury M., 2013, P INT AAAI C WEB SOC, V7, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998]; De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207; Devlin J., 2020, BERT. Google Research GitHub Repository; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duda RO, 1973, Pattern Classification and Scene Analysis; Févotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168; Garg M, 2023, ARCH COMPUT METHOD E, V30, P1819, DOI 10.1007/s11831-022-09863-z; Gaur M, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P514, DOI 10.1145/3308558.3313698; Gkotsis G, 2017, SCI REP-UK, V7, DOI 10.1038/srep45141; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Greco CM, 2023, PATTERN RECOGN LETT, V167, P204, DOI 10.1016/j.patrec.2023.02.016; Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Han Sooji, 2022, COLING, P94; Haque A, 2021, LECT NOTES COMPUT SC, V12895, P436, DOI 10.1007/978-3-030-86383-8_35; Hinton G.E., 2012, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), P599, DOI [DOI 10.1007/978-3-642-35289-8-32, DOI 10.1007/978-3-642-35289-8_32]; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hoffman T., 1990, P 22 INT C RES DEV I, P50; Holzinger A, 2017, Arxiv, DOI arXiv:1712.09923; Hugging Face, 2023, Transformers; Hugging Face, 2016, About us; Inkpen D., 2021, CLEF WORKING NOTES, V2936, P966; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Ji SX, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P7184; Ji SX, 2018, COMPLEXITY, DOI 10.1155/2018/6157249; Jia J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5677; Jiang Z.P., 2020, P 11 INT WORKSHOP HL, P147, DOI DOI 10.18653/V1/2020.LOUHI-1.16; Joseph SM, 2023, PHYSICA A, V610, DOI 10.1016/j.physa.2022.128336; Kang D, 2022, PROC CVPR IEEE, P9969, DOI 10.1109/CVPR52688.2022.00974; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kim B, 2016, ADV NEUR IN, V29; Kim J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68764-y; Komati N., 2021, Suicide and Depression Detection; Kundu S, 2021, NAT MED, V27, P1328, DOI 10.1038/s41591-021-01461-z; Lake B., 2011, ANN M COGN SCI SOC, V33; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI [DOI 10.5555/2969830.2969879, DOI 10.1111/DSU.12130]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4257; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Ling J, 2022, PROC CVPR IEEE, P14544, DOI 10.1109/CVPR52688.2022.01416; Liu DX, 2020, IEEE ACCESS, V8, P169333, DOI 10.1109/ACCESS.2020.3019491; Lundberg S. M., 2017, About us; Lundberg SM, 2017, ADV NEUR IN, V30; MacAvaney Sean, 2021, P 7 WORKSH COMP LING, P70, DOI DOI 10.18653/V1/2021.CLPSYCH-1.7; Marcus Gary, 2018, arXiv; Martinez-Castano R., 2020, Working Notes of CLEF, V16; Matero Matthew, 2019, CLPSYCH, P39, DOI [10.18653/v1/W19-3005, DOI 10.18653/V1/W19-3005]; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Mikal J, 2016, BMC MED ETHICS, V17, DOI 10.1186/s12910-016-0105-5; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Molnar C., 2019, INTERPRETABLE MACHIN, DOI DOI 10.1007/S10290-014-0202-9; Morales M., 2021, NAACL HLT, V99; Mowery D., 2016, Online Journal of Public Health Informatics, V8; Mowery D, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6895; Muller B., 2022, HUGGING FACE; Muratov A. A., 2021, Perm Agrarian Journal, V35, P59, DOI 10.47737/2307-2873_2021_35_59; Naseem U, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON EFFICIENT BENCHMARKING IN NLP (NLP POWER 2022), P22; Naseem Usman, 2022, IEEE transactions on computational social systems; Nayak A., 2019, Towards Data Science; Ophir Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73917-0; Orabi A. H., 2018, NAACL HLT, V88; Paul M.J., 2011, ICWSM; Pirina Inna, 2018, P 2018 EMNLP WORKSHO, P9; Ptaszynski M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182211759; Qin W, 2023, Arxiv, DOI arXiv:2305.05138; Ragheb W, 2023, IEEE T KNOWL DATA EN, V35, P770, DOI 10.1109/TKDE.2021.3078898; Reddy S, 2022, LANCET DIGIT HEALTH, V4, DOI 10.1016/S2589-7500(22)00029-2; Reddy S, 2019, J ROY SOC MED, V112, P22, DOI 10.1177/0141076818815510; Ren L, 2021, JMIR MED INF, V9, DOI 10.2196/28754; Rezazadeh M., 2021, Twitter Depression Detection GitHub Repository; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rissola Esteban A., 2021, ACM Transactions on Computing and Healthcare, V2, DOI 10.1145/3437259; Roy T. S., 2022, arXiv; Sadeque F, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3159652.3159725; Safa R, 2022, J SUPERCOMPUT, V78, P4709, DOI 10.1007/s11227-021-04040-8; Salakhutdinov Ruslan, 2010, P 13 INT C ARTIFICIA, P693; Sawhney R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7685; Shapley L., 1953, 17. A Value for n-Person Games, P307, DOI DOI 10.1515/9781400881970-018; Shen TC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1611; Shing H-C, 2018, P 5 WORKSH COMP LING, P25, DOI [10.18653/v1/W18-0603, DOI 10.18653/V1/W18-0603]; Skaik R, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3422824; Song H., 2018, P 32 PAC AS C LANG I, P1; Speer R., 2019, ZENODO; Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/8167821; Suicide Awareness Voices of Education (SAVE), 2023, Suicide Statistics; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Tadesse MM, 2019, IEEE ACCESS, V7, P44883, DOI 10.1109/ACCESS.2019.2909180; Teixeira AS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98147-w; Trotzek M, 2020, IEEE T KNOWL DATA EN, V32, P588, DOI 10.1109/TKDE.2018.2885515; Uban AS, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3202; Uban AS, 2021, FUTURE GENER COMP SY, V124, P480, DOI 10.1016/j.future.2021.05.032; Vajre Vedant, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1077, DOI 10.1109/BIBM52615.2021.9669469; Vaswani A, 2017, ADV NEUR IN, V30; Vellido A, 2019, KIDNEY DIS-BASEL, V5, P11, DOI 10.1159/000492428; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang N., 2021, Interpretable and Explainable AI for Mental Health; Wang XF, 2020, JMIR MED INF, V8, DOI 10.2196/17958; World Health Organization, 2023, Suicide. World Health Organization Fact Sheets; Yang ZL, 2019, ADV NEUR IN, V32; Yates A., 2017, P 2017 C EMPIRICAL M, P2968, DOI 10.18653/v1/D17-1322; Yoon CH, 2022, J MED ETHICS, V48, P581, DOI 10.1136/medethics-2020-107102; Yosinski J, 2014, ADV NEUR IN, V27; Zarandi MHF, 2019, APPL SOFT COMPUT, V80, P329, DOI 10.1016/j.asoc.2019.03.027; Zeberga K, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7893775; Zhang TL, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00589-7; Zogan H, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P133, DOI 10.1145/3404835.3462938	133	3	3	22	22	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2214-4366	1389-0417		COGN SYST RES	Cogn. Syst. Res.	MAR	2024	84								101186	10.1016/j.cogsys.2023.101186	http://dx.doi.org/10.1016/j.cogsys.2023.101186		DEC 2023	28	Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Neurosciences & Neurology; Psychology	EU6C7					2024-07-03	WOS:001141476800001
J	Rodriguez-Echeverría, R; Gutiérrez, JD; Conejero, JM; Prieto, AE				Rodriguez-Echeverria, Roberto; Gutierrez, Juan D.; Conejero, Jose M.; Prieto, Alvaro E.			Analysis of ChatGPT Performance in Computer Engineering Exams	IEEE REVISTA IBEROAMERICANA DE TECNOLOGIAS DEL APRENDIZAJE-IEEE RITA			English	Article						Chatbots; Artificial intelligence; Guidelines; Oral communication; Computational modeling; Codes; ChatGPT; education; experiment		The appearance of ChatGPT at the end of 2022 was a milestone in the field of Generative Artificial Intelligence. However, it also caused a shock in the academic world. For the first time, a simple interface allowed anyone to access a large language model and use it to generate text. These capabilities have a relevant impact on teaching-learning methodologies and assessment methods. This work aims to obtain an objective measure of ChatGPT's possible performance in solving exams related to computer engineering. For this purpose, it has been tested with actual exams of 15 subjects of the Software Engineering branch of a Spanish university. All the questions of these exams have been extracted and adapted to a text format to obtain an answer. Furthermore, the exams have been rewritten to be corrected by the teaching staff. In light of the results, ChatGPT can achieve relevant performance in these exams; it can pass many questions and problems of different natures in multiple subjects. A detailed study of the results by typology of questions and problems is provided as a fundamental contribution, allowing recommendations to be considered in the design of assessment methods. In addition, an analysis of the impact of the non-deterministic aspect of ChatGPT on the answers to test questions is presented, and the need to use a strategy to reduce this effect for performance analysis is concluded.	[Rodriguez-Echeverria, Roberto; Conejero, Jose M.; Prieto, Alvaro E.] Univ Extremadura, Appl Informat Technol Res Inst, Caceres 10003, Spain; [Gutierrez, Juan D.] Univ Santiago De Compostela, Dept Elect & Comp, Lugo 27002, Spain	Universidad de Extremadura; Universidade de Santiago de Compostela	Rodriguez-Echeverría, R (corresponding author), Univ Extremadura, Appl Informat Technol Res Inst, Caceres 10003, Spain.	rre@unex.es; juandiego.gutierrez@usc.es; chemacm@unex.es; aeprieto@unex.es	Rodriguez-Echeverria, Roberto/B-4964-2014; Conejero Manzano, Jose M./L-9776-2014	Rodriguez-Echeverria, Roberto/0000-0002-6545-0913; Conejero Manzano, Jose M./0000-0003-2640-679X	Research and Development Project funded by MICIU/AEI/10.13039/501100011033	Research and Development Project funded by MICIU/AEI/10.13039/501100011033	No Statement Available	Bommarito M., 2022, Gpt takes the bar exam; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Divason J., 2021, P ACT 27 JORN ENS U, P43; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; García-Peñalvo FJ, 2024, RIED-REV IBEROAM EDU, V27, DOI 10.5944/ried.27.1.37716; Gilson A, 2022, medRxiv, DOI [10.1101/2022.12.23.22283901, 10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Liden Lars., 2004, AI Game Programming Wisdom 2, P41; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Rodriguez-Echeverria R., 2023, P ACT 24 JORN ENS U, P33; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tovar E., 1997, JENUI 97 3 JORN ENS, P485; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Vaswani A, 2017, ADV NEUR IN, V30; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Young G., 1964, Plastics, V3, P15; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	23	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		1932-8540		IEEE REV IBEROAM TEC	IEEE Rev. Iberoam. Tecnol Aprendiz.	MAR	2024	19	1					71	80		10.1109/RITA.2024.3381842	http://dx.doi.org/10.1109/RITA.2024.3381842			10	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	SE1G6					2024-07-03	WOS:001232684500001
J	Patel, EA; Fleischer, L; Filip, P; Eggerstedt, M; Hutz, M; Michaelides, E; Batra, PS; Tajudeen, BA				Patel, Evan A.; Fleischer, Lindsay; Filip, Peter; Eggerstedt, Michael; Hutz, Michael; Michaelides, Elias; Batra, Pete S.; Tajudeen, Bobby A.			The Use of Artificial Intelligence to Improve Readability of Otolaryngology Patient Education Materials	OTOLARYNGOLOGY-HEAD AND NECK SURGERY			English	Article; Early Access						artificial intelligence; patient education; PS/QI; readability	INFORMATION LEAFLETS; HEALTH INFORMATION; ONLINE INFORMATION; LITERACY	ObjectiveThe recommended readability of health education materials is at the sixth-grade level. Artificial intelligence (AI) large language models such as the newly released ChatGPT4 might facilitate the conversion of patient-education materials at scale. We sought to ascertain whether online otolaryngology education materials meet recommended reading levels and whether ChatGPT4 could rewrite these materials to the sixth-grade level. We also wished to ensure that converted materials were accurate and retained sufficient content.MethodsSeventy-one articles from patient educational materials published online by the American Academy of Otolaryngology-Head and Neck Surgery were selected. Articles were entered into ChatGPT4 with the prompt "translate this text to a sixth-grade reading level." Flesch Reading Ease Score (FRES) and Flesch-Kincaid Grade Level (FKGL) were determined for each article before and after AI conversion. Each article and conversion were reviewed for factual inaccuracies, and each conversion was reviewed for content retention.ResultsThe 71 articles had an initial average FKGL of 11.03 and FRES of 46.79. After conversion by ChatGPT4, the average FKGL across all articles was 5.80 and FRES was 77.27. Converted materials provided enough detail for patient education with no factual errors.DiscussionWe found that ChatGPT4 improved the reading accessibility of otolaryngology online patient education materials to recommended levels quickly and effectively.Implications for PracticePhysicians can determine whether their patient education materials exceed current recommended reading levels by using widely available measurement tools, and then apply AI dialogue platforms to modify materials to more accessible levels as needed.Level of EvidenceLevel 5.	[Patel, Evan A.; Fleischer, Lindsay; Filip, Peter; Eggerstedt, Michael; Hutz, Michael; Michaelides, Elias; Batra, Pete S.; Tajudeen, Bobby A.] Rush Univ, Dept Otorhinolaryngol Head & Neck Surg, Med Ctr, 1611 W Harrison St,Suite 550, Chicago, IL 60612 USA	Rush University	Tajudeen, BA (corresponding author), Rush Univ, Dept Otorhinolaryngol Head & Neck Surg, Med Ctr, 1611 W Harrison St,Suite 550, Chicago, IL 60612 USA.	bobby_tajudeen@rush.edu		Patel, Evan/0009-0005-9742-4225				[Anonymous], 2010, Simply put: A guide to creating easy-to-understand materials; Baker DW, 1997, AM J PUBLIC HEALTH, V87, P1027, DOI 10.2105/AJPH.87.6.1027; Baker DW, 2002, AM J PUBLIC HEALTH, V92, P1278, DOI 10.2105/AJPH.92.8.1278; Carnegie Mellon University, 2023, CMU Pronouncing Dictionary; Davis TC, 2004, FAM MED, V36, P595; Dickinson D, 2001, PATIENT EDUC COUNS, V43, P147, DOI 10.1016/S0738-3991(00)00156-7; Flesch R., 1979, How to Write Plain English: A Book for Lawyers and Consumers, Vxiii, P126; Frye BL., 2023, Fordham Intellect Property Media Entertainment Law J, V33; Gal I, 2005, HEALTH EDUC RES, V20, P485, DOI 10.1093/her/cyh009; Greenberg E., 2003, National Assessment of Adult Literacy: Public-Use Data File User's Guide; Greywoode J, 2009, OTOLARYNG HEAD NECK, V141, P555, DOI 10.1016/j.otohns.2009.08.004; Griffith E., 2023, The New York Times; Haver HL, 2023, AM J ROENTGENOL, V221, P701, DOI 10.2214/AJR.23.29622; Kim JH, 2022, OTOLARYNG HEAD NECK, V166, P862, DOI 10.1177/01945998211033254; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; McMullan M, 2006, PATIENT EDUC COUNS, V63, P24, DOI 10.1016/j.pec.2005.10.006; Mondal H, 2023, INDIAN DERMATOL ONL, V14, P482, DOI 10.4103/idoj.idoj_72_23; National Institutes of Health (NIH), 2021, Clear Communication: Clear and Simple; OpenAI, 2023, Data from: ChatGPT, GPT-4; Roose Kevin, 2022, NEW YORK TIMES; Simani L, 2022, OTOL NEUROTOL, V43, P159, DOI 10.1097/MAO.0000000000003424; Tan SSL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5729; Wang LW, 2013, RES SOC ADMIN PHARM, V9, P503, DOI 10.1016/j.sapharm.2012.05.009; Weis B., 2003, Health literacy: a manual for clinicians; Wong K, 2017, OTOLARYNG HEAD NECK, V156, P96, DOI 10.1177/0194599816674711; Zeatoun A, 2023, INT FORUM ALLERGY RH, V13, P277, DOI 10.1002/alr.23082	26	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0194-5998	1097-6817		OTOLARYNG HEAD NECK	Otolaryngol. Head Neck Surg.	2024 MAY 15	2024										10.1002/ohn.816	http://dx.doi.org/10.1002/ohn.816		MAY 2024	6	Otorhinolaryngology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology; Surgery	QU1S0	38751109				2024-07-03	WOS:001223295700001
J	Li, WW; Hsu, CY; Wang, SZ; Yang, YZ; Lee, H; Liljedahl, A; Witharana, C; Yang, YL; Rogers, BM; Arundel, ST; Jones, MB; McHenry, K; Solis, P				Li, Wenwen; Hsu, Chia-Yu; Wang, Sizhe; Yang, Yezhou; Lee, Hyunho; Liljedahl, Anna; Witharana, Chandi; Yang, Yili; Rogers, Brendan M.; Arundel, Samantha T.; Jones, Matthew B.; McHenry, Kenton; Solis, Patricia			Segment Anything Model Can Not Segment Anything: Assessing AI Foundation Model's Generalizability in Permafrost Mapping	REMOTE SENSING			English	Article						foundation model; artificial intelligence; mapping; zero-shot; segmentation; GeoAI	GEOAI	This paper assesses trending AI foundation models, especially emerging computer vision foundation models and their performance in natural landscape feature segmentation. While the term foundation model has quickly garnered interest from the geospatial domain, its definition remains vague. Hence, this paper will first introduce AI foundation models and their defining characteristics. Built upon the tremendous success achieved by Large Language Models (LLMs) as the foundation models for language tasks, this paper discusses the challenges of building foundation models for geospatial artificial intelligence (GeoAI) vision tasks. To evaluate the performance of large AI vision models, especially Meta's Segment Anything Model (SAM), we implemented different instance segmentation pipelines that minimize the changes to SAM to leverage its power as a foundation model. A series of prompt strategies were developed to test SAM's performance regarding its theoretical upper bound of predictive accuracy, zero-shot performance, and domain adaptability through fine-tuning. The analysis used two permafrost feature datasets, ice-wedge polygons and retrogressive thaw slumps because (1) these landform features are more challenging to segment than man-made features due to their complicated formation mechanisms, diverse forms, and vague boundaries; (2) their presence and changes are important indicators for Arctic warming and climate change. The results show that although promising, SAM still has room for improvement to support AI-augmented terrain mapping. The spatial and domain generalizability of this finding is further validated using a more general dataset EuroCrops for agricultural field mapping. Finally, we discuss future research directions that strengthen SAM's applicability in challenging geospatial domains.	[Li, Wenwen; Hsu, Chia-Yu; Wang, Sizhe; Lee, Hyunho; Solis, Patricia] Arizona State Univ, Sch Geog Sci & Urban Planning, Tempe, AZ 85287 USA; [Wang, Sizhe; Yang, Yezhou] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85287 USA; [Liljedahl, Anna; Yang, Yili; Rogers, Brendan M.] Woodwell Climate Res Ctr, Falmouth, MA 02540 USA; [Witharana, Chandi] Univ Connecticut, Dept Nat Resources & Environm, Storrs, CT 06269 USA; [Arundel, Samantha T.] US Geol Survey, Ctr Excellence Geospatial Informat Sci, Rolla, MO 65401 USA; [Jones, Matthew B.] Univ Calif Santa Barbara, Natl Ctr Ecol Anal & Synth, Santa Barbara, CA 93106 USA; [McHenry, Kenton] Univ Illinois, Natl Ctr Supercomp Applicat NCSA, Champaign, IL 61820 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe; University of Connecticut; United States Department of the Interior; United States Geological Survey; National Center for Ecological Analysis & Synthesis; University of California System; University of California Santa Barbara; University of Illinois System; University of Illinois Urbana-Champaign	Li, WW (corresponding author), Arizona State Univ, Sch Geog Sci & Urban Planning, Tempe, AZ 85287 USA.	wenwen@asu.edu; chsu53@asu.edu; wsizhe@asu.edu; yz.yang@asu.edu; hlee401@asu.edu; aliljedahl@woodwellclimate.org; chandi.witharana@uconn.edu; yyang@woodwellclimate.org; brogers@woodwellclimate.org; sarundel@usgs.gov; jones@nceas.ucsb.edu; mchenry@illinois.edu; patricia.solis@asu.edu	Li, Wenwen/I-8671-2016; witharana, chandi/C-9074-2015; Athie, Katherine/KSL-6032-2024; Hsu, Chia-Yu/GPF-4406-2022	Hsu, Chia-Yu/0000-0002-8923-1213; Rogers, Brendan/0000-0001-6711-8466	National Science Foundation [1043681, 1559691]; Polar Geospatial Center under NSF-OPP	National Science Foundation(National Science Foundation (NSF)); Polar Geospatial Center under NSF-OPP	Image data access support for this work was provided in part by the Polar Geospatial Center under NSF-OPP awards 1043681 and 1559691. Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.	Avery, 2022, Our ML Tooling 2022-Part2: Data Operations; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cha K, 2024, Arxiv, DOI arXiv:2304.05215; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Goodchild MF, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2015759118; Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550; IPCC, 2020, Climate Change and Land: an IPCC special report on climate change, desertification, land degradation, sustainable land management, food security, and greenhouse gas fluxes in terrestrial ecosystems; Jakubik J., 2023, arXiv; Jiang P., 2023, Conect Segment-Anything with CLIP; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Li J., 2022, IEEECVF C COMPUT VIS, P19914; Li Wenwen, 2022, GeoAI '22: Proceedings of the 5th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery, P62, DOI 10.1145/3557918.3565869; Li WW, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11070385; Li WW, 2020, J SPAT INT SCI, P71, DOI 10.5311/JOSIS.2020.20.658; Li Y., 2022, IEEE CVF C COMP VIS, P4804; Liljedahl AK, 2016, NAT GEOSCI, V9, P312, DOI [10.1038/NGEO2674, 10.1038/ngeo2674]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long Y, 2021, IEEE J-STARS, V14, P4205, DOI 10.1109/JSTARS.2021.3070368; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Natali SM, 2022, ENVIRON RES LETT, V17, DOI 10.1088/1748-9326/ac8c5a; Nitze I., 2022, P AGU FALL M ABSTR C, V2022; Nitze I, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214294; Radford A, 2021, PR MACH LEARN RES, V139; Raynolds MK, 2019, REMOTE SENS ENVIRON, V232, DOI 10.1016/j.rse.2019.111297; Schneider M, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02517-0; Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324; Udawalpola MR, 2022, PHOTOGRAMM ENG REM S, V88, P181, DOI 10.14358/PERS.21-00059R2; Vaswani A, 2017, ADV NEUR IN, V30; Wang D, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2022.3222818; Wang SZ, 2021, COMPUT ENVIRON URBAN, V90, DOI 10.1016/j.compenvurbsys.2021.101715; Yang YL, 2023, REMOTE SENS ENVIRON, V288, DOI 10.1016/j.rse.2023.113495	31	2	2	22	22	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2072-4292		REMOTE SENS-BASEL	Remote Sens.	MAR	2024	16	5							797	10.3390/rs16050797	http://dx.doi.org/10.3390/rs16050797			17	Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology	KW1W8		Green Submitted, gold			2024-07-03	WOS:001182918300001
J	Escalante, J; Pack, A; Barrett, A				Escalante, Juan; Pack, Austin; Barrett, Alex			AI-generated feedback on writing: insights into efficacy and ENL student preference	INTERNATIONAL JOURNAL OF EDUCATIONAL TECHNOLOGY IN HIGHER EDUCATION			English	Article						Automated writing evaluation; ChatGPT; Artificial intelligence; Language education		The question of how generative AI tools, such as large language models and chatbots, can be leveraged ethically and effectively in education is ongoing. Given the critical role that writing plays in learning and assessment within educational institutions, it is of growing importance for educators to make thoughtful and informed decisions as to how and in what capacity generative AI tools should be leveraged to assist in the development of students' writing skills. This paper reports on two longitudinal studies. Study 1 examined learning outcomes of 48 university English as a new language (ENL) learners in a six-week long repeated measures quasi experimental design where the experimental group received writing feedback generated from ChatGPT (GPT-4) and the control group received feedback from their human tutor. Study 2 analyzed the perceptions of a different group of 43 ENLs who received feedback from both ChatGPT and their tutor. Results of study 1 showed no difference in learning outcomes between the two groups. Study 2 results revealed a near even split in preference for AI-generated or human-generated feedback, with clear advantages to both forms of feedback apparent from the data. The main implication of these studies is that the use of AI-generated feedback can likely be incorporated into ENL essay evaluation without affecting learning outcomes, although we recommend a blended approach that utilizes the strengths of both forms of feedback. The main contribution of this paper is in addressing generative AI as an automatic essay evaluator while incorporating learner perspectives.	[Escalante, Juan; Pack, Austin] Brigham Young Univ Hawaii, Fac Educ & Social Work, 55-220 Kulanui St, Laie, HI 96762 USA; [Barrett, Alex] Florida State Univ, Coll Educ, Stone Bldg, 114 West Call St, Tallahassee, FL 32306 USA	Brigham Young University; Brigham Young University - Hawaii; State University System of Florida; Florida State University	Escalante, J (corresponding author), Brigham Young Univ Hawaii, Fac Educ & Social Work, 55-220 Kulanui St, Laie, HI 96762 USA.	Juan.escalante@byuh.edu		Escalante, Juan/0009-0009-8534-2504	We would like to extend our sincere gratitude to our Research Assistant.	We would like to extend our sincere gratitude to our Research Assistant.	We would like to extend our sincere gratitude to our Research Assistant.	Abd-Elaal ES, 2022, EUR J ENG EDUC, V47, P725, DOI 10.1080/03043797.2022.2046709; Baktash JA, 2023, Arxiv, DOI arXiv:2305.03195; Behizadeh N., 2011, Assessing Writing, V16, P189, DOI [10.1016/j.asw.2011.03.001, DOI 10.1016/J.ASW.2011.03.001]; Chiu T.K.F., 2023, Computers and Education: Artificial Intelligence, V4, DOI DOI 10.1016/J.CAEAI.2022.100118; Dai W., 2023, PREPRINT, DOI DOI 10.35542/OSF.IO/HCGZJ; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; Derner E, 2023, Arxiv, DOI arXiv:2305.08005; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Elliot N., 2013, The Handbook of automated essay evaluation: Current applications and new directions; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fitria TN., 2019, Metathesis, V5, P65, DOI [10.31002/metathesis.v5i1.3519, DOI 10.31002/METATHESIS.V5I1.3519]; FLORIO S, 1982, RES TEACH ENGL, V16, P115; Futterer T., 2023, Research Square, DOI [10.21203/rs.3.rs-2840105/v1, DOI 10.21203/RS.3.RS-2840105/V1]; Godwin-Jones R, 2022, LANG LEARN TECHNOL, V26, P5, DOI 10.10125/73474; Grove WM, 2000, PSYCHOL ASSESSMENT, V12, P19, DOI 10.1037/1040-3590.12.1.19; Herbold S, 2023, Arxiv, DOI [arXiv:2304.14276, DOI 10.48550/ARXIV.2304.14276]; Huawei S, 2023, EDUC INF TECHNOL, V28, P771, DOI 10.1007/s10639-022-11200-7; Ingley SJ, 2023, TRENDS ECOL EVOL, V38, P785, DOI 10.1016/j.tree.2023.05.007; JohnSteiner V, 1996, EDUC PSYCHOL, V31, P191, DOI 10.1207/s15326985ep3103&4_4; Koltovskaia S, 2020, ASSESS WRIT, V44, DOI 10.1016/j.asw.2020.100450; Krashen S.D., 1982, PRINCIPLES PRACTICE; Krishna K, 2023, Arxiv, DOI arXiv:2303.13408; Kumar R, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00130-7; Lampropoulos G., 2023, SSRN, DOI [10.2139/ssrn.4468181, DOI 10.2139/SSRN.4468181]; Leike Jan, 2023, Introducing superalignment; Mizumoto A., 2023, Research Methods in Applied Linguistics, V2, P100050, DOI DOI 10.1016/J.RMAL.2023.100050; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, GPT 4 SYST CARD; Roscoe RD, 2017, COMPUT HUM BEHAV, V70, P207, DOI 10.1016/j.chb.2016.12.076; Shermis M.D., 2013, HDB AUTOMATED ESSAY, P1, DOI DOI 10.4324/9780203122761; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Suleyman M., 2023, MIT Technology Review; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Tate T. P., 2023, EdArXiv, DOI [10.35542/osf.io/4mec3, DOI 10.35542/OSF.IO/4MEC3]; Tseng W., 2023, Journal of China Computer-Assisted Language Learning, V3, P258, DOI [https://doi.org/10.1515/jccall-2023-0008, DOI 10.1515/JCCALL-2023-0008]; Urlaub P., 2022, L2 Journal, V14, DOI [https://doi.org/10.5070/L214151790, DOI 10.5070/L214151790]; Weigle SC., 2013, The handbook of automated essay evaluation: Current applications and new directions; Yang M., 2023, GUARDIAN; Yeo MA, 2023, TESOL J, V14, DOI 10.1002/tesj.716; Zhou Y., 2023, INT C LEARN REPR 202; Zhu CJ, 2023, KNOWL MANAG E-LEARN, V15, P133, DOI 10.34105/j.kmel.2023.15.008	41	14	14	191	286	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	2365-9440			INT J EDUC TECHNOL H	Int. J. Educ. Technol. High. Educ.	OCT 27	2023	20	1							57	10.1186/s41239-023-00425-2	http://dx.doi.org/10.1186/s41239-023-00425-2			20	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	U9JC9		gold			2024-07-03	WOS:001087884500001
J	Spies, NC; Hubler, Z; Roper, SM; Omosule, CL; Senter-Zapata, M; Roemmich, BL; Brown, HM; Gimple, R; Farnsworth, CW				Spies, Nicholas C.; Hubler, Zita; Roper, Stephen M.; Omosule, Catherine L.; Senter-Zapata, Michael; Roemmich, Brittany L.; Brown, Hannah Marie; Gimple, Ryan; Farnsworth, Christopher W.			GPT-4 Underperforms Experts in Detecting IV Fluid Contamination	JOURNAL OF APPLIED LABORATORY MEDICINE			English	Article							ERRORS	Background Specimens contaminated with intravenous (IV) fluids are common in clinical laboratories. Current methods for detecting contamination rely on insensitive and workflow-disrupting delta checks or manual technologist review. Herein, we assessed the utility of large language models for detecting contamination by IV crystalloids and compared its performance to multiple, but variably trained healthcare personnel (HCP).Methods Contamination of basic metabolic panels was simulated using 0.9% normal saline (NS), with (n = 30) and without (n = 30) 5% dextrose (D5NS), at mixture ratios of 0.10 and 0.25. A multimodal language model (GPT-4) and a diverse panel of 8 HCP were asked to adjudicate between real and contaminated results. Classification performance, mixture quantification, and confidence was compared by Wilcoxon rank sum.Results The 95% CIs for accuracy were 0.57-0.71 vs 0.73-0.80 for GPT-4 and HCP, respectively, on the NS set and 0.57-0.57 vs 0.73-0.80 on the D5NS set. HCP overestimated severity of contamination in the 0.10 mixture group (95% CI of estimate error, 0.05-0.20) for both fluids, while GPT-4 markedly overestimated the D5NS mixture at both ratios (0.16-0.33 for NS, 0.11-0.35 for D5NS). There was no correlation between reported confidence and likelihood of a correct classification.Conclusions GPT-4 is less accurate than trained HCP for detecting IV fluid contamination of basic metabolic panel results. However, trained individuals were imperfect at identifying contaminated specimens implying the need for novel, automated tools for its detection.	[Spies, Nicholas C.; Hubler, Zita; Roper, Stephen M.; Omosule, Catherine L.; Roemmich, Brittany L.; Brown, Hannah Marie; Farnsworth, Christopher W.] Washington Univ St Louis, Sch Med, Dept Pathol & Immunol, St Louis, MO USA; [Roper, Stephen M.] Washington Univ St Louis, Sch Med, Dept Pediat, St Louis, MO USA; [Senter-Zapata, Michael] Brigham & Womens Hosp, Dept Med, Boston, MA USA; [Senter-Zapata, Michael] Harvard Med Sch, Boston, MA USA; [Gimple, Ryan] Washington Univ St Louis, Sch Med, Dept Med, St Louis, MO USA; [Spies, Nicholas C.] 660 S Euclid Ave, St Louis, MO 63110 USA	Washington University (WUSTL); Washington University (WUSTL); Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School; Washington University (WUSTL)	Spies, NC (corresponding author), 660 S Euclid Ave, St Louis, MO 63110 USA.	nspies13@gmail.com	Omosule, Catherine/JEP-6400-2023	Omosule, Cate L/0000-0003-0750-2129; Hubler, Zita/0000-0003-0991-6229				[Anonymous], 2015, Improving Diagnosis in Health Care; [Anonymous], 2000, ERR IS HUMAN BUILDIN; Arsand A, EFLM BIOL VARIATION; Baron JM, 2012, AM J CLIN PATHOL, V138, P406, DOI 10.1309/AJCPQIRIB3CT1EJV; Bubeck S, 2023, PREPRINT; Choucair I, 2023, CLIN CHIM ACTA, V538, P22, DOI 10.1016/j.cca.2022.10.011; Hawkins R. D., 2023, PREPRINT; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lyu Q., 2023, PREPRINT; Nori H., 2023, PREPRINT; OpenAI, 2023, PREPRINT; Patel DK, 2015, CLIN CHEM LAB MED, V53, P1585, DOI 10.1515/cclm-2014-0955; Perlis RH., 2023, PREPRINT; Plebani M, 2014, CLIN CHIM ACTA, V432, P44, DOI 10.1016/j.cca.2013.07.033; Rosenbaum MW, 2018, AM J CLIN PATHOL, V150, P555, DOI [10.1093/ajcp/aqy085, 10.1093/AJCP/AQY085]; Shen L, 2022, JT COMM J QUAL PATIE, V48, P71, DOI 10.1016/j.jcjq.2021.10.002; Singh H, 2017, BMJ QUAL SAF, V26, P484, DOI 10.1136/bmjqs-2016-005401; Singhal K., 2023, PREPRINT; Zhao W. X., 2023, PREPRINT	20	4	4	0	2	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	2576-9456	2475-7241		J APPL LAB MED	J. Appl. Lab. Med.	NOV 2	2023	8	6					1092	1100		10.1093/jalm/jfad058	http://dx.doi.org/10.1093/jalm/jfad058		SEP 2023	9	Medical Laboratory Technology	Emerging Sources Citation Index (ESCI)	Medical Laboratory Technology	X8GH6	37702018				2024-07-03	WOS:001064776200001
C	Li, ZJ; Wang, CZ; Liu, ZB; Wang, HX; Chen, D; Wang, S; Gao, CY			IEEE	Li, Zongjie; Wang, Chaozheng; Liu, Zhibo; Wang, Haoxuan; Chen, Dong; Wang, Shuai; Gao, Cuiyun			CCTEST: Testing and Repairing Code Completion Systems	2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ICSE	International Conference on Software Engineering		English	Proceedings Paper	45th IEEE/ACM International Conference on Software Engineering (ICSE)	MAY 14-20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, Melbourne Convent Bur, State Govt Victoria, CSIRO, Huawei, Monash Univ, Meta, Google, AWS, Monash Univ, Dragon Testing Technol, IBM, Univ Melbourne, RMIT Univ				Code completion, a highly valuable topic in the software development domain, has been increasingly promoted for use by recent advances in large language models (LLMs). To date, visible LLM-based code completion frameworks such as GitHub Copilot and GPT are trained using deep learning over vast quantities of unstructured text and open source code. As the paramount component and the cornerstone in daily programming tasks, code completion has largely boosted professionals' efficiency in building real-world software systems. In contrast to this flourishing market, we find that code completion systems often output suspicious results, and to date, an automated testing and enhancement framework for code completion systems is not available. This research proposes CCTEST, a framework to test and repair code completion systems in black-box settings. CCTEST features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs. Then, it detects inconsistent outputs, representing possibly erroneous cases, from all the completed code cases. Moreover, CCTEST repairs the code completion outputs by selecting the output that mostly reflects the "average" appearance of all output cases, as the final output of the code completion systems. With around 18K test inputs, we detected 33,540 inputs that can trigger erroneous cases (with a true positive rate of 86%) from eight popular LLM-based code completion systems. With repairing, we show that the accuracy of code completion systems is notably increased by 40% and 67% with respect to BLEU score and Levenshtein edit similarity.	[Li, Zongjie; Liu, Zhibo; Chen, Dong; Wang, Shuai] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Wang, Chaozheng; Gao, Cuiyun] Harbin Inst Technol, Shenzhen, Peoples R China; [Wang, Haoxuan] Swiss Fed Inst Technol Lausanne, Lausanne, Switzerland	Hong Kong University of Science & Technology; Harbin Institute of Technology; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Wang, S (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.	zligo@cse.ust.hk; wangchaozheng@stu.hit.edu.cn; zliudc@cse.ust.hk; haoxuan.wang@epfl.ch; dchenbl@cse.ust.hk; shuaiw@cse.ust.hk; gaocuiyun@hit.edu.cn	Wang, Chaozheng/KHT-6430-2024		RGC ECS grant [26206520]	RGC ECS grant	We thank anonymous reviewers for their valuable feedback. HKUST authors are supported in part by a RGC ECS grant under the contract 26206520.	Alon U., 2018, arXiv; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; [Anonymous], PYC SIM; [Anonymous], US; Artifact, 2022, CCTEST; Bielik P, 2020, PR MACH LEARN RES, V119; Black Sid, 2021, GPT-Neo: Large scale autoregressive language modeling with mesh-tensorflow; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brunsfeld Max., Tree-sitter; Cambronero J, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P964, DOI 10.1145/3338906.3340458; Chen M., 2021, arXiv; Chen M., 2021, ARXIV; Chen SQ, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P104, DOI 10.1109/ASE51524.2021.9678670; Chen T.Y., 1998, Metamorphic testing: a new approach for generating next test cases; Chen Zhe, 2022, arXiv; codastory, ABOUT US; Copilot, About us; Dwarakanath A, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P118, DOI 10.1145/3213846.3213858; EleutherAI, GPT J; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Fuzzywuzzy, About us; Gage P., 1994, C Users Journal, V12, P23; Galhotra S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P498, DOI 10.1145/3106237.3106277; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; github, LEETC PYTH; Goel K, 2021, Arxiv, DOI arXiv:2101.04840; Gu WC, 2021, NEURAL NETWORKS, V141, P385, DOI 10.1016/j.neunet.2021.04.019; Guo DY, 2022, Arxiv, DOI arXiv:2203.03850; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Gupta S, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P863, DOI 10.1145/3368089.3409756; He PJ, 2020, PROC INT CONF SOFTW, P961, DOI 10.1145/3377811.3380339; He PJ, 2021, PROC INT CONF SOFTW, P410, DOI 10.1109/ICSE43902.2021.00047; Henkel J, 2022, EUR CON SFTWR MTNCE, P526, DOI 10.1109/SANER53432.2022.00070; Hugging Face, COD; huggingface, Hugging Face; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Kalash M, 2018, INT CONF NEW TECHNOL; Lagler K, 2013, GEOPHYS RES LETT, V40, P1069, DOI 10.1002/grl.50288; Leetcode0285, US; Lei MG, 2022, J SYST SOFTWARE, V184, DOI 10.1016/j.jss.2021.111141; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Li Z, 2018, Arxiv, DOI arXiv:1801.01681; Li ZJ, 2022, PROC INT CONF SOFTW, P2253, DOI 10.1145/3510003.3510217; Liu Shangqing, 2021, arXiv; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Ma PC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P458; Mou LL, 2016, AAAI CONF ARTIF INTE, P1287; Nakajima Shin, 2019, IFIP ICTSS; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Odena A, 2018, Arxiv, DOI arXiv:1807.10875; Pang Qi., 2022, ISSTA; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Pearce Hammond, 2022, arXiv, DOI [10.48550/arXiv.2202.01142, DOI 10.48550/ARXIV.2202.01142]; Pei KX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P1, DOI 10.1145/3132747.3132785; Pour Maryam Vahdat, 2021, ICST; Rabin Md Rafiqul Islam, 2021, UNDERSTANDING NEURAL; Rabin Md Rafiqul Islam, 2021, GENERALIZABILITY NEU; Sarsa Sami., 2022, arXiv; Shao JY, 2021, PROC IEEE ACM INT C, P117, DOI 10.1109/ICSE-Companion52605.2021.00052; Sun ZY, 2022, PROC INT CONF SOFTW, P1181, DOI 10.1145/3510003.3510206; Sun ZY, 2020, PROC INT CONF SOFTW, P974, DOI 10.1145/3377811.3380420; Suneja S, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P945, DOI 10.1145/3468264.3468545; Tay Yi, 2020, ACM COMPUTING SURVEY; Tian YQ, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-09985-1; Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220; Ribeiro MT, 2020, Arxiv, DOI arXiv:2005.04118; Udeshi S, 2018, IEEE INT CONF AUTOM, P98, DOI 10.1145/3238147.3238165; Wang HJ, 2023, IEEE T SOFTWARE ENG, V49, P226, DOI 10.1109/TSE.2022.3149240; Wang Huaijin, 2022, ACM T SOFTW ENG METH; Wang HT, 2021, IEEE T INF FOREN SEC, V16, P1943, DOI 10.1109/TIFS.2020.3044773; Wang JY, 2019, PROC INT CONF SOFTW, P1245, DOI 10.1109/ICSE.2019.00126; Wang S, 2020, IEEE INT CONF AUTOM, P1053, DOI 10.1145/3324884.3416584; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wang Yue, 2021, Codet5: Identifier-aware unified pre-trained encoderdecoder models for code understanding and generation; Weiss Dror., COMP COPILOT TABNINE; Woo S, 2021, PROC INT CONF SOFTW, P860, DOI 10.1109/ICSE43902.2021.00083; Yefet N, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428230; Yu Sangwon, 2022, ACL; Yu Zeping, 2020, Advances in Neural Information Processing Systems, V33, P3872; Yuan YY, 2021, PROC CVPR IEEE, P16903, DOI 10.1109/CVPR46437.2021.01663; Yuan Yuanyuan, 2022, UNVEILING HIDDEN DNN; Zhan X, 2021, PROC INT CONF SOFTW, P1695, DOI 10.1109/ICSE43902.2021.00150; Zhang MS, 2018, IEEE INT CONF AUTOM, P132, DOI 10.1145/3238147.3238187; Zhang ZW, 2022, Arxiv, DOI arXiv:2206.14390; Zhou HS, 2020, PROC INT CONF SOFTW, P347, DOI 10.1145/3377811.3380422; Zhou Yaqin., 2019, NEUIPS; Zugner Daniel., 2021, 9 INT C LEARNING REP	91	2	3	2	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0270-5257		978-1-6654-5701-9	PROC INT CONF SOFTW			2023							1238	1250		10.1109/ICSE48619.2023.00110	http://dx.doi.org/10.1109/ICSE48619.2023.00110			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JK		Green Submitted			2024-07-03	WOS:001032629800101
J	Molero, JM; Pérez-Martín, J; Rodrigo, A; Peñas, A				Molero, Jose Maria; Perez-Martin, Jorge; Rodrigo, Alvaro; Penas, Anselmo			Offensive Language Detection in Spanish Social Media: Testing From Bag-of-Words to Transformers Models	IEEE ACCESS			English	Article						Task analysis; Social networking (online); Transformers; Data models; Blogs; Hate speech; Feature extraction; Natural language processing; Offensive language; natural language processing; transformers-based models		Social networks allow us to communicate with people around the world. However, some users usually take advantage of anonymity for writing offensive comments to others, which might affect those who receive offensive messages or discourage the use of these networks. However, it is impossible to manually check every message. This has promoted several proposals for automatic detection systems. Current state-of-the-art systems are based on the transformers' architecture and most of the work has been focused on the English language. However, these systems do not pay too much attention to the unbalanced nature of data, since there are fewer offensive comments than non-offensive in a real environment. Besides, these previous works have not studied the impact on the final results of pre-processing or the corpora used for pre-training the models. In this work, we propose and evaluate a series of automatic methods aimed at detecting offensive language in Spanish texts addressing the unbalanced nature of data. We test different learning models, from those based on classical Machine Learning algorithms using Bag-of-Words as data representation to those based in large language models and neural networks such as transformers, paying more attention to minor classes and the corpora used for pre-training the transformer-based models. We show how transformer-based models continue obtaining the best results, but we improved previous results by a 6,2% by adding new steps of pre-processing and using models pre-trained with Spanish social-media data, setting new state-of-the-art results.	[Molero, Jose Maria; Perez-Martin, Jorge; Rodrigo, Alvaro; Penas, Anselmo] Univ Nacl Educ Distancia UNED, Comp Engn Sch, Madrid 28040, Spain	Universidad Nacional de Educacion a Distancia (UNED)	Pérez-Martín, J (corresponding author), Univ Nacl Educ Distancia UNED, Comp Engn Sch, Madrid 28040, Spain.		Rodrigo, Alvaro/R-3399-2018; Perez-Martin, Jorge/G-4486-2016; Penas, Anselmo/H-4308-2015	Perez-Martin, Jorge/0000-0002-3588-7233; Penas, Anselmo/0000-0002-7867-0149	Spanish Research Agency (Agencia Estatal de Investigacion) [PID2021-127777OB-C22]; Holistic Analysis of Organized Misinformation Activity in Social Networks Project [PCI2022-135026-2]; Intelligent Systems for Learning (ISL) Group [GID2016-39]; Spanish Government [PID2019-110686RB-I00]; Universidad Nacional de Educacion a Distancia (UNED) [2022V/ITEMP/005]	Spanish Research Agency (Agencia Estatal de Investigacion); Holistic Analysis of Organized Misinformation Activity in Social Networks Project; Intelligent Systems for Learning (ISL) Group; Spanish Government(Spanish Government); Universidad Nacional de Educacion a Distancia (UNED)	This work was supported in part by the Spanish Research Agency (Agencia Estatal de Investigacion) through DeepInfo Project (MCIU/AEI/FEDER,UE) under Grant PID2021-127777OB-C22, in part by the Holistic Analysis of Organized Misinformation Activity in Social Networks Project under Grant PCI2022-135026-2, and in part by the Projects Given to the Intelligent Systems for Learning (ISL) Group in the PID 20/21 and 21/22 calls under Grant GID2016-39. The work of Jorge Perez-Martin was supported in part by the Spanish Government under Grant PID2019-110686RB-I00, and in part by Universidad Nacional de Educacion a Distancia (UNED) under Grant 2022V/ITEMP/005.	Anand M, 2023, THEOR COMPUT SCI, V943, P203, DOI 10.1016/j.tcs.2022.06.020; Aragon M. E., 2018, PROC IBEREVAL SEPLN, P134; Aragon M. E., 2019, IBERLEF SEPLN, P478; Aragon M. E., 2020, IBERLEF SEPLN, P222, DOI DOI 10.29057/MJMR.V8I16; Aroyehun S.T., 2021, P IBERLEF SEPLN MAL, P313; Basile Valerio, 2019, P 13 INT WORKSHOP SE, P54, DOI [DOI 10.18653/V1/S19-2007, 10.18653/v1/S19-2007]; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Canete Jose, 2020, PML4DC ICLR 2020; Casavantes M., 2019, PROC IBERLEF SEPLN, P537; Casavantes M., 2020, P 2 SEPLN WORKSHOP I; Caselli T, 2021, WOAH 2021: THE 5TH WORKSHOP ON ONLINE ABUSE AND HARMS, P17; Chen PC, 2020, PROC 14 WORKSHOP SEM, P2105; Chen Y, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P71, DOI 10.1109/SocialCom-PASSAT.2012.55; De la Pena Sarracen G. L., 2020, P 14 WORKSH SEM EV, P1605; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Djandji M., 2020, P 4 WORKSH OP SOURC, P97; El-Alami FZ, 2022, J KING SAUD UNIV-COM, V34, P6048, DOI 10.1016/j.jksuci.2021.07.013; Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676; Garcia-Diaz J. A., P IB LANG EV FOR IB, V2943; Guzman-Silverio M., 2020, P IBERLEF SEPLN, P293; Han J., 2019, PROC 13 INT WORKSHOP, P652; Hassan S., 2020, P 4 WORKSHOP OPEN SO, P61; Hickey D., 2023, P INT AAAI C WEB SOC, V17, P1133, DOI [10.1609/icwsm.v17i1.22222, DOI 10.1609/ICWSM.V17I1.22222]; Imran M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14084529; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Liu Ping, 2019, SEMEVAL NAACL HLT, P87, DOI [10.18653/v1/s19-2011, DOI 10.18653/V1/S19-2011]; Mahata D., 2019, P 13 INT WORKSHOP SE, P683; Meaney J.A., 2021, P 15 INT WORKSHOP SE, P105, DOI 10.18653/v1/2021.semeval-1.9; Miguel A, 2018, P 3 WORKSH EV HUM LA, P74; Plaza-del-Arco FM, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109965; Plaza-del-Arco FM, 2021, PROCES LENG NAT, P183, DOI 10.26342/2021-67-16; Mozafari M, 2022, IEEE ACCESS, V10, P14880, DOI 10.1109/ACCESS.2022.3147588; Mubarak H., 2020, Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection, P48; Nand P, 2016, PROC 26 INT C COMPUT, P695; Nikolov A., 2019, P 13 INT WORKSHOP SE, P691, DOI [10.18653/v1/S19-2123, DOI 10.18653/V1/S19-2123]; Oberstrass A, 2019, PROC 13 INT WORKSHOP, P628, DOI 10.18653/v1/S19-2112; Pavlopoulos J., 2021, P 15 INT WORKSHOP SE, P59, DOI DOI 10.18653/V1/2021.SEMEVAL-1.6; Perez J. M., 2022, P LANG RES EV C LREC, P1; Pham-Hong B.-T., 2020, PROC 14 WORKSHOP SEM, P2111; Pimies M., 2020, PROC 14 WORKSHOP SEM, P1569; Pingping Lin, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P372, DOI 10.1007/978-3-030-60450-9_30; Plaza del Arco F. M., 2021, P INT C RECENT ADV N, P1096; Ram O, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3066; Roy PK, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101386; Rozental A., Proceedings of the 13th International Workshop on Semantic Evaluation, V2019, P377, DOI [DOI 10.18653/V1/S19-2066, 10.18653/v1/s19-2066]; Sanchez-Gomez C., 2018, P OPENAIRE, P1; Sarracen G. L. D. L. P., 2019, P IBERLEF SEPLN, P531; Seganti A., 2019, P 13 INT WORKSH SEM, P712; Shanmugavadivel K, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-26092-3; Stefanita O, 2021, ROM J COMMUN PUB REL, V23, P47; Subramanian M, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101404; Tanase M.-A., 2020, PROC IBERLEF SEPLN, P236; Tunstall L., 2022, Natural Language Processing with Transformers; Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735; Vaswani A, 2017, ADV NEUR IN, V30; Wang S, 2020, P 14 WORKSH SEM EV, P1448; Wiedemann G., 2020, PROC 14 WORKSHOP SEM, P1638; WIEGAND M, 2018, P GERMEVAL WORKSHOP; Wypych M, 2024, CULT DIVERS ETHN MIN, V30, DOI 10.1037/cdp0000522; Zampieri M, 2019, SEMEVAL, P75, DOI [DOI 10.18653/V1/S19-2010, 10.18653/v1/S19-2010]; Zampieri M., 2020, P SEMEVAL; Zhang BW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3188	62	0	0	1	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						95639	95652		10.1109/ACCESS.2023.3310244	http://dx.doi.org/10.1109/ACCESS.2023.3310244			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	R5AL1		gold			2024-07-03	WOS:001064474300001
J	Touma, R; Hajj, H; El-Hajj, W; Shaban, K				Touma, Roudy; Hajj, Hazem; El-Hajj, Wassim; Shaban, Khaled			Automated Generation of Human-readable Natural Arabic Text from RDF Data	ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING			English	Article						Low-resource languages; data-to-text; RDF; language models; neural networks; datasets		With the advances in Natural Language Processing (NLP), the industry has been moving towards human-directed artificial intelligence (AI) solutions. Recently, chatbots and automated news generation have captured a lot of attention. The goal is to automatically generate readable text from tabular data or web data commonly represented in Resource Description Framework (RDF) format. The problem can then be formulated as Data-to-text (D2T) generation from structured non-linguistic data into human-readable natural language. Despite the significant work done for the English language, no efforts are being directed towards low-resource languages like the Arabic language. This work promotes the development of the first RDF data-to-text (D2T) generation system for the Arabic language while trying to address the low-resource limitation. We develop several models for the Arabic D2T task using transfer learning from large language models (LLM) such as AraBERT, AraGPT2, and mT5. These models include a baseline Bi-LSTM Sequence-to-Sequence (Seq2Seq) model, as well as encoder-decoder transformers like BERT2BERT, BERT2GPT, and T5. We then provide a detailed comparative study highlighting the strengths and limitations of these methods setting the stage for further advancement in the field. We also introduce a new Arabic dataset (AraWebNLG) that can be used for new model development in the field. To ensure a comprehensive evaluation, general-purpose automated metrics (BLEU and Perplexity scores) are used as well as task-specific human evaluation metrics related to the accuracy of the content selection and fluency of the generated text. The results highlight the importance of pre-training on a large corpus of Arabic data and show that transfer learning from AraBERT gives the best performance. Text-to-text pre-training using mT5 achieves second best performance results even with multilingual weights.	[Touma, Roudy; Hajj, Hazem; El-Hajj, Wassim] Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon; [Shaban, Khaled] Qatar Univ, POB 2713, Doha, Qatar	American University of Beirut; Qatar University	Touma, R (corresponding author), Amer Univ Beirut, POB 11-0236, Beirut 1107, Lebanon.	rst10@mail.aub.edu; hh63@aub.edu.lb; we07@aub.edu.lb; khaled.shaban@qu.edu.qa	Shaban, Khaled/AFK-5505-2022; Shaban, Khaled/M-2768-2014	Shaban, Khaled/0000-0002-5688-7515; El-Hajj, Wassim/0000-0002-5206-2954; Hajj, Hazem/0000-0002-9954-7924	Qatar National Research Fund (Qatar Foundation) [NPRP13S-0112-200037]	Qatar National Research Fund (Qatar Foundation)(Qatar Foundation (QF)Qatar National Research Fund (QNRF))	This work was made possible by NPRP13S-0112-200037 grant from Qatar National Research Fund (a member of Qatar Foundation). The statements made herein are solely the responsibility of the authors.	Antoun W., 2021, P 6 AR NAT LANG PROC, P196; Antoun Wissam, 2020, LREC 2020 WORKSHOP L; Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102; Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Darwish K, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1070; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P68; Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P552; Ferreira Thiago Castro, 2020, P 3 INT WORKSH NAT L; Gardent C., 2017, P 10 INT C NATURAL L, P124; Kale A., 2020, P 13 INT C NATURAL L, P97; Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012; Li X., 2020, P 3 INT WORKSHOP NAT, P117; Miculicich Lesly, 2019, PROC 3 WORKSHOP NEUR, P289; Moryossef A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2267; Mota Abelardo Vieira, 2020, Advances in Databases and Information Systems. 24th European Conference, ADBIS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12245), P157, DOI 10.1007/978-3-030-54832-2_13; Parikh AP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1173; Puduppully R, 2019, AAAI CONF ARTIF INTE, P6908; Puzikov Y., 2018, INLG, P463, DOI [10.18653/v1/W18-6557, DOI 10.18653/V1/W18-6557]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rebuffel Clement, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P65, DOI 10.1007/978-3-030-45439-5_5; Ribeiro M., 2021, P 3 WORKSHOP NATURAL, P211; Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_00313, 10.1162/tacl_a_.00313]; Vaswani A, 2017, ADV NEUR IN, V30; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wiseman Sam., 2017, P 2017 C EMPIRICAL M, P2253, DOI [DOI 10.18653/V1/D17-1239, 10.18653/v1/D17-1239]; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Ye Rong., 2020, INT C LEARNING REPRE	30	0	0	3	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2375-4699	2375-4702		ACM T ASIAN LOW-RESO	ACM Trans. Asian Low-Resour. Lang. Inf. Process.	APR	2023	22	4							98	10.1145/3582262	http://dx.doi.org/10.1145/3582262			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	H9FI3					2024-07-03	WOS:000998929700006
J	Rutinowski, J; Franke, S; Endendyk, J; Dormuth, I; Roidl, M; Pauly, M				Rutinowski, Jerome; Franke, Sven; Endendyk, Jan; Dormuth, Ina; Roidl, Moritz; Pauly, Markus			The Self-Perception and Political Biases of ChatGPT	HUMAN BEHAVIOR AND EMERGING TECHNOLOGIES			English	Article							PERSONALITY; TRAITS	This contribution analyzes the self-perception and political biases of OpenAI's Large Language Model ChatGPT. Considering the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution is aimed at providing further clarity on this subject. Although the concept of political bias and affiliation is hard to define, lacking an agreed-upon measure for its quantification, this contribution attempts to examine this issue by having ChatGPT respond to questions on commonly used measures of political bias. In addition, further measures for personality traits that have previously been linked to political affiliations were examined. More specifically, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and indicate that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, supporting the claims of prior research. The political questionnaires for the G7 member states indicated a bias towards progressive views but no significant bias between authoritarian and libertarian views, contradicting the findings of prior reports. In addition, ChatGPT's Big Five personality traits were tested using the OCEAN test, and its personality type was queried using the Myers-Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT was evaluated using the Dark Factor test. These three tests were also repeated ten times each, revealing that ChatGPT perceives itself as highly open and agreeable, has the Myers-Briggs personality type ENFJ, and is among the test-takers with the least pronounced dark traits.	[Rutinowski, Jerome; Franke, Sven; Endendyk, Jan; Roidl, Moritz] TU Dortmund Univ, Chair Mat Handling & Warehousing, Dortmund, Germany; [Dormuth, Ina; Pauly, Markus] TU Dortmund Univ, Chair Math Stat & Applicat Ind, Dortmund, Germany; [Pauly, Markus] UA Ruhr, Res Ctr Trustworthy Data Sci & Secur, Dortmund, Germany	Dortmund University of Technology; Dortmund University of Technology; Dortmund University of Technology	Rutinowski, J (corresponding author), TU Dortmund Univ, Chair Mat Handling & Warehousing, Dortmund, Germany.	jerome.rutinowski@tu-dortmund.de; sven.franke@tu-dortmund.de; jan.endendyk@tu-dortmund.de; ina.dormuth@tu-dortmund.de; moritz.roidl@tu-dortmund.de; markus.pauly@tu-dortmund.de		Rutinowski, Jerome/0000-0001-6907-9296; Franke, Sven/0000-0001-5822-5745	Projekt DEAL; German Ministry of Education and Research; Research Center Trustworthy Data Science and Security, an institution of the University Alliance Ruhr	Projekt DEAL; German Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Research Center Trustworthy Data Science and Security, an institution of the University Alliance Ruhr	This work is part of the research of the Lamarr Institute for Machine Learning and Artificial Intelligence which is funded by the German Ministry of Education and Research. This work was supported by the Research Center Trustworthy Data Science and Security, an institution of the University Alliance Ruhr. Open Access funding is enabled and organized by Projekt DEAL.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amirhosseini MH, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4010009; D'Alonzo S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271947; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; FISKE DW, 1949, J ABNORM SOC PSYCH, V44, P329, DOI 10.1037/h0057198; Future of Life Institute, Pause giant AI experiments: an open letter; Gerber AS, 2011, ANNU REV POLIT SCI, V14, P265, DOI 10.1146/annurev-polisci-051010-111659; Ghosh S, 2023, Arxiv, DOI arXiv:2305.10510; Hartmann J, 2023, Arxiv, DOI [arXiv:2301.01768, 10.48550/ARXIV.2301.01768, DOI 10.48550/ARXIV.2301.01768]; iSideWithcom, LLC iSideWith political questionnaires; Lalor JP, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3598; Lameris M. D., 2018, An Experimental Test of the Validity of Survey-Measured Political Ideology, DOI [10.2139/ssrn.3237290, DOI 10.2139/SSRN.3237290]; LeCun Y., 2023, Do Large Language Models Need Sensory Grounding for Meaning and Understanding?; LESTER JC, 1994, J SOC EVOL SYST, V17, P231, DOI 10.1016/1061-7361(94)90011-6; Li K., 2021, The personalities of political identity: analyzing the relationship between the Myers-Briggs Indicator Traits and identification with political liberalism and conservatism; Liu RB, 2022, ARTIF INTELL-AMST, V304, DOI 10.1016/j.artint.2021.103654; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lytwyn T., 2012, Res Publica-Journal of Undergraduate Research, V17, P11; Mammadov S, 2022, J PERS, V90, P222, DOI 10.1111/jopy.12663; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; McGee R. W., 2023, Is ChatGPT biased against conservatives? An empirical study, DOI DOI 10.2139/SSRN.4359405; McGee R. W., 2023, SSRN Electronic Journal, DOI [10.2139/ssrn.4367762, DOI 10.2139/SSRN.4367762]; Morten Moshagen I. Z., D Score: The Dark Factor of personality; Moshagen M, 2018, PSYCHOL REV, V125, P656, DOI 10.1037/rev0000111; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Myers K. C., 1962, The Myers Briggs Type Indicator: Manual, DOI [10.1037/14404-000, DOI 10.1037/14404-000]; NERIS Analytics Ltd, Myers-Briggs Type Indicator; Nolan D., 1971, The Individualist, V1, P5; OpenAi, ChatGPT; Pace News Ltd, Political compass test; Paulhus DL, 2002, J RES PERS, V36, P556, DOI 10.1016/S0092-6566(02)00505-6; Peters Uwe, 2022, Philos Technol, V35, P25, DOI 10.1007/s13347-022-00512-8; Petrik A., 2010, JSSE-Journal of Social Science Education, V9, DOI [10.4119/jsse-541, DOI 10.4119/JSSE-541]; PITTENGER DJ, 1993, REV EDUC RES, V63, P467, DOI 10.2307/1170497; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radisavljevic D, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074506; Ray P. H., 2002, Yes! Magazine, V24, P2010; Rozado D., 2023, Danger in the Machine: The Perils of Political and Demographic Biases Embedded in AI Systems; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Stein R, 2019, SOC PERSONAL PSYCHOL, V13, DOI 10.1111/spc3.12434; Steinmann E, ChatGPT Conversation Downloader; Tong SS, 2020, Arxiv, DOI arXiv:2012.05463; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Truity, Psychometrics LLC The Big Five personality test; Urchs S, 2024, Arxiv, DOI arXiv:2310.03031; van den Broek M., 2023, ChatGPT's left-leaning liberal bias; Vaswani A, 2017, ADV NEUR IN, V30; Weisberg YJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00178; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zettler I, 2021, SOC PSYCHOL PERS SCI, V12, P974, DOI 10.1177/1948550620953288; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	54	2	2	7	7	WILEY-HINDAWI	LONDON	ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND		2578-1863		HUM BEHAV EMERG TECH	Hum. Behav. Emerg. Tech.	JAN 22	2024	2024								7115633	10.1155/2024/7115633	http://dx.doi.org/10.1155/2024/7115633			9	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	GQ1B2		Green Submitted, gold			2024-07-03	WOS:001154031300001
J	Chen, XL; Zhang, WY; Zhao, ZW; Xu, PS; Zheng, YF; Shi, DL; He, MG				Chen, Xiaolan; Zhang, Weiyi; Zhao, Ziwei; Xu, Pusheng; Zheng, Yingfeng; Shi, Danli; He, Mingguang			ICGA-GPT: report generation and question answering for indocyanine green angiography images	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Early Access						Imaging		Background Indocyanine green angiography (ICGA) is vital for diagnosing chorioretinal diseases, but its interpretation and patient communication require extensive expertise and time-consuming efforts. We aim to develop a bilingual ICGA report generation and question-answering (QA) system.Methods Our dataset comprised 213 129 ICGA images from 2919 participants. The system comprised two stages: image-text alignment for report generation by a multimodal transformer architecture, and large language model (LLM)-based QA with ICGA text reports and human-input questions. Performance was assessed using both qualitative metrics (including Bilingual Evaluation Understudy (BLEU), Consensus-based Image Description Evaluation (CIDEr), Recall-Oriented Understudy for Gisting Evaluation-Longest Common Subsequence (ROUGE-L), Semantic Propositional Image Caption Evaluation (SPICE), accuracy, sensitivity, specificity, precision and F1 score) and subjective evaluation by three experienced ophthalmologists using 5-point scales (5 refers to high quality).Results We produced 8757 ICGA reports covering 39 disease-related conditions after bilingual translation (66.7% English, 33.3% Chinese). The ICGA-GPT model's report generation performance was evaluated with BLEU scores (1-4) of 0.48, 0.44, 0.40 and 0.37; CIDEr of 0.82; ROUGE of 0.41 and SPICE of 0.18. For disease-based metrics, the average specificity, accuracy, precision, sensitivity and F1 score were 0.98, 0.94, 0.70, 0.68 and 0.64, respectively. Assessing the quality of 50 images (100 reports), three ophthalmologists achieved substantial agreement (kappa=0.723 for completeness, kappa=0.738 for accuracy), yielding scores from 3.20 to 3.55. In an interactive QA scenario involving 100 generated answers, the ophthalmologists provided scores of 4.24, 4.22 and 4.10, displaying good consistency (kappa=0.779).Conclusion This pioneering study introduces the ICGA-GPT model for report generation and interactive QA for the first time, underscoring the potential of LLMs in assisting with automated ICGA image interpretation.	[Chen, Xiaolan; Zhang, Weiyi; Zhao, Ziwei; Shi, Danli; He, Mingguang] Hong Kong Polytech Univ, Sch Optometry, Kowloon, Hong Kong, Peoples R China; [Xu, Pusheng; Zheng, Yingfeng] Sun Yat sen Univ, Zhongshan Ophthalm Ctr, Guangdong Prov Clin Res Ctr Ocular Dis, State Key Lab Ophthalmol,Guangdong Prov Key Lab Op, Guangzhou, Guangdong, Peoples R China; [Shi, Danli; He, Mingguang] Hong Kong Polytech Univ, Res Ctr SHARP Vis RCSV, Kowloon, Hong Kong, Peoples R China; [He, Mingguang] Ctr Eye & Vis Res CEVR, 17W Hong Kong Sci Pk, Hong Kong, Peoples R China; [Shi, Danli] Hong Kong Polytech Univ, Hong Kong 999077, Peoples R China	Hong Kong Polytechnic University; Sun Yat Sen University; Hong Kong Polytechnic University; Hong Kong Polytechnic University	Shi, DL (corresponding author), Hong Kong Polytech Univ, Hong Kong 999077, Peoples R China.	danli.shi@polyu.edu.hk	Shi, Danli/KLD-8383-2024	Shi, Danli/0000-0001-6094-137X; Zheng, Yingfeng/0000-0002-0914-7864	Start- up Fund for RAPs under the Strategic Hiring Scheme [P0048623]; Global STEM Professorship Scheme from HKSAR [P0046113]	Start- up Fund for RAPs under the Strategic Hiring Scheme; Global STEM Professorship Scheme from HKSAR	This study was supported by the Start- up Fund for RAPs under the Strategic Hiring Scheme (P0048623) and the Global STEM Professorship Scheme (P0046113) from HKSAR.	Anderson P., 2016, SEMANTIC PROPOSITION, DOI [10.1007/978-3-319-46454-1, DOI 10.1007/978-3-319-46454-1]; Chen RY, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01018-7; Chen Z., 2021, P 59 ANN M ASS COMP, P5904, DOI DOI 10.18653/V1/2021.ACL-LONG.459; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.1136/bmj.g7594, 10.1016/j.jclinepi.2014.11.010, 10.7326/M14-0697, 10.1002/bjs.9736, 10.1186/s12916-014-0241-z, 10.1038/bjc.2014.639, 10.7326/M14-0698, 10.1016/j.eururo.2014.11.025]; Cui TX, 2023, JAMA OPHTHALMOL, V141, P1045, DOI 10.1001/jamaophthalmol.2023.4650; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; Lee JH, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222976; Li J., 2022, BOOTSTRAPPING LANGUA; Li MJ, 2022, PROC CVPR IEEE, P20624, DOI 10.1109/CVPR52688.2022.02000; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin ZH, 2023, J BIOMED INFORM, V138, DOI 10.1016/j.jbi.2023.104281; Mandrekar JN, 2011, J THORAC ONCOL, V6, P6, DOI 10.1097/JTO.0b013e318200f983; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Mosbach M., 2023, FINDINGS ASS COMPUTA, P12284; Oluwasammi A, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5538927; openai, GPT-4V(Ision) system card; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Sen P, 2023, CLIN OPHTHALMOL, V17, P53, DOI 10.2147/OPTH.S385827; Shamshad F, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102802; Shi DL, 2022, FRONT CARDIOVASC MED, V9, DOI 10.3389/fcvm.2022.823436; Si C., 2023, Prompting GPT-3 to be reliable; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Tong WJ, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.13674; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Tu T., 2024, NEJM AI, V1, DOI 10.1056/AIoa2300138; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang S., 2023, CHATCAD INTERACTIVE; Wu TW, 2023, IEEE WINT CONF APPL, P1859, DOI 10.1109/WACV56688.2023.00190; Xu P., PREPRINT, DOI [10.1101/2023.11.27.23299056, DOI 10.1101/2023.11.27.23299056]; Yang JY, 2020, GRAEF ARCH CLIN EXP, V258, P17, DOI 10.1007/s00417-019-04493-x; Yannuzzi LA, 2011, AM J OPHTHALMOL, V151, P745, DOI 10.1016/j.ajo.2011.01.043; Zhao W. X., 2023, A survey of large language models	35	1	1	5	5	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161	1468-2079		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	2024 MAR 20	2024										10.1136/bjo-2023-324446	http://dx.doi.org/10.1136/bjo-2023-324446		MAR 2024	7	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	LT3B8	38508675				2024-07-03	WOS:001189002900001
C	Wang, Y; Zheng, ZL; Tang, ZC; Li, JT; Liu, ZH; Chen, KL; Chang, JX; Zhang, QS; Liu, ZY; Zhang, M			Assoc computing machinery	Wang, Yue; Zheng, Zilong; Tang, Zecheng; Li, Juntao; Liu, Zhihui; Chen, Kunlong; Chang, Jinxiong; Zhang, Qishen; Liu, Zhongyi; Zhang, Min			Towards Better Chinese Spelling Check for Search Engines: A New Dataset and Strong Baseline	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Chinese Spelling Check; Datasets; Chinese Mobile Search Engine		Misspellings in search engine queries may prevent search engines from returning accurate results. For Chinese mobile search engines, due to the different input methods (e.g., hand-written and T9 input methods), more types of misspellings exist, making this problem more challenging. As an essential module of search engines, Chinese Spelling Check (CSC) models aim to detect and correct misspelled Chinese characters from user-issued queries. Despite the great value of CSC to the search engine, there is no CSC benchmark collected from real-world search engine queries. To fill this blank, we construct and release the Alipay Search Engine Query (AlipaySEQ) spelling check dataset. To the best of our knowledge, AlipaySEQ is the first Chinese Spelling Check dataset collected from the realworld scenario of Chinese mobile search engines. It consists of 15,522 high-quality human annotated and 1,175,151 automatically generated samples. To demonstrate the unique challenges of AlipaySEQ in the era of Large Language Models (LLMs), we conduct a thorough study to analyze the difference between AlipaySEQ and existing SIGHAN benchmarks and compare the performance of various baselines, including existing task-specific methods and LLMs. We observe that all baselines fail to perform satisfactorily due to the over-correction problem. Especially, LLMs exhibit below-par performance on AlipaySEQ, which is rather surprising. Therefore, to alleviate the over-correction problem, we introduce a modelagnostic CSC Self-Refine Framework (SRF) to construct a strong baseline. Comprehensive experiments demonstrate that our proposed SRF, though more effective against existing models on both the AlipaySEQ and SIGHAN15, is still far from achieving satisfactory performance on our real-world dataset. With the newly collected real-world dataset and strong baseline, we hope more progress can be achieved on such a challenging and valuable task.	[Wang, Yue; Zheng, Zilong; Tang, Zecheng; Li, Juntao; Zhang, Min] Soochow Univ, Suzhou, Peoples R China; [Wang, Yue; Liu, Zhihui; Chang, Jinxiong; Zhang, Qishen] Ant Grp, Beijing, Peoples R China; [Chen, Kunlong; Liu, Zhongyi] Ant Grp, Hangzhou, Peoples R China	Soochow University - China	Li, JT (corresponding author), Soochow Univ, Suzhou, Peoples R China.	ywangnlp@stu.suda.edu.cn; 1535157606@qq.com; zctang@stu.suda.edu.cn; ljt@suda.edu.cn; liuzhihui.lzh@antgroup.com; kunlong.ckl@antgroup.com; jinxiong.cjx@antgroup.com; qishen.zqs@antgroup.com; zhongyi.lzy@antgroup.com; minzhang@suda.edu.cn		Zhang, Qishen/0000-0001-9964-6298; Liu, Zhongyi/0000-0001-9478-8107	National Science Foundation of China [62206194]; Natural Science Foundation of Jiangsu Province [BK20220488]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province)	This work is supported by the National Science Foundation of China (No. 62206194), the Natural Science Foundation of Jiangsu Province (No. BK20220488).	Bao ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2031; Chang CT, 1995, P INT COMP SOFTW APP, P278, DOI 10.1109/CMPSAC.1995.524791; Chen XY, 2023, Arxiv, DOI arXiv:2303.09719; Chen Xiuying, 2022, P 4 WORKSHOP GENDER, P121; Cheng XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P871; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ge T, 2018, Arxiv, DOI arXiv:1807.01270; Guo Z, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1419; Hong Y., 2019, P 5 WORKSH NOIS US G, P160, DOI DOI 10.1145/2964284.2967242; Huang L, 2021, P 59 ANN M ASS COMPU, P5958; Ji T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3544; Ji Yong Deng Yunjie, 2023, BELLE: Be Everyone's Large Language model Engine; Jiang WJ, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4084, DOI 10.1145/3511808.3557636; Kiyono S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1236; Lan Z., 2020, INT C LEARNING REPRE; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li C, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P441; Li YH, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3202; Liang X., 2021, Advances in Neural Information Processing Systems, p10 890; Liu SL, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3008; Liu SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2991; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Martins B, 2004, LECT NOTES ARTIF INT, V3230, P372; MAYS E, 1991, INFORM PROCESS MANAG, V27, P517, DOI 10.1016/0306-4573(91)90066-U; Omelianchuk K, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P163; OpenAI, 2023, Introducing chatgpt; Raffel C, 2020, J MACH LEARN RES, V21; Tseng Yuen-Hsien, 2015, P 8 SIGHAN WORKSH CH, P32; Wane D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2517; Wang BX, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2437; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu S, 2021, arXiv; Wu S.-H., 2013, P 7 SIGHAN WORKSH CH, P35; Xie W., 2015, P 8 SIGHAN WORKSH CH, P128; Xu HD, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P716; Yu L.-C., 2014, P 3 CIPS SIGHAN JOIN, P126; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang L, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P248; Zhang RQ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2250; Zhang SH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P882; Zhou ZL, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2773, DOI 10.1145/3511808.3557416; Zhu CX, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1244	43	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							769	778		10.1145/3616855.3635847	http://dx.doi.org/10.1145/3616855.3635847			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100086
J	Mira, FA; Favier, V; Nunes, HDS; de Castro, JV; Carsuzaa, F; Meccariello, G; Vicini, C; De Vito, A; Lechien, JR; Estomba, CC; Maniaci, A; Iannella, G; Rojas, EP; Cornejo, JB; Cammaroto, G				Mira, Felipe Ahumada; Favier, Valentin; Nunes, Heloisa dos Santos Sobreira; de Castro, Joana Vaz; Carsuzaa, Florent; Meccariello, Giuseppe; Vicini, Claudio; De Vito, Andrea; Lechien, Jerome R.; Estomba, Carlos Chiesa; Maniaci, Antonino; Iannella, Giannicola; Rojas, Eduardo Pena; Cornejo, Jenifer Barros; Cammaroto, Giovanni			Chat GPT for the management of obstructive sleep apnea: do we have a polar star?	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						OSA; Sleep apnea; Chat-Gpt; Chatbot		PurposeThis study explores the potential of the Chat-Generative Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in assisting healthcare professionals in the diagnosis of obstructive sleep apnea (OSA). It aims to assess the agreement between Chat-GPT's responses and those of expert otolaryngologists, shedding light on the role of AI-generated content in medical decision-making.MethodsA prospective, cross-sectional study was conducted, involving 350 otolaryngologists from 25 countries who responded to a specialized OSA survey. Chat-GPT was tasked with providing answers to the same survey questions. Responses were assessed by both super-experts and statistically analyzed for agreement.ResultsThe study revealed that Chat-GPT and expert responses shared a common answer in over 75% of cases for individual questions. However, the overall consensus was achieved in only four questions. Super-expert assessments showed a moderate agreement level, with Chat-GPT scoring slightly lower than experts. Statistically, Chat-GPT's responses differed significantly from experts' opinions (p = 0.0009). Sub-analysis revealed areas of improvement for Chat-GPT, particularly in questions where super-experts rated its responses lower than expert consensus.ConclusionsChat-GPT demonstrates potential as a valuable resource for OSA diagnosis, especially where access to specialists is limited. The study emphasizes the importance of AI-human collaboration, with Chat-GPT serving as a complementary tool rather than a replacement for medical professionals. This research contributes to the discourse in otolaryngology and encourages further exploration of AI-driven healthcare applications. While Chat-GPT exhibits a commendable level of consensus with expert responses, ongoing refinements in AI-based healthcare tools hold significant promise for the future of medicine, addressing the underdiagnosis and undertreatment of OSA and improving patient outcomes.	[Mira, Felipe Ahumada] Hosp Linares, ENT Dept, Linares, Chile; [Favier, Valentin] Univ Hosp Montpellier, ENT Dept, Montpellier, France; [Nunes, Heloisa dos Santos Sobreira] Nucleus Otolaryngol Head & Neck Surg & Sleep Med S, ENT & Sleep Med Dept, Sao Paulo, Brazil; [de Castro, Joana Vaz] Armed Forces Hosp, ENT Dept, Lisbon, Portugal; [Carsuzaa, Florent] Univ Hosp Poitiers, ENT Dept, Poitiers, France; [Meccariello, Giuseppe; Vicini, Claudio; De Vito, Andrea; Cammaroto, Giovanni] GB Morgagni L Pierantoni Hosp, Head & Neck Dept, ENT & Oral Surg Unity, Via Forlanini, I-47121 Forli, Italy; [Lechien, Jerome R.] Univ Mons, EpiCURA Hosp, UMONS Res Inst Hlth Sci & Technol, Dept Otolaryngol & Head & Neck Surg,Div Laryngol &, Mons, Belgium; [Estomba, Carlos Chiesa] Donostia Univ Hosp, Biodonostia Res Inst, Dept Otorhinolaryngol, San Sebastian 20014, Spain; [Maniaci, Antonino] Univ Catania, Dept Med & Surg Sci & Adv Technol GF Ingrassia, ENT Sect, Piazza Univ 2, I-95100 Catania, Italy; [Iannella, Giannicola] Univ Sapienza, Dept Organi Senso, Viale Univ 33, I-00185 Rome, Italy; [Rojas, Eduardo Pena] Clin Lircay, Talca, Chile; [Cornejo, Jenifer Barros] Hosp Clin UC Christus, Santiago, Chile; [Mira, Felipe Ahumada; Favier, Valentin; Nunes, Heloisa dos Santos Sobreira; de Castro, Joana Vaz; Carsuzaa, Florent; Lechien, Jerome R.; Estomba, Carlos Chiesa; Maniaci, Antonino; Iannella, Giannicola; Cammaroto, Giovanni] Young Otolaryngologists Int Federat Otorhinolaryng, Paris, France	Universite de Montpellier; CHU de Montpellier; CHU Poitiers; Universite de Poitiers; University of Mons; University Hospital Donostia; University of Catania; Sapienza University Rome	Cammaroto, G (corresponding author), GB Morgagni L Pierantoni Hosp, Head & Neck Dept, ENT & Oral Surg Unity, Via Forlanini, I-47121 Forli, Italy.; Cammaroto, G (corresponding author), Young Otolaryngologists Int Federat Otorhinolaryng, Paris, France.	felipe.ahumada.m@gmail.com; valentin_favier@hotmail.com; helo2005@hotmail.com; joanavazdecastro@gmail.com; florent.carsuzza@gmail.com; lechienj@gmail.com; chiesaestomba86@gmail.com; tnmaniaci29@gmail.com; giannicola.iannella@uniroma1.it; giovanni.cammaroto@hotmail.com	Meccariello, Giuseppe/K-5685-2016; Maniaci, Antonino/AAB-6004-2021; Cammaroto, Giovanni/D-4401-2017	Maniaci, Antonino/0000-0002-1251-0185; Favier, Valentin/0000-0002-7999-951X	The authors would like to express their gratutide to the following super-experts for having participated to the study Bhik Kotecha, Clemens Heiser, Nico De Vrie, Rodolfo Lugo Saldana, Joachim Maurer, Ofer Jacobowitz, Kenny Pang, Michel Cahali, Ewa Olszewsk	The authors would like to express their gratutide to the following super-experts for having participated to the study Bhik Kotecha, Clemens Heiser, Nico De Vrie, Rodolfo Lugo Saldana, Joachim Maurer, Ofer Jacobowitz, Kenny Pang, Michel Cahali, Ewa Olszewsk	The authors would like to express their gratutide to the following super-experts for having participated to the study Bhik Kotecha, Clemens Heiser, Nico De Vrie, Rodolfo Lugo Saldana, Joachim Maurer, Ofer Jacobowitz, Kenny Pang, Michel Cahali, Ewa Olszewska.	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Chiesa-Estomba CM, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08104-8; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Lyons Riley J, 2023, Can J Ophthalmol, DOI 10.1016/j.jcjo.2023.07.016; Peppard PE, 2013, AM J EPIDEMIOL, V177, P1006, DOI 10.1093/aje/kws342; Peppard PE, 2000, NEW ENGL J MED, V342, P1378, DOI 10.1056/NEJM200005113421901; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259; Senaratna CV, 2017, SLEEP MED REV, V34, P70, DOI 10.1016/j.smrv.2016.07.002; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Warrens MJ, 2010, ADV DATA ANAL CLASSI, V4, P271, DOI 10.1007/s11634-010-0073-4; Xv Y, 2023, WORLD J UROL, V41, P2569, DOI 10.1007/s00345-023-04539-0; Yeghiazarians Y, 2021, CIRCULATION, V144, pE56, DOI 10.1161/CIR.0000000000000988	14	9	9	39	48	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	APR	2024	281	4					2087	2093		10.1007/s00405-023-08270-9	http://dx.doi.org/10.1007/s00405-023-08270-9		NOV 2023	7	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	LQ7A3	37980605				2024-07-03	WOS:001103635400001
J	Walker, HL; Ghani, S; Kuemmerli, C; Nebiker, CA; Müller, BP; Raptis, DA; Staubli, SM				Walker, Harriet Louise; Ghani, Shahi; Kuemmerli, Christoph; Nebiker, Christian Andreas; Muller, Beat Peter; Raptis, Dimitri Aristotle; Staubli, Sebastian Manuel			Reliability of Medical Information Provided by ChatGPT: Assessment Against Clinical Guidelines and Patient Information Quality Instrument	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						artificial intelligence; internet information; patient information; ChatGPT; EQIP tool; chatbot; chatbots; conversational agent; conversational agents; internal medicine; pancreas; liver; hepatic; biliary; gall; bile; gallstone; pancreatitis; pancreatic; medical information		Background: ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot able to answer freely formulated and complex questions. In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information. However, little is known about the quality of medical information provided by the AI. Objective: We aimed to assess the reliability of medical information provided by ChatGPT. Methods: Medical information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden was measured with the Ensuring Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections. In addition, 5 guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently. All queries were repeated 3 times to measure the internal consistency of ChatGPT. Results: Five conditions were identified (gallstone disease, pancreatitis, liver cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. Divided by subsection, median scores for content, identification, and structure data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. Agreement between guideline recommendations and answers provided by ChatGPT was 60% (15/25). Interrater agreement as measured by the Fleiss kappa was 0.78 (P<.001), indicating substantial agreement. Internal consistency of the answers provided by ChatGPT was 100%. Conclusions: ChatGPT provides medical information of comparable quality to available static internet information. Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information.	[Walker, Harriet Louise; Ghani, Shahi; Staubli, Sebastian Manuel] Royal Free London NHS Fdn Trust, Pond St, London NW3 2QG, England; [Kuemmerli, Christoph; Muller, Beat Peter; Staubli, Sebastian Manuel] Clarunis Univ Ctr Gastrointestinal & Liver Dis, Basel, Switzerland; [Nebiker, Christian Andreas] Kantonsspital Aarau, Dept Chirurg, Aarau, Switzerland; [Raptis, Dimitri Aristotle] King Faisal Specialist Hosp & Res Ctr, Organ Transplant Ctr Excellence, Riyadh, Saudi Arabia	University of London; University College London; Royal Free London NHS Foundation Trust; Kantonsspital Aarau AG (KSA); King Faisal Specialist Hospital & Research Center	Staubli, SM (corresponding author), Royal Free London NHS Fdn Trust, Pond St, London NW3 2QG, England.	s.staubli@nhs.net	Kuemmerli, Christoph/AEL-8125-2022; Staubli, Sebastian/HJP-1257-2023	Kuemmerli, Christoph/0000-0002-7109-3545; Raptis, Dimitri Aristotle/0000-0002-0898-3270; Muller-Stich, Beat Peter/0000-0002-8552-8538; Staubli, Sebastian/0000-0002-0818-9835; Walker, Harriet/0009-0009-6278-6399				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], PANCR CANC AD DIAGN; [Anonymous], CIRRH 16S ASS MAN; [Anonymous], DIG DIS LEV 2 CAUS; [Anonymous], PANCR NICE GUID NG10; [Anonymous], Chatgpt; [Anonymous], TOT CANC CAUS; [Anonymous], CLIN GUID GALLST DIS; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Charvet-Berard AI, 2008, PATIENT EDUC COUNS, V70, P407, DOI 10.1016/j.pec.2007.11.018; European Assoc Study Liver, 2018, J HEPATOL, V69, P182, DOI 10.1016/j.jhep.2018.03.019; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fan KS, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-040487; Ghani S, 2021, J MED INTERNET RES, V23, DOI 10.2196/22618; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Tran KB, 2022, LANCET, V400, P563, DOI 10.1016/S0140-6736(22)01438-6; Kwan LY, 2022, INT J PEDIATR OTORHI, V159, DOI 10.1016/j.ijporl.2022.111224; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Moult B, 2004, HEALTH EXPECT, V7, P165, DOI 10.1111/j.1369-7625.2004.00273.x; OpenAI, Wikipedia; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Raptis DA, 2019, HPB, V21, P1632, DOI 10.1016/j.hpb.2019.03.355; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sebastian G., 2023, IJSPPC, V15, P1, DOI [10.4018/IJSPPC.325475, DOI 10.4018/IJSPPC.325475]; Sebastian G, 2023, J MED INTERNET RES, V25, DOI 10.2196/41430; Springfeld C, 2023, NAT REV CLIN ONCOL, V20, P318, DOI 10.1038/s41571-023-00746-1; Stevens L, 2023, J GASTROINTEST CANC, V54, P890, DOI 10.1007/s12029-022-00879-z; Tsytsarev V, 2022, BEHAV BRAIN RES, V419, DOI 10.1016/j.bbr.2021.113684; Vetter D, 2018, OBES SURG, V28, P1240, DOI 10.1007/s11695-017-2983-0; Willems J., 2023, Social Science Research Network, DOI DOI 10.2139/SSRN.4334162	32	44	45	36	72	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JUN 30	2023	25								e47479	10.2196/47479	http://dx.doi.org/10.2196/47479			9	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	L9WM8	37389908	Green Published, gold			2024-07-03	WOS:001026704100002
J	Zalzal, HG; Abraham, A; Cheng, JH; Shah, RK				Zalzal, Habib G.; Abraham, Ariel; Cheng, Jenhao; Shah, Rahul K.			Can ChatGPT help patients answer their otolaryngology questions?	LARYNGOSCOPE INVESTIGATIVE OTOLARYNGOLOGY			English	Article						artificial intelligence; ChatGPT; large language model; machine learning; OpenAI; patient education		Background: Over the past year, the world has been captivated by the potential of artificial intelligence (AI). The appetite for AI in science, specifically healthcare is huge. It is imperative to understand the credibility of large language models in assisting the public in medical queries.Objective: To evaluate the ability of ChatGPT to provide reasonably accurate answers to public queries within the domain of Otolaryngology.Methods: Two board-certified otolaryngologists (HZ, RS) inputted 30 text-based patient queries into the ChatGPT-3.5 model. ChatGPT responses were rated by physicians on a scale (accurate, partially accurate, incorrect), while a similar 3-point scale involving confidence was given to layperson reviewers. Demographic data involving gender and education level was recorded for the public reviewers. Inter-rater agreement percentage was based on binomial distribution for calculating the 95% confidence intervals and performing significance tests. Statistical significance was defined as p < .05 for two-sided tests.Results: In testing patient queries, both Otolaryngology physicians found that ChatGPT answered 98.3% of questions correctly, but only 79.8% (range 51.7%-100%) of patients were confident that the AI model was accurate in its responses (corrected agreement = 0.682; p < .001). Among the layperson responses, the corrected coefficient was of moderate agreement (0.571; p < .001). No correlation was noted among age, gender, or education level for the layperson responses.Conclusion: ChatGPT is highly accurate in responding to questions posed by the public with regards to Otolaryngology from a physician standpoint. Public reviewers were not fully confident in believing the AI model, with subjective concerns related to less trust in AI answers compared to physician explanation. Larger evaluations with a representative public sample and broader medical questions should immediately be conducted by appropriate organizations, governing bodies, and/or governmental agencies to instill public confidence in AI and ChatGPT as a medical resource.Level of Evidence: 4.	[Zalzal, Habib G.; Shah, Rahul K.] Childrens Natl Hosp, Div Otolaryngol Head & Neck Surg, Washington, DC USA; [Abraham, Ariel] Univ Maryland, Baltimore, MD USA; [Cheng, Jenhao] Childrens Natl Hosp, Qual, Safety, Analyt, Washington, DC USA; [Zalzal, Habib G.] Childrens Natl Med Ctr, Div Otolaryngol, 111 Michigan Ave NW, Washington, DC 20010 USA	Children's National Health System; University System of Maryland; University of Maryland Baltimore; Children's National Health System; Children's National Health System	Zalzal, HG (corresponding author), Childrens Natl Med Ctr, Div Otolaryngol, 111 Michigan Ave NW, Washington, DC 20010 USA.	hzalzal@cnmc.org	Cheng, Jacob/JDC-9120-2023	Cheng, Jenhao/0000-0001-8359-2475				Altman DG., 1991, Practical statistics for medical research; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Campbell DJ, 2023, J CLIN SLEEP MED, V19, P1989, DOI 10.5664/jcsm.10728; Cao Y., 2023, PREPRINT; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Gwet K. L., 2014, Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters, V4th; Harris E, 2023, JAMA-J AM MED ASSOC, V329, P1053, DOI 10.1001/jama.2023.3310; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; OpenAI, 2023, "ChatGPT," OpenAI; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Tamir SO, 2017, ARCH DIS CHILD, V102, P450, DOI 10.1136/archdischild-2016-310729	13	6	6	14	15	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2378-8038			LARYNGOSCOPE INVEST	Laryngoscope Investig. Otol.	FEB	2024	9	1								10.1002/lio2.1193	http://dx.doi.org/10.1002/lio2.1193		DEC 2023	8	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	LA0L3	38362184	gold, Green Published			2024-07-03	WOS:001118053700001
J	Invernici, F; Bernasconi, A; Ceri, S				Invernici, Francesco; Bernasconi, Anna; Ceri, Stefano			Exploring the evolution of research topics during the COVID-19 pandemic	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Research data; Scientific literature; Natural language processing; Topic modeling; COVID-19; Time series		The COVID-19 pandemic has changed the research agendas of most scientific communities, resulting in an overwhelming production of research articles in a variety of domains, including medicine, virology, epidemiology, economy, psychology, and so on. Several open-access corpora and literature hubs were established; among them, the COVID-19 Open Research Dataset (CORD-19) has systematically gathered scientific contributions for 2.5 years, by collecting and indexing over one million articles-this corpus, however, does not provide an easy-to-access overview of its content. Here, we present the CORD-19 Topic Visualizer (CORToViz), a method and associated visualization tool for inspecting the CORD-19 textual corpus of scientific abstracts. Our method is based upon a careful selection of up-to-date technologies (including large language models), resulting in an architecture for clustering articles along orthogonal dimensions and extraction techniques for temporal topic mining. Topic inspection is supported by an interactive dashboard, providing fast, one-click visualization of topic contents as word clouds and topic trends as time series, equipped with easy-to-drive statistical testing for analyzing the significance of topic emergence along arbitrarily selected time windows. Overall, our pipeline is very fast and its results match our expectations on topic identification (F1-score 0.854). The processes of data preparation and results visualization are completely general and virtually applicable to any corpus of textual documents-thus suited for effective adaptation to other contexts.	[Invernici, Francesco; Bernasconi, Anna; Ceri, Stefano] Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy	Polytechnic University of Milan	Bernasconi, A (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy.	francesco.invernici@polimi.it; anna.bernasconi@polimi.it; stefano.ceri@polimi.it	Bernasconi, Anna/AAF-2594-2019	Bernasconi, Anna/0000-0001-8016-5750; Invernici, Francesco/0009-0002-5423-6978	NGI [OC2_18]; European Union [101069364]; PNRR-PE-AI FAIR - NextGeneration EU program	NGI; European Union(European Union (EU)); PNRR-PE-AI FAIR - NextGeneration EU program	This research is supported by the TEThYS project, a beneficiary of the NGI Search 2nd Open Call (Number of the Sub -grant Agreement SEARCH OC2_18) , funded by the European Union. The NGI Search project has received funding from the European Union's Horizon Europe research and innovation programme under the grant agreement 101069364 and it is framed under the Next Generation Internet Initiative. S.C. is supported by the PNRR-PE-AI FAIR project funded by the NextGeneration EU program.	American Society for Microbiology, 2023, COVID-19 (SARS-CoV-2 coronavirus) resources; Angelov D, 2020, Arxiv, DOI [arXiv:2008.09470, DOI 10.48550/ARXIV.2008.09470, 10.48550/arXiv.2008.09470]; Tran BX, 2020, INT J ENV RES PUB HE, V17, DOI [10.3390/ijerph17114095, 10.3390/ijerph17103577]; Badawy A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14010226; Berchialla P, 2021, EPIDEMIOL PREV, V45, P449, DOI 10.19191/EP21.6.136; Capobianchi MR, 2020, CLIN MICROBIOL INFEC, V26, P954, DOI 10.1016/j.cmi.2020.03.025; Ceri S., 2013, Data-centric systems and applications, Web information retrieval, P27; Cerqua A, 2022, STAT METHOD APPL-GER, V31, P181, DOI 10.1007/s10260-021-00568-4; Chen QY, 2021, NUCLEIC ACIDS RES, V49, pD1534, DOI 10.1093/nar/gkaa952; Chen Y, 2019, KNOWL-BASED SYST, V163, P1, DOI 10.1016/j.knosys.2018.08.011; Cohan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2270; Colavizza G, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0244839; Dagdelen J, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0281147; Deka P., 2022, Lecture notes in computer science, Health information science, P3; Moody CE, 2016, Arxiv, DOI arXiv:1605.02019; Ebeling R., 2022, P INT AAAI C WEB SOC, V16, P159; Egger R, 2022, FRONT SOCIOL, V7, DOI 10.3389/fsoc.2022.886498; Elsevier, 2023, Novel coronavirus information center; Falkenberg M, 2022, NAT CLIM CHANGE, V12, P1114, DOI 10.1038/s41558-022-01527-x; García GS, 2023, GIGASCIENCE, V12, DOI 10.1093/gigascience/giad036; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Huang T.-H. K., 2020, P 1 WORKSH NLP COVID; James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1; Jayabharathy J., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P425, DOI 10.1109/ICCSN.2011.6014600; Korn D, 2021, BIOINFORMATICS, V37, P586, DOI 10.1093/bioinformatics/btaa718; Krause A., 2006, P 23 INT C MACHINE L, P497; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; Logette E, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.695139; MacMillan Learning, 2022, Information about COVID-19; Mahmoud T., 2016, British Journal of Applied Science & Technology, V18, P1; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Meng Y, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3143, DOI 10.1145/3485447.3512034; Moulavi D., 2014, P 14 SIAM INT C DAT, P839, DOI DOI 10.1137/1.9781611973440.96; Mueller A. C., 2023, Wordcloud; National Institutes of Health, 2023, NIH OPA iSearch COVID-19 portfolio; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pourhatami A, 2021, SCIENTOMETRICS, V126, P6625, DOI 10.1007/s11192-021-04038-2; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ritchie H., 2020, CORONAVIRUS PANDEMIC; Scepanovic S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-26796-6; Shahapure KR, 2020, PR INT CONF DATA SC, P747, DOI 10.1109/DSAA49011.2020.00096; Shao YJ, 2018, IEEE INT CONF BIG DA, P2874, DOI 10.1109/BigData.2018.8622345; Springer Nature, 2023, Querystring parameter-API portal; Streamlit, 2023, A faster way to build and share data apps; Thakur Nandan, 2021, 35 C NEURAL INFORM P; The Lens, 2021, Human coronaviruses data initiative; United Nations News, 2023, WHO chief declares end to COVID-19 as a global health emergency; Valika TS, 2020, OTOLARYNG HEAD NECK, V163, P931, DOI 10.1177/0194599820935850; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wadden D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7534; Wang L.L., 2020, arXiv; Wang LL, 2021, BRIEF BIOINFORM, V22, P781, DOI 10.1093/bib/bbaa296; Wang QY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P66; Wikipedia, 2023, Timeline of the COVID-19 pandemic; Wise C, 2020, P KNOWLEDGEABLE NLP, P1; World Health Organization, 2023, A brief history of vaccination; World Health Organization, 2023, Global research on coronavirus disease (COVID-19); Zhang Y, 2021, SCIENTOMETRICS, V126, P4225, DOI 10.1007/s11192-021-03946-7	61	0	0	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	OCT 15	2024	252		A						124028	10.1016/j.eswa.2024.124028	http://dx.doi.org/10.1016/j.eswa.2024.124028			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	TE1T2		hybrid			2024-07-03	WOS:001239500800001
J	Xu, F; Nguyen, T; Du, J				Xu, Fang; Nguyen, Tri; Du, Jing			Augmented Reality for Maintenance Tasks with ChatGPT for Automated Text-to-Action	JOURNAL OF CONSTRUCTION ENGINEERING AND MANAGEMENT			English	Article						Augmented reality (AR); ChatGPT; Maintenance	OPPORTUNITIES; SYSTEM; TRUST	Advancements in sensor technology, artificial intelligence (AI), and augmented reality (AR) have unlocked opportunities across various domains. AR and large language models like GPT have witnessed substantial progress and increasingly are being employed in diverse fields. One such promising application is in operations and maintenance (O&M). O&M tasks often involve complex procedures and sequences that can be challenging to memorize and execute correctly, particularly for novices or in high-stress situations. By combining the advantages of superimposing virtual objects onto the physical world and generating human-like text using GPT, we can revolutionize O&M operations. This study introduces a system that combines AR, optical character recognition (OCR), and the GPT language model to optimize user performance while offering trustworthy interactions and alleviating workload in O&M tasks. This system provides an interactive virtual environment controlled by the Unity game engine, facilitating a seamless interaction between virtual and physical realities. A case study (N=30) was conducted to illustrate the findings and answer the research questions. The Multidimensional Measurement of Trust (MDMT) was applied to understand the complexity of trust engagement with such a human-like system. The results indicate that users can complete similarly challenging tasks in less time using our proposed AR and AI system. Moreover, the collected data also suggest a reduction in cognitive load when executing the same operations using the AR and AI system. A divergence of trust was observed concerning capability and ethical dimensions.	[Xu, Fang; Nguyen, Tri] Univ Florida, Dept Civil & Coastal Engn, Informat Cobots & Intelligent Construct Lab, Weil Hall 360, Gainesville, FL 32611 USA; [Du, Jing] Univ Florida, Dept of Civil & Coastal Engn, Informat Cobots & Intelligent Construct Lab, 460F Weil Hall, Gainesville, FL 32611 USA	State University System of Florida; University of Florida; State University System of Florida; University of Florida	Du, J (corresponding author), Univ Florida, Dept of Civil & Coastal Engn, Informat Cobots & Intelligent Construct Lab, 460F Weil Hall, Gainesville, FL 32611 USA.	xufang@ufl.edu; tri.nguyen@ufl.edu; eric.du@essie.ufl.edu		Xu, Fang/0009-0002-9597-917X	National Institute of Standards and Technology (NIST) [70NANB21H045]	National Institute of Standards and Technology (NIST)(National Institute of Standards & Technology (NIST) - USA)	This material is supported by the National Institute of Standards and Technology (NIST) under Grant 70NANB21H045. Any opinions, findings, conclusions, or recommendations expressed in this article are those of the authors and do not reflect the views of NIST.	Alavi H., 2021, PROC EC3 C 2021, P431; Ammari K. E., 2014, COMPUTING CIVIL BUIL, P657, DOI DOI 10.1061/9780784413616.082; Ananthaswamy A, 2023, NATURE, V615, P202, DOI 10.1038/d41586-023-00641-w; Awasthi I, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1310, DOI 10.1109/ICICT50816.2021.9358703; Baek F, 2019, AUTOMAT CONSTR, V99, P18, DOI 10.1016/j.autcon.2018.11.034; Banks J, 2021, INT J SOC ROBOT, V13, P2021, DOI 10.1007/s12369-020-00692-3; Bansal P, 2023, Arxiv, DOI arXiv:2306.15766; Bortolini R, 2020, BUILD RES INF, V48, P207, DOI 10.1080/09613218.2019.1609291; Brzowski Matthew, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1595, DOI 10.1177/1071181319631462; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Campello de Souza B., 2023, ChatGPT, the cognitive mediation networks theory and the emergence of sophotechnic thinking: How natural language AIs will bring a new step in collective cognitive evolution; Chen J., 2021, PROC 38 INT S AUTOMA, P467; Chen YJ, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103041; Cheng JCP, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001749; Cheng MY, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103265; Chi HL, 2013, AUTOMAT CONSTR, V33, P116, DOI 10.1016/j.autcon.2012.12.017; Chita-Tegmark M, 2021, 2021 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI, P92, DOI 10.1145/3434073.3444677; Choi JH., 2021, J Legal Educ, V71, P387; Chong OW, 2021, AUTOMAT CONSTR, V129, DOI 10.1016/j.autcon.2021.103756; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Chung S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110283; Corneli A., 2019, PROC ISARC PROC INT, P332; Du J., 2023, Augumented reality (AR) HoloLens and ChatGPT for maintenance; Du J, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000740; Ezer Neta, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P322, DOI 10.1177/1071181319631264; Gebru B, 2022, IEEE T HUM-MACH SYST, V52, P952, DOI 10.1109/THMS.2022.3144956; Graves L., 2018, UNDERSTANDING PROMIS; Guan P, 2023, Arxiv, DOI arXiv:2303.15666; Hajirasouli A, 2022, CONSTR INNOV-ENGL, V22, P412, DOI 10.1108/CI-01-2022-0007; HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x; Hampshire A, 2012, NEURON, V76, P1225, DOI 10.1016/j.neuron.2012.06.022; Hart S.G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]; Herbers P, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204260; Holmes EA, 2008, ACTA PSYCHOL, V127, P553, DOI 10.1016/j.actpsy.2007.11.002; Holmes J, 2023, Arxiv, DOI arXiv:2304.01938; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Hua W, 2015, PROC INT CONF DATA, P495, DOI 10.1109/ICDE.2015.7113309; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Joseph M. H., 2019, PROC 2019 IEEE INT C, P1; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Klyuchnikov N, 2022, IEEE ACCESS, V10, P45736, DOI 10.1109/ACCESS.2022.3169897; Koch C, 2014, AUTOMAT CONSTR, V48, P18, DOI 10.1016/j.autcon.2014.08.009; Kolaei AZ, 2022, AUTOMAT CONSTR, V143, DOI 10.1016/j.autcon.2022.104586; Künz A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P389, DOI 10.1109/VR51125.2022.00058; Lee J, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000757; Liu A, 2023, Arxiv, DOI arXiv:2304.14399; Liu F, 2018, AUTOMAT CONSTR, V90, P79, DOI 10.1016/j.autcon.2018.02.020; Lu QC, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103277; Luebbers M. B., 2022, PROC 5 INT WORKSHOP; Machado RL, 2020, J CIV ENG MANAG, V26, P83, DOI 10.3846/jcem.2020.11803; Madsen Maria., 2000, 11 AUSTR C INF SYST, Vvol. 53, P6; Marocco M, 2021, BUILD RES INF, V49, P893, DOI 10.1080/09613218.2021.1953368; Mayer RE, 2002, PSYCHOL LEARN MOTIV, V41, P85, DOI 10.1016/S0079-7421(02)80005-6; Merritt SM, 2011, HUM FACTORS, V53, P356, DOI 10.1177/0018720811411912; Microsoft, 2023, MixedRealityToolkit-Unity; Mithe R., 2013, Int. J. Recent. Technol. Eng., V2, P72; OCONNOR T, 1994, AM PHILOS QUART, V31, P91; Omar Reham, 2023, ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots, DOI DOI 10.48550/ARXIV.2302.06466; Ong S., 2021, Beginning windows mixed reality programming: For HoloLens and mixed reality headsets, P175; Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002; Porter D., 2020, Trustworthy autonomy: A roadmap to assurance-Part 1: System effectiveness; Pterneas V., 2022, Mastering the Microsoft Kinect: Body tracking, object detection, and the Azure Cloud Services, P219; Rahaman MS, 2023, J Eng Emerg Technol, V2, P1, DOI [10.52631/jeet.v2i1.188, DOI 10.52631/JEET.V2I1.188]; Schaub L, 2022, IEEE INT SYMP M AU R, P77, DOI 10.1109/ISMAR-Adjunct57072.2022.00025; Schwartz S, 2023, Arxiv, DOI arXiv:2308.05391; Servières M, 2021, J SENSORS, V2021, DOI 10.1155/2021/2054828; Siau Keng, 2018, Cutter Bus. Tech. J., V31, P47; Sidani A, 2021, J BUILD ENG, V42, DOI 10.1016/j.jobe.2021.102500; Siegele D, 2020, LECT NOTES COMPUT SC, V12242, P255, DOI 10.1007/978-3-030-58465-8_20; Singh H, 2020, Arxiv, DOI arXiv:2002.06544; Socher R., 2011, P 28 INT C MACH LEAR, P129; Takayuki F., 2020, PROC INT DISPLAY WOR, P702; Tan YM, 2023, Arxiv, DOI arXiv:2303.07992; Tas O., 2007, PressAcademia Procedia, V5, P205; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; ul Hassan F, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002122; Ullman D., 2019, MDMT: Multi-dimensional measure of trust; Ullman D, 2021, 2021 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI, P110, DOI 10.1145/3434073.3444652; Ullman D, 2018, ACMIEEE INT CONF HUM, P263, DOI 10.1145/3173386.3176991; Ullman D, 2019, ACMIEEE INT CONF HUM, P618, DOI [10.1109/HRI.2019.8673154, 10.1109/hri.2019.8673154]; Ungureanu D, 2020, Arxiv, DOI [arXiv:2008.11239, DOI 10.48550/ARXIV.2008.11239]; Unity, 2023, Unity; Vaswani A, 2017, ADV NEUR IN, V30; Vinumol K. P., 2013, Proceedings of the 2013 XV Symposium on Virtual and Augmented Reality (SVR), P232, DOI 10.1109/SVR.2013.26; Wang TK, 2019, J PERFORM CONSTR FAC, V33, DOI 10.1061/(ASCE)CF.1943-5509.0001339; Wei JJ, 2021, THEOR ISS ERGON SCI, V22, P274, DOI 10.1080/1463922X.2020.1766596; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Wojton HM, 2020, J SOC PSYCHOL, V160, P735, DOI 10.1080/00224545.2020.1749020; Wu HQ, 2020, ENG CONSTR ARCHIT MA, V27, P1891, DOI 10.1108/ECAM-09-2019-0480; Xiong JH, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00658-8; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Yeh M, 2001, HUM FACTORS, V43, P355, DOI 10.1518/001872001775898269; You HX, 2023, Arxiv, DOI arXiv:2304.11018; Zhang JS, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000583; Zhang JS, 2017, AUTOMAT CONSTR, V73, P45, DOI 10.1016/j.autcon.2016.08.027; Zhou SH, 2020, ENG CONSTR ARCHIT MA, V27, P458, DOI 10.1108/ECAM-02-2019-0097; Zhou TY, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101170	100	0	0	33	33	ASCE-AMER SOC CIVIL ENGINEERS	RESTON	1801 ALEXANDER BELL DR, RESTON, VA 20191-4400 USA	0733-9364	1943-7862		J CONSTR ENG M	J. Constr. Eng. Manage.	APR 1	2024	150	4							04024015	10.1061/JCEMD4.COENG-14142	http://dx.doi.org/10.1061/JCEMD4.COENG-14142			14	Construction & Building Technology; Engineering, Industrial; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	HZ5Z7		Green Submitted			2024-07-03	WOS:001163361000006
J	Li, DJ; Kao, YC; Tsai, SJ; Bai, YM; Yeh, TC; Chu, CS; Hsu, CW; Cheng, SW; Hsu, TW; Liang, CS; Su, KP				Li, Dian-Jeng; Kao, Yu-Chen; Tsai, Shih-Jen; Bai, Ya-Mei; Yeh, Ta-Chuan; Chu, Che-Sheng; Hsu, Chih-Wei; Cheng, Szu-Wei; Hsu, Tien-Wei; Liang, Chih-Sung; Su, Kuan-Pin			Comparing the performance of ChatGPT GPT-4, Bard, and Llama-2 in the Taiwan Psychiatric Licensing Examination and in differential diagnosis with multi-center psychiatrists	PSYCHIATRY AND CLINICAL NEUROSCIENCES			English	Article; Early Access						chatbot; ChatGPT; differential diagnosis in psychiatry; psychiatric application; Taiwanese psychiatric licensing examination		Aim: Large language models (LLMs) have been suggested to play a role in medical education and medical practice. However, the potential of their application in the psychiatric domain has not been well-studied. Method: In the first step, we compared the performance of ChatGPT GPT-4, Bard, and Llama-2 in the 2022 Taiwan Psychiatric Licensing Examination conducted in traditional Mandarin. In the second step, we compared the scores of these three LLMs with those of 24 experienced psychiatrists in 10 advanced clinical scenario questions designed for psychiatric differential diagnosis. Result: Only GPT-4 passed the 2022 Taiwan Psychiatric Licensing Examination (scoring 69 and >= 60 being considered a passing grade), while Bard scored 36 and Llama-2 scored 25. GPT-4 outperformed Bard and Llama-2, especially in the areas of 'Pathophysiology & Epidemiology' (chi(2) = 22.4, P < 0.001) and 'Psychopharmacology & Other therapies' (chi(2) = 15.8, P < 0.001). In the differential diagnosis, the mean score of the 24 experienced psychiatrists (mean 6.1, standard deviation 1.9) was higher than that of GPT-4 (5), Bard (3), and Llama-2 (1). Conclusion: Compared to Bard and Llama-2, GPT-4 demonstrated superior abilities in identifying psychiatric symptoms and making clinical judgments. Besides, GPT-4's ability for differential diagnosis closely approached that of the experienced psychiatrists. GPT-4 revealed a promising potential as a valuable tool in psychiatric practice among the three LLMs.	[Li, Dian-Jeng] Kaohsiung Municipal Kai Syuan Psychiat Hosp, Dept Addict Sci, Kaohsiung, Taiwan; [Li, Dian-Jeng] Meiho Univ, Dept Nursing, Pingtung, Taiwan; [Kao, Yu-Chen; Yeh, Ta-Chuan; Liang, Chih-Sung] Triserv Gen Hosp, Natl Def Med Ctr, Dept Psychiat, Taipei, Taiwan; [Kao, Yu-Chen; Liang, Chih-Sung] Triserv Gen Hosp, Dept Psychiat, Beitou Branch, Taipei, Taiwan; [Tsai, Shih-Jen; Bai, Ya-Mei] Taipei Vet Gen Hosp, Dept Psychiat, Taipei, Taiwan; [Tsai, Shih-Jen; Bai, Ya-Mei] Natl Yang Ming Chiao Tung Univ, Coll Med, Dept Psychiat, Taipei, Taiwan; [Bai, Ya-Mei] Natl Yang Ming Chiao Tung Univ, Inst Brain Sci, Taipei, Taiwan; [Chu, Che-Sheng] Kaohsiung Vet Gen Hosp, Ctr Geriatr & Gerontol, Kaohsiung, Taiwan; [Chu, Che-Sheng] Noninvas Neuromodulat Consortium Mental Disorders, Soc Psychophysiol, Taipei, Taiwan; [Chu, Che-Sheng] Kaohsiung Med Univ, Grad Inst Med, Coll Med, Kaohsiung, Taiwan; [Chu, Che-Sheng] Kaohsiung Vet Gen Hosp, Dept Psychiat, Kaohsiung, Taiwan; [Hsu, Chih-Wei] Kaohsiung Chang Gung Mem Hosp, Dept Psychiat, Kaohsiung, Taiwan; [Cheng, Szu-Wei] Chi Mei Med Ctr, Dept Gen Med, Tainan, Taiwan; [Cheng, Szu-Wei; Su, Kuan-Pin] China Med Univ Hosp, Mind Body Interface Lab MBI Lab, Taichung, Taiwan; [Cheng, Szu-Wei; Su, Kuan-Pin] China Med Univ Hosp, Dept Psychiat, Taichung, Taiwan; [Hsu, Tien-Wei] I Shou Univ, E DA Dachang Hosp, Dept Psychiat, Kaohsiung, Taiwan; [Hsu, Tien-Wei] I Shou Univ, E DA Hosp, Dept Orthoped, Kaohsiung, Taiwan; [Su, Kuan-Pin] China Med Univ, Coll Med, Taichung, Taiwan; [Su, Kuan-Pin] China Med Univ, An Nan Hosp, Tainan, Taiwan	National Defense Medical Center; Tri-Service General Hospital; Tri-Service General Hospital; Taipei Veterans General Hospital; National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung University; Kaohsiung Veterans General Hospital; Kaohsiung Medical University; Kaohsiung Veterans General Hospital; Chang Gung Memorial Hospital; Chi Mei Hospital; China Medical University Taiwan; China Medical University Hospital - Taiwan; China Medical University Taiwan; China Medical University Hospital - Taiwan; I Shou University; E-Da Hospital; I Shou University; E-Da Hospital; China Medical University Taiwan; China Medical University Taiwan	Liang, CS (corresponding author), Triserv Gen Hosp, Natl Def Med Ctr, Dept Psychiat, Taipei, Taiwan.; Liang, CS (corresponding author), Triserv Gen Hosp, Dept Psychiat, Beitou Branch, Taipei, Taiwan.; Hsu, TW (corresponding author), I Shou Univ, E DA Dachang Hosp, Dept Psychiat, Kaohsiung, Taiwan.; Hsu, TW (corresponding author), I Shou Univ, E DA Hosp, Dept Orthoped, Kaohsiung, Taiwan.	s9801101@gmail.com; lcsyfw@gmail.com		Bai, Ya Mei/0000-0003-3779-9074; Tsai, Shih-Jen/0000-0002-9987-022X; Liang, Chih-Sung/0000-0003-1138-5586; Cheng, Szu-Wei/0000-0002-4460-5517				Ahmed I., 2023, ChatGPT vs. Bard: A comparative study; American Psychiatric Association (APA), 2013, DIAGN STAT MAN MENT; Arora A, 2023, LANCET, V402, P180, DOI [10.1016/s0140-6736(23)01129-7, 10.1016/S0140-6736(23)01129-7]; Burns D., 2007, When panic attacks: The new, drug-free anxiety therapy that can change your life; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782; Gabbard GO, 2017, ACAD PSYCHIATR, V41, P30, DOI 10.1007/s40596-016-0627-7; Hitakshi T., 2023, Google Bard Training Data Parameters-Is it 1.56 trillion?; Holmes J, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1219326; Kao YS, 2024, ANN BIOMED ENG, V52, P455, DOI 10.1007/s10439-023-03308-9; Lin Y., Taiwan LLaMa; Liu Y., 2023, MetaRadiology, V1; Loge C., 2021, arXiv preprint arXiv:2108.01764, V2108, P01764; MetaAI, 2023, Introducing LLaMA: A foundational, 65 -billion -parameter language model; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Nosta J., 2023, The Left Brain, Right Brain Dynamics of LLMs; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Savery M, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00667-z; Shetty M., 2023, medRxiv, V2023, p13.23292418; Shevchuk V., 2023, GPT-4 Parameters Explained: Everything you Need to Know; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Towery J., 2016, The Anti-Depressant Book: A Practical Guide for Teens and Young Adults to Overcome Depression and Stay Healthy; Wang S., 2023, arXiv preprint arXiv:2302.07257, V2302, P07257; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946; Wu S., 2023, arXiv preprint arXiv:2308.04709, V2023, P04709	27	1	1	14	14	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1323-1316	1440-1819		PSYCHIAT CLIN NEUROS	Psychiatry Clin. Neurosci.	2024 FEB 26	2024										10.1111/pcn.13656	http://dx.doi.org/10.1111/pcn.13656		FEB 2024	6	Clinical Neurology; Neurosciences; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Psychiatry	KA2R5	38404249				2024-07-03	WOS:001177180500001
J	Kim, E; Jeong, Y; Choi, MS				Kim, Eunhui; Jeong, Yuna; Choi, Myung-Seok			MediBioDeBERTa: Biomedical Language Model With Continuous Learning and Intermediate Fine-Tuning	IEEE ACCESS			English	Article						Task analysis; Training; Biological system modeling; Transformers; Natural language processing; Correlation; Computational modeling; Language model; fine-tuning; domain-specific modeling; natural language processing		The emergence of large language models (LLMs) has marked a significant milestone in the evolution of natural language processing. With the expanded use of LLMs in multiple fields, the development of domain-specific pre-trained language models (PLMs) has become a natural progression and requirement. Developing domain-specific PLMs requires careful design, considering not only differences in training methods but also various factors such as the type of training data and hyperparameters. This paper proposes MediBioDeBERTa, a specialized language model (LM) for biomedical applications. First, we present several practical analyses and methods for improving the performance of LMs in specialized domains. As the initial step, we developed SciDeBERTa v2, an LM specialized in the scientific domain. In the SciERC dataset evaluation, SciDeBERTa v2 achieves the state-of-the-art model performance in the named entity recognition (NER) task. We then provide an in-depth analysis of the datasets and training methods used in the biomedical field. Based on these analyses, MediBioDeBERTa, was continually trained on SciDeBERTa v2 to specialize in the biomedical domain. Utilizing the biomedical language understanding and reasoning benchmark (BLURB), we analyzed factors that degrade task performance and proposed additional improvement methods based on intermediate fine-tuning. The results demonstrate improved performance in three categories: named entity recognition (NER), semantic similarity (SS), and question-answering (QnA), as well as in the ChemProt relation extraction (RE) task on BLURB, compared with existing state-of-the-art LMs.	[Kim, Eunhui; Jeong, Yuna; Choi, Myung-Seok] Korea Inst Sci & Technol Informat, Daejeon 34131, South Korea	Korea Institute of Science & Technology Information (KISTI)	Jeong, Y (corresponding author), Korea Inst Sci & Technol Informat, Daejeon 34131, South Korea.	jeongyuna@kisti.re.kr	Kim, Eunhui/AAJ-6355-2021	Kim, Eunhui/0000-0001-7775-3172; Choi, Myung-Seok/0000-0003-4821-3390	Korea Institute of Science and Technology Information (KISTI)	Korea Institute of Science and Technology Information (KISTI)(Korea Institute of Science & Technology Information (KISTI))	No Statement Available	Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Devlin M.-W., 2019, NAACL-HLT, P2; He J., 2023, INT C LEARN REPRESEN, P1; Jeong Y, 2022, IEEE ACCESS, V10, P60805, DOI 10.1109/ACCESS.2022.3180830; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lehman E., 2023, C HLTH INF LEARN, P578; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lo Kyle., 2020, P 58 ANN M ASS COMPU, P4969; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Luo L., 2022, Briefings Bioinf., V23; Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499; Singh A, 2023, Arxiv, DOI [arXiv:2211.13308, 10.48550/arXiv.2211.13308, DOI 10.48550/ARXIV.2211.13308]; Vaswani A, 2017, ADV NEUR IN, V30; Wang Alex, 2019, P INT C LEARN REPR I; Wang N., 2018, BioCreative/OHNLPChallenge, P575; Wang YS, 2020, JMIR MED INF, V8, DOI 10.2196/23375; Yasunaga J., 2022, ICML 2 SCI WORKSHOP, P1; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou HJ, 2024, Arxiv, DOI arXiv:2311.05112	24	0	0	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						141036	141044		10.1109/ACCESS.2023.3341612	http://dx.doi.org/10.1109/ACCESS.2023.3341612			9	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	DE1G2		gold			2024-07-03	WOS:001130256300001
C	Shukor, M; Dancette, C; Cord, M			IEEE	Shukor, Mustafa; Dancette, Corentin; Cord, Matthieu			eP-ALM: Efficient Perceptual Augmentation of Language Models	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2023)	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with little to no effort on direct finetuning. We investigate the minimal computational effort needed to adapt unimodal models for multimodal tasks and propose a new challenging setup, alongside different approaches, that efficiently adapts unimodal pretrained models. We show that by freezing more than 99% of total parameters, training only one linear projection layer, and prepending only one trainable token, our approach (dubbed eP-ALM) significantly outperforms other baselines on VQA and Captioning across Image, Video, and Audio modalities, following the proposed setup. The code is available here: https://github.com/mshukor/eP-ALM.	[Shukor, Mustafa; Dancette, Corentin; Cord, Matthieu] Sorbonne Univ, Paris, France; [Cord, Matthieu] Valeo Ai, Paris, France	Sorbonne Universite	Shukor, M (corresponding author), Sorbonne Univ, Paris, France.	mustafa.shukorv@sorbonne-universite.fr; corentin.dancette@sorbonne-universite.fr; matthieu.cord@sorbonne-universite.fr			ANR grant VISA DEEP [ANR-20-CHIA-0022]; GENCI [AD011013415, AD011013415R1]; Agence Nationale de la Recherche (ANR) [ANR-20-CHIA-0022] Funding Source: Agence Nationale de la Recherche (ANR)	ANR grant VISA DEEP(Agence Nationale de la Recherche (ANR)); GENCI; Agence Nationale de la Recherche (ANR)(Agence Nationale de la Recherche (ANR))	This work was partly supported by ANR grant VISA DEEP (ANR-20-CHIA-0022), and HPC resources of IDRIS under the allocation 2022-[AD011013415] and 2023-[AD011013415R1] made by GENCI. The authors would like to thank Theophane Vallaeys for fruitful discussion.	Agrawal Aishwarya, 2022, ARXIV220512191; [Anonymous], 2022, ARXIV PREPRINT ARXIV; Banki-Horvath A., 2018, arXiv preprint arXiv:1808.01340; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1; Bertasius G, 2021, PR MACH LEARN RES, V139; Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209; Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951; Carreira Joao, 2019, CoRR; Chen J, 2022, PROC CVPR IEEE, P18009, DOI 10.1109/CVPR52688.2022.01750; Chen Shizhe, 2022, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28-December 9, 2022; Chen Xinlei, 2015, MICROSOFT COCO CAPTI; Cheng Feng, 2022, ARXIV221205051; Cho Jaemin, 2021, P 38 INT C MACHINE L, P1931; Chowdhery A., 2022, ARXIV220402311; Dehghani Mostafa, 2023, ARXIV230205442; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; Du N, 2022, PR MACH LEARN RES; Eren AÖ, 2020, IEEE INT SYM MULTIM, P41, DOI 10.1109/ISM.2020.00014; Fan A., 2018, ACL; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Fedus W., 2022, Journal of Machine Learning Research, V23, P1; Fu Tsu-Jui, 2021, ARXIV211112681; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Grill JB., 2020, ADV NEURAL INFORM PR, V33, P21271; Hao Yaru, 2022, ARXIV220606336; Hoffmann Jordan, 2022, arXiv; Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039; Jia ML, 2022, LECT NOTES COMPUT SC, V13693, P709, DOI 10.1007/978-3-031-19827-4_41; Jiang H., 2020, P IEEE CVF C COMP VI, P10267, DOI [DOI 10.1109/CVPR42600.2020.01028, 10.1109/CVPR42600.2020.01028]; Ke L, 2019, IEEE I CONF COMP VIS, P8887, DOI 10.1109/ICCV.2019.00898; Kim C.D., 2019, NAACL HLT; Kim W, 2021, PR MACH LEARN RES, V139; Koizumi Yuma, 2020, ARXIV201207331; Le Scao Teven, 2022, ARXIV221105100; Lenc Karel, 2022, ARXIV220414198; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li JH, 2021, ADV NEUR IN, V34; Li M., 2022, CVPR, P16420; Liang S, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2976; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Haokun, 2022, ARXIV220505638; Lu JS, 2019, ADV NEUR IN, V32; Lu Jiasen, 2022, ARXIV220608916; Mahabadi RK, 2021, ADV NEUR IN, V34; Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565; MEI XINHAO, WORKSH DET CLASS AC; Men Rui, 2022, ARXIV220203052; Mialon Gregoire<prime>, 2023, ARXIV230207842; Moon JH, 2022, IEEE J BIOMED HEALTH, V26, P6070, DOI 10.1109/JBHI.2022.3207502; Nishi H, 2016, PROC IEEE COOL CHIPS; Pan Junting, 2022, ARXIV220613559; Patel Roma, 2022, INT C LEARN REPR; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Seo PH, 2022, PROC CVPR IEEE, P17938, DOI 10.1109/CVPR52688.2022.01743; Shimomoto Erica K, 2022, ARXIV220913359; Shukor Mustafa, 2022, 33 BRIT MACH VIS C B; Shukor Mustafa, 2022, ARXIV221204267; Singh Ishika, 2022, ARXIV220911302; Smith S., 2022, arXiv preprint arXiv:2201.11990; Srivastava Aarohi, 2022, ARXIV220604615; Sung Yi-Lin, ADV NEURAL INFORM PR; Tian Y., 2020, ADV NEURAL INFORM PR, V33, P6827, DOI DOI 10.5555/3495724.3496297; Tiong Anthony Meng Huat, 2022, ARXIV221008773; Touvron H, 2021, PR MACH LEARN RES, V139, P7358; Touvron Hugo, 2022, ECCV; Tsimpoukelli M, 2021, ADV NEUR IN, V34; Wang Wenhui, 2022, ARXIV220810442; Wei Jason, 2022, arXiv:2206.07682; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1645, DOI 10.1145/3123266.3123427; Yang Antoine, 2022, NEURIPS 2022 36 C NE; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Yu Jiahui, 2022, ARXIV220501917; Zellers R, 2022, PROC CVPR IEEE, P16354, DOI 10.1109/CVPR52688.2022.01589; Zhang S., 2022, arXiv; Zhou KY, 2022, PROC CVPR IEEE, P16795, DOI 10.1109/CVPR52688.2022.01631	79	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							21999	22012		10.1109/ICCV51070.2023.02016	http://dx.doi.org/10.1109/ICCV51070.2023.02016			14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5YO		Green Submitted			2024-07-03	WOS:001169500506058
J	Karaçay, L; Laaroussi, Z; Ujjwal, S; Soykan, EU				Karacay, Leyli; Laaroussi, Zakaria; Ujjwal, Sonika; Soykan, Elif Ustundag			Guarding 6G use cases: a deep dive into AI/ML threats in All-Senses meeting	ANNALS OF TELECOMMUNICATIONS			English	Article; Early Access						6G; AI/ML; Threat analysis; Security; Holographic communication		With the recent advances in 5G and 6G communications and the increasing need for immersive interactions due to pandemic, new use cases such as All-Senses meeting are emerging. To realize these use cases, numerous sensors, actuators, and virtual reality devices are used. Additionally, artificial intelligence (AI) and machine learning (ML) including generative AI can be used to analyze large amount of data generated by 6G networks and devices to enable new applications and services. While AI/ML technologies are evolving, they do not have the same level of security as well-known information technology components. So, AI/ML threats and their impacts can be overlooked. On the other hand, due to inherent characteristics of AI/ML components and design of AI/ML pipeline, AI/ML services can be a target for sophisticated attacks. In order to provide a holistic security view, the effect of AI/ML components should be investigated, threats should be identified, and countermeasures should be planned. Therefore, in this study, which is an extended version of our recent study (Karacay et al. 2023), we shed the light on the use of AI/ML services including generative large language model scenarios in All-Senses meeting use case and their security aspects by carrying out a threat modeling using the STRIDE framework and attack tree methodology. Additionally, we point out some countermeasures for identified threats.	[Karacay, Leyli] Ericsson, Res, Istanbul, Turkiye; [Laaroussi, Zakaria; Ujjwal, Sonika] Ericsson, Res, Helsinki, Finland; [Soykan, Elif Ustundag] Ericsson, Prod Secur, Stockholm, Sweden	Ericsson Turkey; Ericsson; Ericsson	Karaçay, L (corresponding author), Ericsson, Res, Istanbul, Turkiye.	leyli.karacay@ericsson.com; zakaria.laaroussi@ericsson.com; sonika.a.ujjwal@ericsson.com; elif.ustundag.soykan@ericsson.com			Hexa-X II	Hexa-X II	No Statement Available	Akyildiz IF, 2022, Holographic-type communication: a new challenge for the next decade; Barreno Marco, 2006, P 2006 ACM S INF COM, P16, DOI [DOI 10.1145/1128817.1128824, 10.1145/1128817.1128824]; Bibhudatta D, 2023, Generative AI will transform virtual meetings; Boyd C, 2022, Meta blows safety bubble around users after reports of sexual harassment; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Casella D, 2022, AI and privacy: everything you need to know about trust and technology; Challenges AC, 2020, report; Chen Ling, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1452, DOI 10.1109/SP40001.2021.00061; Clemm A, 2020, IEEE COMMUN MAG, V58, P93, DOI 10.1109/MCOM.001.1900272; Foundation TO, 2023, OWASP top 10 for large language model applications; Foundation TO, 2023, OWASP API Security Project; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Hasan R, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369505; Hong SHY, 2020, Arxiv, DOI arXiv:2002.11497; Industry Specification Group (ISG) Securing artificial intelligence (SAI), 2021, Securing Artificial Intelligence (SAI); Isobe T, 2021, IEEE ACCESS, V9, P90677, DOI 10.1109/ACCESS.2021.3091722; Karacay L, 2023, 2023 2 INT C 6G NETW, P1, DOI [10.1109/6GNet58894.2023.10317758, DOI 10.1109/6GNET58894.2023.10317758]; Khorsandi BM, 2022, report, European Union's Horizon 2020 research and innovation programme; Kononenko D, 2015, PROC CVPR IEEE, P4667, DOI 10.1109/CVPR.2015.7299098; Laaroussi Z, 2022, 2022 IEEE 19 ANN CON, P1, DOI [10.1109/CCNC49033.2022.9700673, DOI 10.1109/CCNC49033.2022.9700673]; Lawrence J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480490; Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020; Martinek R, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P382, DOI 10.1109/TSP.2015.7296288; Mauri L, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176662; Mauri L, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND RESILIENCE (IEEE CSR), P147, DOI 10.1109/CSR51186.2021.9527917; Microsoft, 2021, Microsoft AI Security Risk Assessment, Best Practices and Guidance to Secure AI Systems; mpai.community, MPAI Community; National Cyber Security Center, 2023, Using attack trees to understand cyber security risk; Nelson Blaine, 2008, USENIX WORKSHOP LARG, P1; NVIDIA, 2020, NVIDIA announces cloud-AI video-streaming platform to better connect millions working and studying remotely; Oprea Alina, 2023, Adversarial machine learning: a taxonomy and terminology of attacks and mitigations (draft), DOI [10.6028/NIST.AI.100-2e2023.ipd, DOI 10.6028/NIST.AI.100-2E2023.IPD]; Papernot N, 2018, AISEC'18: PROCEEDINGS OF THE 11TH ACM WORKSHOP ON ARTIFICIAL INTELLIGENCE AND SECURITY, P1, DOI 10.1145/3270101.3270102; Papernot N, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P399, DOI 10.1109/EuroSP.2018.00035; Patel K, 2020, IEEE ACCESS, V8, P90495, DOI 10.1109/ACCESS.2020.2993803; Qamar S, 2023, COMPUT SECUR, V128, DOI 10.1016/j.cose.2023.103127; Selin J, 2019, Evaluation of threat modeling methodologies; Shevchenko N., 2018, Threat modeling: a summary of available methods; Shi L, 2021, NATURE, V593, pE13, DOI 10.1038/s41586-021-03476-5; Soykan EU, 2022, IEEE ACCESS, V10, P97495, DOI 10.1109/ACCESS.2022.3204037; Tabassi E., 2019, NIST IR; You DH, 2019, IEEE ACCESS, V7, P65797, DOI 10.1109/ACCESS.2019.2917291	41	0	0	1	1	SPRINGER INT PUBL AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0003-4347	1958-9395		ANN TELECOMMUN	Ann. Telecommun.	2024 APR 5	2024										10.1007/s12243-024-01031-7	http://dx.doi.org/10.1007/s12243-024-01031-7		APR 2024	15	Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Telecommunications	MZ0X0					2024-07-03	WOS:001197350500001
J	Baygi, SF; Barupal, DK				Baygi, Sadjad Fakouri; Barupal, Dinesh Kumar			IDSL_MINT: a deep learning framework to predict molecular fingerprints from mass spectra	JOURNAL OF CHEMINFORMATICS			English	Article						Mass spectrometry; Metabolomics; Lipidomics; LipidMaps; Transformer; Molecular fingerprint descriptor; Deep learning; PyTorch	TOOLS	The majority of tandem mass spectrometry (MS/MS) spectra in untargeted metabolomics and exposomics studies lack any annotation. Our deep learning framework, Integrated Data Science Laboratory for Metabolomics and Exposomics-Mass INTerpreter (IDSL_MINT) can translate MS/MS spectra into molecular fingerprint descriptors. IDSL_MINT allows users to leverage the power of the transformer model for mass spectrometry data, similar to the large language models. Models are trained on user-provided reference MS/MS libraries via any customizable molecular fingerprint descriptors. IDSL_MINT was benchmarked using the LipidMaps database and improved the annotation rate of a test study for MS/MS spectra that were not originally annotated using existing mass spectral libraries. IDSL_MINT may improve the overall annotation rates in untargeted metabolomics and exposomics studies. The IDSL_MINT framework and tutorials are available in the GitHub repository at https://github.com/idslme/IDSL_MINT.Scientific contribution statement.Structural annotation of MS/MS spectra from untargeted metabolomics and exposomics datasets is a major bottleneck in gaining new biological insights. Machine learning models to convert spectra into molecular fingerprints can help in the annotation process. Here, we present IDSL_MINT, a new, easy-to-use and customizable deep-learning framework to train and utilize new models to predict molecular fingerprints from spectra for the compound annotation workflows.	[Baygi, Sadjad Fakouri; Barupal, Dinesh Kumar] Icahn Sch Med Mt Sinai, Dept Environm Med & Publ Hlth, 17 East 102nd St, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai	Barupal, DK (corresponding author), Icahn Sch Med Mt Sinai, Dept Environm Med & Publ Hlth, 17 East 102nd St, New York, NY 10029 USA.	dinesh.barupal@mssm.edu			National Center for Advancing Translational Sciences	National Center for Advancing Translational Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS))	No Statement Available	Barupal S.F.B.D.K., 2023, MINT publication; Baygi SF, 2023, ANAL CHEM, V95, P9480, DOI 10.1021/acs.analchem.3c00376; Baygi SF, 2022, ANAL CHEM, DOI 10.1021/acs.analchem.2c00563; Baygi SF, 2022, J PROTEOME RES, V21, P1485, DOI 10.1021/acs.jproteome.2c00120; Bickerton GR, 2012, NAT CHEM, V4, P90, DOI [10.1038/NCHEM.1243, 10.1038/nchem.1243]; Chen KX, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-023-00715-x; Colby SM, 2019, ANAL CHEM, V91, P4346, DOI 10.1021/acs.analchem.8b04567; de Jonge NF, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37446-4; Domingo-Almenara X, 2018, ANAL CHEM, V90, P480, DOI 10.1021/acs.analchem.7b03929; Dührkop K, 2015, P NATL ACAD SCI USA, V112, P12580, DOI 10.1073/pnas.1509788112; Duhrkop K, 2019, NAT METHODS, V16, P299, DOI 10.1038/s41592-019-0344-8; Elser D., 2023, bioRxiv; Ertl P, 2009, J CHEMINFORMATICS, V1, DOI 10.1186/1758-2946-1-8; Fahy E, 2007, NUCLEIC ACIDS RES, V35, pW606, DOI 10.1093/nar/gkm324; Heid E., 2023, CHEMPROP MACHINE LEA; Huber F, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00558-4; Huber F, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008724; Ji HC, 2020, ANAL CHEM, V92, P8649, DOI 10.1021/acs.analchem.0c01450; Kind T, 2014, ANAL CHEM, V86, P11024, DOI 10.1021/ac502511a; Li YY, 2021, NAT METHODS, V18, P1524, DOI 10.1038/s41592-021-01331-z; Liu CY, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-023-00698-9; Lo YC, 2018, DRUG DISCOV TODAY, V23, P1538, DOI 10.1016/j.drudis.2018.05.010; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Schrimpe-Rutledge AC, 2016, J AM SOC MASS SPECTR, V27, P1897, DOI 10.1007/s13361-016-1469-y; Schwaller P, 2021, NAT MACH INTELL, V3, P144, DOI 10.1038/s42256-020-00284-w; Semiatin SL, 2024, METALL MATER TRANS A, V55, P375, DOI 10.1007/s11661-023-07270-y; Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021; Stoyanova R, 2023, J CHEM INF MODEL, V63, P442, DOI 10.1021/acs.jcim.2c01134; Stravs MA, 2022, NAT METHODS, V19, P865, DOI 10.1038/s41592-022-01486-3; Sutton C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17112-9; Vaswani A, 2017, ADV NEUR IN, V30; Voronov G., 2022, bioRxiv, P2022, DOI 10.09.511482; Xie LX, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.606668; Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237; Yongye AB, 2011, J CHEM INF MODEL, V51, P1259, DOI 10.1021/ci200081k	35	1	1	24	24	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1758-2946			J CHEMINFORMATICS	J. Cheminformatics	JAN 18	2024	16	1							8	10.1186/s13321-024-00804-5	http://dx.doi.org/10.1186/s13321-024-00804-5			8	Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Computer Science	FF0V6	38238779	Green Published, gold			2024-07-03	WOS:001144240000001
C	Dettmers, T; Lewis, M; Belkada, Y; Zettlemoyer, L		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Dettmers, Tim; Lewis, Mike; Belkada, Younes; Zettlemoyer, Luke			LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					Large language models have been widely adopted but require significant GPU memory for inference. We develop a procedure for Int8 matrix multiplication for feed-forward and attention projection layers in transformers, which cut the memory needed for inference by half while retaining full precision performance. With our method, a 175B parameter 16/32-bit checkpoint can be loaded, converted to Int8, and used immediately without performance degradation. This is made possible by understanding and working around properties of highly systematic emergent features in transformer language models that dominate attention and transformer predictive performance. To cope with these features, we develop a two-part quantization procedure, LLM.int8(). We first use vector-wise quantization with separate normalization constants for each inner product in the matrix multiplication, to quantize most of the features. However, for the emergent outliers, we also include a new mixed-precision decomposition scheme, which isolates the outlier feature dimensions into a 16-bit matrix multiplication while still more than 99.9% of values are multiplied in 8-bit. Using LLM.int8(), we show empirically it is possible to perform inference in LLMs with up to 175B parameters without any performance degradation. This result makes such models much more accessible, for example making it possible to use OPT-175B/BLOOM on a single server with consumer GPUs. We open source our software.	[Dettmers, Tim; Zettlemoyer, Luke] Univ Washington, Seattle, WA 98195 USA; [Lewis, Mike; Zettlemoyer, Luke] Facebook AI Res, Menlo Pk, CA USA; [Belkada, Younes] Hugging Face, Manhattan, KS USA; [Belkada, Younes] ENS Paris Saclay, Paris, France	University of Washington; University of Washington Seattle; Facebook Inc; Universite Paris Saclay	Dettmers, T (corresponding author), Univ Washington, Seattle, WA 98195 USA.							[Anonymous], 2016, arXiv preprint arXiv:1602.02830; Artetxe M., 2021, ARXIV211210684; Bai H., 2021, ABS201215701 ARXIV; Bondarenko Y., 2021, ARXIV210912948; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cambier L., 2020, 8 INT C LEARN REPR I; Chen J., 2020, ADV NEURAL INFORM PR, V33, P883; Choi J., 2019, P MACH LEARN SYST 20; Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588; Courbariaux Matthieu, 2014, Training deep neural networks with low precision multiplications; Dettmers T., 2022, 9 INT C LEARN REPR I; Devlin J., 2018, BERT PRE TRAINING DE; Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038; Edunov S., 2019, ARXIV190401038; Esser Steven K, 2019, ARXIV190208153; Fan A., 2020, ARXIV200407320; Gao Jun, 2019, ARXIV190712009; Gao Leo, 2021, A framework for few-shot language model evaluation; Gholami A., 2022, Low-Power Computer Vision, P291; Gokaslan A., 2019, Openwebtext corpus; Gong RH, 2019, IEEE I CONF COMP VIS, P4851, DOI 10.1109/ICCV.2019.00495; Henighan T., 2020, ARXIV201014701; Hoffmann Jordan, 2022, arXiv; Ilharco G., 2020, P 2020 C EMP METH NA, P24; Jin Q., 2022, ARXIV220205239; Khudia Daya, 2021, ARXIV210105615; Kovaleva O., 2021, ARXIV210506990; Li RD, 2019, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR.2019.00292; Lin Y., 2020, ARXIV200908034; Liu Y., 2019, CoRR abs/1907.11692; Luo Z., 2021, P 59 ANN M ASS COMP, V1, P5312, DOI [10.18653/v1/2021.acl-long.413, DOI 10.18653/V1/2021.ACL-LONG.413]; Machacek M., 2014, P 9 WORKSH STAT MACH, P293, DOI 10.3115/v1/W14-3336; Mellempudi N., 2019, ABS190512334 CORR; Nagel S., 2016, CC NEWS; Ott Myle, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, P1; Park G., 2022, ARXIV220609557; Puccetti G., 2022, ARXIV220511380; Qin H., 2020, ABS200403333 CORR; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C., 2019, arXiv preprint arXiv:1910.10683; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Sennrich R., 2016, P 1 C MACH TRANSL AS, V2, P371, DOI DOI 10.18653/V1/W16-2323; Shazeer Noam, 2018, Advances in neural information processing systems, P10414; Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815; Sun X., 2019, Advances in Neural Information Processing Systems, V32; Timkey W., 2021, ARXIV210904404; Trinh Trieu H, 2018, A simple method for commonsense reasoning; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang N., 2018, P 32 INT C NEUR INF, P7686; Wei X., 2022, ARXIV220913325; Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu H., 2020, AXIV200409602; Yao Z., 2022, ARXIV220601861; YAO ZW, 2021, INT C MACH LEARN, V139; Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016; Zeng A., 2022, ARXIV221002414; Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23; Zhang S., 2022, arXiv; Zhang W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P509; Zhao C., 2021, ARXIV211214938; Zhu Chenzhuo, 2017, ICLR; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	63	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														15	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259103056
J	Krstic, D; Suljovic, S; Djordjevic, G; Petrovic, N; Milic, D				Krstic, Dragana; Suljovic, Suad; Djordjevic, Goran; Petrovic, Nenad; Milic, Dejan			MDE and LLM Synergy for Network Experimentation: Case Analysis of Wireless System Performance in Beaulieu-Xie Fading and κ-μ Co-Channel Interference Environment with Diversity Combining	SENSORS			English	Article						Beaulieu-Xie fading; kappa-mu co-channel interference; first-order performance; second-order performance; selection combining; large language model; model-driven engineering	LEVEL-CROSSING RATE; CHANNELS	Channel modeling is a first step towards the successful projecting of any wireless communication system. Hence, in this paper, we analyze the performance at the output of a multi-branch selection combining (SC) diversity receiver in a wireless environment that has been distracted by fading and co-channel interference (CCI), whereby the fading is modelled by newer Beaulieu-Xie (BX) distribution, and the CCI is modelled by the kappa-mu distribution. The BX distribution provides the ability to include in consideration any number of line-of-sight (LOS) useful signal components and non-LOS (NLOS) useful signal components. This distribution contains characteristics of some other fading models thanks to its flexible fading parameters, which also applies to the kappa-mu distribution. We derived here the expressions for the probability density function (PDF) and cumulative distribution function (CDF) for the output signal-to-co-channel interference ratio (SIR). After that, other performances are obtained, namely: outage probability (Pout), channel capacity (CC), moment-generating function (MGF), average bit error probability (ABEP), level crossing rate (LCR), and average fade duration (AFD). Numerical results are presented in several graphs versus the SIR for different values of fading and CCI parameters, as well as the number of input branches in the SC receiver. Then, the impact of parameters on all performance is checked. From our numerical results, it is possible to directly obtain the performance for all derived and displayed quantities for cases of previously known distributions of fading and CCI by inserting the appropriate parameter values. In the second part of the paper, a workflow for automated network experimentation relying on the synergy of Large Language Models (LLMs) and model-driven engineering (MDE) is presented, while the previously derived expressions are used for evaluation. Due to the aforementioned, the biggest value of the obtained results is the applicability to the cases of a large number of other distributions for fading and CCI by replacing the corresponding parameters in the formulas for the respective performances.	[Krstic, Dragana; Petrovic, Nenad; Milic, Dejan] Univ Nis, Fac Elect Engn, Nish 18000, Serbia; [Suljovic, Suad; Djordjevic, Goran] Acad Tech Profess Studies, Belgrade 11120, Serbia	University of Nis	Krstic, D (corresponding author), Univ Nis, Fac Elect Engn, Nish 18000, Serbia.	dragana.krstic@elfak.ni.ac.rs; ssuljovic@atssb.edu.rs; gdjordjevic@atssb.edu.rs; nenad.petrovic@elfak.ni.ac.rs; dejan.milic@elfak.ni.ac.rs	Krstic, Dragana/AFT-5078-2022	Krstic, Dragana/0000-0002-2579-3911				Abramowitz M., 1972, HDB MATH FUNCTIONS F; Alouini MS, 1999, IEEE T VEH TECHNOL, V48, P1165, DOI 10.1109/25.775366; Beals R, 2013, Notices Amer. Math. Soc., V60, P866; Beaulieu NC, 2015, IEEE WIREL COMMUN LE, V4, P54, DOI 10.1109/LWC.2014.2367501; Gradshteyn I.S., 2014, Tables of Integrals, Series, and Products; Huang H, 2020, IEICE T COMMUN, VE103B, P458, DOI 10.1587/transcom.2019EBP3132; Kansal Veenu, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P344, DOI 10.1109/ICSC48311.2020.9182720; Kansal Veenu, 2019, Data and Communication Networks. Proceedings of GUCON 2018. Advances in Intelligent Systems and Computing (AISC 847), P13, DOI 10.1007/978-981-13-2254-9_2; Kansal V, 2021, TELECOMMUN SYST, V78, P163, DOI 10.1007/s11235-021-00775-0; Kansal V, 2021, ANN TELECOMMUN, V76, P43, DOI 10.1007/s12243-020-00762-7; Kansal V, 2018, 2018 6TH EDITION OF INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS & EMBEDDED SYSTEMS (WECON), P11, DOI 10.1109/WECON.2018.8782053; Kansal V, 2017, 2017 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2017), P207, DOI 10.1109/WIECON-ECE.2017.8468917; Kaur M, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3949; Krsti D., 2023, P 16 BAK GNSS C TECH, P53; Krstic D., 2023, P IEEE 21 INT S INT; Krstic D, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12194088; Krstic D, 2023, Inter Confer Telecom, DOI 10.1109/ConTEL58387.2023.10199003; Krstic D, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/4140522; Mitrovic Z.J., 2009, Electronics, V13, P58; Olutayo A., 2021, Doctoral Dissertation; Olutayo A, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01705-5; Olutayo A, 2017, 2017 15TH CANADIAN WORKSHOP ON INFORMATION THEORY (CWIT); Olutayo A, 2017, IEEE WIREL COMMUN LE, V6, P326, DOI 10.1109/LWC.2017.2685506; Olutayo A, 2017, IEEE ICC; Panic S., 2014, Fading and Interference Mitigation in Wireless Communications; Pätzold M, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292439; Petrovic Nenad, 2023, Advances in Systems Engineering: Proceedings of the 30th International Conference on Systems Engineering, ICSEng 2023. Lecture Notes in Networks and Systems (761), P387, DOI 10.1007/978-3-031-40579-2_37; Sagias NC, 2005, IEEE T INFORM THEORY, V51, P3608, DOI 10.1109/TIT.2005.855598; Shankar H, 2022, WIRELESS PERS COMMUN, V126, P531, DOI 10.1007/s11277-022-09757-0; Simon M. K., 2004, Digital communication over fading channels; Stefanovic C, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P569, DOI 10.1109/ICSCCC.2018.8703293; Stuber G.L., 2000, PRINCIPLES MOBILE CO; Suljovi S., 2023, P 22 INT S INFOTEH J; Suljovic S, 2023, ELEKTRON ELEKTROTECH, V29, P68, DOI 10.5755/j02.eie.34018; Suljovic S, 2021, ELMAR PROC, P11, DOI 10.1109/ELMAR52657.2021.9550962; Suljovic S, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102758; Yacoub MD, 2001, IEEE VTS VEH TECHNOL, P1427, DOI 10.1109/VTC.2001.956432; US	38	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	MAY	2024	24	10							3037	10.3390/s24103037	http://dx.doi.org/10.3390/s24103037			30	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	RY6H6		gold			2024-07-03	WOS:001231252900001
J	Achille, A; Kearns, M; Klingenberg, C; Soatto, S				Achille, Alessandro; Kearns, Michael; Klingenberg, Carson; Soatto, Stefano			AI model disgorgement: Methods and choices	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						machine learning; artificial intelligence; model disgorgement; machine unlearning; generative AI		Over the past few years, machine learning models have significantly increased in size and complexity, especially in the area of generative AI such as large language models. These models require massive amounts of data and compute capacity to train, to the extent that concerns over the training data (such as protected or private content) cannot be practically addressed by retraining the model "from scratch" with the questionable data removed or altered. Furthermore, despite significant efforts and controls dedicated to ensuring that training corpora are properly curated and composed, the sheer volume required makes it infeasible to manually inspect each datum comprising a training corpus. One potential approach to training corpus data defects is model disgorgement, by which we broadly mean the elimination or reduction of not only any improperly used data, but also the effects of improperly used data on any component of an ML model. Model disgorgement techniques can be used to address a wide range of issues, such as reducing bias or toxicity, increasing fidelity, and ensuring responsible use of intellectual property. In this paper, we survey the landscape of model disgorgement methods and introduce a taxonomy of disgorgement techniques that are applicable to modern ML systems. In particular, we investigate the various meanings of "removing the effects" of data on the trained model in a way that does not require retraining from scratch.	[Achille, Alessandro; Kearns, Michael; Klingenberg, Carson; Soatto, Stefano] Amazon Web Serv Artificial Intelligence AWS AI, Pasadena, CA 91125 USA; [Kearns, Michael] Univ Penn, Comp & Informat Sci, Philadelphia, PA 19130 USA; [Soatto, Stefano] Univ Calif Los Angeles, Comp Sci, Los Angeles, CA 90095 USA	University of Pennsylvania; University of California System; University of California Los Angeles	Kearns, M (corresponding author), Amazon Web Serv Artificial Intelligence AWS AI, Pasadena, CA 91125 USA.; Kearns, M (corresponding author), Univ Penn, Comp & Informat Sci, Philadelphia, PA 19130 USA.	mkearns@cis.upenn.edu		Klingenberg, Carson/0009-0001-5386-0958				Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Bansal G, 2019, AAAI CONF ARTIF INTE, P2429; Basu S, 2021, Arxiv, DOI [arXiv:2006.14651, DOI 10.48550/ARXIV.2006.14651, 10.48550/arxiv.2006.14651]; Bourtoule Lucas, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P141, DOI 10.1109/SP40001.2021.00019; Brown G, 2021, ACM S THEORY COMPUT, P123, DOI 10.1145/3406325.3451131; Bu ZQ, 2023, Arxiv, DOI arXiv:2210.00038; Cao YZ, 2015, P IEEE S SECUR PRIV, P463, DOI 10.1109/SP.2015.35; Dong JS, 2022, J ROY STAT SOC B, V84, P3, DOI 10.1111/rssb.12454; Dukler Y, 2023, Arxiv, DOI arXiv:2304.13169; Dukler Y, 2023, Arxiv, DOI arXiv:2303.04105; Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042; Feldman V, 2020, ACM S THEORY COMPUT, P954, DOI 10.1145/3357713.3384290; Ginart AA, 2019, ADV NEUR IN, V32; Goland J. A., 2023, Richm. J. Law Technol., VXXIX; Golatkar Aditya, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9301, DOI 10.1109/CVPR42600.2020.00932; Golatkar A., 2020, COMPUTER VISION ECCV, P383; Golatkar A, 2022, PROC CVPR IEEE, P8366, DOI 10.1109/CVPR52688.2022.00819; Golatkar A, 2021, PROC CVPR IEEE, P792, DOI 10.1109/CVPR46437.2021.00085; Guo C, 2023, Arxiv, DOI arXiv:1911.03030; Gupta, 2021, ADV NEURAL INF PROCE, V34, P16319, DOI DOI 10.48550/ARXIV.2106.04378; Harutyunyan H, 2021, Arxiv, DOI arXiv:2101.06640; Jang J., 2022, arXiv; Koch K, 2023, 2023 IEEE CONFERENCE ON SECURE AND TRUSTWORTHY MACHINE LEARNING, SATML, P622, DOI 10.1109/SaTML54575.2023.00047; Koh PW, 2017, PR MACH LEARN RES, V70; Kumar V. B., 2022, PREPRINT; Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17; Neel S., 2021, ALGORITHMIC LEARNING, P931; Nilsback ME, 2006, IEEE C COMP VIS PATT, Vvol2, P1447, DOI [10.1109/CVPR.2006.42, DOI 10.1109/CVPR.2006.42]; Pawelczyk M, 2024, Arxiv, DOI [arXiv:2310.07579, 10.48550/arXiv.2310.07579]; Radford A, 2021, PR MACH LEARN RES, V139; Rensink Ronald A., 2001, P169; Shaik T, 2024, Arxiv, DOI arXiv:2305.06360; Shan SW, 2023, Arxiv, DOI [arXiv:2302.04222, DOI 10.48550/ARXIV.2302.04222]; Shen YT, 2020, PROC CVPR IEEE, P6367, DOI 10.1109/CVPR42600.2020.00640; Srivastava M, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3272, DOI 10.1145/3394486.3403379; Vyas N., 2023, P INT C MACH LEARN; Vyas N, 2023, Arxiv, DOI arXiv:2302.10870; W. article, 2024, Disgorgement; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu Y., 2020, INT C MACHINE LEARNI, P10355; Wu Y., 2020, 2020 IEEE INT C MULT, P1; Xie Q, 2019, ARXIV190412848; Yan H., 2022, P 31 INT JOINT C ART, P4006; Yan SJ, 2021, PROC CVPR IEEE, P14294, DOI 10.1109/CVPR46437.2021.01407; Yoon D, 2023, Arxiv, DOI arXiv:2306.07052; Zeng Y., 2023, 11 INT C LEARN REPR; Zhao WS, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P737, DOI [10.1109/SSCI47803.2020.9308468, 10.1109/ssci47803.2020.9308468]; Zhu XF, 2021, NEUROCOMPUTING, V464, P141, DOI 10.1016/j.neucom.2021.08.089	48	0	0	0	0	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	APR 30	2024	121	18							e2307304121	10.1073/pnas.2307304121	http://dx.doi.org/10.1073/pnas.2307304121			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	RN2B5	38640257	hybrid, Green Submitted			2024-07-03	WOS:001228264400004
J	Liu, C; Sun, KJ; Zhou, QQ; Duan, YC; Shu, JH; Kan, HX; Gu, ZY; Hu, JL				Liu, Can; Sun, Kaijie; Zhou, Qingqing; Duan, Yuchen; Shu, Jianhua; Kan, Hongxing; Gu, Zongyun; Hu, Jili			CPMI-ChatGLM: parameter-efficient fine-tuning ChatGLM with Chinese patent medicine instructions	SCIENTIFIC REPORTS			English	Article								Chinese patent medicine (CPM) is a typical type of traditional Chinese medicine (TCM) preparation that uses Chinese herbs as raw materials and is an important means of treating diseases in TCM. Chinese patent medicine instructions (CPMI) serve as a guide for patients to use drugs safely and effectively. In this study, we apply a pre-trained language model to the domain of CPM. We have meticulously assembled, processed, and released the first CPMI dataset and fine-tuned the ChatGLM-6B base model, resulting in the development of CPMI-ChatGLM. We employed consumer-grade graphics cards for parameter-efficient fine-tuning and investigated the impact of LoRA and P-Tuning v2, as well as different data scales and instruction data settings on model performance. We evaluated CPMI-ChatGLM using BLEU, ROUGE, and BARTScore metrics. Our model achieved scores of 0.7641, 0.8188, 0.7738, 0.8107, and - 2.4786 on the BLEU-4, ROUGE-1, ROUGE-2, ROUGE-L and BARTScore metrics, respectively. In comparison experiments and human evaluation with four large language models of similar parameter scales, CPMI-ChatGLM demonstrated state-of-the-art performance. CPMI-ChatGLM demonstrates commendable proficiency in CPM recommendations, making it a promising tool for auxiliary diagnosis and treatment. Furthermore, the various attributes in the CPMI dataset can be used for data mining and analysis, providing practical application value and research significance.	[Liu, Can; Sun, Kaijie; Zhou, Qingqing; Duan, Yuchen; Shu, Jianhua; Kan, Hongxing; Gu, Zongyun; Hu, Jili] Anhui Univ Chinese Med, Sch Med Informat Engn, Hefei 230012, Peoples R China; [Liu, Can; Kan, Hongxing; Hu, Jili] China Acad Chinese Med Sci, Anhui Comp Applicat Res Inst Chinese Med, Hefei 230012, Peoples R China	Anhui University of Chinese Medicine; China Academy of Chinese Medical Sciences	Hu, JL (corresponding author), Anhui Univ Chinese Med, Sch Med Informat Engn, Hefei 230012, Peoples R China.; Hu, JL (corresponding author), China Acad Chinese Med Sci, Anhui Comp Applicat Res Inst Chinese Med, Hefei 230012, Peoples R China.	hujili@ahtcm.edu.cn			Anhui Province University Collaborative Innovation Project [GXXT2023-071]; Central Financial Special Fund for the Inheritance and Development of Traditional Chinese Medicine [RZ2200001383]; College Students' Innovative Entrepreneurial Training Plan Program [S202310369096]; Industry-University Cooperation Collaborative Education Project of the Ministry of Education of the People's Republic of China [202101123001]	Anhui Province University Collaborative Innovation Project; Central Financial Special Fund for the Inheritance and Development of Traditional Chinese Medicine; College Students' Innovative Entrepreneurial Training Plan Program; Industry-University Cooperation Collaborative Education Project of the Ministry of Education of the People's Republic of China	This work was supported by the Anhui Province University Collaborative Innovation Project [Grant no. GXXT2023-071], the Central Financial Special Fund for the Inheritance and Development of Traditional Chinese Medicine [Grant No. RZ2200001383], the College Students' Innovative Entrepreneurial Training Plan Program [Grant No. S202310369096] and the Industry-University Cooperation Collaborative Education Project of the Ministry of Education of the People's Republic of China [Grant No. 202101123001].	Ahmad PN, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11091268; Bai J., 2023, arXiv; Bellan P, 2022, LECT NOTES COMPUT SC, V13585, P182, DOI 10.1007/978-3-031-17604-3_11; Bird S., 2006, PAPER PRESENTED COLI, P69, DOI [10.48550/arXiv.cs/0205028, DOI 10.3115/1225403.1225421, 10.3115/1225403.1225421]; Bommasani R, 2023, ANN NY ACAD SCI, V1525, P140, DOI 10.1111/nyas.15007; Chen He, 2023, Natural Language Processing and Chinese Computing: 12th National CCF Conference, NLPCC 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14304), P29, DOI 10.1007/978-3-031-44699-3_3; Chen T, 2019, DATABASE-OXFORD, DOI 10.1093/database/baz116; Cui, 2023, ARXIV; Cyranoski D, 2018, NATURE, V561, P448, DOI 10.1038/d41586-018-06782-7; Diao SZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3336; Ding N, 2023, NAT MACH INTELL, V5, P220, DOI 10.1038/s42256-023-00626-4; Du HZ, 2020, CHIN J NAT MEDICINES, V18, P206, DOI [10.3724/SP.J.1009.2019.000000, 10.1016/S1875-5364(20)30022-4]; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Edwards A., 2020, P 28 INT C COMPUTATI, P5522, DOI DOI 10.18653/V1/2020; Gao WQ, 2023, MULTIMED TOOLS APPL, V82, P26987, DOI 10.1007/s11042-023-14701-w; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang YZ, 2023, Arxiv, DOI [arXiv:2305.08322, DOI 10.48550/ARXIV.2305.08322, 10.48550/arXiv.2305.08322]; Lee DYW, 2021, PHYTOMEDICINE, V80, DOI 10.1016/j.phymed.2020.153337; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu M, 2021, INTEGR MED RES, V10, DOI 10.1016/j.imr.2020.100644; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu WG, 2022, LECT NOTES ARTIF INT, V13551, P447, DOI 10.1007/978-3-031-17120-8_35; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Loshchilov I., 2017, ARXIV; Luo H, 2020, CHIN MED-UK, V15, DOI 10.1186/s13020-020-00375-1; Ni P, 2024, INFORM SYST FRONT, V26, P137, DOI 10.1007/s10796-022-10295-0; Niu Y., 2020, Thirty Great Inventions of China: From Millet Agriculture to Artemisinin, P387, DOI [10.1007/978-981-15-6525-0_14, DOI 10.1007/978-981-15-6525-0_14]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Sezgin E, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231186520; Sun Q, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.685002; Tianchi, 2020, Entity Recognition of Traditional Chinese Medicine's Manual; Urbizu G., 2023, FINDINGS ASS COMPUTA, P3826; Wang HC, 2023, Arxiv, DOI [arXiv:2304.06975, DOI 10.48550/ARXIV.2304.06975]; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Xu C., 2021, 2021 11 INT C INFORM, P282, DOI [10.1109/ITME53901.2021.00065, DOI 10.1109/ITME53901.2021.00065]; Xu CW, 2023, Arxiv, DOI [arXiv:2304.01196, DOI 10.48550/ARXIV.2304.01196]; Xuefeng P., 2022, 2022 12 INT C INFORM, P575, DOI [10.1109/ITME56794.2022.00125, DOI 10.1109/ITME56794.2022.00125]; Yang AY, 2023, Arxiv, DOI [arXiv:2309.10305, DOI 10.48550/ARXIV.2309.10305]; Yang X., 2023, Chin. Med. Cult, DOI [10.1097/MC9.0000000000000066, DOI 10.1097/MC9.0000000000000066]; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan WZ, 2021, Arxiv, DOI arXiv:2106.11520; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zeng H, 2021, EVID-BASED COMPL ALT, V2021, DOI 10.1155/2021/7402979; Zhang T., 2022, Evid.-Based Complement. Altern. Med, V2022; Zhong X., 2021, J. Data Anal. Inf. Process, V9, P123, DOI DOI 10.4236/JDAIP.2021.93008; Zhu LG, 2020, J ETHNOPHARMACOL, V263, DOI 10.1016/j.jep.2020.113117; Zou Y., 2023, 2023 IEEE INT C BIOI, P4776, DOI [10.1109/BIBM58861.2023.10386068, DOI 10.1109/BIBM58861.2023.10386068]	54	1	1	38	38	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAR 16	2024	14	1							6403	10.1038/s41598-024-56874-w	http://dx.doi.org/10.1038/s41598-024-56874-w			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	LK5F6	38493251	gold			2024-07-03	WOS:001186700500007
J	Meyer, A; Riese, J; Streichert, T				Meyer, Annika; Riese, Janik; Streichert, Thomas			Comparison of the Performance of GPT-3.5 and GPT-4 With That of Medical Students on the Written German Medical Licensing Examination: Observational Study	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; artificial intelligence; large language model; medical exams; medical examinations; medical education; LLM; public trust; trust; medical accuracy; licensing exam; licensing examination; improvement; patient care; general population; licensure examination		Background: The potential of artificial intelligence (AI)-based large language models, such as ChatGPT, has gained significant attention in the medical field. This enthusiasm is driven not only by recent breakthroughs and improved accessibility, but also by the prospect of democratizing medical knowledge and promoting equitable health care. However, the performance of ChatGPT is substantially influenced by the input language, and given the growing public trust in this AI tool compared to that in traditional sources of information, investigating its medical accuracy across different languages is of particular importance. Objective: This study aimed to compare the performance of GPT-3.5 and GPT-4 with that of medical students on the written German medical licensing examination. Methods: To assess GPT-3.5's and GPT-4's medical proficiency, we used 937 original multiple-choice questions from 3 written German medical licensing examinations in October 2021, April 2022, and October 2022. Results: GPT-4 achieved an average score of 85% and ranked in the 92.8th, 99.5th, and 92.6th percentiles among medical students who took the same examinations in October 2021, April 2022, and October 2022, respectively. This represents a substantial improvement of 27% compared to GPT-3.5, which only passed 1 out of the 3 examinations. While GPT-3.5 performed well in psychiatry questions, GPT-4 exhibited strengths in internal medicine and surgery but showed weakness in academic research. Conclusions: The study results highlight ChatGPT's remarkable improvement from moderate (GPT-3.5) to high competency (GPT-4) in answering medical licensing examination questions in German. While GPT-4's predecessor (GPT-3.5) was imprecise and inconsistent, it demonstrates considerable potential to improve medical education and patient care, provided that medically trained users critically evaluate its results. As the replacement of search engines by AI tools seems possible in the future, further studies with nonprofessional questions are needed to assess the safety and accuracy of ChatGPT for the general population.	[Meyer, Annika; Streichert, Thomas] Univ Hosp Cologne, Inst Clin Chem, Cologne, Germany; [Riese, Janik] Univ Hosp Greifswald, Dept Gen Surg Visceral Thorac & Vasc Surg, Greifswald, Germany; [Meyer, Annika] Univ Hosp Cologne, Inst Clin Chem, Kerpener Str 62, D-50937 Cologne, Germany	University of Cologne; University of Cologne	Meyer, A (corresponding author), Univ Hosp Cologne, Inst Clin Chem, Kerpener Str 62, D-50937 Cologne, Germany.	annika.meyer1@uk-koeln.de		Riese, Janik/0000-0003-0701-060X; Meyer, Annika/0000-0002-8411-8799				Abhinav V, 2023, Mosaic ML; Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; [Anonymous], Examen (M2/M3) No.1 in der Examensvorbereitung; [Anonymous], 2008, R: A Language Environment for Statistical Computing; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Budler LC, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1487; Chan CH, rio: A Swiss-Army Knife for Data I/O; Dietrich J, citation: Software Citation Tools; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Le DV, 2018, J BIOMED INFORM, V86, P49, DOI 10.1016/j.jbi.2018.08.007; Epstein RH, 2023, JMIR MED EDUC, V9, DOI 10.2196/48305; FAQ, Haufig gefrage Fragen; Ferrari AJ, 2022, LANCET PSYCHIAT, V9, P137, DOI 10.1016/S2215-0366(21)00395-3; Fruhjahr, 2022, Ergebnisinformartion; Gabriel N, 2023, Lost in Translation: Large Language Models in Non-English Content Analysis; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Grabeel KL, 2018, J MED LIBR ASSOC, V106, P38, DOI 10.5195/jmla.2018.262; Herbst, 2022, Ergebnisinformartion; Herbst, 2021, Ergebnisinformartion; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Institut fur medizinische und pharmazeutische Prufungsfragen, Zusammenstellung der Prufungsinhalte fur den Zweiten Abschnitt der Arztlichen Prufung ("Blueprint") nach derzeit gultiger AApprO 2002; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jünger J, 2018, BUNDESGESUNDHEITSBLA, V61, P171, DOI 10.1007/s00103-017-2668-9; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; Kassambara A., ggpubr: 'ggplot2' Based Publication Ready Plots R package version 0.6.0; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kurz C, 2023, DEUT ARZTEBLATT, V120, P04; Larmarange J., labelled: Manipulating Labelled Data. labelled; Lau T., KI-Chatbot konnte Therapiegesprache empathischer machen; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Ludecke Daniel, 2023, CRAN; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; Muller K., A Simpler Way to Find Your Files; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; OpenAI, GPT-4 Technical Report; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Perlis RH, 2012, PSYCHOL MED, V42, P41, DOI 10.1017/S0033291711000997; Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77; Robinson D., 2023, Broom: Convert Statistical Objects into Tidy Tibbles. R package version 1.0.4 ed; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Seth P, 2023, JMIR MED EDUC, V9, DOI 10.2196/46344; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sjoberg DD, 2021, R J, V13, P570; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Wickham H., 2016, ggplot2: Elegant graphics for data analysis, DOI 10.1007/978-3-319-24277-4; Wickham H., 2019, JOSS, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]; Wickham H., 2020, GGPLOT2 CREATE ELEGA; Wickham H., Easily Install and Load the Tidyverse; Wilke C.O., 2020, STREAMLINED PLOT THE, DOI DOI 10.1038/S41598-021-83135-X	57	7	7	15	15	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e50965	10.2196/50965	http://dx.doi.org/10.2196/50965			12	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IE1L4	38329802	gold, Green Published			2024-07-03	WOS:001164556600001
J	García-Penalvo, FJ; Vázquez-Ingelmo, A				Garcia-Penalvo, Francisco Jose; Vazquez-Ingelmo, Andrea			What Do We Mean by GenAI? A Systematic Mapping of The Evolution, Trends, and Techniques Involved in Generative AI	INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE			English	Article						Artificial Intelligence; Content Generation; Generative AI; Generative Models; Machine Learning; Systematic Literature Mapping		Artificial Intelligence has become a focal point of interest across various sectors due to its ability to generate creative and realistic outputs. A specific subset, generative artificial intelligence, has seen significant growth, particularly in late 2022. Tools like ChatGPT, Dall-E, or Midjourney have democratized access to Large Language Models, enabling the creation of human-like content. However, the concept 'Generative Artificial Intelligence' lacks a universally accepted definition, leading to potential misunderstandings. While a model that produces any output can be technically seen as generative, the Artificial Intelligent research community often reserves the term for complex models that generate high-quality, human-like material. This paper presents a literature mapping of AI-driven content generation, analyzing 631 solutions published over the last five years to better understand and characterize the Generative Artificial Intelligence landscape. Our findings suggest a dichotomy in the understanding and application of the term "Generative AI". While the broader public often interprets "Generative AI" as AI-driven creation of tangible content, the AI research community mainly discusses generative implementations with an emphasis on the models in use, without explicitly categorizing their work under the term "Generative AI".	[Garcia-Penalvo, Francisco Jose; Vazquez-Ingelmo, Andrea] Univ Salamanca, Comp Sci Dept, GRIAL Res Grp, Salamanca, Spain	University of Salamanca	Vázquez-Ingelmo, A (corresponding author), Univ Salamanca, Comp Sci Dept, GRIAL Res Grp, Salamanca, Spain.	fgarcia@usal.es; andreavazquez@usal.es	GARCÍA-PEÑALVO, Francisco José/D-5445-2013	GARCÍA-PEÑALVO, Francisco José/0000-0001-9987-5584	Ministry of Science and Innovation [PID2020-118345RB-I00]	Ministry of Science and Innovation(Spanish Government)	This research was partially funded by the Ministry of Science and Innovation through the AvisSA project grant number (PID2020-118345RB-I00).	Arcas BAY, 2017, ARTS, V6, DOI 10.3390/arts6040018; Alvarez P, 2023, INT J INTERACT MULTI, V8, P168, DOI 10.9781/ijimai.2022.04.002; Bozkurt A., 2023, Asian Journal of Distance Education; Chatterjee A, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1024449; Civit M, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118190; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Foster D., 2023, Generative deep learning, V2nd ed.; Foster D., 2019, Write, Compose, and Play (Japanese Version), P139; Garcia-Penalvo F., 2023, International Journal of Interactive Multimedia and Artificial Intelligence; García-Peñalvo FJ, 2024, RIED-REV IBEROAM EDU, V27, DOI 10.5944/ried.27.1.37716; García-Peñalvo FJ, 2023, EDUC KNOWL SOC, V24, DOI 10.14201/eks.31279; García-Peñalvo FJ, 2022, EDUC KNOWL SOC, V23, DOI 10.14201/eks.28600; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gruetzemacher R, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505245; Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285; Hazzan Orit, 2023, ChatGPT in Computer Science Education; Khosravi H., 2022, Comput. Educ. Artif. Intell., V3, DOI [DOI 10.1016/J.CAEAI.2022.100074, 10.1016/j.caeai, DOI 10.1016/J.CAEAI]; Kitchenham B, 2007, Technical Report EBSE-2007-01; Kulkarni RH, 2017, IET SOFTW, V11, P18, DOI 10.1049/iet-sen.2016.0095; Lies J, 2022, INT J INTERACT MULTI, V7, P115, DOI 10.9781/ijimai.2022.10.001; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Mashkoor A, 2022, COMPUTER, V55, P24, DOI 10.1109/MC.2022.3144805; Meyer B., 2022, What Do ChatGPT and AI-based Automatic Program Generation Mean for the Future of Software; Mikalef P, 2023, J BUS RES, V164, DOI 10.1016/j.jbusres.2023.113998; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Petersen K., 2008, 12 INT C EVALUATION, P68, DOI 10.14236/ewic/ease2008.8; Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007; Tredinnick L., 2023, The dangers of generative artificial intelligence; van der Zant T., 2013, Philosophy and Theory of Artificial Intelligence, V5, P107, DOI [10.1007/978-3-642-31674-6, DOI 10.1007/978-3-642-31674-68]; Vaswani A, 2017, ADV NEUR IN, V30; Vazquez-Ingelmo A, 2023, Zenodo, DOI 10.5281/ZENODO.8162484; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Zhang C, 2023, INT J INTERACT MULTI, V8, P69, DOI 10.9781/ijimai.2023.01.009; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou JM, 2023, INT J INTERACT MULTI, V8, P7, DOI 10.9781/ijimai.2023.04.007	36	12	13	95	95	UNIV INT RIOJA-UNIR	LOGRONO	RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN	1989-1660			INT J INTERACT MULTI	Int. J. Interact. Multimed. Artif. Intell.	DEC	2023	8	4								10.9781/ijimai.2023.07.006	http://dx.doi.org/10.9781/ijimai.2023.07.006			217	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DE9W2		Green Submitted, Green Published, gold			2024-07-03	WOS:001130481400013
J	Foroumandi, E; Moradkhani, H; Sanchez-Vila, X; Singha, K; Castelletti, A; Destouni, G				Foroumandi, Ehsan; Moradkhani, Hamid; Sanchez-Vila, Xavier; Singha, Kamini; Castelletti, Andrea; Destouni, Georgia			ChatGPT in Hydrology and Earth Sciences: Opportunities, Prospects, and Concerns	WATER RESOURCES RESEARCH			English	Editorial Material								The emergence of large language models (LLMs), such as ChatGPT, has garnered significant attention, particularly in academic and scientific circles. Researchers, scientists, and instructors hold varying perspectives on the advantages and disadvantages of using ChatGPT for research and teaching purposes. ChatGPT will be used by many scientists going forward for creating content and driving scientific progress. This commentary offers a brief explanation of the fundamental principles behind ChatGPT and how it can be applied in the fields of hydrology and other Earth sciences. The article examines the primary applications of this open artificial intelligence tool within these fields, specifically its ability to assist with writing and coding tasks, and highlights both the advantages and concerns associated with using such a model. Moreover, the study brings up some other limitations of the model, and the dangers of potential miss-uses. Finally, we suggest that the academic community adapts its regulations and policies to harness the potential benefits of LLMs while mitigating its pitfalls, including establishing a structure for utilizing LLMs and presenting clear regulations for their implementation. We also outline some specific steps on how to accomplish this structure.	[Foroumandi, Ehsan; Moradkhani, Hamid] Univ Alabama, Dept Civil Construct & Environm Engn, Tuscaloosa, AL 35487 USA; [Foroumandi, Ehsan; Moradkhani, Hamid] Univ Alabama, Ctr Complex Hydrosyst Res, Tuscaloosa, AL 35487 USA; [Sanchez-Vila, Xavier] Univ Politecn Cataluna, Dept Civil & Environm Engn, Barcelona, Spain; [Singha, Kamini] Colorado Sch Mines, Dept Geol & Geol Engn, Golden, CO USA; [Castelletti, Andrea] Dept Elect Informat & Bioengn, Milan, Italy; [Destouni, Georgia] Stockholm Univ, Dept Phys Geog, Stockholm, Sweden; [Destouni, Georgia] KTH Royal Inst Technol, Dept Sustainable Dev, Environm Sci & Engn, Sustainabil Assessment & Management, Stockholm, Sweden	University of Alabama System; University of Alabama Tuscaloosa; University of Alabama System; University of Alabama Tuscaloosa; Universitat Politecnica de Catalunya; Colorado School of Mines; Stockholm University; Royal Institute of Technology	Moradkhani, H (corresponding author), Univ Alabama, Dept Civil Construct & Environm Engn, Tuscaloosa, AL 35487 USA.; Moradkhani, H (corresponding author), Univ Alabama, Ctr Complex Hydrosyst Res, Tuscaloosa, AL 35487 USA.	Hmoradkhani@ua.edu	Foroumandi, Ehsan/CAH-3797-2022; Moradkhani, Hamid/B-1571-2012; Destouni, Georgia/M-9662-2016	Foroumandi, Ehsan/0000-0001-6867-7550; Moradkhani, Hamid/0000-0002-2889-999X; Sanchez-Vila, Xavier/0000-0002-1234-9897; Destouni, Georgia/0000-0001-9408-4425; Castelletti, Andrea/0000-0002-7923-1498	We would like to thank Dr. Marc Bierkens for providing insightful comments on the original draft of this paper.	We would like to thank Dr. Marc Bierkens for providing insightful comments on the original draft of this paper.	We would like to thank Dr. Marc Bierkens for providing insightful comments on the original draft of this paper.	Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Halloran LJS, 2023, HYDROL PROCESS, V37, DOI 10.1002/hyp.14843; Karimiziarani M., 2023, Toward reduction of detrimental effects of hurricanes using a social media data analytic approach: How climate change is perceived?, P100480; Karimiziarani M, 2023, INT J DISAST RISK RE, V95, DOI 10.1016/j.ijdrr.2023.103865; Kashefi A., 2023, Journal of Machine Learning for Modeling and Computing, V4, P1, DOI DOI 10.1615/JMACHLEARNMODELCOMPUT.2023048492; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Lee C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00435; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Lund B. D., 2023, SSRN Electron J, V74, DOI [10.2139/ssrn.4333415, DOI 10.2139/SSRN.4333415]; MacNeil S., 2022, Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume 2; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091; OpenAI, 2023, ABOUT US; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pavlik J. V., 2023, Collaborating with ChatGPT: Considering the implications of generative artificial intelligence for journalism and media education; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Tobore TO, 2019, PSYCHOL REP, V122, P2406, DOI 10.1177/0033294118792670; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	26	7	7	22	39	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397	1944-7973		WATER RESOUR RES	Water Resour. Res.	OCT	2023	59	10							e2023WR036288	10.1029/2023WR036288	http://dx.doi.org/10.1029/2023WR036288			8	Environmental Sciences; Limnology; Water Resources	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	U0EP6		Bronze, Green Published			2024-07-03	WOS:001081628100001
J	Hendriksen, C				Hendriksen, Christian			Artificial intelligence for supply chain management: Disruptive innovation or innovative disruption?	JOURNAL OF SUPPLY CHAIN MANAGEMENT			English	Article						artificial intelligence; disruption; GPT-4; metaphorical imagination; sensemaking	COMPLEX ADAPTIVE SYSTEMS; PERSPECTIVES; OPERATIONS; MECHANISMS; KNOWLEDGE	This article examines the theoretical and practical implications of artificial intelligence (AI) integration in supply chain management (SCM). AI has developed dramatically in recent years, embodied by the newest generation of large language models (LLMs) that exhibit human-like capabilities in various domains. However, SCM as a discipline seems unprepared for this potential revolution, as existing perspectives do not capture the potential for disruption offered by AI tools. Moreover, AI integration in SCM is not only a technical but also a social process, influenced by human sensemaking and interpretation of AI systems. This article offers a novel theoretical lens called the AI Integration (AII) framework, which considers two key dimensions: the level of AI integration across the supply chain and the role of AI in decision-making. It also incorporates human meaning-making as an overlaying factor that shapes AI integration and disruption dynamics. The article demonstrates that different ways of integrating AI will lead to different kinds of disruptions, both in theory and in practice. It also discusses the implications of AI integration for SCM theorizing and practice, highlighting the need for cross-disciplinary collaboration and sociotechnical perspectives.	[Hendriksen, Christian] Copenhagen Business Sch, Dept Operat Management, Frederiksberg, Denmark	Copenhagen Business School	Hendriksen, C (corresponding author), Copenhagen Business Sch, Dept Operat Management, Frederiksberg, Denmark.	che.om@cbs.dk		Hendriksen, Christian/0000-0003-0987-329X				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; BARNEY J, 1991, J MANAGE, V17, P99, DOI 10.1177/014920639101700108; Beach Derek., 2014, PROCESS TRACING METH, DOI DOI 10.3998/MPUB.10072208; Bendoly E, 2016, J BUS LOGIST, V37, P6, DOI 10.1111/jbl.12113; Berger P., 1966, SOCIAL CONSTRUCTION; Bille A, 2023, SUPPLY CHAIN MANAG, V28, P724, DOI 10.1108/SCM-03-2022-0119; Blome C, 2014, INT J OPER PROD MAN, V34, P639, DOI 10.1108/IJOPM-11-2012-0515; Bogers M, 2017, IND INNOV, V24, P8, DOI 10.1080/13662716.2016.1240068; Boiko D. A., 2023, EMERGENT AUTONOMOUS; Bonde F., 2023, NAVIGATING TECHNICAL; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Carter CR, 2015, J SUPPLY CHAIN MANAG, V51, P89, DOI 10.1111/jscm.12073; Choi TY, 2001, J OPER MANAG, V19, P351, DOI 10.1016/S0272-6963(00)00068-1; Danese P, 2020, J PURCH SUPPLY MANAG, V26, DOI 10.1016/j.pursup.2020.100634; Darby JL, 2022, DECISION SCI, V53, P578, DOI 10.1111/deci.12538; Darby JL, 2019, INT J LOGIST MANAG, V30, P395, DOI 10.1108/IJLM-07-2018-0187; Dubey R, 2020, INT J PROD ECON, V226, DOI 10.1016/j.ijpe.2019.107599; Espejel JL, 2023, arXiv; Fabbe-Costes N, 2020, INT J OPER PROD MAN, V40, P1475, DOI 10.1108/IJOPM-12-2019-0828; Frohlich MT, 2001, J OPER MANAG, V19, P185, DOI 10.1016/S0272-6963(00)00055-3; Garrido-Merchán EC, 2023, Arxiv, DOI [arXiv:2305.03429, DOI 10.48550/ARXIV.2305.03429]; Gates B, 2023, The Age of AI has begun; Hitch D., 2023, Artificial intelligence (AI) augmented qualitative analysis: The way of the future? SSRN; Hobbs J.E., 1996, SUPPLY CHAIN MANAGEM, V1, P15, DOI [DOI 10.1108/13598549610155260, 10.1108/13598549610155260]; Illari PM, 2012, EUR J PHILOS SCI, V2, P119, DOI 10.1007/s13194-011-0038-2; Kamble SS, 2021, TECHNOL FORECAST SOC, V163, DOI 10.1016/j.techfore.2020.120465; Ketchen DJ, 2021, J SUPPLY CHAIN MANAG, V57, P50, DOI 10.1111/jscm.12251; Ketokivi M, 2020, PROD OPER MANAG, V29, P1011, DOI 10.1111/poms.13148; Kinra A, 2020, INT J OPER PROD MAN, V40, P439, DOI 10.1108/IJOPM-07-2019-0544; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Mollick E., 2023, IT IS STARTING GET S; Nair A, 2019, J OPER MANAG, V65, P80, DOI 10.1002/joom.1022; Nayal K, 2022, INT J LOGIST MANAG, V33, P744, DOI 10.1108/IJLM-12-2020-0493; Panigrahi S., 2023, GPT 4 CAN CHANGE GAM; Perano M, 2023, INT J PHYS DISTR LOG, V53, P628, DOI 10.1108/IJPDLM-06-2022-0201; Sawyer RK, 2004, PHILOS SOC SCI, V34, P260, DOI 10.1177/0048393103262553; Scott WR, 2014, MANAGEMENT, V17, P136, DOI 10.3917/mana.172.0136; Shevlane T, 2023, Arxiv, DOI [arXiv:2305.15324, 10.48550/arXiv.2305.15324]; Sileo D., 2023, ARXIV; Stephens V, 2022, J SUPPLY CHAIN MANAG, V58, P124, DOI 10.1111/jscm.12257; Tate WL, 2014, INT J PHYS DISTR LOG, V44, P353, DOI 10.1108/IJPDLM-12-2012-0356; Teece DJ, 1997, STRATEGIC MANAGE J, V18, P509, DOI 10.1002/(SICI)1097-0266(199708)18:7<509::AID-SMJ882>3.0.CO;2-Z; Touboulic A, 2020, J SUPPLY CHAIN MANAG, V56, P36, DOI 10.1111/jscm.12226; Trautrims A, 2016, INT J LOGIST MANAG, V27, P886, DOI 10.1108/IJLM-01-2015-0003; TSOUKAS H, 1993, ORGAN STUD, V14, P323, DOI 10.1177/017084069301400301; van den Adel MJ, 2022, SUPPLY CHAIN MANAG, V27, P64, DOI 10.1108/SCM-03-2021-0136; Weick Karl., 1995, SENSEMAKING ORG; Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133; Wieland A, 2021, J SUPPLY CHAIN MANAG, V57, P58, DOI 10.1111/jscm.12248; WILLIAMSON OE, 1979, J LAW ECON, V22, P233, DOI 10.1086/466942; Yu YS, 2023, IEEE T ENG MANAGE, DOI 10.1109/TEM.2023.3268340	51	14	14	71	155	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1523-2409	1745-493X		J SUPPLY CHAIN MANAG	J. Supply Chain Manag.	JUL	2023	59	3					65	76		10.1111/jscm.12304	http://dx.doi.org/10.1111/jscm.12304		JUN 2023	12	Management	Social Science Citation Index (SSCI)	Business & Economics	K8OZ1		hybrid			2024-07-03	WOS:001005754900001
C	Lin, YT; Papangelis, A; Kim, S; Lee, S; Hazarika, D; Namazifar, M; Jin, D; Liu, Y; Hakkani-Tur, D		Vlachos, A; Augenstein, I		Lin, Yen-Ting; Papangelis, Alexandros; Kim, Seokhwan; Lee, Sungjin; Hazarika, Devamanyu; Namazifar, Mahdi; Jin, Di; Liu, Yang; Hakkani-Tur, Dilek			Selective In-Context Data Augmentation for Intent Detection using Pointwise V-Information	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				This work focuses on in-context data augmentation for intent detection. Having found that augmentation via in-context prompting of large pre-trained language models (PLMs) alone does not improve performance, we introduce a novel approach based on PLMs and pointwise V-information (PVI), a metric that can measure the usefulness of a datapoint for training a model. Our method first fine-tunes a PLM on a small seed of training data and then synthesizes new datapoints - utterances that correspond to given intents. It then employs intent-aware filtering, based on PVI, to remove datapoints that are not helpful to the downstream intent classifier. Our method is thus able to leverage the expressive power of large language models to produce diverse training data. Empirical results demonstrate that our method can produce synthetic training data that achieve state-of-the-art performance on three challenging intent detection datasets under few-shot settings (1.28% absolute improvement in 5-shot and 1.18% absolute in 10-shot, on average) and perform on par with the state-of-the-art in full-shot settings (within 0.01% absolute, on average).	[Lin, Yen-Ting] Natl Taiwan Univ, Taipei, Taiwan; [Papangelis, Alexandros; Kim, Seokhwan; Lee, Sungjin; Hazarika, Devamanyu; Namazifar, Mahdi; Jin, Di; Liu, Yang; Hakkani-Tur, Dilek] Amazon Alexa AI, Sunnyvale, CA USA	National Taiwan University	Lin, YT (corresponding author), Natl Taiwan Univ, Taipei, Taiwan.	ytl@ieee.org; papangea@amazon.com; seokhwk@amazon.com; sungjinl@amazon.com; dvhaz@amazon.com; mahdinam@amazon.com; djinamzn@amazon.com; yangliud@amazon.com; hakkanit@amazon.com						Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Bowman Samuel R., 2016, PROC 20 SIGNLL C COM, P10, DOI [10.18653/V1/K16-1002, DOI 10.18653/V1/K16-1002]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bunk T, 2020, Arxiv, DOI [arXiv:2004.09936, DOI 10.48550/ARXIV.2004.09936]; Cai Hengyi, 2020, P 58 ANN M ASS COMP, P6334; Casanueva I, 2020, NLP FOR CONVERSATIONAL AI, P38; Coucke A, 2018, Arxiv, DOI arXiv:1805.10190; Culotta Aron, 2005, Proceeding of the 20th National Conference on Artificial Intelligenc(AAAI-2005), V2, P746; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489; Ethayarajh K, 2022, PR MACH LEARN RES; Ghorbani A, 2019, PR MACH LEARN RES, V97; Gupta A, 2018, AAAI CONF ARTIF INTE, P5149; Hemphill J. J., 1990, P SPEECH NAT LANG WO, P96; Henderson M, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2161; Hu YS, 2022, Arxiv, DOI arXiv:2203.08568; Iyyer M., 2018, P 2018 C N AM CHAPTE, V1, P1875, DOI DOI 10.18653/V1/N18-1170; Jolly Shailza, 2020, P 28 INT C COMP LING, P10; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Kumar Varun, 2019, P 2 WORKSHOP DEEP LE, P1; Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1311; Lee Kenton, 2021, arXiv; Li Siyuan, 2021, 9 INT C LEARNING REP; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I., 2019, INT C LEARN REPR NEW, P1; Luo T, 2004, INT C PATT RECOG, P478, DOI 10.1109/ICPR.2004.1334570; Margatina K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P650; Mehri S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2979; Mehri S, 2020, Arxiv, DOI arXiv:2009.13570; Meister C, 2022, Arxiv, DOI arXiv:2202.00666; Mindermann Soren, 2022, INT C MACHINE LEARNI, V162, P15630; Namazifar M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7803, DOI 10.1109/ICASSP39728.2021.9413810; Okur E, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4114; Panda Subhadarshi, 2021, P 3 WORKSHOP NATURAL, P30; Papangelis A, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P111; Peng BL, 2021, INTERSPEECH, P1219, DOI 10.21437/Interspeech.2021-117; Raux Antoine, 2005, 9 EUR C SPEECH COMM, P885; Roy N., 2001, INT C MACHINE LEARNI; Sahu G, 2022, PROCEEDINGS OF THE 4TH WORKSHOP ON NLP FOR CONVERSATIONAL AI, P47; Scheffer T, 2001, INT S INT DAT AN, ppp309, DOI [10.1007/3-540-44816-0_31, DOI 10.1007/3-540-44816-0_31]; Schohn Greg., 2000, P 17 INT C MACHINE L, P839; Shin R, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5417; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Swayamdipta S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9275; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xingkun Liu, 2021, Increasing Naturalness and Flexibility in Spoken Dialogue Interaction. 10th International Workshop on Spoken Dialogue Systems. Lecture Notes in Electrical Engineering (LNEE 714), P165, DOI 10.1007/978-981-15-9323-9_15; Yang YB, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1008; Yang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P87; Yoo KM, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2225; Young S, 2013, P IEEE, V101, P1160, DOI 10.1109/JPROC.2012.2225812; Yu D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P734; Zhang HD, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1114; Zhang JG, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1906; Zhang JG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5064; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	56	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							1463	1476						14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056900010
C	Power, W; Obradovic, Z		Prakash, BA; Wang, D; Weninger, T		Power, William; Obradovic, Zoran			Understanding Online Attitudes with Pre-Trained Language Models	PROCEEDINGS OF THE 2023 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, ASONAM 2023	Proceedings of the IEEE-ACM International Conference on Advances in Social Networks Analysis and Mining		English	Proceedings Paper	15th IEEE/ACM Annual International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	NOV 06-09, 2023	Kusadasi, TURKEY	IEEE, Assoc Comp Machinery, IEEE Comp Soc, ACM SIGKDD, IEEE ICDE, Springer, Istanbul Medipol Univ		Social Network Analysis; Data-mining; Question Answering; Attitude Modeling		This work investigates how the rich semantic embeddings of pre-trained language models can be used to help understand the general attitudes of an online community. This work describes a novel prediction model that can ingest statements describing an arbitrary context and a piece of content, and output answers to a set of 'attitude questions' describing the relationship between them. Typically, annotating answers to questions like "Does this contain sarcasm?", or "Is this content positive with respect to this context?" requires costly human interaction. In this work, we consider the ability of large language models to answer these questions, while under the constraint of a small dataset using a novel prediction head. We show that this methodology can accurately answer these attitude questions, compare the model to off-the-shelf language model approaches, and describe a method for collecting and annotating attitude question data sets. The novel attitude question answering model achieves a 89% accuracy on the attitude question answering task, outperforming the ablated models (87%) as well as the off the shelf models using BERT-based Sequence Classification (13%), BART-based Natural Language Inference (88%), and RoBERTa-based Question-Answering (87%).	[Power, William; Obradovic, Zoran] Temple Univ, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Power, W (corresponding author), Temple Univ, Philadelphia, PA 19122 USA.	tug00038@temple.edu; zoran.obradovic@temple.edu		Obradovic, Zoran/0000-0002-2051-0142	DEVCOM Analysis Center [W911NF-22-2-0001]; Temple University office of the Vice President for Research 2022 Catalytic Collaborative Research Initiative Program	DEVCOM Analysis Center; Temple University office of the Vice President for Research 2022 Catalytic Collaborative Research Initiative Program	Research was sponsored by the DEVCOM Analysis Center and was accomplished under Cooperative Agreement Number W911NF-22-2-0001. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein. This research is also supported in part by Temple University office of the Vice President for Research 2022 Catalytic Collaborative Research Initiative Program. AI & ML Focus Area.	Acheampong FA, 2021, ARTIF INTELL REV, V54, P5789, DOI 10.1007/s10462-021-09958-2; Alambo A, 2019, IEEE INT C SEMANT CO, P468, DOI [10.1109/ICSC.2019.00090, 10.1109/ICOSC.2019.8665525]; Andrade C, 2020, Indian Journal of Prychological Medirine, V42, P438; Aydin B, 2019, TECHNOL SOC, V59, DOI 10.1016/j.techsoc.2019.101180; Cage E, 2019, AUTISM, V23, P1373, DOI 10.1177/1362361318811290; Das R., 2022, INT C MACHINE LEARNI, P4777; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3558; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; Fu B, 2020, Arxiv, DOI arXiv:2007.13069; Jain P., 2022, Journal of Physics: Confere Series, V2151; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Long SW, 2023, FINANC REV, V58, P19, DOI 10.1111/fire.12328; Medvedev AN., 2017, Dynamics on and of Complex Networks, P183; Pogue K, 2020, VACCINES-BASEL, V8, DOI 10.3390/vaccines8040582; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250; Reacts A., 2023, ACM Companng Surveys, V55, P145; Sobkowicz P, 2012, GOV INFORM Q, V29, P470, DOI 10.1016/j.giq.2012.06.005; Stedman RC, 2019, SOC NATUR RESOUR, V32, P1139, DOI 10.1080/08941920.2019.1587127; Tang FL, 2019, INFORM SCIENCES, V488, P190, DOI 10.1016/j.ins.2019.02.064; To QG, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231158033; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Zad S, 2021, 2021 IEEE WORLD AI IOT CONGRESS (AIIOT), P255, DOI [10.1109/AIIOT52608.2021.9454192, 10.1109/AIIoT52608.2021.9454192]; Zomick J., 2019, Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology, P74, DOI [10.18653/v1/W19-3009, DOI 10.18653/V1/W19-3009]	25	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES	2473-9928	2473-991X	979-8-4007-0409-3	PR I-A I C AD S N A			2023							745	752		10.1145/3625007.3627302	http://dx.doi.org/10.1145/3625007.3627302			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Communication	BW7KE		Bronze			2024-07-03	WOS:001191293500116
C	Yong, Q; Wei, JQ; Zhang, YR; Zhang, XL; Wei, C; Chen, SM; Li, YH; Ye, C; Huang, B; Wang, H			ACM	Yong, Qian; Wei, Jueqi; Zhang, Yiren; Zhang, Xilun; Wei, Chao; Chen, Simiao; Li, Yunhe; Ye, Cheng; Huang, Bing; Wang, Hao			CGSMP: Controllable Generative Summarization via Multimodal Prompt	PROCEEDINGS OF THE 1ST WORKSHOP ON LARGE GENERATIVE MODELS MEET MULTIMODAL APPLICATIONS, LGM3A 2023			English	Proceedings Paper	1st Workshop on Large Generative Models Meet Multimodal Applications (LGM3A)	NOV 02, 2023	Ottawa, CANADA	Assoc Comp Machinery, ACM SIGMM		Multimodal; Summarization; Controllable; LLM; Hallucination		Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of a large language model (LLM), this advancement has resulted in more fluent and coherent Natural Language Generation, which has contributed to improved development in downstream tasks such as abstractive summarization. Despite the recent progress in LLM, hallucination has become a serious problem in NLG. Hallucination happens when language models generate nonsensical or unfaithful text, which will lead to severe problems with reliability and effectiveness. In this paper, we propose a novel approach called Controllable Generative Summarization via Multimodal Prompt (CGSMP), which uses entities extracted from content and images as multimodal prompt control signals, thereby reducing hallucination issues. Specifically, the proposed CGSMP consists of three main modules: (1) an image prefix module that obtains image representations; (2) a prompt encoder module that fusion entities and images as multimodal prompts; and (3) a pre-trained causal language model that fuses input and controllable prompt and serves as the backbone of the language model. Experimental results demonstrate that the proposed method significantly improves the quality of generated summaries compared to the state of the arts.	[Yong, Qian; Wei, Jueqi; Zhang, Yiren; Zhang, Xilun; Wei, Chao; Chen, Simiao; Li, Yunhe; Ye, Cheng; Huang, Bing; Wang, Hao] Shanghai Shizhuang Informat Technol Co Ltd, Shang Hai, Peoples R China		Yong, Q (corresponding author), Shanghai Shizhuang Informat Technol Co Ltd, Shang Hai, Peoples R China.	sarahyongq@gmail.com; weijueqi@shizhuang-inc.com; zhangyiren@shizhuang-inc.com; zhangxilun@shizhuang-inc.com; weichao@shizhuang-inc.com; sean@shizhuang-inc.com; yunheli07@gmail.com; yecheng01@shizhuang-inc.com; huangbin@shizhuang-inc.com; wanghao1228@shizhuang-inc.com						Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Calixto I, 2017, Arxiv, DOI arXiv:1702.01287; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Carlsson F, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6837; Clarke J, 2008, J ARTIF INTELL RES, V31, P399, DOI 10.1613/jair.2433; Dathathri S, 2020, Arxiv, DOI arXiv:1912.02164; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Houlsby N, 2019, PR MACH LEARN RES, V97; Koehn P, 2017, Arxiv, DOI [arXiv:1706.03872, 10.48550/arXiv.1706.03872, DOI 10.48550/ARXIV.1706.03872]; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li HR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4152; Li ML, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2190; Libovicky Jindrich, 2017, arXiv; Lin C.-Y., 2002, P ACL 02 WORKSHOP AU, P74; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Loper E, 2002, ARXIV; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Rush AM, 2015, Arxiv, DOI [arXiv:1509.00685, DOI 10.18653/V1/D15-1044]; Palaskar S, 2019, Arxiv, DOI arXiv:1906.07901; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qian J, 2022, Arxiv, DOI arXiv:2202.13257; R OpenAI, 2023, arXiv; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raunak V, 2021, Arxiv, DOI [arXiv:2104.06683, 10.48550/arXiv.2104.06683]; Roberts A, 2020, Arxiv, DOI arXiv:2002.08910; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, Arxiv, DOI arXiv:1506.05869; Xiao M, 2023, Arxiv, DOI arXiv:2307.02716; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Yu Tiezheng, 2021, arXiv; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536; Zhu JN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4154	35	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0283-9				2023							45	50		10.1145/3607827.3616841	http://dx.doi.org/10.1145/3607827.3616841			6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KH					2024-07-03	WOS:001150367900008
C	Kwon, H; Koupaee, M; Singh, P; Sawhney, G; Shukla, A; Kallur, KK; Chambers, N; Balasubramanian, N		Cohn, T; He, Y; Liu, Y		Kwon, Heeyoung; Koupaee, Mahnaz; Singh, Pratyush; Sawhney, Gargi; Shukla, Anmol; Kallur, Keerthi Kumar; Chambers, Nathanael; Balasubramanian, Niranjan			Modeling Preconditions in Text with a Crowd-sourced Dataset	FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020			English	Proceedings Paper	Meeting of the Association-for-Computational-Linguistics (ACL-EMNLP)	NOV 16-20, 2020	ELECTR NETWORK	Assoc Computat Linguist				Preconditions provide a form of logical connection between events that explains why some events occur together and information that is complementary to the more widely studied relations such as causation, temporal ordering, entailment, and discourse relations. Modeling preconditions in text has been hampered in part due to the lack of large scale labeled data grounded in text. This paper introduces PeKo, a crowd-sourced annotation of preconditions between event pairs in newswire, an order of magnitude larger than prior text annotations. To complement this new corpus, we also introduce two challenge tasks aimed at modeling preconditions: (i) Precondition Identification - a standard classification task defined over pairs of event mentions, and (ii) Precondition Generation - a generative task aimed at testing a more general ability to reason about a given event. Evaluation on both tasks shows that modeling preconditions is challenging even for today's large language models (LM). This suggests that precondition knowledge is not easily accessible in LM-derived representations alone. Our generation results show that fine-tuning an LM on PeKo yields better conditional relations than when trained on raw text or temporally-ordered corpora.	[Kwon, Heeyoung; Koupaee, Mahnaz; Singh, Pratyush; Sawhney, Gargi; Shukla, Anmol; Kallur, Keerthi Kumar; Balasubramanian, Niranjan] SUNY Stony Brook, Stony Brook, NY 11794 USA; [Chambers, Nathanael] US Naval Acad, Annapolis, MD USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; United States Department of Defense; United States Navy; United States Naval Academy	Kwon, H (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.	heekwon@cs.stonybrook.edu; mkoupaee@cs.stonybrook.edu; nchamber@usna.edu; niranjan@cs.stonybrook.edu			Air Force Research Laboratory (AFRL); DARPA [FA8750-19-2-1003]	Air Force Research Laboratory (AFRL)(United States Department of DefenseUS Air Force Research Laboratory); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This material is based on research that is supported by the Air Force Research Laboratory (AFRL), DARPA, for the KAIROS program under agreement number FA8750-19-2-1003. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes.	Berant J, 2015, COMPUT LINGUIST, V41, P249, DOI 10.1162/COLI_a_00220; Bethard S, 2013, P 7 INT WORKSHOP SEM, P10; Blair-Goldensohn Sasha, 2006, DOC UND WORKSH DUC 2; Branavan S.R. K., 2012, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, V1, P126; Caselli T., 2017, P EVENTS STORIES NEW, P77, DOI 10.18653/v1/W17-2711; Chambers T., 2014, Transactions of the Association for Computational Linguistics, V2, P273, DOI [DOI 10.1162/tacl_a_00182, DOI 10.1162/TACL_A_00182]; Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1; Girju R., 2003, Proceedings of the ACL 2003 Workshop on Multilingual Summarization and Question Answering, P76, DOI 10.3115/1119312.1119322; Girju Roxana, 2003, ACL; Han Rujun., 2019, EMNLP; LAI HC, 2014, SYNTAX SEMANTICS STR, P1103, DOI DOI 10.1109/IS3C.2014.287; Lin D., 2001, P 7 ACM SIGKDD INT C, P323, DOI DOI 10.1145/502512.502559; Liu Nelson F., 2019, P C N AM ASS CHAPT A; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Mirza Paramita, 2014, WORKSH COMP APPR CAU; Mostafazadeh N., 2016, Proceedings of the Fourth Workshop on Events, P51; Ning Qiang., 2018, Long Papers), V1, P841; OGorman Tim, 2016, Computing News Storylines, P47; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pustejovsky J., 2003, Corpus linguistics, V2003, P40; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sandhaus E., 2008, The New York Times Annotated Corpus', V6, P26752; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Sil A., 2010, 2010 AAAI Fall Symposium Series; Sil Avirup, 2011, RECENT ADV NATURAL L, P1; Stanovsky Gabriel, 2018, P 2018 C N AM CHAPTE, V1, P885, DOI DOI 10.18653/V1/N18-1081; Vashishtha S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2906; Yang Z., 2019, ADV NEURAL INFORM PR, P5754, DOI DOI 10.5555/3454287.3454804	31	3	3	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-952148-90-3				2020							3818	3828						11	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TF					2024-07-03	WOS:001181866503006
J	Patino, GA; Amiel, JM; Brown, M; Lypson, ML; Chan, TM				Patino, Gustavo A.; Amiel, Jonathan M.; Brown, Megan; Lypson, Monica L.; Chan, Teresa M.			The Promise and Perils of Artificial Intelligence in Health Professions Education Practice and Scholarship	ACADEMIC MEDICINE			English	Article								Artificial intelligence (AI) methods, especially machine learning and natural language processing, are increasingly affecting health professions education (HPE), including the medical school application and selection processes, assessment, and scholarship production. The rise of large language models over the past 18 months, such as ChatGPT, has raised questions about how best to incorporate these methods into HPE. The lack of training in AI among most HPE faculty and scholars poses an important challenge in facilitating such discussions. In this commentary, the authors provide a primer on the AI methods most often used in the practice and scholarship of HPE, discuss the most pressing challenges and opportunities these tools afford, and underscore that these methods should be understood as part of the larger set of statistical tools available. Despite their ability to process huge amounts of data and their high performance completing some tasks, AI methods are only as good as the data on which they are trained. Of particular importance is that these models can perpetuate the biases that are present in those training datasets, and they can be applied in a biased manner by human users. A minimum set of expectations for the application of AI methods in HPE practice and scholarship is discussed in this commentary, including the interpretability of the models developed and the transparency needed into the use and characteristics of such methods. The rise of AI methods is affecting multiple aspects of HPE including raising questions about how best to incorporate these models into HPE practice and scholarship. In this commentary, we provide a primer on the AI methods most often used in HPE and discuss the most pressing challenges and opportunities these tools afford.	[Patino, Gustavo A.] Western Michigan Univ, Med Educ, Homer Stryker MD Sch Med, Kalamazoo, MI USA; [Amiel, Jonathan M.] Columbia Univ, Vagelos Coll Phys & Surg, Med Ctr, New York, NY USA; [Brown, Megan] Newcastle Univ, Sch Med, Med Educ, Newcastle, England; [Lypson, Monica L.] Columbia Univ, Vagelos Coll Phys & Surg, Dept Med, Med,Irving Med Ctr, New York, NY USA; [Chan, Teresa M.] Toronto Metropolitan Univ, Sch Med, Toronto, ON, Canada; [Chan, Teresa M.] Toronto Metropolitan Univ, Med Affairs, Toronto, ON, Canada; [Chan, Teresa M.] Toronto Metropolitan Univ, Toronto, ON, Canada; [Chan, Teresa M.] McMaster Univ, Fac Hlth Sci, Dept Med, Div Emergency Med, Hamilton, ON, Canada; [Chan, Teresa M.] McMaster Univ, Fac Hlth Sci, Dept Med, Div Educ & Innovat, Hamilton, ON, Canada; [Chan, Teresa M.] McMaster Univ, Fac Hlth Sci, McMaster Educ Res Innovat & Theory MERIT Program, Hamilton, ON, Canada; [Chan, Teresa M.] Wilson Ctr, Toronto, ON, Canada; [Patino, Gustavo A.] Western Michigan Univ, Dept Med Educ, Homer Stryker MD Sch Med, 1000 Oakland Dr, Kalamazoo, MI 49008 USA	Western Michigan University; Columbia University; Newcastle University - UK; NewYork-Presbyterian Hospital; Columbia University; Toronto Metropolitan University; Toronto Metropolitan University; Toronto Metropolitan University; McMaster University; McMaster University; McMaster University; Western Michigan University	Patino, GA (corresponding author), Western Michigan Univ, Dept Med Educ, Homer Stryker MD Sch Med, 1000 Oakland Dr, Kalamazoo, MI 49008 USA.	gustavo.patino@wmed.edu; jma2106@cumc.columbia.edu; megan.brown@newcastle.ac.uk; mll2215@cumc.columbia.edu; teresa.chan@medportal.ca	; Chan, Teresa/T-6676-2017	Brown, Megan/0000-0002-9334-0922; Chan, Teresa/0000-0001-6104-462X; Lypson, Monica/0000-0002-1450-9380				[Anonymous], 2023, Pause giant AI experiments: An open letter; [Anonymous], What is natural language processing?; Asimov I., 1950, I, Robot; Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Bond WF., 2023, ACAD MED, V98, pS90, DOI [10.1097/acm.0000000000005357, DOI 10.1097/ACM.0000000000005357]; Boscardin CK, 2024, ACAD MED, V99, P22, DOI 10.1097/ACM.0000000000005439; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Crear-Perry J, 2020, LANCET, V396, P451, DOI 10.1016/S0140-6736(20)31543-9; DeVilbiss MB, 2023, ACAD MED, V98, P865, DOI 10.1097/ACM.0000000000005261; Ghaffary S., 2023, Universities Rethink Using AI Writing Detectors to Vet Students' Work; Hashimoto DA, 2023, ACAD MED, V98, P978, DOI 10.1097/ACM.0000000000005309; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Intelligent, Nearly 1 in 3 College Students Have Used ChatGPT on Written Assignments; James Gareth., 2023, An Introduction to Statistical Learning: With Applications in Python; Kolachalama VB, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0061-1; Krive J, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad037; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Ladbury C, 2022, TRANSL CANCER RES, DOI 10.21037/tcr-22-1626; Latifi S, 2016, EVAL HEALTH PROF, V39, P100, DOI 10.1177/0163278715605358; Liu Y, 2019, JAMA-J AM MED ASSOC, V322, P1806, DOI 10.1001/jama.2019.16489; McCoy LG, 2022, J CLIN EPIDEMIOL, V142, P252, DOI 10.1016/j.jclinepi.2021.11.001; McKinsey & Company, 2022, The state of AU in 2022-and half a decade in review; McMaster University, Generative Artificial Intelligence in Teaching and Learning; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Price WN, 2018, SCI TRANSL MED, V10, DOI 10.1126/scitranslmed.aao5333; Renton M., 2023, The Current Generation of AI Tools: Three Considerations for Quality Leaders; Serrano L., 2021, Grokking Machine Learning; Straw I, 2020, ARTIF INTELL MED, V110, DOI 10.1016/j.artmed.2020.101965; Subramanian T, 2023, ACAD MED, V98, pS34, DOI 10.1097/ACM.0000000000005189; Suchikova Y, 2023, NATURE, V614, P413, DOI 10.1038/d41586-023-00381-x; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Triola MM, 2023, ACAD MED, V98, P1036, DOI 10.1097/ACM.0000000000005202	33	1	1	2	2	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	1040-2446	1938-808X		ACAD MED	Acad. Med.	MAY	2024	99	5					477	481		10.1097/ACM.0000000000005636	http://dx.doi.org/10.1097/ACM.0000000000005636			5	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	OR5B6	38266214	Bronze			2024-07-03	WOS:001209002500001
J	Huang, GM; Li, YY; Jameel, S; Long, YF; Papanastasiou, G				Huang, Guangming; Li, Yingya; Jameel, Shoaib; Long, Yunfei; Papanastasiou, Giorgos			From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?	COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL			English	Review						Explainable; Interpretable; Deep learning; NLP; Healthcare	MODELS	Deep learning (DL) has substantially enhanced natural language processing (NLP) in healthcare research. However, the increasing complexity of DL -based NLP necessitates transparent model interpretability, or at least explainability, for reliable decision -making. This work presents a thorough scoping review of explainable and interpretable DL in healthcare NLP. The term "eXplainable and Interpretable Artificial Intelligence" (XIAI) is introduced to distinguish XAI from IAI. Different models are further categorized based on their functionality (model-, input-, output -based) and scope (local, global). Our analysis shows that attention mechanisms are the most prevalent emerging IAI technique. The use of IAI is growing, distinguishing it from XAI. The major challenges identified are that most XIAI does not explore "global" modelling processes, the lack of best practices, and the lack of systematic evaluation and benchmarks. One important opportunity is to use attention mechanisms to enhance multi -modal XIAI for personalized medicine. Additionally, combining DL with causal logic holds promise. Our discussion encourages the integration of XIAI in Large Language Models (LLMs) and domain -specific smaller models. In conclusion, XIAI adoption in healthcare requires dedicated in-house expertise. Collaboration with domain experts, end -users, and policymakers can lead to ready -to -use XIAI methods across NLP and medical tasks. While challenges exist, XIAI techniques offer a valuable foundation for interpretable NLP algorithms in healthcare.	[Huang, Guangming; Long, Yunfei] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, England; [Li, Yingya] Harvard Med Sch, Boston, MA 02115 USA; [Li, Yingya] Boston Childrens Hosp, Boston, MA 02115 USA; [Jameel, Shoaib] Univ Southampton, Elect & Comp Sci, Southampton SO17 1BJ, England; [Papanastasiou, Giorgos] Athena Res Ctr, Archimedes Unit, Athens 15125, Greece	University of Essex; Harvard University; Harvard Medical School; Harvard University; Boston Children's Hospital; University of Southampton	Long, YF (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, England.; Papanastasiou, G (corresponding author), Athena Res Ctr, Archimedes Unit, Athens 15125, Greece.	gh22231@essex.ac.uk; yingya.li@childrens.harvard.edu; m.s.jameel@southampton.ac.uk; yl20051@essex.ac.uk; g.papanastasiou@athenarc.gr	LONG, YUNFEI/O-5784-2019; Huang, Guangming/GQH-1731-2022	LONG, YUNFEI/0000-0002-4407-578X; Huang, Guangming/0000-0003-2539-0538	National Recovery and Resilience Plan Greece 2.0 - EU under the NextGenerationEU Program [5154714]	National Recovery and Resilience Plan Greece 2.0 - EU under the NextGenerationEU Program	This was work was supported by the MIS under Grant 5154714 of the National Recovery and Resilience Plan Greece 2.0 funded by EU under the NextGenerationEU Program.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed U, 2023, IEEE J BIOMED HEALTH, V27, P1709, DOI 10.1109/JBHI.2022.3204633; Ahmed U, 2022, FUTURE GENER COMP SY, V130, P106, DOI 10.1016/j.future.2021.12.008; Ahne A, 2022, J MED INTERNET RES, V24, DOI 10.2196/27434; Amador-Dominguez E, 2021, report recommendation; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Balagopalan A, 2021, FRONT AGING NEUROSCI, V13, DOI 10.3389/fnagi.2021.635945; Bhatt A, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.711467; Boukobza A, 2022, JMIR MED INF, V10, DOI 10.2196/34306; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brunner Gino, 2019, INT C LEARNING REPRE; Cahyawijaya S, 2022, P 13 INT WORKSH HLTH, P160; Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832; Chen D, 2021, 2021 IEEE INT C BIOI, P3341, DOI [10.1109/bibm52615.2021.9669648, DOI 10.1109/BIBM52615.2021.9669648, 10.1109/BIBM52615.2021.9669648]; Chen PF, 2022, JMIR MED INF, V10, DOI 10.2196/41342; Cheng J.P., EMNLP, P551, DOI 10.18653/v1/d16-1053; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; De Magistris G, 2022, INFORMATION, V13, DOI 10.3390/info13030137; Dobrakowski AG, 2021, J INTELL INF SYST, V57, P447, DOI 10.1007/s10844-021-00659-4; Dong H, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103728; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Duarte F, 2018, J BIOMED INFORM, V80, P64, DOI 10.1016/j.jbi.2018.02.011; Farruque N, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), P1472, DOI 10.1109/ICMLA52953.2021.00237; Feder A, 2022, T ASSOC COMPUT LING, V10, P1138, DOI 10.1162/tacl_a_00511; Ferté T, 2021, J BIOMED INFORM, V117, DOI 10.1016/j.jbi.2021.103746; Frisoni G, 2021, DATA MANAGEMENT TECH, V9, P293; Fu B, 2020, arXiv; Gao Gu, 2020, Web and Big Data. 4th International Joint Conference, APWeb-WAIM 2020. Lecture Notes in Computer Science (LNCS 12317), P257, DOI 10.1007/978-3-030-60259-8_20; Garcia-Olano D, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3547; Gin BC, 2022, MED EDUC, V56, P303, DOI 10.1111/medu.14696; Grundmann P, 2022, P 29 INT C COMP LING, P4765; Hamilton WL., 2020, SYNTHESIS LECT ARTIF, V14, P1, DOI DOI 10.2200/S01045ED1V01Y202009AIM046; Hobbhahn M, 2022, NEURIPS 2022 WORKSH; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Holderness E, 2019, J BIOMED SEMANT, V10, DOI 10.1186/s13326-019-0210-8; Iinuma N, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P161; Jin Z, 2023, 37 C NEUR INF PROC S; Kim B-H, 2022, P 13 INT WORKSH HLTH, P26, DOI [10.18653/v1/2022.louhi-1.3, DOI 10.18653/V1/2022.LOUHI-1.3]; Kim Y, 2014, P 2014 C EMP METH NA, V2014, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/d14-1181]; Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173; Lehman E., 2023, C HLTH INF LEARN, P578; Lin TY, 2022, AI OPEN, V3, P111, DOI 10.1016/j.aiopen.2022.10.001; Lindsay H, 2021, Front Aging Neurosci, P228; Lipton ZC., 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340; Liu ZY, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES(NAACL HLT 2019), VOL. 2 (INDUSTRY PAPERS), P24; Lu ZH, 2021, J MED INTERNET RES, V23, DOI 10.2196/22860; Lundberg SM, 2017, ADV NEUR IN, V30; Luo X, 2021, COMPUT METH PROG BIO, V210, DOI 10.1016/j.cmpb.2021.106395; Maji S, 2021, PROC INT C TOOLS ART, P851, DOI 10.1109/ICTAI52525.2021.00136; Mandalios A, 2021, Complex networks & their applications IX, V2, P92; Marchesin Stefano, 2022, J Pathol Inform, V13, P100139, DOI 10.1016/j.jpi.2022.100139; Martina S, 2020, IEEE J BIOMED HEALTH, V24, P3085, DOI 10.1109/JBHI.2020.3005016; Mascharka D, 2018, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2018.00519; Mellado EA, 2019, P 10 INT WORKSH HLTH, P81; Meng Yuxian, 2021, arXiv, DOI DOI 10.48550/ARXIV.2110.10470; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Michalopoulos G, 2022, FINDINGS ASS COMPUTA, P4741; Minot Joshua R., 2022, ACM Transactions on Computing for Healthcare, DOI 10.1145/3524887; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Moro G, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P180; Mosqueira-Rey E, 2023, ARTIF INTELL REV, V56, P3005, DOI 10.1007/s10462-022-10246-w; Naseem U, 2022, IEEE T COMPUTATIONAL; Ong CJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234908; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Otmakhova Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5098; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Ozyegen O, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102284; Papanastasiou G, 2024, IEEE J BIOMED HEALTH, V28, P1398, DOI 10.1109/JBHI.2023.3348436; Payrovnaziri SN, 2020, J AM MED INFORM ASSN, V27, P1173, DOI 10.1093/jamia/ocaa053; Pearl J, 2010, INT J BIOSTAT, V6, DOI 10.2202/1557-4679.1203; Pruthi Danish, 2020, ANN M ASS COMP LING, DOI 10.18653/v1/2020.aclmain.432; Qinghan Xue, 2019, Smart Health, V13, P130, DOI 10.1016/j.smhl.2019.03.002; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Salvi M, 2024, INFORM FUSION, V103, DOI 10.1016/j.inffus.2023.102134; Schölkopf B, 2021, P IEEE, V109, P612, DOI 10.1109/JPROC.2021.3058954; Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2931; Shapley L., 1953, 17. A Value for n-Person Games, P307, DOI DOI 10.1515/9781400881970-018; Singhal K, 2023, NATURE, DOI 10.1038/s41586-023-06455-0; Sushil M, 2018, J BIOMED INFORM, V84, P103, DOI 10.1016/j.jbi.2018.06.016; Teng F, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00867; Nguyen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8446; Thorsen-Meyer HC, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00679-6; Trigueros O, 2022, INT J MED INFORM, V157, DOI 10.1016/j.ijmedinf.2021.104615; Tu T., 2024, NEJM AI, V1, DOI 10.1056/AIoa2300138; Ribeiro MT, 2016, Arxiv, DOI [arXiv:1606.05386, 10.48550/arXiv.1606.05386]; Uddin Md Zia, 2022, 2022 International Conference on Innovations in Science, Engineering and Technology (ICISET)., P408, DOI 10.1109/ICISET54810.2022.9775893; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vashishth S, 2019, Arxiv, DOI arXiv:1909.11218; Vaswani A, 2017, ADV NEUR IN, V30; Wang Q, 2018, P 11 INT C NAT LANG, P10; Wang Y, 2023, MACH LEARN HEALTHC C, P804; Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11; Wu X., 2022, P 29 INT C COMP LING, P2952; Wu XJ, 2022, FUTURE GENER COMP SY, V135, P364, DOI 10.1016/j.future.2022.05.014; Yan B, 2022, AAAI CONF ARTIF INTE, P2982; Yang J, 2022, P 13 INT WORKSH HLTH, P127; You Jingyi, 2022, P 29 INT C COMP LING, P5989; Zhang AY, 2019, BDCAT'19: PROCEEDINGS OF THE 6TH IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES, P95, DOI 10.1145/3365109.3368791; Zhang F, 2022, P 13 INT WORKSH HLTH, P54; Zhang JH, 2018, IEEE ACCESS, V6, P65333, DOI 10.1109/ACCESS.2018.2875677; Zhang Ya, 2022, 2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI), P460, DOI 10.1109/ICCEAI55464.2022.00102; Zhu YD, 2022, 13TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, BCB 2022, DOI 10.1145/3535508.3545555	103	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2001-0370			COMPUT STRUCT BIOTEC	Comp. Struct. Biotechnol. J..	DEC	2024	24						362	373		10.1016/j.csbj.2024.05.004	http://dx.doi.org/10.1016/j.csbj.2024.05.004			12	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	TR8C6	38800693				2024-07-03	WOS:001243068600001
J	Buonaiuto, G; Guarasci, R; Minutolo, A; De Pietro, G; Esposito, M				Buonaiuto, Giuseppe; Guarasci, Raffaele; Minutolo, Aniello; De Pietro, Giuseppe; Esposito, Massimo			Quantum transfer learning for acceptability judgements	QUANTUM MACHINE INTELLIGENCE			English	Review						Quantum machine learning; Quantum natural language processing; Variational quantum classifier		Hybrid quantum-classical classifiers promise to positively impact critical aspects of natural language processing tasks, particularly classification-related ones. Among the possibilities currently investigated, quantum transfer learning, i.e., using a quantum circuit for fine-tuning pre-trained classical models for a specific task, is attracting significant attention as a potential platform for proving quantum advantage. This work shows potential advantages, in terms of both performance and expressiveness, of quantum transfer learning algorithms trained on embedding vectors extracted from a large language model to perform classification on a classical linguistics task-acceptability judgements. Acceptability judgement is the ability to determine whether a sentence is considered natural and well-formed by a native speaker. The approach has been tested on sentences extracted from ItaCoLa, a corpus that collects Italian sentences labeled with their acceptability judgement. The evaluation phase shows results for the quantum transfer learning pipeline comparable to state-of-the-art classical transfer learning algorithms, proving current quantum computers' capabilities to tackle NLP tasks for ready-to-use applications. Furthermore, a qualitative linguistic analysis, aided by explainable AI methods, reveals the capabilities of quantum transfer learning algorithms to correctly classify complex and more structured sentences, compared to their classical counterpart. This finding sets the ground for a quantifiable quantum advantage in NLP in the near future.	[Buonaiuto, Giuseppe; Guarasci, Raffaele; Minutolo, Aniello; De Pietro, Giuseppe; Esposito, Massimo] Natl Res Council Italy CNR, Inst High Performance Comp & Networking ICAR, I-80131 Naples, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR)	Guarasci, R (corresponding author), Natl Res Council Italy CNR, Inst High Performance Comp & Networking ICAR, I-80131 Naples, Italy.	raffaele.guarasci@icar.cnr.it			Consiglio Nazionale Delle Ricerche (CNR)	Consiglio Nazionale Delle Ricerche (CNR)(Consiglio Nazionale delle Ricerche (CNR))	No Statement Available	Abbas A, 2021, NAT COMPUT SCI, V1, P403, DOI 10.1038/s43588-021-00084-1; Abbaszade M, 2021, IEEE ACCESS, V9, P130434, DOI 10.1109/ACCESS.2021.3108768; [Anonymous], 2013, Trans Assoc Comput Linguist; BATES E, 1982, COGNITION, V11, P245, DOI 10.1016/0010-0277(82)90017-8; Benedetti M, 2019, QUANTUM SCI TECHNOL, V4, DOI 10.1088/2058-9565/ab4eb5; Bergholm V, 2022, Arxiv, DOI arXiv:1811.04968; Bonetti F, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1740; Brunato D., 2020, Proceedings of the seventh evaluation campaign of natural language processing and speech tools for Italian. Final workshop (EVALITA 2020), Online event, December 17th; Brunato D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2690; Chen Z, 2020, J EAST ASIAN LINGUIS, V29, P311, DOI 10.1007/s10831-020-09210-y; Cherniavskii D., 2022, P 2022 EMNLP, P88; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Coecke B, 2020, Arxiv, DOI arXiv:2012.03755; Coecke Bob, 2010, Linguistic Analysis, V36, P345; Correia AD, 2022, Arxiv, DOI arXiv:2106.05299; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du YX, 2022, NPJ QUANTUM INFORM, V8, DOI 10.1038/s41534-022-00570-y; Feldhausen I, 2020, Going romance 2020; Gianani I, 2022, ADV QUANTUM TECHNOL, V5, DOI 10.1002/qute.202100140; Guarasci R, 2023, Numerical Computations: Theory and Algorithms NUMTA, V116; Guarasci R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115651; Guarasci R, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101261; Guarasci R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03297-4; Guarasci R, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.112954; Jentoft M, 2023, P 24 NORD C COMP LIN, P610; Kim Joo-Kyung, 2017, P 2017 C EMPIRICAL M, P2832, DOI DOI 10.18653/V1/D17-1302; Lau JH, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1618; Lau JH, 2014, P ANN M COGN SCI SOC, V36, P99; Li GX, 2023, Arxiv, DOI arXiv:2205.05625; Li QC, 2023, Arxiv, DOI arXiv:2302.13812; Li WK, 2022, SCI CHINA PHYS MECH, V65, DOI 10.1007/s11433-021-1793-6; Linzen T, 2018, Glossa: J Gen Linguist, V3; Linzen T, 2019, LANGUAGE, V95, pE99, DOI 10.1353/lan.2019.0015; Linzen Tal, 2016, Transactions of the Association for Computational Linguistics, V1990, P521, DOI [10.1162/tacl_a_00115, DOI 10.1162/TACL_A_00115]; Liu HT, 2012, POZ STUD CONTEMP LIN, V48, P597, DOI 10.1515/psicl-2012-0027; Lloyd S, 2020, Arxiv, DOI arXiv:2001.03622; Ma Xiaofei, 2019, WORKSHOP DEEP LEARN, P76, DOI [10.18653/v1/D19-6109, DOI 10.18653/V1/D19-6109]; Mari A, 2020, QUANTUM-AUSTRIA, V4, DOI 10.22331/q-2020-10-09-340; Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192; Meichanetzidis K, 2020, Arxiv, DOI arXiv:2012.03756; Mikhailov V, 2022, P 2022 C EMPIRICAL M, P5207, DOI 10.18653/v1/2022.emnlp-main.348; Peters M., 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-1202; Polignano M., 2019, P 6 ITALIAN C COMPUT, V2481, P1; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Rodríguez-Pérez R, 2020, J COMPUT AID MOL DES, V34, P1013, DOI 10.1007/s10822-020-00314-0; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Ruder S, 2019, P C N AM CHAPT ASS C, P15, DOI [10.18653/v1/N19-5004, DOI 10.18653/V1/N19-5004]; Ruder S, 2017, Arxiv, DOI arXiv:1702.02052; Sagae Kenji, 2009, P 11 INT C PARS TECH, P192; Schuld M., 2021, Machine learning with quantum computers, DOI DOI 10.1007/978-3-030-83098-4; Schuster S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3795; Shah DJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1056; Someya T, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1581; Sordoni A, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P653; Sprouse J, 2013, LINGUA, V134, P219, DOI 10.1016/j.lingua.2013.07.002; Sprouse J, 2013, LANG COGNITIVE PROC, V28, P222, DOI 10.1080/01690965.2012.703782; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Torlai G, 2020, ANNU REV CONDEN MA P, V11, P325, DOI 10.1146/annurev-conmatphys-031119-050651; Trotta D, 2021, FINDINGS ASS COMPUTA, P2929; Tsarfaty R., 2010, P NAACL HLT 2010 1 W, P1; Vaswani A, 2017, ADV NEUR IN, V30; Volodina E., 2021, Proceedings of the 10th workshop on NLP for computer assisted language learning, P28; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wiebe N, 2020, NEW J PHYS, V22, DOI 10.1088/1367-2630/abac39; Xiang BL, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2784; Chen SYC, 2020, Arxiv, DOI arXiv:2011.14651; Zeng W, 2016, ELECTRON P THEOR COM, P67, DOI 10.4204/EPTCS.221.8	68	1	1	4	4	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2524-4906	2524-4914		QUANT MACH INTELL	Quant. Mach. Intell.	JUN	2024	6	1							13	10.1007/s42484-024-00141-8	http://dx.doi.org/10.1007/s42484-024-00141-8			18	Computer Science, Artificial Intelligence; Quantum Science & Technology	Emerging Sources Citation Index (ESCI)	Computer Science; Physics	JN0X3		hybrid, Green Submitted			2024-07-03	WOS:001173740400001
J	Crawford, J; Allen, KA; Pani, B; Cowling, M				Crawford, Joseph; Allen, Kelly-Ann; Pani, Bianca; Cowling, Michael			When artificial intelligence substitutes humans in higher education: the cost of loneliness, student success, and retention	STUDIES IN HIGHER EDUCATION			English	Article						AI; ChatGPT; chatbot; intention to leave; sense of belonging; university students	ADJUSTMENT; ENGAGEMENT; VALIDITY; BELONG; SCHOOL; SCALE; NEED	Artificial intelligence (AI) may be the new-new-norm in a post-pandemic learning environment. There is a growing number of university students using AI like ChatGPT and Bard to support their academic experience. Much of the AI in higher education research to date has focused on academic integrity and matters of authorship; yet, there may be unintended consequences beyond these concerns for students. That is, there may be people who reduce their formal social interactions while using these tools. This study evaluates 387 university students and their relationship to - and with - artificial intelligence large-language model-based tools. Using structural equation modelling, the study finds evidence that while AI chatbots designed for information provision may be associated with student performance, when social support, psychological wellbeing, loneliness, and sense of belonging are considered it has a net negative effect on achievement. This study tests an AI-specific form of social support, and the cost it may pose to student success, wellbeing, and retention. Indeed, while AI chatbot usage may be associated with poorer social outcomes, human-substitution activity that may be occurring when a student chooses to seek support from an AI rather than a human (e.g. a librarian, professor, or student advisor) may pose interesting learning and teaching policy implications. We explore the implications of this from the lens of student success and belonging.	[Crawford, Joseph] Univ Tasmania, Tasmanian Sch Business & Econ, Launceston, Australia; [Allen, Kelly-Ann; Pani, Bianca] Monash Univ, Fac Educ, Melbourne, Australia; [Cowling, Michael] Cent Queensland Univ, Sch Engn & Technol, Brisbane, Australia; [Crawford, Joseph] Univ Tasmania, Tasmanian Sch Business & Econ, 2 Invermay Rd, Launceston, TAS 7248, Australia	University of Tasmania; Monash University; Central Queensland University; University of Tasmania	Crawford, J (corresponding author), Univ Tasmania, Tasmanian Sch Business & Econ, 2 Invermay Rd, Launceston, TAS 7248, Australia.	joseph.crawford@utas.edu.au	Crawford, Joseph/J-6397-2019	Crawford, Joseph/0000-0002-2191-6216				Alneyadi S, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13417; Anderson-Butcher D, 2002, EDUC PSYCHOL MEAS, V62, P857, DOI 10.1177/001316402236882; Bartolic SK, 2022, EDUC REV, V74, P517, DOI 10.1080/00131911.2021.1955830; BAUMEISTER RF, 1995, PSYCHOL BULL, V117, P497, DOI 10.1037/0033-2909.117.3.497; Bearman M, 2023, HIGH EDUC, V86, P369, DOI 10.1007/s10734-022-00937-2; Bell S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313072; Bewick B, 2010, STUD HIGH EDUC, V35, P633, DOI 10.1080/03075070903216643; Bond M, 2024, INT J EDUC TECHNOL H, V21, DOI 10.1186/s41239-023-00436-z; Brandtzaeg PB, 2022, HUM COMMUN RES, V48, P404, DOI 10.1093/hcr/hqac008; Brown JEH, 2021, SSM-MENT HEALTH, V1, DOI 10.1016/j.ssmmh.2021.100017; Brunet-Gouet E., 2023, ZENODO, DOI [10.5281/zenodo.7637476, DOI 10.5281/ZENODO.7637476]; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2024, STUD HIGH EDUC, V49, P395, DOI 10.1080/03075079.2023.2238006; Crawford JA, 2019, LEADERSHIP QUART, V30, P133, DOI 10.1016/j.leaqua.2018.07.001; Cresswell K, 2018, J MED INTERNET RES, V20, DOI 10.2196/10410; Dawson P., 2020, Defending assessment security in a digital world: Preventing e-cheating and supporting academic integrity in higher education; de Graaf MMA, 2016, INT J SOC ROBOT, V8, P589, DOI 10.1007/s12369-016-0368-5; Diehl K, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15091865; Dosovitsky G, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.735053; Eager B, 2023, J UNIV TEACH LEARN P, V20; Escotet M.A., 2023, Prospects, P1, DOI [10.1007/s11125-023-09642-z, DOI 10.1007/S11125-023-09642-Z]; Essel HB, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00362-6; Fowler P.R., 2010, Journal of Developmental Education, V34, P2; Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782; Gao LLY, 2024, STUD HIGH EDUC, DOI 10.1080/03075079.2024.2323571; Gillen-O'Neel C, 2021, RES HIGH EDUC, V62, P45, DOI 10.1007/s11162-019-09570-y; Gomes C, 2021, J INT STUDENTS, V11, P19; Gopalan M, 2022, J ADOLESCENT HEALTH, V70, P228, DOI 10.1016/j.jadohealth.2021.10.010; Hayes Sarah., 2024, POSTDIGITAL SCI EDUC, DOI [http://doi.org/10.1007/s42438-024-00459-3, DOI 10.1007/S42438-024-00459-3]; Hu B, 2023, COMPUT HUM BEHAV, V145, DOI 10.1016/j.chb.2023.107760; Hu K., 2023, Reuters; Ivanov S, 2023, SERV IND J, V43, P1055, DOI 10.1080/02642069.2023.2258799; Kahu ER, 2018, HIGH EDUC RES DEV, V37, P58, DOI 10.1080/07294360.2017.1344197; Kalkbrenner MT, 2021, J COLL STUD RETENT-R, V23, P636, DOI 10.1177/1521025119867639; Kelly A, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.6.12; Kelly ME, 2017, SYST REV-LONDON, V6, DOI 10.1186/s13643-017-0632-2; Kerper L.F., 2014, CLIN HLTH PROMOTION, V4, P5, DOI [10.29102/clinhp.14002, DOI 10.29102/CLINHP.14002]; Kift S, 2010, INT J FIRST YEAR HIG, V1, P1, DOI 10.5204/intjfyhe.v1i1.13; Kim J, 2021, TELEMAT INFORM, V64, DOI 10.1016/j.tele.2021.101694; Knox M. W., 2020, J APPL LEARNING TEAC, V3, P108, DOI DOI 10.37074/JALT.2020.3.S1.12; Laestadius L, 2022, NEW MEDIA SOC, DOI 10.1177/14614448221142007; Lee CYS, 2016, J YOUTH ADOLESCENCE, V45, P568, DOI 10.1007/s10964-015-0395-9; Liu H, 2022, INTERNET INTERV, V27, DOI 10.1016/j.invent.2022.100495; Lodge Jason., 2023, J UNIV TEACH LEARN P, V20, DOI [http://doi.org/10.53761/1.20.7.02, DOI 10.53761/1.20.7.02]; Loveys K, 2019, J MED INTERNET RES, V21, DOI 10.2196/13664; Ma Y., 2018, MWAIS 2018 P, V42; Maunder RE, 2018, J FURTH HIGH EDUC, V42, P756, DOI 10.1080/0309877X.2017.1311996; Meehan C, 2019, J FURTH HIGHER EDUC, V43, P1376, DOI 10.1080/0309877X.2018.1490702; Mishra S, 2020, EDUC RES REV-NETH, V29, DOI 10.1016/j.edurev.2019.100307; Nguyen A, 2024, STUD HIGH EDUC, V49, P847, DOI 10.1080/03075079.2024.2323593; Nieuwoudt JE, 2023, J COLL STUD RETENT-R, V25, P326, DOI 10.1177/1521025120985228; OKeeffe P., 2013, J Coll Stud, V47, P605, DOI DOI 10.1016/J.IJME.2014.01.003; Ouyang F, 2022, EDUC INF TECHNOL, V27, P7893, DOI 10.1007/s10639-022-10925-9; Pani B., 2023, APPL GENERATIVE AI; Park C, 2020, PSYCHIAT RES, V294, DOI 10.1016/j.psychres.2020.113514; Park JS, 2023, ARXIV; PEARSON JE, 1986, J COUNS DEV, V64, P390, DOI 10.1002/j.1556-6676.1986.tb01144.x; Pedler ML, 2022, J FURTH HIGHER EDUC, V46, P397, DOI 10.1080/0309877X.2021.1955844; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pesonen J. A., 2021, LEARNING COLLABORATI; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Russell DW, 1996, J PERS ASSESS, V66, P20, DOI 10.1207/s15327752jpa6601_2; Schall J, 2016, INT J ADOLESC YOUTH, V21, P462, DOI 10.1080/02673843.2013.866148; Seo K, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00292-9; Sepahpour T., 2020, RES REV INT J MULTID, V4, P14; Sjöberg A, 2000, SCAND J PSYCHOL, V41, P247, DOI 10.1111/1467-9450.00194; Stevens N, 2001, AGEING SOC, V21, P183, DOI 10.1017/S0144686X01008108; Stickley A, 2015, PUBLIC HEALTH, V129, P403, DOI 10.1016/j.puhe.2014.12.021; Sullivan Y., 2023, COMBATING LONELINESS; Ta V, 2020, J MED INTERNET RES, V22, DOI 10.2196/16235; Tice D, 2021, J UNIV TEACH LEARN P, V18; Tinto V., 1990, Journal of the Freshman Year experience, V2, P35; Turkle Sherry, 2011, ALONE TOGETHER WHY W; Tyrer S, 2016, BJPSYCH BULL, V40, P57, DOI 10.1192/pb.bp.114.050203; Ulmanen S, 2016, INT J EDUC RES, V79, P86, DOI 10.1016/j.ijer.2016.06.003; UNESCO, 2023, HIGH ED WHAT YOU NEE; van Rooij ECM, 2017, LEARN INDIVID DIFFER, V54, P9, DOI 10.1016/j.lindif.2017.01.004; Varrella S., 2021, STATISTA        1104; Vincent-Lancrin S., 2020, Trustworthy Artificial Intelligence (AI) in Education: Promises and Challenges; Wang T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116716; Wang Y, 2022, J NURS MANAGE, V30, P3827, DOI 10.1111/jonm.13823; Xie TL, 2023, J SERV MANAGE, V34, P806, DOI 10.1108/JOSM-02-2022-0072; Yang S.-C., 2019, Communications in Computer and Information Science, P79, DOI [DOI 10.1007/978-981-15-1758-7_7, 10.1145/3371647.3371659, DOI 10.1145/3371647.3371659]; ZIMET GD, 1988, J PERS ASSESS, V52, P30, DOI 10.1207/s15327752jpa5201_2	85	3	3	98	98	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0307-5079	1470-174X		STUD HIGH EDUC	Stud. High. Educ.	MAY 3	2024	49	5			SI		883	897		10.1080/03075079.2024.2326956	http://dx.doi.org/10.1080/03075079.2024.2326956		MAR 2024	15	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	SX4A9		hybrid			2024-07-03	WOS:001182245400001
J	Yilmaz, E; Can, O				Yilmaz, Erhan; Can, Ozgu			Unveiling Shadows: Harnessing Artificial Intelligence for Insider Threat Detection	ENGINEERING TECHNOLOGY & APPLIED SCIENCE RESEARCH			English	Article						-cybersecurity; insider threats; artificial intelligence		Insider threats pose a significant risk to organizations, necessitating robust detection mechanisms to safeguard against potential damage. Traditional methods struggle to detect insider threats operating within authorized access. Therefore, the use of Artificial Intelligence (AI) techniques is essential. This study aimed to provide valuable insights for insider threat research by synthesizing advanced AI methodologies that offer promising avenues to enhance organizational cybersecurity defenses. For this purpose, this paper explores the intersection of AI and insider threat detection by acknowledging organizations' challenges in identifying and preventing malicious activities by insiders. In this context, the limitations of traditional methods are recognized, and AI techniques, including user behavior analytics, Natural Language Processing (NLP), Large Language Models (LLMs), and Graph-based approaches, are investigated as potential solutions to provide more effective detection mechanisms. For this purpose, this paper addresses challenges such as the scarcity of insider threat datasets, privacy concerns, and the evolving nature of employee behavior. This study contributes to the field by investigating the feasibility of AI techniques to detect insider threats and presents feasible approaches to strengthening organizational cybersecurity defenses against them. In addition, the paper outlines future research directions in the field by focusing on the importance of multimodal data analysis, human-centric approaches, privacy-preserving techniques, and explainable AI.	[Yilmaz, Erhan; Can, Ozgu] Ege Univ, Dept Comp Engn, Izmir, Turkiye; [Yilmaz, Erhan] Kron Technol, Istanbul, Turkiye	Ege University	Yilmaz, E (corresponding author), Ege Univ, Dept Comp Engn, Izmir, Turkiye.; Yilmaz, E (corresponding author), Kron Technol, Istanbul, Turkiye.	erhan.yilmaz@itu.edu.tr	YILMAZ, Erhan/JVP-1474-2024	YILMAZ, Erhan/0000-0002-8042-7367; Can, Ozgu/0000-0002-8064-2905				Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Abu Sulayman IIM, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P169, DOI [10.1109/iemcon.2019.8936183, 10.1109/IEMCON.2019.8936183]; Akutota T., 2017, International Research Journal of Engineering and Technology, V4, P1544; Al-Mhiqani MN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155208; [Anonymous], 2023, CISA31 Jul; [Anonymous], Cyber security breaches survey 2023; [Anonymous], 2022, 2022 Cost of Insider Threats Global Report; [Anonymous], 2022, Verizon26 May; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Eberle W, 2010, J APPL SEC RES, V6, P32, DOI 10.1080/19361610.2011.529413; Endsley MR, 2017, HUM FACTORS, V59, P5, DOI 10.1177/0018720816681350; Ferrag MA, 2024, Arxiv, DOI arXiv:2306.14263; Gamachchi A, 2018, Arxiv, DOI [arXiv:1809.00141, 10.48550/ARXIV.1809.00141, DOI 10.48550/ARXIV.1809.00141]; Garba N., 2021, P INT C INN COMP COM, DOI [10.2139/ssrn.3833744, DOI 10.2139/SSRN.3833744]; Geetha P, 2021, ENG TECHNOL APPL SCI, V11, P6745, DOI 10.48084/etasr.4017; Georgiadou A, 2022, J COMPUT INFORM SYST, V62, P706, DOI 10.1080/08874417.2021.1903367; Gheyas I.A., 2016, Big Data Analytics, Big Data Analytics, V1, DOI [10.1186/s41044-016-0006-0, DOI 10.1186/S41044-016-0006-0]; Greitzer FL, 2019, NCS'19: PROCEEDINGS OF THE NORTHWEST CYBERSECURITY SYMPOSIUM, DOI 10.1145/3332448.3332458; Homoliak I, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3303771; Kanan T., 2023, 2023 INT C INF TECHN, P220, DOI [10.1109/ICIT58056.2023.10225847, DOI 10.1109/ICIT58056.2023.10225847]; Khairi MHH, 2018, ENG TECHNOL APPL SCI, V8, P2724; Kwon T, 2023, Arxiv, DOI [arXiv:2401.02974, 10.48550/arXiv.2401.02974, DOI 10.48550/ARXIV.2401.02974]; Nasir R, 2021, IEEE ACCESS, V9, P143266, DOI 10.1109/ACCESS.2021.3118297; Nurse JRC, 2014, IEEE SEC PRIV WORKS, P214, DOI 10.1109/SPW.2014.38; Omar S., 2013, Int. J. Comput. Appl., V79, P33, DOI [10.5120/13715-1478, DOI 10.5120/13715-1478]; Papernot N, 2018, Arxiv, DOI [arXiv:1803.04765, 10.48550/arXiv.1803.04765]; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; Pratibha, 2018, 2018 21 INT C INF FU, P1, DOI [10.23919/ICIF.2018.8455358, DOI 10.23919/ICIF.2018.8455358]; Raissi-Dehkordi M, 2011, 2011 - MILCOM 2011 MILITARY COMMUNICATIONS CONFERENCE, P1164, DOI 10.1109/MILCOM.2011.6127457; Saxena N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091460; Senator TE, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1393; Sharma B., 2020, P 11 INT C ADV INF T, P1; Taher SS, 2024, ENG TECHNOL APPL SCI, V14, P12822, DOI 10.48084/etasr.6641; Theis M., 2020, report, DOI [10.1184/R1/12363665.v1, DOI 10.1184/R1/12363665.V1]; Xi XY, 2018, INT J SOFTW ENG KNOW, V28, P1637, DOI 10.1142/S0218194018400211; Xiao JC, 2023, IEEE T NETW SERV MAN, V20, P3717, DOI 10.1109/TNSM.2022.3222635; Xuebin Wang, 2018, 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC). Proceedings, P476, DOI 10.1109/DSC.2018.00077; Zaboli A, 2023, Arxiv, DOI arXiv:2311.05462; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	39	0	0	7	7	EOS ASSOC	GASTOUNI	ARCHAIAS ILIDAS 16, GASTOUNI, 27050, GREECE	2241-4487	1792-8036		ENG TECHNOL APPL SCI	Eng. Technol. Appl. Sci. Res.	APR	2024	14	2					13341	13346		10.48084/etasr.6911	http://dx.doi.org/10.48084/etasr.6911			6	Engineering, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Engineering	NC4O2		gold			2024-07-03	WOS:001198238800101
J	Samy, D				Samy, Doaa			From Discourse to Action: Classification of Speech Acts in Legislative Texts	PROCESAMIENTO DEL LENGUAJE NATURAL			Spanish	Article						Language models; Speech Acts; Computational Pragmatics; Legal Text Processing	CONTRACTS; LANGUAGE	Speech acts are basic units of linguistic communication which perform actions through words. Certain types of speech acts are especially significant in legislative texts as they go beyond words revealing intentions aiming at shaping the reality of a society. The linguistic theory proposes different types of speech acts. However, this study focuses on the automatic classification of three types for their relevance in the legislative context including: 1) Assertive acts describing events and reality; 2) directive acts setting regulations and, finally, 3) commissive acts indicating commitment to basic rights and principles. For the training and evaluation, a dataset of 1325 statements was manually labeled and further splitted into train and validation sets (80%-20%). Then, the resulting trained classifiers were further evaluated against a test dataset of 250 statements. Different classifier were trained over three types of models: Classical machine learning models, foundational Large Language Models (LLMs) based on "encoders"; namely RoBERTaLex and BERT and finally, generative models based on "decoders", namely GPT3.5 through a 5 -shot prompt tuning. The classifier based on encoder LLMs (BERT and RoBERTa) outperformed the rest of models. BERT achieved f1 -macro score of 0.85 for all classes and a f1 -micro score of 0.87 (BERT) and 0.86 (RoBERTa).	[Samy, Doaa] Cairo Univ, Cairo, Egypt; [Samy, Doaa] Univ Complutense Madrid, Madrid, Spain	Egyptian Knowledge Bank (EKB); Cairo University; Complutense University of Madrid	Samy, D (corresponding author), Cairo Univ, Cairo, Egypt.; Samy, D (corresponding author), Univ Complutense Madrid, Madrid, Spain.	doaasamy@cu.edu.eg						Amorebieta y Vera J., 2020, Quintu Quimun Revista De linguistica, P1; Arguello J., 2015, P 9 INT AAAI C WEB S, V9, P2; AUSTIN J.L., 1962, Como hacer cosas con palabras; Bach K., 1979, Communication and Speech Acts; Bernal CL, 2007, EUR J LEG STUD, V1, P391; Blom B., 1992, HERMES-Journal of Language and Communication in Business, V5, P83; Canete J., 2020, P PML4DC ICLR 2020; Cao D, 2007, Interpretation, Law and The Construction of Meaning, P65, DOI 10.1007/1-4020-5320-7_4; Carvalho V. R., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P345, DOI 10.1145/1076034.1076094; Cifuentes-Honrubia J.L., 2006, Los actos de habla; Cifuentes-Honrubia J.L., 2009, Estudios de linguistica: Investigaciones linguisticas en el siglo XXI, P45; Durant A., 2016, Language and Law; European Language Grid, 2022, Spanish monolingual corpus from contents of Spanish State Official Gazette. Dataset (Text corpus); Fiorito L., 2006, Metalogicon, V19, P101; Gutierrez-Fandino A, 2021, Arxiv, DOI arXiv:2110.12201; Ibanez-Macias A., 2021, Revista Telematica de Filosofia del Derecho, P3; Janicki EA, 2018, GEORGETOWN LAW J, V107, P201; Kone N., 2020, Open Journal of Modern Linguistics, V10, P813; Kurzon D., 1986, IT IS HEREBY PERFORM; Lopez-Hernandez J., 2005, Anuario de derechos humanos, P455; Lopez-Hernandez J., 2005, Cuadernos Electronicos de Filosofia del Derecho, P1; MacCormick N., 1991, Anuario de Filosofia del derecho, P219; Mast M., 1996, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, P217; McKinney W., 2010, P 9 PYTH SCI C, V445, P51, DOI [DOI 10.25080/MAJORA-92BF1922-00A, 10.25080/MAJORA-92BF1922-00A]; Mey J. L., 2013, Cadernos De Linguagem E Sociedade., V4, P11; Moldovan C., 2011, MAICS, V710, P23; Moreu Carbonell E., 2020, Revista de Derecho Publico: Teoria y Metodo, P313; OpenAI, 2023, ChatGPT Large language model; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101; Robles-Morchon G., 2009, Comunicacion, Lenguaje y Derecho: algunas ideas basicas de la teoria comunicacional del Derecho; Saha T, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851805; Samei B, 2014, LECT NOTES COMPUT SC, V8474, P236, DOI 10.1007/978-3-319-07221-0_28; Samy D., 2020, P WORKSHOP LANGUAGE, P32; Searle JR., 1969, Speech acts: An essay in the philosophy of language; TROSBORG A, 1995, J PRAGMATICS, V23, P31, DOI 10.1016/0378-2166(94)00034-C; Twitchell D.P., 2004, P 9 INT WORKING C LA, P121; Vendler Z., 1980, Speech Act Theory and Pragmatics, P273, DOI DOI 10.1007/978-94-009-8964-1_13; Visconti J, 2009, J PRAGMATICS, V41, P393, DOI 10.1016/j.pragma.2008.06.007; Vosoughi S., 2016, P 10 INT C WEB SOCIA, P711; Weston J., 2022, International Journal of Language and Law, P78; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yin Hua., 2020, International Journal of Languages, Literature and Linguistics, V6, P170; Zhang R., 2011, Proceedings of the 5th AAAI Conference on Analyzing Microtext pp, P86	44	0	0	1	1	SOC ESPANOLA PROCESAMIENTO LENGUAJE NATURAL-SEPLN	ALICANTE	DEPT LENGUAJES & SISTEMAS INFORMATICOS, UNIV ALICANTE, APDO 99, ALICANTE, 03080, SPAIN	1135-5948	1989-7553		PROCES LENG NAT	Proces. Leng. Nat.	MAR	2024		72					109	121		10.26342/2024-72-8	http://dx.doi.org/10.26342/2024-72-8			13	Computer Science, Artificial Intelligence; Linguistics	Emerging Sources Citation Index (ESCI)	Computer Science; Linguistics	MV0H9					2024-07-03	WOS:001196288500006
J	Russe, MF; Reisert, M; Bamberg, F; Rau, A				Russe, Maximilian Frederik; Reisert, Marco; Bamberg, Fabian; Rau, Alexander			Improving the use of LLMs in radiology through prompt engineering: from precision prompts to zero-shot learning	ROFO-FORTSCHRITTE AUF DEM GEBIET DER RONTGENSTRAHLEN UND DER BILDGEBENDEN VERFAHREN			English	Article; Early Access						radiology; artificial Intelligence; natural Language Processing		<bold>Purpose: </bold>Large language models (LLMs) such as ChatGPT have shown significant potential in radiology. Their effectiveness often depends on prompt engineering, which optimizes the interaction with the chatbot for accurate results. Here, we highlight the critical role of prompt engineering in tailoring the LLMs' responses to specific medical tasks. <bold>Materials and methods: </bold>Using a clinical case, we elucidate different prompting strategies to adapt the LLM ChatGPT using GPT4 to new tasks without additional training of the base model. These approaches range from precision prompts to advanced in-context methods such as few-shot and zero-shot learning. Additionally, the significance of embeddings, which serve as a data representation technique, is discussed. <bold>Results: </bold>Prompt engineering substantially improved and focused the chatbot's output. Moreover, embedding of specialized knowledge allows for more transparent insight into the model's decision-making and thus enhances trust. <bold>Conclusion: </bold>Despite certain challenges, prompt engineering plays a pivotal role in harnessing the potential of LLMs for specialized tasks in the medical domain, particularly radiology. As LLMs continue to evolve, techniques like few-shot learning, zero-shot learning, and embedding-based retrieval mechanisms will become indispensable in delivering tailored outputs.	[Russe, Maximilian Frederik; Reisert, Marco; Bamberg, Fabian; Rau, Alexander] Univ Hosp Freiburg, Dept Radiol, Freiburg, Germany; [Rau, Alexander] Univ Klinikum Freiburg, Dept Diagnost & Intervent Radiol, Klin Radiol, Breisacher Str 64, D-79106 Freiburg, Germany	University of Freiburg; University of Freiburg	Rau, A (corresponding author), Univ Klinikum Freiburg, Dept Diagnost & Intervent Radiol, Klin Radiol, Breisacher Str 64, D-79106 Freiburg, Germany.	alexander.rau@uniklinik-freiburg.de		Rau, Alexander/0000-0001-5881-6043				Amin Kanhai S, 2023, Radiology, V309, pe232561, DOI 10.1148/radiol.232561; [Anonymous], OpenAI Platform [Internet]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; dos Santos DP, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0777-8; Geis JR, 2019, RADIOLOGY, V293, P436, DOI 10.1148/radiol.2019191586; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jin Q, 2019, Arxiv, DOI [arXiv:1904.02181, DOI 10.48550/ARXIV.1904.02181]; Keskinbora KH, 2019, J CLIN NEUROSCI, V64, P277, DOI 10.1016/j.jocn.2019.03.001; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Medenilla A., 2023, PLoS Digital Health, V2; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Schmidt S, 2024, ARCH ORTHOP TRAUM SU, V144, P611, DOI 10.1007/s00402-023-05113-4; Sushil M, 2023, Arxiv, DOI [arXiv:2308.03853, 10.48550/arXiv.2308.03853, DOI 10.48550/ARXIV.2308.03853]; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Ye S, 2023, Arxiv, DOI arXiv:2302.14691	19	5	5	14	14	GEORG THIEME VERLAG KG	STUTTGART	RUDIGERSTR 14, D-70469 STUTTGART, GERMANY	1438-9029	1438-9010		ROFO-FORTSCHR RONTG	Rofo-Fortschr. Gebiet Rontgenstrahlen Bildgeb. Verfahr.	2024 FEB 26	2024										10.1055/a-2264-5631	http://dx.doi.org/10.1055/a-2264-5631		FEB 2024	5	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	KE6J9	38408477	Bronze			2024-07-03	WOS:001178318200006
J	Huang, DL; Zeng, QL; Xiong, Y; Liu, SX; Pang, CQ; Xia, ML; Fang, T; Ma, YL; Qiang, CC; Zhang, Y; Zhang, Y; Li, H; Yuan, YY				Huang, Dao-Ling; Zeng, Quanlei; Xiong, Yun; Liu, Shuixia; Pang, Chaoqun; Xia, Menglei; Fang, Ting; Ma, Yanli; Qiang, Cuicui; Zhang, Yi; Zhang, Yu; Li, Hong; Yuan, Yuying			A Combined Manual Annotation and Deep-Learning Natural Language Processing Study on Accurate Entity Extraction in Hereditary Disease Related Biomedical Literature	INTERDISCIPLINARY SCIENCES-COMPUTATIONAL LIFE SCIENCES			English	Article; Early Access						Natural language processing; Data mining; Name entity recognition; Genomics	SEQUENCE VARIANTS; RECOGNITION; DATABASE; CLINVAR; TOOL	We report a combined manual annotation and deep-learning natural language processing study to make accurate entity extraction in hereditary disease related biomedical literature. A total of 400 full articles were manually annotated based on published guidelines by experienced genetic interpreters at Beijing Genomics Institute (BGI). The performance of our manual annotations was assessed by comparing our re-annotated results with those publicly available. The overall Jaccard index was calculated to be 0.866 for the four entity types-gene, variant, disease and species. Both a BERT-based large name entity recognition (NER) model and a DistilBERT-based simplified NER model were trained, validated and tested, respectively. Due to the limited manually annotated corpus, Such NER models were fine-tuned with two phases. The F1-scores of BERT-based NER for gene, variant, disease and species are 97.28%, 93.52%, 92.54% and 95.76%, respectively, while those of DistilBERT-based NER are 95.14%, 86.26%, 91.37% and 89.92%, respectively. Most importantly, the entity type of variant has been extracted by a large language model for the first time and a comparable F1-score with the state-of-the-art variant extraction model tmVar has been achieved.	[Huang, Dao-Ling] BGI Res, Shenzhen 518083, Peoples R China; [Huang, Dao-Ling; Yuan, Yuying] BGI Hlth, BGI Shenzhen, Clin Lab, Shenzhen 518083, Peoples R China; [Zeng, Quanlei; Xiong, Yun; Liu, Shuixia; Pang, Chaoqun; Xia, Menglei; Fang, Ting; Ma, Yanli; Qiang, Cuicui; Zhang, Yi; Zhang, Yu; Li, Hong] BGI Shenzhen, BGI Wuhan Clin Labs, Wuhan 430074, Peoples R China	Beijing Genomics Institute (BGI); Beijing Genomics Institute (BGI); Beijing Genomics Institute (BGI)	Huang, DL (corresponding author), BGI Res, Shenzhen 518083, Peoples R China.; Huang, DL (corresponding author), BGI Hlth, BGI Shenzhen, Clin Lab, Shenzhen 518083, Peoples R China.	dlhuang1217@gmail.com	Wang, Fei/KEH-6292-2024; Liu, Donghua/KEJ-1974-2024; WANG, SHIHAO/KHC-8263-2024; Wang, Yuhan/KGL-5855-2024; liu, qi/KFA-4047-2024	Liu, Donghua/0000-0002-5830-9540; 	Innovative Research Group Project of the National Natural Science Foundation of China [32001076]; National Natural Science Foundation of China	Innovative Research Group Project of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (No. 32001076).	Ahern C, 2016, Hum Genet Theses, V15; Allot A, 2018, NUCLEIC ACIDS RES, V46, pW530, DOI 10.1093/nar/gky355; Amberger JS, 2015, NUCLEIC ACIDS RES, V43, pD789, DOI 10.1093/nar/gku1205; Bean LJH, 2016, HUM MUTAT, V37, P559, DOI 10.1002/humu.22982; Buchholz S., 2006, CONLL, P149, DOI [10.5555/1596276.1596305, DOI 10.3115/1596276.1596305]; Chen QY, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007617; Chiu J.P., 2016, Transactions of the Association for Computational Linguistics, V4, P357, DOI [10.1162/tacl_a_00104, 10.1162/tacla00104]; Cho YJ, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3321-4; Colic Nico, 2020, P 1 WORKSHOP NLP COV, DOI [10.18653/v1/2020.nlpcovid19-2.27, DOI 10.18653/V1/2020.NLPCOVID19-2.27]; den Dunnen JT, 2016, HUM MUTAT, V37, P564, DOI 10.1002/humu.22981; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006; Gerner M, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-85; Good BM, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0438-7; Han H, 2023, Arxiv, DOI [arXiv:2305.15734, 10.48550/arXiv.2305.15734, DOI 10.48550/ARXIV.2305.15734]; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351; Kim D, 2019, IEEE ACCESS, V7, P73729, DOI 10.1109/ACCESS.2019.2920708; Kim Jin-Dong, 2004, P INT JOINT WORKSHOP, P70; Köhler S, 2021, NUCLEIC ACIDS RES, V49, pD1207, DOI 10.1093/nar/gkaa1043; Landrum MJ, 2016, NUCLEIC ACIDS RES, V44, pD862, DOI 10.1093/nar/gkv1222; Lappalainen T, 2019, CELL, V177, P70, DOI 10.1016/j.cell.2019.02.032; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee K, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw043; Li JQ, 2020, Arxiv, DOI [arXiv:2010.06133, 10.48550/arXiv.2010.06133, DOI 10.48550/ARXIV.2010.06133]; Li Q, 2017, AM J HUM GENET, V100, P267, DOI 10.1016/j.ajhg.2017.01.004; Morgan AA, 2008, GENOME BIOL, V9, DOI [10.1186/gb-2008-9-s2-s3, 10.1186/gb-2008-9-S2-S3]; Richards S, 2015, GENET MED, V17, P405, DOI 10.1038/gim.2015.30; Rohanian O, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad103; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schriml LM, 2019, NUCLEIC ACIDS RES, V47, pD955, DOI 10.1093/nar/gky1032; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Sachan DS, 2018, Arxiv, DOI [arXiv:1711.07908, 10.48550/arXiv.1711.07908, DOI 10.48550/ARXIV.1711.07908]; Song HJ, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0573-6; Song M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S1-S9; Sun S., 2019, arXiv; Sung M, 2022, BIOINFORMATICS, V38, P4837, DOI 10.1093/bioinformatics/btac598; Vasilevsky N.A., 2022, medRxiv, DOI DOI 10.1101/2022.04.13.22273750; Villarreal Goulart Rodrigo Rafael, 2011, J Braz Comput Soc, V17, P103, DOI DOI 10.1007/S13173-011-0031-9; Wang X, 2019, BIOINFORMATICS, V35, P1745, DOI 10.1093/bioinformatics/bty869; Weber L, 2021, BIOINFORMATICS, V37, P2792, DOI 10.1093/bioinformatics/btab042; Wei CH, 2019, NUCLEIC ACIDS RES, V47, pW587, DOI 10.1093/nar/gkz389; Wei CH, 2018, BIOINFORMATICS, V34, P80, DOI 10.1093/bioinformatics/btx541; Wei CH, 2015, BIOMED RES INT-UK, V2015, DOI 10.1155/2015/918710; Wei CH, 2013, NUCLEIC ACIDS RES, V41, pW518, DOI 10.1093/nar/gkt441; Weinreich S S, 2008, Ned Tijdschr Geneeskd, V152, P518; Xu K, 2019, COMPUT BIOL MED, V108, P122, DOI 10.1016/j.compbiomed.2019.04.002; Yadav V., 2019, arXiv	48	0	0	9	9	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1913-2751	1867-1462		INTERDISCIP SCI	Interdiscip. Sci.	2024 FEB 10	2024										10.1007/s12539-024-00605-2	http://dx.doi.org/10.1007/s12539-024-00605-2		FEB 2024	12	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	HL1Q5	38340264	hybrid			2024-07-03	WOS:001159572300001
J	Kong, SC; Lee, JCK; Tsang, O				Kong, Siu-Cheung; Lee, John Chi -Kin; Tsang, Olson			A pedagogical design for self-regulated learning in academic writing using text-based generative artificial intelligence tools: 6-P pedagogy of plan, prompt, preview, produce, peer-review, portfolio-tracking	RESEARCH AND PRACTICE IN TECHNOLOGY ENHANCED LEARNING			English	Article						6-P pedagogy; Academic writing; Artificial intelligence literacy; ChatGPT; Critical thinking; Pedagogical design; Self -regulated learning	CRITICAL THINKING; ACHIEVEMENT; PREDICTORS; LITERACY; QUALITY; SKILLS	The emergence and popularity of generative artificial intelligence (AI) tools, particularly text-based ones known as large language models, pose both opportunities and challenges to education. The ability of these tools to generate human-like texts based on minimal instructions causes concerns among educators about students' use of these tools for academic writing, which may constitute a breach of academic integrity. We propose a pedagogical design that models on selfregulated learning and the authoring cycle and develops students' critical thinking and self-regulation when composing academic writing using text-based generative AI tools. It contains six iterative and interactive phases. Students first plan the content and structure of the writing, then generate prompts for text-based generative AI tools. Next, students preview and verify the tools' output, followed by the fourth phase of producing the writing using the corrected output. Fifthly, peer review by fellow students may be required to polish and proofread the writing. Lastly, through portfolio-tracking, students reflect on the writing process, and formulate strategies for future usage of text-based generative AI tools for writing. This pedagogical design helps students and teachers embrace text-based generative AI while addressing the perils these tools present, and guides the development of education interventions and instruments.	[Kong, Siu-Cheung] Educ Univ Hong Kong, Dept Math & Informat Technol, Hong Kong, Peoples R China; [Lee, John Chi -Kin] Educ Univ Hong Kong, Dept Curriculum & Instruct, Hong Kong, Peoples R China; [Tsang, Olson] Educ Univ Hong Kong, Artificial Intelligence & Digital Competency Educ, Hong Kong, Peoples R China	Education University of Hong Kong (EdUHK); Education University of Hong Kong (EdUHK); Education University of Hong Kong (EdUHK)	Kong, SC (corresponding author), Educ Univ Hong Kong, Dept Math & Informat Technol, Hong Kong, Peoples R China.	sckong@eduhk.hk		LEE, Chi Kin John/0000-0002-3235-0967				Anwar YAS, 2022, BIOCHEM MOL BIOL EDU, V50, P502, DOI 10.1002/bmb.21655; Araka E, 2020, RES PRACT TECH ENHAN, V15, DOI 10.1186/s41039-020-00129-5; Atlas S, 2023, ChatGPT for higher education and professional development: A guide to conversational AI, P41; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Bavli B, 2023, INTERACT LEARN ENVIR, V31, P7040, DOI 10.1080/10494820.2022.2061005; Biswas G., 2018, Handbook of self-regulation of learning and performance, V2nd, P388, DOI [DOI 10.4324/9781315697048-25, 10.4324/9781315697048-25]; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bouschery SG, 2023, J PROD INNOVAT MANAG, V40, P139, DOI 10.1111/jpim.12656; Buckley S, 2009, MED TEACH, V31, P340, DOI 10.1080/01421590902889897; Carless D, 2022, ACT LEARN HIGH EDUC, V23, P143, DOI 10.1177/1469787420945845; Casal E. J., 2023, RES METHODS APPL LIN, V2, P100068; Chan CKY, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00411-8; Chou CY, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00233-y; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Desaire H, 2023, CELL REP PHYS SCI, V4, DOI 10.1016/j.xcrp.2023.101426; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00140-5; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; FLOWER L., 1989, Planning in writing: The Cognition of a Constructive Process; Flynn LR., 2013, Case studies for ethics in academic research in the social sciences, P19, DOI DOI 10.4135/9781452269986; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Glogger I, 2012, J EDUC PSYCHOL, V104, P452, DOI 10.1037/a0026683; Halpern DF, 1998, AM PSYCHOL, V53, P449, DOI 10.1037/0003-066X.53.4.449; Hill G, 2021, RES PRACT TECH ENHAN, V16, DOI 10.1186/s41039-021-00166-8; Hounsell D., 1984, Higher Education Research and Development, V3, P13, DOI DOI 10.1080/0729436840030102; Huisman B, 2019, ASSESS EVAL HIGH EDU, V44, P863, DOI 10.1080/02602938.2018.1545896; Irvin L., 2010, Writing spaces: Readings on writing, V1, P3; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kaur D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491209; Kim YS, 2013, EARLY CHILD RES Q, V28, P461, DOI 10.1016/j.ecresq.2013.01.001; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Kong S.-C., 2023, Working Paper; Kong SC, 2021, Comput. Educ, V2, DOI DOI 10.1016/J.CAEAI.2021.100026; Kong SC, 2014, COMPUT EDUC, V78, P160, DOI 10.1016/j.compedu.2014.05.009; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Li Y., 2023, Comput. Educ.., V4, DOI [DOI 10.1016/J.CAEAI.2023.100140, 10.1016/j.caeai.2023.100140]; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Luitse D, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211047734; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Mejia-Domenzain P, 2022, IEEE T LEARN TECHNOL, V15, P579, DOI 10.1109/TLT.2022.3195881; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Mouratidis A, 2013, LEARN INDIVID DIFFER, V23, P179, DOI 10.1016/j.lindif.2012.09.001; National Writing Project, 2010, Because digital writing matters: Improving student writing in online and multimedia environments, P41; Noroozi O, 2023, INTERACT LEARN ENVIR, V31, P6302, DOI 10.1080/10494820.2022.2034887; Nückles M, 2020, EDUC PSYCHOL REV, V32, P1089, DOI 10.1007/s10648-020-09541-1; Panadero E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00422; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pintrich PR, 2004, EDUC PSYCHOL REV, V16, P385, DOI 10.1007/s10648-004-0006-x; Procter L, 2020, REFLECT PRACT, V21, P444, DOI 10.1080/14623943.2020.1773421; Rampersad G, 2020, J BUS RES, V116, P68, DOI 10.1016/j.jbusres.2020.05.019; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Saqr M, 2021, RES PRACT TECH ENHAN, V16, DOI 10.1186/s41039-021-00175-7; Schmid Richard F., 2009, Journal of Computing in Higher Education, V21, P95, DOI 10.1007/s12528-009-9021-8; Shepherd SJ, 2007, INT J INFORM MANAGE, V27, P3, DOI 10.1016/j.ijinfomgt.2006.06.005; Short K.G., 2009, Taking the PYP forward, P11; Short K.G., 1996, CREATING CLASSROOMS; Sison AJG, 2023, INT J HUM-COMPUT INT, DOI 10.1080/10447318.2023.2225931; Stahl BC, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102700; Su YF, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100752; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tyson J, 2023, J CHEM EDUC, V100, P3098, DOI 10.1021/acs.jchemed.3c00361; Uhlenbrook S, 2012, HYDROL EARTH SYST SC, V16, P3475, DOI 10.5194/hess-16-3475-2012; Vardi, 2015, PALGRAVE HDB CRITICA, P197, DOI DOI 10.1057/9781137378057_13; Walters WH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41032-5; Wolters CA, 2021, EDUC PSYCHOL REV, V33, P1319, DOI 10.1007/s10648-020-09519-z; Wong A, 2014, MED EDUC, V48, P489, DOI 10.1111/medu.12382; Woods H. B., 2023, ASTROPHYS J, V7, P82, DOI DOI 10.12688/WELLCOMEOPENRES.17715.2; Zhu JX, 2018, EDUC PSYCHOL-UK, V38, P1106, DOI 10.1080/01443410.2018.1497775; Zimmerman BJ, 2002, THEOR PRACT, V41, P64, DOI 10.1207/s15430421tip4102_2	76	1	1	68	68	ASIA PACIFIC SOC COMPUTERS IN EDUCATION - APSCE	 TAOYUAN CITY	NO 300, JUNGDA RD, JHONGLI DISTRICT,  TAOYUAN CITY, TAIWAN		1793-7078		RES PRACT TECH ENHAN	Res. Pract. Technol. Enhanc. Learn.	JAN 1	2024	19								p030	10.58459/rptel.2024.19030	http://dx.doi.org/10.58459/rptel.2024.19030			18	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IN3D3		gold			2024-07-03	WOS:001166957200001
J	Yoon, W; Yi, S; Jackson, R; Kim, H; Kim, S; Kang, JW				Yoon, Wonjin; Yi, Sean; Jackson, Richard; Kim, Hyunjae; Kim, Sunkyu; Kang, Jaewoo			Biomedical relation extraction with knowledge base-refined weak supervision	DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION			English	Article								Biomedical relation extraction (BioRE) is the task of automatically extracting and classifying relations between two biomedical entities in biomedical literature. Recent advances in BioRE research have largely been powered by supervised learning and large language models (LLMs). However, training of LLMs for BioRE with supervised learning requires human-annotated data, and the annotation process often accompanies challenging and expensive work. As a result, the quantity and coverage of annotated data are limiting factors for BioRE systems. In this paper, we present our system for the BioCreative VII challenge-DrugProt track, a BioRE system that leverages a language model structure and weak supervision. Our system is trained on weakly labelled data and then fine-tuned using human-labelled data. To create the weakly labelled dataset, we combined two approaches. First, we trained a model on the original dataset to predict labels on external literature, which will become a model-labelled dataset. Then, we refined the model-labelled dataset using an external knowledge base. Based on our experiment, our approach using refined weak supervision showed significant performance gain over the model trained using standard human-labelled datasets. Our final model showed outstanding performance at the BioCreative VII challenge, achieving 3rd place (this paper focuses on our participating system in the BioCreative VII challenge).	[Yoon, Wonjin; Yi, Sean; Kim, Hyunjae; Kim, Sunkyu; Kang, Jaewoo] Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 02841, South Korea; [Jackson, Richard] AstraZeneca UK, 1 Francis Crick Ave, Cambridge CB2 0AA, England; [Kim, Sunkyu; Kang, Jaewoo] AIGEN Sci Inc, 25 Ttukseom Ro 1 Gil, Seoul 04778, South Korea	Korea University; AstraZeneca	Kang, JW (corresponding author), Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 02841, South Korea.; Kang, JW (corresponding author), AIGEN Sci Inc, 25 Ttukseom Ro 1 Gil, Seoul 04778, South Korea.	kangj@korea.ac.kr		Kang, Jaewoo/0000-0001-6798-9106; Kim, Sunkyu/0000-0002-0240-6210; Kim, Hyunjae/0000-0003-2996-2564	National Research Foundation of Korea [NRF-2020R1A2C3010638, NRF-2014M3C9A3063541]; ICT Creative Consilience program [IITP-2022-2020-0-01 819]; Korea Health Technology Ramp;D Project through the Korea Health Industry Development Institute - Ministry of Health amp; Welfare, Republic of Korea [HR20C0021]	National Research Foundation of Korea(National Research Foundation of Korea); ICT Creative Consilience program; Korea Health Technology Ramp;D Project through the Korea Health Industry Development Institute - Ministry of Health amp; Welfare, Republic of Korea	National Research Foundation of Korea (NRF-2020R1A2C3010638, NRF-2014M3C9A3063541); ICT Creative Consilience program (IITP-2022-2020-0-01 819); Korea & nbsp;Health Technology R & amp;D Project (HR20C0021) through the Korea Health Industry Development Institute, funded by the Ministry of Health & amp; Welfare, Republic of Korea.	Bach SH, 2019, INT CONF MANAGE DATA, P362, DOI 10.1145/3299869.3314036; Baptista D, 2021, BRIEF BIOINFORM, V22, P360, DOI 10.1093/bib/bbz171; Bravo A, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0472-9; Christopoulou F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P11; Davis AP, 2021, NUCLEIC ACIDS RES, V49, pD1138, DOI 10.1093/nar/gkaa891; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Giorgi J, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P10; Gonzalez-Hernandez G, 2022, DATABASE-OXFORD, V2022, DOI 10.1093/database/baac071; Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011; Jiang HM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1775; Kim D, 2019, IEEE ACCESS, V7, P73729, DOI 10.1109/ACCESS.2019.2920708; Krallinger M., 2017, P 6 BIOCREATIVE CHAL, V1, P141; Lai PT, 2020, BIOINFORMATICS, V36, P5678, DOI 10.1093/bioinformatics/btaa1087; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis Patrick, 2020, P 3 CLIN NATURAL LAN, P146, DOI 10.18653/v1/2020.clinicalnlp-1.17; Luo Ling, 2022, Dis Markers, V2022, P8446170, DOI 10.1155/2022/8446170; Luo L, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac282; Milosevic N, 2023, J WEB SEMANT, V75, DOI 10.1016/j.websem.2022.100756; Mintz M, 2009, P JOINT C 47 ANN M A, P1003; Miranda A., 2021, P 7 BIOCREATIVE CHAL; Peng Y., 2016, J CHEMINF, V8, P1; Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101; Segura-Bedmar I, 2013, P 7 INT WORKSH SEM E, V2, P341; Shang JB, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2054; Shin HC, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4700; Tweedie S, 2021, NUCLEIC ACIDS RES, V49, pD939, DOI 10.1093/nar/gkaa980; Verga P., 2018, P 2018 C N AM CHAPT, V1, P872, DOI 10.18653/v1/N18-1080; Wang XD, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P298; Weber L., 2022, DATABASE, V2022, P1; Yoon W., 2022, P 2022 C EMP METH NA, P619; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan JB, 2020, KNOWL INF SYST, V62, P317, DOI 10.1007/s10115-019-01351-4; Zhang YH, 2021, J AM MED INFORM ASSN, V28, P1892, DOI 10.1093/jamia/ocab090	33	0	0	1	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1758-0463			DATABASE-OXFORD	Database	JUL 26	2023	2023								baad054	10.1093/database/baad054	http://dx.doi.org/10.1093/database/baad054			10	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	O5VF4	37551911	Green Published, gold			2024-07-03	WOS:001044477000001
C	Mendelsohn, J; Le Bras, R; Choi, Y; Sap, M		Rogers, A; Boyd-Graber, J; Okazaki, N		Mendelsohn, Julia; Le Bras, Ronan; Choi, Yejin; Sap, Maarten			From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Warning: content in this paper may be upsetting or offensive to some readers. Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second one, often hateful or provocative, to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, in the sentence "we need to end the cosmopolitan experiment," the word "cosmopolitan" likely means "worldly" to many, but secretly means "Jewish" to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians' speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3's performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks of such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources for future research in modeling dogwhistles and mitigating their online harms.	[Mendelsohn, Julia] Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA; [Mendelsohn, Julia; Le Bras, Ronan; Choi, Yejin; Sap, Maarten] Allen Inst AI, Seattle, WA 98103 USA; [Choi, Yejin] Univ Washington, Paul G Allen Sch Comp Sci & Engn, Seattle, WA USA; [Sap, Maarten] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA USA	University of Michigan System; University of Michigan; University of Washington; University of Washington Seattle; Carnegie Mellon University	Mendelsohn, J (corresponding author), Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA.; Mendelsohn, J (corresponding author), Allen Inst AI, Seattle, WA 98103 USA.	juliame@umich.edu			Google PhD Fellowship	Google PhD Fellowship(Google Incorporated)	We thank Ceren Budak, Yulia Tsvetkov, and audiences at Text as Data 2022 (TADA) and New Ways of Analyzing Variation 50 (NWAV) for their helpful feedback on an earlier version of this work. We also thank the anonymous reviewers for their comments and suggestions. J.M. gratefully acknowledges support from the Google PhD Fellowship.	Akerlund M, 2022, INFORM COMMUN SOC, V25, P1808, DOI 10.1080/1369118X.2021.1889639; Albertson BL, 2015, POLIT BEHAV, V37, P3, DOI 10.1007/s11109-013-9265-x; Almendros Carla Perez, 2020, P 28 INT C COMP LING, P5891; Arviv Eyal, 2021, P INT AAAI C WEB SOC, V15, P61; Bateman DA, 2016, STUD AM POLIT DEV, V30, P147, DOI 10.1017/S0898588X16000080; Bhat P, 2020, TWITTER PUBLIC SPHER, P151, DOI [10.1007/978-3-030-41421-4_7, DOI 10.1007/978-3-030-41421-4_7]; Botelho A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1896; Breitfeller LM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1664; Breitholtz Ellen, 2021, P REAS INT C REINACT, P40; Burack Emily, 2020, HEY ALMA; Caffier Justin., 2017, Vice; Carda D, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120510119; Carroll R, 2009, POLIT ANAL, V17, P261, DOI 10.1093/pan/mpp005; Caselli T, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6193; Denigot Quentin, 2020, P PROB MEAN C PAM 20; Eckert P, 2008, J SOCIOLING, V12, P453, DOI 10.1111/j.1467-9841.2008.00374.x; ElSherief Mai, 2018, Proceedings of the International AAAI Conference on Web and Social MediaProceedings of the International AAAI Conference on Web and Social Media, V12; ElSherief Mai, 2021, ARXIV210905322; Gehman S, 2020, M ASS FOR COMPUTATIO; Gentzkow M, 2019, ECONOMETRICA, V87, P1307, DOI 10.3982/ECTA16566; Goodin RE, 2005, POLIT QUART, V76, P471, DOI 10.1111/j.1467-923X.2005.00708.x; Han XC, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7732; Haney-Lopez Ian., 2014, DOG WHISTLE POLITICS; Hartvigsen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3309; Henderson R, 2018, LECT NOTES ARTIF INT, V10838, P231, DOI 10.1007/978-3-319-93794-6_16; Henderson Robert, 2020, P PROB MEAN C PAM 20, P73; Henderson Robert, 2019, P 22 AMST C, P152; Hertzberg Niclas, 2022, P 6 WORKSH ONL AB HA, P170; Khoo J., 2017, Philosophical Topics, V45, P33, DOI [10.5840/philtopics201745213, DOI 10.5840/PHILTOPICS201745213]; Lee Rebecca, 2020, HIGH DESERT LINGUIST, V14; Lewis Jeffrey B, 2023, Voteview: Congressional Roll-Call Votes Database; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Magu R, 2018, P 2 WORKSHOP ABUSIVE, P93, DOI 10.18653/v1/W18-5112; Magu Rijul., 2017, P 11 INT C WEB SOCIA, P608; Martino Giovanni Da San, 2020, P 14 WORKSHOP SEMANT, P1377, DOI DOI 10.18653/V1/2020.SEMEVAL-1.186; Mendelberg Tali., 2001, The Race Card: Campaign Strategy, Implicit Messages, and the Norm of Equality; Mendelsohn J, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00055; Menini Stefano, 2021, ARXIV210314916; Moshin Jamie, 2018, J CONT RHETORIC, V8; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; OpenAI, 2023, GPT 4 TECHN REP; Pal Joyojeet, 2018, CEDEM ASIA 2018, P97; POOLE KT, 1985, AM J POLIT SCI, V29, P357, DOI 10.2307/2111172; Qian Jing, 2019, ARXIV190402418; Queen R, 2007, LANG LINGUIST COMPAS, V1, P314, DOI 10.1111/j.1749-818x.2007.00019.x; Röttger P, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P41; Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668; Sap Maarten, 2020, P 58 ANN M ASS COMPU, P5477; Saul J., 2018, New Work on Speech Acts; Smaldino PE, 2022, PSYCHOL REV, V129, P812, DOI 10.1037/rev0000344; Smaldino PE, 2018, SCI REP-UK, V8, DOI [10.1038/s41598-018-22926-1, 10.1038/s41598-018-30248-5]; Thompson AndrewIfedapo., 2021, POLIT BEHAV, P1; Tilley Brian P., 2020, PSYCHOLOGY, V11, P1941, DOI [10.4236/psych.2020.1112123, DOI 10.4236/PSYCH.2020.1112123]; van der Does T, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2117898119; Wetts Rachel, 2019, Socius, V5; Wiegand M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P576; Wiegand M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P358; Xu CW, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2139; Yang F, 2016, NEW MEDIA SOC, V18, P1364, DOI 10.1177/1461444814555951; Zhou Xuhui, 2023, FINDINGS ACL	61	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15162	15180						19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962506050
J	Awais, M; Nawab, RMA				Awais, Muhammad; Muhammad Adeel Nawab, Rao			Abstractive Text Summarization for the Urdu Language: Data and Methods	IEEE ACCESS			English	Article						Task analysis; Long short term memory; Deep learning; Benchmark testing; Social networking (online); Convolutional neural networks; Natural language processing; Abstracts; Text detection; Artificial intelligence; Publishing; Unsupervised learning; Machine learning; Text analysis; Text summarization; Abstractive text summarization; BART; corpus; deep learning models; GPT-3.5; large language models; Urdu		The task of abstractive text summarization aims to automatically generate a short and concise summary of a given source article. In recent years, automatic abstractive text summarization has attracted the attention of researchers because large volumes of digital text are readily available in multiple languages on a wide range of topics. Automatically generating precise summaries from large text has potential application in the generation of news headlines, a summary of research articles, the moral of the stories, media marketing, search engine optimization, financial research, social media marketing, question-answering systems, and chatbots. In literature, the problem of abstractive text summarization has been mainly investigated for English and some other languages. However, it has not been thoroughly explored for the Urdu language despite having a huge amount of data available in digital format. To fulfill this gap, this paper presents a large benchmark corpus of 2,067,784 Urdu news articles for the Urdu abstractive text summarization task. As a secondary contribution, we applied a range of deep learning (LSTM, Bi-LSTM, LSTM with attention, GRU, Bi-GRU, and GRU with attention), and large language models (BART and GPT-3.5) on our proposed corpus. Our extensive evaluation on 20,000 test instances showed that GRU with attention model outperforms the other models with ROUGE- 1 = 46.7 , ROUGE- 2 = 24.1 , and ROUGE-L = 48.7. To foster research in Urdu, our proposed corpus is publically and freely available for research purposes under the Creative Common Licence.	[Awais, Muhammad; Muhammad Adeel Nawab, Rao] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore 54000, Pakistan	COMSATS University Islamabad (CUI)	Awais, M (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore 54000, Pakistan.	sp19-pcs-012@cuilahore.edu.pk						Akiyama K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P159; Al-Radaideh QA, 2018, COGN COMPUT, V10, P651, DOI 10.1007/s12559-018-9547-z; Al-Sabahi K, 2018, Arxiv, DOI arXiv:1809.06662; Alexandr Nikolich, 2021, DATA SCI INTELLIGENT, V2, P748, DOI [DOI 10.1007/978-3-030-90321-3_61, 10.1007/978-3-030-90321-3_61]; Ali MNA, 2019, ARAB J SCI ENG, V44, P9693, DOI 10.1007/s13369-019-04068-2; Amodei D, 2016, Arxiv, DOI arXiv:1606.06565; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chopra S., 2016, P 2016 C N AM CHAPTE, P93, DOI [10.18653/v1/n16-1012, DOI 10.18653/V1/N16-1012]; Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458; Cui YM, 2016, Arxiv, DOI arXiv:1512.00177; Daud A, 2017, ARTIF INTELL REV, V47, P279, DOI 10.1007/s10462-016-9482-x; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong Y, 2020, Arxiv, DOI arXiv:2010.02443; Farahani M, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420563; Filippova K., 2015, P 2015 C EMP METH NA, P360, DOI DOI 10.18653/V1/D15-1042; Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9; Gehrmann S, 2018, Arxiv, DOI arXiv:1808.10792; Goyal A, 2016, ADV NEUR IN, V29; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Grusky M, 2020, Arxiv, DOI arXiv:1804.11283; Gu JT, 2016, Arxiv, DOI [arXiv:1603.06393, 10.48550/arXiv.1603.06393]; Gunel B, 2020, Arxiv, DOI arXiv:2006.15435; Gusev I, 2020, AINL 2020 ARTIFICIAL, P122, DOI [10.1007/978-3-030-59082-6_9, DOI 10.1007/978-3-030-59082-69]; Haider S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P964; Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693, DOI DOI 10.48550/ARXIV.1506.03340; Hu BT, 2016, Arxiv, DOI [arXiv:1506.05865, DOI 10.48550/ARXIV.1506.05865]; Humayoun M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P796; Hussain N., 2021, Mendeley Data, DOI [10.17632/834vsxnb99.3.[42]Y., DOI 10.17632/834VSXNB99.3.[42]Y]; Jobson E., 2016, Abstractive text summarization using attentive sequence-to-sequence RNNs, P8; Koupaee M, 2018, Arxiv, DOI arXiv:1810.09305; Kryscinski W, 2018, Arxiv, DOI arXiv:1808.07913; La Quatra M, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15010015; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lin JY, 2018, Arxiv, DOI arXiv:1805.03989; Lins RD, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345388; Liu F, 2018, Arxiv, DOI arXiv:1805.10399; Lopyrev K, 2015, Arxiv, DOI arXiv:1512.01712; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Rush AM, 2015, Arxiv, DOI [arXiv:1509.00685, DOI 10.18653/V1/D15-1044]; Mozzherina E, 2013, COMM COM INF SC, V394, P83; Nallapati R, 2016, Arxiv, DOI [arXiv:1602.06023, DOI 10.48550/ARXIV.1602.06023]; Nan F, 2021, Arxiv, DOI arXiv:2102.09130; Napoles C., 2012, P JOINT WORKSHOP AUT, V95, P100; Naseer S., 2009, Tech. Rep.; Nawaz A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102383; Niu JW, 2019, IEEE ICC, DOI DOI 10.1109/icc.2019.8762040; Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019; Patel A., 2018, Int.J. Adv. Res. Comput. Commun. Eng., V7, P194; Paulus R, 2017, Arxiv, DOI [arXiv:1705.04304, 10.48550/arXiv.1705.04304]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rahman T., 2004, PROC SCALLA C COMPUT, V99, P1; Sandhaus E., 2008, The New York Times Annotated Corpus', V6, P26752; See A, 2017, arXiv; Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3; Suleiman D, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107791; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Xu J, 2019, arXiv; Zhao Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P170	59	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						61198	61210		10.1109/ACCESS.2024.3378300	http://dx.doi.org/10.1109/ACCESS.2024.3378300			13	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	PL6V5		gold			2024-07-03	WOS:001214282400001
J	Bozyigit, F; Bardakci, T; Khalilipour, A; Challenger, M; Ramackers, G; Babur,Ö; Chaudron, MRV				Bozyigit, Fatma; Bardakci, Tolgahan; Khalilipour, Alireza; Challenger, Moharram; Ramackers, Guus; Babur, Onder; Chaudron, Michel R. V.			Generating domain models from natural language text using NLP: a benchmark dataset and experimental comparison of tools	SOFTWARE AND SYSTEMS MODELING			English	Article; Early Access						Software functional requirements; Software models; Text-to-model transformation; Benchmark dataset	CONCEPTUAL MODELS; SOFTWARE REQUIREMENTS; USER STORIES; UML MODELS	Software requirements specification describes users' needs and expectations on some target system. Requirements documents are typically represented by unstructured natural language text. Such texts are the basis for the various subsequent activities in software development, such as software analysis and design. As part of software analysis, domain models are made that describe the key concepts and relations between them. Since the analysis process is performed manually by business analysts, it is time-consuming and may introduce mistakes. Recently, researchers have worked toward automating the synthesis of domain models from textual software requirements. Current studies on this topic have limitations in terms of the volume and heterogeneity of experimental datasets. To remedy this, we provide a curated dataset of software requirements to be utilized as a benchmark by algorithms that transform textual requirements documents into domain models. We present a detailed evaluation of two text-to-model approaches: one based on a large-language model (ChatGPT) and one building on grammatical rules (txt2Model). Our evaluation reveals that both tools yield promising results with relatively high F-scores for modeling the classes, attributes, methods, and relationships, with txt2Model performing better than ChatGPT on average. Both tools have relatively lower performance and high variance when it comes to the relation types. We believe our dataset and experimental evaluation pave to way to advance the field of automated model generation from requirements.	[Bozyigit, Fatma; Bardakci, Tolgahan; Khalilipour, Alireza; Challenger, Moharram] Univ Antwerp, Dept Comp Sci, Antwerp, Belgium; [Bozyigit, Fatma; Khalilipour, Alireza; Challenger, Moharram] Flanders Make Strateg Res Ctr, AnSyMo CoSys Core Lab, Lommel, Belgium; [Ramackers, Guus] Leiden Univ, Leiden Inst Adv Comp Sci LIACS, Leiden, Netherlands; [Babur, Onder] Wageningen Univ & Res, Informat Technol Grp, Wageningen, Netherlands; [Babur, Onder; Chaudron, Michel R. V.] Eindhoven Univ Technol, Dept Math & Comp Sci, Eindhoven, Netherlands	University of Antwerp; Leiden University - Excl LUMC; Leiden University; Wageningen University & Research; Eindhoven University of Technology	Bozyigit, F (corresponding author), Univ Antwerp, Dept Comp Sci, Antwerp, Belgium.; Bozyigit, F (corresponding author), Flanders Make Strateg Res Ctr, AnSyMo CoSys Core Lab, Lommel, Belgium.	fatma.bozyigit@uantwerpen.be; tolgahan.bardakci@uantwerpen.be; alireza.khalilipour@uantwerpen.be; moharram.challenger@uantwerpen.be; g.j.ramackers@liacs.leidenuniv.nl; onder.babur@wur.nl; m.r.v.chaudron@tue.nl	Challenger, Moharram/E-2164-2014	Challenger, Moharram/0000-0002-5436-6070; Babur, Onder/0000-0002-1460-2825				Abdelnabi Esra A., 2020, 20th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA 2020), P277, DOI 10.1109/STA50679.2020.9329301; Ahmed S, 2022, 2022 IEEE/ACIS 20TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P112, DOI 10.1109/SERA54885.2022.9806783; Arora C, 2016, 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS'16), P250, DOI 10.1145/2976767.2976769; Bajwa I.S., 2009, Object Oriented Software Modeling Using NLP Based Knowledge Extraction; Bozyigit F, 2021, ENG SCI TECHNOL, V24, P71, DOI 10.1016/j.jestch.2020.11.006; Bozyigit F, 2019, TURK J ELECTR ENG CO, V27, P453, DOI 10.3906/elk-1803-172; Bragilovski M., 2023, From user stories to domain models: recommending relationships between entities; Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009; Cámara J, 2023, SOFTW SYST MODEL, V22, P781, DOI 10.1007/s10270-023-01105-5; Deeptimahanti DK, 2009, IEEE INT CONF AUTOM, P680, DOI 10.1109/ASE.2009.48; Dori D, 2004, LECT NOTES COMPUT SC, V3080, P179; Falessi D, 2019, IEEE SOFTWARE, V36, P48, DOI 10.1109/MS.2018.2874620; Ferrari A, 2017, INT REQUIR ENG CONF, P502, DOI 10.1109/RE.2017.29; Giray G, 2023, J SYST SOFTWARE, V195, DOI 10.1016/j.jss.2022.111537; Habibullah KM, 2023, REQUIR ENG, V28, P283, DOI 10.1007/s00766-022-00395-3; Hamza Z.A., 2019, 2019 8 INT C MOD SIM, P1; Huppler Karl, 2015, P 6 ACMSPEC INT C PE, P333, DOI [10.1145/2668930.2688819, DOI 10.1145/2668930.2688819]; Ibrahim Mohd., 2010, 2010 Second International Conference on Computer Research and Development, P200, DOI DOI 10.1109/ICCRD.2010.71; Jadhav A, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/5782587; Khalilipour Alireza, 2023, IEEE DataPort, DOI 10.21227/R9J6-ND62; Khalilipour A, 2022, COMM COM INF SC, V1652, P425, DOI 10.1007/978-3-031-15743-1_39; Khalilipour A, 2022, LECT NOTE NETW SYST, V505, P173, DOI 10.1007/978-3-031-09176-6_21; Landhäusser M, 2014, SOFTWARE QUAL J, V22, P121, DOI 10.1007/s11219-013-9210-6; Lano K, 2021, 24TH ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL-DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION (MODELS-C 2021), P175, DOI 10.1109/MODELS-C53483.2021.00030; Li G, 2022, IEEE ACCESS, V10, P30080, DOI 10.1109/ACCESS.2022.3159238; Liu Z., 2020, Representation Learning for Natural Language Processing; Lucassen G, 2017, REQUIR ENG, V22, P339, DOI 10.1007/s00766-017-0270-1; Mahmood Y, 2022, SOFTWARE PRACT EXPER, V52, P39, DOI 10.1002/spe.3009; Mich L., 1996, Natural Language Engineering, V2, P161, DOI 10.1017/S1351324996001337; Ozdagoglu A., 2007, Istanbul Ticaret Universitesi Fen Bilimleri Dergisi, V6, P65; Rahimi S., 2022, INT C MOD BAS SOFTW, P1; Ramackers GJ, 2021, 24TH ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL-DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION (MODELS-C 2021), P381, DOI 10.1109/MODELS-C53483.2021.00061; Robeer M, 2016, INT REQUIR ENG CONF, P196, DOI 10.1109/RE.2016.40; Rumbaugh J., 1991, Objectoriented Modeling and Design, V199; Sagar VBRV, 2014, J SYST SOFTWARE, V88, P25, DOI 10.1016/j.jss.2013.08.036; Satapathy S.C., 2020, Automated Software Engineering: A Deep Learning-Based Approach; Sedrakyan G., 2022, MODELSWARD, P129; Sim SE, 2003, PROC INT CONF SOFTW, P74, DOI 10.1109/ICSE.2003.1201189; Tripathy A., 2014, 5 INT C ADV COMP ENG, V26, P27; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689; Zhou X., 2004, Auto-generation of class diagram from free-text functional specifications and domain ontology	42	0	0	0	0	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1619-1366	1619-1374		SOFTW SYST MODEL	Softw. Syst. Model.	2024 MAY 8	2024										10.1007/s10270-024-01176-y	http://dx.doi.org/10.1007/s10270-024-01176-y		MAY 2024	19	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QD6E0					2024-07-03	WOS:001218971100001
J	Tessler, I; Wolfovitz, A; Livneh, N; Gecel, NA; Sorin, V; Barash, Y; Konen, E; Klang, E				Tessler, Idit; Wolfovitz, Amit; Livneh, Nir; Gecel, Nir A.; Sorin, Vera; Barash, Yiftach; Konen, Eli; Klang, Eyal			Advancing Medical Practice with Artificial Intelligence: ChatGPT in Healthcare	ISRAEL MEDICAL ASSOCIATION JOURNAL			English	Article						artificial intelligence (Al); natural language processing; ChatGPT; healthcare; medical research		Background: Advancements in artificial intelligence (Al) and natural language processing (NLP) have led to the development of language models such as ChatGPT. These models have the potential to transform healthcare and medical research. However, understanding their applications and limitations is essential. Objectives: To present a view of ChatGPT research and to critically assess ChatGPT's role in medical writing and clinical environments. Methods: We performed a literature review via the PubMed search engine from 20 November 2022, to 23 April 2023. The search terms included ChatGPT, 0penAl, and large language models. We included studies that focused on ChatGPT, explored its use or implications in medicine, and were original research articles. The selected studies were analyzed considering study design, NLP tasks, main findings, and limitations. Results: Our study included 27 articles that examined ChatGPTs performance in various tasks and medical fields. These studies covered knowledge assessment, writing, and analysis tasks. While ChatGPT was found to be useful in tasks such as generating research ideas, aiding clinical reasoning, and streamlining workflows, limitations were also identified. These limitations included inaccuracies, inconsistencies, fictitious information, and limited knowledge, highlighting the need for further improvements. Conclusions: The review underscores ChatGPT's potential in various medical applications. Yet, it also points to limitations that require careful human oversight and responsible use to improve patient care, education, and decision -making. IMAJ 2024; 26: 80-85	[Tessler, Idit; Wolfovitz, Amit; Livneh, Nir] Sheba Med Ctr, Dept Otolaryngol & Head & Neck Surg, Tel Hashomer, Israel; [Tessler, Idit; Klang, Eyal] Sheba Med Ctr, ARC Innovat Ctr, IL-52621 Tel Hashomer, Israel; [Sorin, Vera; Barash, Yiftach; Konen, Eli] Sheba Med Ctr, Div Diagnost Imaging, Tel Hashomer, Israel; [Tessler, Idit; Wolfovitz, Amit; Livneh, Nir; Gecel, Nir A.; Sorin, Vera; Barash, Yiftach; Konen, Eli; Klang, Eyal] Tel Aviv Univ, Fac Med, Tel Aviv, Israel; [Klang, Eyal] Mt Sinai Clin Intelligence Ctr, Icahn Sch Med Mt Sinai, New York, NY USA	Chaim Sheba Medical Center; Chaim Sheba Medical Center; Chaim Sheba Medical Center; Tel Aviv University; Icahn School of Medicine at Mount Sinai	Tessler, I (corresponding author), Sheba Med Ctr, ARC Innovat Ctr, IL-52621 Tel Hashomer, Israel.	idit.tessler@sheba.health.gov.il						Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Barash Y, 2023, J AM COLL RADIOL, V20, P998, DOI 10.1016/j.jacr.2023.06.009; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Cadamuro J, 2023, CLIN CHEM LAB MED, V61, P1158, DOI 10.1515/cclm-2023-0355; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Looi MK, 2023, BMJ-BRIT MED J, V380, DOI 10.1136/bmj.p205; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wagner MW, 2024, CAN ASSOC RADIOL J, V75, P69, DOI 10.1177/08465371231171125	19	1	1	4	4	ISRAEL MEDICAL ASSOC JOURNAL	RAMAT GAN	2 TWIN TOWERS, 11TH FL, 35 JABOTINSKY ST, PO BOX 3604, RAMAT GAN 52136, ISRAEL	1565-1088			ISR MED ASSOC J	Isr. Med. Assoc. J.	FEB	2024	26	2					80	85						6	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	KG3P4	38420977				2024-07-03	WOS:001178768800007
C	Nakanishi, T			IEEE	Nakanishi, Takafumi			Detection of Latent Gender Biases in Data and Models Using the Approximate Generalized Inverse Method	18TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC 2024	IEEE International Conference on Semantic Computing		English	Proceedings Paper	18th IEEE International Conference on Semantic Computing (ICSC)	FEB 05-07, 2024	Laguna Hills, CA	IEEE, IEEE Comp Soc		gender bias; approximate inverse model explanation; language model; bias detection; embedding representation		Gender bias creates inequalities in roles, expectations, and opportunities between males and females. When such biases are incorporated into artificial intelligence models, the corresponding technological solutions and products can further entrench the social biases. Herein, a new method for investigating the extent to which latent biases in text-based training data affect a language model is presented. Potential gender bias is identified by deriving values assigned to male/female words via inverse operations from embedded expressions to the original words using the approximate inverse model explanation (AIME). In particular, AIME constructs approximate generalized inverse operators for black-box models. A biased embedded representation used in machine learning models as an internal representation of word/sentence vectors likely introduces bias into the overall prediction results of such models. The OpenAI text-embedding-ada-002 large language model, which provides embedded expressions, is employed to determine the gender bias included in the proposed method. Experimental results show that the OpenAI textembedding-ada-002 model is partially gender-biased owing to the training text data. These results are expected to (i) contribute to the development of effective measures preventing gender bias during the design and training of language models, (ii) promote the identification and mitigation of gender bias in future language models, and (iii) provide insights into the effect of language models and their limitations from technical, social, and cultural perspectives.	[Nakanishi, Takafumi] Musashino Univ, Dept Data Sci, Tokyo, Japan		Nakanishi, T (corresponding author), Musashino Univ, Dept Data Sci, Tokyo, Japan.	takafumi.nakanishi@ds.musashino-u.ac.jp	Nakanishi, Takafumi/HKP-2510-2023	Nakanishi, Takafumi/0000-0003-1029-6063				Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Basta C, 2019, Arxiv, DOI arXiv:1904.08783; Bolukbasi T, 2016, ADV NEUR IN, V29; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Kotek H, 2023, Arxiv, DOI arXiv:2308.14921; Kurita K, 2019, Arxiv, DOI arXiv:1906.07337; Lundberg SM, 2017, ADV NEUR IN, V30; May C, 2019, Arxiv, DOI [arXiv:1903.10561, 10.18653/v1/N19-1063]; Moore E. H., 1920, Bulletin of the American Mathematical Society, V26, P294; Nakanishi T, 2023, IEEE ACCESS, V11, P101020, DOI 10.1109/ACCESS.2023.3314336; Nemani P, 2023, Arxiv, DOI arXiv:2306.10530; Penrose R., 1955, Proc. Camb. Philos. Soc., V51, P406, DOI 10.1017/S0305004100030401; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rudinger R, 2018, Arxiv, DOI arXiv:1804.09301; Sharma S., 2021, arXiv; Squazzoni F, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abd0299; Sun TY, 2019, Arxiv, DOI arXiv:1906.08976; Swinger N, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P305, DOI 10.1145/3306618.3314270; Zhao J., 2017, arXiv; Zhao JY, 2018, Arxiv, DOI [arXiv:1809.01496, DOI 10.48550/ARXIV.1809.01496]; Zhao JY, 2018, Arxiv, DOI arXiv:1804.06876; Zhao JY, 2017, Arxiv, DOI arXiv:1707.09457	23	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2325-6516		979-8-3503-8535-9	IEEE INT C SEMANT CO			2024							191	196		10.1109/ICSC59802.2024.00036	http://dx.doi.org/10.1109/ICSC59802.2024.00036			6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7TH					2024-07-03	WOS:001196221400029
J	Abuyaman, O				Abuyaman, Omar			Strengths and Weaknesses of ChatGPT Models for Scientific Writing About Medical Vitamin B12: Mixed Methods Study	JMIR FORMATIVE RESEARCH			English	Article						AI; ChatGPT; GPT-4; GPT-3.5; vitamin B12; artificial intelligence; language editing; wide range information; AI solutions; scientific content		Background: ChatGPT is a large language model developed by OpenAI designed to generate human-like responses to prompts. Objective: This study aims to evaluate the ability of GPT-4 to generate scientific content and assist in scientific writing using medical vitamin B12 as the topic. Furthermore, the study will compare the performance of GPT-4 to its predecessor, GPT-3.5.Methods: The study examined responses from GPT-4 and GPT-3.5 to vitamin B12-related prompts, focusing on their quality and characteristics and comparing them to established scientific literature.Results: The results indicated that GPT-4 can potentially streamline scientific writing through its ability to edit language and write abstracts, keywords, and abbreviation lists. However, significant limitations of ChatGPT were revealed, including its inability to identify and address bias, inability to include recent information, lack of transparency, and inclusion of inaccurate information. Additionally, it cannot check for plagiarism or provide proper references. The accuracy of GPT-4's answers was found to be superior to GPT-3.5.Conclusions: ChatGPT can be considered a helpful assistant in the writing process but not a replacement for a scientist's expertise. Researchers must remain aware of its limitations and use it appropriately. The improvements in consecutive ChatGPT versions suggest the possibility of overcoming some present limitations in the near future.	[Abuyaman, Omar] Hashemite Univ, Fac Appl Med Sci, Dept Med Lab Sci, Zarqa 13133, Jordan; [Abuyaman, Omar] Hashemite Univ, Fac Appl Med Sci, Dept Med Lab Sci, FAMS Bldg,2nd fl, Zarqa 13133, Jordan	Hashemite University; Hashemite University	Abuyaman, O (corresponding author), Hashemite Univ, Fac Appl Med Sci, Dept Med Lab Sci, FAMS Bldg,2nd fl, Zarqa 13133, Jordan.	o.abuyaman@gmail.com		Abuyaman, Omar/0000-0002-7694-7941	JMIR Publications provided APF	JMIR Publications provided APF	Acknowledgments Professor Ebba Nexo (Denmark) is acknowledged for her fruitful discussions and her input, notably to qualify the answers concerning vitamin B12. The author declared that they had insufficient or no funding to support open access publication of this manuscript, including from affiliated organizations or institutions, funding agencies, or other organizations. JMIR Publications provided APF support for the publication of this article.	Abuyaman O, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073110; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adenosylcobalamin, PubChem; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT, about us; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Green R, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.40; Green R, 2017, BLOOD, V129, P2603, DOI 10.1182/blood-2016-10-569186; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Hu K., Reuters; Introducing ChatGPT, OpenAI; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Nielsen MJ, 2012, NAT REV GASTRO HEPAT, V9, P345, DOI 10.1038/nrgastro.2012.76; O'Leary F, 2010, NUTRIENTS, V2, P299, DOI 10.3390/nu2030299; Obeid R, 2015, MOL NUTR FOOD RES, V59, P1364, DOI 10.1002/mnfr.201500019; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Sarker Iqbal H, 2022, SN Comput Sci, V3, P158, DOI 10.1007/s42979-022-01043-x; Stabler SP, 2013, NEW ENGL J MED, V368, P149, DOI [10.1056/NEJMcp1113996, 10.1056/NEJMc1304350]; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479	28	0	0	7	10	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2023	7								e49459	10.2196/49459	http://dx.doi.org/10.2196/49459			9	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	Y8CA7	37948100	Green Published, gold			2024-07-03	WOS:001107472000005
J	Liu, B; Yin, GS				Liu, Bin; Yin, Guosheng			Graphmax for Text Generation	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article								In text generation, a large language model (LM) makes a choice of each new word based only on the former selection of its context using the softmax function. Nevertheless, the link statistics information of concurrent words based on a scene-specific corpus is valuable in choosing the next word, which can help to ensure the topic of the generated text to be aligned with the current task. To fully explore the co-occurrence information, we propose a graphmax function for task-specific text generation. Using the graph-based regularization, graphmax enables the final word choice to be determined by both the global knowledge from the LM and the local knowledge from the scene-specific corpus. The traditional softmax function is regularized with a graph total variation (GTV) term, which incorporates the local knowledge into the LM and encourages the model to consider the statistical relationships between words in a scene-specific corpus. The proposed graphmax is versatile and can be readily plugged into any large pre-trained LM for text generation and machine translation. Through extensive experiments, we demonstrate that the new GTV-based regularization can improve performances in various natural language processing (NLP) tasks in comparison with existing methods. Moreover, through human experiments, we observe that participants can easily distinguish the text generated by graphmax or softmax.	[Liu, Bin] Southwestern Univ Finance & Econ, Ctr Stat Res, Sch Stat, Chengdu, Peoples R China; [Yin, Guosheng] Univ Hong Kong, Dept Stat & Actuarial Sci, Hong Kong, Peoples R China	Southwestern University of Finance & Economics - China; University of Hong Kong	Yin, GS (corresponding author), Univ Hong Kong, Dept Stat & Actuarial Sci, Hong Kong, Peoples R China.	liubin@swufe.edu.cn; gyin@hku.hk	Liu, Bin/B-4768-2018		Research Grants Council of Hong Kong, Institute of Medical Intelligence [T45 -401/22-N]	Research Grants Council of Hong Kong, Institute of Medical Intelligence	We would like to thank the Associate Editor and three referees for their constructive and insightful comments that have significantly improved the paper. The research of Guosheng Yin was partially supported by the Theme -based Research Scheme (TRS) from the Research Grants Council of Hong Kong, Institute of Medical Intelligence and XR (T45 -401/22-N) .	Ahmed HB, 2017, IEEE GLOB CONF SIG, P667, DOI 10.1109/GlobalSIP.2017.8309043; Ahn E., 2016, P 9 INT NATURAL LANG, P70; Anderson P., 2017, P 2017 C EMPIRICAL M, P936; Bojar O, 2016, P 1 C MACH TRANSL, V2, P131; Chambolle A., 2010, Theoretical foundations and numerical methods for sparse recovery, V9, P227; Chen SH, 2015, IEEE T SIGNAL PROCES, V63, P4609, DOI 10.1109/TSP.2015.2441042; Chen ZJ, 2022, J ARTIF INTELL RES, V74, P1037; Dathathri Sumanth, 2020, Plug and play language models: A simple approach to controlled text generation; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duchi J., 2008, PROC INT C MACH LEAR, P272; Ficler Jessica, 2017, P WORKSHOP STYLISTIC, P94; Gao BL, 2018, Arxiv, DOI arXiv:1704.00805; Jain P, 2017, FOUND TRENDS MACH LE, V10, P142, DOI 10.1561/2200000058; Jia F, 2021, ANAL APPL, V19, P147, DOI 10.1142/S0219530519410148; Kann K., 2018, P 22 C COMPUTATIONAL, P313; Keskar N. S., 2019, arXiv; Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284; Koto F., 2020, J. Artif. Intell. Res., V73; Lellmann J, 2011, SIAM J IMAGING SCI, V4, P1049, DOI 10.1137/100805844; Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Liu B, 2016, PATTERN RECOGN LETT, V80, P58, DOI 10.1016/j.patrec.2016.04.017; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; Lv SG, 2022, IEEE T NEUR NET LEAR, V33, P6346, DOI 10.1109/TNNLS.2021.3077312; Martins AFT, 2016, PR MACH LEARN RES, V48; Mcauley J., 2013, P 7 ACM C REC SYST, P165; Miao N., 2019, Advances in Neural Information Processing Systems, P12508; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raguet H., 2018, P MACHINE LEARNING R, V80, P4247; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38; Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810; Siheng Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8267, DOI 10.1109/ICASSP.2014.6855213; Sutskever I., 2011, Proceedings of the 28th International Conference on Machine Learning (ICML-11), P1017; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tran C., 2021, P WMT; Vougiouklis P, 2020, J ARTIF INTELL RES, V69, P1; Yang Z., 2018, ICLR 2018 INT C LEAR; Yu DA, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2251; Zhang S., 2022, Opt: Open pre-trained transformer language models; Zhang X, 2015, ADV NEUR IN, V28	42	0	0	1	1	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757	1943-5037		J ARTIF INTELL RES	J. Artif. Intell. Res.		2023	78						823	848						26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z4ZQ4					2024-07-03	WOS:001112179300002
J	Zhang, BW; Ding, DJ; Huang, ZC; Li, A; Li, YY; Zhang, BQ; Huang, H				Zhang, Bowen; Ding, Daijun; Huang, Zhichao; Li, Ang; Li, Yangyang; Zhang, Baoquan; Huang, Hu			Knowledge-Augmented Interpretable Network for Zero-Shot Stance Detection on Social Media	IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS			English	Article; Early Access						Attention mechanism; chain-of-thought (CoT); neural production system (NPS); zero-shot stance detection (ZSSD)		Stance detection on social media has become increasingly important for understanding public opinions on controversial issues. Existing methods often require large amounts of labeled data to learn target-independent transferable knowledge, which is infeasible under zero-shot settings where the target is unseen. Furthermore, most current stance detection models, primarily based on end-to-end deep learning architectures, lack transparency and may produce counter-intuitive and uninterpretable predictions. In this article, we propose a novel knowledge-augmented interpretable network (KAI) to enable zero-shot stance detection (ZSSD). First, we introduce an unsupervised approach based on large language models (LLMKE) to elicit analysis perspectives, which is target-independent knowledge shared across different targets. This transferable knowledge bridges connections between seen and unseen targets. Second, we develop a bidirectional knowledge-guided neural production system (Bi-KGNPS) that effectively integrates such transferable knowledge through an iterative knowledge-variable binding process to guide stance predictions. Extensive experiments on benchmark datasets demonstrate KAI achieves new state-of-the-art performance on ZSSD. Moreover, our approach also delivers strong results on conventional in-target and cross-target stance detection. With the dual benefits of knowledge-augmented accuracy and model interpretability, this work represents an important advance toward practical stance detection systems that can generalize to emerging topics of interest. The proposed KAI framework provides an interpretable approach to effectively transfer knowledge across domains for zero-shot learning.	[Zhang, Bowen; Ding, Daijun] Shenzhen Technol Univ, Coll Big Data & Internet, Shenzhen 518000, Peoples R China; [Huang, Zhichao; Li, Yangyang; Zhang, Baoquan] Harbin Inst Technol, Dept Comp Sci, Shenzhen 518000, Peoples R China; [Li, Yangyang] Acad Cyber, Beijing 100000, Peoples R China; [Li, Ang; Huang, Hu] Peking Univ, Shenzhen Grad Sch, Shenzhen 518000, Peoples R China	Shenzhen Technology University; Harbin Institute of Technology; Peking University	Huang, H (corresponding author), Peking Univ, Shenzhen Grad Sch, Shenzhen 518000, Peoples R China.	h.huang@pku.edu.cn		Zhang, Bowen/0000-0002-3581-9476	National Nature Science Foundation of China [62306184]; Natural Science Foundation of Top Talent of SZTU [GDRC202320]; Research Promotion Project of Key Construction Discipline in Guangdong Province [2022ZDJS112]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Top Talent of SZTU; Research Promotion Project of Key Construction Discipline in Guangdong Province	This work was supported in part by the National Nature Science Foundation of China under Grant 62306184, in part by the Natural Science Foundation of Top Talent of SZTU under Grant GDRC202320, and in part by the Research Promotion Project of Key Construction Discipline in Guangdong Province under Grant 2022ZDJS112.	Allaway E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4756; Allaway E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8913; Augenstein T., 2016, P C EMP METH NAT LAN; Cai ZF, 2023, Arxiv, DOI arXiv:2306.07932; Cignarella AT, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), P10; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3988; Fei H, 2023, Arxiv, DOI arXiv:2305.11255; Goyal Anirudh, 2021, P ADV NEUR INF PROC, V34, P25673; Guo H, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P659, DOI 10.1145/3583780.3614936; Hardalov M, 2022, AAAI CONF ARTIF INTE, P10729; Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225; Huang H, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3588767; Huang H, 2022, KNOWL-BASED SYST, V257, DOI 10.1016/j.knosys.2022.109943; Ito T, 2020, AAAI CONF ARTIF INTE, V34, P4231; Jain R, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3447650; Jang Eric, 2017, INT C LEARN REPR; Jiang T., 2022, P 2022 C EMPIRICAL M, P8826; Jiang Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P837, DOI 10.1145/3477495.3531979; Küçük D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3369026; Li C, 2022, IEEE T NEUR NET LEAR, V33, P2530, DOI 10.1109/TNNLS.2021.3114027; Li Yingjie, 2023, WWW '23: Proceedings of the ACM Web Conference 2023, P1500, DOI 10.1145/3543507.3583250; Li YJ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2355; Liang B, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P81; Liang B, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2738, DOI 10.1145/3485447.3511994; Liang B, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3453, DOI 10.1145/3442381.3449790; Ling Z, 2023, Arxiv, DOI arXiv:2306.03872; Liu R, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3152; Mohammad S., 2016, P 10 INT WORKSH SEM, P31, DOI [DOI 10.18653/V1/S16-1003, 10.18653/v1/S16-1003]; Rani S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3485243; Wei JS, 2022, ADV NEUR IN; Wei PH, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1173, DOI 10.1145/3331184.3331367; Yadav RK, 2021, AAAI CONF ARTIF INTE, V35, P14203; Yin N, 2023, IEEE T KNOWL DATA EN, V35, P12873, DOI 10.1109/TKDE.2023.3271677; Yin N, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P3470, DOI 10.1145/3503161.3548012; Zhang BW, 2023, Arxiv, DOI arXiv:2304.03087; Zhang BW, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3188; Zhang BW, 2020, IEEE-ACM T AUDIO SPE, V28, P2538, DOI 10.1109/TASLP.2020.3017093; Zhang D., 2023, P IEEE INT C AC SPEE, P1; Zhang JR, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P160, DOI 10.1145/3543873.3587337; Zhang X, 2021, COMM COM INF SC, V1466, P171, DOI 10.1007/978-981-16-6471-7_13; Zhang Z., 2022, arXiv; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]; Zhu QL, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2070, DOI 10.1145/3477495.3531807	45	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-924X			IEEE T COMPUT SOC SY	IEEE Trans. Comput. Soc. Syst.	2024 MAY 24	2024										10.1109/TCSS.2024.3388723	http://dx.doi.org/10.1109/TCSS.2024.3388723		MAY 2024	12	Computer Science, Cybernetics; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RW8G6					2024-07-03	WOS:001230782200001
J	Niszczota, P; Rybicka, I				Niszczota, Pawel; Rybicka, Iga			The credibility of dietary advice formulated by ChatGPT: Robo-diets for people with food allergies	NUTRITION			English	Article						Artificial intelligence; ChatGPT; Dietary advice; Food allergy; Nutrition; Robo-diet		The introduction of ChatGPT has sparked enormous public interest in large language (deep-learning) models, which have been sophisticated enough to perform well on a variety of tasks. One way people are using these models is to construct diets. The prompts often include food restrictions that are an obligatory part of everyday life for millions of people worldwide. The aim of this study was to investigate the safety and accuracy of 56 diets, constructed for hypothetical individuals who are allergic to food allergens. Four levels, corresponding to the "baseline" ability of ChatGPT without prompting for specifics, as well as its ability to prepare appropriate diets when an individual has an adverse food reaction to two allergens or solicits a low-calorie diet, were defined. Findings from our study demonstrated that ChatGPT, although generally accurate, has the potential to produce harmful diets. More common errors involve inaccuracies in portions or calories of food, meals, or diets. We discuss here how the accuracy of large language models could be increased and the trade-offs involved. We propose that prompting for elimination diets can serve as one way to assess differences between such models. (c) 2023 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)	[Niszczota, Pawel] Poznan Univ Econ & Business, Inst Int Business & Econ, Poznan, Poland; [Niszczota, Pawel; Rybicka, Iga] Poznan Univ Econ & Business, Humans & AI Lab HAI Lab, Poznan, Poland; [Rybicka, Iga] Poznan Univ Econ & Business, Inst Qual Sci, Poznan, Poland; [Rybicka, Iga] Poznan Univ Econ & Business, Al Niepodleglosci 10, PL-61875 Poznan, Poland	Poznan University of Economics & Business; Poznan University of Economics & Business; Poznan University of Economics & Business; Poznan University of Economics & Business	Rybicka, I (corresponding author), Poznan Univ Econ & Business, Al Niepodleglosci 10, PL-61875 Poznan, Poland.	iga.rybicka@ue.poznan.pl	Niszczota, Paweł/P-8289-2018	Niszczota, Paweł/0000-0002-4150-3646	National Science Centre, Poland;  [2021/42/E/HS4/00289]	National Science Centre, Poland(National Science Centre, Poland); 	This research was supported by grant 2021/42/E/HS4/00289 from the National Science Centre, Poland.	Afify SM, 2017, WORLD ALLERGY ORGAN, V10, DOI 10.1186/s40413-017-0174-z; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; [Anonymous], WE GAV CHATGPT COLL; Bärebring L, 2020, NUTR J, V19, DOI 10.1186/s12937-020-00659-0; Bartz D, US ADVOCACY GROUP AS; Boström J, 2021, NAT MACH INTELL, V3, P102, DOI 10.1038/s42256-021-00299-x; Brown TB, 2020, ARXIV; Elghoudi Ahmed, 2022, World J Clin Pediatr, V11, P253, DOI 10.5409/wjcp.v11.i3.253; European Food Safety Authority, 2014, EFSA J, V12, DOI 10.2903/j.efsa.2014.3547; FAO, Food-Based Dietary Guidelines; FDA, FOOD ALL WHAT YOU NE; GlobalData, FOOD ALL MARK SIZ TR; Hu K., ChatGPT sets record for fastest-growing user base-analyst note; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; Midun E, 2021, WORLD ALLERGY ORGAN, V14, DOI 10.1016/j.waojou.2020.100491; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pichai Sundar., 2023, An important next step on our AI journey. Google; Renz H, 2018, NAT REV DIS PRIMERS, V4, DOI [10.1007/s11894-018-0624-y, 10.1038/nrdp.2017.98]; Roose K, BING JUST MADE SEARC; Satariano A, CHATGPT IS BANNED IT; Taori R., Alpaca: A strong, replicable instructionfollowing model; Wang SH, 2023, NATURE, V615, P34, DOI 10.1038/d41586-023-00553-9; WHO and FAO, RISK ASS FOOD ALL 1; Zhuang Simon, 2020, Adv. Neural Inf. Process. Syst, V33, P15763	24	15	15	9	18	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0899-9007	1873-1244		NUTRITION	Nutrition	AUG	2023	112								112076	10.1016/j.nut.2023.112076	http://dx.doi.org/10.1016/j.nut.2023.112076		JUN 2023	4	Nutrition & Dietetics	Science Citation Index Expanded (SCI-EXPANDED)	Nutrition & Dietetics	P8WV3	37269717	hybrid			2024-07-03	WOS:001053431100001
C	Atif, F; El Khatib, O; Difallah, D			ACM	Atif, Farah; El Khatib, Ola; Difallah, Djellel			BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Knowledge Graphs; Question Answering		Knowledge Graph Question Answering (KGQA) is a task that aims to answer natural language queries by extracting facts from a knowledge graph. Current state-of-the-art techniques for KGQA rely on text-based information from graph entity and relations labels, as well as external textual corpora. By reasoning over multiple edges in the graph, these can accurately rank and return the most relevant entities. However, one of the limitations of these methods is that they cannot handle the inherent incompleteness of real-world knowledge graphs and may lead to inaccurate answers due to missing edges. To address this issue, recent advances in graph representation learning have led to the development of systems that can use link prediction techniques to handle missing edges probabilistically, allowing the system to reason with incomplete information. However, existing KGQA frameworks that use such techniques often depend on learning a transformation from the query representation to the graph embedding space, which requires access to a large training dataset. We present BeamQA, an approach that overcomes these limitations by combining a sequence-to-sequence prediction model with beam search execution in the embedding space. Our model uses a pretrained large language model and synthetic question generation. Our experiments demonstrate the effectiveness of BeamQA when compared to other KGQA methods on two knowledge graph question-answering datasets.	[Atif, Farah; El Khatib, Ola; Difallah, Djellel] New York Univ Abu Dhabi, Abu Dhabi, U Arab Emirates	New York University Abu Dhabi	Atif, F (corresponding author), New York Univ Abu Dhabi, Abu Dhabi, U Arab Emirates.	fa2462@nyu.edu; oge208@nyu.edu; djellel@nyu.edu		Difallah, Djellel Eddine/0000-0002-7513-6047				Andersen R, 2006, ANN IEEE SYMP FOUND, P475; Andreas J, 2016, Arxiv, DOI arXiv:1601.01705; [Anonymous], 2013, P 2013 C EMPIRICAL M; Atzeni M., 2021, P ADV NEUR INF PROC, V34, P12587; Bordes A, 2014, Arxiv, DOI arXiv:1406.3676; Broscheit S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P165; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fu B, 2020, Arxiv, DOI arXiv:2007.13069; He GL, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P535, DOI 10.1145/3437963.3441753; Hirschman L., 2001, Natural Language Engineering, V7, P275, DOI 10.1017/S1351324901002807; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Janssen M, 2012, INFORM SYST MANAGE, V29, P258, DOI 10.1080/10580530.2012.716740; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Kingma D. P., 2017, ARXIV; Lan YS, 2019, IEEE-ACM T AUDIO SPE, V27, P1629, DOI 10.1109/TASLP.2019.2926125; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li ZY, 2019, Arxiv, DOI arXiv:1910.07454; Madjid NA, 2022, IEEE DATA MINING, P309, DOI 10.1109/ICDM54844.2022.00041; Miller A., 2016, P 2016 C EMPIRICAL M, P1400, DOI 10.18653/v1/D16-1147; Raffel C, 2020, J MACH LEARN RES, V21; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Ren H., 2021, P INT C MACH LEARN, P8959; Ren HY, 2020, Arxiv, DOI [arXiv:2002.05969, DOI 10.48550/ARXIV.2002.05969]; Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4498; Shazeer N, 2018, PR MACH LEARN RES, V80; Shi Jiaxin, 2021, P 2021 C EMPIRICAL M, P4149; Srivastava S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3428; Sun HT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2380; Sun HT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4231; Trouillon T, 2016, PR MACH LEARN RES, V48; Vaswani A, 2017, ADV NEUR IN, V30; Vijayakumar AK, 2018, AAAI CONF ARTIF INTE, P7371; Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321; Yin WP, 2016, Arxiv, DOI arXiv:1606.03391; Zhang YY, 2018, AAAI CONF ARTIF INTE, P6069	35	1	1	6	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							781	790		10.1145/3539618.3591698	http://dx.doi.org/10.1145/3539618.3591698			10	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG					2024-07-03	WOS:001118084000079
J	Williams, CYK; Zack, T; Miao, BY; Sushil, M; Wang, MCL; Kornblith, AE; Butte, AJ				Williams, Christopher Y. K.; Zack, Travis; Miao, Brenda Y.; Sushil, Madhumita; Wang, Michelle; Kornblith, Aaron E.; Butte, Atul J.			Use of a Large Language Model to Assess Clinical Acuity of Adults in the Emergency Department	JAMA NETWORK OPEN			English	Article								IMPORTANCE The introduction of large language models (LLMs), such as Generative Pre-trained Transformer 4 (GPT-4; OpenAI), has generated significant interest in health care, yet studies evaluating their performance in a clinical setting are lacking. Determination of clinical acuity, a measure of a patient's illness severity and level of required medical attention, is one of the foundational elements of medical reasoning in emergency medicine. OBJECTIVE To determine whether an LLM can accurately assess clinical acuity in the emergency department (ED). DESIGN, SETTING, AND PARTICIPANTS This cross-sectional study identified all adult ED visits from January 1, 2012, to January 17, 2023, at the University of California, San Francisco, with a documented Emergency Severity Index (ESI) acuity level (immediate, emergent, urgent, less urgent, or nonurgent) and with a corresponding ED physician note. A sample of 10 000 pairs of ED visits with nonequivalent ESI scores, balanced for each of the 10 possible pairs of 5 ESI scores, was selected at random. EXPOSURE The potential of the LLM to classify acuity levels of patients in the ED based on the ESI across 10 000 patient pairs. Using deidentified clinical text, the LLM was queried to identify the patient with a higher-acuity presentation within each pair based on the patients' clinical history. An earlier LLM was queried to allow comparison with this model. MAIN OUTCOMES AND MEASURES Accuracy score was calculated to evaluate the performance of both LLMs across the 10 000-pair sample. A 500-pair subsample was manually classified by a physician reviewer to compare performance between the LLMs and human classification. RESULTS From a total of 251 401 adult ED visits, a balanced sample of 10 000 patient pairs was created wherein each pair comprised patients with disparate ESI acuity scores. Across this sample, the LLM correctly inferred the patient with higher acuity for 8940 of 10 000 pairs (accuracy, 0.89 [95% CI, 0.89-0.90]). Performance of the comparator LLM (accuracy, 0.84 [95% CI, 0.83-0.84]) was below that of its successor. Among the 500-pair subsample that was also manually classified, LLM performance (accuracy, 0.88 [95% CI, 0.86-0.91]) was comparable with that of the physician reviewer (accuracy, 0.86 [95% CI, 0.83-0.89]). CONCLUSIONS AND RELEVANCE In this cross-sectional study of 10 000 pairs of ED visits, the LLM accurately identified the patient with higher acuity when given pairs of presenting histories extracted from patients' first ED documentation. These findings suggest that the integration of an LLM into ED workflows could enhance triage processes while maintaining triage quality and warrants further investigation.	[Williams, Christopher Y. K.; Zack, Travis; Miao, Brenda Y.; Sushil, Madhumita; Wang, Michelle; Kornblith, Aaron E.; Butte, Atul J.] Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, 490 Illinois St, San Francisco, CA 94107 USA; [Kornblith, Aaron E.] Univ Calif San Francisco, Dept Emergency Med, San Francisco, CA USA; [Kornblith, Aaron E.] Univ Calif San Francisco, Dept Pediat, San Francisco, CA USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco	Williams, CYK; Butte, AJ (corresponding author), Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, 490 Illinois St, San Francisco, CA 94107 USA.	cykw2@doctors.org.uk; atul.butte@ucsf.edu		Sushil, Madhumita/0000-0001-7884-0526				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alsentzer E, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00957-x; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Emergency Nurses Association, 2023, Emergency Severity Index Handbook, V5th; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763; Ilgen JS, 2012, ACAD EMERG MED, V19, P1454, DOI 10.1111/acem.12034; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lehman E, 2023, Arxiv, DOI [arXiv:2302.08091, 10.48550/arXiv.2302.08091, DOI 10.48550/ARXIV.2302.08091]; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; OpenAI, Introducing ChatGPT; Radhakrishnan L, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad045; Tierney AA, 2024, NEJM Catal Innov Care Deliv., V5, DOI [10.1056/cat.23.0404, DOI 10.1056/CAT.23.0404]	15	1	1	2	2	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	MAY 7	2024	7	5							e248895	10.1001/jamanetworkopen.2024.8895	http://dx.doi.org/10.1001/jamanetworkopen.2024.8895			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	QI6O5	38713466	gold			2024-07-03	WOS:001220288300008
J	Marres, N; Castelle, M; Gobbo, B; Poletti, C; Tripp, J				Marres, Noortje; Castelle, Michael; Gobbo, Beatrice; Poletti, Chiara; Tripp, James			AI as super-controversy: Eliciting AI and society controversies with an extended expert community in the UK	BIG DATA & SOCIETY			English	Article						Artificial intelligence; controversy analysis; elicitation methods; science and technology studies; Twitter; design for debate		Following the release of large language models in the late 2010s, the backers of this new type of artificial intelligence (AI) publicly affirmed that the technology is controversial and harmful to society. This situation sets contemporary AI apart from 20th-century controversies about technnoscience, such as nuclear power and genetically modified (GM) foods, and disrupts established assumptions concerning public controversies as occasions for technological democracy. In particular, it challenges the idea that such controversies enable inclusion and collective processes of problem definition ('problematisation') across societal domains. In this paper, we show how social research can contribute to addressing this challenge of AI controversies by adopting a distinctive methodology of controversy analysis: controversy elicitation. This approach actively selects, qualifies and evaluates controversies in terms of their capacity to problematise AI across the science and non-science binary. We describe our implementation of this approach in a participatory study of recent AI controversies, conducted through consultation with UK experts in AI and society. Combining an online questionnaire, social media analysis and a participatory workshop, our study suggests that civil society actors have developed distinctive strategies of problematisation that counter the strategic affirmation of AI's controversiality by its proponents and which centre on the public mobilisation of AI-related incidents: demonstrations of bias, accidents and walkouts. Crucially, this emphasis on 'AI frictions' does not result in the fragmentation of AI controversies, but rather enables the articulation of AI as a 'super-controversy': the explication of connections between technical propositions, situated troubles and structural problems in society (discrimination, inequalities and corporate power).	[Marres, Noortje; Castelle, Michael; Poletti, Chiara; Tripp, James] Univ Warwick, Ctr Interdisciplinary Methodol, Coventry CV4 7AL, England; [Gobbo, Beatrice] Politecn Milan, Dept Design, Milan, Italy	University of Warwick; Polytechnic University of Milan	Marres, N (corresponding author), Univ Warwick, Ctr Interdisciplinary Methodol, Coventry CV4 7AL, England.	N.Marres@warwick.ac.uk			Economic and Social Research Council	Economic and Social Research Council(UK Research & Innovation (UKRI)Economic & Social Research Council (ESRC))	We would like to thank all the respondents to our online consultation 'What makes AI controversial?' as well as our interviewees and the participants in the 'Shifting AI Controversies' workshop, without whose expert contributions this research would not have been possible. We also thank our colleagues and students in the Centre for Interdisciplinary Methodologies at the University of Warwick who took on key roles to help realise the workshop. We are grateful to all Shaping AI teams for inspiring discussions.	Alfrink K, 2023, MIND MACH, V33, P613, DOI 10.1007/s11023-022-09611-z; Ashwin J, 2023, Arxiv, DOI arXiv:2309.17147; Barnes B., 1977, Interests and the growth of knowledge; Barry A, 2021, THEOR CULT SOC, V38, P93, DOI 10.1177/0263276420958043; Bender EM Gebru T McMillan-Major A, 2021, Proceedings of the 2021 ACM conference on fairness, accountability, and transparency; Burgess J, 2016, COMMUN RES PRACT, V2, P79, DOI 10.1080/22041451.2016.1155338; Callon M., 2009, ACTING UNCERTAIN WOR; Collier J., 2007, Concept Work and Collaboration in the Anthropology of the Contemporary, P54; Costas R, 2021, J ASSOC INF SCI TECH, V72, P595, DOI 10.1002/asi.24427; Crpel M., 2021, COMP HUM RES C AMST, P77; Dandurand G., 2022, Training the News: Coverage of Canadas AI Hype Cycle (20122021); FUNTOWICZ SO, 1991, ECOLOGICAL ECONOMICS : THE SCIENCE AND MANAGEMENT OF SUSTAINABILITY, P137; Geiger S, 2020, J CULT ECON-UK, V13, P169, DOI 10.1080/17530350.2019.1684337; Geiger S, 2014, CONCERNED MARKETS: ECONOMIC ORDERING FOR MULTIPLE VALUES, P1; Gerbaudo P, 2022, DEMOCR THEORY, V9, P120, DOI 10.3167/dt.2022.090207; Kak A., 2023, Confronting tech power, 2023 landscape; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Kling R.)., 1996, Computerization and controversy: Value conflicts and social choices, V2nd; Latour B., 2005, REASSEMBLING SOCIAL; Lupton D, 2015, DIGITAL SOCIOLOGY, P1; Madsen AK, 2019, BIG DATA SOC, V6, DOI 10.1177/2053951718825357; Mannheim Karl, IDEOLOGY UTOPIA INTR; Marcus G., 2018, ARXIV; Marres N, 2020, QUANT SCI STUD, V1, P1041, DOI 10.1162/qss_a_00062; McGoey L, 2021, ANNU REV LAW SOC SCI, V17, P391, DOI 10.1146/annurev-lawsocsci-120220-074323; Meunier A., 2021, A New AI Lexicon, P1; Nishi R, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0334-0; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Parks P, 2021, JOURNALISM, V22, P122, DOI 10.1177/1464884917736998; PATEY DL, 1986, J HIST IDEAS, V47, P139, DOI 10.2307/2709600; Powles J, 2017, HEALTH TECHNOL-GER, V7, P351, DOI 10.1007/s12553-017-0179-1; Roberge Jonathan., 2021, The cultural life of machine learning, P1, DOI [DOI 10.1007/978-3-030-56286-1, 10.1007/978-3-030-56286-1_1]; Rogers R, 2000, PUBLIC UNDERST SCI, V9, P141, DOI 10.1088/0963-6625/9/2/304; Rogers R, 2017, DATAFIED SOCIETY: STUDYING CULTURE THROUGH DATA, P75; Ruppert E., 2015, Socialising Big Data: From Concept to Practice; Selbst AD, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P59, DOI 10.1145/3287560.3287598; Shane TS, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517231215360; Stark L., 2021, The Cultural Life of Machine Learning: An Incursion into Critical AI Studies, P257, DOI [10.1007/978-3-030-56286-19, DOI 10.1007/978-3-030-56286-19]; Suchman L, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517231206794; Phan T, 2022, SCI CULT-UK, V31, P121, DOI 10.1080/09505431.2021.1990875; Venturini Tommaso, 2021, Controversy mapping: A field guide; Wang Y, 2018, J PERS SOC PSYCHOL, V114, P246, DOI 10.1037/pspa0000098; Ziems C, 2023, COMPUT LINGUIST, V50, P237, DOI 10.1162/coli_a_00502	43	0	0	0	0	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	2053-9517			BIG DATA SOC	Big Data Soc.	JUN	2024	11	2							20539517241255103	10.1177/20539517241255103	http://dx.doi.org/10.1177/20539517241255103			18	Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	TB4I7		gold			2024-07-03	WOS:001238780900001
J	Lechien, JR; Rameau, A				Lechien, Jerome R.; Rameau, Anais			Applications of ChatGPT in Otolaryngology-Head Neck Surgery: A State of the Art Review	OTOLARYNGOLOGY-HEAD AND NECK SURGERY			English	Article; Early Access						artificial Intelligence; ChatGPT; generative; GPT; head neck; otolaryngology; otorhinolaryngology; surgery		ObjectiveTo review the current literature on the application, accuracy, and performance of Chatbot Generative Pre-Trained Transformer (ChatGPT) in Otolaryngology-Head and Neck Surgery.Data SourcesPubMED, Cochrane Library, and Scopus.Review MethodsA comprehensive review of the literature on the applications of ChatGPT in otolaryngology was conducted according to Preferred Reporting Items for Systematic Reviews and Meta-analyses statement.ConclusionsChatGPT provides imperfect patient information or general knowledge related to diseases found in Otolaryngology-Head and Neck Surgery. In clinical practice, despite suboptimal performance, studies reported that the model is more accurate in providing diagnoses, than in suggesting the most adequate additional examinations and treatments related to clinical vignettes or real clinical cases. ChatGPT has been used as an adjunct tool to improve scientific reports (referencing, spelling correction), to elaborate study protocols, or to take student or resident exams reporting several levels of accuracy. The stability of ChatGPT responses throughout repeated questions appeared high but many studies reported some hallucination events, particularly in providing scientific references.Implications for PracticeTo date, most applications of ChatGPT are limited in generating disease or treatment information, and in the improvement of the management of clinical cases. The lack of comparison of ChatGPT performance with other large language models is the main limitation of the current research. Its ability to analyze clinical images has not yet been investigated in otolaryngology although upper airway tract or ear images are an important step in the diagnosis of most common ear, nose, and throat conditions. This review may help otolaryngologists to conceive new applications in further research.	[Lechien, Jerome R.] Res Comm Young Otolaryngologists Int Federat Otorh, Paris, France; [Lechien, Jerome R.] Univ Mons UMons, UMONS Res Inst Hlth Sci & Technol, Div Laryngol & Broncho Esophagol, Dept Otolaryngol Head Neck Surg,EpiCURA Hosp, Mons, Belgium; [Lechien, Jerome R.] Paris Saclay Univ, Univ Sorbonne Nouvelle Paris 3, Dept Otorhinolaryngol & Head & Neck Surg, Foch Hosp,Phonet & Phonol Lab,UMR 7018 CNRS, Paris, France; [Lechien, Jerome R.] CHU St Pierre, Dept Otorhinolaryngol & Head & Neck Surg, Brussels, Belgium; [Rameau, Anais] Weill Cornell Med, Sean Parker Inst Voice, Dept Otolaryngol Head & Neck Surg, New York, NY USA	University of Mons; Hospital Foch; Universite Paris Saclay; Universite Libre de Bruxelles; Cornell University; Weill Cornell Medicine	Lechien, JR (corresponding author), Univ Mons UMons, UMONS Res Inst Hlth Sci & Technol, Div Laryngol & Broncho Esophagol, Dept Otolaryngol Head Neck Surg,EpiCURA Hosp, Mons, Belgium.	Jerome.Lechien@umons.ac.be						Alfertshofer M, 2024, ANN BIOMED ENG, V52, P1542, DOI 10.1007/s10439-023-03338-3; [Anonymous], 2009, PLOS MED, V6, pe1000097, DOI [10.3736/jcim20090918, DOI 10.1371/JOURNAL.PMED.1000097]; Ayoub NF, 2024, OTOLARYNG HEAD NECK, V170, P1484, DOI 10.1002/ohn.465; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Bellinger JR, 2024, OTOLARYNG HEAD NECK, V170, P1504, DOI 10.1002/ohn.506; Campbell DJ, 2024, THYROID, V34, P371, DOI 10.1089/thy.2023.0491; Campbell DJ, 2023, J CLIN SLEEP MED, V19, P1989, DOI 10.5664/jcsm.10728; Capelleras M, 2024, FACIAL PLAST SURG, DOI 10.1055/a-2219-4901; Chee J, 2023, EUR ARCH OTO-RHINO-L, V280, P4687, DOI 10.1007/s00405-023-08135-1; Cheong RCT, 2024, EUR ARCH OTO-RHINO-L, V281, P2137, DOI 10.1007/s00405-023-08381-3; Cheong RCT, 2024, EUR ARCH OTO-RHINO-L, V281, P985, DOI 10.1007/s00405-023-08319-9; Chiesa-Estomba CM, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08104-8; Chiesa-Estomba CM, 2024, EUR ARCH OTO-RHINO-L, V281, P2179, DOI 10.1007/s00405-023-08382-2; Chiesa-Estomba CM., 2024, Clinical Presentation; Dallari V, 2024, EUR ARCH OTO-RHINO-L, V281, P995, DOI 10.1007/s00405-023-08321-1; Davis RJ, 2024, LARYNGOSCOPE, V134, P2252, DOI 10.1002/lary.31191; Durairaj KK, 2024, FACIAL PLAST SURG AE, V26, P270, DOI 10.1089/fpsam.2023.0224; European Commission, 2024, A Strategic Vision to Foster the Development and Use of Lawful, Safe and Trustworthy Artificial Intelligence Systems in the European Commission; Frosolini A, 2023, EUR ARCH OTO-RHINO-L, V280, P5129, DOI 10.1007/s00405-023-08205-4; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Karimov Z, 2024, EUR ARCH OTO-RHINO-L, V281, P2145, DOI 10.1007/s00405-023-08423-w; Kocak Z, 2023, BALK MED J, V40, P149, DOI 10.4274/balkanmedj.galenos.2023.17042023; Kuscu O, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1256459; Langlie J, 2024, AM J OTOLARYNG, V45, DOI 10.1016/j.amjoto.2024.104220; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P3309, DOI 10.1007/s00405-023-08441-8; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P1565, DOI 10.1007/s00405-023-08326-w; Lechien JR, 2023, LARYNGOSCOPE, DOI 10.1002/lary.31134; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P319, DOI 10.1007/s00405-023-08282-5; Lechien JR, 2024, OTOLARYNG HEAD NECK, V170, P1527, DOI 10.1002/ohn.526; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P2063, DOI 10.1007/s00405-023-08219-y; Lechien JR., 2024, Otolaryngol Clin N Am; Lechien JR., 2024, Laryngoscope, V281, P2547; Lee JC, 2024, LARYNGOSCOPE, V134, P2757, DOI 10.1002/lary.31243; Lim B, 2023, J CLIN MED, V12, DOI 10.3390/jcm12206524; Long C, 2024, JMIR MED EDUC, V10, DOI 10.2196/49970; Mahajan AP, 2023, OTO OPEN, V7, DOI 10.1002/oto2.98; Marchi F, 2024, EUR ARCH OTO-RHINO-L, V281, P2123, DOI 10.1007/s00405-024-08525-z; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Mihalache A, 2024, JAMA OPHTHALMOL, V142, P321, DOI 10.1001/jamaophthalmol.2024.0017; Mira FA, 2024, EUR ARCH OTO-RHINO-L, V281, P2087, DOI 10.1007/s00405-023-08270-9; Moise A, 2023, CHILDREN-BASEL, V10, DOI 10.3390/children10101634; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Novet J., 2023, MICROSOFTS NEW WINDO; Ostrowska M., Eur Arch Otorhinolaryngol; Park I, 2023, AM J OTOLARYNG, V44, DOI 10.1016/j.amjoto.2023.103873; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Radulesco T, 2024, INT FORUM ALLERGY RH, V14, P1123, DOI 10.1002/alr.23323; Saibene AM, 2024, EUR ARCH OTO-RHINO-L, V281, P1835, DOI 10.1007/s00405-023-08372-4; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Shen SA, 2024, EUR ARCH OTO-RHINO-L, V281, P3219, DOI 10.1007/s00405-024-08524-0; Sievert M, 2024, EUR ARCH OTO-RHINO-L, V281, P2115, DOI 10.1007/s00405-024-08476-5; Soto-Galindo GA, 2023, FACIAL PLAST SURG, DOI 10.1055/a-2218-6984; Teixeira-Marques F, 2024, EUR ARCH OTO-RHINO-L, V281, P2023, DOI 10.1007/s00405-024-08498-z; The White House, The Biden-Harris Administration; Vaira LA, 2024, OTOLARYNG HEAD NECK, V170, P1492, DOI 10.1002/ohn.489; Workman AD, 2024, INT FORUM ALLERGY RH, V14, P1101, DOI 10.1002/alr.23310; Zalzal HG, 2023, OTO OPEN, V7, DOI 10.1002/oto2.94	57	0	0	11	11	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0194-5998	1097-6817		OTOLARYNG HEAD NECK	Otolaryngol. Head Neck Surg.	2024 MAY 8	2024										10.1002/ohn.807	http://dx.doi.org/10.1002/ohn.807		MAY 2024	11	Otorhinolaryngology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology; Surgery	PQ3A4	38716790	hybrid			2024-07-03	WOS:001215496400001
J	Howe, PDL; Fay, N; Saletta, M; Hovy, E				Howe, Piers Douglas Lionel; Fay, Nicolas; Saletta, Morgan; Hovy, Eduard			ChatGPT's advice is perceived as better than that of professional advice columnists	FRONTIERS IN PSYCHOLOGY			English	Article						ChatGPT; empathy; advice column; agony aunt; advice	EMPATHY	ChatGPT is a high-performance large language model that has the potential to significantly improve human-computer interactions. It can provide advice on a range of topics, but it is unclear how good this advice is relative to that provided by competent humans, especially in situations where empathy is required. Here, we report the first investigation of whether ChatGPT's responses are perceived as better than those of humans in a task where humans were attempting to be empathetic. Fifty social dilemma questions were randomly selected from 10 well-known advice columns. In a pre-registered survey, participants (N = 404) were each shown one question, along with the corresponding response by an advice columnist and by ChatGPT. ChatGPT's advice was perceived as more balanced, complete, empathetic, helpful, and better than the advice provided by professional advice columnists (all values of p < 0.001). Although participants could not determine which response was written by ChatGPT (54%, p = 0.29), most participants preferred that their own social dilemma questions be answered by a human than by a computer (77%, p < 0.001). ChatGPT's responses were longer than those produced by the advice columnists (mean 280.9 words vs. 142.2 words, p < 0.001). In a second pre-registered survey, each ChatGPT answer was constrained to be approximately the same length as that of the advice columnist (mean 143.2 vs. 142.2 words, p = 0.95). This survey (N = 401) replicated the above findings, showing that the benefit of ChatGPT was not solely due to it writing longer answers.	[Howe, Piers Douglas Lionel] Univ Melbourne, Melbourne Sch Psychol Sci, Complex Human Data Hub, Melbourne, Vic, Australia; [Fay, Nicolas] Univ Western Australia, Sch Psychol Sci, Perth, WA, Australia; [Saletta, Morgan] Univ Melbourne, Hunt Lab, Melbourne, Vic, Australia; [Hovy, Eduard] Univ Melbourne, Melbourne Connect, Melbourne, Vic, Australia	University of Melbourne; University of Western Australia; University of Melbourne; University of Melbourne	Howe, PDL (corresponding author), Univ Melbourne, Melbourne Sch Psychol Sci, Complex Human Data Hub, Melbourne, Vic, Australia.	pdhowe@unimelb.edu.au		Fay, Nicolas/0000-0001-9866-2800; Saletta, Morgan/0000-0003-2879-815X	Australian Research Council10.13039/501100000923	Australian Research Council10.13039/501100000923	No Statement Available	Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Belkhir A., 2023, P 14 INT C REC ADV N, P159, DOI DOI 10.26615/978-954-452-092-2018; BELLET PS, 1991, JAMA-J AM MED ASSOC, V266, P1831, DOI 10.1001/jama.266.13.1831; Berger C.R., 2010, The handbook of communication science; Bolker Ben, 2024, CRAN; Clark K., 2020, PREPRINT; Dalton J., 2016, Design Management Institute Review, V27, P20, DOI DOI 10.1111/DREV.12004; De Rosario Helios, 2020, CRAN; Decety J., 2011, Empathy: From Bench to Bedside; Demszky D., 2020, PREPRINT, DOI [10.18653/v1/2020.acl-main.372, DOI 10.18653/V1/2020.ACL-MAIN.372]; Duerr S, 2021, Arxiv, DOI arXiv:2101.05786; Floyd K., 2020, HDB COMMUNICATION SC, DOI [10.1111/j.1469-8986.2010.01083.x, DOI 10.1111/J.1469]; Gohil S., 2023, 20+ ChatGPT statistics & facts to know in 2023; Gomila R, 2021, J EXP PSYCHOL GEN, V150, P700, DOI 10.1037/xge0000920; Halliday M.A.K., 1975, Cohesion in English; Hoffman M. L., 2000, Empathy and Moral Development: Implications for Caring and Justice; Janich N, 2020, MEDIA COMMUN-LISBON, V8, P107, DOI 10.17645/mac.v8i1.2481; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kalla D., 2023, International Journal of Innovative Science and Research Technology, V8, P827; Katz D. M., 2023, PREPRINT, DOI [10.2139/ssrn.4389233, DOI 10.2139/SSRN.4389233]; Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13; Lancaster S., 2015, Winning Minds; Leite I, 2013, INT J HUM-COMPUT ST, V71, P250, DOI 10.1016/j.ijhcs.2012.09.005; Liu S., 2023, PREPRINT, DOI DOI 10.1101/2023.07.14.23292669; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; OpenAI, 2023, CHATGPT; Pounds G, 2018, DISCOURSE CONTEXT ME, V25, P34, DOI 10.1016/j.dcm.2018.01.008; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reardon Sara., 2023, Scientific American; Riess Helen, 2017, J Patient Exp, V4, P74, DOI 10.1177/2374373517699267; Sanders JJ, 2021, CANCER-AM CANCER SOC, V127, P4258, DOI 10.1002/cncr.33834; Sun YX, 2023, AESTHET SURG J, V43, pNP670, DOI 10.1093/asj/sjad134; Wickham Hadley, 2023, CRAN; Wickham Hadley, 2023, CRAN; Wu JG, 2024, Arxiv, DOI arXiv:2305.10163; Zhao WX, 2023, Arxiv, DOI arXiv:2304.09582	38	3	3	14	20	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	NOV 21	2023	14								1281255	10.3389/fpsyg.2023.1281255	http://dx.doi.org/10.3389/fpsyg.2023.1281255			6	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	AF1A2	38078232	gold, Green Published			2024-07-03	WOS:001116946200001
J	Mai, DHA; Nguyen, LT; Lee, EY				Mai, Dung Hoang Anh; Nguyen, Linh Thanh; Lee, Eun Yeol			TSSNote-CyaPromBERT: Development of an integrated platform for highly accurate promoter prediction and visualization of <i>Synechococcus </i>sp. and <i>Synechocystis</i> sp. through a state-of-the-art natural language processing model BERT	FRONTIERS IN GENETICS			English	Article						deep learning; natural language processing; transformer; promoter prediction; dRNA-Seq; differential RNA sequencing	ESCHERICHIA-COLI; CYANOBACTERIA; RECOGNITION; ANNOTATION; ALIGNMENT; REGIONS	Since the introduction of the first transformer model with a unique self-attention mechanism, natural language processing (NLP) models have attained state-of-the-art (SOTA) performance on various tasks. As DNA is the blueprint of life, it can be viewed as an unusual language, with its characteristic lexicon and grammar. Therefore, NLP models may provide insights into the meaning of the sequential structure of DNA. In the current study, we employed and compared the performance of popular SOTA NLP models (i.e., XLNET, BERT, and a variant DNABERT trained on the human genome) to predict and analyze the promoters in freshwater cyanobacterium Synechocystis sp. PCC 6803 and the fastest growing cyanobacterium Synechococcus elongatus sp. UTEX 2973. These freshwater cyanobacteria are promising hosts for phototrophically producing value-added compounds from CO2. Through a custom pipeline, promoters and non-promoters from Synechococcus elongatus sp. UTEX 2973 were used to train the model. The trained model achieved an AUROC score of 0.97 and F1 score of 0.92. During cross-validation with promoters from Synechocystis sp. PCC 6803, the model achieved an AUROC score of 0.96 and F1 score of 0.91. To increase accessibility, we developed an integrated platform (TSSNote-CyaPromBERT) to facilitate large dataset extraction, model training, and promoter prediction from public dRNA-seq datasets. Furthermore, various visualization tools have been incorporated to address the "black box " issue of deep learning and feature analysis. The learning transfer ability of large language models may help identify and analyze promoter regions for newly isolated strains with similar lineages.	[Mai, Dung Hoang Anh; Nguyen, Linh Thanh; Lee, Eun Yeol] Kyung Hee Univ, Dept Chem Engn, BK21 FOUR Integrated Engn Program, Yongin, South Korea	Kyung Hee University	Lee, EY (corresponding author), Kyung Hee Univ, Dept Chem Engn, BK21 FOUR Integrated Engn Program, Yongin, South Korea.	eunylee@khu.ac.kr	LEE, YS/JTU-4754-2023	Nguyen Thanh, Linh/0000-0003-0886-2708; Mai, Dung/0000-0001-5916-3486; Lee, Eun Yeol/0000-0002-6974-3262	National Research Foundation of Korea (NRF) - Ministry of Science and ICT [2015M3D3A1A01064882]	National Research Foundation of Korea (NRF) - Ministry of Science and ICT(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This research was supported by the C1 Gas Refinery Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (2015M3D3A1A01064882).	Amin R, 2020, BIOINFORMATICS, V36, P4869, DOI 10.1093/bioinformatics/btaa609; Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676; Bhandari N, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.365; Bischler T, 2015, METHODS, V86, P89, DOI 10.1016/j.ymeth.2015.06.012; Burden S, 2005, BIOINFORMATICS, V21, P601, DOI 10.1093/bioinformatics/bti047; Butler JEF, 2002, GENE DEV, V16, P2583, DOI 10.1101/gad.1026202; Cock PJA, 2009, BIOINFORMATICS, V25, P1422, DOI 10.1093/bioinformatics/btp163; da Silva K.P., 2006, 2006 IEEE PROC INT J, P1; Danecek P, 2021, GIGASCIENCE, V10, DOI 10.1093/gigascience/giab008; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Di Salvo M, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2049-x; Dorman CJ, 2019, BMC MOL CELL BIOL, V20, DOI 10.1186/s12860-019-0211-6; Dugar G, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003495; Dzabraev M., 2021, PROC IEEE COMPUT SOC, P1; Feklistov A, 2011, CELL, V147, P1257, DOI 10.1016/j.cell.2011.10.041; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gordon L, 2003, BIOINFORMATICS, V19, P1964, DOI 10.1093/bioinformatics/btg265; He WY, 2018, BMC SYST BIOL, V12, DOI 10.1186/s12918-018-0570-1; Huerta AM, 2003, J MOL BIOL, V333, P261, DOI 10.1016/j.jmb.2003.07.017; Ikeuchi M, 2001, PHOTOSYNTH RES, V70, P73, DOI 10.1023/A:1013887908680; Imamura S, 2009, GENE REGUL SYST BIO, V3, P65; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Kans J., 2022, Entrez programming utilities help; Kato Y, 2021, ADV EXP MED BIOL, V1261, P121, DOI 10.1007/978-981-15-7360-6_10; Kim D, 2019, NAT BIOTECHNOL, V37, P907, DOI 10.1038/s41587-019-0201-4; Kokhlikyan N, 2020, Arxiv, DOI [arXiv:2009.07896, DOI 10.48550/ARXIV.2009.07896]; Li FY, 2021, BRIEF BIOINFORM, V22, P2126, DOI 10.1093/bib/bbaa049; Lin PC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57319-5; Liu B, 2018, BIOINFORMATICS, V34, P33, DOI 10.1093/bioinformatics/btx579; Luan GD, 2019, BIOTECHNOL ADV, V37, P771, DOI 10.1016/j.biotechadv.2019.04.005; Mann S, 2007, NUCLEIC ACIDS RES, V35, DOI 10.1093/nar/gkl1024; Mueller TJ, 2017, SCI REP-UK, V7, DOI 10.1038/srep41569; Nguyen N. G., 2016, J Biomed Sci Eng, V9, P280, DOI [10.4236/jbise.2016, DOI 10.4236/JBISE.2016.95021]; Le NQK, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00305; Oubounyt M, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00286; Paszke A, 2019, ADV NEUR IN, V32; Pattharaprachayakul N, 2020, BIOTECHNOL BIOPROC E, V25, P829, DOI 10.1007/s12257-019-0447-1; Qiao Y, 2020, METAB ENG, V62, P161, DOI 10.1016/j.ymben.2020.08.014; Rahman MS, 2019, MOL GENET GENOMICS, V294, P69, DOI 10.1007/s00438-018-1487-5; Rahman MS, 2019, GENOMICS, V111, P1160, DOI 10.1016/j.ygeno.2018.07.011; Rangannan V, 2010, BIOINFORMATICS, V26, P3043, DOI 10.1093/bioinformatics/btq577; Roh H, 2021, BIORESOURCE TECHNOL, V327, DOI 10.1016/j.biortech.2021.124789; Santos-Merino M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2021523118; Sarnaik A, 2019, ALGAL RES, V37, P57, DOI 10.1016/j.algal.2018.11.010; Song K, 2016, APPL MICROBIOL BIOT, V100, P7865, DOI 10.1007/s00253-016-7510-z; Song Y, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-5238-0; Szabo Q, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw1668; Tan XM, 2018, BIOTECHNOL BIOFUELS, V11, DOI 10.1186/s13068-018-1215-8; Taylor G.M., 2020, BIORXIV; Towsey M, 2008, COMPUT BIOL CHEM, V32, P359, DOI 10.1016/j.compbiolchem.2008.07.009; Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656; Vaswani A, 2017, ADV NEUR IN, V30; Vig, 2019, ARXIV; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu BC, 2020, Arxiv, DOI [arXiv:2006.03677, 10.48550/arxiv.2006.03677, DOI 10.48550/ARXIV.2006.03677]; Xiao X, 2019, GENOMICS, V111, P1785, DOI 10.1016/j.ygeno.2018.12.001; Yang ZL, 2019, ADV NEUR IN, V32; Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482; Zhang M, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab551; Zhang M, 2019, BIOINFORMATICS, V35, P2957, DOI 10.1093/bioinformatics/btz016; Zhou DQ, 2021, Arxiv, DOI arXiv:2103.11886; Zhu Y, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa299	62	3	3	4	14	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		1664-8021		FRONT GENET	Front. Genet.	NOV 29	2022	13								1067562	10.3389/fgene.2022.1067562	http://dx.doi.org/10.3389/fgene.2022.1067562			15	Genetics & Heredity	Science Citation Index Expanded (SCI-EXPANDED)	Genetics & Heredity	7A0LA	36523764	Green Published, gold			2024-07-03	WOS:000898156600001
J	Buhr, CR; Smith, H; Huppertz, T; Bahr-Hamm, K; Matthias, C; Blaikie, A; Kelsey, T; Kuhn, S; Eckrich, J				Buhr, Christoph Raphael; Smith, Harry; Huppertz, Tilman; Bahr-Hamm, Katharina; Matthias, Christoph; Blaikie, Andrew; Kelsey, Tom; Kuhn, Sebastian; Eckrich, Jonas			ChatGPT Versus Consultants: Blinded Evaluation on Answering Otorhinolaryngology Case-Based Questions	JMIR MEDICAL EDUCATION			English	Article						large language models; LLMs; LLM; artificial intelligence; AI; ChatGPT; otorhinolaryngology; ORL; digital health; chatbots; global health; low-and middle-income countries; telemedicine; telehealth; language model; chatbot	ONLINE HEALTH INFORMATION; NONVERBAL-COMMUNICATION; SEEKING; ANXIETY; GOOGLE	Background: Large language models (LLMs), such as ChatGPT (Open AI), are increasingly used in medicine and supplement standard search engines as information sources. This leads to more "consultations" of LLMs about personal medical symptoms.Objective: This study aims to evaluate ChatGPT's performance in answering clinical case-based questions in otorhinolaryngology (ORL) in comparison to ORL consultants' answers.Methods: We used 41 case-based questions from established ORL study books and past German state examinations for doctors. The questions were answered by both ORL consultants and ChatGPT 3. ORL consultants rated all responses, except their own, on medical adequacy, conciseness, coherence, and comprehensibility using a 6-point Likert scale. They also identified (in a blinded setting) if the answer was created by an ORL consultant or ChatGPT. Additionally, the character count was compared. Due to the rapidly evolving pace of technology, a comparison between responses generated by ChatGPT 3 and ChatGPT 4 wasResults: Ratings in all categories were significantly higher for ORL consultants (P<.001). Although inferior to the scores of the ORL consultants, ChatGPT's scores were relatively higher in semantic categories (conciseness, coherence, and comprehensibility) compared to medical adequacy. ORL consultants identified ChatGPT as the source correctly in 98.4% (121/123) of cases. ChatGPT's answers had a significantly higher character count compared to ORL consultants (P<.001). Comparison between responses generated by ChatGPT 3 and ChatGPT 4 showed a slight improvement in medical accuracy as well as a better coherence of the answers provided. Contrarily, neither the conciseness (P=.06) nor the comprehensibility (P=.08) improved significantly despite the significant increase in the mean amount of characters by 52.5% (n= (1470-964)/964; P<.001).Conclusions: While ChatGPT provided longer answers to medical problems, medical adequacy and conciseness were significantly lower compared to ORL consultants' answers. LLMs have potential as augmentative tools for medical care, but their "consultation" for medical problems carries a high risk of misinformation as their high semantic quality may mask contextual deficits.	[Buhr, Christoph Raphael; Huppertz, Tilman; Bahr-Hamm, Katharina; Matthias, Christoph; Eckrich, Jonas] Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Otorhinolaryngol, Mainz, Germany; [Buhr, Christoph Raphael; Blaikie, Andrew] Univ St Andrews, Sch Med, St Andrews, Scotland; [Smith, Harry; Kelsey, Tom] Univ St Andrews, Sch Comp Sci, St Andrews, Scotland; [Kuhn, Sebastian] Philipps Univ Marburg, Inst Digital Med, Marburg, Germany; [Kuhn, Sebastian] Univ Hosp Giessen & Marburg, Marburg, Germany; [Buhr, Christoph Raphael] Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Otorhinolaryngol, Langenbeckstr 1, D-55131 Mainz, Germany	Johannes Gutenberg University of Mainz; University of St Andrews; University of St Andrews; Philipps University Marburg; University Hospital of Giessen & Marburg; Johannes Gutenberg University of Mainz	Buhr, CR (corresponding author), Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Otorhinolaryngol, Langenbeckstr 1, D-55131 Mainz, Germany.	buhrchri@uni-mainz.de	Kuhn, Sebastian/H-5100-2018	Blaikie, Andrew/0000-0001-7913-6872; Bahr-Hamm, Katharina/0000-0001-7428-127X; Smith, Harry/0009-0003-4497-1394; Kelsey, Tom/0000-0002-8091-1458; Kuhn, Sebastian/0000-0002-8031-2973; Buhr, Christoph Raphael/0000-0002-9551-2310				[Anonymous], 2014, BBC; Bass D, 2021, Bloomberg; Boyle Alan., 2020, GEEKWIRE; Caiata-Zufferey M, 2010, QUAL HEALTH RES, V20, P1050, DOI 10.1177/1049732310368404; ChatGPT, 2021, OpenAI; Cocco AM, 2018, MED J AUSTRALIA, V209, P342, DOI 10.5694/mja17.00889; Cuthbertson A., 2019, The Independent; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Fox S, 2013, PEDIATRICS, V131, pS224, DOI 10.1542/peds.2012-3786K; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Grant N, 2023, The New York Times; Jacobs W, 2017, COGENT SOC SCI, V3, DOI 10.1080/23311886.2017.1302785; Jungmann SM, 2020, CLIN PSYCHOL SCI, V8, P306, DOI 10.1177/2167702619894904; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee K, 2014, J MED INTERNET RES, V16, P190, DOI 10.2196/jmir.3706; Lenarz T, 2012, Hals-Nasen-Ohren-Heilkunde; Marcinowicz L, 2010, BRIT J GEN PRACT, V60, P83, DOI 10.3399/bjgp10X483111; Mast MS, 2007, PATIENT EDUC COUNS, V67, P315, DOI 10.1016/j.pec.2007.03.005; McMullan RD, 2019, J AFFECT DISORDERS, V245, P270, DOI 10.1016/j.jad.2018.11.037; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Norr AM, 2014, J BEHAV THER EXP PSY, V45, P402, DOI 10.1016/j.jbtep.2014.04.003; Reineke U, 2007, Facharztprufung Hals-Nasen-Ohrenheilkunde: 1000 kommentierte Prufungsfragen; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Tang HW, 2006, BRIT MED J, V333, P1143, DOI 10.1136/bmj.39003.640567.AE; Thorndike EL, 1920, J APPL PSYCHOL, V4, P25, DOI 10.1037/h0071663; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Vaswani A, 2017, ADV NEUR IN, V30; Wangler J, 2019, DEUT MED WOCHENSCHR, V144, pE102, DOI 10.1055/a-0842-8285; Weise K., 2020, NEW YORK TIMES; Yaeger KA, 2019, HEALTH POLICY TECHN, V8, P192, DOI 10.1016/j.hlpt.2019.05.006; Zielinski C., 2023, Chatbots, generative AI, and scholarly manuscripts. WAME recommendations on Chatbots and generative artificial intelligence in relation to scholarly publications	33	6	6	15	15	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e49183	10.2196/49183	http://dx.doi.org/10.2196/49183			9	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	CI8I2	38051578	Green Submitted, gold, Green Published			2024-07-03	WOS:001124710500002
J	Nazarovets, S; Teixeira da Silva, JA				Nazarovets, Serhii; Teixeira da Silva, Jaime A.			ChatGPT as an "author": Bibliometric analysis to assess the validity of authorship	ACCOUNTABILITY IN RESEARCH-ETHICS INTEGRITY AND POLICY			English	Article; Early Access						Artificial intelligence (AI); authorship principles; ethics; responsibility; transparency		Background: Following the 2023 surge in popularity of large language models like ChatGPT, significant ethical discussions emerged regarding their role in academic authorship. Notable ethics organizations, including the ICMJE and COPE, alongside leading publishers, have instituted ethics clauses explicitly stating that such models do not meet the criteria for authorship due to accountability issues.Objective: This study aims to assess the prevalence and ethical implications of listing ChatGPT as an author on academic papers, in violation of existing ethical guidelines set by the ICMJE and COPE.Methods: We conducted a comprehensive review using databases such as Web of Science and Scopus to identify instances where ChatGPT was credited as an author, co-author, or group author.Results: Our search identified 14 papers featuring ChatGPT in such roles. In four of those papers, ChatGPT was listed as an "author" alongside the journal's editor or editor-in-chief. Several of the ChatGPT-authored papers have accrued dozens, even hundreds of citations according to Scopus, Web of Science, and Google Scholar.Discussion: The inclusion of ChatGPT as an author on these papers raises critical questions about the definition of authorship and the accountability mechanisms in place for content produced by artificial intelligence. Despite the ethical guidelines, the widespread citation of these papers suggests a disconnect between ethical policy and academic practice.Conclusion: The findings suggest a need for corrective measures to address these discrepancies. Immediate review and amendment of the listed papers is advised, highlighting a significant oversight in the enforcement of ethical standards in academic publishing.	[Nazarovets, Serhii] Borys Grinchenko Kyiv Metropolitan Univ, Lib, 18-2 Bulvarno Kudriavska Str, UA-04053 Kiev, Ukraine	Ministry of Education & Science of Ukraine; Borys Grinchenko Kyiv Metropolitan University	Nazarovets, S (corresponding author), Borys Grinchenko Kyiv Metropolitan Univ, Lib, 18-2 Bulvarno Kudriavska Str, UA-04053 Kiev, Ukraine.	sergiy.nazarovets@gmail.com	Nazarovets, Serhii/I-1680-2012	Nazarovets, Serhii/0000-0002-5067-4498				Abalkina A, 2023, LEARN PUBL, V36, P689, DOI 10.1002/leap.1574; Berdejo-Espinola V, 2023, SCIENCE, V379, P991, DOI 10.1126/science.adg9714; Cellular and Molecular Bioengineering, 2024, SUBM GUID; Christopher J, 2021, FEBS LETT, V595, P1751, DOI 10.1002/1873-3468.14143; COPE (Committee on Publication Ethics), 2024, AUTH AI TOOLS; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; ICMJE (International Committee of Medical Journal Editors), 2024, REC; Joelving F, 2024, SCIENCE, V383, P252, DOI 10.1126/science.ado0309; Kaebnick GE, 2023, HASTINGS CENT REP, V53, P3, DOI 10.1002/hast.1507; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Lund BD, 2024, LEARN PUBL, V37, P13, DOI 10.1002/leap.1582; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Prillaman M, 2024, NATURE, V627, P16, DOI 10.1038/d41586-024-00592-w; PubMed, 2024, US; Springer Nature, 2024, AUTHORSHIP; Springer Nature, 2024, AUTH PRINC; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Tang GY, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2180359; Teixeira da Silva J. A., 2023, SCI EDITOR PUBLISHER, V8, P110, DOI [https://doi.org/10.24069/SEP-23-17, DOI 10.24069/SEP-23-17]; Teixeira da Silva JA, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102779; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Teixeira da Silva JA, 2021, PUBLISH RES Q, V37, P90, DOI 10.1007/s12109-021-09784-y; Teixeira da Silva JA, 2017, BANGLADESH J MED SCI, V16, P610; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; van Woudenberg Rene, 2024, Philos Technol, V37, P34, DOI 10.1007/s13347-024-00715-1; Wykes T, 2023, J MENT HEALTH, V32, P865, DOI 10.1080/09638237.2023.2232217	30	1	1	9	9	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0898-9621	1545-5815		ACCOUNT RES	Account. Res.	2024 MAY 3	2024										10.1080/08989621.2024.2345713	http://dx.doi.org/10.1080/08989621.2024.2345713		MAY 2024	11	Medical Ethics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Ethics	PS2Z6	38693669				2024-07-03	WOS:001216019800001
J	Rehaag, S				Rehaag, Sean			Luck of the Draw III: Using AI to Extract Data About Decision-Making in Federal Court Stays of Removal	QUEENS LAW JOURNAL			English	Article							REFUGEE DETERMINATIONS	This article examines decision-making in Federal Court of Canada immigration law applications for stays of removal, focusing on how the rates at which stays are granted depend on which justice decides the case. The article deploys a form of computational natural language processing, using a large-language model machine learning process (GPT-3) to extract data from online Federal Court dockets. The article reviews patterns in outcomes in thousands of stay of removal applications identified through this process and reveals a wide range in stay grant rates across many justices. The article argues that the Federal Court should take measures to encourage more consistency in stay decision-making and cautions against relying heavily on stays of removal to ensure that deportation complies with constitutional procedural justice protections. The article is also a demonstration of how machine learning can be used to pursue empirical legal research projects that would have been cost prohibitive or technically challenging only a few years ago-and shows how technology that is increasingly used to enhance the power of the state at the expense of marginalized migrants can instead be used to scrutinize legal decision-making in the immigration law field, hopefully in ways that enhance the rights of migrants. The article also contributes to the broader field of computational legal research in Canada by making available to other non-commercial researchers the code used for the project, as well as a dataset of several thousand Federal Court dockets that can be used for future research.	[Rehaag, Sean] York Univ, Osgoode Hall Law Sch, Toronto, ON, Canada	York University - Canada	Rehaag, S (corresponding author), York Univ, Osgoode Hall Law Sch, Toronto, ON, Canada.							Aberman Tanya, 2022, Migration & Society, V5, P13; Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Agastya Amogh, 2022, Fine-tuning GPT-3 Using Python to Create a Virtual Mental Health Assistant Bot; Aiken Sharryn J, 2007, Interrogating Race and Racism, P63; Alarie B, 2021, LAW TECHNOL HUMANS, V3, P5, DOI 10.5204/lthj.2089; Altman Sam, 2020, The GPT-3 hype is way too much; [Anonymous], 2012, The Lawyers Weekly; Bell Kristen, 2021, BTLJ, V36, P821; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommarito II Michael J, 2023, Working Paper; Bond Jennifer, 2014, Can Bar Rev, V91, P583; Borzunov A, 2023, Arxiv, DOI [arXiv:2209.01188, 10.48550/arXiv.2209.01188, DOI 10.48550/ARXIV.2209.01188]; Brockman Greg, 2019, OpenAI LP; Brockman Greg, 2019, Microsoft invests in and partners with OpenAI to support us building beneficial AGI; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buchanan B., 2021, Truth, Lies, and Automation: How Language Models Could Change Disinformation, DOI DOI 10.51593/2021CA003; Byrne WH, 2023, J REFUG STUD, DOI 10.1093/jrs/feac069; Cameron HE, 2022, J REFUG STUD, V35, P493, DOI 10.1093/jrs/feab054; CanLII, 2022, Call for Participants; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Cyphert Amy B, 2021, UC Davis L Rev, V55, P413; Dennler Kathryn Tomko, 2022, Deporting Refugees: Hidden Injustice in Canada, P29; Federal Court of Canada, 2022, IMM REF P FC, P5; Federal Court of Canada, Important Notices; Federal Court of Canada, 2018, Notice to the Parties and the Profession: Publication of Court Decisions; Federal Court of Canada, 2021, Strategic Plan 2020-2025; Ghezelbash D, 2023, J REFUG STUD, DOI 10.1093/jrs/fead039; Ghezelbash D, 2022, U NSW LAW J, V45, P1085; Grey Colin, 2016, SCLR (2nd), V76, P136; Hao Karen, 2020, MIT Technology Review17 February; Heaven Will Douglas, 2020, MIT Technology Review20 July; Heckman Gerald., 2017, UNBLJ, V68, P312; Ho DE, 2010, CALIF LAW REV, V98, P813; Hudon Marie-Eve, 2020, Publication; Hugging Face, Models; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Joseph AJ, 2015, DEPORTATION AND THE CONFLUENCE OF VIOLENCE WITHIN FORENSIC MENTAL HEALTH AND IMMIGRATION SYSTEMS, P1, DOI 10.1057/9781137513410; Joundi Talia, 2023, Unfortunate but Ordinary: A Study of Federal Court Approaches to Stays of Removal; Kaushal A, 2022, OSGOODE HALL LAW J, V59, P291; Khan Jonathan, 2023, Ottawa L Rev, V54, P357; Kim JY, 2022, INFORM TECHNOL PEOPL, V35, P861, DOI 10.1108/ITP-04-2019-0173; Leurs Koen, 2022, Research Methodologies and Ethical Challenges in Digital Migration Studies Caring For (Big) Data?, P222, DOI [10.1007/978-3-030-81226-3, DOI 10.1007/978-3-030-81226-3]; Liew Jamie, 2021, Not Just the Luck of the Draw? Exploring Competency of Counsel and Other Qualitative Factors in Federal Court Refugee Leave Determinations (2005-2010), V37, P1; Liew JamieChai Yun Donald Galloway., 2015, Immigration Law, V2nd; Little Andrew D, 2021, Adv Q, V51, P386; Liu TY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6723; Livermore Michael, 2019, Law as Data: Computation, Text, and the Future of Legal Analysis; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Madianou M, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119863146; Marche S., 2022, The Atlantic; Maynard R, 2019, CRIT ETHN STUD, V5, P124, DOI 10.5749/jcritethnstud.5.1-2.0124; McKinney W., 2022, Python for Data Analysis: Data Wrangling with Pandas, Numpy, and Jupyter, V3rd; Metz Cade, 2020, The New York Times24 November; Metz Cade, 2022, The New York Times; Mitra Prasenjit, 2020, The Conversation23 September; Molnar Petra, 2022, Migration, Security, and Resistance: Global and Local Perspectives, P66; Molnar Petra, 2018, Bots at the Gate: A Human Rights Analysis of Automated Decision -Making in Canadas' Immigration and Refugee System, P15; Molnar Petra, 2020, Technological Testing Grounds: Migration Management Experiments and Reflections from the Ground Up; Norris Samuel, 2019, Working Paper No 2018-75; OpenAI, 2015, Introducing OpenAI; OpenAI, 2022, DALLE API Now Available in Public Beta; OpenAI, 2022, Introducing Whisper; OpenAI, 2021, OpenAI's API Now Available with No Waitlist; OpenAI, 2019, GPT-2: 1.5B Release; OpenAI, Supported countries and territories; Python Software Foundation, 2024, re-Regular expression operations; Python Software Foundation, Python; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rehaag S, 2019, QUEENS LAW J, V45, P1; Rehaag S, 2011, OSGOODE HALL LAW J, V49; Rehaag S, 2012, QUEENS LAW J, V38, P1; Rehaag Sean, Luck of the Draw III: Code & Data; Rehaag Sean, 2022, Dal LJ, V45, P188; Richman Danny, 2022, GPT-3 Business Email Generator; Richman Danny, 2022, I mentor a young lad with poor literacy skills who is starting a landscaping business; Rossant C., 2018, IPYTHON INTERACTIVE; Silverman SJ, 2016, REFUG SURV Q, V35, P109, DOI 10.1093/rsq/hdv016; Simonite Tom, 2020, Wired22 July; Smith Craig Damian, 2021, Access to Justice for Refugees: How Legal Aid and Quality of Counsel Impact Fairness and Efficiency in Canadas' Asylum System, DOI [10.2139/ssrn.3980954, DOI 10.2139/SSRN.3980954]; Sweigart Al, 2020, Automate the Boring Stuff: Practical Programming for Total Beginners; Theriault Pierre-Andre, 2022, 2020 stay dockets; Thorley D, 2020, J EMPIR LEGAL STUD, V17, P342, DOI 10.1111/jels.12248; Toews Rob, 2020, Forbes19 July	83	0	0	0	0	QUEENS UNIV, FAC LAW	KINGSTON	KINGSTON, ONTARIO K7L 3N6, CANADA	0316-778X			QUEENS LAW J	Queens Law J.	SPR	2024	49	2					73	126						54	Law	Emerging Sources Citation Index (ESCI)	Government & Law	UA0J3					2024-07-03	WOS:001245221700003
J	Sridharan, K; Sivaramakrishnan, G				Sridharan, Kannan; Sivaramakrishnan, Gowri			Leveraging artificial intelligence to detect ethical concerns in medical research: a case study	JOURNAL OF MEDICAL ETHICS			English	Article; Early Access						Ethics; Informed Consent		Background Institutional review boards (IRBs) have been criticised for delays in approvals for research proposals due to inadequate or inexperienced IRB staff. Artificial intelligence (AI), particularly large language models (LLMs), has significant potential to assist IRB members in a prompt and efficient reviewing process.Methods Four LLMs were evaluated on whether they could identify potential ethical issues in seven validated case studies. The LLMs were prompted with queries related to the proposed eligibility criteria of the study participants, vulnerability issues, information to be disclosed in the informed consent document (ICD), risk-benefit assessment and justification of the use of a placebo. Another query was issued to the LLMs to generate ICDs for these case scenarios.Results All four LLMs were able to provide answers to the queries related to all seven cases. In general, the responses were homogeneous with respect to most elements. LLMs performed suboptimally in identifying the suitability of the placebo arm, risk mitigation strategies and potential risks to study participants in certain case studies with a single prompt. However, multiple prompts led to better outputs in all of these domains. Each of the LLMs included all of the fundamental elements of the ICD for all case scenarios. Use of jargon, understatement of benefits and failure to state potential risks were the key observations in the AI-generated ICD.Conclusion It is likely that LLMs can enhance the identification of potential ethical issues in clinical research, and they can be used as an adjunct tool to prescreen research proposals and enhance the efficiency of an IRB.	[Sridharan, Kannan] Arabian Gulf Univ, Coll Med & Med Sci, Dept Pharmacol & Therapeut, Manama, Bahrain; [Sivaramakrishnan, Gowri] Primary Hlth Care Ctr, Riffa, Bahrain; [Sridharan, Kannan] Arabian Gulf Univ, Dept Pharmacol & Therapeut, Manama, Bahrain	Arabian Gulf University; Arabian Gulf University	Sridharan, K (corresponding author), Arabian Gulf Univ, Dept Pharmacol & Therapeut, Manama, Bahrain.	skannandr@gmail.com	Sivaramakrishnan, Gowri/AAA-1867-2020	Sivaramakrishnan, Gowri/0000-0002-5877-205X				Anderson EE, 2012, J LAW MED ETHICS, V40, P951, DOI 10.1111/j.1748-720X.2012.00724.x; [Anonymous], Claude-Instant-100K©; [Anonymous], Informed consent checklist; [Anonymous], ChatGPT© 4.0; [Anonymous], ChatGPT 3.5©; [Anonymous], 2012, FERCAP/SIDCER handbook of case studies on ethical issues in health research; Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071; CIRB for the National Cancer Institute, ABOUT US; Friesen P, 2023, AM J BIOETHICS, V23, P75, DOI 10.1080/15265161.2022.2063434; Ghooi Ravindra B, 2014, Perspect Clin Res, V5, P60, DOI 10.4103/2229-3485.128020; Gogtay N J, 2011, Indian J Med Ethics, V8, P211; Goldenberg AJ, 2015, BMC MED ETHICS, V16, DOI 10.1186/s12910-015-0020-1; Google Bard, about us; Grant SC, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.10848; Hart Steven N, 2023, J Pathol Inform, V14, P100338, DOI 10.1016/j.jpi.2023.100338; Hemminki E, 2016, HEALTH RES POLICY SY, V14, DOI 10.1186/s12961-016-0078-3; Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037; Jiang LS, 2021, J INT MED RES, V49, DOI 10.1177/03000605211000157; Kadam Rashmi Ashish, 2017, Perspect Clin Res, V8, P107, DOI 10.4103/picr.PICR_147_16; Klitzman Robert, 2019, Ethics Hum Res, V41, P22, DOI 10.1002/eahr.500003; Klitzman RL, 2013, J EMPIR RES HUM RES, V8, P58, DOI 10.1525/jer.2013.8.3.58; Mehta P, 2023, J KOREAN MED SCI, V38, DOI 10.3346/jkms.2023.38.e198; Sharp SM, 2004, AM J CLIN ONCOL-CANC, V27, P570, DOI 10.1097/01.coc.0000135925.83221.b3; Silberman G, 2011, MILBANK Q, V89, P599, DOI 10.1111/j.1468-0009.2011.00644.x; Singh G., 2023, J Integr. Med. Res, V1, P164, DOI [10.4103/jimr.jimr3023, DOI 10.4103/JIMR.JIMR3023]; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Timmers M, 2020, BMC MED ETHICS, V21, DOI 10.1186/s12910-020-00480-8; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Zhao G., A complete guide to running local LLM models	29	1	1	2	2	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0306-6800	1473-4257		J MED ETHICS	J. Med. Ethics	2024 FEB 26	2024										10.1136/jme-2023-109767	http://dx.doi.org/10.1136/jme-2023-109767		FEB 2024	9	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	KD3C8	38408853				2024-07-03	WOS:001177972600001
J	Hijazi, H; Gomes, M; Castelhano, J; Castelo-Branco, M; Praça, I; de Carvalho, P; Madeira, H				Hijazi, Haytham; Gomes, Miguel; Castelhano, Joao; Castelo-Branco, Miguel; Praca, Isabel; de Carvalho, Paulo; Madeira, Henrique			Dynamically predicting comprehension difficulties through physiological data and intelligent wearables	SCIENTIFIC REPORTS			English	Article						Language comprehension; Machine learning; Biosensing; Eye-tracker; Wearable devices		Comprehending digital content written in natural language online is vital for many aspects of life, including learning, professional tasks, and decision-making. However, facing comprehension difficulties can have negative consequences for learning outcomes, critical thinking skills, decision-making, error rate, and productivity. This paper introduces an innovative approach to predict comprehension difficulties at the local content level (e.g., paragraphs). Using affordable wearable devices, we acquire physiological responses non-intrusively from the autonomous nervous system, specifically pulse rate variability, and electrodermal activity. Additionally, we integrate data from a cost-effective eye-tracker. Our machine learning algorithms identify 'hotspots' within the content and regions corresponding to a high cognitive load. These hotspots represent real-time predictors of comprehension difficulties. By integrating physiological data with contextual information (such as the levels of experience of individuals), our approach achieves an accuracy of 72.11% +/- 2.21, a precision of 0.77, a recall of 0.70, and an f1 score of 0.73. This study opens possibilities for developing intelligent, cognitive-aware interfaces. Such interfaces can provide immediate contextual support, mitigating comprehension challenges within content. Whether through translation, content generation, or content summarization using available Large Language Models, this approach has the potential to enhance language comprehension.	[Hijazi, Haytham; de Carvalho, Paulo; Madeira, Henrique] Univ Coimbra, CISUC, P-3004531 Coimbra, Portugal; [Gomes, Miguel; Praca, Isabel] Polytech Porto ISEP IPP, Sch Engn, P-4249015 Porto, Portugal; [Castelhano, Joao] Univ Coimbra, ICNAS, P-3000548 Coimbra, Portugal; [Castelo-Branco, Miguel] Univ Coimbra, ICNAS CIBIT, P-3000548 Coimbra, Portugal	Universidade de Coimbra; Instituto Politecnico do Porto; Universidade de Coimbra; Universidade de Coimbra	Hijazi, H (corresponding author), Univ Coimbra, CISUC, P-3004531 Coimbra, Portugal.	haytham@dei.uc.pt		Hijazi, Haytham/0000-0002-4981-3649	FCT: Fundao para a Cincia e a Tecnologia	FCT: Fundao para a Cincia e a Tecnologia(Fundacao para a Ciencia e a Tecnologia (FCT))	No Statement Available	Ahmad MI, 2020, PERS UBIQUIT COMPUT, DOI 10.1007/s00779-020-01455-7; Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028; Brüser C, 2013, PHYSIOL MEAS, V34, P123, DOI 10.1088/0967-3334/34/2/123; Cain K, 2006, BRIT J EDUC PSYCHOL, V76, P697, DOI 10.1348/000709905X69807; Camm AJ, 1996, CIRCULATION, V93, P1043; Chao CJ, 2017, HUM FACTOR ERGON MAN, V27, P187, DOI 10.1002/hfm.20702; Couceiro R, 2019, I C DEPEND SYS NETWO, P638, DOI 10.1109/DSN.2019.00069; Empatica, Meet embraceplus, the e4 wristband's next-gen successor; Empatica, 2023, E4 wristband; Flesch R., 2007, Flesch-kincaid readability test; Greco A, 2016, IEEE T BIO-MED ENG, V63, P797, DOI 10.1109/TBME.2015.2474131; Hijazi H, 2023, IEEE T SOFTWARE ENG, V49, P626, DOI 10.1109/TSE.2022.3158543; Hijazi H, 2021, IEEE ACCESS, V9, P28393, DOI 10.1109/ACCESS.2021.3058664; humansystems, TLX N. NASA TLX: Task load index; Jang E., 2013, ACHI 2013: The Sixth International Conference on Advances in Computer-Human Interactions, P395; LABERGE D, 1974, COGNITIVE PSYCHOL, V6, P293, DOI 10.1016/0010-0285(74)90015-2; Larmuseau Charlotte., 2019, Frontline Learning Research, V7, P57, DOI DOI 10.14786/FLR.V7I2.403; Ltd. E. E, 2021, B2 key reading text and questions; Ltd. E. E, 2020, A2 key reading text and questions; North B., 2005, Proceedings of the ALTE Berlin Conference, P21; Oakhill J., 2019, Reading development and difficulties: Bridging the gap between research and practice, P83, DOI [DOI 10.1007/978-3-030-26550-25, 10.1007/978-3-030-26550-2_5, DOI 10.1007/978-3-030-26550-2_5]; Pamula VR, 2015, IEEE SENSOR, P873; Sarma P, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102883; Sazuka N, 2024, FRONT HUM NEUROSCI, V18, DOI 10.3389/fnhum.2024.1272121; Semmelmann K, 2018, BEHAV RES METHODS, V50, P451, DOI 10.3758/s13428-017-0913-7; Shatunova O., 2021, J. Ethnic Cult. Stud, V8, P62, DOI [10.29333/ejecs/347, DOI 10.29333/EJECS/347]; Smith AA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-26951-z; Tobii, 2023, Tobii eye-tracker 5l engineered for innovation; Vanneste P, 2021, COGN TECHNOL WORK, V23, P567, DOI 10.1007/s10111-020-00641-0; Whitelam S., Defensive scientific writing or They're out to get you: A guide to writing for the science graduate student; Doost EZ, 2023, ERGONOMICS, V66, P592, DOI 10.1080/00140139.2022.2104381; Zhu LL, 2022, IEEE ICC, P4800, DOI 10.1109/ICC45855.2022.9838970	32	0	0	0	0	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	JUN 13	2024	14	1							13678	10.1038/s41598-024-63654-z	http://dx.doi.org/10.1038/s41598-024-63654-z			17	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UP5L2	38871820	Green Accepted, gold			2024-07-03	WOS:001249273400049
J	Gerald, T; Tamames, L; Ettayeb, S; Le, HQ; Paroubek, P; Vilnat, A				Gerald, Thomas; Tamames, Louis; Ettayeb, Sofiane; Le, Ha-Quang; Paroubek, Patrick; Vilnat, Anne			CQuAE: A new Contextualized QUestion Answering corpus on Education domain	DATA & KNOWLEDGE ENGINEERING			English	Article						Corpus; Question-answering; Question generation; Education		Generating education -related questions and answers remains an open issue while being useful for students, teachers, and teaching aids. Given textual course material, we are interested in generating non-factual questions that require an elaborate answer (relying on analysis or reasoning). Despite the availability of annotated corpora of questions and answers, the effort to develop a generator using deep learning faces two main challenges. Firstly, freely accessible and qualitative data are insufficient to train generative approaches. Secondly, for a standalone application, we do not have explicit support to guide the generation toward complex questions. To tackle the first issue, we propose a new corpus based on education documents. For the second point, we propose to study several retargetable language algorithms to produce answers by extracting text spans from contextual documents to help the generation of questions. We particularly study the contribution of deep neural syntactic parsing and transformer -based semantic representation, taking into account the question type (according to our specific question typology) and the contextual support text span. Additionally, recent advances in generation models have proven the efficiency of the instruction -based approach for natural language generation. Consequently, we propose a first investigation of very large language models to generate questions related to the education domain.	[Gerald, Thomas; Tamames, Louis; Paroubek, Patrick; Vilnat, Anne] Univ Paris Saclay, CNRS, LISN, Orsay, France; [Gerald, Thomas; Tamames, Louis] SATT Paris Saclay, Orsay, France; [Ettayeb, Sofiane; Le, Ha-Quang] Stellia, Paris, France	Universite Paris Cite; Centre National de la Recherche Scientifique (CNRS); Universite Paris Saclay	Gerald, T (corresponding author), Univ Paris Saclay, CNRS, LISN, Orsay, France.	thomas.gerald@lisn.upsaclay.fr			SATT-Paris-Saclay; Company Stellia	SATT-Paris-Saclay; Company Stellia(Australian Wool Innovation)	This work was granted access to the HPC resources of IDRIS under the allocation 20XX-AD011013721 made by GENCI, France. And the data collection and annotation was financed by the SATT-Paris-Saclay and the company Stellia.	Anantha R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P520; Antoine Elie, 2022, 29 C TRAIT AUT LANG; Bechet Frederic, 2019, ACT C TRAIT AUT LANG; Bechet Frederic, 2022, CIRCLE JOINT C INF R; Brown Tom B., 2020, Preprints; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174; Chung H.W., 2022, SCALING INSTRUCTION; Chunting Zhou, 2023, LIMA: Less is more for alignment; dHoffschmidt Martin, 2020, arXiv; Eddine MK, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9369; Elgohary A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5918; Fabbri Alexander R., 2020, Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering; Gerald Thomas, 2023, C EXTR GEST CONN EGC; Gerald Thomas, 2023, 10 LANG TECHN C; Grootendorst M., 2020, Keybert: Minimal keyword extraction with bert; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang Jiaxin, 2022, Large language models can self-improve; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Keraron R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5481; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Kingma D. P., 2017, ARXIV; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Le H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2479; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin Chin-Yew, 2004, P 42 ANN M ASS COMPU, P605, DOI DOI 10.3115/1218955.1219032; Liu XD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1694; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; Martin Louis, 2020, P 58 ANN M ASS COMP, P7203, DOI [DOI 10.18653/V1/2020.ACL-MAIN.645, 10.18653/v1/2020.aclmain.645]; Nema P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3950; Nguyen Tri, 2016, CEUR Workshop Proceedings, V1773; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pfeiffer J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P46; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar Pranav, 2016, EMNLP ASS COMPUTATIO; Surdeanu M., 2010, Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, P649; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wolfe J.H., 1976, AUTOMATIC QUESTION G; Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442; Zhang ZS, 2021, AAAI CONF ARTIF INTE, V35, P14506; Zi KL, 2019, LECT NOTES ARTIF INT, V11776, P339, DOI 10.1007/978-3-030-29563-9_30	48	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0169-023X	1872-6933		DATA KNOWL ENG	Data Knowl. Eng.	MAY	2024	151								102305	10.1016/j.datak.2024.102305	http://dx.doi.org/10.1016/j.datak.2024.102305			13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ST3J8					2024-07-03	WOS:001236656500001
J	Goktas, P; Kucukkaya, A; Karacay, P				Goktas, Polat; Kucukkaya, Aycan; Karacay, Pelin			Utilizing GPT 4.0 with prompt learning in nursing education: A case study approach based on Benner's theory	TEACHING AND LEARNING IN NURSING			English	Article						Artificial intelligence; Benner's theory; ChatGPT; Nursing education; Skill acquisition	CLINICAL JUDGMENT; NOVICE; MODEL	Background: Artificial intelligence (AI) and large language models, such as ChatGPT, have the potential to enhance nursing education by serving as a virtual mentor who can provide real-time guidance and resources. However, integrating AI chatbots into nursing necessitates a detailed understanding of how to align these technologies with established nursing theories. Aim: To develop guidelines on how to employ GPT 4.0 using the prompt learning method. Methods: In the method of prompt learning, users give specific prompts, and the AI model reacts according to its training, specifically aligned with the progression of knowledge and skills in nursing education as outlined by Benner 's theory. This study used a case study methodology. Results: The customization of a conversational AI chatbot is shown to support the development of nursing knowledge and skills. This paper outlines how to integrate Benner 's theory with ChatGPT 's capabilities, addresses bias issues, and establishes best practices for the safe and effective use of AI in nursing. Conclusion: The findings have important implications for the advancement of nursing education and the safe and responsible use of AI tools in clinical environments. (c) 2023 Organization for Associate Degree Nursing. Published by Elsevier Inc. All rights reserved.	[Goktas, Polat] Univ Coll Dublin, UCD Sch Comp Sci, Dublin, Ireland; [Goktas, Polat] CeADAR: Irelands Ctr Appl Arti fi cial Intelligenc, Dublin, Ireland; [Kucukkaya, Aycan] Koc Univ Hosp, Dept Hematol Inpatient Serv, Istanbul, Turkiye; [Karacay, Pelin] Koc Univ, Sch Nursing, Istanbul, Turkiye	University College Dublin; Koc University; Koc University	Goktas, P (corresponding author), Univ Coll Dublin, UCD Sch Comp Sci, Dublin, Ireland.; Goktas, P (corresponding author), CeADAR: Irelands Ctr Appl Arti fi cial Intelligenc, Dublin, Ireland.	polat.goktas@ucd.ie; aycannkucukkaya@gmail.com; pkaracay@ku.edu.tr		GOKTAS, POLAT/0000-0001-7183-6890; Kucukkaya, Aycan/0009-0001-9560-6165				Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed SK, 2023, ANN BIOMED ENG, V51, P2351, DOI 10.1007/s10439-023-03262-6; Alkhaqani A. L., 2023, Al-Rafidain Journal of Medical Sciences, V4, P50; Allen C, 2023, INT J NURS STUD, V145, DOI 10.1016/j.ijnurstu.2023.104522; [Anonymous], 1980, A five-stage model of mental activities involved in directed skill acquisition; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; BENNER P, 1982, AM J NURS, V82, P402, DOI 10.2307/3462928; Benner P., 1984, AM J NURS, V84, P1480, DOI [DOI 10.1097/00000446-198412000-00025, 10.1002/nur.4770080119, DOI 10.1002/NUR.4770080119]; De Gagne Jennie C, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20064884; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Goktas P, 2024, J AM COLL RADIOL, V21, P224, DOI 10.1016/j.jacr.2023.07.023; Goktas P, 2023, SKIN RES TECHNOL, V29, DOI 10.1111/srt.13417; Goktas P, 2023, J ALLER CL IMM-PRACT, V11, P2697, DOI 10.1016/j.jaip.2023.05.042; Google, 2023, Introducing PaLM 2; Google, 2023, Bard; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Hisan U. K., 2023, Journal of Pedagogy and Education Science, V2, P71, DOI [DOI 10.56741/JPES.V2I01.302, 10.56741/jpes.v2i01.302]; Hughes A., 2023, BBC Science Focus Magazine; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; McCarthy J, 2023, TEACH LEARN NURS, V18, P355, DOI 10.1016/j.teln.2023.03.018; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Miao Hongyu, 2023, Asian Pac Isl Nurs J, V7, pe48136, DOI 10.2196/48136; Mufti F., 2023, Southeast Eur. J. Soft Comput, V12, P13, DOI [10.21533/scjournal, DOI 10.21533/SCJOURNAL]; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887; Parviainen J, 2022, MED HEALTH CARE PHIL, V25, P61, DOI 10.1007/s11019-021-10049-w; Reed D, 2011, Vital, V8, P44; Rusandi MA, 2023, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdad049; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; Seney V, 2023, NURS EDUC, V48, P124, DOI 10.1097/NNE.0000000000001383; Sun GH, 2023, NURS EDUC, V48, P119, DOI 10.1097/NNE.0000000000001390; Tanner CA, 2006, J NURS EDUC, V45, P204, DOI 10.3928/01484834-20060601-04; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Thomas CM, 2017, NURS SCI QUART, V30, P227, DOI 10.1177/0894318417708410; Vitorino LM, 2023, J CLIN NURS, V32, P7921, DOI 10.1111/jocn.16706	39	1	1	2	2	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	1557-3087	1557-2013		TEACH LEARN NURS	Teach. Learn. Nurs.	APR	2024	19	2					e358	e367		10.1016/j.teln.2023.12.014	http://dx.doi.org/10.1016/j.teln.2023.12.014			10	Nursing	Emerging Sources Citation Index (ESCI)	Nursing	TF1K0					2024-07-03	WOS:001239753200001
J	Berrezueta-Guzman, S; Kandil, M; Martín-Ruiz, ML; de la Cruz, IP; Krusche, S				Berrezueta-Guzman, Santiago; Kandil, Mohanad; Martin-Ruiz, Maria-Luisa; de la Cruz, Ivan Pau; Krusche, Stephan			Future of ADHD Care: Evaluating the Efficacy of ChatGPT in Therapy Enhancement	HEALTHCARE			English	Article						artificial intelligence; LLMs; cognitive therapy; ADHD; ChatGPT; customizable AI bots; robotic systems in therapy; sensory data integration; AI-driven decision making; occupationaltherapy innovation; personalized therapy sessions; AI in mental health; computational cognitive tools	ROBOT-ASSISTED THERAPY; HOMEWORK ACTIVITIES; CHILDREN; AUTISM	This study explores the integration of large language models (LLMs), like ChatGPT, to improve attention deficit hyperactivity disorder (ADHD) treatments. Utilizing the Delphi method for its systematic forecasting capabilities, we gathered a panel of child ADHD therapy experts. These experts interacted with our custom ChatGPT through a specialized interface, thus engaging in simulated therapy scenarios with behavioral prompts and commands. Using empirical tests and expert feedback, we aimed to rigorously evaluate ChatGPT's effectiveness in therapy settings to integrate AI into healthcare responsibly. We sought to ensure that AI contributes positively and ethically to therapy and patient care, thus filling a gap in ADHD treatment methods. Findings show ChatGPT's empathy, adaptability, and communication strengths, thereby highlighting its potential to significantly improve ADHD care. The study points to ChatGPT's capacity to transform therapy practices through personalized and responsive patient care. However, it also notes the need for enhancements in privacy, cultural sensitivity, and interpreting nonverbal cues for ChatGPT's effective healthcare integration. Our research advocates for merging technological innovation with a comprehensive understanding of patient needs and ethical considerations, thereby aiming to pioneer a new era of AI-assisted therapy. We emphasize the ongoing refinement of AI tools like ChatGPT to meet ADHD therapy and patient care requirements more effectively.	[Berrezueta-Guzman, Santiago; Kandil, Mohanad; Krusche, Stephan] Tech Univ Munich, Sch Computat Informat & Technol, Appl Software Engn Res Grp, D-80333 Munich, Germany; [Martin-Ruiz, Maria-Luisa; de la Cruz, Ivan Pau] Univ Politecn Madrid, Dept Ingn Telematica & Elect, Grp Invest Innovac Tecnol Personas InnoTep, ETSIS Telecomunicac, Campus Sur, Madrid 28031, Spain	Technical University of Munich; Universidad Politecnica de Madrid	Berrezueta-Guzman, S (corresponding author), Tech Univ Munich, Sch Computat Informat & Technol, Appl Software Engn Res Grp, D-80333 Munich, Germany.	s.berrezueta@tum.de; mohanad.kandil@tum.de; marialuisa.martinr@upm.es; ivan.pau@upm.es; krusche@tum.de	; MARTIN RUIZ, MARIA LUISA/F-3782-2016; PAU DE LA CRUZ, IVAN/G-2374-2016	Kandil, Mohanad/0009-0009-9713-098X; Berrezueta-Guzman, Jonnathan Santiago/0000-0001-5559-2056; MARTIN RUIZ, MARIA LUISA/0000-0002-4355-3620; PAU DE LA CRUZ, IVAN/0000-0002-1183-4401				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amato F, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369633; Arpaia P, 2020, IEEE T INSTRUM MEAS, V69, P6362, DOI 10.1109/TIM.2020.2970846; Benjamins R., 2019, arXiv; Berrezueta-Guzman J., 2022, Hum. Factors Robot. Drones Unmanned Syst, V57, P31; Berrezueta-Guzman J., 2022, Proceedings of SAI Intelligent Systems Conference, P661; Berrezueta-Guzman J, 2023, LECT NOTES COMPUT SC, V14417, P104, DOI 10.1007/978-3-031-48348-6_9; Berrezueta-Guzman J, 2022, IEEE ACCESS, V10, P608, DOI 10.1109/ACCESS.2021.3137082; Berrezueta-Guzman J, 2021, IEEE ACCESS, V9, P93450, DOI 10.1109/ACCESS.2021.3093233; Berrezueta-Guzman J, 2020, IEEE ACCESS, V8, P160251, DOI 10.1109/ACCESS.2020.3020734; Bertacchini F, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1232177; Chen CY, 2023, Arxiv, DOI arXiv:2311.05656; Chen CY, 2024, Arxiv, DOI arXiv:2309.13788; Cho Y, 2023, Arxiv, DOI arXiv:2311.09243; Chronis-Tuscano A, 2013, AM J PSYCHIAT, V170, P799, DOI 10.1176/appi.ajp.2013.13030293; Epstein JN, 2013, NEUROPSYCHIATRY-LOND, V3, P455, DOI 10.2217/npy.13.59; Estévez D, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13052771; Faraone SV, 2014, CHILD ADOL PSYCH CL, V23, pXIII, DOI 10.1016/j.chc.2014.06.004; Gabor-Siatkowska K, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12224694; Gargot T, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.596055; Grohs MN, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85391-3; Gupta M, 2023, Arxiv, DOI [arXiv:2307.00691, 10.1109/ACCESS.2023.3300381, DOI 10.1109/ACCESS.2023.3300381]; Hebenstreit K, 2023, Arxiv, DOI [arXiv:2305.02897, DOI 10.48550/ARXIV.2305.02897]; Hodgson K, 2014, J ATTEN DISORD, V18, P275, DOI 10.1177/1087054712444732; Israel N.S., 2021, J. Arts Sci. Technol, V13, P63; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kamra V, 2021, INT CO SIG PROC COMM, P494, DOI 10.1109/ICSPC51351.2021.9451785; Kim R, 2024, J DEV BEHAV PEDIATR, V45, pe8, DOI 10.1097/DBP.0000000000001255; Kostrubiec V, 2024, INT J SOC ROBOT, V16, P281, DOI 10.1007/s12369-023-01063-4; Krichmar JL, 2018, PROCEEDINGS OF THE TECHNOLOGY, MIND, AND SOCIETY CONFERENCE (TECHMINDSOCIETY'18), DOI 10.1145/3183654.3183657; Kumazaki H, 2021, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.598688; Lai YH, 2021, SOFTWARE PRACT EXPER, V51, P595, DOI 10.1002/spe.2866; Li Y, 2017, MOL NEUROBIOL, V54, P6655, DOI 10.1007/s12035-016-0179-6; Lin BH, 2023, Arxiv, DOI [arXiv:2304.00416, 10.48550/arXiv.2304.00416, DOI 10.48550/ARXIV.2304.00416]; Liu Y, 2024, Arxiv, DOI [arXiv:2305.13860, DOI 10.48550/ARXIV.2305.13860, 10.48550/arXiv.2305.13860]; Lopez-Perez L., 2020, P C INF COMM TECHN E, P22; Moraiti I, 2023, INT J ONLINE BIOMED, V19, P145, DOI 10.3991/ijoe.v19i16.43399; Nasa Prashant, 2021, World J Methodol, V11, P116, DOI 10.5662/wjm.v11.i4.116; Park JI, 2023, BMC COMPLEMENT MED, V23, DOI 10.1186/s12906-022-03832-6; Qiu HC, 2023, Arxiv, DOI arXiv:2307.08487; Rakhymbayeva N, 2020, ACMIEEE INT CONF HUM, P401, DOI 10.1145/3371382.3378356; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Stella F, 2023, NAT MACH INTELL, V5, P561, DOI 10.1038/s42256-023-00669-7; Subramonyam H, 2024, Arxiv, DOI arXiv:2309.14459; Taheri Alireza, 2021, Paladyn, Journal of Behavioral Robotics, V12, P256, DOI 10.1515/pjbr-2021-0018; Tamdjidi R., ChatGPT as an Assistive Technology to Enhance Reading Comprehension for Individuals with ADHD; Tao GH, 2023, Arxiv, DOI arXiv:2401.00905; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Vita S., 2019, P 1 S PSYCH BAS TECH; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Wang ZHL, 2024, Arxiv, DOI arXiv:2307.05300; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324; Wolraich M, 2011, PEDIATRICS, V128, P1007, DOI 10.1542/peds.2011-2654; Wolraich ML, 2019, PEDIATRICS, V144, DOI 10.1542/peds.2019-2528; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Young Z, 2020, J ATTEN DISORD, V24, P875, DOI 10.1177/1087054716664413; Yu JH, 2024, Arxiv, DOI arXiv:2311.11538; Zhanatkyzy A, 2020, ACMIEEE INT CONF HUM, P541, DOI 10.1145/3371382.3378254	58	0	0	15	15	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9032		HEALTHCARE-BASEL	Healthcare	MAR	2024	12	6							683	10.3390/healthcare12060683	http://dx.doi.org/10.3390/healthcare12060683			19	Health Care Sciences & Services; Health Policy & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services	MI3C9	38540647	Green Published, gold			2024-07-03	WOS:001192945000001
J	Frick, TW				Frick, Theodore W.			Are We Dupes? Limitations of AI Systems: What Should Educators Do with Them?	TECHTRENDS			English	Article						Artificial intelligence systems; General systems theory; Chatbots; Educology; Critical thinking; Qualitative knowing; Quantitative knowing; Neural networks; Culture; Worthwhile education		Extant chatbots such as ChatGPT and Bard are currently able to converse with humans in natural language, demonstrating impressive linguistic responses. Or so it seems. I critically examine artificial intelligence systems such as these chatbots through examples of dialogue. When taking a systems view of AI, there is a vast and unique human culture in the environmental surroundings of the AI system (its negasystem) that is not accessible to extant AI systems. These generative AI systems, based on large language models, are trained with trillions of signs created by humans in the form of digital text and images as part of their machine learning from which they construct their unique neural networks. However, AI systems do not understand well, if at all, the meanings of those signs that we associate with our human experience of the world and our culture (i.e., in the AI negasystem). Similarly, we humans do not understand well the inner workings of an AI system (its neural network). Teachers and students in education must be very careful and cautious when using such AI systems. Are we dupes? Or not? Without thinking critically and checking facts independently, we can be fooled by responses of those AI systems.	[Frick, Theodore W.] Indiana Univ, Sch Educ, Dept Instruct Syst Technol, Bloomington, IN 47405 USA	Indiana University System; Indiana University Bloomington	Frick, TW (corresponding author), Indiana Univ, Sch Educ, Dept Instruct Syst Technol, Bloomington, IN 47405 USA.	frick@indiana.edu		Frick, Theodore/0000-0003-2488-9396				[Anonymous], 1990, Probabilistic Reasoning in Expert Systems: Theory and Algorithms; ATIS, 2019, AX THEOR INT SYST; Bard, 2023, EXP V1 0; Bateson Gregory, 1979, MIND NATURE NECESSAR; Bogost Ian., 2023, Atlantic; Bruner JS, 1990, ACTS MEANING; Chomsky N., 2023, NEW YORK TIMES; Collins E., 2021, Lamda: Our breakthrough conversation technology; Deng L, 2018, IEEE SIGNAL PROC MAG, V35, P180, DOI 10.1109/MSP.2017.2762725; Dreyfus H. L., 1992, What computers still can't do.; Educology, 2020, KNOWING HOW; Educology, 2020, AFF REL STRUCT; Educology, 2020, AFF REL TEMP; Educology, 2020, KNOW ON; Educology, 2020, CRIT KNOW; Educology, 2020, APPR KNOW ON; Educology, 2020, SIGN; Educology, 2020, CREAT KNOW; Educology, 2020, KNOWING; Frick T. W., 2008, ANN C ASS ED COMM TE; Frick T.W., 1991, RESTRUCTURING ED TEC; Frick TW, 2022, ETR&D-EDUC TECH RES, V70, P1, DOI 10.1007/s11423-021-10077-6; Frick TW, 2020, TECHTRENDS, V64, P693, DOI 10.1007/s11528-020-00527-y; Frick TW, 1997, J EDUC COMPUT RES, V16, P107, DOI 10.2190/4CWM-6JF2-T2DN-QG8L; Greenspan S.I., 1997, The growth of the mind and the endangered origins of intelligence; Hofstadter D., 2018, The shallowness of Google Translate; Hofstadter D., 2023, GODEL ESCHER BACH AI; Huang Kalley., 2023, NEW YORK TIMES; IPTAT: Indiana University Plagiarism Tutorials and Tests, 2023, OV R U DUP; Lanier J., 2023, NEW YORKER; Maccia E.S. Maccia., 1966, Development of educational theory derived from three theory models; Marcus G., 2020, REBOOTING AI BUILDIN; Peirce CharlesS., 1932, Collected Papers. Elements of Logic, VII; Perrigo B, 2023, Time Magazine; Pichai S., 2023, COMMUNICATION; Roose K., 2023, NEW YORK TIMES; Schulman J, 2022, Introducing chatgpt; Sharples Mike, 2022, New AI tools that can write student essays require educators to rethink teaching and assessment; Thompson K.R., 2008, ATIS graph theory; Thompson K. R., 2005, SCI INQUIRY J, V7; Thompson K. R., 2019, ATIS GLOSSARY SYSTEM; Tyson N.D., 2023, Twitter; Von Bertalanffy L., 1972, ACAD MANAGE J, V15, P407, DOI [10.5465/255139, DOI 10.5465/255139, DOI 10.2307/255139, 10.2307/255139]; Winston P., 1984, COMMERCIAL USES ARTI; Wolfram S., 2023, WRITINGS	45	0	0	14	33	SPRINGER INT PUBL AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	8756-3894	1559-7075		TECHTRENDS	TechTrends	JAN	2024	68	1			SI		14	26		10.1007/s11528-023-00893-3	http://dx.doi.org/10.1007/s11528-023-00893-3		SEP 2023	13	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	EH5R3					2024-07-03	WOS:001069494100001
J	Xu, JS; Mazwi, M; Johnson, AEW				Xu, Justin; Mazwi, Mjaye; Johnson, Alistair E. W.			AnnoDash, a clinical terminology annotation dashboard	JAMIA OPEN			English	Article						clinical concepts; ontology; annotation; natural language processing; software	LABORATORY DATA; FRAMEWORK; LOINC	Background: Standard ontologies are critical for interoperability and multisite analyses of health data. Nevertheless, mapping concepts to ontologies is often done with generic tools and is labor-intensive. Contextualizing candidate concepts within source data is also done in an ad hoc manner. Methods and Results: We present AnnoDash, a flexible dashboard to support annotation of concepts with terms from a given ontology. Text-based similarity is used to identify likely matches, and large language models are used to improve ontology ranking. A convenient interface is provided to visualize observations associated with a concept, supporting the disambiguation of vague concept descriptions. Time-series plots contrast the concept with known clinical measurements. We evaluated the dashboard qualitatively against several ontologies (SNOMED CT, LOINC, etc.) by using MIMIC-IV measurements. The dashboard is web-based and step-by-step instructions for deployment are provided, simplifying usage for nontechnical audiences. The modular code structure enables users to extend upon components, including improving similarity scoring, constructing new plots, or configuring new ontologies. Conclusion: AnnoDash, an improved clinical terminology annotation tool, can facilitate data harmonizing by promoting mapping of clinical data. AnnoDash is freely available at https://github.com/justin13601/AnnoDash (https://doi.org/10.5281/zenodo.8043943).	[Xu, Justin; Johnson, Alistair E. W.] Hosp Sick Children, Child Hlth Evaluat Sci, Toronto, ON, Canada; [Mazwi, Mjaye] Hosp Sick Children, Dept Crit Care Med, Toronto, ON, Canada; [Johnson, Alistair E. W.] Hosp Sick Children, Child Hlth Evaluat Sci, 686 Bay St, Toronto, ON M5G 0A4, Canada	University of Toronto; Hospital for Sick Children (SickKids); University of Toronto; Hospital for Sick Children (SickKids); University of Toronto; Hospital for Sick Children (SickKids)	Johnson, AEW (corresponding author), Hosp Sick Children, Child Hlth Evaluat Sci, 686 Bay St, Toronto, ON M5G 0A4, Canada.	alistair.johnson@sickkids.ca		Xu, Justin/0000-0003-4700-6277				Ahmadian L, 2011, INT J MED INFORM, V80, P81, DOI 10.1016/j.ijmedinf.2010.11.006; Baorto DM, 1998, INT J MED INFORM, V51, P29, DOI 10.1016/S1386-5056(98)00089-6; Chute CG, 1998, J AM MED INFORM ASSN, V5, P503, DOI 10.1136/jamia.1998.0050503; Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279; Drenkhahn C, 2019, STUD HEALTH TECHNOL, V264, P108, DOI 10.3233/SHTI190193; Hossain S., 2019, PYTH SCI C AUST TEX, P126, DOI [10.25080/Majora-7ddc1dd1-012, DOI 10.25080/MAJORA-7DDC1DD1-012]; Johnson A., 2023, MIMIC 4 PHYSIONET; Johnson Alistair, 2023, PN, DOI 10.13026/DP1F-EX47; Johnson AEW, 2023, SCI DATA, V10, DOI 10.1038/s41597-022-01899-x; Lin Ming-Chin, 2011, AMIA Annu Symp Proc, V2011, P805; Lin Ming-Chin, 2010, AMIA Annu Symp Proc, V2010, P447; McDonald CJ, 2003, CLIN CHEM, V49, P624, DOI 10.1373/49.4.624; Murdoch TB, 2013, JAMA-J AM MED ASSOC, V309, P1351, DOI 10.1001/jama.2013.393; Parr SK, 2018, J AM MED INFORM ASSN, V25, P1292, DOI 10.1093/jamia/ocy110; Plotly Technologies Inc, 2015, Collaborative Data Science; Safran C, 2007, J AM MED INFORM ASSN, V14, P1, DOI 10.1197/jamia.M2273; Schuemie M., 2021, USAGI VERSION 1 4 3; Xu J., 2023, JUSTIN13601ANNODASH, DOI [10.5281/zenodo.8043943, DOI 10.5281/ZENODO.8043943]	18	0	0	0	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND		2574-2531		JAMIA OPEN	JAMIA Open	JUL 4	2023	6	3							ooad046	10.1093/jamiaopen/ooad046	http://dx.doi.org/10.1093/jamiaopen/ooad046			6	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	L8MO7	37425489	gold, Green Published			2024-07-03	WOS:001025752700002
C	Wu, X; Magnani, A; Chaidaroon, S; Puthenputhussery, A; Liao, C; Fang, Y			ACM	Wu, Xuyang; Magnani, Alessandro; Chaidaroon, Suthee; Puthenputhussery, Ajit; Liao, Ciya; Fang, Yi			A Multi-task Learning Framework for Product Ranking with BERT	PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22)			English	Proceedings Paper	31st ACM Web Conference (WWW)	APR 25-29, 2022	ELECTR NETWORK	Assoc Comp Machinery, ACM SIGWEB, LIRIS, Univ Lyon, Inst Natl Sci Appliquees, Eurecom		Product Search; Multi-task Learning; Neural Information Retrieval	NETWORKS	Product ranking is a crucial component for many e-commerce services. One of the major challenges in product search is the vocabulary mismatch between query and products, which may be a larger vocabulary gap problem compared to other information retrieval domains. While there is a growing collection of neural learning to match methods aimed specifically at overcoming this issue, they do not leverage the recent advances of large language models for product search. On the other hand, product ranking often deals with multiple types of engagement signals such as clicks, add-to-cart, and purchases, while most of the existing works are focused on optimizing one single metric such as click-through rate, which may suffer from data sparsity. In this work, we propose a novel end-to-end multi-task learning framework for product ranking with BERT to address the above challenges. The proposed model utilizes domain-specific BERT with fine-tuning to bridge the vocabulary gap and employs multi-task learning to optimize multiple objectives simultaneously, which yields a general end-to-end learning framework for product search. We conduct a set of comprehensive experiments on a real-world e-commerce dataset and demonstrate significant improvement of the proposed approach over the state-of-the-art baseline methods.	[Wu, Xuyang; Fang, Yi] Santa Clara Univ, Santa Clara, CA USA; [Magnani, Alessandro; Chaidaroon, Suthee; Puthenputhussery, Ajit; Liao, Ciya] Walmart Global Tech, Sunnyvale, CA USA	Santa Clara University	Wu, X (corresponding author), Santa Clara Univ, Santa Clara, CA USA.	xwu5@scu.edu; alessandro.magnani@walmart.com; suthee.chaidaroon@walmart.com; ajit.puthenputhussery@walmart.com; ciya.liao@walmart.com; yfang@scu.edu		Wu, Xuyang/0000-0002-8807-0016				[Anonymous], 2011, CIKM; Bi Keping, 2019, SIGIR CEUR WORKSHOP, V2410; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duan HZ, 2013, PROC VLDB ENDOW, V6, P1786, DOI 10.14778/2556549.2556562; Gao C, 2021, IEEE T KNOWL DATA EN, V33, P2588, DOI 10.1109/TKDE.2019.2958808; Gao C, 2019, PROC INT CONF DATA, P1554, DOI 10.1109/ICDE.2019.00140; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lin M., 2014, ARXIV; Long Bo, 2012, CIKM, P2479; Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007; Ma X, 2018, ACM/SIGIR PROCEEDINGS 2018, P1137, DOI 10.1145/3209978.3210104; Magnani A, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P367, DOI 10.1145/3308560.3316603; Mitra B, 2018, FOUND TRENDS INF RET, V13, P1, DOI 10.1561/1500000061; Nogueira R, 2020, Arxiv, DOI [arXiv:1901.04085, DOI 10.48550/ARXIV.1901.04085]; Onal KD, 2018, INFORM RETRIEVAL J, V21, P111, DOI 10.1007/s10791-017-9321-y; Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371; Qiao YF, 2019, Arxiv, DOI arXiv:1904.07531; Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]; Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129; Sarvi Fatemeh, 2020, SIGIR; Shazeer Noam, 2017, PROC INT C LEARNING; Shen Yelong, 2014, P 23 ACM INT C C INF, P101, DOI DOI 10.1145/2661829.2661935; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tang HY, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P269, DOI 10.1145/3383313.3412236; Trotman Andrew, 2017, SIGIR CEUR WORKSHOP, V2311; Van Gysel C, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P165, DOI 10.1145/2983323.2983702; Vandenhende S, 2022, IEEE T PATTERN ANAL, V44, P3614, DOI 10.1109/TPAMI.2021.3054719; Vaswani A, 2017, ADV NEUR IN, V30; Wen H, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2377, DOI 10.1145/3397271.3401443; Wu L, 2018, ACM/SIGIR PROCEEDINGS 2018, P365, DOI 10.1145/3209978.3209993; Xi DB, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3745, DOI 10.1145/3447548.3467071; Zamani H, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P700, DOI 10.1145/3159652.3159730; Zhang Y, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2390, DOI 10.1145/3308558.3313468	40	4	5	1	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9096-5				2022							493	501		10.1145/3485447.3511977	http://dx.doi.org/10.1145/3485447.3511977			9	Computer Science, Cybernetics; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT8BZ		Green Submitted			2024-07-03	WOS:000852713000051
J	Chen, YZ; Kong, LY; Wang, Y; Kong, DZ				Chen, Yuezhe; Kong, Lingyun; Wang, Yang; Kong, Dezhi			Multi-Grained Attention Representation With ALBERT for Aspect-Level Sentiment Classification	IEEE ACCESS			English	Article						Aspect-level sentiment classi~cation; ALBERT; natural language processing; deep learning		Aspect-level sentiment classification aims to solve the problem, which is to judge the sentiment tendency of each aspect in a sentence with multiple aspects. Previous works mainly employed Long Short-Term Memory (LSTM) and Attention mechanisms to fuse information between aspects and sentences, or to improve large language models such as BERT to adapt aspect-level sentiment classification tasks. The former methods either did not integrate the interactive information of related aspects and sentences, or ignored the feature extraction of sentences. This paper proposes a novel multi-grained attention representation with ALBERT (MGAR-ALBERT). It can learn the representation that contains the relevant information of the sentence and the aspect, while integrating it into the process of sentence modeling with multi granularity, and finally get a comprehensive sentence representation. In Masked LM (MLM) task, in order to avoid the influence of aspect words being masked in the initial stage of the pre-training, the noise linear cosine decay is introduced into n-gram. We implemented a series of comparative experiments to verify the effectiveness of the method. The experimental results show that our model can achieve excellent results on Restaurant dataset with numerous number of parameters reduced, and it is not inferior to other models on Laptop dataset.	[Chen, Yuezhe; Kong, Lingyun; Wang, Yang] Xijing Univ, Sch Sci, Xian 710123, Shaanxi, Peoples R China; [Kong, Lingyun; Wang, Yang] Xijing Univ, Sch Sci, Artificial Intelligence Lab, Xian 710123, Shaanxi, Peoples R China; [Kong, Dezhi] Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China	Xijing University; Xijing University; Northwestern Polytechnical University	Chen, YZ (corresponding author), Xijing Univ, Sch Sci, Xian 710123, Shaanxi, Peoples R China.	chen1995086@163.com		Kong, Dezhi/0000-0002-0801-2730	Key Research and Development Program of Shanxi Province [2019GY-025]; Science and Technology Plan Project of Xi'an [2020KJRC0134]; Special Fund for High Level Talents of Xijing University [XJ20B07]	Key Research and Development Program of Shanxi Province; Science and Technology Plan Project of Xi'an; Special Fund for High Level Talents of Xijing University	This work was supported in part by the Key Research and Development Program of Shanxi Province under Grant 2019GY-025, in part by the Science and Technology Plan Project of Xi'an under Project 2020KJRC0134, and in part by the Special Fund for High Level Talents of Xijing University under Grant XJ20B07.	[Anonymous], 2015, COMPUTER SCI; [Anonymous], 2019, INT C LEARNING REPRE; [Anonymous], 2013, ARXIV13086242; [Anonymous], Attention-over-Attention Neural Networks for Reading Comprehension; [Anonymous], 2016, ACM T INTEL SYST TEC; Ba J.L., 2016, P ADV NEUR INF PROC; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001; Brown T., 2020, ADV NEURAL INFORM PR, VVolume 33, P1877; Chen P, 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047; Devlin J., 2019, N AM ASS COMP LING; Fan FF, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3433; Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594; Glorot X., 2011, P ICML, P1; Glorot X., 2011, P 14 INT C ART INT S, P315; Go A., 2009, CS224N PROJECT REP S, V1; Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He R., 2018, ARXIV180604346; He R, 2018, P 27 INT C COMP LING, P1121, DOI [10.18653/v1/P18-2092, DOI 10.18653/V1/P18-2092]; Hinton G., 2015, ARXIV; Hochreiter S., 1997, "NeuralComput., V9, P1735; Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22; Kaji N., 2007, P 2007 JOINT C EMP M, P1075; Kennedy A., 2010, COMPUT INTELL-US, V22, P110; Kingma D. P., 2017, ARXIV; Liang Yunlong, 2020, ARXIV200401935; Lin PQ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5088; Liu SH, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2079, DOI 10.1145/2505515.2505569; Ma D., 2017, ARXIV PREPRINT ARXIV; Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704; Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI [10.18653/v1/S16-1002, DOI 10.18653/V1/S16-1002]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A., 2018, OpenAI; Rao D., 2009, P 12 C EUR CHAPT ASS, P675, DOI [DOI 10.3115/1609067.1609142, DOI 10.5555/1609067.1609142]; Song Youwei, 2019, ARXIV190209314; Sun Chi, 2019, P 2019 C N AM CHAPT; Sun Zhiqing, 2020, ARXIV200402984; Tan Songbo., 2007, CIKM, P979, DOI DOI 10.1145/1321440.1321590; Tang R., 2019, Distilling task-specific knowledge from bert into simple neural networks; Tay Y., 2018, P AAAI C ART INTELL, V32, P1; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058; Winatmoko Y. A., 2019, ARXIV190911879; Wu ZJ, 2020, IEEE ACCESS, V8, P29238, DOI 10.1109/ACCESS.2020.2972697; Xiao Y., 2020, IEEE ACCESS, V8; Xu H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2324	48	5	5	2	20	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2021	9						106703	106713		10.1109/ACCESS.2021.3100299	http://dx.doi.org/10.1109/ACCESS.2021.3100299			11	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	TU5MT		gold			2024-07-03	WOS:000681081100001
J	Watanabe, Y; Togo, R; Maeda, K; Ogawa, T; Haseyama, M				Watanabe, Yuto; Togo, Ren; Maeda, Keisuke; Ogawa, Takahiro; Haseyama, Miki			Text-Guided Image Editing Based on Post Score for Gaining Attention on Social Media	SENSORS			English	Article						text-guided image editing; diffusion model; posted image editing; post score; social media marketing		Text-guided image editing has been highlighted in the fields of computer vision and natural language processing in recent years. The approach takes an image and text prompt as input and aims to edit the image in accordance with the text prompt while preserving text-unrelated regions. The results of text-guided image editing differ depending on the way the text prompt is represented, even if it has the same meaning. It is up to the user to decide which result best matches the intended use of the edited image. This paper assumes a situation in which edited images are posted to social media and proposes a novel text-guided image editing method to help the edited images gain attention from a greater audience. In the proposed method, we apply the pre-trained text-guided image editing method and obtain multiple edited images from the multiple text prompts generated from a large language model. The proposed method leverages the novel model that predicts post scores representing engagement rates and selects one image that will gain the most attention from the audience on social media among these edited images. Subject experiments on a dataset of real Instagram posts demonstrate that the edited images of the proposed method accurately reflect the content of the text prompts and provide a positive impression to the audience on social media compared to those of previous text-guided image editing methods.	[Watanabe, Yuto] Hokkaido Univ, Grad Sch Informat Sci & Technol, N-14,W-9,Kita Ku, Sapporo, Hokkaido 0600814, Japan; [Togo, Ren; Maeda, Keisuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Fac Informat Sci & Technol, N-14,W-9,Kita Ku, Sapporo, Hokkaido 0600814, Japan	Hokkaido University; Hokkaido University	Haseyama, M (corresponding author), Hokkaido Univ, Fac Informat Sci & Technol, N-14,W-9,Kita Ku, Sapporo, Hokkaido 0600814, Japan.	y_watanabe@lmd.ist.hokudai.ac.jp; togo@lmd.ist.hokudai.ac.jp; maeda@lmd.ist.hokudai.ac.jp; ogawa@lmd.ist.hokudai.ac.jp; mhaseyama@lmd.ist.hokudai.ac.jp		Watanabe, Yuto/0000-0002-9841-4089; Ogawa, Takahiro/0000-0001-5332-8112; Maeda, Keisuke/0000-0001-8039-3462; Togo, Ren/0000-0002-4474-3995	Japan Society for the Promotion of Science (JSPS) KAKENHI	Japan Society for the Promotion of Science (JSPS) KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	No Statement Available	Alikhani M, 2022, AAAI CONF ARTIF INTE, P10427; [Anonymous], 2023, Statista Number of Instagram Users Worldwide from 2020 to 2025; [Anonymous], 2023, Statista Number of Social Media Users Worldwide from 2017 to 2027; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Borges-Tiago MT, 2019, J BUS RES, V101, P574, DOI 10.1016/j.jbusres.2018.11.011; Brooks T, 2023, PROC CVPR IEEE, P18392, DOI 10.1109/CVPR52729.2023.01764; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Center P.R, 2012, Photos and Videos as Social Currency Online; Choi J, 2023, Arxiv, DOI arXiv:2305.15779; Couairon G., 2022, arXiv; Dong H, 2017, IEEE I CONF COMP VIS, pCP1, DOI 10.1109/ICCV.2017.608; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Felix R, 2017, J BUS RES, V70, P118, DOI 10.1016/j.jbusres.2016.05.001; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974; Karnowski V, 2017, COMPUT HUM BEHAV, V76, P42, DOI 10.1016/j.chb.2017.06.041; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T., 2020, ADV NEURAL INFORM PR, V33, p12 104, DOI 10.48550/arXiv.2006.06676; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kim S., 2023, P INT AAAI C WEB SOC, VVolume 17, P482; Kim S, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2878, DOI 10.1145/3366423.3380052; Kingma D. P., 2017, ARXIV; Kiros R, 2014, Arxiv, DOI arXiv:1411.2539; Kocasari U, 2022, IEEE WINT CONF APPL, P3441, DOI 10.1109/WACV51458.2022.00350; Kwon G, 2022, PROC CVPR IEEE, P18041, DOI 10.1109/CVPR52688.2022.01753; Li B., 2020, P IEEE CVF C COMP VI, P7880; Li B., 2020, P ADV NEUR INF PROC, V33, P22020; Li B, 2023, Arxiv, DOI arXiv:2306.05425; Li JN, 2022, PR MACH LEARN RES; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu M, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-022-3679-0; Liu Sun-Ao, 2023, MM '23: Proceedings of the 31st ACM International Conference on Multimedia, P779, DOI 10.1145/3581783.3612117; Liu SX, 2015, INFORM SCIENCES, V306, P34, DOI 10.1016/j.ins.2015.01.034; Liu Y, 2023, IEEE T PATTERN ANAL, V45, P11624, DOI 10.1109/TPAMI.2023.3284038; Madaan A, 2020, Arxiv, DOI arXiv:2004.14257; Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954; Nam S., 2018, Advances in Neural Information Processing Systems, P42; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209; Radford A, 2021, PR MACH LEARN RES, V139; Rahman Wan Nurhayati Abdul, 2022, International Journal of E-Services and Mobile Applications, V14, P1, DOI 10.4018/IJESMA.295960; Rameez Rikaz, 2022, UMAP '22 Adjunct: Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization, P85, DOI 10.1145/3511047.3536415; Ren SN, 2023, J BUS RES, V156, DOI 10.1016/j.jbusres.2022.113476; Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Shen S., 2021, arXiv; Shi Y., 2022, P CVPR, P11254; StudioBinder, 2021, What Is Magic Hour Photography & Cinematography Explained; Sun J., 2022, P C COMP VIS PATT RE, P18687; Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899; Thommes K., 2020, Ph.D. Thesis; Vaswani A, 2017, ADV NEUR IN, V30; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Watanabe Y, 2023, IEEE ACCESS, V11, P42534, DOI 10.1109/ACCESS.2023.3269847; Watanabe Y, 2022, INT CONF ACOUST SPEE, P4818, DOI 10.1109/ICASSP43922.2022.9746970; Wu X, 2017, TSINGHUA SCI TECHNOL, V22, P660, DOI 10.23919/TST.2017.8195348; Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229; Zhan FN, 2023, IEEE Transactions on Pattern Analysis and Machine Intelligence, V45, DOI arXiv:2112.13592	62	0	0	9	9	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	FEB	2024	24	3							921	10.3390/s24030921	http://dx.doi.org/10.3390/s24030921			17	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	HM9U5	38339636	gold, Green Published			2024-07-03	WOS:001160047900001
C	Rosenberg, L		Paul, R		Rosenberg, Louis			The Metaverse and Conversational AI as a Threat Vector for Targeted Influence	2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC			English	Proceedings Paper	IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)	MAR 08-11, 2023	ELECTR NETWORK	IEEE, SMART, IEEE Reg 1, IEEE USA, Inst Engn & Management, Univ Engn & Management		Virtual Reality; Augmented Reality; Mixed Reality; Conversational AI; Virtual Spokespeople; Epistemic Agency; AI Manipulation Problem; Metaverse Regulation; LLMs; Democracy		Over the last 18 months, two human-computer interaction (HCI) technologies have rapidly come to mainstream markets, funded by massive investments from major corporations. The first area of advancement has been virtual and augmented worlds, now commonly called "The Metaverse." The second area of advancement has been the foundational AI models that allow users to freely interact with computers through natural dialog. Commonly referred to as "Conversational AI," this technology has advanced rapidly with the deployment of Large Language Models (LLMs). When combined, these two disciplines will enable users to hold conversations with realistic virtual agents. While this will unleash many positive applications, there is significant danger of abuse. Most significant is the potential deployment of real-time interactive experiences that are designed to persuade, coerce, or manipulate users as a form of AI-powered targeted influence. This issue has largely been overlooked by policymakers who have focused instead on traditional privacy, bias and surveillance risks. It is increasingly important for policymakers to appreciate that interactive influence campaigns can be deployed through AI-powered Virtual Spokespeople (VSPs) that look, speak, and act like authentic users but are designed to push the interests of third parties. Because this "AI Manipulation Problem" is unique to real-time interactive environments, it is presented in this paper in the context of Control Theory to help policymakers appreciate that regulations are likely needed to protect against closed-loop forms of influence, especially when Conversational AI is deployed.	[Rosenberg, Louis] Responsible Metaverse Alliance, Pismo Beach, CA 93448 USA; [Rosenberg, Louis] Unanimous AI, Pismo Beach, CA 93448 USA		Rosenberg, L (corresponding author), Responsible Metaverse Alliance, Pismo Beach, CA 93448 USA.; Rosenberg, L (corresponding author), Unanimous AI, Pismo Beach, CA 93448 USA.	Louis@Unanimous.ai		Rosenberg, Louis/0000-0003-3457-1429				[Anonymous], 2022, XRSI PRIVACY SAFETY; [Anonymous], 2021, COMMISSION INFORMATI; Auxier B., 2020, 64% of Americans say social media have a mostly negative effect on the way things are going in the U.S. today; Bailenson JN, 2008, PUBLIC OPIN QUART, V72, P935, DOI 10.1093/poq/nfn064; Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x; Benitez-Quiroz CF, 2018, P NATL ACAD SCI USA, V115, P3581, DOI 10.1073/pnas.1716084115; Bozdag E, 2016, ETHICS INF TECHNOL, V17, P249, DOI 10.1007/s10676-015-9380-y; Breves P, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106723; Caplan B, 2007, MYTH OF THE RATIONAL VOTER: WHY DEMOCRACIES CHOOSE BAD POLICIES, P1; Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893; Coeckelbergh Mark, 2022, AI Ethics, P1, DOI 10.1007/s43681-022-00239-4; Gunn H., 2021, Applied epistemology, P389, DOI [10.1093/oso/9780198833659.003.0016, DOI 10.1093/OSO/9780198833659.003.0016]; Han E, 2023, J COMPUT-MEDIAT COMM, V28, DOI 10.1093/jcmc/zmac031; Hardin R., 2009, Contemporary debates in political philosophy; Heller B., 2021, J ONLINE TRUST SAFET, V1, DOI [DOI 10.54501/JOTS.V1I1.21, 10.54501/jots.v1i1.21]; Higgins D, 2022, COMPUT GRAPH-UK, V104, P116, DOI 10.1016/j.cag.2022.03.009; Hughes SM, 2013, PERCEPTION, V42, P941, DOI 10.1068/p7526; Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642; Perolat J, 2022, SCIENCE, V378, P990, DOI 10.1126/science.add4679; Robertson D., 2022, POLITICO 0914; Rosenberg Louis, 2022, ICVARS 2022: 2022 the 6th International Conference on Virtual and Augmented Reality Simulations, P21, DOI 10.1145/3546607.3546611; Rosenberg L., 2022, SOCIAL MEDIA MAKING; Rosenberg L, 2022, MARKETING METAVERSE, DOI [10.13140/RG.2.2.35340.80003, DOI 10.13140/RG.2.2.35340.80003]; Rosenberg L., 2022, VENTUREBEAT 0821; Rosenberg L., 2022, CASE DEMANDING IMMER; Rosenberg Louis B., 2022, Proceedings of the Future Technologies Conference (FTC) 2021. Lecture Notes in Networks and Systems (358), P1, DOI 10.1007/978-3-030-89906-6_1; Rosenberg L. B., 2022, FUTURE MARKETING MAG; Rosenberg Louis, 2023, PROFOUND DANGER CONV; Rosenberg Louis, 2022, TECHCRUNCH; Rosenberg Louis, 2012, UPGRADE, V2nd; Rosenberg Louis, 2005, U.S. Patent Application, Patent No. [60/689,301, 60689301]; Rosenberg Louis, 2022, VENTUREBEAT 1022; Rosenberg LB, 2022, LECT NOTES COMPUT SC, V13445, P263, DOI 10.1007/978-3-031-15546-8_23; Rosnberg L, 2022, 2022 IEEE 13TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P35, DOI 10.1109/UEMCON54665.2022.9965661; Sebastian G., 2022, International Journal of Security and Privacy in Pervasive Computing, V14, P1; Sedova K. etal, 2021, AI and the future of disinformation campaigns, part 1: The richdata framework; Verghese J, 2002, NEW ENGL J MED, V347, P1761, DOI 10.1056/NEJMoa020441; Waltzman Rand, 2022, ROLE TODAYS VRE CONS; Wang YM, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.661213; Winkler A., 2022, QUESTSIM HUMAN MOTIO	40	1	1	5	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-3286-5				2023							504	510		10.1109/CCWC57344.2023.10099167	http://dx.doi.org/10.1109/CCWC57344.2023.10099167			7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BV1QP					2024-07-03	WOS:000995182600079
C	Wang, SB; Wei, JL; Sabne, A; Davis, A; Ilbeyi, B; Hechtman, B; Chen, DH; Murthy, KS; Maggioni, M; Zhang, Q; Kumar, S; Guo, TF; Xu, YZ; Zhou, ZW		Aamodt, TM; Jerger, NE; Swift, M		Wang, Shibo; Wei, Jinliang; Sabne, Amit; Davis, Andy; Ilbeyi, Berkin; Hechtman, Blake; Chen, Dehao; Murthy, Karthik Srinivasa; Maggioni, Marcello; Zhang, Qiao; Kumar, Sameer; Guo, Tongfei; Xu, Yuanzhong; Zhou, Zongwei			Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models	PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 1, ASPLOS 2023			English	Proceedings Paper	28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)	MAR 25-29, 2023	Vancouver, CANADA	Assoc Comp Machinery, ACM SIGARCH, ACM SIGOPS, ACM SIGPLAN, ACM SIGBED, Huawei, Qualcomm, MangoBoost, Furiosa, IMO Ventures, Rebellions, Intel, Apple, Google, Vmware, AMD, Western Digital, Arm, Meta		Large scale machine learning; Compiler optimization; Collective communication hiding	PARALLEL MATRIX	Large deep learning models have shown great potential with state-of-the-art results in many tasks. However, running these large models is quite challenging on an accelerator (GPU or TPU) because the on-device memory is too limited for the size of these models. Intra-layer model parallelism is an approach to address the issues by partitioning individual layers or operators across multiple devices in a distributed accelerator cluster. But, the data communications generated by intra-layer model parallelism can contribute to a significant proportion of the overall execution time and severely hurt the computational efficiency. As intra-layer model parallelism is critical to enable large deep learning models, this paper proposes a novel technique to effectively reduce its data communication overheads by overlapping communication with computation. With the proposed technique, an identified original communication collective is decomposed along with the dependent computation operation into a sequence of finer-grained operations. By creating more overlapping opportunities and executing the newly created, finer-grained communication and computation operations in parallel, it effectively hides the data transfer latency and achieves a better system utilization. Evaluated on TPU v4 Pods using different types of large models that have 10 billion to 1 trillion parameters, the proposed technique improves system throughput by 1.14 - 1.38x. The achieved highest peak FLOPS utilization is 72% on 1024 TPU chips with a large language model that has 500 billion parameters.	[Wang, Shibo; Wei, Jinliang; Sabne, Amit; Davis, Andy; Ilbeyi, Berkin; Hechtman, Blake; Murthy, Karthik Srinivasa; Maggioni, Marcello; Zhang, Qiao; Kumar, Sameer; Guo, Tongfei; Xu, Yuanzhong; Zhou, Zongwei] Google, Mountain View, CA 94043 USA; [Chen, Dehao] Waymo, Mountain View, CA USA	Google Incorporated	Wang, SB (corresponding author), Google, Mountain View, CA 94043 USA.	shibow@google.com; jlwei@google.com; asabne@google.com; andydavis@google.com; berkin@google.com; blakehechtman@google.com; dehao@google.com; ksmurthy@google.com; maggioni@google.com; zhangqiaorjc@google.com; sameerkm@google.com; tongfei@google.com; yuanzx@google.com; zongweiz@google.com						Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Adiwardana D., 2020, arXiv; Agarwal RC, 1995, IBM J RES DEV, V39, P575, DOI 10.1147/rd.395.0575; [Anonymous], 2022, XLA DynamicSlice Semantics; [Anonymous], 1994, Technical report; [Anonymous], 2020, Google breaks AI performance records in MLPerf with world's fastest training supercomputer; [Anonymous], 2021, MLPerf Training v1.1; [Anonymous], 2022, Nvidia H100 Tensor Core GPU; [Anonymous], 2021, XLA: Optimizing Compiler for TensorFlow; [Anonymous], 2022, XLA DynamicUpdateSlice Semantics; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bezanson J, 2015, Arxiv, DOI [arXiv:1411.1607, 10.48550/arXiv.1411.1607, DOI 10.48550/ARXIV.1411.1607]; Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Cannon L. E., 1970, A cellular computer to implement the Kalman filter algorithm; Chen TQ, 2018, Arxiv, DOI arXiv:1802.04799; Danalis A., 2005, SC 05, P58, DOI DOI 10.1109/SC.2005.75; Danalis A, 2009, ICS'09: PROCEEDINGS OF THE 2009 ACM SIGARCH INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P316, DOI 10.1145/1542275.1542321; Darte A., 2002, P 16 INT PAR DISTR P; DEKEL E, 1981, SIAM J COMPUT, V10, P657, DOI 10.1137/0210049; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du N, 2022, Arxiv, DOI arXiv:2112.06905; Georganas E, 2012, INT CONF HIGH PERFOR; Guo JC, 2016, IEEE INT C CL COMP, P60, DOI 10.1109/CLUSTER.2016.62; Huang YP, 2019, Arxiv, DOI [arXiv:1811.06965, 10.48550/ARXIV.1811.06965, DOI 10.48550/ARXIV.1811.06965]; Ishizaki K, 2000, INT J PARALLEL PROG, V28, P135, DOI 10.1023/A:1007554715418; Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kharya Ali Alvi Paresh, 2021, Using DeepSpeed and Megatron to Train MegatronTuring NLG 530B, the World's Largest and Most Powerful Generative Language Model; Kosson A, 2021, Arxiv, DOI arXiv:2003.11666; Lepikhin D, 2020, Arxiv, DOI [arXiv:2006.16668, DOI 10.48550/ARXIV.2006.16668]; Mahajan Nilesh, 2012, Automatically Generating Coarse Grained Software Pipelining from Declaratively Specified Communication; Mudigere D, 2022, Arxiv, DOI arXiv:2104.05158; Narayanan D, 2021, Arxiv, DOI arXiv:2006.09503; Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646; Narayanan Deepak, 2021, arXiv; Norrie T, 2021, IEEE MICRO, V41, P56, DOI 10.1109/MM.2021.3058217; Paszke A, 2019, ADV NEUR IN, V32; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Pellegrini Simone., 2012, Proceedings of the 19th European Conference on Recent Advances in the Message Passing Interface, EuroMPI'12, P89, DOI 10.1007/978-3-642-33518-1_14; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Ramesh A, 2021, Arxiv, DOI [arXiv:2102.12092, 10.48550/arXiv.2102.12092]; Rashidi S, 2021, CONF PROC INT SYMP C, P540, DOI 10.1109/ISCA52012.2021.00049; Rotem N, 2019, Arxiv, DOI arXiv:1805.00907; Shazeer N, 2018, Arxiv, DOI arXiv:1811.02084; Keskar NS, 2017, Arxiv, DOI [arXiv:1609.04836, DOI 10.48550/ARXIV.1609.04836]; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Solomonik E, 2011, LECT NOTES COMPUT SC, V6853, P90, DOI 10.1007/978-3-642-23397-5_10; van de Geijn R.A., 1995, Summa: Scalable universal matrix multiplication algorithm; Vaswani A, 2017, ADV NEUR IN, V30; Wang BX, 2021, Arxiv, DOI arXiv:2105.14500; Wikipedia, 2022, Einstein notation D Wikipedia, The Free Encyclopedia; Xu YZ, 2021, Arxiv, DOI arXiv:2105.04663; Yang BW, 2020, Arxiv, DOI arXiv:1910.05124; Zhai XH, 2022, Arxiv, DOI arXiv:2106.04560; Zhang Y., 2021, arXiv	55	3	5	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9915-9				2023							93	106		10.1145/3567955.3567959	http://dx.doi.org/10.1145/3567955.3567959			14	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1QY		Bronze			2024-07-03	WOS:001109605300007
J	Wang, D; Sadrzadeh, M				Wang, Daphne; Sadrzadeh, Mehrnoosh			Causality and signalling of garden-path sentences	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Article						sheaf theory; causality; contextuality; natural language ambiguities; psycholinguistics; garden path phenomena	CONTEXTUALITY; PLAUSIBILITY; REANALYSIS; VARIABLES	Sheaves are mathematical objects that describe the globally compatible data associated with open sets of a topological space. Original examples of sheaves were continuous functions; later they also became powerful tools in algebraic geometry, as well as logic and set theory. More recently, sheaves have been applied to the theory of contextuality in quantum mechanics. Whenever the local data are not necessarily compatible, sheaves are replaced by the simpler setting of presheaves. In previous work, we used presheaves to model lexically ambiguous phrases in natural language and identified the order of their disambiguation. In the work presented here, we model syntactic ambiguities and study a phenomenon in human parsing called garden-pathing. It has been shown that the information-theoretic quantity known as 'surprisal' correlates with human reading times in natural language but fails to do so in garden-path sentences. We compute the degree of signalling in our presheaves using probabilities from the large language model BERT and evaluate predictions on two psycholinguistic datasets. Our degree of signalling outperforms surprisal in two ways: (i) it distinguishes between hard and easy garden-path sentences (with a p-value <10-5), whereas existing work could not, (ii) its garden-path effect is larger in one of the datasets (32 ms versus 8.75 ms per word), leading to better prediction accuracies. This article is part of the theme issue 'Quantum contextuality, causality and freedom of choice'.	[Wang, Daphne; Sadrzadeh, Mehrnoosh] UCL, Dept Comp Sci, London, England	University of London; University College London	Sadrzadeh, M (corresponding author), UCL, Dept Comp Sci, London, England.	m.sadrzadeh@ucl.ac.uk		Wang, Daphne/0000-0001-5088-2759; Sadrzadeh, Mehrnoosh/0000-0002-5863-7835	Royal Academy of Engineering Senior Research Fellowship/Research Chair	Royal Academy of Engineering Senior Research Fellowship/Research Chair	We would like to thank Samson Abramsky, Ehtibar Dzhafarov, Kin Ian Lo, Shane Mansfield, Wing Yee Chow, Yasutada Sudo, and Richard Breheny for discussions.	Abramsky S., 2015, 24 EACSL ANN C COMPU, V41, P211; Abramsky S, 2023, Arxiv, DOI arXiv:2307.04786; Abramsky S, 2011, NEW J PHYS, V13, DOI 10.1088/1367-2630/13/11/113036; Arehalli S., 2022, P 26 C COMPUTATIONAL, P301, DOI [10.18653/v1/2022.conll-1.20, DOI 10.18653/V1/2022.CONLL-1.20]; Barbosa RS, 2014, ELECTRON P THEOR COM, P36, DOI 10.4204/EPTCS.172.4; Bell J. S., 1964, PHYSICS, V1, P195, DOI [DOI 10.1103/PHYSICSPHYSIQUEFIZIKA.1.195, 10.1103/Physics-PhysiqueFizika.1.195]; Bever T. G, 1970, Cognition and development of language; Choi JD, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P387; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dzhafarov EN, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0099; Dzhafarov EN, 2016, J MATH PSYCHOL, V74, P11, DOI 10.1016/j.jmp.2016.04.010; EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6; Einstein A, 1935, PHYS REV, V47, P0777, DOI 10.1103/PhysRev.47.777; Frisson S., 2001, Metaphor and Symbol, V16, P149, DOI [10.1080/10926488.2001.9678893, DOI 10.1080/10926488.2001.9678893]; Frisson S, 2009, LANG LINGUIST COMPAS, V3, P111, DOI 10.1111/j.1749-818x.2008.00104.x; Garnsey SM, 1997, J MEM LANG, V37, P58, DOI 10.1006/jmla.1997.2512; Gogioso S, 2023, Arxiv, DOI arXiv:2303.09017; Gogioso S, 2021, ELECTRON P THEOR COM, P301, DOI 10.4204/EPTCS.343.13; Grodner D, 2003, J PSYCHOLINGUIST RES, V32, P141, DOI 10.1023/A:1022496223965; Grothendieck A., 1957, Tohoku Math. J., V9, P119, DOI [10.2748/tmj/1178244839, DOI 10.2748/TMJ/1178244839]; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Huang KJ., 2023, Surprisal does not explain syntactic disambiguation difficulty: evidence from a large-scale benchmark, DOI DOI 10.31234/OSF.IO/Z38U6; Kishida K., 2023, Logic and structure in computer science and beyond, outstanding contributions to logic in honour of Samson Abramsky, P531; KOCHEN S, 1967, J MATH MECH, V17, P59; Leray J., 1959, Bull. Soc. Math. Fr, V87, P221, DOI [10.24033/bsmf.1519, DOI 10.24033/BSMF.1519]; Lo KI, 2023, ELECTRON P THEOR COM, V384, P187, DOI 10.4204/EPTCS.384.11; Mansfield S., 2022, ELECTRON P THEOR COM, V366, P23, DOI [10.4204/EPTCS.366.5, DOI 10.4204/EPTCS.366.5]; Mansfield S, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.230401; Pickering MJ, 1998, J EXP PSYCHOL LEARN, V24, P940, DOI 10.1037/0278-7393.24.4.940; ROBINSON JJ, 1970, LANGUAGE, V46, P259, DOI 10.2307/412278; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013; Sturt P, 1999, J MEM LANG, V40, P136, DOI 10.1006/jmla.1998.2606; Vallée K, 2023, Arxiv, DOI arXiv:2310.19383; van Schijndel M, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12988; van Schijndel Marten, 2018, CogSci, P2603; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vorobev N. N., 1962, Theory Probab. Its Appl. (Engl. Transl.), V7, P147, DOI DOI 10.1137/1107014; Wang D., 2023, Empirical models and signalling fractions of garden-path sentences; Wang D., 2021, P 2021 WORKSHOP SEMA, P42, DOI [10.48550/arxiv.2107.14589, DOI 10.48550/ARXIV.2107.14589]; Wang D., 2021, 4 WORKSHOP QUANTUM C; Wang D., 2022, PROC 19 INT C QUANTU, V392, P208; Wang D, 2021, J COGN SCI, V22, P391	43	0	0	8	8	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-503X	1471-2962		PHILOS T R SOC A	Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.	MAR 18	2024	382	2268							20230013	10.1098/rsta.2023.0013	http://dx.doi.org/10.1098/rsta.2023.0013			24	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	GK1A2	38281713	hybrid, Green Submitted, Green Published			2024-07-03	WOS:001152459700004
J	Li, X; Yuan, S; Gu, XD; Chen, YT; Shen, BJ				Li, Xuan; Yuan, Shuai; Gu, Xiaodong; Chen, Yuting; Shen, Beijun			Few-shot code translation via task-adapted prompt learning	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article						Code translation; Parameter-efficient fine-tuning; Few-shot learning; Task-adapted prompt tuning; Pre-trained language model		Pre -trained models such as CodeT5 and TransCoder have achieved impressive progress in software engineering. However, fine-tuning PLMs for code translation is confronted with significant challenges owing to the scarce availability of parallel code. Large language models such as ChatGPT have exhibited considerable promise in few -shot learning where only a small number of demonstration examples are given to the LLM. Yet they have not been specifically optimized for domain -specific tasks, and their use often entails significant manual effort in manually curating prompts. In this paper, we propose FSCTrans, a novel parameter -efficient tuning approach for code translation when furnished with only a few demonstration examples. (1) to efficiently reuse prior knowledge during pre -training, FSCTrans employs task -adapted prompt tuning, which freezes the pretrained CodeT5 while merely updating parameters in a small prompt module; (2) to enable parameter efficient tuning on only a small number of examples, FSCTrans bridges pre -training to the translation task through a new pre -training objective of code -to -code generation. We evaluate FSCTrans on Java <-> Python and Java <-> C# datasets from both real -world projects and online judge problems. The evaluation results show that FSCTrans is remarkably effective in few -shot code translation: on average, it improves CodeT5 by 54.61% and 31.59% in terms of BLEU -4 and CodeBLEU; notably, FSCTrans demonstrates 14.42% and 18.36% superior performance in Java -> C# translations in terms of BLEU -4 and CodeBLEU compared to ChatGPT.	[Li, Xuan; Yuan, Shuai; Gu, Xiaodong; Chen, Yuting; Shen, Beijun] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, 800 Dongchuan Rd, Shanghai, Peoples R China	Shanghai Jiao Tong University	Shen, BJ (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, 800 Dongchuan Rd, Shanghai, Peoples R China.	riken01@sjtu.edu.cn; yssjtu@sjtu.edu.cn; xiaodong.gu@sjtu.edu.cn; chenyt@sjtu.edu.cn; bjshen@sjtu.edu.cn		Shen, Beijun/0000-0001-8370-3956	National Key Research and Develop-ment Program of China [2023YFB4503802]; National Natural Science Foundation of China [62102244, 62032004, 62272296]	National Key Research and Develop-ment Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgments</B> This research is supported by National Key Research and Develop-ment Program of China (Grant No. 2023YFB4503802) and National Natural Science Foundation of China (Grant No. 62102244, 62032004 and 62272296) .	Aggarwal K., 2015, PeerJ Prepr, V3, pe1459; Ahmad WU, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1528; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chada R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6081; Chen B, 2021, PROC IEEE ACM INT C, P252, DOI 10.1109/ICSE-Companion52605.2021.00117; Chen M., 2021, ARXIV; Chen Weizhu, 2022, 10 INT C LEARNING RE; Chen XY, 2018, 32 C NEURAL INFORM P, V31; Cui N, 2022, INT C PROGRAM COMPRE, P60, DOI 10.1145/3524610.3527888; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Fu W, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P49, DOI 10.1145/3106237.3106256; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; GeeksforGeeks, 2023, Online judge problems in GeeksforGeeks platform.; Gu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8410; Guo D., 2021, ICLR; Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921; Hu C.-H., 2022, FINDINGS ASS COMPUTA, P2627; Husain H., 2019, arXiv; Jiao MS, 2023, IEEE INT CONF AUTOM, P1529, DOI 10.1109/ASE56229.2023.00114; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Karaivanov S., 2014, P 2014 ACM INT S NEW, P173; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu F, 2023, PROC INT CONF SOFTW, P755, DOI 10.1109/ICSE48619.2023.00072; Liu X., 2023, AI Open, DOI [10.1016/j.aiopen.2023.08.012, DOI 10.1016/J.AIOPEN.2023.08.012]; Lu S., 2021, P NEURIPS DATASETS B; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Microsoft, 2022, CodeBERT based translation.; Mossienko M, 2003, SEVENTH EUROPEAN CONFERENCE ON SOFTWARE MAINTENANCE AND REENGINEERING, PROCEEDINGS, P40, DOI 10.1109/CSMR.2003.1192409; Nguyen A. T., 2013, 9 JOINT M FDN SOFTW, P651; OpenAI, 2023, CHATGPT; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Perez E, 2021, ADV NEUR IN; Raffel C, 2020, J MACH LEARN RES, V21; Ren Shuo, 2020, arXiv; Roziere B., 2020, ADV NEURAL INFORM PR; Roziere B., 2022, 10 INT C LEARNING RE; Salesforce, 2021, CodeT5-base model implementation; Salesforce, 2023, CodeT5 based translation; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Szafraniec M., 2022, arXiv; Tree-sitter, 2023, An incremental parsing system for programming tools.; Vaswani A, 2017, ADV NEUR IN, V30; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]; Wang CZ, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P382, DOI 10.1145/3540250.3549113; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Zhang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1628	52	0	0	9	9	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0164-1212	1873-1228		J SYST SOFTWARE	J. Syst. Softw.	JUN	2024	212								112002	10.1016/j.jss.2024.112002	http://dx.doi.org/10.1016/j.jss.2024.112002		MAR 2024	11	Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NY6C1					2024-07-03	WOS:001204042800001
J	Tiwari, P; Rai, S; Chowdary, CR				Tiwari, Paras; Rai, Sawan; Chowdary, C. Ravindranath			Large scale annotated dataset for code-mix abusive short noisy text	LANGUAGE RESOURCES AND EVALUATION			English	Article; Early Access						Code-mix dataset; Abusive text; Noisy text	TWITTER	With globalization and cultural exchange around the globe, most of the population gained knowledge of at least two languages. The bilingual user base on the Social Media Platform (SMP) has significantly contributed to the popularity of code-mixing. However, apart from multiple vital uses, SMP also suffer with abusive text content. Identifying abusive instances for a single language is a challenging task, and even more challenging for code-mix. The abusive posts detection problem is more complicated than it seems due to its unseemly, noisy data and uncertain context. To analyze these contents, the research community needs an appropriate dataset. A small dataset is not a suitable sample for the research work. In this paper, we have analyzed the dimensions of Devanagari-Roman code-mix in short noisy text. We have also discussed the challenges of abusive instances. We have proposed a cost-effective methodology with 20.38% relevancy score to collect and annotate the code-mix abusive text instances. Our dataset is eight times to the related state-of-the-art dataset. Our dataset ensures the balance with 55.81% instances in the abusive class and 44.19% in the non-abusive class. We have also conducted experiments to verify the usefulness of the dataset. We have performed experiments with traditional machine learning techniques, traditional neural network architecture, recurrent neural network architectures, and pre-trained Large Language Model (LLM). From our experiments, we have observed the suitability of the dataset for further scientific work.	[Tiwari, Paras; Chowdary, C. Ravindranath] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India; [Rai, Sawan] SRM Univ, Dept Comp Sci & Engn, Amravati 522240, Andhra Pradesh, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi); SRM University-AP	Tiwari, P (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.	parastiwari.rs.cse19@iitbhu.ac.in; sawan.r@srmap.edu.in; rchowdary.cse@iitbhu.ac.in						[Anonymous], 2016, P 2016 C EMP METH NA; Atran S, 2021, ANNU REV PSYCHOL, V72, P471, DOI 10.1146/annurev-psych-010419-050800; Banerjee S., 2018, P 27 INT C COMP LING, P3766; Bohra A., 2018, P 2 WORKSH COMP MOD, P36, DOI [10.18653/v1/W18-1105, DOI 10.18653/V1/W18-1105]; Camacho S, 2018, INFORM MANAGE-AMSTER, V55, P494, DOI 10.1016/j.im.2017.11.004; Chakravarthi BR, 2022, LANG RESOUR EVAL, V56, P765, DOI 10.1007/s10579-022-09583-7; Chakravarthi BR, 2020, P 1 JOINT WORKSHOP S, P177; ElSherief M., 2018, 12th International AAAI Conference on Web and Social Media, ICWSM 2018, P52, DOI 10.1609/icwsm.v12i1.15038; Fornaciari T, 2020, LANG RESOUR EVAL, V54, P1019, DOI 10.1007/s10579-020-09486-5; Founta Antigoni-Maria, 2018, ICWSM, P491, DOI DOI 10.1609/ICWSM.V12I1.14991; Gella S, 2014, P ICNLP, P368; Gong HY, 2021, AAAI CONF ARTIF INTE, V35, P14804; Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198; Khanuja Simran, 2020, P THE 4 WORKSHOP COM, P9; Kim Suin., 2014, HT 14 P 25 ACM C HYP, P243, DOI [10.1145/2631775.2631824, DOI 10.1145/2631775.2631824]; Klostermeyer W. F., 1996, Informatica, V20, P185; Gupta VK, 2019, Arxiv, DOI arXiv:1912.13109; Lui M., 2014, 5 WORKSH LANG AN SOC, P17, DOI DOI 10.3115/V1/W14-1303; Maity K, 2021, LECT NOTES COMPUT SC, V12801, P147, DOI 10.1007/978-3-030-80599-9_13; Mathur, 2018, P 2 WORKSH AB LANG O, P138, DOI DOI 10.18653/V1/W18-5118; Pal R, 2019, 13TH LINGUISTIC ANNOTATION WORKSHOP (LAW XIII), P178; Petersen AM, 2012, SCI REP-UK, V2, DOI 10.1038/srep00943; Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8; Roark B, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2413; Santy Sebastin, 2021, P 2 WORKSH DOM AD NL, P111; Saroj Anita, 2020, P WORKSH RES TECHN U, P2; Sharma J., 2014, EMNLP, DOI [10.3115/v1/w14-3914, DOI 10.3115/V1/W14-3914]; Shekhar S, 2020, MOD PHYS LETT B, V34, DOI 10.1142/S0217984920500864; Singh V, 2018, NAMED ENTITIES, P27; Sjobergh J., 2008, LREC CITESEER; Spitzner L., 2003, IEEE Security & Privacy, V1, P15, DOI 10.1109/MSECP.2003.1193207; Srivastava V, 2022, PROCEEDINGS OF THE 5TH JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA, CODS COMAD 2022, P328, DOI 10.1145/3493700.3493766; Stevens F, 2021, CYBERPSYCH BEH SOC N, V24, P367, DOI 10.1089/cyber.2020.0253; Szandala T., 2021, BIOINSPIRED NEUROCOM, P203, DOI [DOI 10.1007/978-981-15-5495-7_11, 10.1007/978-981-15-5495-7_11]; Thara S, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00594-3; Tiwari Paras, 2021, Speech and Computer: 23rd International Conference, SPECOM 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12997), P704, DOI 10.1007/978-3-030-87802-3_63; Usher N, 2018, INT J PRESS/POLIT, V23, P324, DOI 10.1177/1940161218781254; Van Rosendaal Juliet, 2020, P REST, P14; Vijay D., 2018, EMSASW@ESWC, V2111, P38; Vveinhardt J, 2022, J BUS ECON MANAG, V23, P532, DOI 10.3846/jbem.2022.16178; Wiegand M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P602; Xu SF, 2020, COMPUT HUM BEHAV, V102, P87, DOI 10.1016/j.chb.2019.08.006	42	0	0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1574-020X	1574-0218		LANG RESOUR EVAL	Lang. Resour. Eval.	2024 JAN 25	2024										10.1007/s10579-023-09707-7	http://dx.doi.org/10.1007/s10579-023-09707-7		JAN 2024	28	Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FT5O6		Green Submitted			2024-07-03	WOS:001148122700001
J	Jiang, YW; De Raedt, M; Deleu, J; Demeester, T; Develder, C				Jiang, Yiwei; De Raedt, Maarten; Deleu, Johannes; Demeester, Thomas; Develder, Chris			Few-shot out-of-scope intent classification: analyzing the robustness of prompt-based learning	APPLIED INTELLIGENCE			English	Article						Few-shot learning; Prompt-based models; Outlier/novelty detection; Dialogue intent classification	DOMAIN DETECTION	Out-of-scope (OOS) intent classification is an emerging field in conversational AI research. The goal is to detect out-of-scope user intents that do not belong to a predefined intent ontology. However, establishing a reliable OOS detection system is challenging due to limited data availability. This situation necessitates solutions rooted in few-shot learning techniques. For such few-shot text classification tasks, prompt-based learning has been shown more effective than conventionally finetuned large language models with a classification layer on top. Thus, we advocate for exploring prompt-based approaches for OOS intent detection. Additionally, we propose a new evaluation metric, the Area Under the In-scope and Out-of-Scope Characteristic curve (AU-IOC). This metric addresses the shortcomings of current evaluation standards for OOS intent detection. AU-IOC provides a comprehensive assessment of a model's dual performance capacities: in-scope classification accuracy and OOS recall. Under this new evaluation method, we compare our prompt-based OOS detector against 3 strong baseline models by exploiting the metadata of intent annotations, i.e., intent description. Our study found that our prompt-based model achieved the highest AU-IOC score across different data regimes. Further experiments showed that our detector is insensitive to a variety of intent descriptions. An intriguing finding shows that for extremely low data settings (1- or 5-shot), employing a naturally phrased prompt template boosts the detector's performance compared to rather artificially structured template patterns.	[Jiang, Yiwei; De Raedt, Maarten; Deleu, Johannes; Demeester, Thomas; Develder, Chris] Univ Ghent, IDLab, imec, Technol Pk Zwijnaarde 126, B-9052 Ghent, Belgium	Ghent University; IMEC	Jiang, YW (corresponding author), Univ Ghent, IDLab, imec, Technol Pk Zwijnaarde 126, B-9052 Ghent, Belgium.	yiwei.jiang@ugent.be; maarten.deraedt@ugent.be; johannes.deleu@ugent.be; thomas.demeester@ugent.be; chris.develder@ugent.be		Demeester, Thomas/0000-0002-9901-5768; De Raedt, Maarten/0000-0002-9661-1206; Jiang, Yiwei/0000-0002-4906-7308	Vlaamse Overheid	Vlaamse Overheid	No Statement Available	Casanueva I, 2020, NLP FOR CONVERSATIONAL AI, P38; Chen D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P429; Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152; Chen Y., 2022, P 2022 C EMPIRICAL M, P1059; Cheng ZF, 2022, IEEE-ACM T AUDIO SPE, V30, P635, DOI 10.1109/TASLP.2022.3145308; Conneau A, 2019, ADV NEUR IN, V32; Coucke A., 2018, ARXIV; Davis J., 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Efron B, 1994, An Introduction to the Bootstrap, DOI [10.1201/9780429246593, DOI 10.1201/9780429246593]; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Hendrycks Dan, 2017, ICLR; Iqbal T, 2020, INT CONF ACOUST SPEE, P636, DOI [10.1109/ICASSP40776.2020.9054444, 10.1109/icassp40776.2020.9054444]; Jin D, 2022, IEEE-ACM T AUDIO SPE, V30, P1386, DOI 10.1109/TASLP.2022.3162081; Kalyan KS, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103982; Lane I, 2007, IEEE T AUDIO SPEECH, V15, P150, DOI 10.1109/TASL.2006.876727; Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1311; Lee K, 2018, ADV NEUR IN, V31; Lei S, 2017, P 2017 C EMP METH NA, P2911, DOI DOI 10.18653/V1/D17-1314; Li D., 2022, P 29 INT C COMPUTATI, P1896; Liang S., 2018, P ICLR; Lin TE, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5491; Liu J., 2020, Simple and principled uncertainty estimation with deterministic deep learning via distance awareness", V33, P7498; Liu Y., 2019, CoRR abs/1907.11692; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Min SW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5316; Qu J, 2021, P 3 WORKSH NLP CONVA, P8, DOI [10.18653/v1/2021.nlp4convai-1.2, DOI 10.18653/V1/2021.NLP4CONVAI-1.2]; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ren J, 2019, 33 C NEURAL INFORM P, V32; Schick T, 2022, T ASSOC COMPUT LING, V10, P716, DOI 10.1162/tacl_a_00485; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Schuster S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3795; Shen YL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2443; Snell J, 2017, ADV NEUR IN, V30; Tam D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4980; Tan M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3566; Thakur N, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P296; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Xingkun Liu, 2021, Increasing Naturalness and Flexibility in Spoken Dialogue Interaction. 10th International Workshop on Spoken Dialogue Systems. Lecture Notes in Electrical Engineering (LNEE 714), P165, DOI 10.1007/978-981-15-9323-9_15; Xu J., 2015, P 1 WORKSH VECT SPAC, P62, DOI 10.3115/v1/W15-1509; Yan GF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1050; Yen-Chang Hsu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10948, DOI 10.1109/CVPR42600.2020.01096; Zhan LM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3521; Zhang HL, 2021, AAAI CONF ARTIF INTE, V35, P14374; Zhang JG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5064; Zhang JG, 2022, PROCEEDINGS OF THE 4TH WORKSHOP ON NLP FOR CONVERSATIONAL AI, P12; Zheng YH, 2020, IEEE-ACM T AUDIO SPE, V28, P1198, DOI 10.1109/TASLP.2020.2983593; Zhou WX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1100	50	0	0	13	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X	1573-7497		APPL INTELL	Appl. Intell.	JAN	2024	54	2					1474	1496		10.1007/s10489-023-05215-x	http://dx.doi.org/10.1007/s10489-023-05215-x		JAN 2024	23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HX8X2					2024-07-03	WOS:001137187500001
J	Xiao, RB				Xiao, Renbin			Four development stages of collective intelligence	FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING			English	Article; Early Access						Collective intelligence; Meta-synthesis of wisdom; Incompatibility; Labor division; Cooperative behavior; Collective intelligence emergence; Large language model; TP18	ARTIFICIAL-INTELLIGENCE; OPTIMIZATION; LIONS	The new generation of artificial intelligence (AI) research initiated by Chinese scholars conforms to the needs of a new information environment changes, and strives to advance traditional artificial intelligence (AI 1.0) to a new stage of AI 2.0. As one of the important components of AI, collective intelligence (CI 1.0), i.e., swarm intelligence, is developing to the stage of CI 2.0 (crowd intelligence). Through in-depth analysis and informative argumentation, it is found that an incompatibility exists between CI 1.0 and CI 2.0. Therefore, CI 1.5 is introduced to build a bridge between the above two stages, which is based on bio-collaborative behavioral mimicry. CI 1.5 is the transition from CI 1.0 to CI 2.0, which contributes to the compatibility of the two stages. Then, a new interpretation of the meta-synthesis of wisdom proposed by Qian Xuesen is given. The meta-synthesis of wisdom, as an improvement of crowd intelligence, is an advanced stage of bionic intelligence, i.e., CI 3.0. It is pointed out that the dual-wheel drive of large language models and big data with deep uncertainty is an evolutionary path from CI 2.0 to CI 3.0, and some elaboration is made. As a result, we propose four development stages (CI 1.0, CI 1.5, CI 2.0, and CI 3.0), which form a complete framework for the development of CI. These different stages are progressively improved and have good compatibility. Due to the dominant role of cooperation in the development stages of CI, three types of cooperation in CI are discussed: indirect regulatory cooperation in lower organisms, direct communicative cooperation in higher organisms, and shared intention based collaboration in humans. Labor division is the main form of achieving cooperation and, for this reason, this paper investigates the relationship between the complexity of behavior and types of labor division. Finally, based on the overall understanding of the four development stages of CI, the future development direction and research issues of CI are explored.	[Xiao, Renbin] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China; [Xiao, Renbin] Minist Educ, Key Lab Image Informat Proc & Intelligent Control, Wuhan 430074, Peoples R China	Huazhong University of Science & Technology	Xiao, RB (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.; Xiao, RB (corresponding author), Minist Educ, Key Lab Image Informat Proc & Intelligent Control, Wuhan 430074, Peoples R China.	rbxiao@hust.edu.cn			National Science and Technology Innovation 2030 Major Project of the Ministry of Science and Technology of China [2018AAA0101200]	National Science and Technology Innovation 2030 Major Project of the Ministry of Science and Technology of China	Project supported by the National Science and Technology Innovation 2030 Major Project of the Ministry of Science and Technology of China (No. 2018AAA0101200)	An XM., 2018, Syst Eng, V36, P1; Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001; AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396; Bernstein E, 2018, P NATL ACAD SCI USA, V115, P8734, DOI 10.1073/pnas.1802407115; Bonabeau E., 1999, Swarm Intelligence: From Natural to Artificial Systems, DOI 10.1093/oso/9780195131581.001.0001; [蔡文 Cai Wen], 2013, [科学通报, Chinese Science Bulletin], V58, P1190; Chen X, 2023, NAT COMPUT SCI, V3, P805, DOI 10.1038/s43588-023-00523-1; China Artificial Intelligence 2.0 Development Strategy Research Project Team, 2018, Strategic Research on Artificial Intelligence 2.0 in China (Volume I); Dai RW., 2009, Chin J Nat, V31, P311; Galesic M, 2023, J R SOC INTERFACE, V20, DOI 10.1098/rsif.2022.0736; GRINNELL J, 1995, ANIM BEHAV, V49, P95, DOI 10.1016/0003-3472(95)80157-X; Grinnell J, 2001, ANIM BEHAV, V62, P93, DOI 10.1006/anbe.2001.1735; Hare B, 2001, ANIM BEHAV, V61, P139, DOI 10.1006/anbe.2000.1518; Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970; Hills TT, 2015, TRENDS COGN SCI, V19, P46, DOI 10.1016/j.tics.2014.10.004; Jiang X., 2017, International Journal of Robotics and Control, V1, P1, DOI DOI 10.5430/IJRC.V1N1P1; Karsai I, 1999, ARTIF LIFE, V5, P117, DOI 10.1162/106454699568719; Kennedy J., 2001, SWARM INTELLIGENCE, P287, DOI [DOI 10.1016/B978-155860595-4/50007-3, 10.1016/B978-155860595-4/50007-3]; Kshetri N, 2024, INT J INFORM MANAGE, V75, DOI 10.1016/j.ijinfomgt.2023.102716; Li SY., 2019, Intelligent Optimization Algorithms and Emergent Computation; Li W, 2017, FRONT INFORM TECH EL, V18, P15, DOI 10.1631/FITEE.1601859; Lin Shijie, 2018, Computer Engineering and Applications, V54, P1, DOI 10.3778/j.issn.1002-8331.1803-0260; [刘生建 Liu Shengjian], 2018, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V31, P431; Melis AP, 2008, ANIM BEHAV, V76, P951, DOI 10.1016/j.anbehav.2008.05.014; Nick, 2017, A Brief History of Artificial Intelligence.; Pan YH, 2016, ENGINEERING, V2, P409, DOI 10.1016/J.ENG.2016.04.018; Passino KM, 2002, IEEE CONTR SYST MAG, V22, P52, DOI 10.1109/MCS.2002.1004010; Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8; Predic B, 2015, EXPERT SYST APPL, V42, P4892, DOI 10.1016/j.eswa.2015.02.013; Qian XS., 1990, Chin J Nat, V13, P3; Rajakumar BR, 2012, PROC TECH, V1, P126, DOI 10.1016/j.protcy.2012.10.016; Reynolds C.W., 1987, P 14 ANN C COMP GRAP, V21, P25, DOI [DOI 10.1145/37402.37406, 10.1145/37402.37406]; Riedl C, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2005737118; Samuelson P, 2010, Economics; SCHALLER G B, 1972, P480; Senge P., 2006, 5 DISCIPLINE ART PRA; STANDER P E, 1988, Madoqua, V15, P315; Stanton MCB, 2021, TECHNOL FORECAST SOC, V171, DOI 10.1016/j.techfore.2021.120939; Wang B, 2012, SCI CHINA INFORM SCI, V55, P2369, DOI 10.1007/s11432-012-4548-0; Wang WH., 2007, Qian Xuesens Academic Thought; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu F, 2020, NAT MACH INTELL, V2, P312, DOI 10.1038/s42256-020-0183-4; [吴虎胜 Wu Husheng], 2021, [智能系统学报, CAAI Transactions on Intelligent Systems], V16, P125; Wu HS, 2020, RESEARCH-CHINA, V2020, DOI 10.34133/2020/1762107; Wu LF, 2019, NATURE, V566, P378, DOI 10.1038/s41586-019-0941-9; Xiao RB., 2024, Chin J Syst Sci., V32, P73; Xiao RB., 2022, J Nanchang Inst Technol, V41, P1; Xiao RB., 2023, J Nanchang Inst Technol, V42, P1; [肖人彬 Xiao Renbin], 2023, [控制与决策, Control and Decision], V38, P1761; [肖人彬 Xiao Renbin], 2019, [信息与控制, Information and Control], V48, P129; [肖人彬 XIAO Renbin], 2007, [管理科学学报, Journal of management sciences in china], V10, P80; Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830; Yang XS, 2013, ELSEV INSIGHT, P1; Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003; Zhang B, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-021-3449-x; Zhang W, 2020, NATL SCI REV, V7, P1273, DOI 10.1093/nsr/nwaa092; [郑志明 Zheng Zhiming], 2021, [中国科学. 信息科学, Scientia Sinica Informationis], V51, P678; [钟义信 Zhong Yixin], 2018, [智能系统学报, CAAI Transactions on Intelligent Systems], V13, P2; Zhou J, 2024, FRONT INFORM TECH EL, V25, P6, DOI 10.1631/FITEE.2300089	59	0	0	0	0	ZHEJIANG UNIV PRESS	Hangzhou	Xixi Campus, Zhejiang University, No. 148 Tianmushan Road, Hangzhou, Zhejiang, PEOPLES R CHINA	2095-9184	2095-9230		FRONT INFORM TECH EL	Front. Inform. Technol. Elect. Eng.	2024 JUN 22	2024										10.1631/FITEE.2300459	http://dx.doi.org/10.1631/FITEE.2300459		JUN 2024	14	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UY0V5					2024-07-03	WOS:001251516200001
J	Zhou, HX; Austin, R; Lu, SC; Silverman, GM; Zhou, YQ; Kilicoglu, H; Xu, H; Zhang, R				Zhou, Huixue; Austin, Robin; Lu, Sheng-Chieh; Silverman, Greg Marc; Zhou, Yuqi; Kilicoglu, Halil; Xu, Hua; Zhang, Rui			Complementary and Integrative Health Information in the literature: its lexicon and named entity recognition	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						Complementary and Integrative Health; terminology; Unified Medical Language System; named entity recognition	ALTERNATIVE MEDICINE; UMLS	Objective To construct an exhaustive Complementary and Integrative Health (CIH) Lexicon (CIHLex) to help better represent the often underrepresented physical and psychological CIH approaches in standard terminologies, and to also apply state-of-the-art natural language processing (NLP) techniques to help recognize them in the biomedical literature.Materials and methods We constructed the CIHLex by integrating various resources, compiling and integrating data from biomedical literature and relevant sources of knowledge. The Lexicon encompasses 724 unique concepts with 885 corresponding unique terms. We matched these concepts to the Unified Medical Language System (UMLS), and we developed and utilized BERT models comparing their efficiency in CIH named entity recognition to well-established models including MetaMap and CLAMP, as well as the large language model GPT3.5-turbo.Results Of the 724 unique concepts in CIHLex, 27.2% could be matched to at least one term in the UMLS. About 74.9% of the mapped UMLS Concept Unique Identifiers were categorized as "Therapeutic or Preventive Procedure." Among the models applied to CIH named entity recognition, BLUEBERT delivered the highest macro-average F1-score of 0.91, surpassing other models.Conclusion Our CIHLex significantly augments representation of CIH approaches in biomedical literature. Demonstrating the utility of advanced NLP models, BERT notably excelled in CIH entity recognition. These results highlight promising strategies for enhancing standardization and recognition of CIH terminology in biomedical contexts.	[Zhou, Huixue; Zhou, Yuqi] Univ Minnesota, Inst Hlth Informat, Minneapolis, MN 55455 USA; [Austin, Robin] Univ Minnesota, Sch Nursing, Minneapolis, MN 55455 USA; [Lu, Sheng-Chieh] Univ Texas MD Anderson Canc Ctr, Dept Symptom Res, Houston, TX USA; [Silverman, Greg Marc; Zhang, Rui] Univ Minnesota, Dept Surg, Minneapolis, MN 55455 USA; [Zhou, Yuqi] Univ Minnesota, Dept Pharmaceut Care & Hlth Syst, Minneapolis, MN 55455 USA; [Kilicoglu, Halil] Univ Illinois, Sch Informat Sci, Champaign, IL USA; [Xu, Hua] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT USA; [Zhang, Rui] Univ Minnesota, Dept Surg, Div Computat Hlth Sci, 11-132 Phillips Wangensteen Bldg,516 Delaware St S, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Texas System; UTMD Anderson Cancer Center; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Illinois System; University of Illinois Urbana-Champaign; Yale University; University of Minnesota System; University of Minnesota Twin Cities	Zhang, R (corresponding author), Univ Minnesota, Dept Surg, Div Computat Hlth Sci, 11-132 Phillips Wangensteen Bldg,516 Delaware St S, Minneapolis, MN 55455 USA.	zhan1386@umn.edu	Lu, Sheng-Chieh/HTO-1308-2023	Lu, Sheng-Chieh/0000-0002-6685-1524; Zhou, Huixue/0000-0002-6524-5506; Austin, Robin/0000-0003-1993-4623	We would also like to acknowledge the Doctor of Nursing Practice Nursing Informatics students from the School of Nursing, University of Minnesota who contributed to the terminology review process.	We would also like to acknowledge the Doctor of Nursing Practice Nursing Informatics students from the School of Nursing, University of Minnesota who contributed to the terminology review process.	We would also like to acknowledge the Doctor of Nursing Practice Nursing Informatics students from the School of Nursing, University of Minnesota who contributed to the terminology review process.	Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; [Anonymous], 2006, The Duke encyclopedia of new medicine: Conventional and alternative medicine for all ages; [Anonymous], COMPLEMENTARY ALTERN; Aronson AR, 2001, J AM MED INFORM ASSN, P17; Austin RR, 2023, J INTEGR COMPLEMENT, V29, P483, DOI 10.1089/jicm.2022.0748; Bauer BA., 2021, MAYO CLIN GUIDE INTE; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Clarke Tainya C, 2015, Natl Health Stat Report, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong Q., 2023, arXiv; Fan YD, 2021, J AM MED INFORM ASSN, V28, P569, DOI 10.1093/jamia/ocaa218; Griffin KH, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-012006; Harrison JE, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01534-6; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Hu Y., 2023, ARXIV; Huang K., 2022, ARXIV; Hüsers J, 2021, JMIR MED INF, V9, DOI 10.2196/31980; International classification of health interventions (ICHI), ABOUT US; Islamaj R, 2020, NUCLEIC ACIDS RES, V48, pW5, DOI 10.1093/nar/gkaa333; Kreitzer MJ., 2014, INTEGRATIVE NURSING, P575; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lindquist R., 2018, COMPLEMENTARY ALTERN, P550; National Center for Biotechnology Information National Institutes of Health, COMPL THER MESH NCHB; National Center for Complementary and Integrative Health, STRAT PLAN FY 2021 2; National Library of Medicine, 2023, LEX TOOLS; Natural Medicines, 2023, NAT MED HLTH WELLN; OpenAI, 2023, Chat GPT; Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58; Si YQ, 2019, J AM MED INFORM ASSN, V26, P1297, DOI 10.1093/jamia/ocz096; Soysal E, 2018, J AM MED INFORM ASSN, V25, P331, DOI 10.1093/jamia/ocx132; Stan DL, 2018, J ALTERN COMPLEM MED, V24, P988, DOI 10.1089/acm.2018.0141; Tick H, 2018, EXPLORE-NY, V14, P177, DOI 10.1016/j.explore.2018.02.001; Tringali M, 2002, AMIA 2002 SYMPOSIUM, PROCEEDINGS, P801; Vasilakes J, 2020, J AM MED INFORM ASSN, V27, P1547, DOI 10.1093/jamia/ocaa128; Wang YF, 2021, JAMIA OPEN, V4, DOI 10.1093/jamiaopen/ooab081; Wieland LS, 2011, ALTERN THER HEALTH M, V17, P50; Yeo Y, 2016, COMPLEMENT THER MED, V26, P108, DOI 10.1016/j.ctim.2016.03.008; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhou SC, 2021, IEEE INT CONF HEALT, P513, DOI 10.1109/ICHI52183.2021.00096	40	3	3	4	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JAN 18	2024	31	2					426	434		10.1093/jamia/ocad216	http://dx.doi.org/10.1093/jamia/ocad216		NOV 2023	9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	FN2H3	37952122	Green Published, hybrid			2024-07-03	WOS:001100511500001
J	Abbasian, M; Khatibi, E; Azimi, I; Oniani, D; Abad, ZSH; Thieme, A; Sriram, R; Yang, ZQ; Wang, YS; Lin, B; Gevaert, O; Li, LJ; Jain, R; Rahmani, AM				Abbasian, Mahyar; Khatibi, Elahe; Azimi, Iman; Oniani, David; Abad, Zahra Shakeri Hossein; Thieme, Alexander; Sriram, Ram; Yang, Zhongqi; Wang, Yanshan; Lin, Bryant; Gevaert, Olivier; Li, Li-Jia; Jain, Ramesh; Rahmani, Amir M.			Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI	NPJ DIGITAL MEDICINE			English	Review							BENCHMARK	Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, dynamic scheduling of follow-ups, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present a comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.	[Abbasian, Mahyar; Khatibi, Elahe; Azimi, Iman; Yang, Zhongqi; Jain, Ramesh; Rahmani, Amir M.] Univ Calif Irvine, Irvine, CA 92697 USA; [Abbasian, Mahyar; Khatibi, Elahe; Azimi, Iman; Oniani, David; Abad, Zahra Shakeri Hossein; Wang, Yanshan; Lin, Bryant; Li, Li-Jia; Jain, Ramesh; Rahmani, Amir M.] Hlth Unity, Palo Alto, CA 94306 USA; [Oniani, David; Wang, Yanshan] Univ Pittsburgh, Pittsburgh, PA USA; [Abad, Zahra Shakeri Hossein] Univ Toronto, Toronto, ON, Canada; [Thieme, Alexander; Lin, Bryant; Gevaert, Olivier] Stanford Univ, Stanford, CA USA; [Sriram, Ram] Natl Inst Stand & Technol NIST, Gaithersburg, MD USA	University of California System; University of California Irvine; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Toronto; Stanford University; National Institute of Standards & Technology (NIST) - USA	Abbasian, M; Khatibi, E (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.; Abbasian, M; Khatibi, E (corresponding author), Hlth Unity, Palo Alto, CA 94306 USA.	abbasiam@uci.edu; ekhatibi@uci.edu	; Wang, Yanshan/H-4686-2018	Yang, Zhongqi/0000-0002-4196-0652; Abbasian, Mahyar/0009-0000-8448-3158; Wang, Yanshan/0000-0003-4433-7839; Oniani, David/0000-0002-9221-3059; Azimi, Iman/0000-0001-5003-299X	U.S. government or corporate organizations	U.S. government or corporate organizations	The authors would like to thank the following NIST people for their in-depth comments: Ian Soboroff, Hoa Dang, Jacob Collard, and Reva Schwartz. Furthermore, the authors express their gratitude to Nigam Shah from Stanford for his valuable feedback, which has contributed to the enhancement of the paper. Certain commercial systems are identified in this paper. Such identification does not imply recommendation or endorsement by NIST; nor does it imply that the products identified are necessarily the best available for the purpose. Further, any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of NIST, other supporting U.S. government or corporate organizations.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Ahmad MA, 2021, IEEE INT CONF HEALT, P554, DOI 10.1109/ICHI52183.2021.00104; Ahmad MA, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3529, DOI 10.1145/3394486.3406461; Ahuja K, 2023, P 2023 C EMPIRICAL M, P4232; [Anonymous], Privacy Framework-nist.gov; [Anonymous], TEXT RETRIEVAL C TRE; [Anonymous], 2023, AI Risk Management Framework; [Anonymous], 1991, English Today; [Anonymous], 2013, P 2013 ACM SIGMOD IN, DOI DOI 10.1145/2463676.2463712; [Anonymous], 2011, P 49 ANN M ASS COMPU; Aryan A., 2023, The costly dilemma: are large language models the pay-day loans of machine learning?; Bajaj Payal., 2022, arXiv; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Bang Y., 2023, Long Papers, V1, P675; Blagec K, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON EFFICIENT BENCHMARKING IN NLP (NLP POWER 2022), P52; Blodgett S. L., 2016, P 2016 C EMPIRICAL M, P1119; Broniatowski D., 2021, Tech. rep., DOI DOI 10.6028/NIST.IR.8367; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chen M., 2021, arXiv; Chiang C.-H., 2023, Long Papers, V1, P15607; Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174; Chung JJY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P575; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cook DA, 2023, ACAD MED, V98, P357, DOI 10.1097/ACM.0000000000005088; Dalianis H., 2018, Clinical text mining, P45, DOI DOI 10.1007/978-3-319-78503-5_6; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; Dziri N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5271; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gardner N., 2022, Appl. Comput. Intell, V2, P83, DOI 10.3934/aci.2022005; Ge Y., 2024, Advances in Neural Information Processing Systems, V36; Gehman S, 2020, M ASS FOR COMPUTATIO; Gekhman Z., 2023, P 2023 C EMPIRICAL M; Glaese A, 2022, arXiv; Hague Douglas C, 2019, N C Med J, V80, P219, DOI 10.18043/ncm.80.4.219; Hailu T. T., 2020, J. Comput. Commun, V8, P1, DOI DOI 10.4236/JCC.2020.82001; Han TY, 2023, Arxiv, DOI [arXiv:2304.08247, DOI 10.48550/ARXIV.2304.08247]; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Hendrycks D., 2021, 35 C NEURAL INFORM P; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693, DOI DOI 10.48550/ARXIV.1506.03340; Hoffmann Jordan, 2022, Advances in Neural Information Processing Systems (NeurIPS); Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P90, DOI 10.1145/3543873.3587320; Huang H., 2023, FINDINGS ASS COMPUTA, P12365; Hugging Face, 2023, The AI community building the future; Ilicki J., 2023, Mayo Clinic Proc. Digit. Health, V1, P185, DOI DOI 10.1016/J.MCPDIG.2023.03.006; Jain N, 2023, Arxiv, DOI arXiv:2306.13651; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jin Z., 2022, Advances in Neural Information Processing Systems, P28458; Jin ZJ, 2024, Arxiv, DOI arXiv:2306.05836; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kocisky T, 2018, Transactions of the Association for Computational Linguistics, P317, DOI [10.1162/tacl_a_00023, DOI 10.1162/TACL_A_00023]; Konda P, 2016, PROC VLDB ENDOW, V9, P1581, DOI 10.14778/3007263.3007314; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Laban P, 2023, Arxiv, DOI [arXiv:2305.14540, 10.48550/arXiv.2305.14540]; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Liang P., 2023, Trans. Machine Learn. Res; Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Y., 2023, P 2023 C EMPIRICAL M, P2511; Lukas N, 2023, P IEEE S SECUR PRIV, P346, DOI 10.1109/SP46215.2023.10179300; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Manakul P., 2023, P 2023 C EMPIRICAL M, P9004; Marks M, 2023, JAMA-J AM MED ASSOC, V330, P309, DOI 10.1001/jama.2023.9458; Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P653; May R, 2022, INFORM HEALTH SOC CA, V47, P194, DOI 10.1080/17538157.2021.1983578; McKenna N., 2023, Findings of the Association for Computational Linguistics: EMNLP 2023, P2758, DOI DOI 10.18653/V1/2023.FINDINGS-EMNLP; Mei YA, 2021, PROC INT CONF DATA, P61, DOI 10.1109/ICDE51399.2021.00013; Meng JB, 2021, J COMPUT-MEDIAT COMM, V26, P207, DOI 10.1093/jcmc/zmab005; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Miller A. H., 2017, System Demonstrations; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Napoles C., 2011, P WORKSHOP MONOLINGU, P91; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Novikova Jekaterina, 2017, P 2017 C EMPIRICAL M, P2241, DOI DOI 10.18653/V1/D17-1238; Oniani D., 2023, AMIA SUMMITS TRANSLA; Pan A, 2023, P MACHINE LEARNING R, P26837; Paperno D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1525; Parrish A, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2086; Peng BL, 2022, Arxiv, DOI arXiv:2206.11309; Peng BL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6149, DOI 10.1109/ICASSP.2018.8461918; Peng YS, 2018, ADV NEUR IN, V31; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Plank B., 2015, P 19 C COMPUTATIONAL, P315; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raunak V., 2023, FINDINGS ASS COMPUTA, P12009; Reddy Sandeep, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101304; Resnik P., 2006, PERSPECTIVES HLTH IN; Resnik P., 2010, HDB COMPUTATIONAL LI, P57, DOI [DOI 10.1002/9781444324044.CH11, 10.1002/9781444324044.ch11]; Sai AB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485766; Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499; Schick T., 2023, Advances in Neural Information Processing Systems, V36, P68539; Schwartz R, 2022, NIST Special Publication, V1270; Shichel Y, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1625; Silfen E, 2006, AM J EMERG MED, V24, P664, DOI 10.1016/j.ajem.2006.02.005; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Su LX, 2019, AAAI CONF ARTIF INTE, P10041; Suzgun M, 2019, DEEP LEARNING AND FORMAL LANGUAGES: BUILDING BRIDGES, P44; Svikhnushina E., 2022, P 23 ANN M SPECIAL I, P419; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tran K, 2016, P 2016 C N AM CHAPTE, P321, DOI 10.18653/v1/N16-1036; Wahde M, 2021, 2021 THE 4TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INTELLIGENT SYSTEMS, CIIS 2021, P50, DOI 10.1145/3507623.3507632; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang BX, 2024, Arxiv, DOI arXiv:2306.11698; Wang J, 2023, ICLR 2023 WORKSHOP T; Wang PY, 2023, Arxiv, DOI arXiv:2305.17926; Wang X, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P347; Wang YD, 2024, Arxiv, DOI arXiv:2306.05087; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Wei J., 2022, P ICLR; Welivita Anuradha, 2020, P 28 INT C COMPUTATI, P4886; Weston J, 2015, Arxiv, DOI [arXiv:1502.05698, 10.48550/arXiv.1502.05698]; Wu Y., 2021, INT C MACHINE LEARNI, P11251; Xia Y, 2020, AAAI CONF ARTIF INTE, V34, P1062; Xu L, 2019, AAAI CONF ARTIF INTE, P7346; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yang J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116355; Yu JF, 2023, Arxiv, DOI arXiv:2306.09296; Yuan L., 2024, Advances in Neural Information Processing Systems, V36; Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791; Zhang H, 2024, medRxiv, DOI [10.1101/2023.07.10.23292373, 10.1101/2023.07.10.23292373, DOI 10.1101/2023.07.10.23292373, 10.1101/2023.07.10.23292373v1]; Zhang K, 2024, Arxiv, DOI [arXiv:2305.17100, DOI 10.48550/ARXIV.2305.17100]; Zhang T., 2020, INT C LEARNING REPRE; Zhang XT, 2024, Arxiv, DOI arXiv:2305.12474; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563; Zhong WJ, 2021, Arxiv, DOI arXiv:2104.06598; Zhou C., 2024, Advances in Neural Information Processing Systems, V36; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]; Zhou Y, 2022, NEURIPS 2022 FDN MOD; Zhu KJ, 2023, Arxiv, DOI arXiv:2306.04528; Zhuang B., 2023, P 32 INT JOINT C ART, P6823; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	145	0	0	11	11	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	MAR 29	2024	7	1							82	10.1038/s41746-024-01074-z	http://dx.doi.org/10.1038/s41746-024-01074-z			14	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	MQ5B4	38553625	Green Submitted, gold			2024-07-03	WOS:001195095800001
J	Nasution, AH; Onan, A				Nasution, Arbi Haza; Onan, Aytug			ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks	IEEE ACCESS			English	Article						Annotation quality; emotion classification; Indonesian language processing; language models; low-resource languages; natural language processing; sentiment analysis; topic classification; Turkish language processing		This research paper presents a comprehensive comparative study assessing the quality of annotations in Turkish, Indonesian, and Minangkabau Natural Language Processing (NLP) tasks, with a specific focus on the contrast between annotations generated by human annotators and those produced by Large Language Models (LLMs). In the context of NLP, high-quality annotations play a pivotal role in training and evaluating machine-learning models. The study encompasses three core NLP tasks: topic classification, tweet sentiment analysis, and emotion classification, each reflecting a distinct aspect of text analysis. The research methodology incorporates a meticulously curated dataset sourced from a variety of text data, spanning diverse topics and emotions. Human annotators, proficient in the Turkish, Indonesian, and Minangkabau language, were tasked with producing high-quality annotations, adhering to comprehensive annotation guidelines. Additionally, fine-tuned Turkish LLMs were employed to generate annotations for the same tasks. The evaluation process employed precision, recall, and F1-score metrics, tailored to each specific NLP task. The findings of this study underscore the nuanced nature of annotation quality. While LLM-generated annotations demonstrated competitive quality, particularly in sentiment analysis, human-generated annotations consistently outperformed LLM-generated ones in more intricate NLP tasks. The observed differences highlight LLM limitations in understanding context and addressing ambiguity. This research contributes to the ongoing discourse on annotation sources in Turkish, Indonesian, and Minangkabau NLP, emphasizing the importance of judicious selection between human and LLM-generated annotations. It also underscores the necessity for continued advancements in LLM capabilities, as they continue to reshape the landscape of data annotation in NLP and machine learning.	[Nasution, Arbi Haza] Univ Islam Riau, Dept Informat Engn, Pekanbaru 28284, Riau, Indonesia; [Onan, Aytug] Izmir Katip Celebi Univ, Coll Engn & Architecture, Dept Comp Engn, TR-35620 Izmir, Turkiye	Islamic University of Riau Indonesia; Izmir Katip Celebi University	Onan, A (corresponding author), Izmir Katip Celebi Univ, Coll Engn & Architecture, Dept Comp Engn, TR-35620 Izmir, Turkiye.	aytug.onan@ikcu.edu.tr	Nasution, Arbi Haza/F-6881-2018	Nasution, Arbi Haza/0000-0001-6283-3217	Universitas Islam Riau	Universitas Islam Riau	No Statement Available	Abdelrazek A, 2023, INFORM SYST, V112, DOI 10.1016/j.is.2022.102131; Alizadeh M, 2023, Arxiv, DOI [arXiv:2307.02179, DOI 10.48550/ARXIV.2307.02179]; Barthet M, 2023, Arxiv, DOI arXiv:2308.16029; Belal M, 2023, Arxiv, DOI arXiv:2306.17177; Cahyawijaya S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8875; Chang Y., 2023, arXiv; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Day M., 2007, Inf. Fusion, V52; Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding BS, 2023, Arxiv, DOI arXiv:2212.10450; Feng SY, 2021, Arxiv, DOI [arXiv:2105.03075, DOI 10.48550/ARXIV.2105.03075]; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Grosman JS, 2020, INFORM SYST, V93, DOI 10.1016/j.is.2020.101553; Haber J., 2023, Comput. Linguistics, P1; Hadi M. U, 2023, A survey on large language models: Applications, challenges, limitations, and practical usage; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Kalyan K. S., 2024, Natural Language Processing Journal, V6, DOI [DOI 10.1016/J.NLP.2023.100048, 10.1016/j.nlp.2023.100048]; Khakimova A, 2023, KYBERNETES, DOI 10.1108/K-05-2023-0767; Koptyra Bartlomiej, 2023, Computational Science - ICCS 2023: 23rd International Conference, Proceedings. Lecture Notes in Computer Science (14073), P365, DOI 10.1007/978-3-031-35995-8_26; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; Laskar MTR, 2023, Arxiv, DOI arXiv:2305.06147; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011; Metallinou A, 2013, IEEE INT CONF AUTOMA; Nasution AH, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3448215; Nasution AH, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3138815; Neves M, 2014, BRIEF BIOINFORM, V15, P327, DOI 10.1093/bib/bbs084; Ollion E., 2023, ChatGPT for text annotation? mind the hype!; Ostyakova L., 2023, P INT C DIAL JUL, P1; Ostyakova L., 2023, P 24 ANN M SPECIAL I, P242; Peters M. A., 2023, Educ. Philosophy Theory, V1, P1; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Röttger P, 2022, Arxiv, DOI arXiv:2112.07475; Saputri MS, 2018, INT CONF ASIAN LANG, P90, DOI 10.1109/IALP.2018.8629262; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Vujinovic A., 2024, Mach. Learn. Appl., V16; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	41	1	1	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						71876	71900		10.1109/ACCESS.2024.3402809	http://dx.doi.org/10.1109/ACCESS.2024.3402809			25	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	SQ7G4		gold			2024-07-03	WOS:001235976500001
J	Al Qurashi, AA; Albalawi, IAS; Halawani, IR; Asaad, AH; Al Dwehji, AMO; Almusa, HA; Alharbi, RI; Alobaidi, HA; Alarki, SMKZ; Aljindan, FK				Al Qurashi, Abdullah A.; Albalawi, Ibrahim Abdullah S.; Halawani, Ibrahim R.; Asaad, Alanoud Hammam; Al Dwehji, Adnan M. Osama; Almusa, Hala Abdullah; Alharbi, Ruba Ibrahim; Alobaidi, Hussain Amin; Alarki, Subhi M. K. Zino; Aljindan, Fahad K.		SB PLAST	Can a Machine Ace the Test? Assessing GPT-4.0's Precision in Plastic Surgery Board Examinations	PLASTIC AND RECONSTRUCTIVE SURGERY-GLOBAL OPEN			English	Article								Background: As artificial intelligence makes rapid inroads across various fields, its value in medical education is becoming increasingly evident. This study evaluates the performance of the GPT-4.0 large language model in responding to plastic surgery board examination questions and explores its potential as a learning tool.Methods: We used a selection of 50 questions from 19 different chapters of a widely-used plastic surgery reference. Responses generated by the GPT-4.0 model were assessed based on four parameters: accuracy, clarity, completeness, and conciseness. Correlation analyses were conducted to ascertain the relationship between these parameters and the overall performance of the model.Results: GPT-4.0 showed a strong performance with high mean scores for accuracy (2.88), clarity (3.00), completeness (2.88), and conciseness (2.92) on a three-point scale. Completeness of the model's responses was significantly correlated with accuracy (P < 0.0001), whereas no significant correlation was found between accuracy and clarity or conciseness. Performance variability across different chapters indicates potential limitations of the model in dealing with certain complex topics in plastic surgery.Conclusions: The GPT-4.0 model exhibits considerable potential as an auxiliary tool for preparation for plastic surgery board examinations. Despite a few identified limitations, the generally high scores on key parameters suggest the model's ability to provide responses that are accurate, clear, complete, and concise. Future research should focus on enhancing the performance of artificial intelligence models in complex medical topics, further improving their applicability in medical education.	[Al Qurashi, Abdullah A.; Alobaidi, Hussain Amin] King Saud bin Abdulaziz Univ Hlth Sci Natl Guards, Coll Med, Jeddah, Saudi Arabia; [Al Qurashi, Abdullah A.] King Abdullah Int Med Res Ctr, Jeddah, Saudi Arabia; [Al Qurashi, Abdullah A.] McGill Univ, Dept Surg, Div Plast Surg, Montreal, PQ, Canada; [Albalawi, Ibrahim Abdullah S.] Tabuk Univ, Fac Med, Tabuk, Saudi Arabia; [Halawani, Ibrahim R.] King Abdulaziz Univ, Fac Med, Jeddah, Saudi Arabia; [Asaad, Alanoud Hammam; Al Dwehji, Adnan M. Osama; Almusa, Hala Abdullah] Alfaisal Univ, Coll Med, Riyadh, Saudi Arabia; [Alharbi, Ruba Ibrahim] Batterjee Med Coll, Coll Med, Jeddah, Saudi Arabia; [Alarki, Subhi M. K. Zino] King Saud Univ, Coll Med, Riyadh, Saudi Arabia; [Aljindan, Fahad K.; SB PLAST] King Abdullah Med City, Dept Plast Surg, Mecca, Saudi Arabia; [Albalawi, Ibrahim Abdullah S.] Tabuk Univ, Coll Med, Tabuk, Saudi Arabia	McGill University; University of Tabuk; King Abdulaziz University; Alfaisal University; Batterjee Medical College; King Saud University; King Abdullah Medical City; University of Tabuk	Albalawi, IAS (corresponding author), Tabuk Univ, Coll Med, Tabuk, Saudi Arabia.	ebrahimzzz43@gmail.com	Albalawi, Ibrahim/HJY-8217-2023					Al-Alawi M., 2019, Asian J Psychiatry, V42, P69; [Anonymous], 2019, Penn Bioethics J, V15; Beam AL, 2016, JAMA-J AM MED ASSOC, V316, P2368, DOI 10.1001/jama.2016.17217; Chai KEK, 2013, J AM MED INFORM ASSN, V20, P980, DOI 10.1136/amiajnl-2012-001409; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Freedman JD., 2023, arXiv; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; James PA., 2023, J Med Internet Res, V9, pe28776; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lin Z., 2023, JMIR Med Inform, V10, pe28776; Mesko B., 2018, The Medical Futurist; Ozturk CN, 2020, ANN PLAS SURG, V85, pS155, DOI 10.1097/SAP.0000000000002443; Sackett DL, 1997, SEMIN PERINATOL, V21, P3, DOI 10.1016/S0146-0005(97)80013-4; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7	15	0	0	4	4	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	2169-7574			PRS-GLOB OPEN	PRS-GLOB. OPEN	DEC	2023	11	12							e5448	10.1097/GOX.0000000000005448	http://dx.doi.org/10.1097/GOX.0000000000005448			6	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	CL2Y7	38111723	Green Published, gold			2024-07-03	WOS:001125354000003
C	Hemment, D; Currie, M; Bennett, SJ; Elwes, J; Ridler, A; Sinders, C; Vidmar, M; Hill, R; Warner, H			ASSOC COMPUTING MACHINERY	Hemment, Drew; Currie, Morgan; Bennett, S. J.; Elwes, Jake; Ridler, Anna; Sinders, Caroline; Vidmar, Matjaz; Hill, Robin; Warner, Holly			AI in the Public Eye: Investigating Public AI Literacy Through AI Art	PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023			English	Proceedings Paper	6th ACM Conference on Fairness, Accountability, and Transparency (FAccT)	JUN 12-15, 2023	Chicago, IL	Assoc Comp Machinery		Society; Culture; AI literacy; Art; Computational Art; AI Art; Creative AI; Artificial Intelligence; Transparency; Education; Dialogue; Interdisciplinary Research		Recent advances in diffusion models and large language models have underpinned a new generation of powerful and accessible tools, and some of the most publicly visible applications are for artistic endeavour. Such tools, however, provide little scope for deeper understanding of AI systems, while the growing public interest in them can eclipse notice of the vibrant community of artists who have long worked with other forms of AI. We explore the potential for AI Art - particularly work in which AI is both tool and topic - to facilitate public AI literacies and consider how tactics developed before the current generative AI boom have continued relevance today. We look at the strategies of critical AI artists to scaffold public understanding of AI and enhance legibility for non-experts. This paper also investigates how collaborations between artists and AI researchers and designers can illuminate key technical and social issues relevant to the development of AI. The study entailed workshops between three professional artists who work with AI and a cross-disciplinary set of academic participants. This paper reports on these workshops and presents the intentions and strategies expressed by the artists, as well as insights of relevance to the research community on public AI literacies. We find that critical AI art can link underlying technical systems to structural issues of power and facilitate experiential learning that is situated and embodied, valuing interpretation over explanation. The findings also demonstrate the importance of transdisciplinary conversations around art, ethics and the political economy of AI technologies and how these dialogues may feed into AI design processes.	[Hemment, Drew; Currie, Morgan; Bennett, S. J.; Vidmar, Matjaz; Hill, Robin] Univ Edinburgh, Edinburgh, Scotland	University of Edinburgh	Hemment, D (corresponding author), Univ Edinburgh, Edinburgh, Scotland.	drew.hemment@ed.ac.uk; morgan.currie@ed.ac.uk; sarah.bennett@ed.ac.uk; me@jakeelwes.com; anna@annaridler.com; Matjaz.Vidmar@ed.ac.uk; r.l.hill@ed.ac.uk; r.l.hill@ed.ac.uk		Sinders, Caroline/0000-0002-0537-9318; Bennett, SJ/0000-0002-8520-3194; Hemment, Drew/0000-0002-0068-5500; Vidmar, Matjaz/0000-0002-1368-9762	Arts & Humanities Research Council; Engineering & Physical Sciences Research Council; Creative Scotland	Arts & Humanities Research Council(UK Research & Innovation (UKRI)Arts & Humanities Research Council (AHRC)); Engineering & Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Creative Scotland	Thanks to the participants in the research workshops: Dave MurrayRust, Pablo Schyfter, Shannon Vallor, Vaishak Belle, Michael Rovatsos, Ruth Aylet, Frank Boz, and Gill Haddow. The New Real at University of Edinburgh is a partnership with The Alan Turing Institute and Edinburgh's Festivals, supported by funding from Arts & Humanities Research Council, Engineering & Physical Sciences Research Council, and Creative Scotland.	Abbott Thomas, 2019, Strategies to Inform the Swiss Public on Artificial Intelligence; Adams Lizzie, 2019, How to stimulate effective public engagement on the ethics of artificial intelligence; [Anonymous], 2006, Tracking Transience | Creative Capital; Balaram B., 2018, Artificial Intelligence: Real Public Engagement; Birhane A, 2019, Arxiv, DOI arXiv:1912.07376; Bishop Claire., 2012, Artificial Hells: Participatory Art and the Politics of Spectatorship; Bonnefon J.-F., 2021, CAR KNEW TOO MUCH CA; Bradford B, 2020, BRIT J CRIMINOL, V60, P1502, DOI 10.1093/bjc/azaa032; Brennen A, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383047; Bryan-Kinns Nick, 2022, 1 WORKSH EXPLAINABLE; Buolamwini Joy, 2018, When AI Fails on Oprah, Serena Williams, and Michelle Obama, It's Time to Face Truth; Cai CJ, 2019, PROCEEDINGS OF IUI 2019, P258, DOI 10.1145/3301275.3302289; Cave S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P331, DOI 10.1145/3306618.3314232; Cheng HF, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300789; Collins H., 2002, GOLEM LARGE, DOI DOI 10.1017/CBO9780511541353; Crawford K., 2019, Excavating AI; Daniele A., 2019, Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, AIES'19, P155, DOI DOI 10.1145/3306618.3314233; Du Sautoy M., 2020, CREATIVITY CODE ART; Dunne A., 2013, Speculative everything: Design, fiction, and social dreaming, DOI DOI 10.1093/JDH/EPV001; Eslami M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300724; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; Evans Ceryn, 2017, SAGE Research Methods Datasets; Feiyu Xu, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P563, DOI 10.1007/978-3-030-32236-6_51; Ferrario Andrea, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1457, DOI 10.1145/3531146.3533202; FIEBRINK R, 2010, P 11 INT SOC MUS INF; Gaiger J, 2009, BRIT J AESTHET, V49, P43, DOI 10.1093/aesthj/ayn058; Giuliano RM, 2020, AI SOC, V35, P1009, DOI 10.1007/s00146-020-00966-4; Grba Dejan, 2021, P ART MACH 2 INT S M, P2021; Grba Dejan, 2022, MDPI Digital, V2, P1, DOI DOI 10.3390/DIGITAL2010001; Hemment Drew, 2019, AI Matters, V5, P25, DOI 10.1145/3320254.3320264; Hemment D, 2020, LEONARDO, V53, P529, DOI 10.1162/leon_a_01861; Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P241, DOI 10.1145/358916.358995; Hulse LM, 2018, SAFETY SCI, V102, P1, DOI 10.1016/j.ssci.2017.10.001; Jensen Beth, 2020, How AI and Art Hold Each Other Accountable; Kandlhofer M, 2016, PROC FRONT EDUC CONF; Kolb DA., 2015, EXPERIENTIAL LEARNIN, DOI DOI 10.1016/B978-0-7506-7223-8.50017-4; Kompridis Nikolas., 2014, AESTHETIC TURN POLIT; Laufer Benjamin, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P401, DOI 10.1145/3531146.3533107; Lockey S., 2020, Trust in Artificial Intelligence: Australian insights, DOI DOI 10.14264/B32F129; Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727; Manovich L., 2016, INSTAGRAM CONT IMAGE; Martin AK, 2015, PUBLIC UNDERST SCI, V24, P842, DOI 10.1177/0963662513514173; Metaxa Danae, 2021, FDN TRENDS HUMAN COM, V14, P272, DOI DOI 10.1561/1100000083; Metcalf J., 2022, arXiv, DOI [10.48550/ARXIV.2203.01455, DOI 10.48550/ARXIV.2203.01455]; Morley J, 2020, SCI ENG ETHICS, V26, P2141, DOI 10.1007/s11948-019-00165-5; Munster A, 2013, TECHNOL LIVED ABSTR, P1; Ng D.T.K., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100041; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; Onuoha Mimi, What is Missing Is Still There; Paul Christiane., 2008, New Media in the White Cube and Beyond; Rader E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173677; Raji ID, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P33, DOI 10.1145/3351095.3372873; Reichle I, 2009, ART IN THE AGE OF TECHNOSCIENCE, P1, DOI 10.1007/978-3-211-78161-6; Reisman Dillon, 2018, ALGORITHMIC IMPACT A, V2018; Ridley M, 2021, INFORM TECHNOL LIBR, V40, DOI 10.6017/ital.v40i2.12963; Rockhill Gabriel, 2014, Radical History and the Politics of Art, DOI [10.7312/rock15200, DOI 10.7312/ROCK15200]; RSA, 2018, Artificial intelligence: Real public engagement; Selwyn N, 2022, AI SOC, V37, P1645, DOI 10.1007/s00146-021-01268-z; Shin D, 2022, AI SOC, V37, P81, DOI 10.1007/s00146-021-01158-4; Simoniti V, 2018, J AESTHET ART CRITIC, V76, P71, DOI 10.1111/jaac.12414; Srinivasan Ramya, 2021, The Role of Arts in Shaping AI Ethics; Stark L, 2019, SURVEILL SOC, V17, P442; Taylor GrantD., 2014, MACHINE MADE ART TRO; Tennant C, 2019, TRANSPORT RES F-TRAF, V64, P98, DOI 10.1016/j.trf.2019.04.017; Tromble M, 2020, ARTNODES, DOI 10.7238/a.v0i26.3368; V&A, Digital art V&A; Vartiainen H., 2021, International Journal of Child-Computer Interaction, V29, P100281, DOI DOI 10.1016/J.IJCCI.2021.100281; Wilson S., 2002, INFORM ARTS INTERSEC; Zeilinger Martin, 2021, Tactical Entanglements: AI Art, Creative Agency, and the Limits of Intellectual Property; Zer-Aviv, 2018, The Normalizing Machine | An experiment in machine learning & algorithmic prejudice; Zhang Baobao, 2019, SSRN Electronic Journal, DOI [10.2139/ssrn, DOI 10.2139/SSRN]; Zylinska J., 2020, AI Art: Machine Visions and Warped Dreams	72	3	3	33	52	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-7252-7				2023							931	942		10.1145/3593013.3594052	http://dx.doi.org/10.1145/3593013.3594052			12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Ethics; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BV6VC		Green Accepted			2024-07-03	WOS:001062819300081
C	Kirk, HR; Jun, YN; Iqbal, H; Benussi, E; Volpin, F; Dreyer, FA; Shtedritski, A; Asano, YM		Ranzato, M; Beygelzimer, A; Dauphin, Y; Liang, PS; Vaughan, JW		Kirk, Hannah Rose; Jun, Yennie; Iqbal, Haider; Benussi, Elias; Volpin, Filippo; Dreyer, Frederic A.; Shtedritski, Aleksandar; Asano, Yuki M.			Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)	Advances in Neural Information Processing Systems		English	Proceedings Paper	35th Conference on Neural Information Processing Systems (NeurIPS)	DEC 06-14, 2021	ELECTR NETWORK				SEGREGATION	The capabilities of natural language models trained on large-scale data have increased immensely over the past few years. Open source libraries such as HuggingFace have made these models easily available and accessible. While prior research has identified biases in large language models, this paper considers biases contained in the most popular versions of these models when applied `out-of-the-box' for downstream tasks. We focus on generative language models as they are well-suited for extracting biases inherited from training data. Specifically, we conduct an indepth analysis of GPT-2, which is the most downloaded text generation model on HuggingFace, with over half a million downloads per month. We assess biases related to occupational associations for different protected categories by intersecting gender with religion, sexuality, ethnicity, political affiliation, and continental name origin. Using a template-based data collection pipeline, we collect 396K sentence completions made by GPT-2 and find: (i) The machine-predicted jobs are less diverse and more stereotypical for women than for men, especially for intersections; (ii) Intersectional interactions are highly relevant for occupational associations, which we quantify by fitting 262 logistic models; (iii) For most occupations, GPT-2 reflects the skewed gender and ethnicity distribution found in US Labor Bureau data, and even pulls the societally-skewed distribution towards gender parity in cases where its predictions deviate from real labor market observations. This raises the normative question of what language models should learn - whether they should reflect or correct for existing inequalities.	[Kirk, Hannah Rose; Jun, Yennie; Iqbal, Haider; Benussi, Elias; Volpin, Filippo; Dreyer, Frederic A.; Shtedritski, Aleksandar; Asano, Yuki M.] Univ Oxford, Oxford Artificial Intelligence Soc, Oxford, England	University of Oxford	Kirk, HR (corresponding author), Univ Oxford, Oxford Artificial Intelligence Soc, Oxford, England.	hannah.kirk@oii.ox.ac.uk	Dreyer, Frederic A./F-7841-2019; Asano, Yuki M./AAQ-1283-2021	Asano, Yuki M./0000-0002-8533-4020	Oxford Artificial Intelligence student society; EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines Systems [EP/L015897/1]; Economic and Social Research Council grant for Digital Social Science [ES/P000649/1]; ERC under the European Union's Horizon 2020 research and innovation programme [FUN2MODEL/834115]	Oxford Artificial Intelligence student society; EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines Systems(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Economic and Social Research Council grant for Digital Social Science; ERC under the European Union's Horizon 2020 research and innovation programme(European Research Council (ERC)Horizon 2020)	This work has been supported by the Oxford Artificial Intelligence student society, the EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines & Systems [EP/L015897/1] (A.S., Y.M.A.), the Economic and Social Research Council grant for Digital Social Science [ES/P000649/1] (H.R.K.) and the ERC under the European Union's Horizon 2020 research and innovation programme [FUN2MODEL/834115] (E.B). There are no competing interests.	Adiwardana D., 2020, ABS200109977 ARXIV; [Anonymous], 2016, NeurIPS; Antoniak Maria, 2021, ACL IJCNLP; Barbulescu R, 2013, ORGAN SCI, V24, P737, DOI 10.1287/orsc.1120.0757; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; BELLER AH, 1982, J HUM RESOUR, V17, P371, DOI 10.2307/145586; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender Emily M., 2021, C FAIRN ACC TRANSP F; Bhardwaj Rishabh, 2020, ABS200905021 ARXIV; Blodgett S.L., 2020, ACL; Blodgett Su Lin, 2021, ACL IJCNLP; Borghans L., 1999, Labour Economics, V6, P275; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Crenshaw K., 1989, Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Politics; Díaz M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173986; England Paula., 1992, Comparable Worth: Theories and Evidence; Foulds JR, 2020, PROC INT CONF DATA, P1918, DOI 10.1109/ICDE48307.2020.00203; Glynn S.J., 2014, Explaining the Gender Wage Gap, Available at; Gonen H., 2019, ABS190303862 ARXIV; Grönlund A, 2016, EUR SOC, V18, P91, DOI 10.1080/14616696.2015.1124904; He Pengcheng, 2020, ABS200603654 ARXIV; Institute for Genealogical Studies, 2020, US REL REC 2; González MJ, 2019, EUR SOCIOL REV, V35, P187, DOI 10.1093/esr/jcy055; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.1093/biomet/30.1-2.81; Kiritchenko Svetlana., 2018, SEM@ NAACL-HLT; Kurita Keita, 2019, ABS190607337 ARXIV; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Nadeem Moin, 2020, ABS200409456 ARXIV; Pew Research, 2020, REL LANDSC STUD; Purohit J, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P134, DOI [10.1109/ICCMC.2019.8819708, 10.1109/iccmc.2019.8819708]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rudinger R., 2017, Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, P74, DOI DOI 10.18653/V1/W17-1609; Sheng Emily, 2019, ABS190901326 ARXIV; Similarweb, REDD COM TRAFF RANK; Solaiman Irene, 2019, ABS190809203 ARXIV; Tan Y.C., 2019, NeurIPS; US Labor Bureau of Statistics, 2019, EMPL PEONS DET OCC S; WALDMAN E, 1974, MON LABOR REV, V97, P3; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wikipedia, 2021, LIST MOST POP NAM; Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901; Zhao JY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4847; Zhao Jieyu, 2019, ABS190403310 ARXIV	44	14	14	2	2	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258			ADV NEUR IN			2021	34													14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU4JS					2024-07-03	WOS:000901616403059
C	Satyev, B; Ahn, H			IEEE	Satyev, Bekatan; Ahn, Hyemin			VAFOR: Proactive Voice Assistant for Object Retrieval in the Physical World	2023 32ND IEEE INTERNATIONAL CONFERENCE ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, RO-MAN	IEEE RO-MAN		English	Proceedings Paper	32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)	AUG 28-31, 2023	Busan, SOUTH KOREA	IEEE				In this paper, we present a proactive robotic voice assistant with a perceive-reason-act loop that carries out pick-and-place operations based on verbal commands. Unlike existing systems, our robot can retrieve a target object not only when the target is explicitly spelled out, but also given an indirect command that implicitly reflects the human intention or emotion. For instance, when the verbal command is "I had a busy day, so I didn't have much to eat.", the target object would be something that can help with hunger. To successfully estimate the target object from indirect commands, our framework consists of separate modules for the complete perceive-reason-act loop as follows. First, for perception, it runs an object detector on the robot's onboard computer to detect all objects in the surroundings and records a verbal command from a microphone. Second, for reasoning, a list of available objects as well as a transcription of the verbal command are integrated into a prompt for a Large Language Model (LLM) in order to identify the target object in the command. Finally, for action, a TurtleBot3 with a 5 DOF robotic arm finds the target object and brings it to the human. Our experiments show that with a properly designed prompt, the robot can identify the correct target object from implicit commands with at most 97% accuracy. In addition, it is shown that the technique of fine-tuning a language model based on the proposed prompt designing process amplifies the performance of the smallest language model by a factor of five. Our data and code are available at https://github.com/bekatan/vafor	[Ahn, Hyemin] UNIST, Artificial Intelligence Grad Sch AIGS, Ulsan, South Korea	Ulsan National Institute of Science & Technology (UNIST)	Ahn, H (corresponding author), UNIST, Artificial Intelligence Grad Sch AIGS, Ulsan, South Korea.	bekatans@unist.ac.kr; hyemin.ahn@unist.ac.kr	Ahn, Hyemin/KRO-9543-2024	Ahn, Hyemin/0009-0006-8693-9888	UNIST (Ulsan National Institute of Science Technology) [1.220117.01]; Institute of Information & communications Technology Planning & Evaluation(IITP) - Korean government(MSIT) [2020-0-01336, 2022-0-00612]	UNIST (Ulsan National Institute of Science Technology); Institute of Information & communications Technology Planning & Evaluation(IITP) - Korean government(MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea)	This work was supported by the 2023 Research Fund(1.220117.01) of UNIST (Ulsan National Institute of Science Technology), and the Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korean government(MSIT) (No.2020-0-01336, Artificial Intelligence Graduate School Program(UNIST), No. 2022-0-00612, Geometric and Physical Commonsense Reasoning based Behavior Intelligence for Embodied AI).	Bjelonic M., 2016, YOLO ROS: Real-Time Object Detection for ROS; Brohan A., 2022, 6 ANN C ROB LEARN; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Ding Y., 2022, arXiv; Duguleana M, 2016, EXPERT SYST APPL, V62, P104, DOI 10.1016/j.eswa.2016.06.021; Huang WL, 2022, PR MACH LEARN RES; Li ZH, 2021, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.610139; Nieman DC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194843; OpenAI, 2021, Openai api documentation: Text completion; OpenAI, 2021, Fine-tuning with the openai platform api; OpenAI, 2022, What's changed with engine names and best practices; Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767; Rosenbaum DA, 2001, MOTOR CONTROL, V5, P99, DOI 10.1123/mcj.5.2.99; Stanford Artificial Intelligence Laboratory, Robotic operating system.; Zhang Anthony, SPEECH RECOGNITION	15	0	0	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1944-9445		979-8-3503-3670-2	IEEE ROMAN			2023							654	659		10.1109/RO-MAN57019.2023.10309466	http://dx.doi.org/10.1109/RO-MAN57019.2023.10309466			6	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Ergonomics; Robotics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Engineering; Robotics	BW1NV					2024-07-03	WOS:001108678600093
J	Pham, C; Govender, R; Tehami, S; Chavez, S; Adepoju, OE; Liaw, W				Pham, Cecilia; Govender, Romi; Tehami, Salik; Chavez, Summer; Adepoju, Omolola E.; Liaw, Winston			ChatGPT's Performance in Cardiac Arrest and Bradycardia Simulations Using the American Heart Association's Advanced Cardiovascular Life Support Guidelines: Exploratory Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						ChatGPT; artificial intelligence; AI; large language model; LLM; cardiac arrest; bradycardia; simulation; advanced cardiovascular; life support; ACLS; bradycardia simulations; America; American; heart association; cardiac; exploratory study; heart; heart attack; clinical decision support; diagnostics; algorithms	CARDIOPULMONARY-RESUSCITATION; TRAINING-PROGRAM	Background: ChatGPT is the most advanced large language model to date, with prior iterations having passed medical licensing examinations, providing clinical decision support, and improved diagnostics. Although limited, past studies of ChatGPT's performance found that artificial intelligence could pass the American Heart Association's advanced cardiovascular life support (ACLS) examinations with modifications. ChatGPT's accuracy has not been studied in more complex clinical scenarios. As heart disease and cardiac arrest remain leading causes of morbidity and mortality in the United States, finding technologies that help increase adherence to ACLS algorithms, which improves survival outcomes, is critical. Objective: This study aims to examine the accuracy of ChatGPT in following ACLS guidelines for bradycardia and cardiac arrest. Methods: We evaluated the accuracy of ChatGPT's responses to 2 simulations based on the 2020 American Heart Association ACLS guidelines with 3 primary outcomes of interest: the mean individual step accuracy, the accuracy score per simulation attempt, and the accuracy score for each algorithm. For each simulation step, ChatGPT was scored for correctness (1 point) or Results: ChatGPT's median accuracy for each step was 85% (IQR 40%-100%) for cardiac arrest and 30% (IQR 13%-81%) for bradycardia. ChatGPT's median accuracy over 20 simulation attempts for cardiac arrest was 69% (IQR 67%-74%) and for bradycardia was 42% (IQR 33%-50%). We found that ChatGPT's outputs varied despite consistent input, the same actions were persistently missed, repetitive overemphasis hindered guidance, and erroneous medication information was presented. Conclusions: This study highlights the need for consistent and reliable guidance to prevent potential medical errors and optimize the application of ChatGPT to enhance its reliability and effectiveness in clinical practice.	[Pham, Cecilia; Govender, Romi; Tehami, Salik; Chavez, Summer; Adepoju, Omolola E.; Liaw, Winston] Univ Houston, Tilman J Fertitta Family Coll Med, 5055 Med Circle, Houston, TX 77204 USA; [Chavez, Summer; Adepoju, Omolola E.; Liaw, Winston] Univ Houston, Humana Integrated Hlth Sci Inst, Houston, TX USA; [Chavez, Summer; Adepoju, Omolola E.; Liaw, Winston] Tilman J Fertitta Family Coll Med, Dept Hlth Syst & Populat Hlth Sci, Houston, TX USA	University of Houston System; University of Houston; University of Houston System; University of Houston	Pham, C (corresponding author), Univ Houston, Tilman J Fertitta Family Coll Med, 5055 Med Circle, Houston, TX 77204 USA.	cmpham4@uh.edu		Pham, Cecilia/0009-0001-5172-1487; Adepoju, Omolola/0000-0002-5585-7146; Liaw, Winston/0000-0002-7865-1685; Chavez, Summer/0000-0003-4249-6692; Tehami, Salik/0000-0002-2804-502X				Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; [Anonymous], Introducing chatgpt; [Anonymous], CPR Facts and Stats; [Anonymous], History of CPR; [Anonymous], 2020, 2020 HeartCode courses FAQs; [Anonymous], Heart disease deaths-Health; [Anonymous], 2023, GPT-4. AI O; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brophy SL, 2023, AEM EDUC TRAIN, V7, DOI 10.1002/aet2.10880; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Corazza F, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.27272; Corazza F, 2022, INTERN EMERG MED, V17, P2143, DOI 10.1007/s11739-022-03041-6; Crowley CP, 2020, RESUSCITATION, V153, P65, DOI 10.1016/j.resuscitation.2020.05.042; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Graham R., 2015, Strategies to Improve Cardiac Arrest Survival: A Time to Act, V7; Harskamp RE, 2023, medRxiv, DOI [10.1101/2023.03.25.23285475, https://doi.org/10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475, 10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475V1]; Hejjaji V, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15762; Honarmand K, 2018, RESUSCITATION, V129, P76, DOI 10.1016/j.resuscitation.2018.06.005; Hunt EA, 2009, RESUSCITATION, V80, P819, DOI 10.1016/j.resuscitation.2009.03.020; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; SANDERS AB, 1994, ANN EMERG MED, V23, P56, DOI 10.1016/S0196-0644(94)70009-5; Siebert JN, 2020, J MED INTERNET RES, V22, DOI 10.2196/17792; Siebert JN, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7379; Sodhi K, 2011, INDIAN J CRIT CARE M, V15, P209, DOI 10.4103/0972-5229.92070; Waqas, 2023, AI in healthcare: ChatGPT helps boy get diagnosis after doctors fail; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	30	0	0	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	APR 22	2024	26								e55037	10.2196/55037	http://dx.doi.org/10.2196/55037			10	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	PY1Q0	38648098	gold, Green Accepted			2024-07-03	WOS:001217552200004
J	Decker, H; Trang, K; Ramirez, J; Colley, A; Pierce, L; Coleman, M; Bongiovanni, T; Melton, GB; Wick, E				Decker, Hannah; Trang, Karen; Ramirez, Joel; Colley, Alexis; Pierce, Logan; Coleman, Melissa; Bongiovanni, Tasce; Melton, Genevieve B.; Wick, Elizabeth			Large Language Model-Based Chatbot vs Surgeon-Generated Informed Consent Documentation for Common Procedures	JAMA NETWORK OPEN			English	Article							READABILITY	Importance Informed consent is a critical component of patient care before invasive procedures, yet it is frequently inadequate. Electronic consent forms have the potential to facilitate patient comprehension if they provide information that is readable, accurate, and complete; it is not known if large language model (LLM)-based chatbots may improve informed consent documentation by generating accurate and complete information that is easily understood by patients.Objective To compare the readability, accuracy, and completeness of LLM-based chatbot- vs surgeon-generated information on the risks, benefits, and alternatives (RBAs) of common surgical procedures.Design, Setting, and Participants This cross-sectional study compared randomly selected surgeon-generated RBAs used in signed electronic consent forms at an academic referral center in San Francisco with LLM-based chatbot-generated (ChatGPT-3.5, OpenAI) RBAs for 6 surgical procedures (colectomy, coronary artery bypass graft, laparoscopic cholecystectomy, inguinal hernia repair, knee arthroplasty, and spinal fusion).Main Outcomes and Measures Readability was measured using previously validated scales (Flesh-Kincaid grade level, Gunning Fog index, the Simple Measure of Gobbledygook, and the Coleman-Liau index). Scores range from 0 to greater than 20 to indicate the years of education required to understand a text. Accuracy and completeness were assessed using a rubric developed with recommendations from LeapFrog, the Joint Commission, and the American College of Surgeons. Both composite and RBA subgroup scores were compared.Results The total sample consisted of 36 RBAs, with 1 RBA generated by the LLM-based chatbot and 5 RBAs generated by a surgeon for each of the 6 surgical procedures. The mean (SD) readability score for the LLM-based chatbot RBAs was 12.9 (2.0) vs 15.7 (4.0) for surgeon-generated RBAs (P = .10). The mean (SD) composite completeness and accuracy score was lower for surgeons' RBAs at 1.6 (0.5) than for LLM-based chatbot RBAs at 2.2 (0.4) (P < .001). The LLM-based chatbot scores were higher than the surgeon-generated scores for descriptions of the benefits of surgery (2.3 [0.7] vs 1.4 [0.7]; P < .001) and alternatives to surgery (2.7 [0.5] vs 1.4 [0.7]; P < .001). There was no significant difference in chatbot vs surgeon RBA scores for risks of surgery (1.7 [0.5] vs 1.7 [0.4]; P = .38).Conclusions and Relevance The findings of this cross-sectional study suggest that despite not being perfect, LLM-based chatbots have the potential to enhance informed consent documentation. If an LLM were embedded in electronic health records in a manner compliant with the Health Insurance Portability and Accountability Act, it could be used to provide personalized risk information while easing documentation burden for physicians.	[Decker, Hannah] Univ Calif San Francisco, Philip R Lee Inst Hlth Policy Studies, Mission Bay Campus,Valley Tower,490 Illinois St,7t, San Francisco, CA 94158 USA; [Decker, Hannah; Trang, Karen; Ramirez, Joel; Colley, Alexis; Coleman, Melissa; Bongiovanni, Tasce; Wick, Elizabeth] Univ Calif San Francisco, Dept Surg, San Francisco, CA 94158 USA; [Pierce, Logan] Univ Calif San Francisco, Dept Med, San Francisco, CA 94158 USA; [Melton, Genevieve B.] Univ Minnesota, Inst Hlth Informat, Dept Surg, Minneapolis, MN USA; [Melton, Genevieve B.] Univ Minnesota, Ctr Learning Hlth Syst Sci, Minneapolis, MN USA	University of California System; University of California San Francisco; UCSF Medical Center; UCSF Medical Center Mission Bay; University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities	Decker, H (corresponding author), Univ Calif San Francisco, Philip R Lee Inst Hlth Policy Studies, Mission Bay Campus,Valley Tower,490 Illinois St,7t, San Francisco, CA 94158 USA.	58hannah.decker@ucsf.edu	Melton-Meaux, Genevieve B/HSE-3064-2023	Melton-Meaux, Genevieve B/0000-0001-5193-1663				Agency for Healthcare Quality and Research, Most Frequent Operating Room Procedures Performed in US Hospitals; American College of Surgeons, Informed Consent; [Anonymous], 1996, Psychol Health Med, DOI [10.1080/13548509608400003, DOI 10.1080/13548509608400003]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bilimoria KY, 2013, J AM COLL SURGEONS, V217, P833, DOI 10.1016/j.jamcollsurg.2013.07.385; Boztas N, 2014, TURK J ANAESTHESIOL, V42, P140, DOI 10.5152/TJAR.2014.94547; Chang N., View of Linguistic Wisdom from the Crowd; Chimonas S, 2023, JCO CLIN CANCER INFO, V7, DOI 10.1200/CCI.22.00122; Coco L, 2017, AM J AUDIOL, V26, P309, DOI 10.1044/2017_AJA-17-0018; Dharmasukrit C, 2023, ANN SURG, V277, pE513, DOI 10.1097/SLA.0000000000005286; Eltorai AEM, 2015, CTS-CLIN TRANSL SCI, V8, P830, DOI 10.1111/cts.12364; Elwyn G, 2012, J GEN INTERN MED, V27, P1361, DOI 10.1007/s11606-012-2077-6; Falagas ME, 2009, AM J SURG, V198, P420, DOI 10.1016/j.amjsurg.2009.02.010; Grady C, 2015, NEW ENGL J MED, V372, P855, DOI 10.1056/NEJMra1411250; Issa MM, 2006, J UROLOGY, V176, P694, DOI 10.1016/j.juro.2006.03.037; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kessels RPC, 2003, J ROY SOC MED, V96, P219, DOI 10.1258/jrsm.96.5.219; Kinnersley P, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009445.pub2; LAVELLEJONES C, 1993, BRIT MED J, V306, P885, DOI 10.1136/bmj.306.6882.885; Leapfrog Group, Informed Consent: Hospital and Surgery Center Ratings; Meade MJ, 2022, INT ORTHOD, V20, DOI 10.1016/j.ortho.2022.100689; Open AI, GPT-4 technical report; OpenAI, Introducing ChatGPT; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Paterick ZR, 2020, POSTGRAD MED J, V96, P708, DOI 10.1136/postgradmedj-2019-137278; Raja H, 2023, J LARYNGOL OTOL, V137, P1130, DOI 10.1017/S0022215122002626; Reeves JJ, 2020, JAMA SURG, V155, P777, DOI 10.1001/jamasurg.2020.1014; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Scheer AS, 2012, DIS COLON RECTUM, V55, P970, DOI 10.1097/DCR.0b013e31825f2479; Schenker Y, 2011, MED DECIS MAKING, V31, P151, DOI 10.1177/0272989X10364247; Simon CM, 2022, J EMPIR RES HUM RES, V17, P144, DOI 10.1177/15562646211038819; Sivanadarajah N, 2017, ANN ROY COLL SURG, V99, P645, DOI 10.1308/rcsann.2017.0188; Soliman L., 2023, Cleft Palate Craniofac J; Sönmez MG, 2018, TURK J SURG, V34, P295, DOI 10.5152/turkjsurg.2017.3973; The Joint Commission, Quick Safety 21: Informed Consent: More than Getting a Signature; Tustumi F., 2023, Arq Bras Cir Dig, P36, DOI [10.1590/0102-672020230002e171, DOI 10.1590/0102-672020230002E171]	38	10	10	20	26	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	OCT 9	2023	6	10							e2336997	10.1001/jamanetworkopen.2023.36997	http://dx.doi.org/10.1001/jamanetworkopen.2023.36997			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	U5WU3	37812419	Green Published, gold			2024-07-03	WOS:001085513300004
J	Liu, YT; Checa, M; Vasudevan, RK				Liu, Yongtao; Checa, Marti; Vasudevan, Rama K.			Synergizing human expertise and AI efficiency with language model for microscopy operation and automated experiment design	MACHINE LEARNING-SCIENCE AND TECHNOLOGY			English	Article						automated experiment; microscopy; language model; application program interface	PEROVSKITES	With the advent of large language models (LLMs), in both the open source and proprietary domains, attention is turning to how to exploit such artificial intelligence (AI) systems in assisting complex scientific tasks, such as material synthesis, characterization, analysis and discovery. Here, we explore the utility of LLMs, particularly ChatGPT4, in combination with application program interfaces (APIs) in tasks of experimental design, programming workflows, and data analysis in scanning probe microscopy, using both in-house developed APIs and APIs given by a commercial vendor for instrument control. We find that the LLM can be especially useful in converting ideations of experimental workflows to executable code on microscope APIs. Beyond code generation, we find that the GPT4 is capable of analyzing microscopy images in a generic sense. At the same time, we find that GPT4 suffers from an inability to extend beyond basic analyses for more in-depth technical experimental design. We argue that an LLM specifically fine-tuned for individual scientific domains can potentially be a better language interface for converting scientific ideations from human experts to executable workflows. Such a synergy between human expertise and LLM efficiency in experimentation can open new doors for accelerating scientific research, enabling effective experimental protocols sharing in the scientific community.	[Liu, Yongtao; Checa, Marti; Vasudevan, Rama K.] Oak Ridge Natl Lab, Ctr Nanophase Mat Sci, Oak Ridge, TN 37830 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory; Center for Nanophase Materials Sciences	Liu, YT (corresponding author), Oak Ridge Natl Lab, Ctr Nanophase Mat Sci, Oak Ridge, TN 37830 USA.	liuy3@ornl.gov	Vasudevan, Rama/Q-2530-2015	Vasudevan, Rama/0000-0003-4692-8579	Center for Nanophase Materials Sciences (CNMS); US Department of Energy, Office of Science User Facility at Oak Ridge National Laboratory	Center for Nanophase Materials Sciences (CNMS)(United States Department of Energy (DOE)); US Department of Energy, Office of Science User Facility at Oak Ridge National Laboratory(United States Department of Energy (DOE))	This research was supported by the Center for Nanophase Materials Sciences (CNMS), which is a US Department of Energy, Office of Science User Facility at Oak Ridge National Laboratory. Y L wishes to express sincere gratitude to Sergei V Kalinin for helpful discussion.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Beltagy I., 2019, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buehler MJ, 2024, APPL MECH REV, V76, DOI 10.1115/1.4063843; Checa M, 2023, NANOTECHNOLOGY, V34, DOI 10.1088/1361-6528/acd34d; Checa M, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-42583-x; Chen IJ, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35149-w; Dunn A., 2022, arXiv; Hawkes P.W., 2007, Science of microscopy; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Huang S, 2022, J CHEM INF MODEL, V62, P6365, DOI 10.1021/acs.jcim.2c00035; Jablonka KM, 2023, DIGIT DISCOV, V2, P1233, DOI 10.1039/d3dd00113j; Kalinin SV, 2024, APPL PHYS REV, V11, DOI 10.1063/5.0169961; Kang Y, 2023, Arxiv, DOI arXiv:2308.01423; Krull A, 2020, COMMUN PHYS-UK, V3, DOI 10.1038/s42005-020-0317-3; Kuenneth C, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-39868-6; Lei XY, 2023, Arxiv, DOI arXiv:2307.15759; Liu Y., 2023, AEcroscoPy; Liu Y., 2023, MetaRadiology, V1; Liu YT, 2024, SMALL METHODS, DOI 10.1002/smtd.202301740; Liu YT, 2023, ACS NANO, V17, P9647, DOI 10.1021/acsnano.3c03363; Liu YT, 2023, J PHYS CHEM LETT, V14, P3352, DOI 10.1021/acs.jpclett.3c00223; Liu YT, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-00985-x; Liu YT, 2022, SMALL, V18, DOI 10.1002/smll.202204130; Liu YT, 2022, ADV SCI, V9, DOI 10.1002/advs.202203957; Liu YT, 2022, APPL PHYS LETT, V120, DOI 10.1063/5.0079217; Liu YT, 2022, NAT MACH INTELL, V4, P341, DOI 10.1038/s42256-022-00460-0; Liu YT, 2021, ADV MATER, V33, DOI 10.1002/adma.202103680; Liu YT, 2018, NAT MATER, V17, P1013, DOI 10.1038/s41563-018-0152-z; Liu Y, 2023, J MATERIOMICS, V9, P798, DOI 10.1016/j.jmat.2023.05.001; Meyer E, 2004, MRS BULL, V29, P443, DOI 10.1557/mrs2004.137; Microsoft, 2023, Copilot; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; OpenAI, 2023, GPT-4; Prince MH, 2023, Arxiv, DOI arXiv:2312.01291; Qian C, 2023, Arxiv, DOI arXiv:2307.07443; Ramsauer B, 2023, J PHYS CHEM A, V127, P2041, DOI 10.1021/acs.jpca.2c08696; Rashidi M, 2018, ACS NANO, V12, P5185, DOI 10.1021/acsnano.8b02208; Roccapriore KM, 2022, ADV SCI, V9, DOI 10.1002/advs.202203422; Rubungo AN, 2023, Arxiv, DOI arXiv:2310.14029; Scheffler M, 2022, NATURE, V604, P635, DOI 10.1038/s41586-022-04501-x; Sim M., 2023, ChemOS 2.0: an orchestration architecture for chemical self-driving laboratories; Sotres J, 2021, NANOSCALE, V13, P9193, DOI 10.1039/d1nr01109j; Tamura R, 2023, Arxiv, DOI arXiv:2304.13927; Taylor R, 2022, arXiv; Thomas JC, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00777-9; Unlutabak B., 2023, ChemRxiv; Venugopal V., 2023, AI ACC MAT DES NEURI; Xie YC, 2023, PROG MATER SCI, V132, DOI 10.1016/j.pmatsci.2022.101043; Xu M, 2022, MICROSC MICROANAL, V28, P1952, DOI 10.1017/S1431927622012193; Xu ZW, 2024, Arxiv, DOI arXiv:2401.11817; Ye H., 2023, arXiv, DOI DOI 10.48550/ARXIV.2309.06794; Ziatdinov M, 2022, ACS NANO, V16, P13492, DOI 10.1021/acsnano.2c05303	54	0	0	1	1	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND		2632-2153		MACH LEARN-SCI TECHN	Mach. Learn.-Sci. Technol.	JUN 1	2024	5	2							02LT01	10.1088/2632-2153/ad52e9	http://dx.doi.org/10.1088/2632-2153/ad52e9			12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Science & Technology - Other Topics	US2X1					2024-07-03	WOS:001249992900001
J	Ni, ZX; Peng, R; Zheng, XF; Xie, P				Ni, Zhengxin; Peng, Rui; Zheng, Xiaofei; Xie, Ping			Embracing the future: Integrating ChatGPT into China's nursing education system	INTERNATIONAL JOURNAL OF NURSING SCIENCES			English	Editorial Material						Artificial intelligence; ChatGPT; China; Examination; Licensure; Nursing education	QUESTIONS	This article delves into the role of ChatGPT within the rapidly evolving field of artificial intelligence, especially highlighting its significant potential in nursing education. Initially, the paper presents the notable advancements ChatGPT has achieved in facilitating interactive learning and providing real-time feedback, along with the academic community 's growing interest in this technology. Subsequently, summarizing the research outcomes of ChatGPT 's applications in nursing education, including various clinical disciplines and scenarios, showcases the enormous potential for multidisciplinary education and addressing clinical issues. Comparing the performance of several Large Language Models (LLMs) on China 's National Nursing Licensure Examination, we observed that ChatGPT demonstrated a higher accuracy rate than its counterparts, providing a solid theoretical foundation for its application in Chinese nursing education and clinical settings. Educational institutions should establish a targeted and effective regulatory framework to leverage ChatGPT in localized nursing education while assuming corresponding responsibilities. Through standardized training for users and adjustments to existing educational assessment methods aimed at preventing potential misuse and abuse, the full potential of ChatGPT as an innovative auxiliary tool in China 's nursing education system can be realized, aligning with the developmental needs of modern teaching methodologies. (c) 2024 The authors. Published by Elsevier B.V. on behalf of the Chinese Nursing Association.	[Ni, Zhengxin] Yangzhou Univ, Sch Nursing, Yangzhou, Peoples R China; [Peng, Rui; Zheng, Xiaofei] Jinan Univ, Affiliated Hosp 1, Dept Bone & Joint Surg, Guangzhou, Peoples R China; [Peng, Rui; Zheng, Xiaofei] Jinan Univ, Affiliated Hosp 1, Sports Med Ctr, Guangzhou, Peoples R China; [Xie, Ping] Northern Jiangsu Peoples Hosp, Dept External Cooperat, Nanjing, Peoples R China	Yangzhou University; Jinan University; Jinan University	Xie, P (corresponding author), Northern Jiangsu Peoples Hosp, Dept External Cooperat, Nanjing, Peoples R China.	xieping2208@163.com						Alsadhan A, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1259640; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baronchelli A, 2024, PHILOS T R SOC B, V379, DOI 10.1098/rstb.2023.0028; Caglar U, 2023, MINERVA UROL NEPHROL, V75, P729, DOI 10.23736/S2724-6051.23.05450-2; Cox RL, 2023, J NURS EDUC, V62, P679, DOI 10.3928/01484834-20231006-07; Dagci M, 2024, NURS EDUC, V49, pE109, DOI 10.1097/NNE.0000000000001566; Eppler M, 2024, EUR UROL, V85, P146, DOI 10.1016/j.eururo.2023.10.014; Feng Y, 2024, EUR J NUCL MED MOL I, V51, P1203, DOI 10.1007/s00259-023-06579-5; Gabriel J, 2024, BJU INT, V133, P407, DOI 10.1111/bju.16240; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Gosak L, 2024, NURSE EDUC PRACT, V75, DOI 10.1016/j.nepr.2024.103888; Graham A, 2023, BMJ-BRIT MED J, V381, DOI 10.1136/bmj.p1133; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Guevara M, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-023-00970-0; Gupta R, 2023, AESTHET SURG J, DOI 10.1093/asj/sjad128; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Liu JL, 2023, NURS OUTLOOK, V71, DOI 10.1016/j.outlook.2023.102064; Lourenco AP, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231053; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Moons P, 2024, EUR J CARDIOVASC NUR, V23, P122, DOI 10.1093/eurjcn/zvad087; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Policies E, 2023, Science; Qu Xing, 2023, Sichuan Da Xue Xue Bao Yi Xue Ban, V54, P937, DOI 10.12182/20231360302; Sahu PK, 2024, POSTGRAD MED J, V100, P50, DOI 10.1093/postmj/qgad090; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sharma M, 2023, NURS EDUC TODAY, V131, DOI 10.1016/j.nedt.2023.105972; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Taira Kazuya, 2023, JMIR Nurs, V6, pe47305, DOI 10.2196/47305; Tam W, 2023, NURS EDUC TODAY, V129, DOI 10.1016/j.nedt.2023.105917; Younis HA, 2024, DIAGNOSTICS, V14, DOI 10.3390/diagnostics14010109; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	42	0	0	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2352-0132		INT J NURS SCI	INT. J. NURS. SCI.	APR	2024	11	2					295	299		10.1016/j.ijnss.2024.03.006	http://dx.doi.org/10.1016/j.ijnss.2024.03.006			5	Nursing	Emerging Sources Citation Index (ESCI)	Nursing	QS8H9	38707690	Green Published, gold			2024-07-03	WOS:001222946600014
J	Hu, ZC; Lucchetti, F; Schlesinger, C; Saxena, Y; Freeman, A; Modak, S; Guha, A; Biswas, J				Hu, Zichao; Lucchetti, Francesca; Schlesinger, Claire; Saxena, Yash; Freeman, Anders; Modak, Sadanand; Guha, Arjun; Biswas, Joydeep			Deploying and Evaluating LLMs to Program Service Mobile Robots	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						Software tools for benchmarking and reproducibility; software tools for robot programming; social HRI; human-centered robotics; service robotics		Recent advancements in large language models (LLMs) have spurred interest in using them for generating robot programs from natural language, with promising initial results. We investigate the use of LLMs to generate programs for service mobile robots leveraging mobility, perception, and human interaction skills, and where accurate sequencing and ordering of actions is crucial for success. We contribute CodeBotler, an open-source robot-agnostic tool to program service mobile robots from natural language, and RoboEval, a benchmark for evaluating LLMs' capabilities of generating programs to complete service robot tasks. CodeBotler performs program generation via few-shot prompting of LLMs with an embedded domain-specific language (eDSL) in Python, and leverages skill abstractions to deploy generated programs on any general-purpose mobile robot. RoboEval evaluates the correctness of generated programs by checking execution traces starting with multiple initial states, and checking whether the traces satisfy temporal logic properties that encode correctness for each task. RoboEval also includes multiple prompts per task to test for the robustness of program generation. We evaluate several popular state-of-the-art LLMs with the RoboEval benchmark, and perform a thorough analysis of the modes of failures, resulting in a taxonomy that highlights common pitfalls of LLMs at generating robot programs.	[Hu, Zichao; Saxena, Yash; Modak, Sadanand; Biswas, Joydeep] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA; [Lucchetti, Francesca] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA; [Schlesinger, Claire; Freeman, Anders] Wellesley Coll, Dept Comp Sci, Wellesley, MA 02481 USA	University of Texas System; University of Texas Austin; Northeastern University; Wellesley College	Hu, ZC (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	zichao@utexas.edu; lucchetti.f@northeastern.edu; schlesinger.e@northeastern.edu; yash.saxena@utexas.edu; af103@wellesley.edu; sadanandm@utexas.edu; a.guha@northeastern.edu; joydeep@utexas.edu		Guha, Arjun/0000-0002-7493-3271; Modak, Sadanand/0000-0001-7618-9274; Lucchetti, Francesca/0009-0002-5837-6097; Schlesinger, Claire/0009-0000-2533-1242; Biswas, Joydeep/0000-0002-1211-1731; Hu, Zichao/0009-0007-6433-8878	National Science Foundation	National Science Foundation(National Science Foundation (NSF))	No Statement Available	Ahn Michael, 2022, DO I CAN NOT I SAY G; Anil R., 2023, PaLM 2 Technical Report; [Anonymous], 2023, Generative AI for developers; [Anonymous], 2023, OpenAI Platform; [Anonymous], 2023, ROS Actionlib; [Anonymous], 2023, GPT-4 Technical Report; Austin Jacob, 2021, PROGRAM SYNTHESIS LA; Babe H. M., 2023, Studenteval: A benchmark of studentwritten prompts for large language models of code; Bommasani R, 2023, ANN NY ACAD SCI, V1525, P140, DOI 10.1111/nyas.15007; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang Y, 2023, ACM Transactions on Intelligent Systems and Technology; Chen BY, 2023, IEEE INT CONF ROBOT, P11509, DOI 10.1109/ICRA48891.2023.10161534; Chen Mark., 2021, EVALUATING LARGE LAN, P2021, DOI [DOI 10.48550/ARXIV.2107.03374, 10.48550/ARXIV.2107.03374]; Dhole K. D., 2021, Northern Eur. J. Lang. Technol; Ding Y, 2023, IEEE INT C INT ROBOT, P2086, DOI 10.1109/IROS55552.2023.10342169; Driess D., 2023, INT C MACHINE LEARNI, P8469; Gat I., 2023, CODE LLAMA OPEN FDN; Huang CG, 2023, IEEE INT CONF ROBOT, P10608, DOI 10.1109/ICRA48891.2023.10160969; Huang W, 2022, C ROBOT LEARNING P M, P1769; Huang W, 2023, P C ROBOT LEARNING C, P540; Huang W., 2022, P INT C MACH LEARN; Lai Y., 2023, PMLR, P18319; Li R., 2023, Trans. Mach. Learn. Res; Liang J., 2022, Code as Policies: Language Model Programs for Embodied Control; Liu B, 2023, LLM+P: Empowering large language models with optimal planning proficiency; Liu MXY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580817; Liu X, 2023, P 12 INT C LEARN REP; Miceli-Barone A. V., 2023, P 61 ANN M ASS COMP; Shah D., 2022, P C ROB LEARN, V205, P492; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Song Chan Hee, 2023, 2023 IEEE/CVF International Conference on Computer Vision (ICCV), P2986, DOI 10.1109/ICCV51070.2023.00280; Tang Y., 2023, P 7 C ROB LEARN NOV, V229, P3556; Wang G., 2023, P 37 C NEUR INF PROC; Wu J, 2023, AUTON ROBOT, V47, P1087, DOI 10.1007/s10514-023-10139-z; Yao S., 2023, P 37 INT C NEUR INF; Yu W., 2023, P 7 C ROB LEARN, P374; Zitkovich B., 2023, C ROBOT LEARNING, P2165	37	0	0	12	12	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	MAR	2024	9	3					2853	2860		10.1109/LRA.2024.3360020	http://dx.doi.org/10.1109/LRA.2024.3360020			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	JP2F7		Green Submitted			2024-07-03	WOS:001174297500009
J	Zhong, SF; Guan, XH				Zhong, Shifa; Guan, Xiaohong			Developing Quantitative Structure-Activity Relationship (QSAR) Models for Water Contaminants' Activities/Properties by Fine-Tuning GPT-3 Models	ENVIRONMENTAL SCIENCE & TECHNOLOGY LETTERS			English	Article						Machine learning; QSAR; Water contaminants; GPT-3; Fine-tuning		In this study, we developed quantitative structure-activity relationship (QSAR) models for water contaminants' activities/properties by fine-tuning GPT-3 models. We also proposed a novel masked atom importance (MAI) approach for model interpretation and an OpenAIEmbedding similarity-based method for determining the applicability domain. We utilized the Simplified Molecular-Input Line-Entry System (SMILES) of contaminants and their corresponding activities/properties from hree data sets: pKd, Koc, and Solubility. These were used as input prompts and completions, respectively, to fine-tune four GPT-3 models (Davinci, Curie, Babbage, and Ada) obtained from OpenAI. The Babbage model demonstrated superior performance for the pKd data set, while the Davinci model excelled with the Koc and Solubility data sets, even outperforming molecular fingerprint (MF) CatBoost-based QSAR models. The MAI interpretation results were qualitatively consistent with the SHapley additive expansion (SHAP) interpretation but exhibited less sensitivity in quantitative analysis. The OpenAIEmbedding similarity-based applicability domain determination approach showed efficacy comparable to that of the MF-based similarity approach but with added robustness. This study underscores the potential of large language models in developing QSAR models, paving the way for further advancements in QSAR modeling using state-of-the-art language models.	[Zhong, Shifa; Guan, Xiaohong] East China Normal Univ, Sch Ecol & Environm Sci, Dept Environm Sci, Shanghai 200241, Peoples R China	East China Normal University	Guan, XH (corresponding author), East China Normal Univ, Sch Ecol & Environm Sci, Dept Environm Sci, Shanghai 200241, Peoples R China.	xhguan@des.ecnu.edu.cn	Guan, Xiaohong/K-4206-2012	Zhong, Shifa/0000-0002-5822-0837	National Natural Science Foundation of China [22076143, 22306065]; Science and Technology Commission of Shanghai Municipality [22DZ1202300]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality(Science & Technology Commission of Shanghai Municipality (STCSM))	This work was supported by the National Natural Science Foundation of China (Grants No. 22076143 and No. 22306065) and the Science and Technology Commission of Shanghai Municipality (No. 22DZ1202300).	[Anonymous], 2022, PREPRINT; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Boyack KW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018029; Fang XM, 2022, NAT MACH INTELL, V4, P127, DOI 10.1038/s42256-021-00438-4; Gadaleta D, 2016, Int. J. Quant. Struct. Prop. Relations. (IJQSPR), V1, P45, DOI DOI 10.4018/IJQSPR.2016010102; Guan J., 2023, ARXIVPREPRINT; Kingma D. P., 2017, PREPRINT; Lundberg SM, 2017, ADV NEUR IN, V30; Mao A., 2023, PREPRINT; Martin-Moncunill D, 2022, COMM COM INF SC, V1686, P234, DOI 10.1007/978-3-031-21422-6_17; Nam J., 2023, ARXIV PREPRINT; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Roszak R, 2019, J AM CHEM SOC, V141, P17142, DOI 10.1021/jacs.9b05895; Stella F, 2023, NAT MACH INTELL, V5, P561, DOI 10.1038/s42256-023-00669-7; Wang Y, 2015, CHEMOSPHERE, V119, P438, DOI 10.1016/j.chemosphere.2014.07.007; Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x; Wang ZY, 2021, ENVIRON SCI TECHNOL, V55, P6857, DOI 10.1021/acs.est.0c07040; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Xiao F, 2013, WATER RES, V47, P5362, DOI 10.1016/j.watres.2013.06.011; Zhong SF, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c02198; Zhong SF, 2022, ENVIRON SCI TECHNOL, V56, P681, DOI 10.1021/acs.est.1c04883; Zhong SF, 2021, ENVIRON SCI TECHNOL, V55, P12741, DOI 10.1021/acs.est.1c01339; Zhong SF, 2021, CHEM ENG J, V405, DOI 10.1016/j.cej.2020.126627; Zhong SF, 2021, CHEM ENG J, V408, DOI 10.1016/j.cej.2020.127998; Zhong SF, 2020, J HAZARD MATER, V383, DOI 10.1016/j.jhazmat.2019.121141; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	26	1	1	38	60	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	2328-8930			ENVIRON SCI TECH LET	Environ. Sci. Technol. Lett.	SEP 20	2023	10	10					872	877		10.1021/acs.estlett.3c00599	http://dx.doi.org/10.1021/acs.estlett.3c00599		SEP 2023	6	Engineering, Environmental; Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Environmental Sciences & Ecology	T5DP4					2024-07-03	WOS:001069250400001
J	Gilburt, I				Gilburt, Iona			A machine in the loop: the peculiar intervention of artificial intelligence in writer's block	NEW WRITING-THE INTERNATIONAL JOURNAL FOR THE PRACTICE AND THEORY OF CREATIVE WRITING			English	Article						Artificial intelligence; generative AI; writer's block; hypergraphia; Adaptation; Charlie Kaufman		Generative artificial intelligence is changing how we can choose to resolve writing challenges. Large language models (LLMs) like ChatGPT are readily accessible to generate text effortlessly. This paper explores the human-AI relationship when generative AI is used to assist a writer suffering from writer's block. Research shows that talking to others is an effective strategy for blocked writers. This other no longer needs to be a human. I examine what happens when generative AI is brought into the writing loop: the nonlinear process of writing and rewriting a creative piece. The film Adaptation (2002. Directed by Spike Jonze, Performance by Nicolas Cage. Meryl Streep, and Chris Cooper. Columbia), written by Charlie Kaufman, is used as a case study of writer's block to illustrate several complexities of the disorder and to theorise potential openings and limitations for the use of AI. Through the film, writer's block is also explored as having a twin pathology of hypergraphia. Writing with AI is seen to mimic peculiarities of creative writing that include projecting one's inner voice and seeking a false self. In the example of Adaptation, one ultimately comes to appreciate too that suffering through a block unaided can propel a writer to make bold decisions and test the limits of human creativity.	[Gilburt, Iona] Univ Western Cape, Ctr Humanities Res, Bellville, WC, South Africa	University of the Western Cape	Gilburt, I (corresponding author), Univ Western Cape, Ctr Humanities Res, Bellville, WC, South Africa.	iigilburt@gmail.com		Gilburt, Iona/0000-0002-6141-451X				Ahmed SJ, 2022, CREATIVITY RES J, V34, P339, DOI 10.1080/10400419.2022.2031436; Allado-McDowell K., 2022, COMMUNICATION    NOV; Allado-McDowell K., 2022, WIRED           0524; Allado-McDowell K., 2020, Pharmako-AI; Allado-McDowell K., 2022, AMOR CRINGE NOVELETT; Amado N, 2022, INT FORUM PSYCHOANAL, V31, P100, DOI 10.1080/0803706X.2021.1887518; Bergler E, 1950, AM IMAGO, V7, P43; Child Doreen Alexander., 2010, C KAUFMAN CONFESSION; Clark E, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P329, DOI 10.1145/3172944.3172983; Du Sautoy Marcus., 2019, The creativity code: Art and innovation in the age of AI; Dzieza Josh, 2022, VergeJuly 20; Evans S, 2015, NEW WRIT, V12, P311, DOI 10.1080/14790726.2015.1053493; Flaherty AliceWeaver., 2005, The Midnight Disease: The Drive to Write, Writer's Block, and the Creative Brain; Gaiman Neil, 2019, COMMUNICATION   0328; Gaiman Neil., 2008, THE GRAVEYARD BOOK; Handa Yuichi., 2021, WRITERS BLOCK INEVIT; Jonze Spike, 1999, BEING J MALKOVICH; Jonze Spike., 2002, ADAPTATION-UK; King Stephen, 2006, WASH POST; Mahler Andreas., 2011, METAREFERENTIAL TURN, P51; Mori M., 1970, IEEE SPECTRUM; Morrison Toni., 1985, BLACK WOMEN WRITERS, P183; Mukhtar Shakeeb A. M., 2021, ARXIV; Orlean S., 1998, THE ORCHID THIEF; Orlean Susan, 2012, GQ MAGAZINE     0416; Thomas A., 2021, ARXIV; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Vara Vauhini, 2023, COMMUNICATION   0126; Vara Vauhini, 2021, THE BELIEVER	29	0	0	16	34	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1479-0726	1943-3107		NEW WRIT	New Writ.	JAN 2	2024	21	1					26	37		10.1080/14790726.2023.2223176	http://dx.doi.org/10.1080/14790726.2023.2223176		JUN 2023	12	Literature	Emerging Sources Citation Index (ESCI)	Literature	HZ3Q1					2024-07-03	WOS:001011934900001
C	Pang, B; Yavuz, S; Xiong, CM; Zhou, YB		Augenstein, I; Vlachos, A		Pang, Bo; Yavuz, Semih; Xiong, Caiming; Zhou, Yingbo			SharPT: Shared Latent Space Prompt Tuning	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Prompt tuning is an efficient method for adapting large language models, and Soft Prompt Transfer (SPoT) further narrows the gap between prompt tuning and full model tuning by transferring prompts learned from source tasks to target tasks. It is nevertheless difficult and expensive to identify the source task that provides optimal prompts. In this work, we propose to learn a shared latent space which captures a set of basis skills from a mixture of source tasks. Given an instance, its embedding queries the latent space, yielding a basis skill vector. This vector generates soft prompts, via a lightweight prompt generator, which modulates a frozen model. The latent space and prompt transformation are learned end-to-end by training on source tasks. Transfer learning from source tasks to a target task simply amounts to finetuning the prompt generator, accounting for roughly 0.3% parameters of the frozen backbone model, while the shared latent space is also frozen in finetuning. Our approach outperforms prior soft prompt methods by a significant margin on a variety of tasks such as NLI, sentence completion, QA, conference resolution, word sense disambiguation. We also find, on various model scales, our method achieves competitive performance compared to finetuning the full model.	[Pang, Bo; Yavuz, Semih; Xiong, Caiming; Zhou, Yingbo] Salesforce Res, Seattle, WA 98103 USA		Pang, B (corresponding author), Salesforce Res, Seattle, WA 98103 USA.	b.pang@salesforce.com; syavuz@salesforce.com; cxiong@salesforce.com; yingbo.zhou@salesforce.com						Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177; de Marneffe Marie-Catherine, 2019, P SINN BEDEUTUNG; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Hambardzumyan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4921; Houlsby N, 2019, PR MACH LEARN RES, V97; Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2391; Iyer Shankar, 2017, First quora dataset release: Question pairs; Lai G., 2017, ARXIV170404683, P785, DOI [DOI 10.18653/V1/D17-1082, 10.18653/v1/D17-1082]; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Mahabadi RK, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P565; Parekh Z, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2855; Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Roemmele Melissa, 2011, P 25 AAAI SPRING S L; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Sanh Victor, 2022, INT C LEARNING REPRE; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Vu T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5039; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Yin WP, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4913; Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791; Zhang S, 2018, Arxiv, DOI arXiv:1810.12885	34	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-47-0				2023							1244	1250						7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SA					2024-07-03	WOS:001181085100090
C	Jagerman, R; Wang, XH; Zhuang, HL; Qin, Z; Bendersky, M; Najork, M			ACM	Jagerman, Rolf; Wang, Xuanhui; Zhuang, Honglei; Qin, Zhen; Bendersky, Michael; Najork, Marc			Rax: Composable Learning-to-Rank using JAX	PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022			English	Proceedings Paper	28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KKD)	AUG 14-18, 2022	Washington, DC	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD		Learning to Rank; JAX		Rax is a library for composable Learning-to-Rank (LTR) written entirely in JAX. The goal of Rax is to facilitate easy prototyping of LTR systems by leveraging the flexibility and simplicity of JAX. Rax provides a diverse set of popular ranking metrics and losses that integrate well with the rest of the JAX ecosystem. Furthermore, Rax implements a system of ranking-specific function transformations which allows fine-grained customization of ranking losses and metrics. Most notably Rax provides approx_t12n: a function transformation (t12n) that can transform any of our ranking metrics into an approximate and differentiable form that can be optimized. This provides a systematic way to directly optimize neural ranking models for ranking metrics that are not easily optimizable in other libraries. We empirically demonstrate the effectiveness of Rax by benchmarking neural models implemented using Flax and trained using Rax on two popular LTR benchmarks: WEB30K and Istella. Furthermore, we show that integrating ranking losses with T5, a large language model, can improve overall ranking performance on the MS MARCO passage ranking task. We are sharing the Rax library with the open source community as part of the larger JAX ecosystem at https://github.com/google/rax.	[Jagerman, Rolf; Wang, Xuanhui; Zhuang, Honglei; Qin, Zhen; Bendersky, Michael; Najork, Marc] Google Res, Seattle, WA 98105 USA	Google Incorporated	Jagerman, R (corresponding author), Google Res, Seattle, WA 98105 USA.	jagerman@google.com; xuanhui@google.com; hlz@google.com; zhenqin@google.com; bemike@google.com; najork@google.com		Najork, Marc/0000-0003-1423-0854				Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Agarwal A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P5, DOI 10.1145/3331184.3331202; [Anonymous], 2008, P 25 INT C MACH LEAR, DOI DOI 10.1039/B716681H; Babuschkin I., 2020, The DeepMind JAX Ecosystem; Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Bruch S, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P61, DOI 10.1145/3336191.3371844; Burges C., 2005, INT C MACH LEARN ICM, P89, DOI DOI 10.1145/1102351.1102363; Cao H, 2007, PROCEEDINGS OF THE 26TH CHINESE CONTROL CONFERENCE, VOL 4, P129; Capannini Gabriele, 2015, IIR; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Dato D, 2016, ACM T INFORM SYST, V35, DOI 10.1145/2987380; Dehghani Mostafa, 2021, ARXIV211011403; Diaz F, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P275, DOI 10.1145/3340531.3411962; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Fayad ME, 1997, COMMUN ACM, V40, P32, DOI 10.1145/262793.262798; Frostig R., 2018, SysML; Ganjisaffar Y, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P85; Godwin J., 2020, JRAPH LIB GRAPH NEUR; Grover A., 2019, ICLR; Han S., 2020, ARXIV200408476; Heek J., 2020, Flax: A neural network library and ecosystem for jax; Hennigan T., 2020, Haiku: Sonnet for JAX; Hessel M., 2020, JAX; Jagerman Rolf, 2020, P 43 INT ACM SIGIR C; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133; Kingma D. P., 2017, ARXIV; Kumar S, 2021, LIT AESTHET, V31, P81; MCILROY MD, 1978, AT&T TECH J, V57, P1899, DOI 10.1002/j.1538-7305.1978.tb02135.x; Nguyen Tri, 2016, COCO NIPS; Ni Jianmo, 2021, ARXIV211207890; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Pasumarthi RK, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2970, DOI 10.1145/3292500.3330677; Paszke A., 2019, Advances in neural information processing systems, V32, P8024, DOI DOI 10.48550/ARXIV.1912.01703; Pobrotyn P., 2021, ARXIV210207831; Qin T, 2010, INFORM RETRIEVAL, V13, P375, DOI 10.1007/s10791-009-9124-x; Qin Tao., 2013, CoRR abs/1306.2597; Qin Z., 2021, INT C LEARN REPR; Raffel C., 2019, arXiv preprint arXiv:1910.10683; Schoenholz S., 2020, Advances in Neural Information Processing Systems, V33, P11428; Sculley D., 2009, NIPS 2009 Work. Adv. Rank, P1; Selvaggio G, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15299-5; Subramani P, 2021, ADV NEUR IN, V34; Taylor Michael, 2008, P 2008 INT C WEB SEA, P77, DOI DOI 10.1145/1341531.1341544; Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016; Ustimenko A., 2020, INT C MACH LEARN, P9669; Wu Mingrui, 2009, P 18 ACM C INFORM KN, P1923; Yue Yisong, 2007, MSTTR2007115	48	2	2	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9385-0				2022							3051	3060		10.1145/3534678.3539065	http://dx.doi.org/10.1145/3534678.3539065			10	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2MH		Bronze			2024-07-03	WOS:001119000303010
J	Li, YQ; Starly, B				Li, Yunqing; Starly, Binil			Building a knowledge graph to enrich ChatGPT responses in manufacturing service discovery	JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION			English	Article						Digital supply chain; Knowledge graph; ChatGPT; Manufacturing service discovery		Sourcing and identification of new manufacturing partners is crucial for manufacturing system integrators to enhance agility and reduce risk through supply chain diversification in the global economy. The advent of advanced large language models has captured significant interest, due to their ability to generate comprehensive and articulate responses across a wide range of knowledge domains. However, the system often falls short in accuracy and completeness when responding to domain-specific inquiries, particularly in areas like manufacturing service discovery. This research explores the potential of leveraging Knowledge Graphs in conjunction with ChatGPT to streamline the process for prospective clients in identifying small manufacturing enterprises. In this study, we propose a method that integrates bottom-up ontology with advanced machine learning models to develop a Manufacturing Service Knowledge Graph from an array of structured and unstructured data sources, including the digital footprints of small-scale manufacturers throughout North America. The Knowledge Graph and the learned graph embedding vectors are leveraged to tackle intricate queries within the digital supply chain network, responding with enhanced reliability and greater interpretability. The approach highlighted is scalable to millions of entities that can be distributed to form a global Manufacturing Service Knowledge Network Graph that can potentially interconnect multiple types of Knowledge Graphs that span industry sectors, geopolitical boundaries, and business domains. The dataset developed for this study, now publicly accessible, encompasses more than 13,000 manufacturers' weblinks, manufacturing services, certifications, and location entity types.	[Li, Yunqing] North Carolina State Univ, Edward P Fitts Dept Ind & Syst Engn, Raleigh, NC USA; [Starly, Binil] Arizona State Univ, Sch Mfg Syst & Networks, Tempe, AZ 85281 USA	North Carolina State University; Arizona State University; Arizona State University-Tempe	Starly, B (corresponding author), Arizona State Univ, Sch Mfg Syst & Networks, Tempe, AZ 85281 USA.	bstarly@asu.edu		Starly, Binil/0000-0002-8527-1269	NSF [2032043D, 1937043]	NSF(National Science Foundation (NSF))	The authors would like to thank the anonymous reviewers for their invaluable comments that led to an improved article. We gratefully acknowledge support from NSF Grant# 1937043 and partial support from NSF Grant#2032043D.	Agarap A.F., 2018, arXiv, DOI DOI 10.48550/ARXIV.1803.08375; Aliyu F.M., 2021, Wolfram Alpha, V12, P5; Bengio Y., No Unbiased Estimator of the Variance of KFold Cross-Validation, V17; Boschin A., 2019, arXiv; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cai Min, 2020, J Shanghai Jiaotong Univ Sci, V25, P409, DOI 10.1007/s12204-020-2206-z; Chase Harrison, 2023, Langchain; Chen M., Directed Graph Embedding, V6; Le-Phuoc D, 2016, J WEB SEMANT, V37-38, P25, DOI 10.1016/j.websem.2016.02.003; Daull X, 2023, Arxiv, DOI arXiv:2302.09051; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gong F, 2021, BIG DATA RES, V23, DOI 10.1016/j.bdr.2020.100174; Grover A, 2016, Arxiv, DOI [arXiv:1607.00653, 10.48550/ARXIV.1607.00653]; Hamilton WL, 2017, ADV NEUR IN, V30; He LL, 2019, IEEE ACCESS, V7, P101231, DOI 10.1109/ACCESS.2019.2931361; Heuer H, 2016, Arxiv, DOI arXiv:1607.00534; Nguyen H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P549, DOI 10.1145/2939672.2939720; Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956; Karray M.H., The Industrial Ontologies Foundry (IOF) perspectives, V6; Kingma D. P., 2017, ARXIV; Kumar A, 2022, J INTELL MANUF, V33, P2393, DOI 10.1007/s10845-021-01807-x; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li LF, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101817; Li Y., 2023, 929723 Bytes, DOI [10.6084/M9.FIGSHARE.23649879.V4, DOI 10.6084/M9.FIGSHARE.23649879.V4]; Li Y., 2021, Manufacturing Processes; Manufacturing Systems; Nano/Micro/Meso Manufacturing, Quality and Reliability, V2, DOI [10.1115/MSEC2021-63766.V002T07A010, DOI 10.1115/MSEC2021-63766.V002T07A010]; Li Y., 2021, Journal contribution, DOI [10.6084/m9.figshare.16691944.v2, DOI 10.6084/M9.FIGSHARE.16691944.V2]; Liu J., 2022, Zenodo, DOI [10.5281/zenodo.1234, DOI 10.5281/ZENODO.1234]; Lu YQ, 2019, J INTELL MANUF, V30, P317, DOI 10.1007/s10845-016-1250-x; Marreiros AC, 2008, NEUROIMAGE, V42, P147, DOI 10.1016/j.neuroimage.2008.04.239; Mohamed SK, 2021, BRIEF BIOINFORM, V22, P1679, DOI 10.1093/bib/bbaa012; Mountantonakis M, 2023, Arxiv, DOI [arXiv:2304.05774, 10.48550/ARXIV.2304.05774, DOI 10.48550/ARXIV.2304.05774]; Mulyar A, 2020, Arxiv, DOI arXiv:2004.10220; Pahwa D, 2020, RAPID PROTOTYPING J, V26, P82, DOI 10.1108/RPJ-01-2019-0018; Pan JZ, 2023, Arxiv, DOI arXiv:2308.06374; Pujara J., 2013, 2013 AAAI FALL S SER; Shahapure KR, 2020, PR INT CONF DATA SC, P747, DOI 10.1109/DSAA49011.2020.00096; Shokrani A, 2020, MATER DESIGN, V192, DOI 10.1016/j.matdes.2020.108749; Siddharth L, 2022, J COMPUT INF SCI ENG, V22, DOI 10.1115/1.4052293; Syakur MA, 2018, IOP CONF SER-MAT SCI, V336, DOI 10.1088/1757-899X/336/1/012017; .thomasnet, Thomasnet-Product Sourcing and Supplier Discovery Platform-Find North American Manufacturers, Suppliers and Industrial Companies; Tian F., Learning Deep Representations for Graph Clustering, V7; Truong C., Knowledge Injection to Counter Large Language Model (LLM) Hallucination; Tsoumakas G., Multi-Label Classification: An Overview, V17; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang CB, 2018, COMPUT GEOSCI-UK, V112, P112, DOI 10.1016/j.cageo.2017.12.007; Wang Q, 2020, arXiv; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wang ZX, 2018, Arxiv, DOI arXiv:1807.00504; Xiao H, 2017, Arxiv, DOI [arXiv:1512.04792, DOI 10.48550/ARXIV.1512.04792]; Yan HH, 2020, IEEE ACCESS, V8, P41805, DOI 10.1109/ACCESS.2020.2977136; Yang LY, 2024, Arxiv, DOI arXiv:2306.11489; Yang S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186429; Yang Wu, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P408, DOI 10.1109/AVSS.2011.6027363; Yanhao Luo, 2021, Journal of Physics: Conference Series, V1865, DOI 10.1088/1742-6596/1865/4/042032; Zhang CX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P793, DOI 10.1145/3292500.3330961; Zhang DH, 2019, IEEE ACCESS, V7, P57678, DOI 10.1109/ACCESS.2019.2912627; Zhang ZL, 2018, ADV NEUR IN, V31; Zhao MX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132720; Zhou X., A QUESTION ANSWERING System for Chemistry, P29; Zhu S., Adversarial Directed Graph Embedding, P8	60	0	0	15	15	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2467-964X	2452-414X		J IND INF INTEGR	J. Ind. Inf. Integr.	JUL	2024	40								100612	10.1016/j.jii.2024.100612	http://dx.doi.org/10.1016/j.jii.2024.100612		APR 2024	15	Computer Science, Interdisciplinary Applications; Engineering, Industrial	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW8J3		Green Submitted			2024-07-03	WOS:001217207300001
J	Kulmanov, M; Guzmán-Vega, FJ; Roggli, PD; Lane, L; Arold, ST; Hoehndorf, R				Kulmanov, Maxat; Guzman-Vega, Francisco J.; Roggli, Paula Duek; Lane, Lydie; Arold, Stefan T.; Hoehndorf, Robert			Protein function prediction as approximate semantic entailment	NATURE MACHINE INTELLIGENCE			English	Article							LARGE-SCALE; ONTOLOGY; LANGUAGE; SEQUENCE; OWL	The Gene Ontology (GO) is a formal, axiomatic theory with over 100,000 axioms that describe the molecular functions, biological processes and cellular locations of proteins in three subontologies. Predicting the functions of proteins using the GO requires both learning and reasoning capabilities in order to maintain consistency and exploit the background knowledge in the GO. Many methods have been developed to automatically predict protein functions, but effectively exploiting all the axioms in the GO for knowledge-enhanced learning has remained a challenge. We have developed DeepGO-SE, a method that predicts GO functions from protein sequences using a pretrained large language model. DeepGO-SE generates multiple approximate models of GO, and a neural network predicts the truth values of statements about protein functions in these approximate models. We aggregate the truth values over multiple models so that DeepGO-SE approximates semantic entailment when predicting protein functions. We show, using several benchmarks, that the approach effectively exploits background knowledge in the GO and improves protein function prediction compared to state-of-the-art methods. Deep learning language models have proved useful for both natural language and protein modelling. Similar to semantics in natural language, protein functions are complex and depend on the context of their environment, rather than on the similarity of sequences. Kulmanov and colleagues present an approach to frame function prediction as semantic entailment using a neuro-symbolic model to augment a large protein language model.	[Kulmanov, Maxat; Hoehndorf, Robert] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div, Thuwal, Saudi Arabia; [Kulmanov, Maxat; Guzman-Vega, Francisco J.; Arold, Stefan T.; Hoehndorf, Robert] King Abdullah Univ Sci & Technol KAUST, Computat Biosci Res Ctr, Thuwal, Saudi Arabia; [Kulmanov, Maxat; Hoehndorf, Robert] King Abdullah Univ Sci & Technol, SDAIA KAUST Ctr Excellence Data Sci & Artificial I, Thuwal, Saudi Arabia; [Guzman-Vega, Francisco J.; Arold, Stefan T.] King Abdullah Univ Sci & Technol KAUST, Biosci Program, Biol & Environm Sci & Engn Div, Thuwal, Saudi Arabia; [Roggli, Paula Duek; Lane, Lydie] CMU, SIB Swiss Inst Bioinformat, CALIPHO Grp, Geneva, Switzerland; [Roggli, Paula Duek; Lane, Lydie] Univ Geneva, Fac Med, Dept Microbiol & Mol Med, CMU, Geneva, Switzerland	King Abdullah University of Science & Technology; King Abdullah University of Science & Technology; King Abdullah University of Science & Technology; King Abdullah University of Science & Technology; University of Geneva; Swiss Institute of Bioinformatics; University of Geneva	Kulmanov, M; Hoehndorf, R (corresponding author), King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div, Thuwal, Saudi Arabia.; Kulmanov, M; Hoehndorf, R (corresponding author), King Abdullah Univ Sci & Technol KAUST, Computat Biosci Res Ctr, Thuwal, Saudi Arabia.; Kulmanov, M; Hoehndorf, R (corresponding author), King Abdullah Univ Sci & Technol, SDAIA KAUST Ctr Excellence Data Sci & Artificial I, Thuwal, Saudi Arabia.	maxat.kulmanov@kaust.edu.sa; robert.hoehndorf@kaust.edu.sa	Hoehndorf, Robert/H-6127-2019; Arold, Stefan/T-2612-2019; Kulmanov, Maxat/AAG-5628-2021	Hoehndorf, Robert/0000-0001-8149-5890; Kulmanov, Maxat/0000-0003-1710-1820; Arold, Stefan T/0000-0001-5278-0668; Guzman-Vega, Francisco J./0000-0002-6116-9534	King Abdullah University of Science and Technology (KAUST) [REI/1/5235-01-01, URF/1/4675-01-01, URF/1/4697-01-01, URF/1/5041-01-01, FCC/1/1976-46-01]; King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research (OSR); SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence (SDAIA-KAUST AI); King Abdullah University of Science & Technology (KAUST) in Thuwal, Saudi Arabia	King Abdullah University of Science and Technology (KAUST)(King Abdullah University of Science & Technology); King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research (OSR); SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence (SDAIA-KAUST AI); King Abdullah University of Science & Technology (KAUST) in Thuwal, Saudi Arabia	This work has been supported by funding from the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research (OSR) under Award Nos. REI/1/5235-01-01, URF/1/4675-01-01, URF/1/4697-01-01, URF/1/5041-01-01 and FCC/1/1976-46-01. This work was supported by the SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence (SDAIA-KAUST AI). For computer time, this research used the resources of the Supercomputing Laboratory at the King Abdullah University of Science & Technology (KAUST) in Thuwal, Saudi Arabia.	[Anonymous], 2008, SPARQL QUERY LANGUAG; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Baader F, 2003, DESCRIPTION LOGIC HANDBOOK: THEORY, IMPLEMENTATION AND APPLICATIONS, P43; Bateman A, 2023, NUCLEIC ACIDS RES, V51, pD523, DOI 10.1093/nar/gkac1052; Buchfink B, 2015, NAT METHODS, V12, P59, DOI 10.1038/nmeth.3176; CADOLI M, 1991, LECT NOTES ARTIF INT, V549, P68; Cao Y, 2021, BIOINFORMATICS, V37, P2825, DOI 10.1093/bioinformatics/btab198; Carbon S, 2021, NUCLEIC ACIDS RES, V49, pD325, DOI 10.1093/nar/gkaa1113; Chowdhury T., 2023, PREPRINT; Clark WT, 2013, BIOINFORMATICS, V29, P53, DOI 10.1093/bioinformatics/btt228; Degtyarenko K, 2008, NUCLEIC ACIDS RES, V36, pD344, DOI 10.1093/nar/gkm791; Diehl AD, 2016, J BIOMED SEMANT, V7, DOI 10.1186/s13326-016-0088-7; Duek P, 2021, DATABASE-OXFORD, DOI 10.1093/database/baab046; Duek P, 2018, J PROTEOME RES, V17, P4211, DOI 10.1021/acs.jproteome.8b00537; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Gillespie M, 2022, NUCLEIC ACIDS RES, V50, pD687, DOI 10.1093/nar/gkab1028; Gligorijevic V, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23303-9; Grau BC, 2008, J WEB SEMANT, V6, P309, DOI 10.1016/j.websem.2008.05.001; Henkin L., 1959, PROC INT S AXIOMATIC, P1; Hoehndorf R, 2015, BRIEF BIOINFORM, V16, P1069, DOI 10.1093/bib/bbv011; Hoehndorf R, 2011, BIOINFORMATICS, V27, P1001, DOI 10.1093/bioinformatics/btr058; Jones P, 2014, BIOINFORMATICS, V30, P1236, DOI 10.1093/bioinformatics/btu031; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kahanda I, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P60, DOI 10.1145/3107411.3107417; Kanehisa M, 2017, NUCLEIC ACIDS RES, V45, pD353, DOI 10.1093/nar/gkw1092; Krissinel E, 2007, BIOINFORMATICS, V23, P717, DOI 10.1093/bioinformatics/btm006; Kuchta K, 2009, NUCLEIC ACIDS RES, V37, P7701, DOI 10.1093/nar/gkp854; Kulmanov M, 2022, BIOINFORMATICS, V38, P238, DOI 10.1093/bioinformatics/btac256; Kulmanov M, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6103; Kulmanov M, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa199; Kulmanov M, 2020, BIOINFORMATICS, V36, P422, DOI 10.1093/bioinformatics/btz595; Kulmanov M, 2018, BIOINFORMATICS, V34, P660, DOI 10.1093/bioinformatics/btx624; Lai BQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab502; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Makrodimitris S, 2020, BIOINFORMATICS, V36, P1182, DOI 10.1093/bioinformatics/btz731; Motik B., 2012, OWL 2 Web Ontology Language Profiles; Mungall CJ, 2012, GENOME BIOL, V13, DOI 10.1186/gb-2012-13-1-r5; Nadendla S, 2022, NUCLEIC ACIDS RES, V50, pD1515, DOI 10.1093/nar/gkab1025; Nevers Y, 2017, MOL BIOL EVOL, V34, P2016, DOI 10.1093/molbev/msx146; Ogami T, 2022, J BIOCHEM, V171, P399, DOI 10.1093/jb/mvab141; Pan T, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad094; Pellegrini M, 2012, METHODS MOL BIOL, V804, P167, DOI 10.1007/978-1-61779-361-5_9; Radivojac P, 2013, NAT METHODS, V10, P221, DOI [10.1038/NMETH.2340, 10.1038/nmeth.2340]; Rifaioglu AS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43708-3; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Schoch Conrad L, 2020, Database (Oxford), V2020, DOI 10.1093/database/baaa062; Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, pD607, DOI 10.1093/nar/gky1131; Tang Z., 2023, FALCON FAITHFUL NEUR; van Kempen M, 2024, NAT BIOTECHNOL, V42, DOI 10.1038/s41587-023-01773-0; Velickovic P., 2017, stat, V1050, P10; Wang M., 2019, PREPRINT; Wekesa JS, 2021, J COMPUT BIOL, V28, P1, DOI 10.1089/cmb.2019.0120; Wu ZR, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad123; Yao SW, 2021, NUCLEIC ACIDS RES, V49, pW469, DOI 10.1093/nar/gkab398; You RH, 2021, BIOINFORMATICS, V37, pI262, DOI 10.1093/bioinformatics/btab270; You RH, 2019, NUCLEIC ACIDS RES, V47, pW379, DOI 10.1093/nar/gkz388; You RH, 2018, METHODS, V145, P82, DOI 10.1016/j.ymeth.2018.05.026; You RH, 2018, BIOINFORMATICS, V34, P2465, DOI 10.1093/bioinformatics/bty130; Yuan QM, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad117; Zahn-Zabal M, 2020, NUCLEIC ACIDS RES, V48, pD328, DOI 10.1093/nar/gkz995; Zhou NH, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-019-1835-8	61	0	0	19	19	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	FEB	2024	6	2					220	228		10.1038/s42256-024-00795-w	http://dx.doi.org/10.1038/s42256-024-00795-w		FEB 2024	9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IY2B5		Green Submitted, hybrid			2024-07-03	WOS:001161996400001
J	Jin, JH; Song, YF; Kan, D; Zhang, BJ; Lyu, Y; Zhang, JH; Lu, HR				Jin, Jiahui; Song, Yifan; Kan, Dong; Zhang, Binjie; Lyu, Yan; Zhang, Jinghui; Lu, Hongru			Learning context-aware region similarity with effective spatial normalization over Point-of-Interest data	INFORMATION PROCESSING & MANAGEMENT			English	Article						Urban region similarity learning; Spatial normalization; Spatial imbalance; Point-of-Interest		With the increasing availability of Point -of -Interest (PoI) data driven by the widespread adoption of location -based services, there is a growing demand to comprehend the similarities among different regions. Existing works generally regard regions with the similar number or distribution of PoI as similar. However, in practice, the region similarity depends on the surrounding environment as well, owing to the inherent imbalance observed in urban PoI data. In addition, the existing literature does not consider different task contexts when applying regional similarity. This paper primarily investigates how to appropriately represent the distribution of PoIs to measure the similarity between regions for diverse spatial and application contexts. A Context -Aware REgion similarity learning framework (CARE) is proposed, which utilizes a novel spatial normalization technique to capture the unique role of each region within its neighborhoods in order to address the inherent imbalance issue in urban data and a self -supervised contrastive learning method with triplet loss to tackle problem of missing labeled data in datasets. Considering the variations in how different applications define region similarity, CARE prompts large language model to adjust learned region embeddings and adapt them for specific application requirements. We conduct experiments on three datasets and two downstream tasks. Results show that compared with the baseline models, our model improves the performance of site selection recommendation and crime prediction by up to 19.60% and 35.86%, respectively.	[Jin, Jiahui; Song, Yifan; Kan, Dong; Zhang, Binjie; Lyu, Yan; Zhang, Jinghui] Southeast Univ, Sch Comp Sci & Engn, Nanjing 211189, Peoples R China; [Lu, Hongru] Nanjing Audit Univ, Sch Comp Sci, Nanjing 211815, Peoples R China; [Jin, Jiahui] Southeast Univ, Room 368,Comp Bldg, Nanjing 211189, Jiangsu, Peoples R China	Southeast University - China; Nanjing Audit University; Southeast University - China	Jin, JH (corresponding author), Southeast Univ, Room 368,Comp Bldg, Nanjing 211189, Jiangsu, Peoples R China.	jjin@seu.edu.cn; yifansong2000@seu.edu.cn; dongkan@seu.edu.cn	Song, Yi-Fan/AFD-4822-2022	Song, Yi-Fan/0000-0002-5882-6126	National Natural Science Foundation of China [62072099, 62232004, 62102082]; Ministry of Education of the People's Republic of China Humanities and Social Sciences Youth Foundation [23YJC870003]; Natural Science Research of Jiangsu Higher Education Institutions of China [23KJB120005]; Jiangsu Provincial Key Laboratory of Network and Information Security, China [BM2003201]; Natural Science Foundation of Jiangsu Province of China [BK20210203]; Key Laboratory of Computer Network and Information Integration of Ministry of Education of China [93K-9]; The "Zhishan" Scholars Programs of Southeast University; Fundamental Research Funds, China for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Ministry of Education of the People's Republic of China Humanities and Social Sciences Youth Foundation; Natural Science Research of Jiangsu Higher Education Institutions of China; Jiangsu Provincial Key Laboratory of Network and Information Security, China; Natural Science Foundation of Jiangsu Province of China(Natural Science Foundation of Jiangsu Province); Key Laboratory of Computer Network and Information Integration of Ministry of Education of China; The "Zhishan" Scholars Programs of Southeast University; Fundamental Research Funds, China for the Central Universities	We would like to thank Jun Tang and Haoxiang Zhang for their early contributions to the code in the initial stages of this research paper. This work is supported by National Natural Science Foundation of China under Grants No. 62072099, No. 62232004, and No. 62102082, Ministry of Education of the People's Republic of China Humanities and Social Sciences Youth Foundation under Grant No. 23YJC870003, Natural Science Research of Jiangsu Higher Education Institutions of China under Grant No. 23KJB120005, Jiangsu Provincial Key Laboratory of Network and Information Security, China under Grants No. BM2003201, Natural Science Foundation of Jiangsu Province of China under Grant No. BK20210203, Key Laboratory of Computer Network and Information Integration of Ministry of Education of China under Grants No. 93K-9, the "Zhishan" Scholars Programs of Southeast University, and the Fundamental Research Funds, China for the Central Universities.	Ahmed P, 2023, VLDB J, V32, P501, DOI 10.1007/s00778-022-00759-9; Akhtar N, 2020, NEURAL COMPUT APPL, V32, P879, DOI 10.1007/s00521-019-04296-5; Al Shalabi L, 2006, DEPCOS-RELCOMEX 2006, P207; [Anonymous], 2022, wikipedia; Canturk D, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119048; Cao G, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103335; Chan WL, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P3763, DOI 10.1145/3583780.3615194; Chen JY, 2021, J WEB SEMANT, V67, DOI 10.1016/j.websem.2020.100625; Chen T, 2020, PR MACH LEARN RES, V119; Dianping, 2022, Dianping dataset; Ding J., 2019, The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, P1010; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; EUMeTrain, 2022, EUMeTrain doc; Fadlullah ZM, 2017, IEEE COMMUN SURV TUT, V19, P2432, DOI 10.1109/COMST.2017.2707140; Fan JS, 2022, AAAI CONF ARTIF INTE, P11873; Feng KY, 2019, PROC VLDB ENDOW, V12, P1414, DOI 10.14778/3342263.3342277; Fu YJ, 2019, AAAI CONF ARTIF INTE, P906; Gan MX, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103169; Gao JL, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103369; Gao Q, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108791; Guo B., 2018, The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, P1010; Han JD, 2023, IEEE T KNOWL DATA EN, V35, P5230, DOI 10.1109/TKDE.2022.3149815; Houssou NLJ, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P652, DOI 10.1145/3297280.3297341; Huang C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1423, DOI 10.1145/3269206.3271793; Hui B, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P555, DOI 10.1145/3340531.3411882; Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002; Jang DH, 2022, PROC CVPR IEEE, P539, DOI 10.1109/CVPR52688.2022.00063; Jin X, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P669, DOI 10.1145/3357384.3358008; Kim N, 2022, Arxiv, DOI arXiv:2202.09021; LAPD, 2022, Crime data from 2010 to 2019; Le-Khac PH, 2020, IEEE ACCESS, V8, P193907, DOI 10.1109/ACCESS.2020.3031549; Li JM, 2019, IEEE ACCESS, V7, P25452, DOI 10.1109/ACCESS.2019.2893411; Li Y, 2022, LAND-BASEL, V11, DOI 10.3390/land11070996; Li Y, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P1363, DOI 10.1145/3580305.3599538; Li Z, 2022, INT CONF ADV CLOUD B, P246, DOI 10.1109/CBD58033.2022.00051; Li ZH, 2022, PROC INT CONF DATA, P2984, DOI 10.1109/ICDE53745.2022.00269; Liang WC, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3501807; Liu LB, 2019, IEEE T INTELL TRANSP, V20, P3875, DOI 10.1109/TITS.2019.2915525; Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866; Liu Yu, 2023, WWW '23: Proceedings of the ACM Web Conference 2023, P4150, DOI 10.1145/3543507.3583876; Liu YD, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1850, DOI 10.1145/3219819.3220031; Liu Y, 2023, ACM T INTEL SYST TEC, V14, DOI 10.1145/3588577; Liu YW, 2022, INT J INTELL SYST, V37, P4020, DOI 10.1002/int.22710; Luo WJ, 2016, ADV NEUR IN, V29; Luo ZH, 2022, PROC VLDB ENDOW, V15, P3199, DOI 10.14778/3551793.3551863; Ni J, 2021, INFORM SCIENCES, V542, P324, DOI 10.1016/j.ins.2020.07.038; NYPD, 2013, NYPD arrests data; Potluri A, 2023, ARAB J SCI ENG, V48, P2121, DOI 10.1007/s13369-022-07084-x; Safavi S, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6981; Saxena S, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103021; Seyedhoseinzadeh K, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102858; Shaik T, 2024, Arxiv, DOI arXiv:2309.10186; ShangbinWu Xu Yan, 2022, IJCAI, P2312; Sheng C, 2010, LECT NOTES COMPUT SC, V5981, P186, DOI 10.1007/978-3-642-12026-8_16; Sun XG, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103278; Tang Jun, 2022, GeoAI '22: Proceedings of the 5th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery, P92, DOI 10.1145/3557918.3565873; Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141; Wang HJ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P237, DOI 10.1145/3132847.3133006; Wu JH, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103030; Xi YX, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3308, DOI 10.1145/3485447.3512149; Xia Lianghao, 2021, IJCAI INT JOINT C AR, P1631, DOI DOI 10.24963/IJCAI; Yao HX, 2018, AAAI CONF ARTIF INTE, P2588; Yelp, 2013, Yelp dataset; Yi XW, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P965, DOI 10.1145/3219819.3219822; Zafar A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178643; Zeng Z., 2023, Natural Language Processing Journal, V5; Zhang C, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P361, DOI 10.1145/3038912.3052601; Zhang L, 2023, IEEE T KNOWL DATA EN, V35, P9031, DOI 10.1109/TKDE.2022.3220874; Zhang MY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4431; Zhao XY, 2022, AAAI CONF ARTIF INTE, P4388; Zhao YX, 2023, IEEE T KNOWL DATA EN, V35, P10237, DOI 10.1109/TKDE.2023.3253802; Zhou JY, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491206; Zhou S., 2023, P AAAI C ART INT, V37, P4981; Zu SS, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191799	75	0	0	12	12	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-4573	1873-5371		INFORM PROCESS MANAG	Inf. Process. Manage.	MAY	2024	61	3							103673	10.1016/j.ipm.2024.103673	http://dx.doi.org/10.1016/j.ipm.2024.103673		FEB 2024	20	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	KS2K6					2024-07-03	WOS:001181887900001
J	Crowther, GJ; Sankar, U; Knight, LS; Myers, DL; Patton, KT; Jenkins, LD; Knight, TA				Crowther, Gregory J.; Sankar, Usha; Knight, Leena S.; Myers, Deborah L.; Patton, Kevin T.; Jenkins, Lekelia D.; Knight, Thomas A.			Chatbot responses suggest that hypothetical biology questions are harder than realistic ones	JOURNAL OF MICROBIOLOGY & BIOLOGY EDUCATION			English	Article						artificial intelligence (AI); Google Bard; Bloom's taxonomy; cheating; exams; HOCS/LOCS; summative assessment; YouChat	BLOOMS TAXONOMY; CORE CONCEPTS; PHYSIOLOGY; TOOL	The biology education literature includes compelling assertions that unfamiliar problems are especially useful for revealing students' true understanding of biology. However, there is only limited evidence that such novel problems have different cognitive requirements than more familiar problems. Here, we sought additional evidence by using chatbots based on large language models as models of biology students. For human physiology and cell biology, we developed sets of realistic and hypothetical problems matched to the same lesson learning objectives (LLOs). Problems were considered hypothetical if (i) known biological entities (molecules and organs) were given atypical or counterfactual properties (redefinition) or (ii) fictitious biological entities were introduced (invention). Several chatbots scored significantly worse on hypothetical problems than on realistic problems, with scores declining by an average of 13%. Among hypothetical questions, redefinition questions appeared especially difficult, with many chatbots scoring as if guessing randomly. These results suggest that, for a given LLO, hypothetical problems may have different cognitive demands than realistic problems and may more accurately reveal students' ability to apply biology core concepts to diverse contexts. The Test Question Templates (TQT) framework, which explicitly connects LLOs with examples of assessment questions, can help educators generate problems that are challenging (due to their novelty), yet fair (due to their alignment with pre-specified LLOs). Finally, ChatGPT's rapid improvement toward expert-level answers suggests that future educators cannot reasonably expect to ignore or outwit chatbots but must do what we can to make assessments fair and equitable.	[Crowther, Gregory J.; Myers, Deborah L.] Everett Community Coll, Life Sci Dept, Everett, WA 98201 USA; [Sankar, Usha] Fordham Univ, Dept Biol Sci, Bronx, NY USA; [Knight, Leena S.; Knight, Thomas A.] Whitman Coll, Biol Dept, Walla Walla, WA USA; [Patton, Kevin T.] St Charles Community Coll, Biol Dept, Cottleville, MO USA; [Jenkins, Lekelia D.] Arizona State Univ, Sch Future Innovat Soc, Tempe, AZ USA	Fordham University; Whitman College; Arizona State University; Arizona State University-Tempe	Crowther, GJ (corresponding author), Everett Community Coll, Life Sci Dept, Everett, WA 98201 USA.	gcrowther@everettcc.edu	; Crowther, Gregory/KMA-0252-2024	Sankar, Usha/0009-0005-9516-6939; Crowther, Gregory/0000-0003-0530-9130; Patton, Kevin/0000-0003-3219-667X; Jenkins, Lekelia/0000-0002-2375-2032	We thank Benjamin Wiggins (Shoreline Community College) for his encouragement and advice on publishing this project. We thank Susan Wick (University of Minnesota, emerita) for spearheading the NSF-funded Promoting Active Learning and Mentoring (PALM) progr; NSF-funded Promoting Active Learning and Mentoring (PALM) program; American Physiological Society; Everett Community College; Whitman College	We thank Benjamin Wiggins (Shoreline Community College) for his encouragement and advice on publishing this project. We thank Susan Wick (University of Minnesota, emerita) for spearheading the NSF-funded Promoting Active Learning and Mentoring (PALM) progr; NSF-funded Promoting Active Learning and Mentoring (PALM) program; American Physiological Society; Everett Community College; Whitman College	We thank Benjamin Wiggins (Shoreline Community College) for his encouragement and advice on publishing this project. We thank Susan Wick (University of Minnesota, emerita) for spearheading the NSF-funded Promoting Active Learning and Mentoring (PALM) program to support collaboration between G.J.C. and U.S. Finally, G.J.C. thanks the American Physiological Society for its Teaching Career Enhancement Award to cover publication costs and Everett Community College (G.J.C.) and Whitman College (L.S.K. and T.A.K.) for supporting sabbaticals during which the bulk of this project was conducted.	Alfieri L, 2013, EDUC PSYCHOL-US, V48, P87, DOI 10.1080/00461520.2013.775712; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Ambrose S. A., 2010, How learning works: Seven research-based principles for smart teaching; Arneson JB, 2018, CBE-LIFE SCI EDUC, V17, DOI 10.1187/cbe.17-08-0178; Berezow A., 2022, BIGTHINK; Bommineni VL., 2023, MED EDUC, DOI [10.1101/2023.03.05.23286533, DOI 10.1101/2023.03.05.23286533]; Chirillo M, 2021, ADV PHYSIOL EDUC, V45, P812, DOI 10.1152/advan.00106.2021; Clemmons AW, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-11-0259; Couch BA, 2019, CBE-LIFE SCI EDUC, V18, DOI 10.1187/cbe.18-07-0117; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; Crowe A, 2008, CBE-LIFE SCI EDUC, V7, P368, DOI 10.1187/cbe.08-05-0024; Crowther G., 2020, HAPS Ed, V24, P592, DOI DOI 10.21692/HAPS.2020.006; Crowther GJ, 2023, ADV PHYSIOL EDUC, V47, P202, DOI 10.1152/advan.00024.2022; Deane-Coe KK, 2017, CBE-LIFE SCI EDUC, V16, DOI 10.1187/cbe.16-06-0195; Devetak I., 2010, Eurasia Journal of Mathematics, Science Technology Education, V6, P77, DOI [10.12973/ejmste/75229, DOI 10.12973/EJMSTE/75229]; Doherty JH, 2023, CBE-LIFE SCI EDUC, V22, DOI 10.1187/cbe.20-01-0003; Evans DP, 2023, J MICROBIOL BIOL EDU, V24, DOI 10.1128/jmbe.00200-22; Gentner D, 2009, COGNITIVE SCI, V33, P1343, DOI 10.1111/j.1551-6709.2009.01070.x; Han Z., 2023, MEDRXIV, DOI [10.1101/2023.02.13.23285879, DOI 10.1101/2023.02.13.23285879]; Handelsman J, 2004, SCIENCE, V304, P521, DOI 10.1126/science.1096022; Hsu JL, 2021, J MICROBIOL BIOL EDU, V22, DOI 10.1128/jmbe.v22i1.2291; Huang Y., 2023, Benchmarking ChatGPT-4 on ACR radiation oncology in-training (TXIT) exam and red journal gray zone cases: Potentials and challenges for AI-assisted medical education and decision making in radiation oncology, DOI [10.2139/ssrn.4457218, DOI 10.2139/SSRN.4457218]; Kaminske AN, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-11-0227; Kosinski M., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.02083; Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2; McFarland JL, 2017, CBE-LIFE SCI EDUC, V16, DOI 10.1187/cbe.16-10-0305; Michael J, 2022, ADV PHYSIOL EDUC, V46, P438, DOI 10.1152/advan.00005.2022; Momsen JL, 2010, CBE-LIFE SCI EDUC, V9, P435, DOI 10.1187/cbe.10-01-0001; Monrad SU, 2021, MED TEACH, V43, P575, DOI 10.1080/0142159X.2021.1879376; Murugesan S, 2023, COMPUTER, V56, P116, DOI 10.1109/MC.2023.3253292; Schembri N., 2023, IS CHATGPT AID CHEAT; Semsar K, 2019, ADV PHYSIOL EDUC, V43, P15, DOI 10.1152/advan.00128.2018; Semsar K, 2017, ADV PHYSIOL EDUC, V41, P170, DOI 10.1152/advan.00101.2016; Silverthorn DU, 2022, ADV PHYSIOL EDUC, V46, P714, DOI 10.1152/advan.00046.2022; Stanfield E, 2022, CBE-LIFE SCI EDUC, V21, DOI 10.1187/cbe.20-12-0300; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Thompson AR, 2015, ANAT SCI EDUC, V8, P493, DOI 10.1002/ase.1507; Zaidi NB, 2017, ANAT SCI EDUC, V10, P456, DOI 10.1002/ase.1685	38	0	0	4	9	AMER SOC MICROBIOLOGY	WASHINGTON	1752 N ST NW, WASHINGTON, DC 20036-2904 USA	1935-7877	1935-7885		J MICROBIOL BIOL EDU	J. Microbiol. Biol. Educ.	DEC 14	2023	24	3								10.1128/jmbe.00153-23	http://dx.doi.org/10.1128/jmbe.00153-23		NOV 2023	14	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	CT0I0	38107990	Green Published, gold			2024-07-03	WOS:001095972600001
J	Gupta, R; Park, JB; Bisht, C; Herzog, I; Weisberger, J; Chao, J; Chaiyasate, K; Lee, ES				Gupta, Rohun; Park, John B.; Bisht, Chirag; Herzog, Isabel; Weisberger, Joseph; Chao, John; Chaiyasate, Kongkrit; Lee, Edward S.			Expanding Cosmetic Plastic Surgery Research With ChatGPT	AESTHETIC SURGERY JOURNAL			English	Article								Background: In the past 3 months, OpenAI, a San Francisco-based artificial intelligence (AI) research laboratory, has released ChatGPT, a conversation large language model. ChatGPT has the ability to answer user questions, admit to mistakes, and learn from users that are accessing the program. Objectives: Due to the importance of producing evidence-based research in plastic surgery, the authors of this study wanted to determine how accurate ChatGPT could be in creating novel systematic review ideas that encompass the diverse practice of cosmetic surgery. Methods: ChatGPT was given commands to produce 20 novel systematic review ideas for 12 different topics within cosmetic surgery. For each topic, the system was told to give 10 general and 10 specific ideas that were related to the concept. To determine the accuracy of ChatGPT, a literature review was conducted with PubMed, CINAHL, EMBASE, and Cochrane. Results: A total of 240 "novel" systematic review ideas were constructed by ChatGPT. We determined that the system had an overall accuracy of 55%. When topics were stratified by general and specific ideas, we found that ChatGPT was 35% accurate for general ideas and 75% accurate for specific ideas. Conclusions: ChatGPT is an excellent tool that should be utilized by plastic surgeons. ChatGPT is versatile and has uses beyond research, including patient consultation, patient support, and marketing. As advancements in AI continue to be made, it is important for plastic surgeons to consider the utilization of AI in their clinical practice.	[Gupta, Rohun] St Louis Univ, Div Plast & Reconstruct Surg, St Louis, MO USA; [Chaiyasate, Kongkrit] Oakland Univ, William Beaumont Sch Med, Rochester, MI USA; [Park, John B.; Herzog, Isabel; Weisberger, Joseph; Chao, John; Lee, Edward S.] Rutgers New Jersey Sch Med, Dept Plast Surg, Newark, NJ USA; [Bisht, Chirag] Calif Northstate Univ, Coll Med, Elk Grove, CA USA	Saint Louis University; Oakland University	Gupta, R (corresponding author), SLUCare Acad Pavil,1008 S Spring Ave,Suite 1500, St Louis, MO 63110 USA.	rohunguptamd@gmail.com	Gupta, Rohun/HQY-7933-2023	Herzog, Isabel/0000-0001-7491-5746				[Anonymous], 2022, Aesthet Surg J, V42, P1, DOI 10.1093/asj/sjac116; [Anonymous], 2021, THE OPEN; [Anonymous], 2021, 360 DIGITMG; [Anonymous], 2019, THE OPEN; [Anonymous], 2023, Search Engine Journal; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Herzog I, 2023, ANN PLAS SURG, V90, pS630, DOI 10.1097/SAP.0000000000003499; MCDONALD HD, 1982, WESTERN J MED, V136, P23; Michelmann S, 2023, Arxiv, DOI arXiv:2301.10297; openai, CHATGPT OPT LANG MOD; Roose Kevin, 2022, NEW YORK TIMES; Schulman J, 2022, Introducing chatgpt	15	41	42	17	97	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1090-820X	1527-330X		AESTHET SURG J	Aesthet. Surg. J.	JUL 15	2023	43	8					930	937	sjad069	10.1093/asj/sjad069	http://dx.doi.org/10.1093/asj/sjad069			8	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	L6MT9	36943815				2024-07-03	WOS:001024391400032
J	Petit-Jean, T; Gérardin, C; Berthelot, E; Chatellier, G; Frank, M; Tannier, X; Kempf, E; Bey, R				Petit-Jean, Thomas; Gerardin, Christel; Berthelot, Emmanuelle; Chatellier, Gilles; Frank, Marie; Tannier, Xavier; Kempf, Emmanuelle; Bey, Romain			Collaborative and privacy-enhancing workflows on a clinical data warehouse: an example developing natural language processing pipelines to detect medical conditions	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						natural language processing; domain adaptation; Charlson score index; comorbidities; privacy	COMORBIDITY INDEX; INFORMATION; RECORDS	Objective To develop and validate a natural language processing (NLP) pipeline that detects 18 conditions in French clinical notes, including 16 comorbidities of the Charlson index, while exploring a collaborative and privacy-enhancing workflow.Materials and Methods The detection pipeline relied both on rule-based and machine learning algorithms, respectively, for named entity recognition and entity qualification, respectively. We used a large language model pre-trained on millions of clinical notes along with annotated clinical notes in the context of 3 cohort studies related to oncology, cardiology, and rheumatology. The overall workflow was conceived to foster collaboration between studies while respecting the privacy constraints of the data warehouse. We estimated the added values of the advanced technologies and of the collaborative setting.Results The pipeline reached macro-averaged F1-score positive predictive value, sensitivity, and specificity of 95.7 (95%CI 94.5-96.3), 95.4 (95%CI 94.0-96.3), 96.0 (95%CI 94.0-96.7), and 99.2 (95%CI 99.0-99.4), respectively. F1-scores were superior to those observed using alternative technologies or non-collaborative settings. The models were shared through a secured registry.Conclusions We demonstrated that a community of investigators working on a common clinical data warehouse could efficiently and securely collaborate to develop, validate and use sensitive artificial intelligence models. In particular, we provided an efficient and robust NLP pipeline that detects conditions mentioned in clinical notes.	[Petit-Jean, Thomas; Gerardin, Christel; Chatellier, Gilles; Bey, Romain] Assistance Publ Hop Paris, Innovat & Data Unit, IT Dept, F-75012 Paris, France; [Gerardin, Christel] Sorbonne Univ, Inst Pierre Louis Epidemiol & Sante Publ, INSERM, F-75012 Paris, France; [Berthelot, Emmanuelle] Hop Bicetre, Assistance Publ Hop Paris, Dept Cardiol, F-94270 Le Kremlin Bicetre, France; [Chatellier, Gilles] Univ Paris, Assistance Publ Hop Paris Ctr Univ Paris APHP CUP, Dept Med Informat, F-75015 Paris, France; [Frank, Marie] Hop Univ Paris Saclay, Assistance Publ Hop Paris, Dept Med Informat, F-94270 Le Kremlin Bicetre, France; [Tannier, Xavier; Kempf, Emmanuelle] Sorbonne Univ, Univ Sorbonne Paris Nord, Lab Informat Med & Ingn Connaissances E Sante LIMI, INSERM, F-75005 Paris, France; [Kempf, Emmanuelle] Henri Mondor & Albert Chenevier Teaching Hosp, Assistance Publ Hop Paris, Dept Med Oncol, F-94000 Creteil, France; [Petit-Jean, Thomas] Assistance Publ Hop Paris, Innovat & Data Unit, 33 Blvd Picpus, F-75012 Paris, France	Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Sorbonne Universite; Institut National de la Sante et de la Recherche Medicale (Inserm); Universite Paris Saclay; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP; Hopital Universitaire Antoine-Beclere - APHP; Hopital Universitaire Bicetre - APHP; Universite Paris Cite; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Antoine-Beclere - APHP; Hopital Universitaire Bicetre - APHP; Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP; Sorbonne Universite; Institut National de la Sante et de la Recherche Medicale (Inserm); Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Hopital Universitaire Henri-Mondor - APHP; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP	Petit-Jean, T (corresponding author), Assistance Publ Hop Paris, Innovat & Data Unit, 33 Blvd Picpus, F-75012 Paris, France.	thomas.petitjean@aphp.fr		Chatellier, Gilles/0000-0002-6373-8956; Bey, Romain/0000-0002-6413-5188; Tannier, Xavier/0000-0002-2452-8868; PETIT-JEAN, Thomas/0000-0002-4433-442X; Berthelot, Emmanuelle/0000-0002-0418-3110	AP-HP Foundation	AP-HP Foundation	This study received funding from the AP-HP Foundation	[Anonymous], 2005, VLDB; Benchimol EI, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001885; Berman AN, 2021, CLIN CARDIOL, V44, P1296, DOI 10.1002/clc.23687; Bey R, 2020, J AM MED INFORM ASSN, V27, P1244, DOI 10.1093/jamia/ocaa096; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; CHARLSON ME, 1987, J CHRON DIS, V40, P373, DOI 10.1016/0021-9681(87)90171-8; Chuang JH, 2002, AMIA 2002 SYMPOSIUM, PROCEEDINGS, P160; Dalloux C., 2019, RECENT ADV NATURAL L, P1; De Montjoye Y A, 2017, Field Actions Sci Rep, V17, P80; de Montjoye YA, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.286; DEYO RA, 1992, J CLIN EPIDEMIOL, V45, P613, DOI 10.1016/0895-4356(92)90133-8; dos Santos HDP, 2018, COMP MED SY, P6, DOI 10.1109/CBMS.2018.00009; Dura B., 2022, ARXIV; Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042; Ford E, 2016, J AM MED INFORM ASSN, V23, P1007, DOI 10.1093/jamia/ocv180; Fort Karen., 2010, 4 ACL LING ANN WORKS, P56; Gorinski PJ., 2019, ARXIV; Jouffroy J, 2021, JMIR MED INF, V9, DOI 10.2196/17934; Knowles R, 2021, NAT COMPUT SCI, V1, P169, DOI 10.1038/s43588-021-00048-5; Kraljevic Z, 2021, ARTIF INTELL MED, V117, DOI 10.1016/j.artmed.2021.102083; Labrak Y., 2023, BIORXIV, DOI [10.1101/2023.04.03.535368, DOI 10.1101/2023.04.03.535368]; Lampros A, 2020, REV MED INTERNE, V41, P360, DOI 10.1016/j.revmed.2019.12.016; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee S, 2021, JMIR MED INF, V9, DOI 10.2196/23934; Lehman E., 2023, C HLTH INF LEARN, P578; Manuel DG, 2010, BMJ-BRIT MED J, V341, DOI 10.1136/bmj.c4226; Martin L, 2019, arXiv; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Murphy SN, 2010, J AM MED INFORM ASSN, V17, P124, DOI 10.1136/jamia.2009.000893; National Science and Technology Council, NAT STRAT ADV PRIV P; Névéol A, 2018, J BIOMED SEMANT, V9, DOI 10.1186/s13326-018-0179-8; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Rocher L, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10933-3; Salmasian H, 2013, J AM MED INFORM ASSN, V20, pE239, DOI 10.1136/amiajnl-2013-001889; Sheikhalishahi S, 2019, JMIR MED INF, V7, P15, DOI 10.2196/12239; Shek A, 2021, EUR J NEUROL, V28, P4090, DOI 10.1111/ene.15071; Singh B, 2012, MAYO CLIN PROC, V87, P817, DOI 10.1016/j.mayocp.2012.04.015; Sundararajan V, 2004, J CLIN EPIDEMIOL, V57, P1288, DOI 10.1016/j.jclinepi.2004.03.012; Tannier X, 2024, METHOD INFORM MED, DOI 10.1055/s-0044-1778693; The European Parliament and the Council of the European Union, REG EU 2016 679; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Turchin A, 2021, J DIABETES SCI TECHN, V15, P553, DOI 10.1177/19322968211000831; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Zheng L., 2016, JMIR medical informatics, V4, pe6328	45	0	0	2	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1280	1290		10.1093/jamia/ocae069	http://dx.doi.org/10.1093/jamia/ocae069		APR 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38573195	hybrid			2024-07-03	WOS:001196498900001
J	Weber-Wulff, D; Anohina-Naumeca, A; Bjelobaba, S; Foltynek, T; Guerrero-Dib, J; Popoola, O; Sigut, P; Waddington, L				Weber-Wulff, Debora; Anohina-Naumeca, Alla; Bjelobaba, Sonja; Foltynek, Tomas; Guerrero-Dib, Jean; Popoola, Olumide; Sigut, Petr; Waddington, Lorna			Testing of detection tools for AI-generated text	INTERNATIONAL JOURNAL FOR EDUCATIONAL INTEGRITY			English	Article						Artificial intelligence; Generative pre-trained transformers; Machine-generated text; Detection of AI-generated text; Academic integrity; ChatGPT; AI detectors		Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for AI-generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AI-generated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text. Furthermore, content obfuscation techniques significantly worsen the performance of tools. The study makes several significant contributions. First, it summarises up-to-date similar scientific and non-scientific efforts in the field. Second, it presents the result of one of the most comprehensive tests conducted so far, based on a rigorous research methodology, an original document set, and a broad coverage of tools. Third, it discusses the implications and drawbacks of using detection tools for AI-generated text in academic settings.	[Weber-Wulff, Debora] Univ Appl Sci HTW Berlin, Berlin, Germany; [Anohina-Naumeca, Alla] Riga Tech Univ, Riga, Latvia; [Bjelobaba, Sonja] Uppsala Univ, Uppsala, Sweden; [Foltynek, Tomas; Sigut, Petr] Masaryk Univ, Brno, Czech Republic; [Guerrero-Dib, Jean] Univ Monterrey, San Pedro Garza Garcia, Mexico; [Popoola, Olumide] Queen Mary Univ London, London, England; [Waddington, Lorna] Univ Leeds, Leeds, England	Riga Technical University; Uppsala University; Masaryk University Brno; Universidad de Monterrey; Tecnologico de Monterrey; University of London; Queen Mary University London; University of Leeds	Bjelobaba, S (corresponding author), Uppsala Univ, Uppsala, Sweden.	sonja.bjelobaba@crb.uu.se	Foltýnek, Tomáš/L-6448-2018; Weber-Wulff, Debora/AAH-8568-2020	Foltýnek, Tomáš/0000-0001-8412-5553; Weber-Wulff, Debora/0000-0002-7335-6548; Guerrero-Dib, Jean/0000-0003-3150-9363; Bjelobaba, Sonja/0000-0003-2384-9624	Uppsala University	Uppsala University	Open access funding provided by Uppsala University. The authors had no funding for this research other than from their respective institutions.	Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bjelobaba S., 2020, Integrity in education for future happiness, P9, DOI [10.11118/978-80-7509-772-9-0009, DOI 10.11118/978-80-7509-772-9-0009]; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Chakraborty S, 2023, Arxiv, DOI arXiv:2304.04736; Clarke R, 2006, P 2 INT PLAG C NEWC, P14; Compilatio, 2023, Comparison of the best AI detectors in 2023; Content at Scale, 2023, How accurate is this for AI detection purposes?; Crossplag.com, 2023, How accurate is the AI Detector?; Demers T., 2023, Search Engine Land; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00140-5; Elsen-Rooney M., 2023, NYC education department blocks ChatGPT on school devices, networks; Foltynek T, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00133-4; Foltynek T, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00192-4; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gewirtz D., 2023, Can AI detectors save us from ChatGPT? I tried 5 online tools to find out; GoWinston.ai, 2023, Winston AI | The most powerful AI content detector; GPTZero, 2023, The Global Standard for AI Detection:Humans Deserve the Truth; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; HOWARD RM, 1995, COLL ENGL, V57, P788, DOI 10.2307/378403; ICML, 2023, 40 INT C MACH LEARN; Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1808; Johnson Arianna., 2023, Forbes; Khalil M., 2023, arXiv, DOI [10.35542/osf.io/fnh48, DOI 10.35542/OSF.IO/FNH48]; Krishna K, 2023, Arxiv, DOI arXiv:2303.13408; Liyanage V, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4692; Ma YQ, 2023, Arxiv, DOI [arXiv:2301.10416, 10.48550/arXiv.2301.10416, DOI 10.48550/ARXIV.2301.10416]; Marr B., 2023, Forbes; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Milmo D., 2023, The Guardian; Oktay Ozan, 2018, PREPRINT, DOI [DOI 10.48550/ARXIV, 10.48550/arxiv]; OpenAI, 2023, ChatGPT February 13 Version; OpenAI, 2023, New ai classifier for indicating aiwritten text; Pegoraro A, 2023, Arxiv, DOI [arXiv:2304.01487, 10.48550/arXiv.2304.01487, DOI 10.48550/ARXIV.2304.01487]; Quillbot, 2023, Quillbot AI Paraphrasing Tool; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Schechner S., 2023, Wall Street J; Tauginiene L., 2018, Glossary for Academic Integrity ENAI Report 3G; Turnitin, 2023, Understanding false positives within our AI writing detection capabilities; Turnitin, 2023, Resources to Address False Positives.Turnitin Support; van Oijen V., 2023, SURF Communities; Vaswani A, 2017, ADV NEUR IN, V30; Wang J, 2023, Arxiv, DOI [arXiv:2304.05193, DOI 10.48550/ARXIV.2304.05193]; Zero GPT, 2023, What is the accuracy rate of ZeroGPT? ZeroGPT-Chat GPT, Open AI and AI text detector Free Too	46	6	6	47	47	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1833-2595			INT J EDUC INTEGR	Int. J. Educ. Intege.	DEC 25	2023	19	1							26	10.1007/s40979-023-00146-z	http://dx.doi.org/10.1007/s40979-023-00146-z			39	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	DA1W4		Green Published, Green Submitted, gold			2024-07-03	WOS:001129231700001
C	Jain, S; Kumar, A; Roy, T; Shinde, K; Vignesh, G; Tondulkar, R		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Jain, Siddhant; Kumar, Asheesh; Roy, Trinita; Shinde, Kartik; Vignesh, Goutham; Tondulkar, Rohan			SciSpace Literature Review: Harnessing AI for Effortless Scientific Discovery	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Information Retrieval; Vector Search; Retrieval Augmented Generation		In the rapidly evolving landscape of academia, the scientific research community barely copes with the challenges posed by a surging volume of scientific literature. Nevertheless, discovering research remains an important step in the research workflow which is also proven to be a challenging one to automate. We present Scispace Literature Review, a sophisticated, multi-faceted tool that serves as a comprehensive solution to streamline the literature review process. By leveraging the state-of-the-art methods in vector-based search, reranking, and large language models, the tool delivers features like customizable search results, data exintegration with an AI assistant, multi-language support, top papers insights, and customizable results columns to cater a researcher's requirements, and accelerate literature exploration. Resources for simplified sharing and documentation further enhance the scope and depth and breadth of research. We demonstrate the extensive use and popularity of the tool among researchers with various metrics, highlighting its value as a resource to elevate scientific literature review. This tool can be tried using this link: https://typeset.io/search.	[Jain, Siddhant; Kumar, Asheesh; Roy, Trinita; Shinde, Kartik; Vignesh, Goutham; Tondulkar, Rohan] SciSpace, Bengaluru, India		Tondulkar, R (corresponding author), SciSpace, Bengaluru, India.	siddhant@typeset.io; asheesh@typeset.io; trinita@typeset.io; kartik@typeset.io; goutham@typeset.io; rohan@typeset.io						Cai D, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3417, DOI 10.1145/3477495.3532682; Cohan A., 2020, SPECTER: document- level representation learning using citation-informed transformers, DOI [10.18653/V1/2020.ACL-MAIN.207, DOI 10.18653/V1/2020.ACL-MAIN.207]; Jan R., 2017, arXiv Information Retrieval; Patrick S., 2020, arXiv; Santhanam K, 2022, Arxiv, DOI [arXiv:2112.01488, DOI 10.48550/ARXIV.2112.01488]; Siddiqi S., 2015, Int. J. Comput. Appl., V109, P1	6	0	0	4	4	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56068-2; 978-3-031-56069-9	LECT NOTES COMPUT SC			2024	14612						256	260		10.1007/978-3-031-56069-9_28	http://dx.doi.org/10.1007/978-3-031-56069-9_28			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EC					2024-07-03	WOS:001211835200028
C	Gao, LY; Dai, ZY; Pasupat, P; Chen, A; Chaganty, AT; Fan, YC; Zhao, VY; Lao, N; Lee, H; Juan, DC; Guu, K		Rogers, A; Boyd-Graber, J; Okazaki, N		Gao, Luyu; Dai, Zhuyun; Pasupat, Panupong; Chen, Anthony; Chaganty, Arun Tejasvi; Fan, Yicheng; Zhao, Vincent Y.; Lao, Ni; Lee, Hongrae; Juan, Da-Cheng; Guu, Kelvin			RARR: Researching and Revising What Language Models Say, Using Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Language models (LMs) now excel at many tasks such as question answering, reasoning, and dialog. However, they sometimes generate unsupported or misleading content. A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence. To enable attribution while still preserving all the powerful advantages of recent generation models, we propose RARR (Retrofit Attribution using Research and Revision), a system that 1) automatically finds attribution for the output of any text generation model, and 2) post-edits the output to fix unsupported content while preserving the original output as much as possible. When applied to the output of several state-of-the-art LMs on a diverse set of generation tasks, we find that RARR significantly improves attribution while otherwise preserving the original input to a much greater degree than previously explored edit models. Furthermore, the implementation of RARR requires only a handful of training examples, a large language model, and standard web search.(1)	[Gao, Luyu] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Dai, Zhuyun; Pasupat, Panupong; Chaganty, Arun Tejasvi; Fan, Yicheng; Zhao, Vincent Y.; Lao, Ni; Lee, Hongrae; Juan, Da-Cheng; Guu, Kelvin] Google Res, Mountain View, CA USA; [Chen, Anthony] UC Irvine, Irvine, CA USA	Carnegie Mellon University; Google Incorporated; University of California System; University of California Irvine	Gao, LY (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	luyug@cs.cmu.edu; zhuyundai@google.com; ppasupat@google.com; anthony.chen@uci.edu; arunchaganty@google.com; yichengfan@google.com; vzhao@google.com; nlao@google.com; hrlee@google.com; dacheng@google.com; kguu@google.com						Ahn Michael, 2022, ABS220401691 ARXIV; Anantha R., 2021, NAACL; Augenstein Isabelle, 2019, EMNLP; Balachandran Vidhisha, 2022, EMNLP; Bohnet Bernd, 2022, ATTRIBUTED QUESTION; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao Mengyao, 2020, EMNLP; Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171; Choi E, 2021, T ASSOC COMPUT LING, V9, P447, DOI 10.1162/tacl_a_00377; Chowdhery Aakanksha, 2022, ABS220402311 ARXIV; Dziri Nouha, 2022, NAACL; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Fan Angela, 2020, EMNLP; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Goyal Tanya, 2021, NAACL; GUU K, 2020, ICML, V119; Hayati ShirleyAnugrah., 2018, EMNLP; Hendrycks D., 2021, ICLR; Honovich Or, 2022, WORKSH DOC GROUND DI; Honovich Or, 2021, EMNLP; Iso Hayate, 2020, ACL; Karadzhov Georgi, 2017, RANLP; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khot T, 2018, AAAI CONF ARTIF INTE, P5189; Krishna Kalpesh, 2021, North American Association for Computational Linguistics; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086; Lee Kenton, 2021, ABS210201335 ARXIV; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Logan Robert L, 2022, NAACL; Longpre Shayne., 2021, EMNLP; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Menick Jacob, 2022, ABS220311147 ARXIV; Nakano Reiichiro, 2021, ABS211209332 ARXIV; Narayan Shashi, 2022, ABS220700397 ARXIV; Nguyen Tri, 2016, COCO NIPS; Ni Jianmo, 2021, ABS211207899 ARXIV; Nye Maxwell, 2021, ABS211200114 ARXIV; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Piktus Aleksandra, 2021, ABS211209924 ARXIV; Raffel Colin, 2020, JMLR 20, V21; Rashkin Hannah, 2021, ABS211212870 ARXIV; Roberts Adam, 2020, EMNLP; Schick Timo, 2022, ABS220811663 ARXIV; Schuster Tal, 2021, NAACL; Shah DarshJ., 2020, AAAI; Shin Richard, 2021, EMNLP; Song KH, 2019, IEEE INT ULTRA SYM, P5, DOI [10.1109/ULTSYM.2019.8925707, 10.1109/ultsym.2019.8925707]; Thoppilan Romal, 2022, ABS220108239 ARXIV; Thorne James., 2021, ACL; Thorne James, 2018, NAACL; Wadden David, 2020, EMNLP; Wang Alex, 2020, P 58 ANN M ASS COMPU, P5008, DOI DOI 10.18653/V1/2020.ACL-MAIN.450; Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018; Wei Jason, 2022, ABS220111903 ARXIV; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Zettlemoyer Luke., 2020, ICLR; Zhang Jingyi, 2018, NAACL; Zhang Yuan, 2019, NAACL	62	2	2	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							16477	16508						32	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962508015
C	Reichman, B; Heck, L			IEEE	Reichman, Benjamin; Heck, Larry			Cross-Modal Dense Passage Retrieval for Outside Knowledge Visual Question Answering	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS, ICCVW	IEEE International Conference on Computer Vision Workshops		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				In many language processing tasks including most notably Large Language Modeling (LLM), retrieval augmentation improves the performance of the models by adding information during inference that may not be present in the model's weights. This technique has been shown to be particularly useful in multimodal settings. For some tasks, like Outside Knowledge Visual Question Answering (OK-VQA), retrieval augmentation is required given the open nature of the knowledge. In many prior works for the OK-VQA task, the retriever is either a unimodal language retriever or an untrained cross-modal retriever. In this work, we present a weakly supervised training approach for cross-modal retrievers. Our method takes inspiration from the natural language modeling task of information retrieval and extends those methods to cross-modal retrieval. Since the OKVQA task does not typically have consistent ground truth retrieval labels, we evaluate our model using lexical overlap between the ground truth and the retrieved passage. Our approach showed an average recall improvement of 28% across a large range of retrieval sizes compared to a baseline backbone network.	[Reichman, Benjamin; Heck, Larry] Georgia Inst Technol, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Reichman, B (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.	bzr@gatech.edu; larryheck@gatech.edu						Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Borgeaud S, 2022, PR MACH LEARN RES; Gao F, 2022, PROC CVPR IEEE, P5057, DOI 10.1109/CVPR52688.2022.00501; Gardères F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P489; Gui L., 2022, NAACL; Guu K., 2020, INT C MACHINE LEARNI, P3929; Hakkani-Tur Dilek, 2014, P 16 INT C MULTIMODA, P263, DOI 10.1145/2663204.2663277; Heck Larry, 2013, P 1 WORKSH SPEECH LA; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Izacard Gautier, 2020, LEVERAGING PASSAGE R; Izacard Gautier, 2020, ARXIV201204584; Izacard Gautier, 2022, arXiv preprint arXiv:2208.03299; Jia C, 2021, PR MACH LEARN RES, V139; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086; Lerner P, 2023, LECT NOTES COMPUT SC, V13980, P569, DOI 10.1007/978-3-031-28244-7_36; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lin Weizhe, 2022, ARXIV221003809; Lin Yuanze, 2022, ARXIV220601201; Luo Man, 2021, ARXIV210904014; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; OpenAI, 2023, GPT-4 Technical Report; Radford A., 2018, IMPROVING LANGUAGE U; Reichman Benjamin Z., 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10096074; Shuster Kurt, 2021, RETRIEVAL AUGMENTATI; Srinivasan K, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2443, DOI 10.1145/3404835.3463257; Sundar Anirudh, 2022, P 4 ACL WORKSH NLP C; Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401; Wu JL, 2022, AAAI CONF ARTIF INTE, P2712; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yasunaga Michihiro, 2023, RETRIEVAL AUGMENTED	32	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2473-9936		979-8-3503-0744-3	IEEE INT CONF COMP V			2023							2829	2834		10.1109/ICCVW60793.2023.00304	http://dx.doi.org/10.1109/ICCVW60793.2023.00304			6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW4XE					2024-07-03	WOS:001156680302098
C	Komeili, M; Shuster, K; Weston, J			Assoc Computat Linguist	Komeili, Mojtaba; Shuster, Kurt; Weston, Jason			Internet-Augmented Dialogue Generation	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple				The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledge-driven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020b).	[Komeili, Mojtaba; Shuster, Kurt; Weston, Jason] Facebook AI, Res Labs, Menlo Pk, CA 94025 USA	Facebook Inc	Komeili, M (corresponding author), Facebook AI, Res Labs, Menlo Pk, CA 94025 USA.	komeili@fb.com; kshuster@fb.com; jase@fb.com						Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; Angeliki Lazaridou A, 2021, ADV NEURAL INFORM PR; [Anonymous], 2015, 3 INT C LEARN REPR I; Baumgartner Jason, 2020, Technical report; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bruyn M. D., 2020, CONVERSE KDD; Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171; Dinan Emily, 2019, 7 INT C LEARN REPR I; Fan A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7147; Galetzka F, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P565; Ghazvininejad M, 2018, AAAI CONF ARTIF INTE, P5110; Gopalakrishnan K, 2019, INTERSPEECH, P1891, DOI 10.21437/Interspeech.2019-3079; Grave E., 2017, ICLR; Guu K, 2020, PR MACH LEARN RES, V119; Hassan N, 2017, PROC VLDB ENDOW, V10, P1945; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khandelwal Urvashi, 2021, INT C LEARN REPR; Kim B., 2020, 8 INT C LEARN REPR I; Kingma D. P, 2015, P INT C LEARN REPR 2; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Merity Stephen, 2017, 5 INT C LEARNING REP; Petroni F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2523; Raffel C, 2020, J MACH LEARN RES, V21; Rashkin H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5370; Roller Stephen, 2021, P 16 C EUR CHAPT ASS, P300; Shuster Kurt., 2021, FINDINGS ASS COMPUTA, P3784, DOI [DOI 10.18653/V1/2021.FINDINGSEMNLP.320, 10.18653/v1/2021.findings-emnlp.320]; Voorhees Ellen M., 2000, P 2 INT C LANG RES E; Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003; Xu Jing, 2020, ARXIV201007079; Yogatama D, 2021, T ASSOC COMPUT LING, V9, P362, DOI 10.1162/tacl_a_00371; Zettlemoyer Luke., 2020, ICLR; Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhao XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2377, DOI 10.1145/3366423.3380301; Zhou Kangyan, 2018, 2018 C EMPIRICAL MET, P708, DOI 10.18653/v1/D18-1076	39	18	18	1	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-21-6				2022							8460	8478						19	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EM					2024-07-03	WOS:000828702308036
J	Hu, X; Liu, A; Dai, Y				Hu, Xin; Liu, Ang; Dai, Yun			Combining ChatGPT and knowledge graph for explainable machine learning-driven design: a case study	JOURNAL OF ENGINEERING DESIGN			English	Article; Early Access						Machine learning; knowledge graph; explainable AI; ChatGPT; product design		Machine learning has been widely used in design activities, enabling more informed decision-making. However, high-performance machine learning models, often referred to as 'black-box', result in a lack of explainability regarding predictions. The absence of explainability erodes the trust between designers and these models and hinders human-machine collaboration for desirable design decisions. Explainable AI focuses on creating explanations that are accessible and comprehensible to stakeholders, thereby improving explainability. A recent advancement in the field of explainable AI involves leveraging domain-specific knowledge via knowledge graph. Additionally, the advent of large language models like ChatGPT, acclaimed for their ability to output domain knowledge, perform complex language processing, and support seamless end-user interaction, has the potential to expand the horizons of explainable AI. Inspired by these developments, we propose the novel hybrid method that synergizes ChatGPT and knowledge graph to augment post-hoc explainability in design context. The outcome is the generation of more contextual and meaningful explanations, with the added possibility of further interaction to uncover deeper insights. The effectiveness of the proposed method is illustrated through a case study on customer segmentation.	[Hu, Xin; Liu, Ang] Univ New South Wales, Sch Mech & Mfg Engn, Kensington, NSW 2052, Australia; [Dai, Yun] Chinese Univ Hong Kong, Dept Curriculum & Instruct, Shatin, Hong Kong, Peoples R China	University of New South Wales Sydney; Chinese University of Hong Kong	Liu, A (corresponding author), Univ New South Wales, Sch Mech & Mfg Engn, Kensington, NSW 2052, Australia.	ang.liu@unsw.edu.au						Abu-Salih B, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103076; Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805; Rad MA, 2023, J ENG DESIGN, V34, P1, DOI 10.1080/09544828.2022.2164440; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Guo YT, 2024, DECIS SUPPORT SYST, V176, DOI 10.1016/j.dss.2023.114051; Hodler A. E., 2022, Massive Graph Analytics; Hu ZQ, 2023, J ENG DESIGN, DOI 10.1080/09544828.2023.2272555; Klaise J, 2021, J MACH LEARN RES, V22; Lai V, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376873; Li Z, 2018, J ENG DESIGN, V29, P358, DOI 10.1080/09544828.2018.1471671; Ling C, 2023, Arxiv, DOI arXiv:2305.18703; Liu A, 2022, CIRP ANN-MANUF TECHN, V71, P117, DOI 10.1016/j.cirp.2022.03.025; Maillot P, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1960, DOI 10.1145/3167132.3167342; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Naqvi MR, 2024, J INTELL MANUF, DOI 10.1007/s10845-023-02304-z; Nori H, 2019, Arxiv, DOI arXiv:1909.09223; Pan S., 2024, IEEE T KNOWL DATA EN; Pan XY, 2024, J ENG DESIGN, DOI 10.1080/09544828.2023.2301230; Pradhan R, 2022, INT CONF MANAGE DATA, P2452, DOI 10.1145/3514221.3522564; Qiu Y., 2023, INT DES ENG TECHN C; Rahutomo F., 2012, 7 INT STUD C ADV SCI, V1; Rajabi E, 2022, J INF SCI, DOI 10.1177/01655515221112844; Renzi C, 2017, J ENG DESIGN, V28, P118, DOI 10.1080/09544828.2016.1274720; Tian Y., 2024, CIRP Annals, DOI [https://doi.org/10.1016/j.cirp.2024.04.062, DOI 10.1016/J.CIRP.2024.04.062]; Tiddi I, 2022, ARTIF INTELL, V302, DOI 10.1016/j.artint.2021.103627; Tseng MM, 2010, CIRP ANN-MANUF TECHN, V59, P175, DOI 10.1016/j.cirp.2010.03.097; Wang Xingzhi, 2023, Procedia CIRP, P7, DOI 10.1016/j.procir.2023.04.001; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xia LQ, 2024, ROBOT CIM-INT MANUF, V88, DOI 10.1016/j.rcim.2024.102728; Xiao YZ, 2023, J MANUF SYST, V70, P417, DOI 10.1016/j.jmsy.2023.08.006; Xie TL, 2023, J ENG DESIGN, V34, P158, DOI 10.1080/09544828.2023.2177937; Xin Hu, 2023, Procedia CIRP, P21, DOI 10.1016/j.procir.2023.05.001; Zhang J, 2023, J ENG DESIGN, V34, P844, DOI 10.1080/09544828.2023.2263731; Zhang YY, 2007, J ENG DESIGN, V18, P227, DOI 10.1080/09544820600752781; Zhang YF, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P295, DOI 10.1145/3351095.3372852; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhou CY, 2023, J ENG DESIGN, DOI 10.1080/09544828.2023.2290915; Zhu XR, 2024, IEEE T KNOWL DATA EN, V36, P715, DOI 10.1109/TKDE.2022.3224228	40	0	0	10	10	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0954-4828	1466-1837		J ENG DESIGN	J. Eng. Des.	2024 MAY 21	2024										10.1080/09544828.2024.2355758	http://dx.doi.org/10.1080/09544828.2024.2355758		MAY 2024	23	Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	RL6V5		hybrid			2024-07-03	WOS:001227868400001
J	Fredheim, R; Pamment, J				Fredheim, Rolf; Pamment, James			Assessing the risks and opportunities posed by AI-enhanced influence operations on social media	PLACE BRANDING AND PUBLIC DIPLOMACY			English	Article; Early Access						LLM; AI; Influence operations; Disinformation; Digital diplomacy		Large language models (LLMs) like GPT-4 have the potential to dramatically change the landscape of influence operations. They can generate persuasive, tailored content at scale, making campaigns using falsified content, such as disinformation and fake accounts, easier to produce. Advances in self-hosted open-source models have meant that adversaries can evade content moderation and security checks built into large commercial models such as those commercialised by Anthropic, Google, and OpenAI. New multi-lingual models make it easier than ever for foreign adversaries to pose as local actors. This article examines the heightened threats posed by synthetic media, as well as the potential that these tools hold for creating effective countermeasures. It begins with assessing the challenges posed by a toxic combination of automated bots, human-controlled troll accounts, and more targeted social engineering operations. However, the second part of the article assesses the potential for these same tools to improve detection. Promising countermeasures include running internal generative models to bolster training data for internal classifiers, detecting statistical anomalies, identifying output from common prompts, and building specialised classifiers optimised for specific monitoring needs.	[Fredheim, Rolf; Pamment, James] Lund Univ, Psychol Def Res Inst, Box 882, S-25108 Helsingborg, Sweden	Lund University	Pamment, J (corresponding author), Lund Univ, Psychol Def Res Inst, Box 882, S-25108 Helsingborg, Sweden.	james.pamment@isk.lu.se			Swedish Psychological Defence Agency	Swedish Psychological Defence Agency	No Statement Available	[Anonymous], 2023, The Moscow Times; Bai Yuntao, 2022, Anthropic; BBC, 2015, US state department trolls Russian newspaper over 'fake letter'; Brewster J., 2023, Newsguard.; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Christian Jon, 2023, CNET's AI journalist appears to have committed extensive plagiarism; Derner E, 2023, Arxiv, DOI arXiv:2305.08005; Edwards Benj, 2023, Feik Pentagon "explosion"photo sows confusion on Twitter; EU Commision, 2022, Shaping Europe's future: The 2022 code of practice on disinformation; Ha Thanh Nguyen, 2021, Medium.com; Heikkila Melissa, 2023, MIT Technology Review; Lee HRS, 2023, Arxiv, DOI [arXiv:2309.00267, 10.48550/arXiv.2309.00267]; Marcus G., 2020, Rebooting AI: Building artificial intelligence we can trust; Meta Transparency Centre, Manipulated media; Mollick Ethan, 2023, Centaurs and cyborgs on the jagged frontier; Neumeister Larry, 2023, Associated Press; Porter Jon, 2023, The Verge; Saab Beatriz, 2023, ChatGPT vs. Bard: Unveiling the Battle against Disinformation and Creative Output; Santurkar Shibani, 2023, Whose opinions do language models reflect?; Stamos Alex, 2023, About us; Willison S. Bing, 2023, Simon Willison's Weblog; Willison Simon, 2023, Prompt injection: What's the worst that can happen?; X Help Centre, 2023, Synthetic and manipulated media policy; Yang Zeyi, 2022, MIT TECHNOL REV	24	0	0	13	13	PALGRAVE MACMILLAN LTD	BASINGSTOKE	BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND	1751-8040	1751-8059		PLACE BRANDING PUBLI	Place Branding Public Dipl.	2024 FEB 8	2024										10.1057/s41254-023-00322-5	http://dx.doi.org/10.1057/s41254-023-00322-5		FEB 2024	8	Hospitality, Leisure, Sport & Tourism	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	HC6T3		hybrid			2024-07-03	WOS:001157338400001
J	Yang, J; Shu, LQ; Han, MY; Pan, JR; Chen, LH; Yuan, TM; Tan, LH; Shu, Q; Duan, HL; Li, HM				Yang, Jian; Shu, Liqi; Han, Mingyu; Pan, Jiarong; Chen, Lihua; Yuan, Tianming; Tan, Linhua; Shu, Qiang; Duan, Huilong; Li, Haomin			RDmaster: A novel phenotype-oriented dialogue system supporting differential diagnosis of rare disease	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Rare disease; Human phenotype ontology; Differential diagnosis; Phenomic and genomic diagnostics; Electronic differential diagnostic support system	INFORMATION GAIN; GINI INDEX	Background: Clinicians often lack the necessary expertise to differentially diagnose multiple underlying rare diseases (RDs) due to their complex and overlapping clinical features, leading to misdiagnoses and delayed treatments. The aim of this study is to develop a novel electronic differential diagnostic support system for RDs. Method: Through integrating two Bayesian diagnostic methods, a candidate list was generated with enhance clinical interpretability for the further Q&A based differential diagnosis (DDX). To achieve an efficient Q&A dialogue strategy, we introduce a novel metric named the adaptive information gain and Gini index (AIGGI) to evaluate the expected gain of interrogated phenotypes within real -time diagnostic states. Results: This DDX tool called RDmaster has been implemented as a web -based platform (http://rdmaster.nbscn. org/). A diagnostic trial involving 238 published RD patients revealed that RDmaster outperformed existing RD diagnostic tools, as well as ChatGPT, and was shown to enhance the diagnostic accuracy through its Q&A system. Conclusions: The RDmaster offers an effective multi-omics differential diagnostic technique and outperforms existing tools and popular large language models, particularly enhancing differential diagnosis in collecting diagnostically beneficial phenotypes.	[Yang, Jian; Shu, Qiang; Li, Haomin] Zhejiang Univ, Childrens Hosp, Clin Data Ctr, Natl Clin Res Ctr Child Hlth,Sch Med, Hangzhou, Zhejiang, Peoples R China; [Yang, Jian; Duan, Huilong] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Zhejiang, Peoples R China; [Shu, Liqi] Brown Univ, Rhode Isl Hosp, Warren Alpert Med Sch, Providence, RI USA; [Han, Mingyu; Pan, Jiarong; Chen, Lihua; Yuan, Tianming] Zhejiang Univ Sch Med, Childrens Hosp, Natl Clin Res Ctr Child Hlth, Neonatal Dept, Zhejiang, Peoples R China; [Tan, Linhua] Zhejiang Univ Sch Med, Childrens Hosp, Natl Clin Res Ctr Child Hlth, Surg Intens Care Unit, Zhejiang, Peoples R China; [Li, Haomin] 3333 Binsheng Rd, Hangzhou 310052, Zhejiang, Peoples R China	Zhejiang University; Zhejiang University; Lifespan Health Rhode Island; Rhode Island Hospital; Brown University	Li, HM (corresponding author), 3333 Binsheng Rd, Hangzhou 310052, Zhejiang, Peoples R China.	hmli@zju.edu.cn	Li, Haomin/AAY-5044-2021	Li, Haomin/0000-0002-6420-7719	National Natural Science Foundation of China [81871456]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgments</B> This work was supported by the National Natural Science Foundation of China [81871456] .	Aronson JK, 2006, BRIT J CLIN PHARMACO, V61, P243, DOI 10.1111/j.1365-2125.2006.02617.x; Azadifar S, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105766; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Bauer S, 2012, BIOINFORMATICS, V28, P2502, DOI 10.1093/bioinformatics/bts471; Bond WF, 2012, J GEN INTERN MED, V27, P213, DOI 10.1007/s11606-011-1804-8; Boycott KM, 2017, AM J HUM GENET, V100, P695, DOI 10.1016/j.ajhg.2017.04.003; Denison DGT, 1998, BIOMETRIKA, V85, P363; Ebiki M, 2019, YONAGO ACTA MED, V62, P244, DOI 10.33160/yam.2019.09.001; Evans WRH, 2016, BRIT J GEN PRACT, V66, P550, DOI 10.3399/bjgp16X687625; Faviez C, 2020, ORPHANET J RARE DIS, V15, DOI 10.1186/s13023-020-01374-z; Ferreira CR, 2019, AM J MED GENET A, V179, P885, DOI 10.1002/ajmg.a.61124; Ghoreyshi ZS, 2023, FRONT IMMUNOL, V14, DOI 10.3389/fimmu.2023.1228873; Grimes DA, 2005, LANCET, V365, P1500, DOI 10.1016/S0140-6736(05)66422-7; Hamosh A, 2000, HUM MUTAT, V15, P57, DOI 10.1002/(SICI)1098-1004(200001)15:1<57::AID-HUMU12>3.0.CO;2-G; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Jacobsen JOB, 2022, NAT BIOTECHNOL, V40, P817, DOI 10.1038/s41587-022-01357-4; Jain B, 2017, DIAGNOSIS, V4, P239, DOI 10.1515/dx-2017-0005; Jain V, 2018, TENCON IEEE REGION, P2187, DOI 10.1109/TENCON.2018.8650485; Kamdar JH., 2020, Learning and analytics in intelligent systems, P27, DOI [10.1007/978-3-030-40850-3_2, DOI 10.1007/978-3-030-40850-3_2]; Köhler S, 2021, NUCLEIC ACIDS RES, V49, pD1207, DOI 10.1093/nar/gkaa1043; Köhler S, 2009, AM J HUM GENET, V85, P457, DOI 10.1016/j.ajhg.2009.09.003; Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011; Li QG, 2019, GENET MED, V21, P2126, DOI 10.1038/s41436-019-0439-8; Li ZX, 2019, BIOINFORMATICS, V35, P3559, DOI 10.1093/bioinformatics/btz100; Liu QL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P201; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Murray S., 2017, Interactive data visualization for the web: an introduction to designing with D3; Pearson NM, 2021, GENET MED, V23, P1998, DOI 10.1038/s41436-021-01219-5; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251; Raileanu LE, 2004, ANN MATH ARTIF INTEL, V41, P77, DOI 10.1023/B:AMAI.0000018580.96245.c6; Ren LY, 2019, The Journal of the Canadian Health Libraries Association= Journal de l'Association des Bibliotheques de la Sante du Canada, V40, P63, DOI DOI 10.29173/JCHLA29418; Robinson PN, 2020, AM J HUM GENET, V107, P403, DOI 10.1016/j.ajhg.2020.06.021; Robinson PN., 2011, Introduction to Bio-Ontologies, V1, DOI [10.1201/b10967, DOI 10.1201/B10967]; Smedley D, 2015, NAT PROTOC, V10, P2004, DOI 10.1038/nprot.2015.124; Smedley D, 2015, GENOME MED, V7, DOI 10.1186/s13073-015-0199-2; Tangirala S, 2020, INT J ADV COMPUT SC, V11, P612; Wasserstein RL, 2016, AM STAT, V70, P129; Weinreich S S, 2008, Ned Tijdschr Geneeskd, V152, P518; Xu L, 2019, AAAI CONF ARTIF INTE, P7346; Yang J, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104372; Yang J, 2022, INTERDISCIP SCI, V14, P331, DOI 10.1007/s12539-021-00490-z; Yang J, 2021, ORPHANET J RARE DIS, V16, DOI 10.1186/s13023-021-01741-4; Zemojtel T, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3009262; Zhong C, 2023, Arxiv, DOI arXiv:2004.14254	44	0	0	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	FEB	2024	169								107924	10.1016/j.compbiomed.2024.107924	http://dx.doi.org/10.1016/j.compbiomed.2024.107924		JAN 2024	9	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	GE3V2	38181610	hybrid			2024-07-03	WOS:001150959700001
J	Fatouros, G; Soldatos, J; Kouroumali, K; Makridis, G; Kyriazis, D				Fatouros, Georgios; Soldatos, John; Kouroumali, Kalliopi; Makridis, Georgios; Kyriazis, Dimosthenis			Transforming sentiment analysis in the financial domain with ChatGPT	MACHINE LEARNING WITH APPLICATIONS			English	Article						ChatGPT; Artificial intelligence; Finance; Sentiment analysis; Risk assessment	INVESTOR SENTIMENT; TEXTUAL ANALYSIS; STOCK; NEWS	Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero -shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1 -score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an addition evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35% enhanced performance in sentiment classification and a 36% higher correlation with market returns. By underlining the significance of prompt engineering, particularly in zero -shot contexts, this study spotlights ChatGPT's potential to substantially boost sentiment analysis in financial applications. By sharing the utilized dataset, our intention is to stimulate further research and advancements in the field of financial services.	[Fatouros, Georgios; Makridis, Georgios; Kyriazis, Dimosthenis] Univ Piraeus, Dept Digital Syst, Karaoli & Dimitriou 80, Piraeus 18534, Greece; [Fatouros, Georgios; Soldatos, John] Innov Acts Ltd, CY-1101 Nicosia, Cyprus; [Kouroumali, Kalliopi] Hellen Telecommun Org SA OTE, Kifissias Ave 99, GR-15124 Athens, Greece	University of Piraeus	Fatouros, G (corresponding author), Univ Piraeus, Dept Digital Syst, Karaoli & Dimitriou 80, Piraeus 18534, Greece.	gfatouros@unipi.gr; jsoldat@innov-acts.com; kkouroumali@ote.gr; gmakridis@unipi.gr; dimos@unipi.gr	Kyriazis, Dimosthenis/AAM-9407-2021	Kyriazis, Dimosthenis/0000-0001-7019-7214; Fatouros, Georgios/0000-0001-6843-089X	European Union [101092639]	European Union(European Union (EU))	Part of the research leading to the results presented in this paper has received funding from the European Union's funded Project FAME under grant agreement no 101092639. We would also like to express our gratitude to our FAME partners, JRC Capital Management Consultancy Research GmbH and KMcube Asset Management SA, for their invaluble contributions and expertise in the data labeling process. We extend our appreciation to the anonymous reviewers for their constructive feedback, which greatly enhanced the quality of this manuscript.	Arner, 2015, GEORGETOWN J INT L, V47, P1271, DOI [10.2139/SSRN.2676553, 10.2139/ssrn.2676553, DOI 10.2139/SSRN.2676553]; Baker M, 2007, J ECON PERSPECT, V21, P129, DOI 10.1257/jep.21.2.129; Bing L, 2012, synthesis lectures on human language technologies, Sentiment analysis and opinion mining; Blaskowitz O, 2011, INT J FORECASTING, V27, P1058, DOI 10.1016/j.ijforecast.2010.07.002; Bloomberg, 2023, Bloomberg media distribution; Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007; Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen C., 2018, Textual sentiment, option characteristics, and stock return predictability; Chen HL, 2014, REV FINANC STUD, V27, P1367, DOI 10.1093/rfs/hhu001; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Evans MDD, 2005, J INT MONEY FINANC, V24, P197, DOI 10.1016/j.jimonfin.2004.12.004; Farimani SA, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108742; Fatouros Georgios, 2023, Zenodo, DOI 10.5281/ZENODO.7976208; Fatouros Georgios, 2023, Digit Finance, V5, P29, DOI 10.1007/s42521-022-00050-0; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; JasperAI, 2023, The ai in business trend report; Keynes JM, 1937, Q J ECON, V51, P209, DOI 10.2307/1882087; Kotios D, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00651-x; Leippold M, 2023, FINANC RES LETT, V55, DOI 10.1016/j.frl.2023.103957; Liu Z, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4513; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; Mordor Intelligence, 2022, Ai in fintech market-growth, trends, covid-19 impact, and forecasts (2023-2028); OpenAI, 2023, Gpt-4 technical report; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003; Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Refaeli D., 2021, P 2021 5 INT C E BUS, P6; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schumaker RP, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462204; Siering M, 2018, DECIS SUPPORT SYST, V108, P1, DOI 10.1016/j.dss.2018.01.004; Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yeshayahou K., 2021, Israeli co similarweb files for nyse ipo; Yue T, 2023, Democratizing financial knowledge with chatgpt by openai: Unleashing the power of technology; Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776	46	6	7	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2666-8270		MACH LEARN APPL	Mach. Learn. Appl.	DEC 15	2023	14								100508	10.1016/j.mlwa.2023.100508	http://dx.doi.org/10.1016/j.mlwa.2023.100508			13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	QO0O4		Green Submitted, gold			2024-07-03	WOS:001221698100004
C	Pawagi, M; Kumar, V		Babu, C; Goel, N; Karkare, A		Pawagi, Mrigank; Kumar, Viraj			GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose Statements	PROCEEDINGS OF THE 16TH ANNUAL ACM INDIA COMPUTE CONFERENCE, COMPUTE 2023			English	Proceedings Paper	16th Annual ACM India Compute Conference (COMPUTE)	DEC 09-11, 2023	Univ Hyderabad, Hyderabad, INDIA	Indian Inst Technol Madras, BSc Degree, Virtual Labs, Persistent, NPTEL, ACM India I SIGCSE, ACM In Cooperat	Univ Hyderabad	function design; purpose statement; CS1		Before implementing a function, programmers are encouraged to write a purpose statement i.e., a short, natural-language explanation of what the function computes. A purpose statement may be ambiguous i.e., it may fail to specify the intended behaviour when two or more inequivalent computations are plausible on certain inputs. Our paper makes four contributions. First, we propose a novel heuristic that suggests such inputs using Large Language Models (LLMs). Using these suggestions, the programmer may choose to clarify the purpose statement (e.g., by providing a functional example that specifies the intended behaviour on such an input). Second, to assess the quality of inputs suggested by our heuristic, and to facilitate future research, we create an open dataset of purpose statements with known ambiguities. Third, we compare our heuristic against GitHub Copilot's Chat feature, which can suggest similar inputs when prompted to generate unit tests. Fourth, we provide an open-source implementation of our heuristic as an extension to Visual Studio Code for the Python programming language, where purpose statements and functional examples are specified as docstrings and doctests respectively. We believe that this tool will be particularly helpful to novice programmers and instructors.	[Pawagi, Mrigank; Kumar, Viraj] Indian Inst Sci, Bengaluru, Karnataka, India	Indian Institute of Science (IISC) - Bangalore	Pawagi, M (corresponding author), Indian Inst Sci, Bengaluru, Karnataka, India.	mrigankp@iisc.ac.in; viraj@iisc.ac.in		Pawagi, Mrigank/0009-0002-6169-4766				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adithi GS, 2015, IEEE CONF TECHNOL ED, P105, DOI 10.1109/T4E.2015.11; [Anonymous], 2008, IEEE STANDARD FLOATI, V754-2008, P1, DOI 10.1109/IEEESTD.2008.4610935; Balse R, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P292, DOI 10.1145/3587102.3588852; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Chen M., 2021, arXiv; Dave D, 2022, SIGMOD REC, V51, P18, DOI 10.1145/3552490.3552494; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Felleisen Matthias, 2018, How to design programs: an introduction to programming and computing; Fink G., 1997, Software Engineering Notes, V22, P74, DOI 10.1145/263244.263267; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Lahiri SK, 2023, Arxiv, DOI arXiv:2208.05950; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; MacIver David R., 2019, Journal of Open Source Software, V4, P1891, DOI DOI 10.21105/JOSS.01891; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Pankiewicz M, 2023, Arxiv, DOI arXiv:2307.00150; Papadakis M, 2019, ADV COMPUT, V112, P275, DOI 10.1016/bs.adcom.2018.03.015; Prather J, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P531, DOI 10.1145/3287324.3287374; Raman Arun, 2022, COMPUTE 2022: COMPUTE 2022, P29, DOI 10.1145/3561833.3561843; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schneider G.M., 1978, Papers of the SIGCSE/CSA Technical Symposium on Computer Science Education (Detroit, Michigan, February 23-24, 1978), P107, DOI 10.1145/990555.990598; Shu Lin, 2021, ITiCSE '21: Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education, P185, DOI 10.1145/3430665.3456360; Silva L, 2023, IEEE T EDUC, V66, P156, DOI 10.1109/TE.2022.3204906; Takanen A, 2018, ADV TOP SCI TECH CHI, P1; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830; Wrenn J, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P131, DOI 10.1145/3291279.3339416; Wrenn John, 2020, P 20 KOL CALL INT C, DOI DOI 10.1145/3428029.3428060	28	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0840-4				2023							55	60		10.1145/3627217.3627234	http://dx.doi.org/10.1145/3627217.3627234			6	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW6LB		Green Submitted			2024-07-03	WOS:001176678700014
J	Safranek, CW; Huang, TM; Wright, DS; Wright, CX; Socrates, V; Sangal, RB; Iscoe, M; Chartash, D; Taylor, RA				Safranek, Conrad W.; Huang, Thomas; Wright, Donald S.; Wright, Catherine X.; Socrates, Vimig; Sangal, Rohit B.; Iscoe, Mark; Chartash, David; Taylor, R. Andrew			Automated HEART score determination via ChatGPT: Honing a framework for iterative prompt development	JOURNAL OF THE AMERICAN COLLEGE OF EMERGENCY PHYSICIANS OPEN			English	Article						artificial intelligence in medicine; ChatGPT; clinical decision support systems; clinical note analysis; emergency department risk algorithms; HEART score; large language models; natural language processing; prompt engineering		ObjectivesThis study presents a design framework to enhance the accuracy by which large language models (LLMs), like ChatGPT can extract insights from clinical notes. We highlight this framework via prompt refinement for the automated determination of HEART (History, ECG, Age, Risk factors, Troponin risk algorithm) scores in chest pain evaluation.MethodsWe developed a pipeline for LLM prompt testing, employing stochastic repeat testing and quantifying response errors relative to physician assessment. We evaluated the pipeline for automated HEART score determination across a limited set of 24 synthetic clinical notes representing four simulated patients. To assess whether iterative prompt design could improve the LLMs' ability to extract complex clinical concepts and apply rule-based logic to translate them to HEART subscores, we monitored diagnostic performance during prompt iteration.ResultsValidation included three iterative rounds of prompt improvement for three HEART subscores with 25 repeat trials totaling 1200 queries each for GPT-3.5 and GPT-4. For both LLM models, from initial to final prompt design, there was a decrease in the rate of responses with erroneous, non-numerical subscore answers. Accuracy of numerical responses for HEART subscores (discrete 0-2 point scale) improved for GPT-4 from the initial to final prompt iteration, decreasing from a mean error of 0.16-0.10 (95% confidence interval: 0.07-0.14) points.ConclusionWe established a framework for iterative prompt design in the clinical space. Although the results indicate potential for integrating LLMs in structured clinical note analysis, translation to real, large-scale clinical data with appropriate data privacy safeguards is needed.	[Safranek, Conrad W.; Huang, Thomas; Socrates, Vimig; Iscoe, Mark; Chartash, David; Taylor, R. Andrew] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT USA; [Wright, Donald S.; Sangal, Rohit B.; Iscoe, Mark; Taylor, R. Andrew] Yale Univ, Sch Med, Dept Emergency Med, New Haven, CT USA; [Wright, Catherine X.] Yale Univ, Sch Med, Dept Cardiovasc Med, New Haven, CT USA; [Chartash, David] Natl Univ Ireland, Univ Coll Dublin, Sch Med, Dublin, Ireland; [Taylor, R. Andrew] 464 Congress Ave,Suite 260, New Haven, CT 06519 USA	Yale University; Yale University; Yale University; University College Dublin	Taylor, RA (corresponding author), 464 Congress Ave,Suite 260, New Haven, CT 06519 USA.	richard.taylor@yale.edu		Safranek, Conrad/0000-0003-1985-9432; /0000-0002-9082-6644; Wright, Donald/0000-0002-2564-7754	National Heart, Lung, and Blood Institute of the National Institutes of Health;  [T35HL007649]	National Heart, Lung, and Blood Institute of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); 	The authors thank David Yang, MD for reviewing and adjudicating any disagreements in emergency medicine physician HEART score assessments. OpenAI's GPT-4 (2023 version) was used to develop some of the R code used in the data pipeline; all GPT-4 code outputs were reviewed and edited for accuracy prior to deployment. Research reported in this publication was supported by the National Heart, Lung, and Blood Institute of the National Institutes of Health under award T35HL007649 (author CWS). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	[Anonymous], Microsoft Azure compliance offerings; [Anonymous], GPT best practices-OpenAI API documentation. OpenAI Platform; Backus Barbra E, 2010, Crit Pathw Cardiol, V9, P164, DOI 10.1097/HPC.0b013e3181ec36d8; Diaz N., 6 hospitals, health systems testing out ChatGPT; Epic, Epic and microsoft bring GPT-4 to EHRs; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Marks M, 2023, JAMA-J AM MED ASSOC, V330, P309, DOI 10.1001/jama.2023.9458; Ng A., ChatGPT prompt engineering for developers-learning platform beta. DeepLearning AI; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Six AJ, 2008, NETH HEART J, V16, P191, DOI 10.1007/BF03086144; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]	13	0	0	6	6	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2688-1152		JACEP OPEN	J. Am. Coll. Emerg. Phys. Open	APR	2024	5	2							e13133	10.1002/emp2.13133	http://dx.doi.org/10.1002/emp2.13133			7	Emergency Medicine	Emerging Sources Citation Index (ESCI)	Emergency Medicine	KZ8H6	38481520	Green Published, gold			2024-07-03	WOS:001183877800001
J	Wang, JJ; Huang, JX; Tu, XH; Wang, JM; Huang, AJ; Laskar, MTR; Bhuiyan, A				Wang, Jiajia; Huang, Jimmy Xiangji; Tu, Xinhui; Wang, Junmei; Huang, Angela Jennifer; Laskar, Md Tahmid Rahman; Bhuiyan, Amran			Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges	ACM COMPUTING SURVEYS			English	Article						BERT; information retrieval; natural language processing; artificial intelligence		Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. Additionally, we highlight the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.	[Wang, Jiajia] Henan Univ Technol, Sch Sci, Zhengzhou 450001, Henan, Peoples R China; [Huang, Jimmy Xiangji; Bhuiyan, Amran] York Univ, Informat Retrieval & Knowledge Management Res Lab, 4700 Keele St, Toronto, ON M3J 1P3, Canada; [Tu, Xinhui] Cent China Normal Univ, Sch Comp Sci, Wuhan 430079, Hubei, Peoples R China; [Wang, Junmei] Hangzhou Dianzi Univ, Sch Comp, Hangzhou 310018, Peoples R China; [Huang, Angela Jennifer] York Univ, Lassonde Sch Engn, Toronto, ON M3J 2S5, Canada; [Laskar, Md Tahmid Rahman] York Univ, 4700 Keele St, Toronto, ON M3J 1P3, Canada; [Laskar, Md Tahmid Rahman] Dialpad Inc, 4700 Keele St, Toronto, ON M3J 1P3, Canada	Henan University of Technology; York University - Canada; Central China Normal University; Hangzhou Dianzi University; York University - Canada; York University - Canada; York University - Canada	Huang, JX (corresponding author), York Univ, Informat Retrieval & Knowledge Management Res Lab, 4700 Keele St, Toronto, ON M3J 1P3, Canada.	stwjj057@mails.ccnu.edu.cn; jhuang@yorku.ca; tuxinhui@mail.ccnu.edu.cn; wjm2018@mails.ccnu.edu.cn; anqiaj@yorku.ca; tahmid20@yorku.ca; amran@yorku.ca	Huang, Jimmy Xiangji/ABT-1811-2022; Bhuiyan, Md Amran Hossen/ABC-6140-2021	Huang, Jimmy Xiangji/0000-0003-1292-1491; Bhuiyan, Md Amran Hossen/0000-0002-2069-0753; Wang, Junmei/0000-0002-0804-4281	Natural Science and Engineering Research Council (NSERC) of Canada [RGPIN-2020-07157]; York Research Chairs (YRC) program; Ontario Research Fund-Research Excellence (ORF-RE) award from the BRAIN Alliance	Natural Science and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); York Research Chairs (YRC) program; Ontario Research Fund-Research Excellence (ORF-RE) award from the BRAIN Alliance	This research is supported by the research grant (RGPIN-2020-07157) from the Natural Science and Engineering Research Council (NSERC) of Canada, the York Research Chairs (YRC) program, and an Ontario Research Fund-Research Excellence (ORF-RE) award from the BRAIN Alliance.	Abolghasemi A, 2022, LECT NOTES COMPUT SC, V13186, P3, DOI 10.1007/978-3-030-99739-7_1; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'98, page, DOI DOI 10.1145/290941.291008; Babashzadeh A., 2023, HLTH INFORM SCI; BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014; Bai Y, 2020, Arxiv, DOI [arXiv:2010.00768, 10.48550/ARXIV.2010.00768, DOI 10.48550/ARXIV.2010.00768]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cer D, 2018, Arxiv, DOI arXiv:1803.11175; Chen Q, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P993, DOI 10.1145/3077136.3080699; Chowdhery A, 2023, J MACH LEARN RES, V24; Clark Kevin, 2020, P INT C LEARNING REP; Croft W. B., 2010, Search engines: information retrieval in practice, V520; Cui YM, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P657; Dai ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1533, DOI 10.1145/3397271.3401204; Dai ZY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1897, DOI 10.1145/3366423.3380258; Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303; Dai ZY, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P126, DOI 10.1145/3159652.3159659; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Dehghani M, 2017, Arxiv, DOI arXiv:1711.11383; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dietz L., 2017, P TEXT RETRIEVAL C T; Ding M., 2020, ADV NEUR IN, V33, P12792; Duta IC, 2016, INT WORK CONTENT MUL; Formal T, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2288, DOI 10.1145/3404835.3463098; Gaur M, 2022, AAAI CONF ARTIF INTE, P10672; Gharagozlou H, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7839840; Gong XY, 2020, Arxiv, DOI arXiv:2007.00080; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Guo JF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102067; Guo JF, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1297, DOI 10.1145/3331184.3331403; Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769; He B, 2011, INFORM SCIENCES, V181, P3017, DOI 10.1016/j.ins.2011.03.007; Hiemstra D., 2001, CTIT Ph.D. Thesis Series No. 01-32; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hofstätter S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2021, DOI 10.1145/3397271.3401224; Hofst„tter S, 2019, Arxiv, DOI arXiv:1912.01385; Hofst„tter S, 2020, Arxiv, DOI arXiv:2002.01854; Hofstätter S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1349, DOI 10.1145/3404835.3462889; Hofstätter S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P113, DOI 10.1145/3404835.3462891; Hu BT, 2014, ADV NEUR IN, V27; Huang J. X., 2005, TREC; Huang JX, 2013, INFORM PROCESS MANAG, V49, P441, DOI 10.1016/j.ipm.2012.08.002; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Huang XJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P307, DOI 10.1145/1571941.1571995; Huang XJ, 2003, INFORM RETRIEVAL, V6, P333, DOI 10.1023/A:1026028229881; Hui K, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P279, DOI 10.1145/3159652.3159689; Jahan I., 2022, P 22 WORKSH BIOM NAT, P326; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Kamalloo E, 2023, Arxiv, DOI arXiv:2305.06300; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Keyvan K, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3534965; Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lashkari AH, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P385, DOI 10.1109/ICIME.2009.101; Laskar M. T. R., 2020, P 12 LANG RES EV C; Laskar M. T. R., 2023, FINDINGS ASS COMPUTA, P431, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.29; Laskar MTR, 2022, COMPUT LINGUIST, V48, P279, DOI 10.1162/coli_a_00434; Laskar Md Tahmid Rahman., 2020, P 28 INT C COMPUTATI, P5647; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li CJ, 2021, Arxiv, DOI arXiv:2008.09093; Li MH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2347, DOI 10.1145/3477495.3531856; Li MH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2207, DOI 10.1145/3404835.3463083; Lin J., 2014, P 23 TEXT RETRIEVAL; Lin J., 2021, arXiv; Lin SC, 2020, Arxiv, DOI arXiv:2010.11386; Liu L., 2022, arXiv; Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038; Liu WJ, 2020, Arxiv, DOI arXiv:2004.02178; Liu Y, 2007, P ACM SIGIR C RES DE, P607, DOI [10.1145/1277741.1277845, DOI 10.1145/1277741.1277845]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu ZH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2531, DOI 10.1145/3404835.3462789; Lu WH, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2645, DOI 10.1145/3340531.3412747; Luan Y, 2021, T ASSOC COMPUT LING, V9, P329, DOI 10.1162/tacl_a_00369; Luo C, 2017, LECT NOTES COMPUT SC, V10538, P205, DOI 10.1007/978-3-319-68155-9_16; Lupu Mihai, 2009, SIGIR Forum, V43, P63, DOI 10.1145/1670564.1670576; Lupu M., 2009, P TEXT RETRIEVAL C T; MacAvaney S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1573, DOI 10.1145/3397271.3401262; MacAvaney S, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P529, DOI 10.1145/3397271.3401094; MacAvaney S, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P845, DOI 10.1145/3336191.3371864; MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317; MacDonald Craig, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P161, DOI 10.1145/3409256.3409829; Mallia A, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1723, DOI 10.1145/3404835.3463030; Manning C.D., 2008, Introduction to information retrieval; McCann Bryan, 2017, LEARNED TRANSLATION; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mitra B, 2017, Arxiv, DOI arXiv:1705.01509; Mitra B, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1291, DOI 10.1145/3038912.3052579; Naseri Shahrzad, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12656), P467, DOI 10.1007/978-3-030-72113-8_31; Nogueira R, 2019, Arxiv, DOI arXiv:1904.08375; Nogueira R, 2020, Arxiv, DOI [arXiv:1901.04085, DOI 10.48550/ARXIV.1901.04085]; Nogueira Rodrigo, 2019, Online Preprint, V6, P2; Onal KD, 2018, INFORM RETRIEVAL J, V21, P111, DOI 10.1007/s10791-017-9321-y; Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670; Padaki Ramith, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P297, DOI 10.1007/978-3-030-45442-5_37; Pan M, 2023, KNOWL-BASED SYST, V274, DOI 10.1016/j.knosys.2023.110602; Pan M, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102734; Pang L, 2016, AAAI CONF ARTIF INTE, P2793; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Punyani P, 2020, ARTIF INTELL REV, V53, P3299, DOI 10.1007/s10462-019-09765-w; Qin Z, 2024, Arxiv, DOI arXiv:2306.17563; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909; Shi P., 2019, arXiv; Sun WW, 2023, Arxiv, DOI arXiv:2304.09542; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Voorhees Ellen M., 2004, P 23 TEXT RETRIEVAL, P52; Wan S., 2016, P 25 INT JOINT C ART, P2922; Wan SX, 2016, AAAI CONF ARTIF INTE, P2835; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wang SY, 2021, INT C COMP SUPP COOP, P317, DOI [10.1109/CSCWD49262.2021.9437702, 10.1145/3471158.3472233]; Wang W, 2019, Arxiv, DOI arXiv:1908.04577; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Wu ZJ, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2421, DOI 10.1145/3366423.3380305; Xiao Wang, 2021, ICTIR '21: Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval, P297, DOI 10.1145/3471158.3472250; Xinyu Zhang, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P150, DOI 10.1007/978-3-030-72240-1_11; Xiong CY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/3077136.3080809; Xu P, 2019, Arxiv, DOI arXiv:1905.05910; Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5; Yan M., 2019, P TEXT RETRIEVAL C T; Yang PL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1253, DOI 10.1145/3077136.3080721; Yang W, 2019, Arxiv, DOI arXiv:1903.10972; Yang ZL, 2019, ADV NEUR IN, V32; Yates A, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1154, DOI 10.1145/3437963.3441667; Yates A, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P861, DOI 10.1145/3336191.3371868; Ye Z, 2011, J AM SOC INF SCI TEC, V62, P748, DOI 10.1002/asi.21501; Yilmaz Z. A., 2019, P C EMPIRICAL METHOD; Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P19; Yin XS, 2013, IEEE T KNOWL DATA EN, V25, P1201, DOI 10.1109/TKDE.2012.24; Yu H., 2021, arXiv; Zamani H, 2018, PROCEEDINGS OF THE 2018 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'18), P147, DOI 10.1145/3234944.3234968; Zamani H, 2018, ACM/SIGIR PROCEEDINGS 2018, P105, DOI 10.1145/3209978.3210041; Zhan JT, 2020, Arxiv, DOI arXiv:2006.15498; Zhang KT, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P474, DOI 10.1145/3366423.3380131; Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029; Zhao JS, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P155; Zhao JS, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2590988; Zheng Z, 2020, Arxiv, DOI arXiv:2009.07258; Zhu Runjie, 2020, Deep Learning for Data Analytics, P125, DOI [10.1016/B978-0-12-819764-6.00008-9, DOI 10.1016/B978-0-12-819764-6.0000]	155	1	1	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0360-0300	1557-7341		ACM COMPUT SURV	ACM Comput. Surv.	JUL	2024	56	7							185	10.1145/3648471	http://dx.doi.org/10.1145/3648471			33	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OQ7S3		Green Submitted			2024-07-03	WOS:001208811000024
J	Hurley, NC; Gupta, RK; Schroeder, KM; Hess, AS				Hurley, Nathan C.; Gupta, Rajnish K.; Schroeder, Kristopher M.; Hess, Aaron S.			Danger, Danger, Gaston Labat! Does zero-shot artificial intelligence correlate with anticoagulation guidelines recommendations for neuraxial anesthesia?	REGIONAL ANESTHESIA AND PAIN MEDICINE			English	Article; Early Access						Anticoagulation; Nerve Block; Pain Management; TECHNOLOGY	DIABETIC-RETINOPATHY; REGIONAL ANESTHESIA; VALIDATION	IntroductionArtificial intelligence and large language models (LLMs) have emerged as potentially disruptive technologies in healthcare. In this study GPT-3.5, an accessible LLM, was assessed for its accuracy and reliability in performing guideline-based evaluation of neuraxial bleeding risk in hypothetical patients on anticoagulation medication. The study also explored the impact of structured prompt guidance on the LLM's performance.MethodsA dataset of 10 hypothetical patient stems and 26 anticoagulation profiles (260 unique combinations) was developed based on American Society of Regional Anesthesia and Pain Medicine guidelines. Five prompts were created for the LLM, ranging from minimal guidance to explicit instructions. The model's responses were compared with a "truth table" based on the guidelines. Performance metrics, including accuracy and area under the receiver operating curve (AUC), were used.ResultsBaseline performance of GPT-3.5 was slightly above chance. With detailed prompts and explicit guidelines, performance improved significantly (AUC 0.70, 95% CI (0.64 to 0.77)). Performance varied among medication classes.DiscussionLLMs show potential for assisting in clinical decision making but rely on accurate and relevant prompts. Integration of LLMs should consider safety and privacy concerns. Further research is needed to optimize LLM performance and address complex scenarios. The tested LLM demonstrates potential in assessing neuraxial bleeding risk but relies on precise prompts. LLM integration should be approached cautiously, considering limitations. Future research should focus on optimization and understanding LLM capabilities and limitations in healthcare.	[Hurley, Nathan C.; Hess, Aaron S.] Univ Wisconsin Madison, Dept Anesthesiol, Madison, WI 53706 USA; [Gupta, Rajnish K.] Vanderbilt Univ Sch Med, Anesthesiol, Nashville, TN USA; [Schroeder, Kristopher M.] Univ Wisconsin Madison, Anesthesiol, Madison, WI USA; [Hess, Aaron S.] Univ Wisconsin Madison, Dept Pathol & Lab Med, Madison, WI USA	University of Wisconsin System; University of Wisconsin Madison; Vanderbilt University; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison	Hess, AS (corresponding author), Univ Wisconsin Madison, Dept Anesthesiol, Madison, WI 53706 USA.	ahess5@wisc.edu		Gupta, Rajnish/0000-0003-3401-4737				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bornmann L, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00903-w; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen X, 2021, J CARDIOTHOR VASC AN, V35, P251, DOI 10.1053/j.jvca.2020.08.048; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; De Cassai A, 2024, REGION ANESTH PAIN M, V49, P378, DOI 10.1136/rapm-2023-104771; Grauslund J, 2022, DIABETOLOGIA, V65, P1415, DOI 10.1007/s00125-022-05727-0; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Gupta RK, 2021, REGION ANESTH PAIN M, V46, P354, DOI 10.1136/rapm-2020-101921; Hashimoto DA, 2020, ANESTHESIOLOGY, V132, P379, DOI 10.1097/ALN.0000000000002960; Horlocker T.T., 2019, Obstet. Anesth. Dig, V39, P28, DOI [10.1097/01.aoa.0000552901.03545.fb, DOI 10.1097/01.AOA.0000552901.03545.FB]; Hurley NC, 2023, TRANSFUSION, V63, P1833, DOI 10.1111/trf.17526; Ibrahim A, 2020, BREAST, V49, P267, DOI 10.1016/j.breast.2019.12.007; Kietaibl S, 2022, EUR J ANAESTH, V39, P100, DOI 10.1097/EJA.0000000000001600; Lee S, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.17636; Lloyd J, 2022, ADV EXP MED BIOL, V1356, P117, DOI 10.1007/978-3-030-87779-8_6; Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0; Powers DMW, 2020, Arxiv, DOI [arXiv:2010.16061, DOI 10.48550/ARXIV.2010.16061]; Mathis MR, 2018, ANESTHESIOLOGY, V129, P619, DOI 10.1097/ALN.0000000000002384; Myszewski J, 2022, REGION ANESTH PAIN M, V47, P151, DOI 10.1136/rapm-2021-103261; Narouze S, 2018, REGION ANESTH PAIN M, V43, P225, DOI 10.1097/AAP.0000000000000700; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Schroeder DR, 1998, REGION ANESTH PAIN M, V23, P183, DOI 10.1016/S1098-7339(98)90145-6; Sechopoulos I, 2021, SEMIN CANCER BIOL, V72, P214, DOI 10.1016/j.semcancer.2020.06.002; Smistad E, 2021, IEEE INT ULTRA SYM, DOI 10.1109/IUS52206.2021.9593525; Tagliafico AS, 2020, BREAST, V49, P74, DOI 10.1016/j.breast.2019.10.018; Tavolara TE, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104737; Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152; Tran WT, 2021, CAN ASSOC RADIOL J, V72, P98, DOI 10.1177/0846537120949974; Tryba M, 1993, Anasthesiol Intensivmed Notfallmed Schmerzther, V28, P179, DOI 10.1055/s-2007-998902; Wijnberge M, 2020, JAMA-J AM MED ASSOC, V323, P1052, DOI 10.1001/jama.2020.0592; Wu CL, 2023, REGION ANESTH PAIN M, DOI 10.1136/rapm-2023-104646	32	2	2	11	11	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1098-7339	1532-8651		REGION ANESTH PAIN M	Region. Anesth. Pain Med.	2024 JAN 22	2024										10.1136/rapm-2023-104868	http://dx.doi.org/10.1136/rapm-2023-104868		JAN 2024	7	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	FU6Y3	38253610				2024-07-03	WOS:001148419600001
C	Nardini, FM; Rulli, C; Venturini, R		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Nardini, Franco Maria; Rulli, Cosimo; Venturini, Rossano			Efficient Multi-vector Dense Retrieval with Bit Vectors	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Dense Retrieval; Multi-vector; Efficiency; Bit Vectors		Dense retrieval techniques employ pre-trained large language models to build a high-dimensional representation of queries and passages. These representations compute the relevance of a passage w.r.t. to a query using efficient similarity measures. In this line, multi-vector representations show improved effectiveness at the expense of a one-order-of-magnitude increase in memory footprint and query latency by encoding queries and documents on a per-token level. Recently, PLAID has tackled these problems by introducing a centroid-based term representation to reduce the memory impact of multi-vector systems. By exploiting a centroid interaction mechanism, PLAID filters out non-relevant documents, thus reducing the cost of the successive ranking stages. This paper proposes "Efficient Multi-Vector dense retrieval with Bit vectors" (EMVB), a novel framework for efficient query processing in multi-vector dense retrieval. First, EMVB employs a highly efficient pre-filtering step of passages using optimized bit vectors. Second, the computation of the centroid interaction happens column-wise, exploiting SIMD instructions, thus reducing its latency. Third, EMVB leverages Product Quantization (PQ) to reduce the memory footprint of storing vector representations while jointly allowing for fast late interaction. Fourth, we introduce a per-document term filtering method that further improves the efficiency of the last step. Experiments on MS MARCO and LoTTE show that EMVB is up to 2.8x faster while reducing the memory footprint by 1.8x with no loss in retrieval accuracy compared to PLAID.	[Nardini, Franco Maria; Rulli, Cosimo] CNR, ISTI, Pisa, Italy; [Venturini, Rossano] Univ Pisa, Pisa, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); University of Pisa	Rulli, C (corresponding author), CNR, ISTI, Pisa, Italy.	francomaria.nardini@isti.cnr.it; cosimo.rulli@isti.cnr.it; rossano.venturini@unipi.it		Rulli, Cosimo/0000-0003-0194-361X	EU [PE00000013]; European Commission under the NextGeneration EU program [PNRR ECS00000017]; European Commission under the NextGeneration EU programme; Horizon Europe RIA [101093026]; Combinatorics for Machine Learning" (MIUR-PRIN); "Algorithmic Problems and Machine Learning" (MIUR-PRIN) [2022]	EU(European Union (EU)); European Commission under the NextGeneration EU program; European Commission under the NextGeneration EU programme; Horizon Europe RIA; Combinatorics for Machine Learning" (MIUR-PRIN); "Algorithmic Problems and Machine Learning" (MIUR-PRIN)(Ministry of Education, Universities and Research (MIUR))	This work was partially supported by the EU - NGEU, by the PNRR - M4C2 - Investimento 1.3, Partenariato Esteso PE00000013 - "FAIR - Future Artificial Intelligence Research" - Spoke 1 "Human-centered AI" funded by the European Commission under the NextGeneration EU program, by the PNRR ECS00000017 Tuscany Health Ecosystem Spoke 6 "Precision medicine & personalized healthcare", by the European Commission under the NextGeneration EU programme, by the Horizon Europe RIA "Extreme Food Risk Analytics" (EFRA), grant agreement n. 101093026, by the "Algorithms, Data Structures and Combinatorics for Machine Learning" (MIUR-PRIN 2017), and by the "Algorithmic Problems and Machine Learning" (MIUR-PRIN 2022).	[Anonymous], 2004, P 2004 ACM S APPL CO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bruch S, 2023, FOUND TRENDS INF RET, V17, P1, DOI 10.1561/1500000071; Dai DM, 2022, Arxiv, DOI arXiv:2212.10559; Deng HW, 2014, PROC SPIE, V9247, DOI 10.1117/12.2064087; Devlin J., 2019, P NAACLHLT; Fang Y, 2022, LECT NOTES ARTIF INT, V13551, P631, DOI 10.1007/978-3-031-17120-8_49; Formal T, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2288, DOI 10.1145/3404835.3463098; Gao LY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3030; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Guu K, 2020, PR MACH LEARN RES, V119; Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khattab O, 2021, ADV NEUR IN, V34; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Lemire D., 2023, AVX-512: when and how to use these new instructions; Nguyen DHN, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510844; Santhanam K, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P1747, DOI 10.1145/3511808.3557325; Wang X, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P12688; Wang X, 2023, ACM T WEB, V17, DOI 10.1145/3572405; Xiong Lee, 2021, INT C LEARNING REPRE; Zhan JT, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1328, DOI 10.1145/3488560.3498443; Zhan JT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1503, DOI 10.1145/3404835.3462880; Zhihao Li M.S.A., 2022, ARXIV	25	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						3	17		10.1007/978-3-031-56060-6_1	http://dx.doi.org/10.1007/978-3-031-56060-6_1			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY					2024-07-03	WOS:001211832000001
C	Hu, YS; Hua, H; Yang, ZY; Shi, WJ; Smith, NA; Luo, JB			IEEE	Hu, Yushi; Hua, Hang; Yang, Zhengyuan; Shi, Weijia; Smith, Noah A.; Luo, Jiebo			PROMPTCAP: Prompt-Guided Image Captioning for VQA with GPT-3	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION, ICCV	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Knowledge-based visual question answering (VQA) involves questions that require world knowledge beyond the image to yield the correct answer. Large language models (LMs) like GPT-3 are particularly helpful for this task because of their strong knowledge retrieval and reasoning capabilities. To enable LM to understand images, prior work uses a captioning model to convert images into text. However, when summarizing an image in a single caption sentence, which visual entities to describe are often underspecified. Generic image captions often miss visual details essential for the LM to answer visual questions correctly. To address this challenge, we propose PROMPTCAP (Prompt-guided image Captioning), a captioning model designed to serve as a better connector between images and black-box LMs. Different from generic captions, PROMPTCAP takes a naturallanguage prompt to control the visual entities to describe in the generated caption. The prompt contains a question that the caption should aid in answering. To avoid extra annotation, PROMPTCAP is trained by examples synthesized with GPT-3 and existing datasets. We demonstrate PROMPT-CAP's effectiveness on an existing pipeline in which GPT-3 is prompted with image captions to carry out VQA. PROMPT-CAP outperforms generic captions by a large margin and achieves state-of-the-art accuracy on knowledge-based VQA tasks (60.4% on OK-VQA and 59.6% on A-OKVQA). Zeroshot results on WebQA show that PROMPTCAP generalizes well to unseen domains.(1)	[Hu, Yushi; Shi, Weijia; Smith, Noah A.] Univ Washington, Seattle, WA 98195 USA; [Hua, Hang; Luo, Jiebo] Univ Rochester, Rochester, NY 14627 USA; [Yang, Zhengyuan] Microsoft, Redmond, WA USA; [Smith, Noah A.] Allen Inst AI, Seattle, WA USA	University of Washington; University of Washington Seattle; University of Rochester; Microsoft	Hu, YS (corresponding author), Univ Washington, Seattle, WA 98195 USA.; Hua, H (corresponding author), Univ Rochester, Rochester, NY 14627 USA.	yushihu@uw.edu; hhua2@cs.rochester.edu						Alayrac J.-B., 2022, Flamingo: a visual language model for few-shot learning, V35, P23716; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; [Anonymous], 2020, P 28 ACM INT C MULT, DOI DOI 10.1145/3394171.3413943; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang Yingshan, 2022, 2022 IEEE CVF C COMP; Chen X, 2015, IET RADAR SONAR NAV, V9, P1, DOI 10.1049/iet-rsn.2014.0037; Chen Yen-Chun, 2020, ECCV; Cheng Zhoujun, 2022, ARXIV221002875; Chung Hyung Won, 2022, ABS221011416 ARXIV; Gao F, 2022, PROC CVPR IEEE, P5057, DOI 10.1109/CVPR52688.2022.00501; Gardères F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P489; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Gui LK, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P956; Hu C.-H., 2022, FINDINGS ASS COMPUTA, P2627; Izacard Gautier, 2020, LEVERAGING PASSAGE R; Izacard Gautier, 2020, ARXIV201204584; Jiang Yu, 2018, arXiv; Kamath Amita, 2022, ARXIV220202317; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kim W, 2021, PR MACH LEARN RES, V139; Kingma D. P., 2017, ARXIV; Lee CH, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4937; Li Junnan, 2023, ABS230112597 ARXIV; Li X., 2020, EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin Yuanze, 2022, ABS220601201 ARXIV; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154; Liu Pengfei, 2021, arXiv; Lu JS, 2019, ADV NEUR IN, V32; Lu Jiasen, 2022, ABS220608916 ARXIV; Luo Man, 2021, P 2021 C EMP METH NA; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Marino Kenneth, 2019, 2019 IEEE CVF C COMP; Min SW, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2791; Narasimhan M, 2018, ADV NEUR IN, V31; Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radford A, 2021, PR MACH LEARN RES, V139; Rubin Ohad, 2022, P 2022 C N AM CHAPT; Sanh Victor, 2021, ABS211008207 CORR; Schwenk Dustin, 2022, OKVQA BENCH MARK VIS; Sennrich Rico, 2015, ARXIV PREPRINT ARXIV; Shi Weijia, 2023, ABS230112652 ARXIV; Shi Weijia, 2022, ARXIV220513792; Shi ZP, 2022, SURF REV LETT, DOI 10.1142/S0218625X22400029; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710; Suhr A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6418; Tan Hao Hao, 2019, ABS190807490 ARXIV; Tsimpoukelli Maria, 2021, Multimodal few-shot learning with frozen language models, P2; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang Jianfeng, 2022, ARXIV220514100; Wang Peng, 2022, ABS220203052 CORR; Wang Yizhong, 2022, C EMP METH NAT LANG; Wang Zirui, 2021, Simvlm: Simple visual language model pretraining with weak supervision; Wei Jason, 2021, arXiv preprint arXiv:2109.01652; Wu JL, 2022, AAAI CONF ARTIF INTE, P2712; Xie Tianbao, 2022, ARXIV220105966; Xie Yujia, 2022, ARXIV220601843; Yang ZY, 2022, LECT NOTES COMPUT SC, V13696, P521, DOI 10.1007/978-3-031-20059-5_30; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yuan Lu, 2021, ARXIV211111432; Yuan W., 2021, Advances in Neural Information Processing Systems, P27263; Zeng Andy, 2022, ARXIV220400598; Zhang HM, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P201, DOI 10.1145/3366423.3380107; Zhao QY, 2022, HSCC 2022: PROCEEDINGS OF THE 25TH ACM INTERNATIONAL CONFERENCE ON HYBRID SYSTEMS: COMPUTATION AND CONTROL (PART OF CPS-IOT WEEK 2022), DOI 10.1145/3501710.3519511; Zhu Z., 2020, ARXIV200609073	72	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							2951	2963		10.1109/ICCV51070.2023.00277	http://dx.doi.org/10.1109/ICCV51070.2023.00277			13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5FA					2024-07-03	WOS:001159644303020
J	Rosen, J; Lindblom, J; Lamb, M; Billing, E				Rosen, Julia; Lindblom, Jessica; Lamb, Maurice; Billing, Erik			Previous Experience Matters: An in-Person Investigation of Expectations in Human-Robot Interaction	INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS			English	Article						Expectations; Previous experience; Social robot; Human-robot interaction; Experiment; Expectation gap; Pepper; GPT; Large language models	PERCEPTION	The human-robot interaction (HRI) field goes beyond the mere technical aspects of developing robots, often investigating how humans perceive robots. Human perceptions and behavior are determined, in part, by expectations. Given the impact of expectations on behavior, it is important to understand what expectations individuals bring into HRI settings and how those expectations may affect their interactions with the robot over time. For many people, social robots are not a common part of their experiences, thus any expectations they have of social robots are likely shaped by other sources. As a result, individual expectations coming into HRI settings may be highly variable. Although there has been some recent interest in expectations within the field, there is an overall lack of empirical investigation into its impacts on HRI, especially in-person robot interactions. To this end, a within-subject in-person study (N=31\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$N=31$$\end{document}) was performed where participants were instructed to engage in open conversation with the social robot Pepper during two 2.5 min sessions. The robot was equipped with a custom dialogue system based on the GPT-3 large language model, allowing autonomous responses to verbal input. Participants' affective changes towards the robot were assessed using three questionnaires, NARS, RAS, commonly used in HRI studies, and Closeness, based on the IOS scale. In addition to the three standard questionnaires, a custom question was administered to capture participants' views on robot capabilities. All measures were collected three times, before the interaction with the robot, after the first interaction with the robot, and after the second interaction with the robot. Results revealed that participants to large degrees stayed with the expectations they had coming into the study, and in contrast to our hypothesis, none of the measured scales moved towards a common mean. Moreover, previous experience with robots was revealed to be a major factor of how participants experienced the robot in the study. These results could be interpreted as implying that expectations of robots are to large degrees decided before interactions with the robot, and that these expectations do not necessarily change as a result of the interaction. Results reveal a strong connection to how expectations are studied in social psychology and human-human interaction, underpinning its relevance for HRI research.	[Rosen, Julia; Lindblom, Jessica; Lamb, Maurice; Billing, Erik] Univ Skovde, Sch Informat, Hogskolevagen 1, S-54128 Skovde, Sweden; [Lindblom, Jessica] Uppsala Univ, Dept Informat Technol, Lagerhyddsvagen 1, SE-75237 Uppsala, Sweden	University of Skovde; Uppsala University	Rosen, J (corresponding author), Univ Skovde, Sch Informat, Hogskolevagen 1, S-54128 Skovde, Sweden.	julia.rosen@his.se; jessica.lindblom@it.uu.se; maurice.lamb@his.se; erik.billing@his.se		Rosen, Julia/0000-0001-8642-336X	University of Skvde; Knowledge Foundation; Strategic Knowledge Reinforcement initiative	University of Skvde; Knowledge Foundation; Strategic Knowledge Reinforcement initiative	This work was partially supported through the Knowledge Foundation as a part of both the Recruitment and Strategic Knowledge Reinforcement initiative.	Alac M, 2016, AI SOC, V31, P519, DOI 10.1007/s00146-015-0631-6; Aldebaran, US; Allan DD, 2022, INT J SOC ROBOT, V14, P127, DOI 10.1007/s12369-021-00767-9; [Anonymous], OpenAI; ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596; Berzuk JM, 2023, COMPANION OF THE ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI 2023, P231, DOI 10.1145/3568294.3580078; Billing E, 2023, COMPANION 2023 ACMIE; Borg MB, 2010, PSYCHOL EMOT MOTIV A, P1; Braun V, 2021, QUAL RES PSYCHOL, V18, P328, DOI 10.1080/14780887.2020.1769238; Dautenhahn K, 2018, ACM T HUM-ROBOT INTE, V7, DOI 10.1145/3209769; Edwards A, 2019, COMPUT HUM BEHAV, V90, P308, DOI 10.1016/j.chb.2018.08.042; Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X; Gächter S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129478; Horstmann AC, 2020, ACMIEEE INT CONF HUM, P254, DOI 10.1145/3371382.3378292; Horstmann AC, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0238133; Horstmann AC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00939; Jokinen K, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P511, DOI 10.1145/3125739.3132610; Kahn PH, 2011, ACMIEEE INT CONF HUM, P159, DOI 10.1145/1957656.1957710; Kwon M, 2016, ACMIEEE INT CONF HUM, P463, DOI 10.1109/HRI.2016.7451807; Lindblom J., 2020, HUMAN ROBOT INTERACT, P231, DOI [DOI 10.1007/978, 10.1007/978-3-030-42307-0_9, DOI 10.1007/978-3-030-42307-0_9]; Lindblom J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154284; Lohse M, 2009, NEW FRONTIERS HUMAN, P35; Lohse M., 2011, Proceedings of the 20th IEEE Int. Symp. on Robot and Human Interactive Communication (Ro-Man), P485, DOI [10.1109/ROMAN.2011.6005252, DOI 10.1109/ROMAN.2011.6005252]; Manzi F, 2021, CYBERPSYCH BEH SOC N, V24, P307, DOI 10.1089/cyber.2020.0162; Meister M., 2014, Science, Technology Innovation Studies, V10, P107; Moore, 2019, ARXIV; Moore Roger K., 2017, DIALOGUES SOCIAL ROB, V427, P281, DOI [10.1007/978-981-10-2585-3_22, DOI 10.1007/978-981-10-2585-3_22]; Nomura T, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P35, DOI 10.1109/ROMAN.2004.1374726; Nomura T., 2006, ROMAN 2006 15 IEEE I, DOI DOI 10.1109/ROMAN.2006.314462; Olson J.M., 1996, SOC PSYCHOL-GERMANY, P211; Paetzel M, 2020, ACMIEEE INT CONF HUM, P73, DOI 10.1145/3319502.3374786; Roese N.J., 2007, Social psychology: handbook of basic principles, V2nd; Rosen Julia, 2021, Advances in Neuroergonomics and Cognitive Engineering. Proceedings of the AHFE 2021 Virtual Conferences on Neuroergonomics and Cognitive Engineering, Industrial Cognitive Ergonomics and Engineering Psychology, and Cognitive Computing and Internet of Things. Lecture Notes in Networks and Systems (LNNS 259), P98, DOI 10.1007/978-3-030-80285-1_12; Rosén J, 2022, LECT NOTES COMPUT SC, V13303, P590, DOI 10.1007/978-3-031-05409-9_43; Sandoval EB, 2014, LECT NOTES ARTIF INT, V8755, P54, DOI 10.1007/978-3-319-11973-1_6; Schramm LT, 2020, ACMIEEE INT CONF HUM, P439, DOI 10.1145/3371382.3378280; Wallkötter S, 2020, ACMIEEE INT CONF HUM, P609, DOI 10.1145/3319502.3374800; Yogeeswaran K, 2016, J HUM-ROBOT INTERACT, V5, P29, DOI 10.5898/JHRI.5.2.Yogeeswaran	38	0	0	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1875-4791	1875-4805		INT J SOC ROBOT	Int. J. Soc. Robot.	MAR	2024	16	3					447	460		10.1007/s12369-024-01107-3	http://dx.doi.org/10.1007/s12369-024-01107-3		FEB 2024	14	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	SK8I8		hybrid			2024-07-03	WOS:001172192700001
J	Hristidis, V; Ruggiano, N; Brown, EL; Ganta, SRR; Stewart, S				Hristidis, Vagelis; Ruggiano, Nicole; Brown, Ellen L.; Ganta, Sai Rithesh Reddy; Stewart, Selena			ChatGPT vs Google for Queries Related to Dementia and Other Cognitive Decline: Comparison of Results	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						chatbots; large language models; ChatGPT; web search; language model; Google; aging; cognitive; cognition; dementia; gerontology; geriatric; geriatrics; query; queries; information seeking; search	ALZHEIMERS-DISEASE; CAREGIVERS; INTERNET	Background: People living with dementia or other cognitive decline and their caregivers (PLWD) increasingly rely on the web to find information about their condition and available resources and services. The recent advancements in large language models (LLMs), such as ChatGPT, provide a new alternative to the more traditional web search engines, such as Google. Objective: This study compared the quality of the results of ChatGPT and Google for a collection of PLWD-related queries. Methods: A set of 30 informational and 30 service delivery (transactional) PLWD-related queries were selected and submitted to both Google and ChatGPT. Three domain experts assessed the results for their currency of information, reliability of the source, objectivity, relevance to the query, and similarity of their response. The readability of the results was also analyzed. Interrater reliability coefficients were calculated for all outcomes. Results: Google had superior currency and higher reliability. ChatGPT results were evaluated as more objective. ChatGPT had a significantly higher response relevance, while Google often drew upon sources that were referral services for dementia care or service providers themselves. The readability was low for both platforms, especially for ChatGPT (mean grade level 12.17, SD 1.94) compared to Google (mean grade level 9.86, SD 3.47). The similarity between the content of ChatGPT and Google responses was rated as high for 13 (21.7%) responses, medium for 16 (26.7%) responses, and low for 31 (51.6%) responses. Conclusions: Both Google and ChatGPT have strengths and weaknesses. ChatGPT rarely includes the source of a result. Google more often provides a date for and a known reliable source of the response compared to ChatGPT, whereas ChatGPT supplies more relevant responses to queries. The results of ChatGPT may be out of date and often do not specify a validity time stamp. Google sometimes returns results based on commercial entities. The readability scores for both indicate that responses are often not appropriate for persons with low health literacy skills. In the future, the addition of both the source and the date of health-related information and availability in other languages may increase the value of these platforms for both nonmedical and medical professionals.	[Hristidis, Vagelis; Ganta, Sai Rithesh Reddy] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA USA; [Ruggiano, Nicole; Stewart, Selena] Univ Alabama, Sch Social Work, Tuscaloosa, AL USA; [Brown, Ellen L.] Florida Int Univ, Nicole Wertheim Coll Nursing & Hlth Sci, Miami, FL USA; [Hristidis, Vagelis] Univ Calif Riverside, Dept Comp Sci & Engn, Winston Chung Hall,Room 317, Riverside, CA 92521 USA	University of California System; University of California Riverside; University of Alabama System; University of Alabama Tuscaloosa; State University System of Florida; Florida International University; University of California System; University of California Riverside	Hristidis, V (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Winston Chung Hall,Room 317, Riverside, CA 92521 USA.	vagelis@cs.ucr.edu		Ganta, Sai Rithesh Reddy/0009-0006-3445-7561; Christidis, Evangelos/0000-0001-8905-2832				Abner EL, 2016, J RURAL HEALTH, V32, P314, DOI 10.1111/jrh.12155; Agronin M, 2015, DEMENTIA CAREGIVER G; [Anonymous], FINDING DEMENTIA CAR; [Anonymous], WELCOME CHATGPT; Bangerter Lauren R, 2019, JMIR Aging, V2, pe11237, DOI 10.2196/11237; Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carpenter BD, 2009, GERONTOLOGIST, V49, P236, DOI 10.1093/geront/gnp023; Chirico I, 2022, INT J GERIATR PSYCH, V37, DOI 10.1002/gps.5801; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dixon E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517554; Dixon E, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445225; Efthymiou A, 2022, HEALTH SOC CARE COMM, V30, P1109, DOI 10.1111/hsc.13341; Esteve A, 2017, INT DATA PRIV LAW, V7, P36, DOI 10.1093/idpl/ipw026; Flesch R., 1981, How to write plain English: A book for lawyers; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Ganta SRR, 2023, GOOGLE DOCS; Introducing ChatGPT, 2022, OpenAI.; Jackson DN, 2021, HEALTH COMMUN, V36, P1155, DOI 10.1080/10410236.2020.1748828; Jiménez S, 2022, LECT NOTE NETW SYST, V468, P336, DOI 10.1007/978-3-031-04826-5_33; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kaufman AV, 2010, J GERONTOL SOC WORK, V53, P251, DOI 10.1080/01634370903478989; Kim H, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01708-9; Lee K, 2014, J MED INTERNET RES, V16, P190, DOI 10.2196/jmir.3706; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Levene M, 2010, COMPUT J, V54, P831, DOI [10.1093/comjnl/bxq039, DOI 10.1093/COMJNL/BXQ039]; Lewandowski D, 2019, ASLIB J INFORM MANAG, V71, P310, DOI 10.1108/AJIM-07-2018-0172; Morley J, 2020, SOC SCI MED, V260, DOI 10.1016/j.socscimed.2020.113172; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Ruggiano N, 2023, AGENCY HEALTHCARE RE; Ruggiano Nicole, 2021, J Med Internet Res, V23, pe25006, DOI 10.2196/25006; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Savla J, 2023, J APPL GERONTOL, V42, P821, DOI 10.1177/07334648221147916; Surabhi S, 2020, INT J ADV SCI TECH, V29, P6582; Waltz C.F., 2010, MEASUREMENT NURSING, V4th; Wolff JL, 2016, J GEN INTERN MED, V31, P117, DOI 10.1007/s11606-015-3494-0; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5; Zhu Yunshu, 2021, Stud Health Technol Inform, V284, P374, DOI 10.3233/SHTI210750	39	9	10	9	38	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JUL 25	2023	25								e48966	10.2196/48966	http://dx.doi.org/10.2196/48966			13	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	P1EL8	37490317	gold, Green Published			2024-07-03	WOS:001048138200005
C	Fioravanti, S; Zugarini, A; Giannini, F; Rigutini, L; Maggini, M; Diligenti, M			IEEE	Fioravanti, Stefano; Zugarini, Andrea; Giannini, Francesco; Rigutini, Leonardo; Maggini, Marco; Diligenti, Michelangelo			Linguistic Feature Injection for Efficient Natural Language Processing	2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUN 18-23, 2023	Broadbeach, AUSTRALIA	Int Neural Network Soc, IEEE Computat Intelligence Soc				Transformers have been established as one of the most effective neural approach in performing various Natural Language Processing tasks. However, following common trend in modern deep architectures, their scale has quickly grown to an extent that reduces the concrete possibility for several enterprises to train such models from scratch. Indeed, despite their high-level performances, Transformers have the general drawback of requiring a huge amount of training data, computational resources and energy consumption to be successfully optimized. For this reason, more recent architectures like Bidirectional Encoder Representations from Transformers rely on unlabeled data to pre-train the model, which is later fine-tuned for a specific downstream task using a relatively smaller amount of training data. In a similar fashion, this paper considers a plug-and-play framework that can be used to inject multiple syntactic features, like Part-of-Speech Tagging or Dependency Parsing, into any kind of pre-trained Transformer. This novel approach allows to perform sequence-to-sequence labeling tasks by exploiting: (i) the (more abundant) available training data that is also used to learn the syntactic features, (ii) the language data that is used to pre-train the transformer model. The experimental results show that our approach improves over the baseline performances of the underlying model in different datasets, thus proving the effectiveness of employing syntactic language information for semantic regularization. In addition, we show that our architecture has a huge efficiency advantage over pure large language models. Indeed, by using a model with limited size, but whose input data are enriched with syntactic information, we show that it is possible to obtain a significant reduction of CO2 emissions without decreasing the prediction performances.	[Fioravanti, Stefano; Giannini, Francesco; Maggini, Marco; Diligenti, Michelangelo] Univ Siena, DIISM, Siena, Italy; [Zugarini, Andrea; Rigutini, Leonardo] Expert Ai, R&D, Siena, Italy	University of Siena	Fioravanti, S (corresponding author), Univ Siena, DIISM, Siena, Italy.	stefano.fioravanti66@gmail.com; azugarini@expert.ai; francesco.giannini@unisi.it; lrigutini@expert.ai; maggini@unisi.it; diligenti@unisi.it	Rigutini, Leonardo/AFB-7238-2022	Rigutini, Leonardo/0000-0002-6309-2542	EU [952215, 952026]; European Union [101073307]; Marie Curie Actions (MSCA) [101073307] Funding Source: Marie Curie Actions (MSCA)	EU(European Union (EU)); European Union(European Union (EU)); Marie Curie Actions (MSCA)(Marie Curie Actions)	This work was supported by TAILOR and by HumanE-AI-Net, projects funded by EU Horizon 2020 research and innovation programme under GA No 952215 and No 952026, respectively. This project has also received funding from the European Union's Horizon-MSCA-2021 research and innovation program under grant agreement No 101073307.	Bai J., 2021, C EUR CHAPT ASS COMP; Beltagy I., 2020, ARXIV PREPRINT ARXIV, V2004, P05150, DOI DOI 10.48550/ARXIV.2004.05150; Derczynski L., 2017, PROC 3 WORKSHOP NOIS, P140, DOI [10.18653/v1/W17-4418,eprint:https://aclanthology.org/W17-4418.pdf, 10.18653/v1/w17-4418]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding X., 2022, P 29 INT C COMP LING, P3210; Gee L., 2022, P 2022 C EMP METH NA; He P, 2020, ICLR; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hinton G., 2015, ARXIV; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; JiapengWang Lianwen Jin, 2022, ARXIV220213669; LACOSTE A., 2019, Quantifying the carbon emissions of machine learning; Li J., 2016, DATABASE J BIOL DATA, V2016; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Y., 2019, CoRR abs/1907.11692; Lottick K., 2019, WORKSH TACKL CLIM CH; Michel P, 2019, ADV NEUR IN, V32; Nguyen Xuan-Phi, 2020, ICLR; Roberts Adam, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer; Sachan D. S., 2020, C EUR CHAPT ASS COMP; Sanh Victor, 2019, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815; Shen Yanyao, 2017, ICLR; Strauss B, 2016, P 2 WORKSH NOIS US G, P138, DOI DOI 10.19346/V1/W16-2381; Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027; Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556; Vaswani A, 2017, ADV NEUR IN, V30; Wang W., 2020, P 34 INT C NEURAL IN, V33, P5776; Xu Y, 2015, P 2015 C EMPIRICAL M, P1785; Yang Y, 2016, AAAI CONF ARTIF INTE, P65; Zanzotto FM, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P256; Zhu M., 2017, ARXIV171001878	33	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-6654-8867-9	IEEE IJCNN			2023										10.1109/IJCNN54540.2023.10191680	http://dx.doi.org/10.1109/IJCNN54540.2023.10191680			7	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BV5BH					2024-07-03	WOS:001046198705007
C	Reeves, B; Sarsa, S; Prather, J; Denny, P; Becker, BA; Hellas, A; Kimmel, B; Powell, G; Leinonen, J			ACM	Reeves, Brent; Sarsa, Sami; Prather, James; Denny, Paul; Becker, Brett A.; Hellas, Arto; Kimmel, Bailey; Powell, Garrett; Leinonen, Juho			Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations	PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1			English	Proceedings Paper	28th Annual Conference on Innovation and Technology in Computer Science Education (ITiCSE)	JUL 08-12, 2023	Univ Turku, Turku, FINLAND	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ, ACM Europe Council, Informat Europe	Univ Turku	academic integrity; AI; artificial intelligence; ChatGPT; code generation; code writing; Codex; computer programming; Copilot; CS1; deep learning; generative AI; introductory programming; GitHub; GPT-3; large language models; machine learning; ML; neural networks; natural language processing; novice programming; OpenAI		The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.	[Reeves, Brent; Prather, James; Kimmel, Bailey; Powell, Garrett] Abilene Christian Univ, Abilene, TX 79699 USA; [Sarsa, Sami; Hellas, Arto] Aalto Univ, Espoo, Finland; [Denny, Paul; Leinonen, Juho] Univ Auckland, Auckland, New Zealand; [Becker, Brett A.] Univ Coll Dublin, Dublin, Ireland	Abilene Christian University; Aalto University; University of Auckland; University College Dublin	Reeves, B (corresponding author), Abilene Christian Univ, Abilene, TX 79699 USA.	brent.reeves@acu.edu; sami.sarsa@aalto.fi; james.prather@acu.edu; paul@cs.auckland.ac.nz; brett.becker@ucd.ie; arto.hellas@aalto.fi; blk20c@acu.edu; gbp18a@acu.edu; juho.leinonen@auckland.ac.nz	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449; Denny, Paul/0000-0002-5150-9806; Powell, Garrett/0000-0002-3221-7015; Prather, James/0000-0003-2807-6042; Reeves, Brent/0000-0001-5781-1136; Kimmel, Bailey/0009-0000-6655-0564				[Anonymous], 2016, P 47 ACM TECHNICAL S, DOI DOI 10.1145/2839509.2844617; [Anonymous], 2008, P 4 INT WORKSHOP COM, DOI DOI 10.1145/1404520.1404532; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Cheng N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P123, DOI 10.1145/3017680.3017704; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny P, 2022, Arxiv, DOI [arXiv:2210.15157, 10.48550/ARXIV.2210.15157]; Du YM, 2020, PROCEEDINGS OF THE TWENTY-SECOND AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE'20, P195, DOI 10.1145/3373165.3373187; Ericson Barbara J., 2022, ITiCSE-WGR '22: Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education, P191, DOI 10.1145/3571785.3574127; Ericson B, 2022, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2022, VOL 1, P290, DOI 10.1145/3502718.3524808; Ericson BJ, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P60, DOI 10.1145/3230977.3231000; Ericson BJ, 2017, 17TH KOLI CALLING INTERNATIONAL CONFERENCE ON COMPUTING EDUCATION RESEARCH (KOLI CALLING 2017), P20, DOI 10.1145/3141880.3141895; Ericson Barbara J., 2015, Proceedings of the eleventh annual International Conference on International Computing Education Research, P169, DOI DOI 10.1145/2787622.2787731; Fabic GVF, 2018, UMAP'18: ADJUNCT PUBLICATION OF THE 26TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P269, DOI 10.1145/3213586.3225235; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Fisler Kathi, 2014, P 10 ANN C INT COMP, P35, DOI [DOI 10.1145/2632320.2632346, 10.1145/2632320.2632346]; Garcia Rita, 2018, P 18 KOL CALL INT C, DOI [10.1145/3279720.3279746, DOI 10.1145/3279720.3279746]; Harms KJ, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER'16), P241, DOI 10.1145/2960310.2960314; Haynes CC, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445292; Haynes-Magyar Carl, 2022, P 22 KOLI CALLING IN, P1; Helminen J., 2012, Proceedings of the ninth annual international conference on International computing education research, P119; Ihantola Petri, 2011, Journal of Information Technology Education, V10, P119; Karavirta Ville., 2012, Proceedings of the 12th Koli Calling International Conference on Computing Education Research, Koli Calling'12, P11; Kumar AN, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P65, DOI 10.1145/3304221.3319735; Kumar AN, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P527, DOI 10.1145/3159450.3159576; Leinonen Juho, 2023, PROC 2023 ACM SIGCSE; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil S, 2022, Arxiv, DOI arXiv:2212.05113; MacNeil Stephen, 2023, PROC 54 ACM TECHNICA; Margulieux L, 2021, ICER 2021: PROCEEDINGS OF THE 17TH ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P184, DOI 10.1145/3446871.3469750; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; Parsons D., 2006, Australasian Computing Education Conference, V52, P157; Prather James, 2022, PROC 2022 WORLD C CO, P1; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Seppala Otto, 2015, P 15 KOL CALL C COMP, P87; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS; Weinman N, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P1349, DOI 10.1145/3328778.3372639; Weinman N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1115/3411764.3445228; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Wu Zihan, 2021, PROC 21 KOLI CALLING, DOI [10.1145/3488042.3489968, DOI 10.1145/3488042.3489968]; Xinying Hou, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P15, DOI 10.1145/3501385.3543977; Zhi R, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P51, DOI 10.1145/3291279.3339419	43	14	14	5	19	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0138-2				2023							299	305		10.1145/3587102.3588805	http://dx.doi.org/10.1145/3587102.3588805			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BV5PJ		Bronze, Green Published			2024-07-03	WOS:001051691300045
J	Socol, Y; Richardson, A; Garali-Zineddine, I; Grison, S; Vares, G; Klokov, D				Socol, Yehoshua; Richardson, Ariella; Garali-Zineddine, Imene; Grison, Stephane; Vares, Guillaume; Klokov, Dmitry			Artificial intelligence in biology and medicine, and radioprotection research: perspectives from Jerusalem	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						low doses; ionizing radiation; artificial intelligence; machine learning; radioprotection; public health		While AI is widely used in biomedical research and medical practice, its use is constrained to few specific practical areas, e.g., radiomics. Participants of the workshop on "Artificial Intelligence in Biology and Medicine" (Jerusalem, Feb 14-15, 2023), both researchers and practitioners, aimed to build a holistic picture by exploring AI advancements, challenges and perspectives, as well as to suggest new fields for AI applications. Presentations showcased the potential of large language models (LLMs) in generating molecular structures, predicting protein-ligand interactions, and promoting democratization of AI development. Ethical concerns in medical decision making were also addressed. In biological applications, AI integration of multi-omics and clinical data elucidated the health relevant effects of low doses of ionizing radiation. Bayesian latent modeling identified statistical associations between unobserved variables. Medical applications highlighted liquid biopsy methods for non-invasive diagnostics, routine laboratory tests to identify overlooked illnesses, and AI's role in oral and maxillofacial imaging. Explainable AI and diverse image processing tools improved diagnostics, while text classification detected anorexic behavior in blog posts. The workshop fostered knowledge sharing, discussions, and emphasized the need for further AI development in radioprotection research in support of emerging public health issues. The organizers plan to continue the initiative as an annual event, promoting collaboration and addressing issues and perspectives in AI applications with a focus on low-dose radioprotection research. Researchers involved in radioprotection research and experts in relevant public policy domains are invited to explore the utility of AI in low-dose radiation research at the next workshop.	[Socol, Yehoshua] Jerusalem Coll Technol, Dept Elect & Elect Engn, Jerusalem, Israel; [Richardson, Ariella] Jerusalem Coll Technol, Dept Data Min, Jerusalem, Israel; [Garali-Zineddine, Imene; Grison, Stephane; Vares, Guillaume; Klokov, Dmitry] Inst Radioprotect & Surete Nucl IRSN, Hlth & Environnent Div, Fontenay Aux Roses, France; [Klokov, Dmitry] Univ Ottawa, Dept Biochem Microbiol & Immunol, Ottawa, ON, Canada	University of Ottawa	Socol, Y (corresponding author), Jerusalem Coll Technol, Dept Elect & Elect Engn, Jerusalem, Israel.; Richardson, A (corresponding author), Jerusalem Coll Technol, Dept Data Min, Jerusalem, Israel.; Klokov, D (corresponding author), Inst Radioprotect & Surete Nucl IRSN, Hlth & Environnent Div, Fontenay Aux Roses, France.; Klokov, D (corresponding author), Univ Ottawa, Dept Biochem Microbiol & Immunol, Ottawa, ON, Canada.	socol@jct.ac.il; richards@jct.ac.il; dmitry.klokov@irsn.fr			Israeli Ministry of Innovation, Science and Technology (MOST) [3-17549, 46513ZA]	Israeli Ministry of Innovation, Science and Technology (MOST)	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This research was funded by the Israeli Ministry of Innovation, Science and Technology (MOST), project #3-17549 and by the Ministere de l'Enseignement Superieur, de la Recherche et de l'Innovation (MESRI), grant #46513ZA, both in the framework of Israel-France Maimonide-Israel research program.r The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This research was funded by the Israeli Ministry of Innovation, Science and Technology (MOST), project #3-17549 and by the Ministere de l'Enseignement Superieur, de la Recherche et de l'Innovation (MESRI), grant #46513ZA, both in the framework of Israel-France Maimonide-Israel research program.	Aceves-Fernandez M. A., 2019, Artificial Intelligence: Applications in Medicine and Biology, DOI [10.5772/intechopen.77536, DOI 10.5772/INTECHOPEN.77536]; AIBM, 2023, about us; Bera K, 2022, NAT REV CLIN ONCOL, V19, P132, DOI 10.1038/s41571-021-00560-7; Burtt JJ, 2022, INT J RADIAT BIOL, V98, P1763, DOI 10.1080/09553002.2022.2121439; Car C, 2023, BMC BIOL, V21, DOI 10.1186/s12915-023-01659-2; Car C, 2022, EVOL APPL, V15, P203, DOI 10.1111/eva.13282; Chauhan V, 2021, INT J RADIAT BIOL, V97, P60, DOI 10.1080/09553002.2020.1761570; Cohen IG, 2023, AM J BIOETHICS, V23, P8, DOI 10.1080/15265161.2023.2233357; Feinendegen L E, 2020, Health Phys, V118, P322, DOI 10.1097/HP.0000000000001207; GR-LDR, 2023, NEA High-Level Group on Low-Dose Research; Guo TC, 2023, Arxiv, DOI arXiv:2305.18365; Jaylet T, 2022, INT J RADIAT BIOL, V98, P1752, DOI 10.1080/09553002.2022.2110312; Jiménez-Luna J, 2020, NAT MACH INTELL, V2, P573, DOI 10.1038/s42256-020-00236-4; Laurier D, 2021, RADIAT ENVIRON BIOPH, V60, P519, DOI 10.1007/s00411-021-00947-1; Long ER, 2023, CELL GENOM, V3, DOI 10.1016/j.xgen.2023.100320; Milgrom B, 2020, OPT EXPRESS, V28, P23862, DOI 10.1364/OE.393037; Oberhofer A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081834; Ribeiro S, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.945521; Rudigkeit S, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.688333; Sadeh R, 2021, NAT BIOTECHNOL, V39, P586, DOI 10.1038/s41587-020-00775-6; Thomasian NM, 2021, J PUBLIC HEALTH POL, V42, P602, DOI 10.1057/s41271-021-00319-5; Vía J, 2007, NEURAL NETWORKS, V20, P139, DOI 10.1016/j.neunet.2006.09.011; Wahid KA, 2022, SEMIN RADIAT ONCOL, V32, P400, DOI 10.1016/j.semradonc.2022.06.009; Wang B, 2014, NAT METHODS, V11, P333, DOI [10.1038/NMETH.2810, 10.1038/nmeth.2810]; Wilson LJ, 2023, INT J RADIAT BIOL, V99, P1291, DOI 10.1080/09553002.2023.2173823; Xu J, 2019, HUM GENET, V138, P109, DOI 10.1007/s00439-019-01970-5; Yanovskiy M., 2023, Semestre Economico, V12, P78, DOI [10.26867/se.2023.v12i2.153, DOI 10.26867/SE.2023.V12I2.153]; Yanovskiy M., 2023, Institutional Aspects of the Power Abuse Problem in Healthcare Under Totalitarian Rule: Case of Nazi Germany, DOI [10.2139/ssrn.3724313, DOI 10.2139/SSRN.3724313]; Yeshua T, 2023, EUR RADIOL, V33, P7507, DOI 10.1007/s00330-023-09726-6; Zander A, 2019, INT J RADIAT BIOL, V95, P1378, DOI 10.1080/09553002.2019.1572249; Zheng Y, 2019, INT J HEALTH ECON MA, V19, P79, DOI 10.1007/s10754-018-9246-z	31	1	1	5	5	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	JAN 11	2024	6								1291136	10.3389/frai.2023.1291136	http://dx.doi.org/10.3389/frai.2023.1291136			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	FU1N6	38282906	gold			2024-07-03	WOS:001148278700001
J	Leng, GN; Zhang, GW; Xiong, YJ; Chen, J				Leng, Guannan; Zhang, Guowei; Xiong, Yu-Jie; Chen, Jue			CODP-1200: An AIGC based benchmark for assisting in child language acquisition	DISPLAYS			English	Article						Diffusion model; Image captioning; AI generated content; Child language acquisition; Benchmark		AIGC (Artificial Intelligence Generated Content) is a novel AI technology that encompasses tasks such as textto -image generation, text -to -text generation, and image -to -text generation. In the process of child language acquisition, some children may face challenges, exhibiting symptoms such as delayed language development, limited vocabulary, and poor expressive ability. To address this issue, the "Look and Speak" method can be employed, which allows children to learn and express language by observing images. In our paper, we build a dataset, named CODP-1200, benchmark for assisting in children language acquisition, which is curated and augmented using AIGC techniques. The dataset consists of 1200 children cartoon images paired with 6000 corresponding sentences that are used to describe them. Initially, we carefully curated and selected twelve Chinese language textbooks, ranging from the first to the sixth grade, as part of the primary compulsory education curriculum, to construct the foundational corpus. Based on the original data, two famous large language models ChatGPT and SparkDesk are employed for data augmentation, subsequently. Finally, the ERNIE-ViLG is utilized to generate children's style images corresponding to the textual descriptions. In addition, based on our proposed dataset, we propose a benchmark approach called DDMXCap, which is a diffusionbased model for image captioning, specifically from image to text. Experimental results demonstrate that our method achieves promising performance in children's image captioning tasks and provides a standardized learning process for child language acquisition. The implementation codes for our approach and build dataset are available at https://github.com/Leng-bingo/Chinese-Child-Captions.	[Leng, Guannan; Zhang, Guowei; Xiong, Yu-Jie; Chen, Jue] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201600, Peoples R China	Shanghai University of Engineering Science	Xiong, YJ (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201600, Peoples R China.	805477481@qq.com; 2510047926@qq.com; xiong@sues.edu.cn; jadeschen@sues.edu.cn	Zhang, Guowei/HJH-0318-2022	Zhang, Guowei/0000-0002-6371-5455	National Natural Science Foundation of China [62006150]; Science and Technology Commission of Shanghai Municipality, China [21DZ2203100]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality, China(Science & Technology Commission of Shanghai Municipality (STCSM))	This work is supported by the National Natural Science Foundation of China under Grant No. 62006150, and the Science and Technology Commission of Shanghai Municipality, China under Grant No. 21DZ2203100.	Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Austin J, 2021, ADV NEUR IN; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Bigham J., 2010, P 23 ANN ACM S US IN, P333, DOI 10.1145/1866029.1866080; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Chen XL, 2015, Arxiv, DOI arXiv:1504.00325; Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Feng ZD, 2023, PROC CVPR IEEE, P10135, DOI 10.1109/CVPR52729.2023.00977; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gurari Danna, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P417, DOI 10.1007/978-3-030-58520-4_25; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Li X.L., 2022, PREPRINT; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu XH, 2023, IEEE WINT CONF APPL, P289, DOI [10.1007/978-3-031-33545-7_20, 10.1109/WACV56688.2023.00037]; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Luo JF, 2023, ADV INTELL SYST-GER, V5, DOI 10.1002/aisy.202300439; Nichol A, 2022, Arxiv, DOI arXiv:2112.10741; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856; Ramesh A., 2022, arXiv; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Song JM, 2022, Arxiv, DOI arXiv:2010.02502; Sutskever I, 2014, ADV NEUR IN, V27; Tomasello M, 2005, BEHAV BRAIN SCI, V28, P675, DOI 10.1017/S0140525X05000129; Vaswani A, 2017, ADV NEUR IN, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu Shitong, 2022, arXiv; Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098; Young P., 2014, P TACL, V2, P67, DOI DOI 10.1162/TACL_A_00166; Zhang XX, 2023, ADV INTELL SYST-GER, V5, DOI 10.1002/aisy.202200345; Zhu ZX, 2022, Arxiv, DOI arXiv:2211.11694	37	0	0	56	56	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0141-9382	1872-7387		DISPLAYS	Displays	APR	2024	82								102627	10.1016/j.displa.2023.102627	http://dx.doi.org/10.1016/j.displa.2023.102627		JAN 2024	10	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic; Instruments & Instrumentation; Optics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Instruments & Instrumentation; Optics	GI8B3					2024-07-03	WOS:001152119200001
J	Leung, HW; Bovy, J				Leung, Henry W.; Bovy, Jo			Towards an astronomical foundation model for stars with a transformer-based model	MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY			English	Article						methods: data analysis; stars: fundamental parameters	NEURAL-NETWORKS; GAIA; REPRESENTATION	Rapid strides are currently being made in the field of artificial intelligence using transformer-based models like Large Language Models (LLMs). The potential of these methods for creating a single, large, versatile model in astronomy has not yet been explored. In this work, we propose a framework for data-driven astronomy that uses the same core techniques and architecture as used by LLMs. Using a variety of observations and labels of stars as an example, we build a transformer-based model and train it in a self-supervised manner with cross-survey data sets to perform a variety of inference tasks. In particular, we demonstrate that a single model can perform both discriminative and generative tasks even if the model was not trained or fine-tuned to do any specific task. For example, on the discriminative task of deriving stellar parameters from Gaia XP spectra, we achieve an accuracy of 47 K in T-eff, 0.11 dex in log g, and 0.07 dex in [M/H], outperforming an expert XGBoost model in the same setting. But the same model can also generate XP spectra from stellar parameters, inpaint unobserved spectral regions, extract empirical stellar loci, and even determine the interstellar extinction curve. Our framework demonstrates that building and training a single foundation model without fine-tuning using data and parameters from multiple surveys to predict unmeasured observations and parameters is well within reach. Such 'Large Astronomy Models' trained on large quantities of observational data will play a large role in the analysis of current and future large surveys.	[Leung, Henry W.; Bovy, Jo] Univ Toronto, David A Dunlap Dept Astron & Astrophys, 50 St George St, Toronto, ON M5S 3H4, Canada; [Bovy, Jo] Univ Toronto, Dunlap Inst Astron & Astrophys, 50 St George St, Toronto, ON M5S 3H4, Canada	University of Toronto; University of Toronto	Leung, HW (corresponding author), Univ Toronto, David A Dunlap Dept Astron & Astrophys, 50 St George St, Toronto, ON M5S 3H4, Canada.	henrysky.leung@mail.utoronto.ca		Bovy, Jo/0000-0001-6855-442X	NSERC [RGPIN-2020-04712]; Natural Sciences and Engineering Research Council of Canada (NSERC)	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	We thank the anonymous referee, Joshua S. Speagle, and Alexander Laroche for helpful comments. HL and JB acknowledge financial support from the Natural Sciences and Engineering Research Council of Canada (NSERC; funding reference number RGPIN-2020-04712).	Abdurro'uf, 2022, ASTROPHYS J SUPPL S, V259, DOI 10.3847/1538-4365/ac4414; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Allam T Jr, 2023, Arxiv, DOI arXiv:2105.06178; Anderson L, 2018, ASTRON J, V156, DOI 10.3847/1538-3881/aad7bf; Andrae R, 2023, ASTROPHYS J SUPPL S, V267, DOI 10.3847/1538-4365/acd53e; Ba JL., 2016, arXiv; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Barbary Kyle, 2016, Zenodo; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Blanton MR, 2017, ASTRON J, V154, DOI 10.3847/1538-3881/aa7567; Bovy J, 2016, ASTROPHYS J, V818, DOI 10.3847/0004-637X/818/2/130; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Carrasco JM, 2021, ASTRON ASTROPHYS, V652, DOI 10.1051/0004-6361/202141249; Chase H., 2022, Langchain; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Ciuc I., 2023, RNAAS, V7, P193, DOI DOI 10.3847/2515-5172/ACF85F; Coughlin MW, 2023, ASTROPHYS J SUPPL S, V267, DOI 10.3847/1538-4365/acdee1; Dagli R, 2023, Arxiv, DOI arXiv:2304.05350; De Angeli F, 2023, ASTRON ASTROPHYS, V674, DOI 10.1051/0004-6361/202243680; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Donoso-Oliva C, 2023, ASTRON ASTROPHYS, V670, DOI 10.1051/0004-6361/202243928; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Drimmel R, 2003, ASTRON ASTROPHYS, V409, P205, DOI 10.1051/0004-6361:20031070; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Fitzpatrick EL, 1999, PUBL ASTRON SOC PAC, V111, P63, DOI 10.1086/316293; Pérez AEG, 2016, ASTRON J, V151, DOI 10.3847/0004-6256/151/6/144; Green GM, 2019, ASTROPHYS J, V887, DOI 10.3847/1538-4357/ab5362; Hadsell R, 2006, IEEE C COMP VIS PATT, P1735; Hauser MG, 1998, ASTROPHYS J, V508, P25, DOI 10.1086/306379; Hayat MA, 2021, ASTROPHYS J LETT, V911, DOI 10.3847/2041-8213/abf2c7; He KM, 2020, Arxiv, DOI arXiv:1911.05722; He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]; Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, 10.48550/arXiv.1606.08415]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Khosla Prannay, 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2004.11362; Kingma D. P., 2017, ARXIV; Kollmeier J.A., 2017, arXiv, DOI 10.48550/arXiv.1711.03234; Laroche A., 2023, arXiv, DOI [10.48550/arXiv.2307.06378, DOI 10.48550/ARXIV.2307.06378]; Laureijs R, 2011, Arxiv, DOI arXiv:1110.3193; Leung HW, 2023, MON NOT R ASTRON SOC, V522, P4577, DOI 10.1093/mnras/stad1272; Leung HW, 2023, MON NOT R ASTRON SOC, V519, P948, DOI 10.1093/mnras/stac3529; Leung HW, 2019, MON NOT R ASTRON SOC, V489, P2079, DOI 10.1093/mnras/stz2245; Leung HW, 2019, MON NOT R ASTRON SOC, V483, P3255, DOI 10.1093/mnras/sty3217; Lindegren L, 2021, ASTRON ASTROPHYS, V649, DOI 10.1051/0004-6361/202039653; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Loshchilov Ilya, 2016, arXiv, DOI DOI 10.48550/ARXIV.1608.03983; Majewski SR, 2017, ASTRON J, V154, DOI 10.3847/1538-3881/aa784d; Marshall DJ, 2006, ASTRON ASTROPHYS, V453, P635, DOI 10.1051/0004-6361:20053842; Maynez J, 2020, Arxiv, DOI [arXiv:2005.00661, DOI 10.48550/ARXIV.2005.00661]; Micikevicius P, 2017, arXiv; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Montegriffo P, 2023, ASTRON ASTROPHYS, V674, DOI 10.1051/0004-6361/202243880; Moreno-Cartagena D, 2023, Arxiv, DOI arXiv:2308.06404; Paszke A, 2019, Arxiv, DOI [arXiv:1912.01703, 10.48550/arXiv.1912.01703, 10.48550/arxiv.1912.01703]; Pimentel O, 2023, ASTRON J, V165, DOI 10.3847/1538-3881/ac9ab4; Prusti T, 2016, ASTRON ASTROPHYS, V595, DOI 10.1051/0004-6361/201629272; Radford A., 2021, arXiv, DOI 10.48550/arXiv.2103.00020; Riello M, 2021, ASTRON ASTROPHYS, V649, DOI 10.1051/0004-6361/202039587; Rix HW, 2022, ASTROPHYS J, V941, DOI 10.3847/1538-4357/ac9e01; Rózański T, 2023, Arxiv, DOI arXiv:2306.15703; Salton Gerard, 1962, P COMP C AM FED INF, P234; Sanders JL, 2023, MON NOT R ASTRON SOC, V521, P2745, DOI 10.1093/mnras/stad574; Schlafly EF, 2011, ASTROPHYS J, V737, DOI 10.1088/0004-637X/737/2/103; Schlegel DJ, 1998, ASTROPHYS J, V500, P525, DOI 10.1086/305772; Skrutskie MF, 2006, ASTRON J, V131, P1163, DOI 10.1086/498708; Slijepcevic IV, 2023, Arxiv, DOI arXiv:2305.16127; Smith MJ, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.221454; Sohn Kihyuk., 2016, Advances in Neural Information Processing Systems, P1857, DOI DOI 10.5555/3157096.3157304; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stein G, 2022, ASTROPHYS J, V932, DOI 10.3847/1538-4357/ac6d63; Vallenari A, 2023, ASTRON ASTROPHYS, V674, DOI 10.1051/0004-6361/202243940; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Walmsley M., 2022, Machine Learning for Astrophysics, P29, DOI [10.48550/arXiv.2206.11927, DOI 10.48550/ARXIV.2206.11927]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wilson JC, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/ab0075; Yoon M, 2019, ASTROPHYS J, V870, DOI 10.3847/1538-4357/aaf3a9; Zhang AS, 2022, Arxiv, DOI [arXiv:2106.11342, DOI 10.48550/ARXIV.2106.11342]; Zhang XY, 2023, MON NOT R ASTRON SOC, V524, P1855, DOI 10.1093/mnras/stad1941; Zou ZQ, 2020, PUBL ASTRON SOC PAC, V132, DOI 10.1088/1538-3873/ab7548	79	2	2	5	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0035-8711	1365-2966		MON NOT R ASTRON SOC	Mon. Not. Roy. Astron. Soc.	JAN	2024	527	1					1494	1520		10.1093/mnras/stad3015	http://dx.doi.org/10.1093/mnras/stad3015			27	Astronomy & Astrophysics	Science Citation Index Expanded (SCI-EXPANDED)	Astronomy & Astrophysics	HN2Q1		Green Submitted, hybrid			2024-07-03	WOS:001160121500080
J	Wang, L; Chen, XY; Wang, C; Xu, LN; Shadiev, R; Li, Y				Wang, Li; Chen, Xinya; Wang, Chung; Xu, Lingna; Shadiev, Rustam; Li, Yan			ChatGPT's capabilities in providing feedback on undergraduate students' argumentation: A case study	THINKING SKILLS AND CREATIVITY			English	Article						ChatGPT (ChatGPT 3.5); Feedback capabilities; Teacher's feedback; Argumentation teaching; Undergraduate students	AUTOMATED ESSAY EVALUATION; COLLABORATIVE ARGUMENTATION; KNOWLEDGE; SCIENCE; ONLINE; DESIGN; ENVIRONMENTS; SKILLS; MODEL	In argumentation teaching, providing timely and high-quality feedback is always a challenging task for teachers because of the high complexity and large volume of students' argumentation contents. ChatGPT, a large language model introduced in November 2022, offers a potential solution for this problem. To examine the potential reliability and credibility of leveraging ChatGPT for argumentation feedback, the study conducted a retrospective analysis by applying ChatGPT to generate feedback on 50 sets of argumentation contents that human teachers had previously assessed. The study first assessed the feedback accuracy of ChatGPT and the factors that influenced the evaluation of arguments. The findings showed that ChatGPT demonstrated impressive precision rate (91.8 %) and recall rate (63.2 %) when providing feedback on arguments, indicating that ChatGPT possesses a fundamental capability to provide feedback on arguments. However, this capability of ChatGPT was significantly affected by the length of arguments and the discourse markers used in the arguments. The study then qualitatively compared the ChatGPT's feedback and teacher's feedback. The results revealed that these two types of feedback each had their own advantages and disadvantages. While ChatGPT could potentially generate comprehensive feedback and textual-based feedback, and limited to the linguistic level when provide affective feedback, teacher's feedback was more focused on student's overall learning progress, based on personal teaching experience to correctly identify immediate critical problem of the student, and consideration on the humanistic empathy interaction. Although the overall findings suggested that ChatGPT exhibited potential reliability and credibility for argumentation feedback, the study did identify several limitations.	[Wang, Li; Wang, Chung; Xu, Lingna; Shadiev, Rustam; Li, Yan] Zhejiang Univ, Coll Educ, Hangzhou 310058, Peoples R China; [Wang, Li] Minist Educ, 1 North Buona Vista Dr,Podium Block, Singapore 138675, Singapore; [Chen, Xinya] Henan Univ, Fac Educ, Jinming Rd, Kaifeng 475000, Peoples R China	Zhejiang University; Henan University	Li, Y (corresponding author), Zhejiang Univ, Coll Educ, Hangzhou 310058, Peoples R China.	yanli@zju.edu.cn	yan, li/AGT-6808-2022; Shadiev, Rustam/G-5083-2010	yan, li/0000-0002-0640-1783; Shadiev, Rustam/0000-0001-5571-1158; Wang, Chung/0009-0005-8567-8068	National Natural Science Foundation of China [61977057]; Social Science Research Council Graduate Research Fellowship [MOE SSRC GRF 3/23]; Basic Research Funding of Zhejiang University of China [S20230157]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Social Science Research Council Graduate Research Fellowship; Basic Research Funding of Zhejiang University of China	The authors would like to thank the reviewers for their valuable comments and all of the research participants. In addition, we acknowledge the funding supported by the Precision Teaching Model and Mechanism Based on Intelligent Teaching System under National Natural Science Foundation of China (61977057), the Social Science Research Council Graduate Research Fellowship adminstered by Nanyang Technological University of Singapore (Reference No. MOE SSRC GRF 3/23 WL) and the Basic Research Funding of Zhejiang University of China (S20230157).	[Anonymous], 2001, International Journal of Artificial Intelligence in Education; [Anonymous], 2014, P 2014 C EMPIRICAL M; Bell P, 2000, INT J SCI EDUC, V22, P797, DOI 10.1080/095006900412284; Bodily R, 2018, J COMPUT HIGH EDUC, V30, P572, DOI 10.1007/s12528-018-9186-0; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Burstein J., 2003, Proceedings of the Fifteenth Innovative Applications of Artificial Intelligence Conference, P3; Burstein J., Enriching automated essay scoring using discourse marking; BURSTIEN JILL., 1999, S COMPUT MEDIATED LA, P68; Cavalcanti A. P., 2021, Comput. Educ, V2, DOI DOI 10.1016/J.CAEAI.2021.100027; Chen HB, 2014, COMPUT J, V57, P1318, DOI 10.1093/comjnl/bxt117; Chen XY, 2022, THINK SKILLS CREAT, V44, DOI 10.1016/j.tsc.2022.101035; Chodorow M., 2004, ETS Research Report Series, V2004, pi, DOI DOI 10.1002/J.2333-8504.2004.TB01931.X; Chodorow M, 2010, LANG TEST, V27, P419, DOI 10.1177/0265532210364391; Clark DB, 2008, J RES SCI TEACH, V45, P293, DOI 10.1002/tea.20216; Cohen R., 1984, 10th International Conference on Computational Linguistics. 22nd Annual Meeting of the Association for Computational Linguistics. Proceedings of Coling 84, P251; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Davis D, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P454, DOI 10.1145/3027385.3027411; Deng JF, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2020.101182; Dikli S, 2011, CALICO J, V28, P99; Diklil S, 2014, ASSESS WRIT, V22, P1, DOI 10.1016/j.asw.2014.03.006; Erduran S, 2004, SCI EDUC, V88, P915, DOI 10.1002/sce.20012; Fan YC, 2020, J COMPUT ASSIST LEAR, V36, P526, DOI 10.1111/jcal.12420; Gao F, 2013, BRIT J EDUC TECHNOL, V44, P469, DOI 10.1111/j.1467-8535.2012.01330.x; Hoang GTL, 2016, LANG ASSESS Q, V13, P359, DOI 10.1080/15434303.2016.1230121; Gunawardena CN, 1997, J EDUC COMPUT RES, V17, P397, DOI 10.2190/7MQV-X9UJ-C7Q3-NRAG; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Huang Hen-Hsen., 2011, P 5 INT JOINT C NATU, P1442; Jeong A, 2007, COMPUT EDUC, V48, P427, DOI 10.1016/j.compedu.2005.02.002; Jones E, 2006, MACHINE SCORING OF STUDENT ESSAYS: TRUTH AND CONSEQUENCES, P93; Khan I, 2016, LAK '16 CONFERENCE PROCEEDINGS: THE SIXTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE,, P249, DOI 10.1145/2883851.2883911; Kuhn D, 1997, COGNITION INSTRUCT, V15, P287, DOI 10.1207/s1532690xci1503_1; Kuhn D., 1991, The skills of argument, DOI [10.1017/CBO9780511571350, DOI 10.1017/CBO9780511571350]; Kuhn D, 2010, SCI EDUC, V94, P810, DOI 10.1002/sce.20395; Landauer TK, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P87; Liang WX, 2023, Arxiv, DOI arXiv:2310.01783; Lin SS, 2014, INT J SCI MATH EDUC, V12, P1023, DOI 10.1007/s10763-013-9451-7; Link S, 2022, COMPUT ASSIST LANG L, V35, P605, DOI 10.1080/09588221.2020.1743323; Litman DJ, 1996, J ARTIF INTELL RES, V5, P53, DOI 10.1613/jair.327; Liu S., 2021, Open Education Research, V27, P73, DOI [10.13966/j.cnki.kfjyyj.2021.03.008, DOI 10.13966/J.CNKI.KFJYYJ.2021.03.008]; Liu S, 2016, CALICO J, V33, P71, DOI 10.1558/cj.v33i1.26380; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Lu Y., 2023, Chinese Journal of Distance Education, P2023; Marcu D, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P368; Mason L, 2006, LEARN INSTR, V16, P492, DOI 10.1016/j.learninstruc.2006.09.007; McAlister S, 2004, J COMPUT ASSIST LEAR, V20, P194, DOI 10.1111/j.1365-2729.2004.00086.x; McManis M. M., 1995, Journal of Artificial Intelligence in Education, V6, P307; Nadeem F, 2019, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P484; OpenAI, 2023, What are tokens and how to count them?; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pinkwart N, 2006, LECT NOTES COMPUT SC, V4053, P227; Quirk Randolph, 1985, COMPREHENSIVE GRAMMA; Roose K., 2023, The New York Times, V1; SADLER DR, 1989, INSTR SCI, V18, P119, DOI 10.1007/BF00117714; Sadler TD, 2006, SCI EDUC, V90, P986, DOI 10.1002/sce.20165; Sanosi A, 2021, Australian Journal of Applied Linguistics, V4, P119; Scheuer O, 2012, TECH TEACHING ARGUME, V2, P71; Schwarz BB, 2007, INT J COMP-SUPP COLL, V2, P449, DOI 10.1007/s11412-007-9024-2; Shen S, 2023, Chinese Journal of Distance Education, V43, P8, DOI [10.13541/j.cnki.chinade.20230223.001, DOI 10.13541/J.CNKI.CHINADE.20230223.001]; Stede M., 1998, P 17 INT C COMPUTATI, V2; Toulmin S., 1958, USES ARGUMENT; Van Eemeren F.H., 2013, Fundamentals ofArgumentation Theory: A Handbook of Historical Backgrounds and ContemporaryDevelopments, DOI [DOI 10.4324/9780203811306, 10.4324/9780203811306]; Vaswani A, 2017, ADV NEUR IN, V30; Voss JF, 2001, DISCOURSE PROCESS, V32, P89, DOI 10.1207/S15326950DP3202&3_01; Wang TW, 2020, AAAI CONF ARTIF INTE, V34, P12216; Weinberger A, 2007, COMPUT-SUPP COLLAB L, V6, P191; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wilson J, 2016, COMPUT EDUC, V100, P94, DOI 10.1016/j.compedu.2016.05.004; Xie JB, 2020, COMPUTING, V102, P683, DOI 10.1007/s00607-019-00766-9; Zeidler DL, 2006, SCI TECHNOL EDUC LIB, V19, P97; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zohar A, 2002, J RES SCI TEACH, V39, P35, DOI 10.1002/tea.10008	72	1	1	109	109	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1871-1871	1878-0423		THINK SKILLS CREAT	Think. Skills Creat.	MAR	2024	51								101440	10.1016/j.tsc.2023.101440	http://dx.doi.org/10.1016/j.tsc.2023.101440		DEC 2023	14	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	EP6U6					2024-07-03	WOS:001140175900001
J	Coughlin, MW; Bloom, JS; Nir, G; Antier, S; du Laz, TJ; van der Walt, S; Crellin-Quick, A; Culino, T; Duev, DA; Goldstein, DA; Healy, BF; Karambelkar, V; Lilleboe, J; Shin, KM; Singer, LP; Ahumada, T; Anand, S; Bellm, EC; Dekany, R; Graham, MJ; Kasliwal, MM; Kostadinova, I; Kiendrebeogo, RW; Kulkarni, SR; Jenkins, S; LeBaron, N; Mahabal, AA; Neill, JD; Parazin, B; Peloton, J; Perley, DA; Riddle, R; Rusholme, B; van Santen, J; Sollerman, J; Stein, R; Turpin, D; Wold, A; Amat, C; Bonnefon, A; Bonnefoy, A; Flament, M; Kerkow, F; Kishore, S; Jani, S; Mahanty, SK; Liu, C; Llinares, L; Makarison, J; Olliéric, A; Perez, I; Pont, L; Sharma, V				Coughlin, Michael W.; Bloom, Joshua S.; Nir, Guy; Antier, Sarah; du Laz, Theophile Jegou; van der Walt, Stefan; Crellin-Quick, Arien; Culino, Thomas; Duev, Dmitry A.; Goldstein, Daniel A.; Healy, Brian F.; Karambelkar, Viraj; Lilleboe, Jada; Shin, Kyung Min; Singer, Leo P.; Ahumada, Tomas; Anand, Shreya; Bellm, Eric C.; Dekany, Richard; Graham, Matthew J.; Kasliwal, Mansi M.; Kostadinova, Ivona; Kiendrebeogo, R. Weizmann; Kulkarni, Shrinivas R.; Jenkins, Sydney; LeBaron, Natalie; Mahabal, Ashish A.; Neill, James D.; Parazin, B.; Peloton, Julien; Perley, Daniel A.; Riddle, Reed; Rusholme, Ben; van Santen, Jakob; Sollerman, Jesper; Stein, Robert; Turpin, D.; Wold, Avery; Amat, Carla; Bonnefon, Adrien; Bonnefoy, Adrien; Flament, Manon; Kerkow, Frank; Kishore, Sulekha; Jani, Shloke; Mahanty, Stephen K.; Liu, Celine; Llinares, Laura; Makarison, Jolyane; Ollieric, Alix; Perez, Ines; Pont, Lydie; Sharma, Vyom			A Data Science Platform to Enable Time-domain Astronomy	ASTROPHYSICAL JOURNAL SUPPLEMENT SERIES			English	Article							GAMMA-RAY BURST; ZWICKY TRANSIENT FACILITY; NEUTRON-STAR MERGER; GRAVITATIONAL-WAVE; REAL-TIME; ELECTROMAGNETIC COUNTERPART; INFRARED COUNTERPART; HUBBLE CONSTANT; LIGHT CURVES; FOLLOW-UP	SkyPortal is an open-source software package designed to discover interesting transients efficiently, manage follow-up, perform characterization, and visualize the results. By enabling fast access to archival and catalog data, crossmatching heterogeneous data streams, and the triggering and monitoring of on-demand observations for further characterization, a SkyPortal-based platform has been operating at scale for >2 yr for the Zwicky Transient Facility Phase II community, with hundreds of users, containing tens of millions of time-domain sources, interacting with dozens of telescopes, and enabling community reporting. While SkyPortal emphasizes rich user experiences across common front-end workflows, recognizing that scientific inquiry is increasingly performed programmatically, SkyPortal also surfaces an extensive and well-documented application programming interface system. From back-end and front-end software to data science analysis tools and visualization frameworks, the SkyPortal design emphasizes the reuse and leveraging of best-in-class approaches, with a strong extensibility ethos. For instance, SkyPortal now leverages ChatGPT large language models to generate and surface source-level human-readable summaries automatically. With the imminent restart of the next generation of gravitational-wave detectors, SkyPortal now also includes dedicated multimessenger features addressing the requirements of rapid multimessenger follow-up: multitelescope management, team/group organizing interfaces, and crossmatching of multimessenger data streams with time-domain optical surveys, with interfaces sufficiently intuitive for newcomers to the field. This paper focuses on the detailed implementations, capabilities, and early science results that establish SkyPortal as a community software package ready to take on the data science challenges and opportunities presented by this next chapter in the multimessenger era.	[Coughlin, Michael W.; Healy, Brian F.; Lilleboe, Jada; Kiendrebeogo, R. Weizmann; Parazin, B.; Kerkow, Frank; Jani, Shloke; Mahanty, Stephen K.; Sharma, Vyom] Univ Minnesota, Sch Phys & Astron, Minneapolis, MN 55455 USA; [Bloom, Joshua S.; Nir, Guy; LeBaron, Natalie] Univ Calif Berkeley, Dept Astron, Berkeley, CA 94720 USA; [Bloom, Joshua S.; Nir, Guy] Lawrence Berkeley Natl Lab, 1 Cyclotron Rd,MS 50B 4206, Berkeley, MS USA; [Antier, Sarah] Univ Cote Azur, Artemis, Observatoire Cote Azur, Blvd Observatoire, F-06304 Nice, France; [du Laz, Theophile Jegou; Karambelkar, Viraj; Ahumada, Tomas; Anand, Shreya; Graham, Matthew J.; Kasliwal, Mansi M.; Kostadinova, Ivona; Stein, Robert; Kishore, Sulekha] CALTECH, Div Phys Math & Astron, Pasadena, CA 91125 USA; [van der Walt, Stefan] Univ Calif Berkeley, Berkeley Inst Data Sci, Berkeley, CA 94720 USA; [Crellin-Quick, Arien; Duev, Dmitry A.; Goldstein, Daniel A.] Weights & Biases Inc, 1479 Folsom St, San Francisco, CA 90063 USA; [Culino, Thomas; Amat, Carla; Bonnefon, Adrien; Bonnefoy, Adrien; Flament, Manon; Liu, Celine; Llinares, Laura; Makarison, Jolyane; Ollieric, Alix; Perez, Ines; Pont, Lydie] ESILV Ecole Superieure Ingenieurs Leonard Vinci, Paris, France; [Shin, Kyung Min] EnergyHub Inc, 41 Flatbush Ave,Suite 400A, Brooklyn, NY 11217 USA; [Singer, Leo P.] NASA Goddard Space Flight Ctr, Astroparticle Phys Lab, Code 661, Greenbelt, MD 20771 USA; [Bellm, Eric C.] Univ Washington, DIRAC Inst, Dept Astron, 3910 15th Ave NE, Seattle, WA 98195 USA; [Dekany, Richard; Riddle, Reed] CALTECH, Caltech Opt Observatories, Pasadena, CA 91125 USA; [Kiendrebeogo, R. Weizmann] Univ Joseph KI ZERBO, Lab Phys & Chim Environm, Ouagadougou, Burkina Faso; [Kulkarni, Shrinivas R.] CALTECH, Owens Valley Radio Observ, 249 17, Pasadena, CA 91125 USA; [Jenkins, Sydney] MIT, Dept Phys, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Mahabal, Ashish A.] CALTECH, Div Phys Math & Astron, Pasadena, CA 91125 USA; [Mahabal, Ashish A.] CALTECH, Ctr Data Driven Discovery, Pasadena, CA 91125 USA; [Parazin, B.] Northeastern Univ, Boston, MA 02115 USA; [Peloton, Julien] Univ Paris Saclay, IJCLab, CNRS, IN2P3, Orsay, France; [Perley, Daniel A.] Liverpool John Moores Univ, Astrophys Res Inst, IC2,Liverpool Sci Pk,146 Brownlow Hill, Liverpool L3 5RF, Merseyside, England; [Rusholme, Ben] CALTECH, IPAC, 1200 E Calif Blvd, Pasadena, CA 91125 USA; [van Santen, Jakob] Deutsch Elekt Synchrotron DESY, Platanenallee 6, D-15738 Zeuthen, Germany; [Sollerman, Jesper] Stockholm Univ, Dept Astron, Oskar Klein Ctr, AlbaNova, SE-10691 Stockholm, Sweden; [Turpin, D.] Univ Paris Saclay, Univ Paris Cite, CNRS, CEA,AIM, Gif Sur Yvette, France	University of Minnesota System; University of Minnesota Twin Cities; University of California System; University of California Berkeley; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Universite Cote d'Azur; Observatoire de la Cote d'Azur; California Institute of Technology; University of California System; University of California Berkeley; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center; University of Washington; University of Washington Seattle; California Institute of Technology; Universite Joseph Ki-Zerbo; California Institute of Technology; Massachusetts Institute of Technology (MIT); California Institute of Technology; California Institute of Technology; Northeastern University; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute of Nuclear and Particle Physics (IN2P3); Universite Paris Cite; Universite Paris Saclay; Liverpool John Moores University; California Institute of Technology; Helmholtz Association; Deutsches Elektronen-Synchrotron (DESY); Oskar Klein Centre; Stockholm University; Universite Paris Saclay; CEA; Centre National de la Recherche Scientifique (CNRS); Universite Paris Cite	Coughlin, MW (corresponding author), Univ Minnesota, Sch Phys & Astron, Minneapolis, MN 55455 USA.	cough052@umn.edu	Nir, Guy/HJJ-0199-2023; Duev, Dmitry/AAI-9214-2020; Llinares-Insa, Lucía Inmaculada/HCH-1517-2022	Duev, Dmitry/0000-0001-5060-8733; Llinares-Insa, Lucía Inmaculada/0000-0001-9626-4948; LeBaron, Natalie/0000-0002-2249-0595; Nir, Guy/0000-0002-7501-5579; Goldstein, Daniel/0000-0003-3461-8661; Bloom, Joshua/0000-0002-7777-216X; Kiendrebeogo, Ramodwende Weizmann/0000-0002-9108-5059; Coughlin, Michael/0000-0002-8262-2924; Jegou du Laz, Theophile/0009-0003-6181-4526; van der Walt, Stefan/0000-0001-9276-1891; Bellm, Eric/0000-0001-8018-5348; Anand, Shreya/0000-0003-3768-7515	National Science Foundation; LSST Program - Heising-Simons Foundation; Gordon and Betty Moore Foundation; Northeastern Lawrence Co-op Fellowship [OAC-2117997]; LSST-France [PHY-2010970]; CNRS/IN2P3 [2021-2975]; IdEx Universite de Paris Cite; MITI CNRS Sciences participative program; National Science Foundation; Caltech; IPAC [ANR-18-IDEX-0001]; Weizmann Institute of Science; Oskar Klein Center at Stockholm University [AST-2034437]; University of Maryland; Deutsches Elektronen-Synchrotron; Humboldt University; TANGO Consortium of Taiwan; University of Wisconsin at Milwaukee; Trinity College Dublin; Lawrence Livermore National Laboratories; IN2P3; University of Warwick; Ruhr University Bochum; Northwestern University	National Science Foundation(National Science Foundation (NSF)); LSST Program - Heising-Simons Foundation; Gordon and Betty Moore Foundation(Gordon and Betty Moore Foundation); Northeastern Lawrence Co-op Fellowship; LSST-France; CNRS/IN2P3(Centre National de la Recherche Scientifique (CNRS)); IdEx Universite de Paris Cite; MITI CNRS Sciences participative program; National Science Foundation(National Science Foundation (NSF)); Caltech; IPAC; Weizmann Institute of Science; Oskar Klein Center at Stockholm University; University of Maryland; Deutsches Elektronen-Synchrotron; Humboldt University; TANGO Consortium of Taiwan; University of Wisconsin at Milwaukee; Trinity College Dublin; Lawrence Livermore National Laboratories(United States Department of Energy (DOE)); IN2P3; University of Warwick; Ruhr University Bochum; Northwestern University	The authors appreciate comments from Dave Coulter, Fabian Schussler, and the anomymous referee on an initial draft of this paper.M.W.C., J.L., and V.S. are supported by the National Science Foundation with grant No. OAC-2117997; M.W.C. is also supported by PHY-2010970. M.W.C. and R.W.K. were supported by the Preparing for Astrophysics with LSST Program, funded by the Heising-Simons Foundation through grant 2021-2975, and administered by Las Cumbres Observatory. The Gordon and Betty Moore Foundation, through both the Data-driven Investigator Program and a dedicated grant to develop SkyPortal, provided critical funding for this project without which this project could not have succeeded. J.S.B., G.N., A.C-Q., and D.A.D. were partially supported by the Gordon and Betty Moore Foundation. B.P. thanks the Northeastern Lawrence Co-op Fellowship for their continuous support. J.P. thanks LSST-France and CNRS/IN2P3 for supporting Fink. The Kilonova-Catcher program is supported by the IdEx Universite de Paris Cite ANR-18-IDEX-0001 and the MITI CNRS Sciences participative program.Based on observations obtained with the Samuel Oschin Telescope 48 inch and the 60 inch Telescope at the Palomar Observatory as part of the Zwicky Transient Facility project. ZTF is supported by the National Science Foundation under grant No. AST-2034437 and a collaboration including Caltech, IPAC, the Weizmann Institute of Science, the Oskar Klein Center at Stockholm University, the University of Maryland, Deutsches Elektronen-Synchrotron and Humboldt University, the TANGO Consortium of Taiwan, the University of Wisconsin at Milwaukee, Trinity College Dublin, Lawrence Livermore National Laboratories, IN2P3, University of Warwick, Ruhr University Bochum and Northwestern University. Operations are conducted by COO, IPAC, and UW.	Aartsen MG, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/P03012; Aasi J, 2015, CLASSICAL QUANT GRAV, V32, DOI 10.1088/0264-9381/32/7/074001; Abbott BP, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.161101; Abbott BP, 2017, ASTROPHYS J LETT, V848, DOI 10.3847/2041-8213/aa920c; Abbott B.P., 2017, ASTROPHYS J, V848, pL12, DOI [10.3847/2041-8213/aa91c9, DOI 10.3847/2041-8213/AA91C9]; Abbott B.P., 2017, NATUR, V551, P85, DOI [10.1038/nature24471, DOI 10.1038/NATURE24471]; Acernese F, 2015, CLASSICAL QUANT GRAV, V32, DOI 10.1088/0264-9381/32/2/024001; Ackley K., 2020, A&A, V643, pA113, DOI [DOI 10.1051/0004-6361/202037669, 10.1051/0004-6361/202037669]; Ahumada T, 2022, ASTROPHYS J, V932, DOI 10.3847/1538-4357/ac6c29; Ahumada T, 2021, NAT ASTRON, V5, P917, DOI 10.1038/s41550-021-01428-7; Aivazyan V, 2022, MON NOT R ASTRON SOC, V515, P6007, DOI 10.1093/mnras/stac2054; Allan A, 2017, Arxiv, DOI arXiv:1709.01264; Almualla M, 2020, MON NOT R ASTRON SOC, V495, P4366, DOI 10.1093/mnras/staa1498; Anand S, 2021, NAT ASTRON, V5, DOI 10.1038/s41550-020-1183-3; Andreoni I, 2021, ASTROPHYS J, V918, DOI 10.3847/1538-4357/ac0bc7; Andreoni I, 2020, ASTROPHYS J, V904, DOI 10.3847/1538-4357/abbf4c; Andreoni I, 2020, ASTROPHYS J, V890, DOI 10.3847/1538-4357/ab6a1b; Andreoni I, 2019, ASTROPHYS J LETT, V881, DOI 10.3847/2041-8213/ab3399; Antier S, 2020, MON NOT R ASTRON SOC, V497, P5518, DOI 10.1093/mnras/staa1846; Antier S., 2019, Monthly Notices of the Royal Astronomical Society, V492, P3904, DOI DOI 10.1093/MNRAS/STZ3142; Arcavi I, 2017, NATURE, V551, P64, DOI 10.1038/nature24291; Barbary K., 2016, Astrophysics Source Code Library; BARTHELMY SD, 1995, ASTROPHYS SPACE SCI, V231, P235, DOI 10.1007/BF00658623; Bellm EC, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/ab0c2a; Biswas B, 2023, Arxiv, DOI arXiv:2210.17433; Blagorodnova N, 2018, PUBL ASTRON SOC PAC, V130, DOI 10.1088/1538-3873/aaa53f; Bloom JS, 2008, ASTRON NACHR, V329, P284, DOI 10.1002/asna.200710957; Bulla M, 2019, MON NOT R ASTRON SOC, V489, P5037, DOI 10.1093/mnras/stz2495; Bulla M, 2023, MON NOT R ASTRON SOC, V520, P2558, DOI 10.1093/mnras/stad232; Chambers KC, 2019, Arxiv, DOI [arXiv:1612.05560, DOI 10.48550/ARXIV.1612.05560]; Chornock, 2017, ApJL, V848, pL19, DOI 10.3847/2041-8213/aa905c; Cook D. O., 2017, Census of the Local Universe (CLU) I: Characterization of Galaxy Catalogs from Preliminary Fields; Coughlin MW, 2021, MON NOT R ASTRON SOC, V505, P2954, DOI 10.1093/mnras/stab1502; Coughlin MW, 2020, MON NOT R ASTRON SOC, V497, P1181, DOI 10.1093/mnras/staa1925; Coughlin MW, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17998-5; Coughlin MW, 2020, NAT ASTRON, V4, P550, DOI 10.1038/s41550-020-1130-3; Coughlin MW, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.022006; Coughlin MW, 2020, MON NOT R ASTRON SOC, V492, P863, DOI 10.1093/mnras/stz3457; Coughlin MW, 2019, ASTROPHYS J LETT, V885, DOI 10.3847/2041-8213/ab4ad8; Coughlin MW, 2019, MON NOT R ASTRON SOC, V489, P5775, DOI 10.1093/mnras/stz2485; Coughlin MW, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/aaff99; Coughlin MW, 2018, MON NOT R ASTRON SOC, V478, P692, DOI 10.1093/mnras/sty1066; Coulter DA, 2023, PUBL ASTRON SOC PAC, V135, DOI 10.1088/1538-3873/acd662; Coulter DA, 2017, SCIENCE, V358, P1556, DOI 10.1126/science.aap9811; Cowperthwaite PS, 2017, ASTROPHYS J LETT, V848, DOI 10.3847/2041-8213/aa8fc7; Cutri R., 2012, Explanatory Supplement to the WISE All-Sky Data Release Products; Cutri R. M., 2003, 2MASS All Sky Catalog of point sources; Dalya G., 2021, YCAT, VVII/291; De K, 2020, PUBL ASTRON SOC PAC, V132, DOI 10.1088/1538-3873/ab6069; Dekany R, 2020, PUBL ASTRON SOC PAC, V132, DOI 10.1088/1538-3873/ab4ca2; Dietrich T, 2020, SCIENCE, V370, DOI 10.1126/science.abb4317; Duev DA, 2021, ASTRON J, V161, DOI 10.3847/1538-3881/abea7b; Duev DA, 2019, MON NOT R ASTRON SOC, V489, P3582, DOI 10.1093/mnras/stz2357; Feindt U, 2019, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2019/10/005; Fernique P., 2022, IVOA RECOMMENDATION; Fernique P, 2015, Arxiv, DOI [arXiv:1505.02937, DOI arXiv:1505.02937.null]; Flewelling H., 2018, AAS Meeting, V231, p436.01; Förster F, 2021, ASTRON J, V161, DOI 10.3847/1538-3881/abe9bc; Fremling C, 2020, ASTROPHYS J, V895, DOI 10.3847/1538-4357/ab8943; Fremling C, 2021, ASTROPHYS J LETT, V917, DOI 10.3847/2041-8213/ac116f; Gehrels N, 2004, ASTROPHYS J, V611, P1005, DOI 10.1086/422091; Goldstein A, 2017, ASTROPHYS J LETT, V848, DOI 10.3847/2041-8213/aa8f41; Goldstein DA, 2019, ASTROPHYS J LETT, V881, DOI 10.3847/2041-8213/ab3046; Gomez S, 2019, ASTROPHYS J LETT, V884, DOI 10.3847/2041-8213/ab4ad5; Gompertz BP, 2020, MON NOT R ASTRON SOC, V497, P726, DOI 10.1093/mnras/staa1845; Górski KM, 2005, ASTROPHYS J, V622, P759, DOI 10.1086/427976; Graham M., 2017, IVOA RECOMMENDATION; Graham MJ, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/ab006c; Guillochon J, 2018, ASTROPHYS J SUPPL S, V236, DOI 10.3847/1538-4365/aab761; Ho AYQ, 2020, ASTROPHYS J, V905, DOI 10.3847/1538-4357/abc34d; Hotokezaka K, 2019, NAT ASTRON, V3, P940, DOI 10.1038/s41550-019-0820-1; Ivezic Z., 2019, ASTROPHYS J, V873, P111, DOI 10.3847/1538-4357/ab042c; Kasliwal M. M., 2019, MNRAS, V510, pL7, DOI [10.1093/mnrasl/slz007, DOI 10.1093/MNRASL/SLZ007]; Kasliwal M. M., 2020, ARXIV200611306; Kumar R., 2019, Journal of Open Source Software, V4, P1143, DOI DOI 10.21105/JOSS.01143; Li WD, 2003, PUBL ASTRON SOC PAC, V115, P844, DOI 10.1086/376432; Licorish SA, 2022, J SYST SOFTWARE, V186, DOI 10.1016/j.jss.2021.111156; Lourie NP, 2020, PROC SPIE, V11447, DOI 10.1117/12.2561210; Lundquist MJ, 2019, ASTROPHYS J LETT, V881, DOI 10.3847/2041-8213/ab32f2; Mahabal A, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/aaf3fa; Masci FJ, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/aae8ac; Matheson T, 2021, ASTRON J, V161, DOI 10.3847/1538-3881/abd703; Meegan C, 2009, ASTROPHYS J, V702, P791, DOI 10.1088/0004-637X/702/1/791; Metzger BD, 2017, LIVING REV RELATIV, V20, DOI 10.1007/s41114-017-0006-z; Möller A, 2021, MON NOT R ASTRON SOC, V501, P3272, DOI 10.1093/mnras/staa3602; Naul B., 2016, cesium: Open-source platform for time-series inference; Nordin J, 2019, ASTRON ASTROPHYS, V631, DOI 10.1051/0004-6361/201935634; Pang PTH, 2024, Arxiv, DOI arXiv:2205.08513; Parazin B, 2022, ASTROPHYS J, V935, DOI 10.3847/1538-4357/ac7fa2; Patterson MT, 2019, PUBL ASTRON SOC PAC, V131, DOI 10.1088/1538-3873/aae904; Perley DA, 2020, ASTROPHYS J, V904, DOI 10.3847/1538-4357/abbd98; Petrov P, 2022, ASTROPHYS J, V924, DOI 10.3847/1538-4357/ac366d; Pian E, 2017, NATURE, V551, P67, DOI 10.1038/nature24298; Reichherzer P, 2021, ASTROPHYS J SUPPL S, V256, DOI 10.3847/1538-4365/ac1517; Ricker GR, 2014, PROC SPIE, V9143, DOI 10.1117/12.2063489; Rigault M, 2019, ASTRON ASTROPHYS, V627, DOI 10.1051/0004-6361/201935344; Rosswog S, 2018, ASTRON ASTROPHYS, V615, DOI 10.1051/0004-6361/201732117; Rosswog S, 2017, CLASSICAL QUANT GRAV, V34, DOI 10.1088/1361-6382/aa68a9; Ryan G, 2020, ASTROPHYS J, V896, DOI 10.3847/1538-4357/ab93cf; Savchenko V, 2017, ASTROPHYS J LETT, V848, DOI 10.3847/2041-8213/aa8f94; Seaman R., 2011, Sky Event Reporting Metadata Version 2.0 IVOA Recommendation; Singer L., 2023, AAS M, V241, p108.02; Singer LP, 2022, ASTRON J, V163, DOI 10.3847/1538-3881/ac5ab8; Smartt SJ, 2017, NATURE, V551, P75, DOI 10.1038/nature24303; Smith KW, 2020, PUBL ASTRON SOC PAC, V132, DOI 10.1088/1538-3873/ab936e; Smith KW., 2019, Research Notes of the AAS, V3, P26, DOI [10.3847/2515-5172/ab020f, DOI 10.3847/2515-5172/AB020F]; Steele IA, 2004, P SOC PHOTO-OPT INS, V5489, P679, DOI 10.1117/12.551456; Stonebraker M., 1986, SIGMOD Record, V15, P340, DOI 10.1145/16856.16888; Street RA, 2018, PROC SPIE, V10707, DOI 10.1117/12.2312293; Tachibana Y, 2018, PUBL ASTRON SOC PAC, V130, DOI 10.1088/1538-3873/aae3d9; Tonry JL, 2018, PUBL ASTRON SOC PAC, V130, DOI 10.1088/1538-3873/aabadf; Valenti S, 2017, ASTROPHYS J LETT, V848, DOI 10.3847/2041-8213/aa8edf; van Roestel J, 2021, ASTRON J, V161, DOI 10.3847/1538-3881/abe853; Walt van der., 2019, JOSS, V4, P1247, DOI DOI 10.21105/JOSS.01247; Watson D, 2019, NATURE, V574, P497, DOI 10.1038/s41586-019-1676-3; Wyatt SD, 2020, ASTROPHYS J, V894, DOI 10.3847/1538-4357/ab855e; Yao Y., 2021, TNSAN, V2021-258; Zechmeister M, 2009, ASTRON ASTROPHYS, V496, P577, DOI 10.1051/0004-6361:200811296	118	14	14	18	20	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0067-0049	1538-4365		ASTROPHYS J SUPPL S	Astrophys. J. Suppl. Ser.	AUG 1	2023	267	2							31	10.3847/1538-4365/acdee1	http://dx.doi.org/10.3847/1538-4365/acdee1			17	Astronomy & Astrophysics	Science Citation Index Expanded (SCI-EXPANDED)	Astronomy & Astrophysics	O1OV4		Green Published, Green Submitted, gold			2024-07-03	WOS:001041591800001
C	Sikand, S; Phokela, KK; Sharma, VS; Singi, K; Kaulgud, V; Tung, T; Sharma, P; Burden, AP		Chakrabarti, SK; Rastogi, A; Ghosh, S; Komondoor, R; Medicherla, RK; Kumar, L; Godboley, S		Sikand, Samarth; Phokela, Kanchanjot Kaur; Sharma, Vibhu Saujanya; Singi, Kapil; Kaulgud, Vikrant; Tung, Teresa; Sharma, Pragya; Burden, Adam P.			How much SPACE do metrics have in GenAI assisted software development?	PROCEEDINGS OF THE 17TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, ISEC 2024			English	Proceedings Paper	17th Innovations in Software Engineering Conference (ISEC)	FEB 22-24, 2024	IIITB Bangalore, Bangalore, INDIA	ACM India SIGSOFT Chapter, ACM In Cooperat, IIITB Bangalore, Ctr Technol Res & Innovat Digital Governance, TCS Res, Microsoft, IBM, ABB, Google, ISoft, ACM Chapter Conference	IIITB Bangalore	Generative AI; Software; SDLC; Metrics; Developer Productivity		Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer's experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer's experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs.	[Sikand, Samarth; Phokela, Kanchanjot Kaur; Sharma, Vibhu Saujanya; Singi, Kapil; Kaulgud, Vikrant] Accenture Labs, Bengaluru, Karnataka, India; [Tung, Teresa; Burden, Adam P.] Accenture, New York, NY USA; [Sharma, Pragya] Accenture, Bengaluru, India	Accenture	Sikand, S (corresponding author), Accenture Labs, Bengaluru, Karnataka, India.	s.sikand@accenture.com; kanchanjot.k.phokela@accenture.com; vibhu.sharma@accenture.com; kapil.singi@accenture.com; vikrant.kaulgud@accenture.com; teresa.tung@accenture.com; pragya.c.sharma@accenture.com; adam.p.burden@accenture.com		Sharma, Vibhu Saujanya/0009-0002-2352-2090; SINGI, KAPIL/0009-0008-5785-9509; Phokela, Kanchanjot Kaur/0009-0003-0208-9803				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Al Madi N, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3560438; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Barke S., 2022, arXiv; Bird C, 2023, COMMUN ACM, V66, P56, DOI 10.1145/3589996; Dibia V, 2023, Arxiv, DOI arXiv:2210.16494; Evtikhiev M, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111741; Forsgren Nicole, 2021, ACM Queue, V19, P20, DOI 10.1145/3454122.3454124; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Roziere B, 2024, Arxiv, DOI arXiv:2308.12950; Sandoval G, 2022, Arxiv, DOI arXiv:2208.09727; Sun J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P212, DOI 10.1145/3490099.3511119; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vasconcelos Helena, 2022, VIRTUAL WORKSHOP HUM, P1; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569; Zan DG, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7443; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	19	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1767-3				2024									14	10.1145/3641399.3641419	http://dx.doi.org/10.1145/3641399.3641419			5	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6ID					2024-07-03	WOS:001174625700014
