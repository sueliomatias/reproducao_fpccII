PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Guigue, PA; Meyer, R; Thivolle-Lioux, G; Brezinov, Y; Levin, G				Guigue, Paul-Adrien; Meyer, Raanan; Thivolle-Lioux, Gaetan; Brezinov, Yoav; Levin, Gabriel			Performance of ChatGPT in French language Parcours d′Acces Specifique Sante test and in OBGYN	INTERNATIONAL JOURNAL OF GYNECOLOGY & OBSTETRICS			English	Article						ChatGPT; French; large language models; OBGYN; performance; test	SUCCESS	Objectives: To evaluate the performance of ChatGPT in a French medical school entrance examination. Methods: A cross-sectional study using a consecutive sample of text-based multiple-choice practice questions for the Parcours d ' Acces Specifique Sante. ChatGPT answered questions in French. We compared performance of ChatGPT in obstetrics and gynecology (OBGYN) and in the whole test. Results: Overall, 885 questions were evaluated. The mean test score was 34.0% (306; maximal score of 900). The performance of ChatGPT was 33.0% (292 correct answers, 885 questions). The performance of ChatGPT was lower in biostatistics (13.3% +/- 19.7%) than in anatomy (34.2% +/- 17.9%; P = 0.037) and also lower than in histology and embryology (40.0% +/- 18.5%; P = 0.004). The OBGYN part had 290 questions. There was no difference in the test scores and the performance of ChatGPT in OBGYN versus the whole entrance test (P = 0.76 vs P = 0.10, respectively). Conclusions: ChatGPT answered one-third of questions correctly in the French test preparation. The performance in OBGYN was similar.	[Guigue, Paul-Adrien; Thivolle-Lioux, Gaetan] Univ Claude Bernard Lyon I, Lyon, France; [Guigue, Paul-Adrien; Brezinov, Yoav; Levin, Gabriel] McGill Univ, Jewish Gen Hosp, Lady Davis Inst Canc Res, Montreal, PQ, Canada; [Meyer, Raanan] Chaim Sheba Med Ctr, Dept Obstet & Gynecol, Ramat Gan, Israel; [Meyer, Raanan] Tel Aviv Univ, Fac Med, Tel Aviv, Israel; [Meyer, Raanan] Cedar Sinai Med Ctr, Los Angeles, CA USA; [Thivolle-Lioux, Gaetan] Ctr Rech Cancerol Lyon CRCL, Lyon, France; [Levin, Gabriel] Hebrew Univ Jerusalem, Fac Med, Hadassah Med Ctr, Dept Gynecol Oncol, Jerusalem, Israel; [Levin, Gabriel] McGill Univ, Lady Davis Inst Canc Res, Montreal, PQ, Canada	Universite Claude Bernard Lyon 1; McGill University; Chaim Sheba Medical Center; Tel Aviv University; Cedars Sinai Medical Center; Universite Claude Bernard Lyon 1; Hebrew University of Jerusalem; Hadassah University Medical Center; McGill University	Levin, G (corresponding author), McGill Univ, Lady Davis Inst Canc Res, Montreal, PQ, Canada.	gabriel.levin2@mail.mcgill.ca		Brezinov, Yoav/0000-0001-6452-9868				Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT, ABOUT US; Gillois P, 2015, PRESSE MED, V44, pE353, DOI 10.1016/j.lpm.2015.03.027; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Huguier M, 2014, B ACAD NAT MED PARIS, V198, P1367, DOI 10.1016/S0001-4079(19)31231-2; Levin G, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2023.100993; Levin G, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2023.100936; Lhuaire M, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1903-5; Medenilla A., 2023, PLoS Digital Health, V2; Rouprêt M, 2005, PRESSE MED, V34, P786, DOI 10.1016/S0755-4982(05)84042-4; Segouin C, 2007, MED EDUC, V41, P295, DOI 10.1111/j.1365-2929.2007.02690.x; Soong TK, 2021, ADV MED EDUC PRACT, V12, P167, DOI 10.2147/AMEP.S287926; Wikipedia, PREM ANN COMM ET SAN; Windish DM, 2007, JAMA-J AM MED ASSOC, V298, P1010, DOI 10.1001/jama.298.9.1010	16	3	3	5	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0020-7292	1879-3479		INT J GYNECOL OBSTET	Int. J. Gynecol. Obstet.	MAR	2024	164	3					959	963		10.1002/ijgo.15083	http://dx.doi.org/10.1002/ijgo.15083		SEP 2023	5	Obstetrics & Gynecology	Science Citation Index Expanded (SCI-EXPANDED)	Obstetrics & Gynecology	HU8M9	37655838	hybrid			2024-07-03	WOS:001059810100001
C	Desai, S; Sharma, T; Saha, P			ACM	Desai, Smit; Sharma, Tanusree; Saha, Pratyasha			Using ChatGPT in HCI Research-A Trioethnography	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023			English	Proceedings Paper	5th International Conference on Conversational User Interfaces (CUI)	JUL 19-21, 2023	Eindhoven Univ Technol, Eindhoven, NETHERLANDS	Assoc Comp Machinery, ACM SIGCHI, Bold Insight UK, Eindhoven Univ Technol, Eindhoven AI Syst Inst, HMD Res	Eindhoven Univ Technol	Trioethnography; ChatGPT; Large Language Models (LLMs); Situated XAI	SOCIAL PRESENCE	This paper explores the lived experience of using ChatGPT in HCI research through a month-long trioethnography. Our approach combines the expertise of three HCI researchers with diverse research interests to reflect on our daily experience of living and working with ChatGPT. Our findings are presented as three provocations grounded in our collective experiences and HCI theories. Specifically, we examine (1) the emotional impact of using ChatGPT, with a focus on frustration and embarrassment, (2) the absence of accountability and consideration of future implications in design and raise (3) questions around bias from a Global South perspective. Our work aims to inspire critical discussions about utilizing ChatGPT in HCI research and advance equitable and inclusive technological development.	[Desai, Smit] Univ Illinois, Sch Informat Sci, Urbana, IL 61801 USA; [Sharma, Tanusree] Univ Illinois, Informat, Urbana, IL USA; [Saha, Pratyasha] Univ Dhaka, Dept Phys, Dhaka, Bangladesh	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; University of Dhaka	Desai, S (corresponding author), Univ Illinois, Sch Informat Sci, Urbana, IL 61801 USA.	smitad2@illinois.edu; tsharma6@illinois.edu; pratyasha.saha1195@gmail.com		Desai, Smit/0000-0001-6983-8838; Sharma, Tanusree/0000-0003-1523-163X; Saha, Pratyasha/0000-0003-2987-672X				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, Futurama (New York World's fair); [Anonymous], Saudi Arabia: Haraj.sa app reportedly " facilitating exploitation" of "auctioned" Domestic Migrant Workers; incl. com- ment from Apple.; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bathaee Y., 2017, Harvard Journal ofLaw Technology, V31, P889; Beede E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376718; Bellemo V, 2019, LANCET DIGIT HEALTH, V1, pE35, DOI 10.1016/S2589-7500(19)30004-4; Brandli L., 2021, Gender Equality. Encyclopedia of the UN Sustainable Development Goals, DOI DOI 10.1007/978-3-319-95687-9_107; Broussard M, 2018, ARTIFICIAL UNINTELLIGENCE: HOW COMPUTERS MISUNDERSTAND THE WORLD; Camus A., 1965, MYTH SISYPHUS OTHER; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cecchinato ME, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3557, DOI 10.1145/3025453.3025538; Chin Jessie, 2021, Technology, Mind, and Behavior, DOI DOI 10.1037/TMS0000027; Chowdhury R., 2023, Wired; Costa M, 2001, J NONVERBAL BEHAV, V25, P225, DOI 10.1023/A:1012544204986; Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539; Desai S, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544535; Deterding Sebastian, 2015, P 33 ANN ACM C EXT A, P2365, DOI DOI 10.1145/2702613.2702647; Ehsan U, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445188; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; Evans Dylan, 2002, Emotion: The science of sentiment; Garcia T, 2014, SPECUL REALISM, P1; Glikson E, 2020, ACAD MANAG ANN, V14, P627, DOI 10.5465/annals.2018.0057; Hadfield G.K., 2022, Explanation and justification: Ai decision-making, Law, and the rights of Citizens; Harrisberg K., 2023, TimesLIVE; Hertzum M, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3582432; Hiriyur S., 2018, Feminism in India; Holzinger A, 2020, KUNSTL INTELL, V34, P193, DOI 10.1007/s13218-020-00636-z; Howell N, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3462447; Jain D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P236, DOI 10.1145/3308561.3353800; Jipguep-Akhtar M, 2020, SOC FORCES, V98, DOI 10.1093/sf/soz162; Johnson Deborah G., 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kip Viscusi W., 2018, Pricing Lives: Guideposts for a Safer Society, DOI DOI 10.2307/J.CTVC772D8; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Lockton D, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P1579, DOI 10.1145/3357236.3395482; Lucero A, 2019, DIS '19 COMPANION: COMPANION PUBLICATION OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P385, DOI 10.1145/3301019.3319996; Lucero A, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P765, DOI 10.1145/3196709.3196731; Mack K, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3471199; Mathur A., 2021, P 2021 CHI C HUMAN F, DOI DOI 10.1145/3411764.3445610; Mgala Mvurya., 2015, P 7 INT C INF COMM T, P1; Moreira MWL, 2019, J AMB INTEL HUM COMP, V10, P4121, DOI 10.1007/s12652-019-01230-4; Ni Y, 2021, IEEE GEOSCI REMOTE S, V18, P1545, DOI 10.1109/LGRS.2020.3006019; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289; Okolo CT, 2022, PROCEEDINGS OF THE 4TH ACM SIGCAS/SIGCHI CONFERENCE ON COMPUTING AND SUSTAINABLE SOCIETIES, COMPASS'22, P439, DOI 10.1145/3530190.3534802; openai, INTRO CHATGPT; Perrigo B, 2023, Time; Pradhan Alisha, 2021, CUI '21: CUI 2021 - 3rd Conference on Conversational User Interfaces, DOI 10.1145/3469595.3469607; Sambasivan N, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P315, DOI 10.1145/3442188.3445896; Sawyer R. D., 2012, Duoethnography; Scholz T., 2016, PLATFORM COOPERATIVI; Seberger JS, 2021, INFORM COMMUN SOC, V24, P1712, DOI 10.1080/1369118X.2020.1726985; Srinivasan Ramya, 2022, Journal of Responsible Technology, V9; Tehrany MS, 2014, J HYDROL, V512, P332, DOI 10.1016/j.jhydrol.2014.03.008; Tiku N, 2022, WASH POST; Ullman D, 2017, ACMIEEE INT CONF HUM, P309, DOI 10.1145/3029798.3038423; Vaswani A, 2017, ADV NEUR IN, V30; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Winner Langdon., 1978, AUTONOMOUS TECHNOLOG; Xiang Chloe, 2023, VICE; Zhang YF, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P295, DOI 10.1145/3351095.3372852	62	2	3	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0014-9				2023									8	10.1145/3571884.3603755	http://dx.doi.org/10.1145/3571884.3603755			6	Computer Science, Cybernetics; Psychology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Psychology	BW2OK		Green Submitted			2024-07-03	WOS:001122710800008
C	Klamra, C; Krynska, K; Ogrodniczuk, M		Goh, DH; Chen, SJ; Tuarob, S		Klamra, Cezary; Krynska, Katarzyna; Ogrodniczuk, Maciej			Evaluating the Use of Generative LLMs for Intralingual Diachronic Translation of Middle-Polish Texts into Contemporary Polish	LEVERAGING GENERATIVE INTELLIGENCE IN DIGITAL LIBRARIES: TOWARDS HUMAN-MACHINE COLLABORATION, ICADL 2023, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	25th International Conference on Asia-Pacific Digital Libraries (ICADL)	DEC 04-07, 2023	Taipei, TAIWAN			Intralingual diachronic translation; Automatic annotation; Large Language Models		This paper presents efforts towards creating a tool for translating texts from Middle Polish into modern Polish. Archaic texts sourced from the CBDU digital library were translated into modern language using ChatGPT and the resulting parallel corpus was used to train a neural text-to-text model. We assessed the results using automatic metrics and performed human evaluation of translations of the best-performing model and ChatGPT. Even though the performance of the trained models was far from perfect, the quality of translations produced with ChatGPT was good in most cases. Although caution should be exercised, we believe that LLMs have a high potential for text-to-text annotation applications.	[Klamra, Cezary; Ogrodniczuk, Maciej] Polish Acad Sci, Inst Comp Sci, Jana Kazimierza 5, PL-01248 Warsaw, Poland; [Krynska, Katarzyna] Polish Acad Sci, Inst Polish Language, Al Mickiewicza 31, PL-31120 Krakow, Poland	Polish Academy of Sciences; Institute of Computer Science of the Polish Academy of Sciences; Polish Academy of Sciences; Institute of the Polish Language of the Polish Academy of Sciences	Ogrodniczuk, M (corresponding author), Polish Acad Sci, Inst Comp Sci, Jana Kazimierza 5, PL-01248 Warsaw, Poland.	katarzyna.krynska@ijp.pan.pl; maciej.ogrodniczuk@ipipan.waw.pl						Agrawal Sweta., 2023, FINDINGS ACL, P8857, DOI 10.18653/v1/2023.findings-acl.564; Bawden R, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3354; Chrabrowa A, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4374; Ding BS, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11173; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Gruszczynski W., 2010, MAT K POLSK BIBL CYF, P23; Gruszczynski W, 2022, LANG RESOUR EVAL, V56, P309, DOI 10.1007/s10579-021-09549-1; Hartvigsen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3309; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Jassem K., 2017, Investig. Linguist., V37, P17, DOI [10.14746/il.2017.37.2, DOI 10.14746/IL.2017.37.2]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Kieras W, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3854; Kocmi Tom, 2021, P 6 C MACHINE TRANSL, P478; Korchagina Natalia, 2017, P NODALIDA 2017 WORK, P12; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; Laskar MTR, 2023, Arxiv, DOI arXiv:2305.06147; Liu DYH, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3325887; Minixhofer B, 2023, Arxiv, DOI arXiv:2305.18893; Ogrodniczuk M, 2022, LECT NOTES COMPUT SC, V13636, P430, DOI 10.1007/978-3-031-21756-2_34; Park C, 2020, IEEE ACCESS, V8, P116617, DOI 10.1109/ACCESS.2020.3004879; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2685; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Skórzewski P, 2020, LECT NOTES COMPUT SC, V12598, P73, DOI 10.1007/978-3-030-66527-2_6; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; White John S., 1994, P 1 C ASS MACH TRANS; Yang Z., 2021, Natural Language Processing and Chinese Computing, P116, DOI 10.1007/978-3-030-88480-2_10; Zhiyuan Zhang, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P157, DOI 10.1007/978-3-030-32236-6_13	33	0	0	2	2	SPRINGER-VERLAG SINGAPORE PTE LTD	SINGAPORE	152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE	0302-9743	1611-3349	978-981-99-8084-0; 978-981-99-8085-7	LECT NOTES COMPUT SC			2023	14457						18	27		10.1007/978-981-99-8085-7_2	http://dx.doi.org/10.1007/978-981-99-8085-7_2			10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Information Science & Library Science	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science	BW5HE					2024-07-03	WOS:001160644600002
C	Liu, MH; Xue, C; Zhai, YX			Assoc Computing Machinery	Liu, Minghui; Xue, Cheng; Zhai, Yuxiang			Lab to Virtual: Comparing Real and AI-Generated User Interviews in Home Appliances Evaluation	2023 11TH INTERNATIONAL SYMPOSIUM OF CHINESE CHI, CHINESE CHI2023			English	Proceedings Paper	11th International Symposium of Chinese CHI (Chinese CHI)	NOV 13-16, 2023	UID Bali Campus, Tsinghua SE Asia Ctr, Denpasar, INDONESIA	ICACHI	UID Bali Campus, Tsinghua SE Asia Ctr	User Study; Large Language Model; Artificial Intelligence		This study provides insights into the use of conversational AI, particularly ChatGPT, in household appliance evaluation interviews and how it differs from real user behaviour. Three comparison experiments (real researcher-real user, real researcher-simulated user vs. simulated researcher and simulated user) reveal the differences in the responses of ChatGPT simulated and real users in specific evaluation scenarios, especially in the evaluation of product appearance, GUI, and PUI. The study found that although simulated users agreed with real users in evaluating the core features of smart appliances, there were limitations in certain practical experience aspects and significant differences in SUS, learning ability, and usability scores across experimental settings. The study also explores the advantages and disadvantages of incorporating simulated users into the product evaluation process, concluding that this introduces an innovative approach to product evaluation that, although challenging, demonstrates the great potential of simulated users in future product evaluation.	[Liu, Minghui; Xue, Cheng; Zhai, Yuxiang] Tsinghua Univ, Acad Arts & Design, Beijing, Peoples R China; [Liu, Minghui; Xue, Cheng; Zhai, Yuxiang] Tsinghua Univ, Future Lab, Beijing, Peoples R China	Tsinghua University; Tsinghua University	Liu, MH (corresponding author), Tsinghua Univ, Acad Arts & Design, Beijing, Peoples R China.; Liu, MH (corresponding author), Tsinghua Univ, Future Lab, Beijing, Peoples R China.	liu-mh20@mails.tsinghua.edu.cn; 2249931737@qq.com; diyx22@mails.tsinghua.edu.cn	Liu, Minghui/IQS-1893-2023	Liu, Minghui/0000-0001-7242-5452				Averkin AN, 2021, J COMPUT SYS SC INT+, V60, P966, DOI 10.1134/S1064230721060046; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Barandas M, 2015, PROCEDIA MANUF, V3, P823, DOI 10.1016/j.promfg.2015.07.337; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brooke JSUS., 1996, Usability Eval. Ind., V189194, P4, DOI DOI 10.1201/9781498710411-35; Chen M., 2021, arXiv; Chowdhury Md Naseef-Ur-Rahman, 2023, 2023 3 INT C INTELLI, P1; Doshi R., 2023, medRxiv; Elin Mirza Niaz Zaman., IJFMRInternational Journal For Multidisciplinary Research, V5, P3; Flanagin AJ, 2014, ELECTRON COMMER RES, V14, P1, DOI 10.1007/s10660-014-9139-2; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Giorgi J, 2023, Arxiv, DOI arXiv:2305.02220; Giorgi John, 2023, P 5 CLIN NATURAL LAN, P323; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Hong Wilson Cheong Hin, 2023, Journal of Educational Technology and Innovation, V5, P1; Huseynov Farid., 2023, Contemporary Approaches of Digital Marketing and the Role of Machine Intelligence, P46, DOI DOI 10.4018/978-1-6684-7735-9.CH003; Kapgate D, 2022, INT J HUM-COMPUT INT, V38, P42, DOI 10.1080/10447318.2021.1921482; Karakose T, 2023, ADM SCI, V13, DOI 10.3390/admsci13070157; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Martins AI, 2015, PROCEDIA COMPUT SCI, V67, P293, DOI 10.1016/j.procs.2015.09.273; Mauro G, 2017, Arxiv, DOI arXiv:1701.08468; Polu S, 2020, Arxiv, DOI arXiv:2009.03393; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rueben M, 2016, ACMIEEE INT CONF HUM, P507, DOI 10.1109/HRI.2016.7451829; Sandlin J., 2022, ChatGPT arrives in the academic world; Santhosh R., 2023, P 2023 7 INT C TREND, P1614, DOI [10.1109/ICOEI56765.2023.10125747, DOI 10.1109/ICOEI56765.2023.10125747]; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Yang C, 2021, J THEOR APPL EL COMM, V16, P1598, DOI 10.3390/jtaer16050090; Yang JY, 2023, Arxiv, DOI arXiv:2308.06294; Yeh SY, 2010, CYBERPSYCH BEH SOC N, V13, P601, DOI 10.1089/cyber.2009.0323; Zhou PY, 2024, Arxiv, DOI arXiv:2303.13856; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	36	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1645-4				2023							571	581		10.1145/3629606.3629672	http://dx.doi.org/10.1145/3629606.3629672			11	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TJ					2024-07-03	WOS:001182063600062
C	Horawalavithana, S; Ayton, E; Sharma, S; Howland, S; Subramanian, M; Vasquez, S; Cosbey, R; Glenski, M; Volkova, S			Assoc Computat Linguist	Horawalavithana, Sameera; Ayton, Ellyn; Sharma, Shivam; Howland, Scott; Subramanian, Megha; Vasquez, Scott; Cosbey, Robin; Glenski, Maria; Volkova, Svitlana			Foundation Models of Scientific Knowledge for Chemistry: Opportunities, Challenges and Lessons Learned	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				Foundation models pre-trained on large corpora demonstrate significant gains across many natural language processing tasks and domains e.g., law, healthcare, education, etc. However, only limited efforts have investigated the opportunities and limitations of applying these powerful models to science and security applications. In this work, we develop foundation models of scientific knowledge for chemistry to augment scientists with the advanced ability to perceive and reason at scale previously unimagined. Specifically, we build large-scale (1.47B parameter) general-purpose models for chemistry that can be effectively used to perform a wide range of in-domain and out-of-domain tasks. Evaluating these models in a zero-shot setting, we analyze the effect of model and data scaling, knowledge depth, and temporality on model performance in context of model training efficiency. Our novel findings demonstrate that (1) model size significantly contributes to the task performance when evaluated in a zero-shot setting; (2) data quality (aka diversity) affects model performance more than data quantity; (3) similarly, unlike previous work (Luu et al., 2021) temporal order of the documents in the corpus boosts model performance only for specific tasks, e.g., SciQ; and (4) models pre-trained from scratch perform better on in-domain tasks than those tuned from general-purpose models like Open AI's GPT-2.	[Horawalavithana, Sameera; Ayton, Ellyn; Sharma, Shivam; Howland, Scott; Subramanian, Megha; Vasquez, Scott; Cosbey, Robin; Glenski, Maria; Volkova, Svitlana] Pacific Northwest Natl Lab, Richland, WA 99352 USA	United States Department of Energy (DOE); Pacific Northwest National Laboratory	Horawalavithana, S (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99352 USA.		Horawalavithana, Sameera/IAP-1738-2023	Sharma, Shivam/0009-0005-6374-7368; Horawalavithana, Sameera/0000-0002-0327-3819				Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; AMiner, US; Amini A, 2019, Arxiv, DOI arXiv:1905.13319; Andonian A., GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch; [Anonymous], BIOINFORMATICS, V36, P1234; Beltagy I., 2019, arXiv; Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432; Black S., 2022, Gpt-neox-20b: An open-source autoregressive language model; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Clark Christopher, 2019, ARXIV PREPRINT ARXIV; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cord19, US; de Marneffe Marie-Catherine, 2019, P SINN BEDEUTUNG; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gallagher R. J., 2017, Transactions of the Association for Computational Linguistics (TACL), V5, P529, DOI [10.1162/tacl_a_00078, DOI 10.1162/TACL_A_00078]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao Leo, 2021, A framework for few-shot language model evaluation; Guo Jiang, 2021, J CHEM INF MODEL; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Jaegle A., 2021, Perceiver: General perception with iterative attention, P2021; Jin Q, 2019, arXiv; Kanakarajan Kamal, P 20 WORKSH BIOM LAN, P143; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Lee CLY, 2020, Arxiv, DOI [arXiv:1909.11299, 10.48550/arXiv.1909.11299]; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Lewis Patrick, 2020, P 3 CLIN NATURAL LAN, P146, DOI 10.18653/v1/2020.clinicalnlp-1.17; Ling W, 2017, Arxiv, DOI arXiv:1705.04146; Liu X, 2021, Arxiv, DOI arXiv:2103.02410; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lo Kyle., 2020, P 58 ANN M ASS COMPU, P4969; Luu Kelvin, 2021, arXiv preprint arXiv 2111.07408; Merity S, 2016, Arxiv, DOI [arXiv:1609.07843, DOI 10.48550/ARXIV.1609.07843]; Mihaylov T, 2018, Arxiv, DOI [arXiv:1809.02789, 10.48550/arXiv.1809.02789]; Miolo G, 2021, Arxiv, DOI [arXiv:2104.09585, DOI 10.48550/ARXIV.2104.09585]; Naseem U, 2021, Arxiv, DOI arXiv:2107.04374; OAG, About Us; Paperno Denis, 2016, arXiv; Peng YF, 2019, Arxiv, DOI arXiv:1906.05474; Phan LN, 2021, Arxiv, DOI arXiv:2106.03598; Pontika Nancy, 2016, LIBER Quarterly, V25, P172, DOI 10.18352/lq.10138; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajbhandari S, 2020, Arxiv, DOI arXiv:1910.02054; Ramasesh V.V., 2021, INT C LEARNING REPRE; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Shin HC, 2020, Arxiv, DOI arXiv:2010.06060; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Singh A., 2021, arXiv; Smith S, 2022, arXiv; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Pilehvar MT, 2019, Arxiv, DOI arXiv:1808.09121; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang KS, 2020, QUANT SCI STUD, V1, P396, DOI 10.1162/qss_a_00021; Wang L. L., 2020, P 1 WORKSHOP NLP COV; Welbl J, 2017, Arxiv, DOI arXiv:1707.06209; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan Z, 2021, Arxiv, DOI arXiv:2104.10344; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	60	3	3	0	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							160	172						13	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900012
C	Neyem, A; Alcocer, JPS; Mendoza, M; Centellas-Claros, L; Gonzalez, LA; Paredes-Robles, C			Assoc Computing Machinery	Neyem, Andres; Sandoval Alcocer, Juan Pablo; Mendoza, Marcelo; Centellas-Claros, Leonardo; Gonzalez, Luis A.; Paredes-Robles, Carlos			Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		Generative AI; Large Language Models; ChatGPT; Software Engineering Education; Capstone Courses		StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.	[Neyem, Andres; Sandoval Alcocer, Juan Pablo; Mendoza, Marcelo; Centellas-Claros, Leonardo; Gonzalez, Luis A.; Paredes-Robles, Carlos] Pontificia Univ Catolica Chile, Comp Sci Dept, Santiago, Chile	Pontificia Universidad Catolica de Chile	Neyem, A (corresponding author), Pontificia Univ Catolica Chile, Comp Sci Dept, Santiago, Chile.	aneyem@uc.cl; juanpablo.sandoval@uc.cl; marcelo.mendoza@uc.cl; lcentellas@uc.cl; lagonza2@uc.cl; cparedesr@uc.cl	Mendoza, Marcelo/D-2312-2014; Sandoval Alcocer, Juan Pablo/CAA-0465-2022	Mendoza, Marcelo/0000-0002-7969-6041; Sandoval Alcocer, Juan Pablo/0000-0002-8335-4351; Gonzalez, Luis A./0000-0001-7210-2186; Paredes, Carlos/0009-0003-2616-0918; Centellas-Claros, Leonardo/0009-0008-3396-9332	National Center of Artificial Intelligence [CENIA FB210017]; Millennium Institute for Foundational Research on Data (IMFD) (ANID -Millennium Science Initiative Program) [ICN17_002]; ANID grant FONDECYT [1200211]; Chilean National Agency for Research and Development (ANID)/Scholarship Program/DOCTORADO NACIONAL/2021 [21212115]; ANID FONDECYT Iniciacion, Folio [11220885]; Enlace Scholarship, Graduate Studies Office, School of Engineering UC, Chile	National Center of Artificial Intelligence; Millennium Institute for Foundational Research on Data (IMFD) (ANID -Millennium Science Initiative Program); ANID grant FONDECYT; Chilean National Agency for Research and Development (ANID)/Scholarship Program/DOCTORADO NACIONAL/2021; ANID FONDECYT Iniciacion, Folio; Enlace Scholarship, Graduate Studies Office, School of Engineering UC, Chile	A. Neyem and M. Mendoza are supported by the National Center of Artificial Intelligence (CENIA FB210017, Basal ANID). M. Mendoza was also supported by the Millennium Institute for Foundational Research on Data (IMFD) (ANID -Millennium Science Initiative Program -Code ICN17_002) and ANID grant FONDECYT 1200211. Luis A. Gonzalez is supported by the Chilean National Agency for Research and Development (ANID)/Scholarship Program/DOCTORADO NACIONAL/2021-21212115. Juan P. Sandoval is supported by the ANID FONDECYT Iniciacion, Folio 11220885. L. Centellas is supported by the Enlace Scholarship, Graduate Studies Office, School of Engineering UC, Chile.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed A., 2010, 2010 IEEE International Conference on Management of Innovation & Technology (ICMIT 2010), P287, DOI 10.1109/ICMIT.2010.5492703; Alharbi W., 2023, Education Research International, V3, P1, DOI [10.1155/2023/4253331, DOI 10.1155/2023/4253331]; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; Aydin N., 2022, 2022 3 INT INF SOFTW, DOI [DOI 10.1109/IISEC56263.2022.9998298, 10.1109/iisec56263.2022.9998298]; Badran R, 2022, IEEE INT PROF COMMUN, P262, DOI 10.1109/ProComm53155.2022.00054; Bahrini Aram, 2023, 2023 Systems and Information Engineering Design Symposium (SIEDS), P274, DOI 10.1109/SIEDS58326.2023.10137850; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Berry FC, 2021, IEEE T EDUC, V64, P383, DOI 10.1109/TE.2021.3059739; Chelvan Ilamparithi Thirumai, 2021, 2021 IEEE International Professional Communication Conference (ProComm), P85, DOI 10.1109/ProComm52174.2021.00022; Clarke V, 2017, J POSIT PSYCHOL, V12, P297, DOI 10.1080/17439760.2016.1262613; Dale R, 2021, NAT LANG ENG, V27, P511, DOI 10.1017/S1351324921000164; Davenport Thomas H., 2022, Intuit: AIAssisted Writing with Writer. com, P89; Ebert C, 2023, IEEE SOFTWARE, V40, P30, DOI 10.1109/MS.2023.3265877; Gayed John, 2022, Exploring an AI-based writing Assistant's impact on English language learners, V3, DOI [10.1016/j.caeai.2022.100055, DOI 10.1016/J.CAEAI.2022.100055]; Jannach D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453154; Koltovskaia S, 2020, ASSESS WRIT, V44, DOI 10.1016/j.asw.2020.100450; Kumar Shreya, 2014, 2014 IEEE Frontiers in Education Conference (FIE). Proceedings, P1, DOI 10.1109/FIE.2014.7044167; Li J., 2021, 2021 INT C COMP INF, P309; Mahnic V, 2012, IEEE T EDUC, V55, P99, DOI 10.1109/TE.2011.2142311; McSkimming BM, 2021, 2021 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2021), DOI 10.1109/FIE49875.2021.9637198; Neyem A, 2014, PROCEEDINGS OF THE 45TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'14), P391, DOI 10.1145/2538862.2538920; Neyem A, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/6371793; Ozkan Necmettin, 2022, 2022 3rd International Informatics and Software Engineering Conference (IISEC), P1, DOI 10.1109/IISEC56263.2022.9998281; Pikkarainen M, 2008, EMPIR SOFTW ENG, V13, P303, DOI 10.1007/s10664-008-9065-9; Pramod D, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117539; Pu P., 2011, P 5 ACM C REC SYST, P157, DOI [10.1145/2043932.2043962, DOI 10.1145/2043932.2043962]; Ranalli J, 2022, LANG LEARN TECHNOL, V26; Ranalli J, 2018, COMPUT ASSIST LANG L, V31, P653, DOI 10.1080/09588221.2018.1428994; Schneider JG, 2020, 2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET 2020), P119, DOI 10.1145/3377814.3381715; Scott A, 2017, PROCEEDINGS OF THE 18TH ANNUAL CONFERENCE ON INFORMATION TECHNOLOGY EDUCATION (SIGITE'17), P1, DOI 10.1145/3125659.3125680; Siddiq ML, 2022, IEEE INT WORK C SO, P71, DOI 10.1109/SCAM55253.2022.00014; Srivastava A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P864, DOI 10.1109/CCAA.2017.8229928; Stray V, 2016, J SYST SOFTWARE, V114, P101, DOI 10.1016/j.jss.2016.01.004; Stray VG, 2012, EUROMICRO CONF PROC, P274, DOI 10.1109/SEAA.2012.16; Vijayakumar Sudha, 2022, 2022 IEEE Eighth International Conference on Big Data Computing Service and Applications (BigDataService), P53, DOI 10.1109/BigDataService55688.2022.00016; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	37	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							951	957		10.1145/3626252.3630854	http://dx.doi.org/10.1145/3626252.3630854			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP					2024-07-03	WOS:001181240800139
C	Petrocchi, M; Viviani, M		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Petrocchi, Marinella; Viviani, Marco			ROMCIR 2024: Overview of the 4th Workshop on Reducing Online Misinformation Through Credible Information Retrieval	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Information Retrieval; Information Disorder; Information Truthfulness; Misinformation; Explainability; Large Language Models		In the realm of the Social Web, we are continuously surrounded by information pollution, posing significant threats to both individuals and society as a whole. Instances of false news, for instance, wield the power to sway public opinion on matters of politics and finance. Deceptive reviews can either bolster or tarnish the reputation of businesses, while unverified medical advice may steer people toward harmful health practices. In light of this challenging landscape, it has become imperative to ensure that users have access to both topically relevant and truthful information that does not warp their perception of reality, and there has been a surge of interest in various strategies to combat disinformation through different contexts and multiple tasks. The purpose of the ROMCIR Workshop, for some years now, is precisely that of engaging the Information Retrieval community to explore potential solutions that extend beyond conventional misinformation detection approaches. Key objectives include integrating information truthfulness as a fundamental dimension of relevance within Information Retrieval Systems (IRSs) and ensuring that truthful search results are also explainable to IRS users. Moreover, it is essential to evaluate the role of generative models such as Language Models (LLMs) in inadvertently amplifying misinformation problems, and how they can be used to support IRSs.	[Petrocchi, Marinella] CNR, IIT, Pisa, Italy; [Petrocchi, Marinella] IMT Scuola Alti Studi Lucca, Lucca, Italy; [Viviani, Marco] Univ Milano Bicocca DISCo UNIMIB, Dept Informat Syst & Commun, Milan, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Informatica e Telematica (IIT-CNR); IMT School for Advanced Studies Lucca	Viviani, M (corresponding author), Univ Milano Bicocca DISCo UNIMIB, Dept Informat Syst & Commun, Milan, Italy.	marinella.petrocchi@iit.cnr.it; marco.viviani@unimib.it		Viviani, Marco/0000-0002-2274-9050	IIT-CNR [PE00000014]; EU [CN00000013]	IIT-CNR; EU(European Union (EU))	Partially supported by re-DESIRE: DissEmination of ScIentific REsults 2.0, funded by IIT-CNR; by SERICS (PE00000014) under the NRRP MUR program funded by the EU -NGEU; by the PNRR ICSC National Research Centre for High Performance Computing, Big Data and Quantum Computing (CN00000013), under the NRRP MUR program funded by the NextGenerationEU.	Bawden D, 1999, ASLIB PROC, V51, P249, DOI 10.1108/EUM0000000006984; Bozdag E, 2016, ETHICS INF TECHNOL, V17, P249, DOI 10.1007/s10676-015-9380-y; Cabitza F, 2022, Arxiv, DOI [arXiv:2203.03616, 10.48550/ARXIV.2203.03616, DOI 10.48550/ARXIV.2203.03616]; Chen SJ, 2023, COMPUT HUM BEHAV, V141, DOI 10.1016/j.chb.2022.107643; Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113; Khaleel I, 2020, PATIENT EDUC COUNS, V103, P15, DOI 10.1016/j.pec.2019.08.008; Kojima T, 2022, ADV NEUR IN; Lioma C, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P91, DOI 10.1145/3121050.3121072; Livraga G, 2019, 11TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES), P191, DOI 10.1145/3297662.3365829; Monteith S, 2024, BRIT J PSYCHIAT, V224, P33, DOI 10.1192/bjp.2023.136; Pasi G, 2020, Arxiv, DOI arXiv:2001.09473; Petrocchi M., 2022, ROMCIR 2022 CEUR WOR, V3138, pi; Petrocchi M., 2023, ROMCIR 2023 CEUR WOR, V3406, pi; Saracco F., 2021, ROMCIR 2021 CEUR WOR, V2838, pi; Suominen Hanna, 2021, Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12880), P308, DOI 10.1007/978-3-030-85251-1_21; Villa G, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00779-3; Viviani M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1209; Wardle C., 2017, Counc. Europe, V27; Xu Danni, 2023, MM '23: Proceedings of the 31st ACM International Conference on Multimedia, P9291, DOI 10.1145/3581783.3612704	19	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56068-2; 978-3-031-56069-9	LECT NOTES COMPUT SC			2024	14612						403	408		10.1007/978-3-031-56069-9_54	http://dx.doi.org/10.1007/978-3-031-56069-9_54			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EC					2024-07-03	WOS:001211835200054
C	Veneri, A			ACM	Veneri, Alberto			Explaining Learning to Rank Methods to Improve Them	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Explainable Artificial Intelligence; Learning to Rank; Large Language Models; Text Ranking		State-of-the-art methods for Learning to Rank (LtR), either designed for tabular or textual data, are incredibly complex. Increasing the complexity of the models has many drawbacks, including difficulties in understanding the logic behind each prediction and a lack of trust in the system during its deployment. In this paper, which describes the author's goals during his Ph.D., there is an analysis and discussion of how we can use the ideas and tools coming from the eXplainable Artificial Intelligence (XAI) field to make the most effective methods for LtR understandable to the practitioners with the final goal of making them more efficient and/or understand better when they can be improved. The strategies adopted to achieve the aforementioned goals are different and based on the type of models analyzed, which go from more traditional LtR models based on ensembles of decision trees and using handcrafted features to fairly new neural LtR models using text data.	[Veneri, Alberto] Ca Foscari Univ Venice, ISTI, CNR, Venice, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); Universita Ca Foscari Venezia	Veneri, A (corresponding author), Ca Foscari Univ Venice, ISTI, CNR, Venice, Italy.	alberto.veneri@unive.it	Veneri, Alberto/IQT-3604-2023	Veneri, Alberto/0000-0003-2094-3375				Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Anand Avishek, 2022, EXPLAINABLE INFORM R, DOI [10.48550/arXiv.2211.02405, DOI 10.48550/ARXIV.2211.02405]; BigScience Workshop, 2023, ARXIV221105100 CS; Bruch S, 2023, FOUND TRENDS INF RET, V17, P1, DOI 10.1561/1500000071; BURGES C. J, From RankNet to LambdaRank to LambdaMART: An Overview; Camara Arthur, 2020, LECT NOTES COMPUTER, P605, DOI [10.1007/978-3-030- 4 5439-5_40, DOI 10.1007/978-3-030-4]; Fernando ZT, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1005, DOI 10.1145/3331184.3331312; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Hutson M, 2018, SCIENCE, V360, P478, DOI 10.1126/science.360.6388.478; Lucchese C, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2255, DOI 10.1145/3477495.3531840; Lucchese C, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P73, DOI 10.1145/2766462.2767733; Lucchese Claudio, 2023, P 32 ACM INT C INF K, DOI [10.1145/3583780.3615225, DOI 10.1145/3583780.3615225]; Lucchese Claudio, 2023, GAM FOREST EXPLANATI, DOI [10.48786/EDBT.2023.14, DOI 10.48786/EDBT.2023.14]; Nogueira Rodrigo, 2019, ARXIV191014424, DOI [10.48550/arXiv.1910.14424, DOI 10.48550/ARXIV.1910.14424]; Olah C., 2020, DISTILL, V5, DOI [10.2 3915/distill.00024.001, DOI 10.23915/DISTILL.00024.001]; Panigutti C, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1139, DOI 10.1145/3593013.3594069; Rennings Daniel, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P489, DOI 10.1007/978-3-030-15712-8_32; Rizzo Matteo, 2023, ARXIV221214447 CS AI; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249; Singh J, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P770, DOI 10.1145/3289600.3290620; Verma M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1281, DOI 10.1145/3331184.3331377; Wu C, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3576923; Yu PX, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P669, DOI 10.1145/3477495.3532067; Zhang RQ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1823, DOI 10.1145/3340531.3411999; Zhuang HL, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P499, DOI 10.1145/3437963.3441796	26	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5185	5188		10.1145/3583780.3616002	http://dx.doi.org/10.1145/3583780.3616002			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		hybrid			2024-07-03	WOS:001161549505038
J	Miao, J; Thongprayoon, C; Craici, IM; Cheungpasitporn, W				Miao, Jing; Thongprayoon, Charat; Craici, Iasmina M.; Cheungpasitporn, Wisit			How to improve ChatGPT performance for nephrologists: a technique guide	JOURNAL OF NEPHROLOGY			English	Article; Early Access						ChatGPT; Large language model; LLM; Nephrology; Artificial intelligence; Technique guide		BackgroundThe integration of ChatGPT into nephrology presents opportunities for enhanced decision-making and patient care. However, refining its performance to meet the specific needs of nephrologists remains a challenge. This guide offers a strategic roadmap for advancing ChatGPT's effectiveness in nephrological applications.MethodsUtilizing the advanced capabilities of GPT-4, we customized user profiles to optimize the model's response quality for nephrological inquiries. We assessed the efficacy of chain-of-thought prompting versus standard prompting in delineating the diagnostic pathway for nephrogenic diabetes insipidus-associated hypernatremia and polyuria. Additionally, we explored the influence of integrating retrieval-augmented generation on the model's proficiency in detailing pharmacological interventions to decelerate the progression from chronic kidney disease (CKD) G3 to end-stage kidney disease (ESKD), comparing it to responses without retrieval-augmented generation.ResultsIn contrast to the standard prompting, the chain-of-thought method offers a step-by-step diagnostic process that mirrors the intricate thought processes needed for diagnosing nephrogenic diabetes insipidus-related hypernatremia and polyuria. This begins with an initial assessment, notably including a water deprivation test. After evaluating the outcomes of this test, the approach continues by identifying potential causes. Furthermore, if a patient's history suggests lithium usage, the chain-of-thought model adjusts by proposing a more customized course of action. In response to "List medication treatment to help slow progression of CKD G3 to ESKD?", GPT-4 only provides a general summary of medication options. Nevertheless, a specialized GPT-4 model equipped with a retrieval-augmented generation system delivers more precise responses, including renin-angiotensin system inhibitors, sodium-glucose cotransporter-2 inhibitors, and mineralocorticoid receptor antagonists. This aligns well with the 2024 KDIGO guidelines.ConclusionsGPT-4, when integrated with chain-of-thought prompting and retrieval-augmented generation techniques, demonstrates enhanced performance in the nephrology domain. This guide underscores the transformative potential of chain-of-thought and retrieval-augmented generation techniques in optimizing ChatGPT for nephrology, and highlights the ongoing need for innovative, tailored AI solutions in specialized medical fields.	[Miao, Jing; Thongprayoon, Charat; Craici, Iasmina M.; Cheungpasitporn, Wisit] Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA	Mayo Clinic	Cheungpasitporn, W (corresponding author), Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA.	wcheungpasitporn@gmail.com						Mayo M, 2023, Unraveling the power of chain-of-thought prompting in large language models; Merritt R, 2023, What is retrieval-augmented generation, aka RAG?; Miao J, 2024, MEDICINA-LITHUANIA, V60, DOI 10.3390/medicina60010148; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; OpenAI, 2023, Gpt-4v(ision) system card; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Shah D, 2023, The beginner's guide to hallucinations in large language models. 2023; Suppadungsuk S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12175550; Wolff T, 2023, How to craft prompts for maximum effectiveness	9	0	0	4	4	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1121-8428	1724-6059		J NEPHROL	J. Nephrol.	2024 MAY 21	2024										10.1007/s40620-024-01974-z	http://dx.doi.org/10.1007/s40620-024-01974-z		MAY 2024	7	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	RO2O9	38771519				2024-07-03	WOS:001228541300002
J	Alessandri-Bonetti, M; Liu, HY; Palmesano, M; Nguyen, VT; Egro, FM				Alessandri-Bonetti, Mario; Liu, Hilary Y.; Palmesano, Marco; Nguyen, Vu T.; Egro, Francesco M.			Online patient education in body contouring: A comparison between Google and ChatGPT	JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY			English	Letter						Patient education; Body contouring; Artificial intelligence; ChatGPT; Large language model		Appropriate patient education and preparation prior to surgery represent a fundamental step in managing expectations, avoiding unnecessary encounters and eventually achieving optimal outcomes. Thus, the objective of this study is to evaluate ChatGPT's potential as a viable source for patient education by comparing its responses and provided references to frequently asked questions on body contouring, with Google's. A Google search was conducted on July 15th, 2023, using the search term "body contouring surgery". The first 15 questions under the "People also ask" section and answers provided by Google were recorded. The 15 questions were then asked to ChatGPT-3.5. Four plastic surgeons evaluated the answers from 1 to 5 according to the Global Quality Scale. The mean score for responses given by Google was 2.55 +/- 1.29, indicating poor quality but some information present, of very limited use to patients. The mean score for responses produced by ChatGPT was 4.38 +/- 0.67, suggesting that the content was of good quality, useful to patients, and encompassed the most important topics. The difference was statistically significant (p = 0.001). Deficiencies in providing references represent one of the most evident weaknesses of ChatGPT. However, ChatGPT did not appear to spread misinformation, and the content of the generated responses was deemed of good quality and useful to patients. The integration of AI technology as a source for patient education has the potential to optimize patient queries on body contouring questions. (c) 2023 British Association of Plastic, Reconstructive and Aesthetic Surgeons. Published by Elsevier Ltd. All rights reserved.	[Alessandri-Bonetti, Mario; Liu, Hilary Y.; Nguyen, Vu T.; Egro, Francesco M.] Univ Pittsburgh, Dept Plast Surg, Med Ctr, 1350 Locust St,G103, Pittsburgh, PA 15219 USA; [Palmesano, Marco] Univ Roma Tor Vergata, Dept Plast Surg, Rome, Italy; [Egro, Francesco M.] Univ Pittsburgh, Med Ctr, Dept Plast Surg, 3550 Terrace St,6B Scaife Hall, Pittsburgh, PA 15261 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Rome Tor Vergata; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Egro, FM (corresponding author), Univ Pittsburgh, Med Ctr, Dept Plast Surg, 3550 Terrace St,6B Scaife Hall, Pittsburgh, PA 15261 USA.	francescoegro@gmail.com						Alessandri-Bonetti M, 2024, ANN BIOMED ENG, V52, P1107, DOI 10.1007/s10439-023-03325-8; Bernard A, 2007, AM J GASTROENTEROL, V102, P2070, DOI 10.1111/j.1572-0241.2007.01325.x; Cho HE, 2021, ANN PLAS SURG, V86, P463, DOI 10.1097/SAP.0000000000002471; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Rohrich RJ, 2021, PLAST RECONSTR SURG, V148, p104S, DOI 10.1097/01.prs.0000794912.60516.94	5	2	2	0	1	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1748-6815	1878-0539		J PLAST RECONSTR AES	J. Plast. Reconstr. Aesthet. Surg.	DEC	2023	87						390	402		10.1016/j.bjps.2023.10.091	http://dx.doi.org/10.1016/j.bjps.2023.10.091		NOV 2023	13	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	Z7FC8	37939643				2024-07-03	WOS:001113684800001
J	Hu, SL; Zhang, HJ; Zhang, WY				Hu, Shulin; Zhang, Huajun; Zhang, Wanying			Domain Knowledge Graph Question Answering Based on Semantic Analysis and Data Augmentation	APPLIED SCIENCES-BASEL			English	Article						domain knowledge graph; question answering; data augmentation; large language model		Information retrieval-based question answering (IRQA) and knowledge-based question answering (KBQA) are the main forms of question answering (QA) systems. The answer generated by the IRQA system is extracted from the relevant text but has a certain degree of randomness, while the KBQA system retrieves the answer from structured data, and its accuracy is relatively high. In the field of policy and regulations such as household registration, the QA system requires precise and rigorous answers. Therefore, we design a QA system based on the household registration knowledge graph, aiming to provide rigorous and accurate answers for relevant household registration inquiries. The QA system uses a semantic analysis-based approach to simplify one question into a simple problem consisting of a single event entity and a single intention relationship, and quickly generates accurate answers by searching in the household registration knowledge graph. Due to the scarcity and imbalance of QA corpus data in the field of household registration, we use GPT3.5 to augment the collected questions dataset and explore the impact of data augmentation on the QA system. The experiment results show that the accuracy rate of the QA system using the augmented dataset reaches 93%, which is 6% higher than before.	[Hu, Shulin; Zhang, Huajun; Zhang, Wanying] Wuhan Univ Technol, Sch Automat, Wuhan 430062, Peoples R China	Wuhan University of Technology	Zhang, HJ (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430062, Peoples R China.	bookwoods@whut.edu.cn; zhanghj_hust@163.com; zhangwanying@whut.edu.cn		Zhang, Wanying/0000-0002-3839-1022; Zhang, Huajun/0000-0002-5135-8198	Science and Technology Department of Hubei Province [2022BAA051]	Science and Technology Department of Hubei Province	This work search was funded by the Science and Technology Department of Hubei Province, grant number 2022BAA051.	Abu-Salih B, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103076; Abujabal A, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1191, DOI 10.1145/3038912.3052583; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aghaei S, 2022, IEEE ACCESS, V10, P69788, DOI 10.1109/ACCESS.2022.3187178; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; [Anonymous], 2012, P 21 INT C WORLD WID, DOI DOI 10.1145/2187836.2187923; Bao J, 2016, P COLING 2016 26 INT, P2503; Bast H., 2015, P 24 ACM INT C INFOR, P1431, DOI [10.1145/2806416.2806472, DOI 10.1145/2806416.2806472]; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bordes A, 2015, Arxiv, DOI arXiv:1506.02075; Chapman D., 2011, The Asia-Pacific Journal, V9; Che WX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P42; Chen J, 2022, IEEE T INTELL TRANSP, V23, P19954, DOI 10.1109/TITS.2022.3182410; Chen YR, 2023, IEEE T KNOWL DATA EN, V35, P8343, DOI 10.1109/TKDE.2022.3207477; Cheng L, 2022, IEEE SIGNAL PROC MAG, V39, P18, DOI 10.1109/MSP.2022.3198201; CoSENT, COSENT MOR EFF SENT; Cui WY, 2019, Arxiv, DOI [arXiv:1903.02419, 10.14778/3055540.3055549]; Cullen M.J., 1974, Journal of Ecclesiastical History, V24, P39; Deng Y, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3258413; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du Z.Y., 2017, COMPUT APPL SOFTW, V34, P153; GREEN B., 1986, Readings in natural language processing, P545; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jiang ZX, 2021, IEEE ACCESS, V9, P21094, DOI 10.1109/ACCESS.2021.3055371; Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052; Jurafsky D., 2014, Speech and Language Processing, V2nd; Lai SW, 2015, AAAI CONF ARTIF INTE, P2267; Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134; Li L, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101862; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; [刘峤 Liu Qiao], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P582; Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; ltp.readthedocs.io, APP LTP4 4 1 4 DOC; Lu S., 2023, Comput Syst Sci Eng, V47, P1149, DOI [10.32604/csse.2023.038598, DOI 10.32604/CSSE.2023.038598]; Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400; Lukovnikov D, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1211, DOI 10.1145/3038912.3052675; Nigh M., 2023, CHATGPT3 PROMPT ENG; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Vaswani A, 2017, ADV NEUR IN, V30; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wei Jason, 2019, EDA: Easy data augmentation techniques for boosting performance on text classification tasks; Woods W.A., 1977, Linguistic structures processing, V5, P521; Wu WJ, 2021, IEEE ACCESS, V9, P126357, DOI 10.1109/ACCESS.2020.3034920; wuhan.gov.cn, WUH CIT HOUS REG BUS; Xiong ZG, 2022, J SIGNAL PROCESS SYS, V94, P1253, DOI 10.1007/s11265-022-01790-3; Xu K, 2018, Arxiv, DOI arXiv:1808.07624; Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang YJ, 2024, J RES INTERACT MARK, V18, P166, DOI 10.1108/JRIM-09-2022-0286; Zheng WG, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1809, DOI 10.1145/2723372.2747648; Zhou WJ, 2021, IEEE T IMAGE PROCESS, V30, P7790, DOI 10.1109/TIP.2021.3109518; zwfw.hubei.gov.cn, HUB GOV SERV NETW	59	1	1	20	37	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	AUG	2023	13	15							8838	10.3390/app13158838	http://dx.doi.org/10.3390/app13158838			23	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	O7FA2		gold			2024-07-03	WOS:001045411900001
J	Watters, C; Lemanski, MK				Watters, Casey; Lemanski, Michal K.			Universal skepticism of ChatGPT: a review of early literature on chat generative pre-trained transformer	FRONTIERS IN BIG DATA			English	Review						ChatGPT; large language model (LLM); transformer; GPT; disruptive technology; artificial intelligence; AI	LARGE LANGUAGE MODELS; ARTIFICIAL-INTELLIGENCE; IMPACT; MEDICINE; OPPORTUNITIES; EDUCATION; FUTURE; AI; CHALLENGES; MANAGEMENT	ChatGPT, a new language model developed by OpenAI, has garnered significant attention in various fields since its release. This literature review provides an overview of early ChatGPT literature across multiple disciplines, exploring its applications, limitations, and ethical considerations. The review encompasses Scopus-indexed publications from November 2022 to April 2023 and includes 156 articles related to ChatGPT. The findings reveal a predominance of negative sentiment across disciplines, though subject-specific attitudes must be considered. The review highlights the implications of ChatGPT in many fields including healthcare, raising concerns about employment opportunities and ethical considerations. While ChatGPT holds promise for improved communication, further research is needed to address its capabilities and limitations. This literature review provides insights into early research on ChatGPT, informing future investigations and practical applications of chatbot technology, as well as development and usage of generative AI.	[Watters, Casey] Bond Univ, Fac Law, Gold Coast, Qld, Australia; [Lemanski, Michal K.] WU Vienna, Inst Human Resource Management, Vienna, Austria	Bond University	Watters, C (corresponding author), Bond Univ, Fac Law, Gold Coast, Qld, Australia.	cwatters@bond.edu.au	İnanç, Yelda/ISS-6977-2023					Abdel-Messih M. S., 2023, JMIR Med. Educ, DOI [10.22541/au.167715747.75006360/v1, DOI 10.22541/AU.167715747.75006360/V1]; Adesso G., 2023, Authorea, DOI [10.22541/au.167701309.98216987/v1, DOI 10.22541/AU.167701309.98216987/V1]; Adetayo Adebowale Jeremy, 2023, Library Hi Tech News, P18, DOI 10.1108/LHTN-01-2023-0007; Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Ai HS, 2024, APPL ECON, V56, P2337, DOI 10.1080/00036846.2023.2186367; Alberts IL, 2023, EUR J NUCL MED MOL I, V50, P1549, DOI 10.1007/s00259-023-06172-w; Ali MJ, 2023, SEMIN OPHTHALMOL, V38, P403, DOI 10.1080/08820538.2023.2193444; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; Ameen N, 2023, SERV IND J, V43, P125, DOI 10.1080/02642069.2023.2185934; An JF, 2023, NATURE, V615, P586, DOI 10.1038/d41586-023-00843-2; Anders BA, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100694; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Ang TL, 2023, SINGAP MED J, V64, P219, DOI 10.4103/singaporemedj.SMJ-2023-055; [Anonymous], 2023, BJU INT, V131, P381, DOI 10.1111/bju.15995; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Berger U, 2023, PSYCHOTHER PSYCH MED, V73, P159, DOI 10.1055/a-2017-8471; Bernstein J, 2023, CLIN ORTHOP RELAT R, V481, P651, DOI 10.1097/CORR.0000000000002619; Bhatia G, 2023, ASIAN J PSYCHIATR, V84, DOI 10.1016/j.ajp.2023.103564; Bhattacharya K, 2023, INDIAN J SURG, V85, P1346, DOI 10.1007/s12262-023-03727-x; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Borges RM, 2023, J BIOSCIENCES, V48, DOI 10.1007/s12038-023-00334-6; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Budler LC, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1487; Cahan P, 2023, STEM CELL REP, V18, P1, DOI 10.1016/j.stemcr.2022.12.009; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chatterjee J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2022.100676; Chen X., 2023, Internet Reference Services Quarterly, V27, P121, DOI [10.1080/10875301.2023.2181262, DOI 10.1080/10875301.2023.2181262]; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Costello E., 2023, POSTDIGITAL SCI EDUC, P1, DOI [10.1007/s42438-023-00398-5, DOI 10.1007/S42438-023-00398-5]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; Cox Louis Anthony Jr, 2023, Glob Epidemiol, V5, P100102, DOI 10.1016/j.gloepi.2023.100102; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Dasborough MT, 2023, J ORGAN BEHAV, V44, P177, DOI 10.1002/job.2695; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Donato H, 2023, ACTA MEDICA PORT, V36, P147, DOI 10.20344/amp.19694; Doshi RH, 2023, AM J BIOETHICS, V23, P6, DOI 10.1080/15265161.2023.2180110; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eisenberg T, 1998, J LEGAL STUD, V27, P373, DOI 10.1086/468024; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Elwood T. W., 2023, J Allied Health; Emenike ME, 2023, J CHEM EDUC, V100, P1413, DOI 10.1021/acs.jchemed.3c00063; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Fernandez Peter, 2023, Library Hi Tech News, P11, DOI 10.1108/LHTN-02-2023-0017; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Gancarczyk M, 2022, ENTREPR BUS ECON REV, V10, P143, DOI 10.15678/EBER.2022.100309; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Gasevic D., 2023, Comput. Educ. Artif. Intell, V4, DOI [DOI 10.1016/J.CAEAI.2023.100130, 10.1016/j.caeai.2023.100130]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Graf A, 2023, NEUROSCIENCE, V515, P71, DOI 10.1016/j.neuroscience.2023.02.008; Graham Flora, 2023, Nature, DOI 10.1038/d41586-023-00373-x; Graham Flora, 2023, Nature, DOI 10.1038/d41586-023-00360-2; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Gregorcic Bor, 2023, Physics Education, DOI 10.1088/1361-6552/acc299; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Halloran LJS, 2023, HYDROL PROCESS, V37, DOI 10.1002/hyp.14843; Hallsworth JE, 2023, MICROB BIOTECHNOL, V16, P1131, DOI 10.1111/1751-7915.14222; Haluza D, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11030120; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Harder N, 2023, CLIN SIMUL NURS, V78, P1, DOI 10.1016/j.ecns.2023.02.011; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Holzinger A, 2023, NEW BIOTECHNOL, V74, P16, DOI 10.1016/j.nbt.2023.02.001; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Hu GW, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2184262; Huang JT, 2023, J DIABETES SCI TECHN, V17, P853, DOI 10.1177/19322968231161095; Huh S, 2023, SCI EDIT, V10, P1, DOI 10.6087/kcse.290; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Humphry T, 2023, J CHEM EDUC, V100, P1434, DOI 10.1021/acs.jchemed.3c00006; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Johinke R, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.01; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kahambing JG, 2023, ASIAN J PSYCHIATR, V83, DOI 10.1016/j.ajp.2023.103548; Kapengut E, 2023, Commodities, V2, P96, DOI [10.3390/COMMODITIES2020006, DOI 10.3390/COMMODITIES2020006]; Karaali Gizem, 2023, Numeracy, V16, DOI [10.5038/1936-4660.16.1.1438, DOI 10.5038/1936-4660.16.1.1438]; Karimabadi H, 2023, FRONT ASTRON SPACE, V10, DOI 10.3389/fspas.2023.1120389; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kim SG, 2023, MAX PLAST RECONSTR S, V45, DOI 10.1186/s40902-023-00381-x; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Krettek C, 2023, UNFALLCHIRURGIE, V126, P252, DOI 10.1007/s00113-023-01296-y; Kurpicz-Briki M, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.625290; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lahat A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231155520; Lamba Hemank, 2021, ACM SIGKDD Explorations Newsletter, V23, P69, DOI 10.1145/3468507.3468518; Lawuobahsumo K. K., 2022, Commodities, V1, P34, DOI [10.3390/commodities1010004, DOI 10.3390/COMMODITIES1010004]; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Levin G, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2023.100936; Liang Y, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142417050; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lin CC, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15054012; Looi MK, 2023, BMJ-BRIT MED J, V380, DOI 10.1136/bmj.p205; Lund B. D., 2023, SSRN Electron J, V74, DOI [10.2139/ssrn.4333415, DOI 10.2139/SSRN.4333415]; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Maad M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P65, DOI DOI 10.52866/IJCSM.2023.01.01.0019; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Maeker E, 2023, NPG, V23, P137, DOI [10.1016/j.npg.2023.03.002, DOI 10.1016/J.NPG.2023.03.002]; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Masters K, 2023, MED TEACH, V45, P666, DOI 10.1080/0142159X.2023.2190476; Merhbene G, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.863100; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; Moisset X, 2023, REV NEUROL-FRANCE, V179, P517, DOI 10.1016/j.neurol.2023.02.066; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Naumova EN, 2023, J PUBLIC HEALTH POL, V44, P173, DOI 10.1057/s41271-023-00400-1; Nautiyal R, 2023, ANN TOURISM RES, V99, DOI 10.1016/j.annals.2023.103544; Nuryana Z, 2023, ASIAN J PSYCHIATR, V84, DOI 10.1016/j.ajp.2023.103571; O'Connor S, 2023, NURSE EDUC PRACT, V67, DOI 10.1016/j.nepr.2023.103572; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Odom-Forren J, 2023, J PERIANESTH NURS, V38, P176, DOI 10.1016/j.jopan.2023.02.006; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Panda Subhajit, 2023, Library Hi Tech News, P22, DOI 10.1108/LHTN-02-2023-0032; Park I, 2023, AM J OTOLARYNG, V44, DOI 10.1016/j.amjoto.2023.103873; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Prada Paco, 2023, Rev Med Suisse, V19, P532, DOI 10.53738/REVMED.2023.19.818.532; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Quintans LJ, 2023, REV SOC BRAS MED TRO, V56, DOI 10.1590/0037-8682-0060-2023; Rahimi F, 2023, ARCH MED RES, V54, P272, DOI 10.1016/j.arcmed.2023.03.004; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Rocca R, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1082787; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Roy K, 2023, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.1056728; Rozencwajg S, 2023, ANAESTH CRIT CARE PA, V42, DOI 10.1016/j.accpm.2023.101209; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sardana D, 2023, J AM DENT ASSOC, V154, P361, DOI 10.1016/j.adaj.2023.02.008; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; Schijven MP, 2023, SIMULAT GAMING, V54, P147, DOI 10.1177/10468781231152682; Schorrlepp Marcel, 2023, MMW Fortschr Med, V165, P12, DOI 10.1007/s15006-023-2473-3; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Seth I, 2023, ANN SURG ONCOL, DOI 10.1245/s10434-023-13642-w; Short C.E., 2023, J Bus Ventur Insights, V19, pe00388, DOI DOI 10.1016/J.JBVI.2023.E00388; Shu K., 2019, Emerging Research Challenges and Opportunities in Computational Social Network Analysis and Mining, P43; Siegerink B, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103599; Slapeta J, 2023, TRENDS PARASITOL, V39, P314, DOI 10.1016/j.pt.2023.02.006; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Strunga M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11050683; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Tang GY, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2180359; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Temsah MH, 2023, NEW MICROB NEW INFEC, V52, DOI 10.1016/j.nmni.2023.101103; Testoni A, 2022, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.736709; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Thomas SP, 2023, ISSUES MENT HEALTH N, V44, P141, DOI 10.1080/01612840.2023.2180982; Thornhill C, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00011; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tong YJ, 2023, SYN SYST BIOTECHNO, V8, P220, DOI 10.1016/j.synbio.2023.02.004; Tregoning John, 2023, Nature, DOI 10.1038/d41586-023-00528-w; Tsigaris P, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2179919; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang J, 2023, AM J PHYS, V91, P255, DOI 10.1119/5.0145897; Wang SH, 2023, NATURE, V615, P34, DOI 10.1038/d41586-023-00553-9; Watters C, 2023, LAWS-BASEL, V12, DOI 10.3390/laws12020033; Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677; Yadava OP, 2023, INDIAN J THORAC CARD, V39, P217, DOI 10.1007/s12055-023-01507-6; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2177160; Zhou J, 2024, FRONT INFORM TECH EL, V25, P6, DOI 10.1631/FITEE.2300089; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	192	9	9	59	151	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-909X		FRONT BIG DATA	Front. Big Data	AUG 23	2023	6								1224976	10.3389/fdata.2023.1224976	http://dx.doi.org/10.3389/fdata.2023.1224976			10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Computer Science; Science & Technology - Other Topics	Q7IJ8	37680954	gold, Green Published			2024-07-03	WOS:001059220600001
J	Khatri, S; Shah, AS; Yumeen, S; Saliba, E				Khatri, Surya; Shah, Asghar; Yumeen, Sara; Saliba, Elie			Analysis of Dermatology Journal Policy Toward Artificial Intelligence	JOURNAL OF CUTANEOUS MEDICINE AND SURGERY			English	Letter						artificial intelligence; large language models; chat bots; journal policy			[Khatri, Surya; Shah, Asghar] Brown Univ, Warren Alpert Med Sch, Providence, RI USA; [Yumeen, Sara; Saliba, Elie] Brown Univ, Dept Dermatol, Warren Alpert Med Sch, Providence, RI USA; [Saliba, Elie] Lebanese Amer Univ, Gilbert & Rose Marie Chagoury Sch Med, Dept Dermatol, Beirut, Lebanon; [Saliba, Elie] Brown Univ, Dept Dermatol, Warren Alpert Med Sch, 593 Eddy St,APC 10, Providence, RI 02905 USA	Brown University; Brown University; Lebanese American University; American University of Beirut; Brown University	Saliba, E (corresponding author), Brown Univ, Dept Dermatol, Warren Alpert Med Sch, 593 Eddy St,APC 10, Providence, RI 02905 USA.	elie_saliba@brown.edu		Saliba, Elie/0000-0001-5994-3212; Khatri, Surya/0000-0002-3852-4702				Aczel B., 2023, PREPRINT; De A, 2020, INDIAN J DERMATOL, V65, P352, DOI 10.4103/ijd.IJD_418_20; Gomolin A, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00100; Park JY, 2023, J KOR ASSOC ORAL MAX, V49, P105, DOI 10.5125/jkaoms.2023.49.3.105; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2	5	0	0	6	6	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1203-4754	1615-7109		J CUTAN MED SURG	J. Cutan. Med. Surg.	MAY	2024	28	3					304	305		10.1177/12034754241238709	http://dx.doi.org/10.1177/12034754241238709		MAR 2024	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	SS2G0	38468122				2024-07-03	WOS:001183394400001
J	Thiebaut, R; Hejblum, B; Mougin, F; Tzourio, C; Richert, L				Thiebaut, Rodolphe; Hejblum, Boris; Mougin, Fleur; Tzourio, Christophe; Richert, Laura			ChatGPT and beyond with artificial intelligence (AI) in health: Lessons to be learned	JOINT BONE SPINE			English	Editorial Material						Artificial intelligence; Large language models; Data science; Evaluation; Teaching			[Thiebaut, Rodolphe; Hejblum, Boris; Mougin, Fleur; Tzourio, Christophe; Richert, Laura] Univ Bordeaux, Bordeaux Populat Hlth, Inserm, U1219, F-33000 Bordeaux, France; [Thiebaut, Rodolphe; Hejblum, Boris; Richert, Laura] INRIA, SISTM, F-33000 Bordeaux, France; [Thiebaut, Rodolphe; Tzourio, Christophe; Richert, Laura] CHU Bordeaux, Med Informat Dept, F-33000 Bordeaux, France; [Thiebaut, Rodolphe] Univ Bordeaux, Bordeaux Populat Hlth, Inserm, 146, Rue Leo Saignat, F-33076 Bordeaux, France	Universite de Bordeaux; Institut National de la Sante et de la Recherche Medicale (Inserm); Inria; CHU Bordeaux; Universite de Bordeaux; Institut National de la Sante et de la Recherche Medicale (Inserm); Universite de Bordeaux	Thiebaut, R (corresponding author), Univ Bordeaux, Bordeaux Populat Hlth, Inserm, 146, Rue Leo Saignat, F-33076 Bordeaux, France.	rodolphe.thiebaut@u-bordeaux.fr	Tzourio, Christophe/B-4015-2009; Mougin, Fleur/T-2899-2019	Tzourio, Christophe/0000-0002-6517-2984; Mougin, Fleur/0000-0002-7436-3010				Abràmoff MD, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0040-6; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Char DS, 2018, NEW ENGL J MED, V378, P981, DOI 10.1056/NEJMp1714229; Do HM, 2020, ACAD RADIOL, V27, P96, DOI 10.1016/j.acra.2019.09.014; Karamchandani RR, 2023, BRAIN BEHAV, V13, DOI 10.1002/brb3.2808; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; McCoy LG, 2022, J CLIN EPIDEMIOL, V142, P252, DOI 10.1016/j.jclinepi.2021.11.001; McCoy LG, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0294-7; Medenilla A., 2023, PLoS Digital Health, V2; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; OpenAI, INTR CHATGPT 2023; Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ten A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26196-w; Verhoeven F, 2023, ANN RHEUM DIS, V82, P1015, DOI 10.1136/ard-2023-223936; WHO, Ethics and governance of artificial intelligence for health: Guidance on large multi-modal models; Wu E, 2021, NAT MED, V27, P582, DOI 10.1038/s41591-021-01312-x; Young AT, 2021, LANCET DIGIT HEALTH, V3, pE599, DOI 10.1016/S2589-7500(21)00132-1	19	0	0	7	13	ELSEVIER FRANCE-EDITIONS SCIENTIFIQUES MEDICALES ELSEVIER	ISSY-LES-MOULINEAUX	65 RUE CAMILLE DESMOULINS, CS50083, 92442 ISSY-LES-MOULINEAUX, FRANCE	1297-319X	1778-7254		JOINT BONE SPINE	Joint Bone Spine	SEP	2023	90	5							105607	10.1016/j.jbspin.2023.105607	http://dx.doi.org/10.1016/j.jbspin.2023.105607		JUL 2023	3	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	P0EG8	37414138	Bronze, Green Submitted			2024-07-03	WOS:001047451500001
J	Woo, KMC; Simon, GW; Akindutire, O; Aphinyanaphongs, Y; Austrian, JS; Kim, JG; Genes, N; Goldenring, JA; Major, VJ; Pariente, CS; Pineda, EG; Kang, SK				Woo, Kar-mun C.; Simon, Gregory W.; Akindutire, Olumide; Aphinyanaphongs, Yindalon; Austrian, Jonathan S.; Kim, Jung G.; Genes, Nicholas; Goldenring, Jacob A.; Major, Vincent J.; Pariente, Chloe S.; Pineda, Edwin G.; Kang, Stella K.			Evaluation of GPT-4 ability to identify and generate patient instructions for actionable incidental radiology findings	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						ChatGPT; GPT; radiology; incidentaloma; follow-up; large language model	EMERGENCY-DEPARTMENT PATIENTS; COMPUTED-TOMOGRAPHY; FOLLOW-UP; RECOMMENDATIONS	Objectives To evaluate the proficiency of a HIPAA-compliant version of GPT-4 in identifying actionable, incidental findings from unstructured radiology reports of Emergency Department patients. To assess appropriateness of artificial intelligence (AI)-generated, patient-facing summaries of these findings.Materials and Methods Radiology reports extracted from the electronic health record of a large academic medical center were manually reviewed to identify non-emergent, incidental findings with high likelihood of requiring follow-up, further sub-stratified as "definitely actionable" (DA) or "possibly actionable-clinical correlation" (PA-CC). Instruction prompts to GPT-4 were developed and iteratively optimized using a validation set of 50 reports. The optimized prompt was then applied to a test set of 430 unseen reports. GPT-4 performance was primarily graded on accuracy identifying either DA or PA-CC findings, then secondarily for DA findings alone. Outputs were reviewed for hallucinations. AI-generated patient-facing summaries were assessed for appropriateness via Likert scale.Results For the primary outcome (DA or PA-CC), GPT-4 achieved 99.3% recall, 73.6% precision, and 84.5% F-1. For the secondary outcome (DA only), GPT-4 demonstrated 95.2% recall, 77.3% precision, and 85.3% F-1. No findings were "hallucinated" outright. However, 2.8% of cases included generated text about recommendations that were inferred without specific reference. The majority of True Positive AI-generated summaries required no or minor revision.Conclusion GPT-4 demonstrates proficiency in detecting actionable, incidental findings after refined instruction prompting. AI-generated patient instructions were most often appropriate, but rarely included inferred recommendations. While this technology shows promise to augment diagnostics, active clinician oversight via "human-in-the-loop" workflows remains critical for clinical implementation.	[Woo, Kar-mun C.; Simon, Gregory W.; Akindutire, Olumide; Kim, Jung G.; Genes, Nicholas; Goldenring, Jacob A.] NYU Grossman Sch Med, Ronald O Perelman Dept Emergency Med, New York, NY 10016 USA; [Aphinyanaphongs, Yindalon; Major, Vincent J.; Kang, Stella K.] NYU Grossman Sch Med, Dept Populat Hlth, New York, NY 10016 USA; [Aphinyanaphongs, Yindalon; Austrian, Jonathan S.; Genes, Nicholas; Major, Vincent J.; Pariente, Chloe S.] NYU Langone Hlth, Med Ctr IT, Dept Hlth Informat, New York, NY 10016 USA; [Austrian, Jonathan S.] NYU Grossman Sch Med, Dept Med, New York, NY 10016 USA; [Pineda, Edwin G.] NYU Langone Hlth, MCIT Clin Syst ASAP applicat, New York, NY 10016 USA; [Kang, Stella K.] NYU Grossman Sch Med, Dept Radiol, New York, NY 10016 USA; NYU Langone Hlth, Inst Innovat Med Educ, Dept Urol, New York, NY 10016 USA	NYU Langone Medical Center; NYU Langone Medical Center; NYU Langone Medical Center	Woo, KMC (corresponding author), NYU Grossman Sch Med, Ronald O Perelman Dept Emergency Med, New York, NY 10016 USA.	kar-mun.woo@nyulangone.org			NYU Langone Health; NYU Langone Health Medical Center IT	NYU Langone Health; NYU Langone Health Medical Center IT	We thank Dr Catherine Jamin, Dr Soterios Gyftopoulos, Dr Sarah Spiegel, Dr Leland Chan, and Duo (Walter) Wang for their support. We also thank the NYU Langone Health Medical Center IT for supporting exploratory and API access to the secure, HIPAA-compliant instance of GPT-4 that enabled this work.	Barrett TW, 2022, ANN EMERG MED, V80, P235, DOI 10.1016/j.annemergmed.2022.04.026; Berge P, 2020, EUR J RADIOL, V129, DOI 10.1016/j.ejrad.2020.109072; Berland LL, 2013, J AM COLL RADIOL, V10, P672, DOI 10.1016/j.jacr.2013.05.012; Bhayana R., 2024, AJR Am J Roentgenol, V222, pe233065; Dutta S, 2013, ANN EMERG MED, V62, P162, DOI 10.1016/j.annemergmed.2013.02.001; Evans CS, 2022, ANN EMERG MED, V80, P243, DOI 10.1016/j.annemergmed.2022.03.027; Evans CS, 2023, ANN EMERG MED, V81, P262, DOI 10.1016/j.annemergmed.2022.08.450; Fu SY, 2019, JMIR MED INF, V7, P82, DOI 10.2196/12109; Hansra SS, 2021, J AM COLL RADIOL, V18, P233, DOI 10.1016/j.jacr.2020.02.021; Kang SK, 2019, J AM COLL RADIOL, V16, P1587, DOI 10.1016/j.jacr.2019.04.026; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Kwan JL, 2019, J HOSP MED, V14, P349, DOI 10.12788/jhm.3128; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Liao GJ, 2019, J AM COLL RADIOL, V16, P781, DOI 10.1016/j.jacr.2018.11.010; Lumbreras B, 2010, BRIT J RADIOL, V83, P276, DOI 10.1259/bjr/98067945; Moore CL, 2023, J AM COLL RADIOL, V20, P422, DOI 10.1016/j.jacr.2023.01.001; Moore CL, 2021, J AM COLL RADIOL, V18, P853, DOI 10.1016/j.jacr.2020.12.027; Munk MD, 2010, J EMERG MED, V38, P346, DOI 10.1016/j.jemermed.2008.01.021; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; O'Sullivan JW, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k2387; Pham AD, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-266; Smith-Bindman R, 2019, JAMA-J AM MED ASSOC, V322, P843, DOI 10.1001/jama.2019.11456; Thompson RJ, 2011, EMERG MED INT, V2011, DOI 10.1155/2011/624847; Vernooij MW, 2007, NEW ENGL J MED, V357, P1821, DOI 10.1056/NEJMoa070972	24	0	0	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 MAY 23	2024										10.1093/jamia/ocae117	http://dx.doi.org/10.1093/jamia/ocae117		MAY 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RQ5H5	38778578	hybrid			2024-07-03	WOS:001229133600001
J	Ranjan, J; Ahmad, A; Subudhi, M; Kumar, A				Ranjan, Jai; Ahmad, Absar; Subudhi, Monalisa; Kumar, Ajay			Assessment of Artificial Intelligence Platforms With Regard to Medical Microbiology Knowledge: An Analysis of ChatGPT and Gemini	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						learning; large language model; artificial intelligence; medical education; microbiology		The performance of two artificial intelligence (AI) platforms, ChatGPT 3.5 (OpenAI, California, United States) and Gemini (Google AI, California, United States) was assessed by answering 200 questions of microbiology drawn from validated sources. The questions were selected from topics such as General Microbiology, Immunology, and Microbiology Applied to Infectious Diseases. The study was conducted from December 2023 to March 2024, and the responses of the different AI platforms were compared with an answer key. Statistical analysis was performed to assess accuracy. ChatGPT 3.5 and Gemini had comparable accuracy with correct response scores of 71% and 70.5%, respectively. Their performance varied across different sections. Gemini performed better in General Microbiology and Immunology, and ChatGPT 3.5 had a better score in the Applied Microbiology section. The study's findings highlight that AI platforms such as ChatGPT and Gemini can be utilized in microbiology and medical education. The evolution and continuous updating of AI platforms are required to improve their performance.	[Ranjan, Jai] All India Inst Med Sci, Microbiol, Bathinda, India; [Ahmad, Absar] Birsa Agr Univ, Fac Vet Sci & Anim Husb, Anim Genet & Breeding, Ranchi, India; [Subudhi, Monalisa] Inst Med Sci & SUM II Hosp, Microbiol, Bhubaneswar, India; [Kumar, Ajay] Manipal Acad Higher Educ, Manipal Tata Med Coll, Pediat, Manipal, India	Birsa Agricultural University; Manipal Academy of Higher Education (MAHE)	Kumar, A (corresponding author), Manipal Acad Higher Educ, Manipal Tata Med Coll, Pediat, Manipal, India.	ajaymicro786@gmail.com						Ananthanarayan R, 2022, Ananthanarayan and Paniker's Textbook of Microbiology, V12th; Cross J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41399; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Egli A, 2023, CLIN INFECT DIS, V77, P1322, DOI 10.1093/cid/ciad407; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goodswen SJ, 2021, FEMS MICROBIOL REV, V45, DOI 10.1093/femsre/fuab015; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mir Mohammad Muzaffar, 2023, J Adv Med Educ Prof, V11, P133, DOI 10.30476/JAMP.2023.98655.1803; Vignesh R, 2023, Med J Malaysia, V78, P547	10	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 20	2024	16	5							e60675	10.7759/cureus.60675	http://dx.doi.org/10.7759/cureus.60675			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	SU6E5	38770053	gold			2024-07-03	WOS:001236991800022
J	Gupta, A; Rangarajan, K				Gupta, Amit; Rangarajan, Krithika			Uncover This Tech Term: Transformers	KOREAN JOURNAL OF RADIOLOGY			English	Editorial Material						Artificial intelligence; Transformer; ChatGPT; Deep learning; Large language models			[Gupta, Amit; Rangarajan, Krithika] All India Inst Med Sci, Dept Radiol, Dr BRA IRCH, Room 160D, New Delhi 110029, India	All India Institute of Medical Sciences (AIIMS) New Delhi; DR. B.R.A. Institute Rotary Cancer Hospital	Rangarajan, K (corresponding author), All India Inst Med Sci, Dept Radiol, Dr BRA IRCH, Room 160D, New Delhi 110029, India.	krithikarangarajan86@gmail.com		Gupta, Amit/0000-0003-0192-3512				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Jung KH, 2023, KOREAN J RADIOL, V24, P1038, DOI 10.3348/kjr.2023.0790; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Park SH, 2023, KOREAN J RADIOL, V24, P715, DOI 10.3348/kjr.2023.0643; Park SH, 2023, KOREAN J RADIOL, V24, P171, DOI 10.3348/kjr.2023.0112; Shamshad F, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102802; Srivastav S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41435; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]	10	0	0	1	1	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	JAN	2024	25	1					113	115		10.3348/kjr.2023.0948	http://dx.doi.org/10.3348/kjr.2023.0948			3	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	QS3Z5	38184774	Green Published			2024-07-03	WOS:001222833600015
J	Mat, Q; Briganti, G; Maniaci, A; Lelubre, C				Mat, Quentin; Briganti, Giovanni; Maniaci, Antonino; Lelubre, Christophe			Will ChatGPT soon replace otolaryngologists?	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Letter						Artificial; GPT; ChatGPT; Large language model; Otolaryngology; Medicine			[Mat, Quentin] CHU Charleroi, Dept Otorhinolaryngol, Chaussee Bruxelles 140, B-6042 Charleroi, Belgium; [Mat, Quentin; Briganti, Giovanni; Lelubre, Christophe] Univ Mons, Fac Med & Pharm, Dept Neurosci, Mons, Belgium; [Briganti, Giovanni] Univ Liege, Quartier Hop, Fac Med, Dept Clin Sci, Ave Hippocrate 13, B-4000 Liege, Belgium; [Briganti, Giovanni] Univ Libre Bruxelles, IRIBHM, Fac Med, Route Lennik 808, B-1070 Brussels, Belgium; [Maniaci, Antonino] Univ Enna Kore, Fac Med & Surg, Enna, Italy; [Lelubre, Christophe] CHU Charleroi, Dept Internal Med, Charleroi, Belgium	University of Mons; University of Liege; Universite Libre de Bruxelles; Universita Kore di ENNA	Mat, Q (corresponding author), CHU Charleroi, Dept Otorhinolaryngol, Chaussee Bruxelles 140, B-6042 Charleroi, Belgium.; Mat, Q (corresponding author), Univ Mons, Fac Med & Pharm, Dept Neurosci, Mons, Belgium.	quentin.mat@humani.be	Maniaci, Antonino/AAB-6004-2021; Briganti, Giovanni/C-2094-2018	Maniaci, Antonino/0000-0002-1251-0185; Briganti, Giovanni/0000-0002-4038-3363				Briganti G, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08337-7; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Ethics and governance of artificial intelligence for health, 2024, GUIDANCE LARGE MULTI; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P1565, DOI 10.1007/s00405-023-08326-w; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	6	0	0	5	5	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	JUN	2024	281	6					3303	3304		10.1007/s00405-024-08543-x	http://dx.doi.org/10.1007/s00405-024-08543-x		MAR 2024	2	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	TG9T2	38438614				2024-07-03	WOS:001175843800002
J	Rojas-Carabali, W; Sen, A; Agarwal, A; Tan, GV; Cheung, CY; Rousselot, A; Agrawal, R; Liu, RE; Cifuentes-González, C; Elze, T; Kempen, JH; Sobrin, L; Nguyen, QD; de-la-Torre, A; Lee, B; Gupta, V; Agrawal, R				Rojas-Carabali, William; Sen, Alok; Agarwal, Aniruddha; Tan, Gavin; Cheung, Carol Y.; Rousselot, Andres; Agrawal, Rajdeep; Liu, Renee; Cifuentes-Gonzalez, Carlos; Elze, Tobias; Kempen, John H.; Sobrin, Lucia; Nguyen, Quan Dong; de-la-Torre, Alejandra; Lee, Bernett; Gupta, Vishali; Agrawal, Rupesh			Chatbots Vs. Human Experts: Evaluating Diagnostic Performance of Chatbots in Uveitis and the Perspectives on AI Adoption in Ophthalmology	OCULAR IMMUNOLOGY AND INFLAMMATION			English	Article; Early Access						Artificial intelligence; ChatGPT; diagnosis; large language model; ophthalmology		PurposeTo assess the diagnostic performance of two chatbots, ChatGPT and Glass, in uveitis diagnosis compared to renowned uveitis specialists, and evaluate clinicians' perception about utilizing artificial intelligence (AI) in ophthalmology practice.MethodsSix cases were presented to uveitis experts, ChatGPT (version 3.5 and 4.0) and Glass 1.0, and diagnostic accuracy was analyzed. Additionally, a survey about the emotions, confidence in utilizing AI-based tools, and the likelihood of incorporating such tools in clinical practice was done.ResultsUveitis experts accurately diagnosed all cases (100%), while ChatGPT achieved a diagnostic success rate of 66% and Glass 1.0 achieved 33%. Most attendees felt excited or optimistic about utilizing AI in ophthalmology practice. Older age and high level of education were positively correlated with increased inclination to adopt AI-based tools.ConclusionsChatGPT demonstrated promising diagnostic capabilities in uveitis cases and ophthalmologist showed enthusiasm for the integration of AI into clinical practice.	[Rojas-Carabali, William; Agrawal, Rajdeep; Lee, Bernett; Agrawal, Rupesh] Nanyang Technol Univ, Lee Kong Chiang Sch Med, Singapore City, Singapore; [Sen, Alok] Sadguru Netra Chikitsalaya, Retina & Uvea Serv, Chitrakoot, India; [Agarwal, Aniruddha] Cleveland Clin, Eye Inst, Abu Dhabi, U Arab Emirates; [Agarwal, Aniruddha] Case Western Reserve Univ, Cleveland Clin Lerner Coll Med, Cleveland, OH USA; [Agarwal, Aniruddha] Maastricht Univ, Dept Ophthalmol, Med Ctr, Maastricht, Netherlands; [Tan, Gavin] Singapore Natl Eye Ctr, Singapore Eye Res Inst, Singapore City, Singapore; [Tan, Gavin; Agrawal, Rupesh] Duke NUS Med Sch, Singapore City, Singapore; [Cheung, Carol Y.] Chinese Univ Hong Kong, Fac Med, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China; [Rousselot, Andres] Univ Salvador, Dept Ophthalmol, Buenos Aires, Argentina; [Liu, Renee; Elze, Tobias; Kempen, John H.; Sobrin, Lucia] Harvard Med Sch, Massachusetts Eye & Ear Infirm, Dept Ophthalmol, Boston, MA USA; [Liu, Renee; Elze, Tobias; Kempen, John H.; Sobrin, Lucia] Harvard Med Sch, Massachusetts Eye & Ear Infirm, Schepens Eye Res Inst, Boston, MA USA; [Cifuentes-Gonzalez, Carlos; de-la-Torre, Alejandra] Univ Rosario, Escuela Med & Ciencias Salud, Inst Translat Med IMT, Neurovitae Ctr Neurosci,Neurosci Res Grp NEUROS, Bogota, Colombia; [Kempen, John H.] Sight Souls, Bellevue, WA USA; [Kempen, John H.] Addis Ababa Univ, Dept Ophthalmol, Sch Med, Addis Ababa, Ethiopia; [Kempen, John H.] MCM Comprehens Specialized Hosp, Myungsung Med Coll, Dept Ophthalmol, Addis Ababa, Ethiopia; [Nguyen, Quan Dong] Stanford Univ, Byers Eye Inst, Palo Alto, CA USA; [Gupta, Vishali] Adv Eye Ctr, Post Grad Inst Med Educ & Res PGIMER, Chandigarh, India; [Agrawal, Rupesh] NHS Fdn Trust, Moorfields Eye Hosp, London, England; [Agrawal, Rupesh] Tan Tock Seng Hosp, Natl Healthcare Grp, Singapore City, Singapore; [Agrawal, Rupesh] Tan Tock Seng Hosp, Natl Healthcare Grp Eye Inst, Singapore City 308433, Singapore	Nanyang Technological University; Cleveland Clinic Foundation; University System of Ohio; Case Western Reserve University; Cleveland Clinic Foundation; Maastricht University; Singapore National Eye Center; National University of Singapore; Chinese University of Hong Kong; Harvard University; Massachusetts Eye & Ear Infirmary; Harvard Medical School; Harvard University; Harvard Medical School; Massachusetts Eye & Ear Infirmary; Schepens Eye Research Institute; Universidad del Rosario; Addis Ababa University; Stanford University; Post Graduate Institute of Medical Education & Research (PGIMER), Chandigarh; Oxford University Hospitals NHS Foundation Trust; University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; Tan Tock Seng Hospital; Tan Tock Seng Hospital	Agrawal, R (corresponding author), Nanyang Technol Univ, Lee Kong Chiang Sch Med, Singapore City, Singapore.; Agrawal, R (corresponding author), Duke NUS Med Sch, Singapore City, Singapore.; Agrawal, R (corresponding author), Tan Tock Seng Hosp, Natl Healthcare Grp Eye Inst, Singapore City 308433, Singapore.	Rupesh_agrawal@ttsh.com.sg	Nguyen, Quan/JMP-5630-2023; Cifuentes González, Carlos Humberto/ACQ-8931-2022; Nguyen, Truong/JXN-9786-2024	Cifuentes González, Carlos Humberto/0000-0002-2703-0977; Rojas-Carabali, William/0000-0002-9976-8989	We want to thank the Asia-Pacific Ocular Imaging Society (APOIS) and Zeiss for their support in the webinar organization.; Asia-Pacific Ocular Imaging Society; Zeiss	We want to thank the Asia-Pacific Ocular Imaging Society (APOIS) and Zeiss for their support in the webinar organization.; Asia-Pacific Ocular Imaging Society; Zeiss	We want to thank the Asia-Pacific Ocular Imaging Society (APOIS) and Zeiss for their support in the webinar organization.	[Anonymous], 2023, EC TIMES; Bhinder B, 2021, CANCER DISCOV, V11, P900, DOI 10.1158/2159-8290.CD-21-0090; Deschenes J, 2008, OCUL IMMUNOL INFLAMM, V16, P1, DOI 10.1080/09273940801899822; Glass Health AI, 2023, Glass; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Jabs DA, 2022, CLIN EXP OPHTHALMOL, V50, P991, DOI 10.1111/ceo.14175; Oh BL, 2021, OCUL IMMUNOL INFLAMM, V29, P1040, DOI 10.1080/09273948.2020.1746352; OpenAI, 2023, Introducing ChatGPT; Packalen M, 2019, J HUM CAPITAL, V13, P341, DOI 10.1086/703160; Paris M., 2019, Forbes; Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]	13	1	1	2	2	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0927-3948	1744-5078		OCUL IMMUNOL INFLAMM	Ocul. Immunol. Inflamm.	2023 OCT 11	2023										10.1080/09273948.2023.2266730	http://dx.doi.org/10.1080/09273948.2023.2266730		OCT 2023	8	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	T9QF6	37831553				2024-07-03	WOS:001081250300001
J	Lin, GG; Hsieh, CY; Lai, YC; Wang, CC; Lin, YP; Lu, KY; Chai, WY; Chen, AP; Yen, TC; Ng, SH; Lai, CH				Lin, Gigin; Hsieh, Ching-Yi; Lai, Ying-Chieh; Wang, Chun-Chieh; Lin, Yenpo; Lu, Kuan-Ying; Chai, Wen-Yen; Chen, Albert P.; Yen, Tzu-Chen; Ng, Shu-Hang; Lai, Chyong-Huey			Hyperpolarized [1-<SUP>13</SUP>C]-pyruvate MRS evaluates immune potential and predicts response to radiotherapy in cervical cancer	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Carbon-13; Magnetic resonance spectroscopy; Radiotherapy; Spleen; Uterine cervical neoplasms	PET/CT	Background Monitoring pyruvate metabolism in the spleen is important for assessing immune activity and achieving successful radiotherapy for cervical cancer due to the significance of the abscopal effect. We aimed to explore the feasibility of utilizing hyperpolarized (HP) [1-C-13]-pyruvate magnetic resonance imaging (MRI) and magnetic resonance spectroscopy (MRS) to evaluate pyruvate metabolism in the human spleen, with the aim of identifying potential candidates for radiotherapy in cervical cancer. Methods This prospective study recruited six female patients with cervical cancer (median age 55 years; range 39-60) evaluated using HP [1-C-13]-pyruvate MRI/MRS at baseline and 2 weeks after radiotherapy. Proton (H-1) diffusion-weighted MRI was performed in parallel to estimate splenic cellularity. The primary outcome was defined as tumor response to radiotherapy. The Student t-test was used for comparing C-13 data between the groups. Results The splenic HP [1-C-13]-lactate-to-total carbon (tC) ratio was 5.6-fold lower in the responders than in the non-responders at baseline (p = 0.009). The splenic [1-C-13]-lactate-to-tC ratio revealed a 1.7-fold increase (p = 0.415) and the splenic [1-C-13]-alanine-to-tC ratio revealed a 1.8-fold increase after radiotherapy (p = 0.482). The blood leukocyte differential count revealed an increased proportion of neutrophils two weeks following treatment, indicating enhanced immune activity (p = 0.013). The splenic apparent diffusion coefficient values between the groups were not significantly different. Conclusions This exploratory study revealed the feasibility of HP [1-C-13]-pyruvate MRS of the spleen for evaluating baseline immune potential, which was associated with clinical outcomes of cervical cancer after radiotherapy.	[Lin, Gigin; Hsieh, Ching-Yi; Lai, Ying-Chieh; Lin, Yenpo; Lu, Kuan-Ying; Chai, Wen-Yen; Ng, Shu-Hang] Chang Gung Mem Hosp Linkou, Dept Med Imaging & Intervent, 5 Fuhsing St, Taoyuan 33382, Taiwan; [Lin, Gigin; Lai, Ying-Chieh; Wang, Chun-Chieh; Lin, Yenpo; Chai, Wen-Yen; Ng, Shu-Hang] Chang Gung Univ, Dept Med Imaging & Radiol Sci, Taoyuan, Taiwan; [Lin, Gigin; Hsieh, Ching-Yi; Lai, Ying-Chieh; Lin, Yenpo; Lu, Kuan-Ying] Chang Gung Mem Hosp Linkou, Clin Metabol Core Lab, Taoyuan, Taiwan; [Lin, Gigin; Hsieh, Ching-Yi; Wang, Chun-Chieh] Chang Gung Univ, Res Ctr Radiat Med, Taoyuan, Taiwan; [Wang, Chun-Chieh] Chang Gung Mem Hosp LinKou, Dept Radiat Oncol, Taoyuan, Taiwan; [Chen, Albert P.] GE Healthcare, Toronto, ON, Canada; [Yen, Tzu-Chen] Chang Gung Univ, Chang Gung Mem Hosp, Coll Med, Dept Nucl Med, Taoyuan, Taiwan; [Yen, Tzu-Chen] Chang Gung Univ, Chang Gung Mem Hosp, Coll Med, Mol Imaging Ctr, Taoyuan, Taiwan; [Lai, Chyong-Huey] Chang Gung Mem Hosp, Gynecol Oncol Res Ctr, Div Gynecol Oncol, Taoyuan, Taiwan; [Lai, Chyong-Huey] Chang Gung Univ, Coll Med, Taoyuan, Taiwan	Chang Gung Memorial Hospital; Chang Gung University; Chang Gung Memorial Hospital; Chang Gung University; Chang Gung Memorial Hospital; General Electric; Chang Gung Memorial Hospital; Chang Gung University; Chang Gung University; Chang Gung Memorial Hospital; Chang Gung Memorial Hospital; Chang Gung University	Lin, GG (corresponding author), Chang Gung Mem Hosp Linkou, Dept Med Imaging & Intervent, 5 Fuhsing St, Taoyuan 33382, Taiwan.; Lin, GG (corresponding author), Chang Gung Univ, Dept Med Imaging & Radiol Sci, Taoyuan, Taiwan.; Lin, GG (corresponding author), Chang Gung Mem Hosp Linkou, Clin Metabol Core Lab, Taoyuan, Taiwan.; Lin, GG (corresponding author), Chang Gung Univ, Res Ctr Radiat Med, Taoyuan, Taiwan.	giginlin@cgmh.org.tw	Lin, Gigin/A-2676-2017	Lin, Gigin/0000-0001-7246-1058; Lin, Yenpo/0000-0001-9617-503X	National Science and Technology Council; NIBIB [P41EB013598]; NIH [109-TDU-B-212-114005, CLRPG3N0011]; Cancer Center and Clinical Trial Center, Chang Gung Memorial Hospital - Ministry of Health and Welfare of Taiwan MOHW	National Science and Technology Council; NIBIB(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Cancer Center and Clinical Trial Center, Chang Gung Memorial Hospital - Ministry of Health and Welfare of Taiwan MOHW	The authors acknowledge the helps from Chun-Yu Su, Yu-Ying Yu, Rainie Liu, Hsin-Ju Chiang, Dr. Lan-Yan Yang, Dr. Yu-Chun Lin, Dr. Kung-Chu Ho, Dr. Rolf F Schulte, Dr. Chien-Yuan Eddy Lin, and HMTRC, UCSF, supported by NIBIB and NIH Grant P41EB013598. We thank the Cancer Center and Clinical Trial Center, Chang Gung Memorial Hospital, funded by the Ministry of Health and Welfare of Taiwan MOHW 109-TDU-B-212-114005. The authors wish to thank Ms. Ingrid Kuo and the Center for Big Data Analytics and Statistics (Grant CLRPG3N0011) at Chang Gung Memorial Hospital for creating the illustrations used herein. GE Healthcare kindly provides investigational sequences in multinuclear spectroscopy (MNS) research package. The authors declare that Large Language Models have not been used for this manuscript.	Abu-Rustum NR, 2020, J NATL COMPR CANC NE, V18, P661, DOI 10.6004/jnccn.2020.0027; Ahn SS, 2017, J NUCL MED, V58, P507, DOI 10.2967/jnumed.116.180729; Can E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57026-1; Cunningham CH, 2008, J MAGN RESON, V193, P139, DOI 10.1016/j.jmr.2008.03.012; Cunningham CH, 2016, CIRC RES, V119, P1177, DOI 10.1161/CIRCRESAHA.116.309769; De Jaeghere EA, 2020, GYNECOL ONCOL, V159, P335, DOI 10.1016/j.ygyno.2020.08.001; Gallagher FA, 2020, P NATL ACAD SCI USA, V117, P2092, DOI 10.1073/pnas.1913841117; Lai YC, 2021, METABOLITES, V11, DOI 10.3390/metabo11080518; Lin GG, 2019, EUR RADIOL, V29, P556, DOI 10.1007/s00330-018-5651-4; McInnes MDF, 2011, RADIOLOGY, V260, P699, DOI 10.1148/radiol.11110333; Nelson SJ, 2013, SCI TRANSL MED, V5, DOI 10.1126/scitranslmed.3006070; Ngwa W, 2018, NAT REV CANCER, V18, P313, DOI 10.1038/nrc.2018.6; Park JM, 2021, RADIOLOGY, V300, P626, DOI 10.1148/radiol.2021204500; Patel NH, 2021, ATHEROSCLEROSIS, V339, P20, DOI 10.1016/j.atherosclerosis.2021.11.008; Pearce Erika L, 2013, Science, V342, P1242454, DOI 10.1126/science.1242454; Rodríguez-Ruiz ME, 2018, TRENDS IMMUNOL, V39, P644, DOI 10.1016/j.it.2018.06.001; Seban RD, 2021, LUNG CANCER, V159, P45, DOI 10.1016/j.lungcan.2021.06.024; Seban RD, 2021, EUR J NUCL MED MOL I, V48, P3560, DOI 10.1007/s00259-021-05322-2; Tang SY, 2021, CANCER-AM CANCER SOC, V127, P2693, DOI 10.1002/cncr.33554; Wang ZJ, 2019, RADIOLOGY, V291, P273, DOI 10.1148/radiol.2019182391; Wong AN, 2020, CANCER IMAGING, V20, DOI 10.1186/s40644-020-00313-2	21	1	1	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	APR 10	2024	8	1							46	10.1186/s41747-024-00445-1	http://dx.doi.org/10.1186/s41747-024-00445-1			10	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	NH3D6	38594558	gold, Green Published			2024-07-03	WOS:001199512100001
J	Godwin, RC; Bryant, AS; Wagener, BM; Ness, TJ; DeBerry, JJ; Horn, LL; Graves, SH; Archer, AC; Melvin, RL				Godwin, Ryan C.; Bryant, Ayesha S.; Wagener, Brant M.; Ness, Timothy J.; DeBerry, Jennifer J.; Horn, LaShun L.; Graves, Shanna H.; Archer, Ashley C.; Melvin, Ryan L.			IRB-draft-generator: A generative AI tool to streamline the creation of institutional review board applications	SOFTWAREX			English	Review						Institutional review board; Generative AI; Large language models	BURNOUT; MODELS	The Institutional Review Board (IRB) is fundamental to conducting ethical research involving human subjects. IRB applications require detailed descriptions of the research and specific indications of how the research will be implemented. This can be difficult for inexperienced researchers. Preparing the application is a significant time commitment, even for experienced researchers. In order to lighten the administrative burden on busy clinical professionals, this software application will automatically generate a draft human subject research protocol (the most laborious element of an IRB application) based on responses to a short form. This technology uses generative AI and a custom literature search plug-in to draft the protocol from succinct, user-provided details. User inputs include a brief description of the research, including the hypothesis, inclusion/exclusion criteria, and the study design type (e.g., randomized clinical trial). This tool can expedite the IRB application creation process, provide additional consistency for reviewers, and may reduce clinician researcher burnout through a reduction in clerical work thereby facilitating participation in meaningful research.	[Godwin, Ryan C.; Bryant, Ayesha S.; Wagener, Brant M.; Ness, Timothy J.; DeBerry, Jennifer J.; Horn, LaShun L.; Graves, Shanna H.; Melvin, Ryan L.] Univ Alabama Birmingham, Sch Med, Dept Anesthesiol & Perioperat Med, Birmingham, AL 35294 USA; [Godwin, Ryan C.] Univ Alabama Birmingham, Sch Med, Dept Radiol, Birmingham, AL 35233 USA; [Archer, Ashley C.] Univ Alabama Birmingham, Sch Med, Birmingham, AL USA	University of Alabama System; University of Alabama Birmingham; University of Alabama System; University of Alabama Birmingham; University of Alabama System; University of Alabama Birmingham	Godwin, RC (corresponding author), Univ Alabama Birmingham, Sch Med, Dept Anesthesiol & Perioperat Med, Birmingham, AL 35294 USA.; Godwin, RC (corresponding author), Univ Alabama Birmingham, Sch Med, Dept Radiol, Birmingham, AL 35233 USA.	ryangodwin@uabmc.edu		Godwin, Ryan/0000-0001-6590-3970				Cabitza F, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00138-8; Edu-Valsania S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031780; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Harry E, 2021, JT COMM J QUAL PATIE, V47, P76, DOI 10.1016/j.jcjq.2020.09.011; Lynch HF, 2018, J LAW MED ETHICS, V46, P145, DOI 10.1177/1073110518766028; MASLACH C, 1981, J OCCUP BEHAV, V2, P99, DOI 10.1002/job.4030020205; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Pech C, 2007, NUTR CLIN PRACT, V22, P618, DOI 10.1177/0115426507022006618; Reason J, 2000, WESTERN J MED, V172, P393, DOI 10.1136/ewjm.172.6.393; Reverberi C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18751-2; Rotenstein LS, 2023, J GEN INTERN MED, V38, P1920, DOI 10.1007/s11606-023-08153-z; Shanafelt TD, 2016, MAYO CLIN PROC, V91, P836, DOI 10.1016/j.mayocp.2016.05.007; Shanafelt TD, 2009, ARCH INTERN MED, V169, P990, DOI 10.1001/archinternmed.2009.70; Shoenbill K, 2017, J CLIN TRANSL SCI, V1, P176, DOI 10.1017/cts.2016.25; Wiegmann DA, 2022, J PATIENT SAF, V18, P119, DOI 10.1097/PTS.0000000000000810	18	1	1	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-7110			SOFTWAREX	SoftwareX	FEB	2024	25								101601	10.1016/j.softx.2023.101601	http://dx.doi.org/10.1016/j.softx.2023.101601		DEC 2023	5	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DS2S4		gold			2024-07-03	WOS:001134000400001
C	Zheng, QK; Xia, X; Zou, X; Dong, YX; Wang, S; Xue, YF; Shen, L; Wang, ZH; Wang, AD; Li, Y; Su, T; Yang, ZL; Tang, J			ACM	Zheng, Qinkai; Xia, Xiao; Zou, Xu; Dong, Yuxiao; Wang, Shan; Xue, Yufei; Shen, Lei; Wang, Zihan; Wang, Andi; Li, Yang; Su, Teng; Yang, Zhilin; Tang, Jie			CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Benchmarking on HumanEval-X	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD		code generation; pre-trained model; large language model		Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 8 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to increase coding efficiency for 83.4% of its users. Finally, CodeGeeX is publicly accessible since Sep. 2022, we open-sourced its code, modelweights, API, extensions, and HumanEval-X at https://github.com/THUDM/CodeGeeX.	[Zheng, Qinkai; Xia, Xiao; Zou, Xu; Dong, Yuxiao; Wang, Zihan; Yang, Zhilin; Tang, Jie] Tsinghua Univ, Beijing, Peoples R China; [Wang, Shan; Xue, Yufei; Shen, Lei; Wang, Andi; Li, Yang] Zhipu AI, Beijing, Peoples R China; [Su, Teng] Huawei, Hangzhou, Peoples R China	Tsinghua University; Huawei Technologies	Tang, J (corresponding author), Tsinghua Univ, Beijing, Peoples R China.	qinkai@tsinghua.edu.cn; xiax19@mails.tsinghua.edu.cn; zoux18@mails.tsinghua.edu.cn; yuxiaod@tsinghua.edu.cn; shan.wang@zhipuai.cn; yufei.xue@zhipuai.cn; lei.shen@zhipuai.cn; zhwang19@mails.tsinghua.edu.cn; andi.wang@zhipuai.cn; yang.li@zhipuai.cn; suteng@huawei.com; zhiliny@tsinghua.edu.cn; jietang@tsinghua.edu.cn	tang, jie/KIE-8633-2024; TANG, JIE/KIL-8226-2024	Zou, Xu/0000-0002-9471-1481; li, yang/0000-0002-2485-3951	Natural Science Foundation of China (NSFC) [61825602, 62276148, 61836013]; Zhipu.AI	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Zhipu.AI	This research was supported by Natural Science Foundation of China (NSFC) for Distinguished Young Scholars No. 61825602, NSFC No. 62276148 and No. 61836013, and a research fund from Zhipu.AI. We give our special thanks to Wenguang Chen from Tsinghua, the Peng Cheng Laboratory, and Zhipu.AI for sponsoring the training and inference GPU resources. We thank all our collaborators and partners from Tsinghua KEG, IIIS, Peng Cheng Laboratory, and Zhipu.AI, including Aohan Zeng, Wendi Zheng, Lilong Xue, Yifeng Liu, Yanru Chen, Yichen Xu, Qingyu Chen, Zhongqi Li, Gaojun Fan, Yifan Yao, Qihui Deng, Bin Zhou, Ruijie Cheng, Peinan Yu, Jingyao Zhang, Bowen Huang, Zhaoyu Wang, Jiecai Shan, Xuyang Ding, Xuan Xue, and Peng Zhang.	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; [Anonymous], 2021, YOU USE THIS SOFTWAR, DOI DOI 10.1016/J.PEDN.2021.03.005; [Anonymous], 2020, SC, DOI DOI 10.1109/SC41405.2020.00024; Austin Jacob, 2021, ARXIV210807732; Ba LJ., 2016, CORR; Black Sid, 2022, ARXIV220406745; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Fried Daniel, 2022, ARXIV220405999; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendrycks D., 2021, ARXIV210509938; Hendrycks D., 2016, ARXIV160608415, DOI DOI 10.48550/ARXIV.1606.08415; Kingma D. P., 2017, ARXIV; Kulal S, 2019, ADV NEUR IN, V32; Li Yujia, 2022, ARXIV220307814; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lu S., 2021, arXiv, P2021; Mou Lili, 2015, ARXIV151007211; Nijkamp Erik, 2022, ARXIV220313474; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Phan Long, 2021, ARXIV210508645; Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]; Qi Weizhen, 2021, ARXIV210408006; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ren Shuo, 2020, ARXIV200910297; Sennrich Rico, 2015, ARXIV PREPRINT ARXIV; Solar-Lezama A., 2008, Program synthesis by sketching; SUMMERS PD, 1977, J ACM, V24, P161, DOI 10.1145/321992.322002; Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Tunstall L., 2022, Natural Language Processing with Transformers; Vaswani A, 2017, ADV NEUR IN, V30; Waldinger R. J., 1969, P 1 INT JOINT C ARTI, P241; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang Y., 2021, arXiv preprint arXiv:2109.00859; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Zeng A., 2022, ARXIV221002414; Zeng Wei, 2021, PANGU ALPHA LARGE SC; Zhang S., 2022, arXiv; Zhu Ming, 2022, ARXIV220608474; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	46	2	2	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5673	5684		10.1145/3580305.3599790	http://dx.doi.org/10.1145/3580305.3599790			12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ		hybrid			2024-07-03	WOS:001118896305064
J	van der Gaag, MAE				van der Gaag, Mandy A. E.			A person-centered approach in developmental science: Why this is the future and how to get there	INFANT AND CHILD DEVELOPMENT			English	Article							IDENTITY DEVELOPMENT; DYNAMIC-SYSTEMS; PSYCHOPATHOLOGY; COMMITMENT; MODEL	This paper argues for a person-centered approach in developmental science and presents theoretical and empirical techniques to help shift the focus to the individual. The need for a person-centered approach is urgent, because of widespread nonergodicity in developmental psychology: traditional between-individual, group-level statistics often cannot be used to understand individuals over time. Evidence for nonergodicity has been gathered in domains such as personality, emotions, identity, performance and intelligence. This highlights a mismatch between our typical research methods-group-level analyses-and a core aim of developmental science: understanding the development of individuals. The implications are profound. Without insights into within-individual processes, our understanding of development remains incomplete and perhaps even incorrect, which could hinder the design of effective interventions. Many of our developmental theories might need to be adjusted to accurately capture individual-level development. The theory of complex dynamic systems and person-centered simulations offer promising avenues to do this. In addition, many promising person-centered analysis techniques, that typically use long time series of data, are available to enhance our understanding of individual-level development. Together, these person-centered theoretical and empirical tools have the potential to help shift developmental science towards an understanding of development that genuinely reflects individual processes.	[van der Gaag, Mandy A. E.] Univ Groningen, Fac Behav & Social Sci, Dept Dev Psychol, Groningen, Netherlands; [van der Gaag, Mandy A. E.] Univ Groningen, Fac Behav & Social Sci, Dept Dev Psychol, Grote Kruisstr 2-1, NL-9712 TS Groningen, Netherlands	University of Groningen; University of Groningen	van der Gaag, MAE (corresponding author), Univ Groningen, Fac Behav & Social Sci, Dept Dev Psychol, Grote Kruisstr 2-1, NL-9712 TS Groningen, Netherlands.	m.a.e.van.der.gaag@rug.nl		van der Gaag, Mandy/0000-0002-1957-1183	The author owes much thanks to all the colleagues at the Developmental Psychology department of the University of Groningen. The perspective presented in this paper has been shaped in the context of their dedicated work on the edge of psychological science [GPT-4, 2023]	The author owes much thanks to all the colleagues at the Developmental Psychology department of the University of Groningen. The perspective presented in this paper has been shaped in the context of their dedicated work on the edge of psychological science	The author owes much thanks to all the colleagues at the Developmental Psychology department of the University of Groningen. The perspective presented in this paper has been shaped in the context of their dedicated work on the edge of psychological science using person-centered studies and complex dynamic systems theory. A special thanks to professor Paul van Geert who has been particularly relentless in this pursuit and so far ahead of his time that it shall take developmental science many years to catch up. The language of this paper has been refined with the assistance of ChatGPT (GPT-4; openAI, 2023), a generative AI large language model.	Adler D., 2020, VIOPLOT VIOLIN PLOT; Allen Micah, 2019, Wellcome Open Res, V4, P63, DOI 10.12688/wellcomeopenres.15191.1; [Anonymous], 2008, Journal of Statistical Software; Asparouhov T, 2018, STRUCT EQU MODELING, V25, P359, DOI 10.1080/10705511.2017.1406803; Bakdash JZ, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01201; Borkenau P, 1998, J RES PERS, V32, P202, DOI 10.1006/jrpe.1997.2206; Borsboom D, 2021, PERSPECT PSYCHOL SCI, V16, P756, DOI 10.1177/1745691620969647; Borsboom D, 2017, WORLD PSYCHIATRY, V16, P5, DOI 10.1002/wps.20375; Bringmann LF, 2021, CURR OPIN PSYCHOL, V41, P59, DOI 10.1016/j.copsyc.2021.03.004; Bringmann LF, 2018, MULTIVAR BEHAV RES, V53, P293, DOI 10.1080/00273171.2018.1439722; Cox RFA, 2016, SPRINGER PROC PHYS, V180, P209, DOI 10.1007/978-3-319-29922-8_11; Cox RFA, 2013, ECOL PSYCHOL, V25, P304, DOI 10.1080/10407413.2013.810095; Dablander F, 2023, PSYCHOL METHODS, V28, P765, DOI 10.1037/met0000450; De Jonge-Hoekstra L, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12989; de Ruiter N., 2019, PSYCHOSOCIAL DEV ADO; de Ruiter N. M., 2019, Psychosocial development in adolescence, P1, DOI [10.4324/9781315165844, DOI 10.4324/9781315165844]; De Ruiter NMP, 2017, REV GEN PSYCHOL, V21, P49, DOI 10.1037/gpr0000099; Fisher AJ, 2018, P NATL ACAD SCI USA, V115, pE6106, DOI 10.1073/pnas.1711978115; Frankenhuis WE, 2019, DEV PSYCHOL, V55, P2002, DOI 10.1037/dev0000732; Frankenhuis WE, 2018, CHILD DEV, V89, P2303, DOI 10.1111/cdev.13021; Gates KM, 2012, NEUROIMAGE, V63, P310, DOI 10.1016/j.neuroimage.2012.06.026; Hamaker EL, 2022, MULTIVAR BEHAV RES, DOI 10.1080/00273171.2022.2155930; Hamaker EL, 2015, EMOT REV, V7, P316, DOI 10.1177/1754073915590619; Hamaker E. L., 2012, Handbook of research methods for studying daily life, P43, DOI DOI 10.5860/CHOICE.50-1159; Haslbeck JMB, 2020, MULTIVAR BEHAV RES, V56, P120, DOI 10.1080/00273171.2020.1743630; Haslbeck JMB, 2022, PSYCHOL METHODS, V27, P930, DOI 10.1037/met0000303; Hayes SC, 2019, BEHAV RES THER, V117, P40, DOI 10.1016/j.brat.2018.10.005; Heininga VE, 2021, CURR OPIN BEHAV SCI, V39, P10, DOI 10.1016/j.cobeha.2020.11.005; Heino MTJ, 2021, BEHAV SCI-BASEL, V11, DOI 10.3390/bs11050077; Hoffman L, 2022, ANNU REV PSYCHOL, V73, P659, DOI 10.1146/annurev-psych-020821-103525; Hollenstein T., 2019, PSYCHOSOCIAL DEV ADO, P127; Hollenstein T, 2007, INT J BEHAV DEV, V31, P384, DOI 10.1177/0165025407077765; Jung T, 2008, SOC PERSONAL PSYCHOL, V2, P302, DOI 10.1111/j.1751-9004.2007.00054.x; Kaplan U., 2019, PSYCHOSOCIAL DEV ADO, P127; Kunnen E. S., 2011, DYNAMIC SYSTEMS APPR; Lichtwarck-Aschoff A, 2004, EUR J DEV PSYCHOL, V1, P399, DOI 10.1080/17405620444000157; Lundh Lars-Gunnar, 2019, J Pers Oriented Res, V5, P65, DOI 10.17505/jpor.2019.07; McNeish D, 2020, PSYCHOL METHODS, V25, P610, DOI 10.1037/met0000250; Meinecke AL, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00863; Menninga A, 2022, RES SCI EDUC, V52, P1497, DOI 10.1007/s11165-021-09997-3; Molenaar P. C. M., 2004, Measurement, V2, P201, DOI [DOI 10.1207/S15366359MEA0204_1, 10.1207/s15366359mea02041]; Molenaar PCM, 2009, CURR DIR PSYCHOL SCI, V18, P112, DOI 10.1111/j.1467-8721.2009.01619.x; Muthén B, 2009, CH CRC HANDB MOD STA, P143; Neumann ND, 2022, INT J SPORT PHYSIOL, V17, P391, DOI 10.1123/ijspp.2021-0126; Oberauer K, 2019, PSYCHON B REV, V26, P1596, DOI 10.3758/s13423-019-01645-2; Olthof M, 2020, CLIN PSYCHOL SCI, V8, P25, DOI 10.1177/2167702619865969; OpenAI, 2023, CHATGPT GPT 4 SEPTEM; Petris G, 2009, USE R, P31, DOI 10.1007/b135794_2; Phillips N., 2017, PIRATEPLOT; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Robinaugh DJ, 2021, PERSPECT PSYCHOL SCI, V16, P725, DOI 10.1177/1745691620974697; Scheffer M, 2012, SCIENCE, V338, P344, DOI 10.1126/science.1225244; Schiepek G., 2019, PSYCHOSOCIAL DEV ADO, P51, DOI 10.4324/9781315165844-4; Schmiedek F, 2020, PEERJ, V8, DOI 10.7717/peerj.9290; Smaldino PE, 2020, SOC PSYCHOL-GERMANY, V51, P207, DOI 10.1027/1864-9335/a000425; Smaldino PE, 2017, FRONT SOC PSYCHOL, P311; Smith LB, 2003, TRENDS COGN SCI, V7, P343, DOI 10.1016/S1364-6613(03)00156-6; Tan P. N., 2005, Introduction to Data Mining; Toonen R. B., 2016, J PERSON ORIENTED RE, V2, P142, DOI 10.17505/jpor.2016.14; van de Water M, 2019, PERFORM BOOKS, P127; van der Gaag M. A. E., 2019, PSYCHOSOCIAL DEV ADO, P223, DOI [10.4324/9781315165844-14, DOI 10.4324/9781315165844-14]; Van der Gaag MAE, 2020, IDENTITY, V20, P272, DOI 10.1080/15283488.2020.1821154; van der Gaag MAE, 2020, PALGR COMMUN, V6, DOI 10.1057/s41599-020-0446-z; van der Gaag MAE, 2017, DEV PSYCHOL, V53, P2205, DOI 10.1037/dev0000336; van der Gaag MAE, 2016, J ADOLESCENCE, V47, P38, DOI 10.1016/j.adolescence.2015.11.007; Van Der Krieke L, 2016, INT J METH PSYCH RES, V25, P123, DOI 10.1002/mpr.1495; van der Maas HLJ, 2006, PSYCHOL REV, V113, P842, DOI 10.1037/0033-295X.113.4.842; van Dijk M, 2007, INFANT CHILD DEV, V16, P7, DOI 10.1002/icd.506; van Geert P, 2011, CHILD DEV PERSPECT, V5, P273, DOI 10.1111/j.1750-8606.2011.00197.x; Voelkle MC, 2014, MULTIVAR BEHAV RES, V49, P193, DOI 10.1080/00273171.2014.889593; von Neumann J, 1941, ANN MATH STAT, V12, P153, DOI 10.1214/aoms/1177731746; von Oertzen T, 2020, J INTELL-BASEL, V8, DOI 10.3390/jintelligence8010003; Wright AGC, 2020, ANNU REV CLIN PSYCHO, V16, P49, DOI 10.1146/annurev-clinpsy-102419-125032; Wright AGC, 2019, PSYCHOL ASSESSMENT, V31, P502, DOI 10.1037/pas0000617	74	2	2	5	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1522-7227	1522-7219		INFANT CHILD DEV	Infant Child Dev.	NOV	2023	32	6								10.1002/icd.2478	http://dx.doi.org/10.1002/icd.2478		NOV 2023	17	Psychology, Developmental	Social Science Citation Index (SSCI)	Psychology	CL3H8		hybrid, Green Published			2024-07-03	WOS:001102040500001
C	Liu, TT; Jain, D; Rapole, SR; Curtis, B; Eichstaedt, JC; Ungar, LH; Guntuku, SC			ACM	Liu, Tingting; Jain, Devansh; Rapole, Shivani Reddy; Curtis, Brenda; Eichstaedt, Johannes C.; Ungar, Lyle H.; Guntuku, Sharath Chandra			Detecting Symptoms of Depression on Reddit	PROCEEDINGS OF THE 15TH ACM WEB SCIENCE CONFERENCE, WEBSCI 2023			English	Proceedings Paper	15th ACM Web Science Conference (WebSci)	APR 30-MAY 01, 2023	Austin, TX	Assoc Comp Machinery, ACM Special Interest Grp Hypertext & Web		Depression; Symptomology; Reddit; Psycholinguistics; Large Language Models; Heterogeneity	ANXIETY; LONELINESS; DISORDER; SCALE	Depression is known to have heterogeneous symptom manifestations. Investigating various symptoms of depression is essential to understanding underlying mechanisms and personalizing treatments. Reddit, an online peer-to-peer social media platform, contains varied communities (subreddits) where individuals discuss their detailed mental health experiences and seek support. The current paper has two aims. The first is to identify psycho-linguistic and open-vocabulary language markers associated with different symptoms using 1,318,749 posts from 43 subreddit communities (e.g., r/bingeeating) clustered into 13 expert-validated depression symptoms (e.g., disordered eating). The second aim is to develop prediction models based on the above linguistic features and RoBERTa embeddings to detect specific symptom discourse in contrast to control subreddit posts contributed by the same Reddit users. These predictive models are then validated on a second sample of individuals (N = 2,986) who shared their Facebook posts and completed self-report depression (PHQ-9), anxiety (GAD-7), and loneliness (UCLA-3) surveys. Based on the differential linguistic patterns that emerged across the various symptoms in our data, we identified three potential clusters, which could also be mapped to the Research Domain Criteria (RDoC) framework. RoBERTa embeddings demonstrated the highest accuracy at predicting most symptoms and were particularly robust at predicting the severity of suicidal thoughts and attempts, self-loathing, loneliness, and disordered eating. Our study demonstrates the potential of using large, pseudonymous online forums to train language-based symptom-estimation machine-learning models that can be applied to other text sources. Such technologies could be helpful in clinical psychology, population health, and other areas where early mental health monitoring could improve diagnosis, risk reduction, and treatment.	[Liu, Tingting; Curtis, Brenda] Natl Inst Drug Abuse, Baltimore, MD 21224 USA; [Jain, Devansh; Rapole, Shivani Reddy; Ungar, Lyle H.; Guntuku, Sharath Chandra] Univ Penn, Philadelphia, PA 19104 USA; [Eichstaedt, Johannes C.] Stanford Univ, Stanford, CA 94305 USA	National Institutes of Health (NIH) - USA; NIH National Institute on Drug Abuse (NIDA); University of Pennsylvania; Stanford University	Liu, TT (corresponding author), Natl Inst Drug Abuse, Baltimore, MD 21224 USA.	tingting.liu@nih.gov; devanshrjain7@gmail.com; srapole@seas.upenn.edu; brenda.curtis@nih.gov; johannes.stanford@gmail.com; ungar@cis.upenn.edu; sharathg@cis.upenn.edu	Liu, Tingting/GYD-4727-2022	Liu, Tingting/0000-0002-8179-6180; Eichstaedt, Johannes/0000-0002-3220-2972; Curtis, Brenda/0000-0002-2511-3322; Ungar, Lyle/0000-0003-2047-1443	National Institute On Minority Health And Health Disparities of the National Institutes of Health [R01MD018340]; Intramural Research Program of the National Institutes of Health (NIH); National Institute on Drug Abuse (NIDA)	National Institute On Minority Health And Health Disparities of the National Institutes of Health; Intramural Research Program of the National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institute on Drug Abuse (NIDA)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA))	Research reported in this publication was supported by the National Institute On Minority Health And Health Disparities of the National Institutes of Health under Award Number R01MD018340, and was funded by the Intramural Research Program of the National Institutes of Health (NIH), National Institute on Drug Abuse (NIDA). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	Alghamdi NS, 2020, IEEE ACCESS, V8, P57317, DOI 10.1109/ACCESS.2020.2981834; Andrew Schwartz H., 2017, P 2017 C EMPIRICAL M, P55, DOI DOI 10.18653/V1/D17-2010; [Anonymous], 2015, DEV PSYCHOMETRIC PRO, DOI DOI 10.15781/T29G6Z; [Anonymous], 2013, P 23 INT JOINT C ART; Bao Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P239, DOI 10.1145/2505515.2505556; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; BECK AT, 1988, CLIN PSYCHOL REV, V8, P77, DOI 10.1016/0272-7358(88)90050-5; Beck AT, 1996, BECK DEPRESSION INVE, DOI [10.1037/t00742-000, DOI 10.1037/T00742-000]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blumenthal SR, 2014, JAMA PSYCHIAT, V71, P889, DOI 10.1001/jamapsychiatry.2014.414; Boettcher N, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29487; Chancellor S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0233-7; Cohan A, 2018, Arxiv, DOI arXiv:1806.05258; De Choudhury M., 2013, P INT AAAI C WEB SOC, V7, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998]; De Choudhury Munmun, 2017, Proc Int AAAI Conf Weblogs Soc Media, V2017, P32; De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207; DOBSON KS, 1985, CLIN PSYCHOL REV, V5, P307, DOI 10.1016/0272-7358(85)90010-8; Eichstaedt JC, 2021, PSYCHOL METHODS, V26, P398, DOI 10.1037/met0000349; Eichstaedt JC, 2018, P NATL ACAD SCI USA, V115, P11203, DOI 10.1073/pnas.1802331115; Erzen E, 2018, INT J SOC PSYCHIATR, V64, P427, DOI 10.1177/0020764018776349; Fried EI, 2022, NAT REV PSYCHOL, V1, P358, DOI 10.1038/s44159-022-00050-2; Fried EI, 2017, J AFFECT DISORDERS, V208, P191, DOI 10.1016/j.jad.2016.10.019; Fried EI, 2015, BMC MED, V13, DOI 10.1186/s12916-015-0325-4; Fried EI, 2015, J AFFECT DISORDERS, V172, P96, DOI 10.1016/j.jad.2014.10.010; Gaur M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P753, DOI 10.1145/3269206.3271732; Giuntini FT, 2020, J AMB INTEL HUM COMP, V11, P4713, DOI 10.1007/s12652-020-01726-4; Gkotsis G, 2017, SCI REP-UK, V7, DOI 10.1038/srep45141; Groen RN, 2019, PSYCHIAT RES, V271, P640, DOI 10.1016/j.psychres.2018.12.054; Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005; Guntuku Sharath Chandra., 2019, Proceedings of the international AAAI conference on web and social media, V13, P214, DOI DOI 10.1609/ICWSM.V13I01.3223; HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56; Hughes ME, 2004, RES AGING, V26, P655, DOI 10.1177/0164027504268574; Insel T, 2010, AM J PSYCHIAT, V167, P748, DOI 10.1176/appi.ajp.2010.09091379; Islam MR, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0046-0; Jaidka Kokil, 2018, P INT AAAI C WEB SOC, V12; Jiang Z.P., 2020, P 11 INT WORKSHOP HL, P147, DOI DOI 10.18653/V1/2020.LOUHI-1.16; Kendler KS, 2013, JAMA PSYCHIAT, V70, P599, DOI 10.1001/jamapsychiatry.2013.751; Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x; Li DY, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17144988; Liu TT, 2022, AM J DRUG ALCOHOL AB, V48, P573, DOI 10.1080/00952990.2022.2091450; Liu Tingting, 2022, npj Mental Health Research, V1; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Matero Matthew, 2019, CLPSYCH, P39, DOI [10.18653/v1/W19-3005, DOI 10.18653/V1/W19-3005]; McCallum AK, 2002, MALLET MACHINE LEARN; Moussavi S, 2007, LANCET, V370, P851, DOI 10.1016/S0140-6736(07)61415-9; Orsolini L, 2020, PSYCHIAT INVEST, V17, P207, DOI 10.30773/pi.2019.0171; Pala AN, 2016, BRAIN BEHAV IMMUN, V56, P105, DOI 10.1016/j.bbi.2016.02.013; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Proferes N., 2021, Social Media + Society, V7, DOI DOI 10.1177/20563051211019004; PYSZCZYNSKI T, 1987, J PERS SOC PSYCHOL, V52, P994, DOI 10.1037/0022-3514.52.5.994; Resnik Philip, 2015, P 2 WORKSH COMP LING, P99, DOI [DOI 10.3115/V1/W15-1212, 10.3115/v1/W15-1212]; Araujo DMR, 2010, WORLD J BIOL PSYCHIA, V11, P199, DOI 10.3109/15622970802563171; Salas-Zárate R, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10020291; Salazar JW, 2019, OTOLARYNG HEAD NECK, V161, P28, DOI 10.1177/0194599819835178; Saqib K, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/29838; Smith Kerri, 2014, Nature, V515, P181, DOI 10.1038/515180a; Spitzer RL, 2006, ARCH INTERN MED, V166, P1092, DOI 10.1001/archinte.166.10.1092; STAVRAKAKI C, 1986, BRIT J PSYCHIAT, V149, P7, DOI 10.1192/bjp.149.1.7; Thorp JG, 2020, PSYCHOL MED, V50, P2385, DOI 10.1017/S0033291719002526; Wanchoo K, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0280337; WEEKS DG, 1980, J PERS SOC PSYCHOL, V39, P1238, DOI 10.1037/h0077709; WilliamWEaton Corey Smith, 2004, Center for Epidemiologic Studies Depression Scale: review and revision (CESD and CESD-R); Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yazdavar AH, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0226248; Yazdavar Amir Hossein, 2017, Proc IEEE ACM Int Conf Adv Soc Netw Anal Min, V2017, P1191, DOI 10.1145/3110025.3123028	65	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0089-7				2023							174	183		10.1145/3578503.3583621	http://dx.doi.org/10.1145/3578503.3583621			10	Computer Science, Information Systems; History & Philosophy Of Science; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; History & Philosophy of Science; Social Sciences - Other Topics	BW2MC					2024-07-03	WOS:001118948600018
C	Mai, GC; Cundy, C; Choi, K; Hu, YJ; Lao, N; Ermon, S		Renz, M; Sarwat, M; Nascimento, MA; Shekhar, S; Xie, X		Mai, Gengchen; Cundy, Chris; Choi, Kristy; Hu, Yingjie; Lao, Ni; Ermon, Stefano			Towards a Foundation Model for Geospatial Artificial Intelligence (Vision Paper)	30TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, ACM SIGSPATIAL GIS 2022			English	Proceedings Paper	30th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS)	NOV 01-04, 2022	Seattle, WA	ACM SIGSPATIAL, Apple, Oracle, Esri, Google, Wherobots		Foundation models; large language models; geospatial artificial intelligence		Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet to see an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges for developing multimodal foundation models for GeoAI. We first show the advantages of this idea by testing the performance of existing Large pre-trained Language Models (LLMs) (e.g. GPT-2 and GPT-3) on two geospatial semantics tasks. Results indicate that these task-agnostic LLMs can outperform task-specific fully-supervised models on both tasks with 2-9% improvement in a few-shot learning setting. However, we also show the limitations of these existing foundation models given the multimodality nature of GeoAI, especially when dealing with geometries in conjunction with other modalities. So we discuss the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such model for GeoAI.	[Mai, Gengchen; Cundy, Chris; Choi, Kristy; Ermon, Stefano] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Hu, Yingjie] Univ Buffalo, Dept Geog, Buffalo, NY USA; [Lao, Ni] Google, Mountain View, CA USA	Stanford University; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; Google Incorporated	Mai, GC (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	maigch@cs.stanford.edu; cundy@cs.stanford.edu; kechoi@cs.stanford.edu; yhu42@buffalo.edu; nlao@google.com; ermon@cs.stanford.edu	Choi, Kristy/KPB-1598-2024	Mai, Gengchen/0000-0002-7818-7309	NSF [1651565, 1522054, 1733686, BCS-2117771]; ONR [N00014-19-1-2145]; AFOSR [FA9550-19-1-0024]; ARO [W911NF2110125]; Amazon AWS; Sloan Fellowship; Qualcomm Innovation Fellowship; Two Sigma PhD Diversity Fellowship; CZ Biohub; U.S. Department of Defense (DOD) [W911NF2110125] Funding Source: U.S. Department of Defense (DOD)	NSF(National Science Foundation (NSF)); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); ARO; Amazon AWS; Sloan Fellowship(Alfred P. Sloan Foundation); Qualcomm Innovation Fellowship; Two Sigma PhD Diversity Fellowship; CZ Biohub; U.S. Department of Defense (DOD)(United States Department of Defense)	This work is supported by the NSF (Grant No. BCS-2117771). SE, CC, and KC acknowledge support by NSF (#1651565, #1522054, #1733686), ONR (N00014-19-1-2145), AFOSR (FA9550-19-1-0024), ARO (W911NF2110125), CZ Biohub, Amazon AWS, and Sloan Fellowship. KC is supported by the Qualcomm Innovation Fellowship and Two Sigma PhD Diversity Fellowship.	Akbari H, 2021, ADV NEUR IN; Alex B, 2015, INT J HUMANIT ARTS C, V9, P15, DOI 10.3366/ijhac.2015.0136; Ayush K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10161, DOI 10.1109/ICCV48922.2021.01002; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; DeLozier G., 2016, P 10 LING ANN WORKSH, VX, P188, DOI [DOI 10.18653/V1/W16-1721, 10.18653/v1/W16-1721]; Goodchild MF, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2015759118; Gritta M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1285; Hu Yingjie, 2014, GIR WORKSH 2014, P1; Hu Yingjie, 2020, GISCIENCE 2020; Ju YT, 2016, LECT NOTES COMPUT SC, V10024, P353, DOI 10.1007/978-3-319-49004-5_23; Kamath Aishwarya, 2021, arXiv; Lam D., 2018, arXiv; Liu ZL, 2022, AGILE GIScience, V3, DOI 10.5194/agile-giss-3-9-2022; Mai G., 2021, AGILE GISCIENCE SERI, V2, P1; Mai GC, 2022, INT J GEOGR INF SCI, V36, P639, DOI 10.1080/13658816.2021.2004602; Mai Gengchen, 2020, ICLR 2020; Mai Gengchen., 2020, Transactions in GIS; Mendes Pablo N, 2011, I SEMANTICS 2011; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Ramesh A., 2022, arXiv; Rolf E, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24638-z; Wang JM, 2020, T GIS, V24, P719, DOI 10.1111/tgis.12627; Wang JM, 2019, T GIS, DOI 10.1111/tgis.12579; Wang X., 2019, P 13 INT WORKSH SEM, P917, DOI 10.18653/v1/s19-2156	27	1	1	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9529-8				2022							744	747		10.1145/3557915.3561043	http://dx.doi.org/10.1145/3557915.3561043			4	Computer Science, Information Systems; Geosciences, Multidisciplinary; Remote Sensing	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Geology; Remote Sensing	BW7JG		Bronze			2024-07-03	WOS:001191032100106
C	Wang, B; Li, RS; Li, MK; Saxena, P		Chandra, S; Blincoe, K; Tonella, P		Wang, Bo; Li, Ruishi; Li, Mingkai; Saxena, Prateek			TransMap: Pinpointing Mistakes in Neural Code Translation	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Code Translation; Large Language Models; Semantic Mistakes		Automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code. Recent neural machine translation models, such as Codex, have been shown to be effective on many code generation tasks including translation. However, code produced by neural translators often has semantic mistakes. These mistakes are difficult to eliminate from the neural translator itself because the translator is a black box, which is difficult to interpret or control compared to rule-based transpilers. We propose the first automated approach to pinpoint semantic mistakes in code obtained after neural code translation. Our techniques are implemented in a prototype tool called TransMap which translates Python to JavaScript, both of which are popular scripting languages. On our created micro-benchmarks of Python programs with 648 semantic mistakes in total, TransMap accurately pinpoints the correct location for a fix for 87.96%, often highlighting 1-2 lines for the user to inspect per mistake. We report on our experience in translating 5 Python libraries with up to 1: lines of code with TransMap. Our preliminary user study suggests that TransMap can reduce the time for fixing semantic mistakes by around 70% compared to using a standard IDE with debuggers.	[Wang, Bo; Li, Ruishi; Li, Mingkai; Saxena, Prateek] Natl Univ Singapore, Singapore, Singapore	National University of Singapore	Wang, B (corresponding author), Natl Univ Singapore, Singapore, Singapore.	bo_wang@u.nus.edu; liruishi@u.nus.edu; t0927617@u.nus.edu; prateeks@comp.nus.edu.sg		Li, Mingkai/0009-0007-3191-0890; Li, Ruishi/0000-0003-2513-1704; Wang, Bo/0000-0003-1444-0237	Ministry of Education in Singapore [MOE-T2EP20220-0014, T1 251RES2023]	Ministry of Education in Singapore(Ministry of Education, Singapore)	We thank the anonymous reviewers. This research is supported by grants given by the Ministry of Education in Singapore: Tier-2 grant MOE-T2EP20220-0014 and Tier-1 grant T1 251RES2023.	Abreu R, 2007, TAIC PART 2007 - TESTING: ACADEMIC AND INDUSTRIAL CONFERENCE - PRACTICE AND RESEARCH TECHNIQUES, PROCEEDINGS, P89, DOI 10.1109/TAIC.PART.2007.13; [Anonymous], 2023, Supplementary Material; Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Blazytko T, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P235; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chan SCY, 2022, Arxiv, DOI [arXiv:2205.05055, DOI 10.48550/ARXIV.2205.05055]; Chandra S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P121, DOI 10.1145/1985793.1985811; Chen M., 2021, arXiv; CodeGeeX, 2023, HumanEval-X: A new benchmark for Multilingual Program Synthesis; Cordy JR, 2006, SCI COMPUT PROGRAM, V61, P190, DOI 10.1016/j.scico.2006.04.002; Cui WD, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P17; Deletang Gregoire, 2023, Neural Networks and the Chomsky Hierarchy; doocs, 2023, LeetCode solutions in any programming language; Ermis Evren, 2012, FM 2012: Formal Methods. Proceedings of the 18th International Symposium, P187, DOI 10.1007/978-3-642-32759-9_17; Fairdoth Jeremy, 2002, C# For Java Programmers, DOI [10.1016/B978-193183654-8/50019-0, DOI 10.1016/B978-193183654-8/50019-0]; Fan ZY, 2023, PROC INT CONF SOFTW, P1469, DOI 10.1109/ICSE48619.2023.00128; Feldman J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1173; Gao X, 2022, Arxiv, DOI arXiv:2211.12787; Garg S, 2022, Arxiv, DOI arXiv:2208.01066; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Nguyen HDT, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P772, DOI 10.1109/ICSE.2013.6606623; Irrera A., 2017, Banks scramble to fix old systems as IT "cowboys" ride into sunset; Jain Naman, 2021, arXiv; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Jin Wei., 2013, P 2013 INT S SOFTWAR, P213, DOI DOI 10.1145/2483760.2483763; Jones JA, 2002, ICSE 2002: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P467, DOI 10.1109/ICSE.2002.1007991; Jose M, 2011, ACM SIGPLAN NOTICES, V46, P437, DOI 10.1145/1993316.1993550; Kochhar P. S., 2016, P 25 INT S SOFTWARE, P165; Lample G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5039; Li JY, 2023, Arxiv, DOI arXiv:2305.11747; Xie SM, 2022, Arxiv, DOI [arXiv:2111.02080, 10.48550/arXiv.2111.02080]; Microsoft, 2023, Visual studio code; mozilla, 2023, source-map: Consume and generate source maps; OpenAI, 2023, Code completion-OpenAI API; OpenAI, 2023, CHATGPT; OpenAI, 2023, Openai api; OpenAI Github, 2023, GitHub Copilot Your AI pair programmer; Pacheco C, 2007, PROC INT CONF SOFTW, P75; Poesia G, 2022, Arxiv, DOI [arXiv:2201.11227, 10.48550/ARXIV.2201.11227]; Qi DW, 2012, ACM T SOFTW ENG METH, V21, DOI 10.1145/2211616.2211622; Raffel C, 2020, J MACH LEARN RES, V21; Roziere B., 2020, Advances in neural information processing systems, V33, P20601; Shen SQ, 2021, ASIA CCS'21: PROCEEDINGS OF THE 2021 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P537, DOI 10.1145/3433210.3437528; Shin R, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5417; Stack Overflow, 2023, Does JavaScript support array/list comprehensions like Python?; Szafraniec M, 2022, Arxiv, DOI arXiv:2207.03578; Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811; Tillmann N, 2008, LECT NOTES COMPUT SC, V4966, P134; Tipirneni S, 2024, Arxiv, DOI arXiv:2206.05239; tree sitter, 2023, Tree-sitter; typescriptlang, 2023, TSConfig Reference: Source Map; Wang Bo, 2023, Zenodo, DOI 10.5281/ZENODO.8283633; Wang B, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586034; Wang HJ, 2021, IEEE T SOFTWARE ENG, V47, P2421, DOI 10.1109/TSE.2019.2949568; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weimer W, 2009, PROC INT CONF SOFTW, P364, DOI 10.1109/ICSE.2009.5070536; Welleck S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5553; Wong WE, 2016, IEEE T SOFTWARE ENG, V42, P707, DOI 10.1109/TSE.2016.2521368; Xin B, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P238, DOI 10.1145/1375581.1375611; Zhang X, 2006, ACM SIGPLAN NOTICES, V41, P169, DOI 10.1145/1133981.1134002	62	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							999	1011		10.1145/3611643.3616322	http://dx.doi.org/10.1145/3611643.3616322			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		hybrid			2024-07-03	WOS:001148157800081
J	Kawahara, T; Sumi, Y				Kawahara, Tomoki; Sumi, Yuki			GPT-4/4V's performance on the Japanese National Medical Licensing Examination	MEDICAL TEACHER			English	Article; Early Access						Large language model; application programming interface; generative pretrained transformer; medical licensing examination		BackgroundRecent advances in Artificial Intelligence (AI) are changing the medical world, and AI will likely replace many of the actions performed by medical professionals. The overall clinical ability of the AI has been evaluated by its ability to answer a text-based national medical examination. This study uniquely assesses the performance of Open AI's ChatGPT against all Japanese National Medical Licensing Examination (NMLE), including images, illustrations, and pictures.MethodsWe obtained the questions of the past six years of the NMLE (112th to 117th) from the Japanese Ministry of Health, Labour and Welfare website. We converted them to JavaScript Object Notation (JSON) format. We created an application programming interface (API) to output correct answers using GPT-4 for questions without images and GPT4-V(ision) or GPT4 console for questions with images.ResultsThe percentage of image questions was 723/2400 (30.1%) over the past six years. In all years, GPT-4/4V exceeded the minimum score the examinee should score. In total, over the six years, the percentage of correct answers for basic medical knowledge questions was 665/905 (73.5%); for clinical knowledge questions, 1143/1531 (74.7%); and for image questions 497/723 (68.7%), respectively.ConclusionsRegarding medical knowledge, GPT-4/4V met the minimum criteria regardless of whether the questions included images, illustrations, and pictures. Our study sheds light on the potential utility of AI in medical education.	[Kawahara, Tomoki; Sumi, Yuki] Tokyo Med & Dent Univ TMDU, Dept Clin Informat Appl Sci, 1-5-45 Yushima,Bunkyo ku, Tokyo 1138510, Japan	Tokyo Medical & Dental University (TMDU)	Kawahara, T (corresponding author), Tokyo Med & Dent Univ TMDU, Dept Clin Informat Appl Sci, 1-5-45 Yushima,Bunkyo ku, Tokyo 1138510, Japan.	aaagcuugggcu@gmail.com		Kawahara, Tomoki/0000-0002-9849-3880				Ahmad Z, 2021, DIAGN PATHOL, V16, DOI 10.1186/s13000-021-01085-4; Alami H, 2020, J MED INTERNET RES, V22, DOI 10.2196/17707; [Anonymous], 2021, National Medical Licensing Examination; Çaliskan SA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271872; Chan Kai Siang, 2019, JMIR Med Educ, V5, pe13930, DOI 10.2196/13930; Civaner MM, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03852-3; Dai C-P., 2022, Computers Education: Artificial Intelligence, V3, P100087, DOI DOI 10.1016/J.CAEAI.2022.100087; Flores-Cohaila JA, 2023, JMIR MED EDUC, V9, DOI 10.2196/48039; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hah H, 2021, J MED INTERNET RES, V23, DOI 10.2196/33540; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Huang JAT, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36100; Japan Ministry of Health Labour and Welfare, 2022, Questions and correct answers for the 116th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2018, Questions and correct answers for the 112th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2020, Announcement of acceptance rate of the 114th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2023, Announcement of successful passage of the 117th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2022, Announcement of acceptance rate of the 116th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2019, Announcement of acceptance rate of the 113th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2021, Announcement of acceptance rate of the 115th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2023, Questions and correct answers for the 117th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2019, Report of the subcommittee to study the improvement of the Japanese National Medical Licensing Examination; Japan Ministry of Health Labour and Welfare, 2020, Questions and correct answers for the 114th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2019, Questions and correct answers for the 113th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2018, Announcement of acceptance rate of the 112th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2021, Questions and correct answers for the 115th National Medical Examination; Japan Ministry of Health Labour and Welfare, 2023, Announcement of acceptance rate of the 117th National Medical Examination; Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; MEC, 2023, MEC National Medical Licensing Examination Bulletin Board; Medic Media, 2022, The 116th National Medical Licensing Examination; Mir Mohammad Muzaffar, 2023, J Adv Med Educ Prof, V11, P133, DOI 10.30476/JAMP.2023.98655.1803; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Naithani Nardeep, 2021, Med J Armed Forces India, V77, pS1, DOI 10.1016/j.mjafi.2021.01.021; Office of Educational Technology, 2023, Artificial intelligence and the future of teaching and learning; Open AI I, 2022, GPT-4: @OpenAI; Open AI I, 2023, Vision-Lear how to use GPT-4 to understand images; Sapci AH, 2020, JMIR MED EDUC, V6, DOI 10.2196/19285; Shafi S, 2023, DIAGN PATHOL, V18, DOI 10.1186/s13000-023-01375-z; Shokrollahi Y, 2023, Arxiv, DOI arXiv:2310.00795; Tolsgaard MG, 2023, MED TEACH, V45, P565, DOI 10.1080/0142159X.2023.2180340; Wang LKP, 2023, MED TEACH, V45, P925, DOI 10.1080/0142159X.2023.2198663; Wu WT, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.870777; Yanagita Y, 2023, JMIR FORM RES, V7, DOI 10.2196/48023	43	0	0	2	2	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0142-159X	1466-187X		MED TEACH	Med. Teach.	2024 APR 19	2024										10.1080/0142159X.2024.2342545	http://dx.doi.org/10.1080/0142159X.2024.2342545		APR 2024	8	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	OJ9Y7	38648547				2024-07-03	WOS:001207033300001
J	Akrout, M; Cirone, KD; Vender, R				Akrout, Mohamed; Cirone, Katrina D.; Vender, Ronald			Evaluation of Vision LLMs GTP-4V and LLaVA for the Recognition of Features Characteristic of Melanoma	JOURNAL OF CUTANEOUS MEDICINE AND SURGERY			English	Letter						multimodal large language models; melanoma features; ABCDE guidelines for melanoma; artificial intelligence			[Akrout, Mohamed] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Akrout, Mohamed] AIP Labs, Budapest, Hungary; [Cirone, Katrina D.] Western Univ, Schulich Sch Med & Dent, London, ON, Canada; [Vender, Ronald] McMaster Univ, Dept Med, Hamilton, ON, Canada; [Vender, Ronald] Dermatrials Res Inc, Hamilton, ON, Canada; [Vender, Ronald] Dermatrials Res Inc, 707-25 Charlton Ave East, Hamilton, ON L8N 1Y2, Canada	University of Toronto; Western University (University of Western Ontario); McMaster University	Vender, R (corresponding author), Dermatrials Res Inc, 707-25 Charlton Ave East, Hamilton, ON L8N 1Y2, Canada.	ron.vender@me.com		Cirone, Katrina/0000-0001-5439-228X				Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Haggenmüller S, 2021, EUR J CANCER, V156, P202, DOI 10.1016/j.ejca.2021.06.049; Klumpp M, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9080961; Liu H., 2023, ARXIV230408485; OpenAI, 2023, GTP 4V ISION SYSTEM	5	0	0	7	7	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1203-4754	1615-7109		J CUTAN MED SURG	J. Cutan. Med. Surg.	JAN	2024	28	1					98	99		10.1177/12034754231220934	http://dx.doi.org/10.1177/12034754231220934		JAN 2024	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	KH3K2	38174854				2024-07-03	WOS:001137051400001
J	Koohi-Moghadam, M; Bae, KT				Koohi-Moghadam, Mohamad; Bae, Kyongtae Ty			Generative AI in Medical Imaging: Applications, Challenges, and Ethics	JOURNAL OF MEDICAL SYSTEMS			English	Editorial Material						Generative artificial intelligence; Large language models; Medical imaging; Radiology; Synthetic medical data		Medical imaging is playing an important role in diagnosis and treatment of diseases. Generative artificial intelligence (AI) have shown great potential in enhancing medical imaging tasks such as data augmentation, image synthesis, image-to-image translation, and radiology report generation. This commentary aims to provide an overview of generative AI in medical imaging, discussing applications, challenges, and ethical considerations, while highlighting future research directions in this rapidly evolving field.	[Koohi-Moghadam, Mohamad; Bae, Kyongtae Ty] Univ Hong Kong, Li Ka Shing Fac Med, Dept Diagnost Radiol, Hong Kong, Peoples R China	University of Hong Kong	Koohi-Moghadam, M; Bae, KT (corresponding author), Univ Hong Kong, Li Ka Shing Fac Med, Dept Diagnost Radiol, Hong Kong, Peoples R China.	koohi@hku.hk; baekt@hku.hk						Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Alamir M, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527849; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Gao C, 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00629-1; Ghorbani A., 2020, Machine Learning for Health Workshop, P155; Gurney-Champion O. J., SEMIN RADIAT ONCOL, P377; Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z; Jung E, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109061; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Schwarz K, 2021, Advances in Neural Information Processing Systems, V34, P18126; Shabani S, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106033; Shad R, 2021, NAT MACH INTELL, V3, P929, DOI 10.1038/s42256-021-00399-8; Shneiderman B, 2021, COMMUN ACM, V64, P32, DOI 10.1145/3445973; Wang J., P IEEE CVF WINT C AP, P3627; Wang JB, 2023, NEUROCOMPUTING, V546, DOI 10.1016/j.neucom.2023.126282; Yang ZJ, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26703-z; Yu BT, 2019, IEEE T MED IMAGING, V38, P1750, DOI 10.1109/TMI.2019.2895894; Zhou Y, 2022, IEEE J BIOMED HEALTH, V26, P56, DOI 10.1109/JBHI.2020.3045475	20	5	5	76	118	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	AUG 31	2023	47	1							94	10.1007/s10916-023-01987-4	http://dx.doi.org/10.1007/s10916-023-01987-4			4	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	Q3LC1	37651022				2024-07-03	WOS:001056553500001
J	Kiuchi, K; Otsu, K; Hayashi, Y				Kiuchi, Keita; Otsu, Kouyou; Hayashi, Yugo			Psychological insights into the research and practice of embodied conversational agents, chatbots and social assistive robots: a systematic meta-review	BEHAVIOUR & INFORMATION TECHNOLOGY			English	Review; Early Access						Large language models; artificial intelligence; interactive robots; ethics; education; mental health	LONG-TERM-CARE; OLDER-ADULTS; ARTIFICIAL-INTELLIGENCE; SPECTRUM DISORDER; ELDERLY CARE; ACCEPTABILITY; DEMENTIA; PEOPLE; AUTISM; INTERVENTIONS	This study presents a systematic literature search and narrative meta-review of the current state of research on conversational agents (CAs), including embodied CAs, chatbots, and social assistive robots (SARs). The investigation identifies 1,830 academic articles, of which 315 articles satisfied the inclusion criteria for the review. Systematic reviews across various fields are reported, including mental disorders, neurodevelopmental disorders, dementia/cognitive impairment, other medical conditions, elderly support, health promotion, mental health, education, industrial applications, agent characteristics, and robot characteristics. The study highlights challenges in current CA research, such as the scarcity of high-quality comparative studies and the acceptance of CAs by users and caregivers, particularly in elderly support. The article also categorises ethical discussions into nine elements: privacy, safety, innovation, user acceptance, psychological attachment, care philosophy, evaluation, social systems compatibility, and rule development. It also offers insights into the development of future guidelines. The role of CAs in fostering human relationships through their conversational function is emphasised to provide guidance for subsequent CA research and social implementation. As advancements in CA technology and research continue to progress, there is an increasing demand for sophisticated psychological investigations addressing relationships, emotions, and the self.	[Kiuchi, Keita] Japan Org Occupat Hlth & Safety, Natl Inst Occupat Safety & Hlth, Kawasaki, Japan; [Otsu, Kouyou; Hayashi, Yugo] Ritsumeikan Univ, Ibaraki, Japan	Ritsumeikan University	Kiuchi, K (corresponding author), Japan Org Occupat Hlth & Safety, Natl Inst Occupat Safety & Hlth, Kawasaki, Japan.	kiuchi@h.jniosh.johas.go.jp		Kiuchi, Keita/0000-0003-0812-9071	Ritsumeikan Global Innovation Research Organization	Ritsumeikan Global Innovation Research Organization	No Statement Available	Aafjes-van Doorn K, 2021, PSYCHOTHER RES, V31, P92, DOI 10.1080/10503307.2020.1808729; Abbott R, 2019, INT J OLDER PEOPLE N, V14, DOI 10.1111/opn.12239; Abd-Alrazaq A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18301; Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828; Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021; Abdi J, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-018815; Abrantes C., 2023, Observatorio (OBS*), V17, P1, DOI [https://doi.org/10.15847/obsobs17220232263, DOI 10.15847/OBSOBS17220232263]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Agarwal R., 2020, SN Comput. Sci, V1, P246, DOI [10.1007/s42979-020-00255-3, DOI 10.1007/S42979-020-00255-3]; Agarwal S, 2022, LIBR HI TECH, V40, P1013, DOI 10.1108/LHT-09-2021-0330; Aggarwal A, 2023, J MED INTERNET RES, V25, DOI 10.2196/40789; Ahmed A., 2022, Computer Methods and Programs in Biomedicine Update, P100057, DOI [DOI 10.1016/J.CMPBUP.2022.100057, https://doi.org/10.1016/j.cmpbup.2022.100057]; Ahmed A, 2023, HEALTH INFORM J, V29, DOI 10.1177/14604582221146719; Aitsam M, 2022, IEEE ACCESS, V10, P122261, DOI 10.1109/ACCESS.2022.3219440; Alabdulkareem A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030944; Albites-Tapia A, 2022, INT J ADV COMPUT SC, V13, P991; Alhaidry H. M., 2023, Cureus, V15, P1, DOI [https://doi.org/10.7759/cureus.37285, DOI 10.7759/CUREUS.37285]; Almalki Manal, 2020, Acta Inform Med, V28, P241, DOI 10.5455/aim.2020.28.241-247; Alnajjar F, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00291; Alsheddi AS, 2022, INT J ADV COMPUT SC, V13, P662; Amiri P, 2022, J AM MED INFORM ASSN, V29, P1000, DOI 10.1093/jamia/ocac014; Amirova A, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.744526; Ao YT, 2022, EDUC RES INT, V2022, DOI 10.1155/2022/1958317; Aresti-Bartolome N, 2014, INT J ENV RES PUB HE, V11, P7767, DOI 10.3390/ijerph110807767; Armando M, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.862997; Arnold M, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2942288; Perez IA, 2021, ETIC NET, V21, P51, DOI 10.30827/eticanet.v21i1.18137; Arsenyan J, 2023, TECHNOL FORECAST SOC, V193, DOI 10.1016/j.techfore.2023.122644; Asgharian P, 2022, ROBOTICS, V11, DOI 10.3390/robotics11060127; Asimov I., 1950, I, Robot; Asl AM, 2022, J MED INTERNET RES, V24, DOI 10.2196/37434; Bakkouri Bouchra El, 2022, Procedia Computer Science, P432, DOI 10.1016/j.procs.2022.07.057; Balaji JN, 2022, J PERS MED, V12, DOI 10.3390/jpm12101599; Balan C, 2023, J THEOR APPL EL COMM, V18, P995, DOI 10.3390/jtaer18020051; Basteris A, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-111; Bavaresco R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100239; Bemelmans R, 2012, J AM MED DIR ASSOC, V13, P114, DOI 10.1016/j.jamda.2010.10.002; Bendig E., 2019, Verhaltenstherapie, DOI [DOI 10.1159/000501812, https://doi.org/10.1159/000501812]; Berdahl C, 2022, J MED INTERNET RES, V24, DOI 10.2196/36074; Bérubé C, 2021, J MED INTERNET RES, V23, DOI 10.2196/25933; Bevilacqua R, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17165930; Bibault JE, 2019, CLIN TRANSL RAD ONCO, V16, P55, DOI 10.1016/j.ctro.2019.04.002; Bibauw S, 2019, COMPUT ASSIST LANG L, V32, P827, DOI 10.1080/09588221.2018.1535508; Bilquise G, 2022, HUM BEHAV EMERG TECH, V2022, DOI 10.1155/2022/9601630; Bin Sawad A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072625; Blaurock M, 2022, J SERV MANAGE, V33, P27, DOI 10.1108/JOSM-09-2021-0345; Blaurock M, 2022, INT J CONSUM STUD, V46, P1877, DOI 10.1111/ijcs.12808; Bonaiuti G, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.1005669; Borboni A, 2023, MACHINES, V11, DOI 10.3390/machines11010111; Boumans R, 2022, JMIR AGING, V5, DOI 10.2196/32473; Buchanan Christine, 2021, JMIR Nurs, V4, pe23933, DOI 10.2196/23933; Budak KB, 2023, DISABIL REHABIL-ASSI, V18, P1107, DOI 10.1080/17483107.2021.1984594; Caballer A, 2022, CURR PSYCHOL, V41, P6225, DOI 10.1007/s12144-020-01117-0; Caldarini G, 2022, INFORMATION, V13, DOI 10.3390/info13010041; Cano S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155166; Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158; Cavallo F, 2018, J BIONIC ENG, V15, P185, DOI 10.1007/s42235-018-0015-y; Chard I, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.842460; Chattopadhyay D, 2020, J MED INTERNET RES, V22, DOI 10.2196/18839; Chaturvedi R, 2023, TECHNOL FORECAST SOC, V193, DOI 10.1016/j.techfore.2023.122634; Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510; Chen SC, 2018, J NURS SCHOLARSHIP, V50, P612, DOI 10.1111/jnu.12423; Chen YPP, 2016, COMPUT SPEECH LANG, V37, P98, DOI 10.1016/j.csl.2015.08.005; Chew HSJ, 2022, JMIR MED INF, V10, P4, DOI 10.2196/32578; Chew HSJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/32939; Cho E, 2023, INT J NURS STUD, V138, DOI 10.1016/j.ijnurstu.2022.104392; Chollet G, 2009, LECT NOTES ARTIF INT, V5398, P1; Choukou MA, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/40330; Chow J. C. L., 2021, Artificial Intelligence in Medicine, P1; Chow JCL, 2023, AI-BASEL, V4, P319, DOI 10.3390/ai4010015; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Chua JYX, 2023, J MIDWIFERY WOM HEAL, DOI 10.1111/jmwh.13472; Ciecierski-Holmes T, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00700-y; Cinquin PA, 2019, COMPUT EDUC, V130, P152, DOI 10.1016/j.compedu.2018.12.004; Coronado E, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031292; Coronado E, 2020, J COMPUT LANG, V58, DOI 10.1016/j.cola.2020.100970; Curtis RG, 2021, J MED INTERNET RES, V23, DOI 10.2196/31737; D'Alfonso S, 2020, CURR OPIN PSYCHOL, V36, P112, DOI 10.1016/j.copsyc.2020.04.005; Oliveira ABD, 2021, AUSTRALAS J INF SYST, V25, DOI 10.3127/ajis.v25i0.3223; Dada S, 2021, ASSIST TECHNOL, DOI 10.1080/10400435.2021.1992540; Dai C-P., 2022, Computers Education: Artificial Intelligence, V3, P100087, DOI DOI 10.1016/J.CAEAI.2022.100087; Damholdt MF, 2023, INT J SOC ROBOT, V15, P1203, DOI 10.1007/s12369-023-01014-z; David D, 2022, COMPUT HUM BEHAV, V137, DOI 10.1016/j.chb.2022.107419; Davis RO, 2021, J RES TECHNOL EDUC, V53, P89, DOI 10.1080/15391523.2020.1830894; Dawe J, 2019, BMJ PAEDIATR OPEN, V3, DOI 10.1136/bmjpo-2018-000371; de Araujo BS, 2022, LIBR HI TECH, V40, P1108, DOI 10.1108/LHT-09-2020-0244; de Filippis M. L., 2020, Springer-Verlag, DOI [https://doi.org/10.1007/978-3-030-58796-3_30, DOI 10.1007/978-3-030-58796-3_30]; de Jong C, 2019, INTERACT STUD, V20, P393, DOI 10.1075/is.18071.jon; De Keyser A, 2022, J SERV MANAGE, V33, P165, DOI 10.1108/JOSM-12-2021-0488; de Wit J, 2023, ACM T HUM-ROBOT INTE, V12, DOI 10.1145/3549530; Denecke K, 2023, J MED INTERNET RES, V25, DOI 10.2196/41583; Denecke Kerstin, 2022, Stud Health Technol Inform, V294, P169, DOI 10.3233/SHTI220431; Denecke K, 2022, J MED INTERNET RES, V24, DOI 10.2196/27791; Deng XJ, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15042940; Di Dio C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00469; Dunham M, 2021, GERIATRICS-BASEL, V6, DOI 10.3390/geriatrics6020040; Eiris R, 2017, J INF TECHNOL CONSTR, V22, P168; El Kamali M, 2020, IEEE ACCESS, V8, P101884, DOI 10.1109/ACCESS.2020.2996404; Ess C., 2008, The Blackwell Guide to the Philosophy of Computing and Information, P76; Esterwood C, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.748246; Even C, 2022, Z GERONTOL GERIATR, V55, P381, DOI 10.1007/s00391-022-02085-9; Fardeau E, 2023, INT J SOC ROBOT, V15, P1025, DOI 10.1007/s12369-023-00980-8; Federici S, 2020, DISABIL REHABIL-ASSI, V15, P832, DOI 10.1080/17483107.2020.1775313; Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009; Felding SA, 2023, INT J SOC ROBOT, V15, P1115, DOI 10.1007/s12369-023-01012-1; Felnhofer A, 2023, INT J HUM-COMPUT INT, DOI 10.1080/10447318.2023.2209979; Urquiza-Yllescas JF, 2022, J INTELL FUZZY SYST, V43, P5095, DOI 10.3233/JIFS-213275; Filippini C, 2023, INT J SOC ROBOT, V15, P393, DOI 10.1007/s12369-023-00985-3; Frennert S, 2014, INT J SOC ROBOT, V6, P299, DOI 10.1007/s12369-013-0225-8; Gabarrona E, 2020, STUD HEALTH TECHNOL, V270, P796, DOI 10.3233/SHTI200270; Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166; Gasteiger N, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/17298814211066740; Gasteiger N, 2021, CLIN INTERV AGING, V16, P941, DOI 10.2147/CIA.S282709; Geoghegan L, 2021, BJS OPEN, V5, DOI 10.1093/bjsopen/zrab070; Ghafurian M, 2021, ACM T HUM-ROBOT INTE, V10, DOI 10.1145/3469653; GHANI JA, 1994, J PSYCHOL, V128, P381, DOI 10.1080/00223980.1994.9712742; Giansanti D, 2023, LIFE-BASEL, V13, DOI 10.3390/life13051130; Gibelli F, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/1478025; Alonso SG, 2019, TELEMED E-HEALTH, V25, P533, DOI 10.1089/tmj.2018.0051; González-González CS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135976; González-González CS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010216; Gooding P, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/24668; Gopinath K, 2023, INT J CONSUM STUD, V47, P2367, DOI 10.1111/ijcs.12933; Grodniewicz JP, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1190084; Gual-Montolio P, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19137737; Guemghar I, 2022, JMIR MENT HEALTH, V9, DOI 10.2196/36094; Han R, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/43227; HARRIS WG, 1987, APPL PSYCHOL-INT REV, V36, P237, DOI 10.1111/j.1464-0597.1987.tb01189.x; Hatfield HR, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmac016; Haubold AK, 2020, GIO-GRUP-INTERAKT-OR, V51, P259, DOI 10.1007/s11612-020-00523-z; Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806; He Y, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6334732; He YH, 2023, J MED INTERNET RES, V25, DOI 10.2196/43862; Hennessy S, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100080; Hirt J, 2021, J ALZHEIMERS DIS, V79, P773, DOI 10.3233/JAD-200347; Hocking J, 2023, JBI EVID SYNTH, V21, P326, DOI 10.11124/JBIES-22-00025; Hoel V, 2021, BMC GERIATR, V21, DOI 10.1186/s12877-021-02105-0; Hoermann S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7023; Hsieh CJ, 2023, GERONTOLOGY, V69, P1027, DOI 10.1159/000529849; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Huang WJ, 2022, J COMPUT ASSIST LEAR, V38, P237, DOI 10.1111/jcal.12610; Hung LL, 2019, BMC GERIATR, V19, DOI 10.1186/s12877-019-1244-6; Huq SM, 2024, DISABIL REHABIL-ASSI, V19, P1059, DOI 10.1080/17483107.2022.2146768; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Islam MA, 2023, J INTELL ROBOT SYST, V108, DOI 10.1007/s10846-023-01872-9; Jabir AI, 2023, J MED INTERNET RES, V25, DOI 10.2196/44548; Japanese Council for Social Principles of Human-centric AI, 2019, Social Principles of Human-Centric AI; Jenneboer L, 2022, J THEOR APPL EL COMM, V17, P212, DOI 10.3390/jtaer17010011; Jeon J, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2204343; Jones C, 2020, GERIATR NURS, V41, P863, DOI 10.1016/j.gerinurse.2020.06.001; Jouaiti M, 2019, INT J SOC ROBOT, V11, P753, DOI 10.1007/s12369-019-00598-9; Jung M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041388; Kabacinska K, 2021, INT J SOC ROBOT, V13, P919, DOI 10.1007/s12369-020-00679-0; Kachaturoff M, 2021, J GERONTOL NURS, V47, P49, DOI 10.3928/00989134-20210803-05; Kachouie R, 2014, INT J HUM-COMPUT INT, V30, P369, DOI 10.1080/10447318.2013.873278; Kalyanathaya K. P., 2019, Int. J. Recent Technol. Eng., V7, P199; Kambur E, 2023, INT J MANPOWER, V44, P422, DOI 10.1108/IJM-10-2021-0622; Kang HS, 2020, GERIATR NURS, V41, P207, DOI 10.1016/j.gerinurse.2019.09.003; Kavaz E, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13127025; Kelly S, 2023, TELEMAT INFORM, V77, DOI 10.1016/j.tele.2022.101925; Kennedy CM, 2012, J MED INTERNET RES, V14, P116, DOI 10.2196/jmir.1893; Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018; Klímová B, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1131506; Klimova B, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11010042; Kocaballi AB, 2019, J MED INTERNET RES, V21, DOI 10.2196/15360; Koh WQ, 2021, BMC GERIATR, V21, DOI 10.1186/s12877-021-02277-9; Koh Wei Qi, 2021, JMIR Rehabil Assist Technol, V8, pe25340, DOI 10.2196/25340; Kouroupa A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269800; Kovacek David, 2021, Nano Express, DOI 10.1088/2633-1357/ac1f88; Kramer LL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14058; Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083; Kruse CS, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8030278; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Kulpa E, 2021, INT REV PSYCHIATR, V33, P424, DOI 10.1080/09540261.2020.1839391; Lajante M, 2023, SERV BUS, V17, P315, DOI 10.1007/s11628-023-00525-z; Lambert A, 2020, INT J HUM-COMPUT INT, V36, P1804, DOI 10.1080/10447318.2020.1801172; Landim ARDB, 2022, INT J FASH DES TECHN, V15, P200, DOI 10.1080/17543266.2021.1990417; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Latikka R, 2021, J MED INTERNET RES, V23, DOI 10.2196/28022; Lee Hocheol, 2022, JMIR Aging, V5, pe38896, DOI 10.2196/38896; Lee SE, 2023, TECHNOL FORECAST SOC, V194, DOI 10.1016/j.techfore.2023.122722; Lee SC, 2022, INT J HUM-COMPUT ST, V165, DOI 10.1016/j.ijhcs.2022.102864; Lew ZJ, 2023, MEDIA PSYCHOL, V26, P1, DOI 10.1080/15213269.2022.2084111; Lewis TT, 2021, J PEDIATR NURS, V58, DOI 10.1016/j.pedn.2020.10.016; Li Y, 2023, INT J NURS STUD, V143, DOI 10.1016/j.ijnurstu.2023.104494; Liew TW, 2021, TELEMAT INFORM, V65, DOI 10.1016/j.tele.2021.101721; Lillywhite B, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15010387; Lim SM, 2022, BEHAV THER, V53, P334, DOI 10.1016/j.beth.2021.09.007; Lim WM, 2022, PSYCHOL MARKET, V39, P1129, DOI 10.1002/mar.21654; Lin CC, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15054012; Lin YP, 2024, INTERACT TECHNOL SMA, V21, P189, DOI 10.1108/ITSE-12-2022-0165; Ling EC, 2021, PSYCHOL MARKET, V38, P1031, DOI 10.1002/mar.21491; Littler BKM, 2021, ARCH DIS CHILD, V106, P1095, DOI 10.1136/archdischild-2020-320721; Liu BS, 2022, INT J SOC ROBOT, V14, P1339, DOI 10.1007/s12369-022-00870-5; Lo CK, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1175715; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lokman A. S., 2018, P FUTURE TECHNOLOGIE; Lorenzo G, 2021, EDUC INF TECHNOL, V26, P4111, DOI 10.1007/s10639-021-10464-9; Loveys K, 2022, LANCET HEALTH LONGEV, V3, pE286, DOI 10.1016/S2666-7568(22)00034-4; Loveys K, 2020, INT J SOC ROBOT, V12, P1293, DOI 10.1007/s12369-020-00680-7; Lu LC, 2021, INNOV AGING, V5, DOI 10.1093/geroni/igab013; Lundgren AVA, 2022, AI-BASEL, V3, P229, DOI 10.3390/ai3010014; Luo TC, 2021, J MED INTERNET RES, V23, DOI 10.2196/25486; Lutz C, 2019, MOB MEDIA COMMUN, V7, P412, DOI 10.1177/2050157919843961; Lyzwinski LN, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/39649; MacHale R, 2023, J APPL RES INTELLECT, V36, P448, DOI 10.1111/jar.13082; Maddalon L, 2023, MEDICINA-BUENOS AIRE, V83, P48; Makasi T., 2020, First Monday, V25, P1; Malik NA, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/64163; Mancioppi G, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00058; Mariani MM, 2023, J BUS RES, V161, DOI 10.1016/j.jbusres.2023.113838; Mariciuc D. F., 2022, Journal of Public Administration, Finance Law, V26, P206, DOI [https://doi.org/10.47743/jopafl-2022-26-18, DOI 10.47743/JOPAFL-2022-26-18]; Maroto-Gómez M, 2023, INT J SOC ROBOT, V15, P745, DOI 10.1007/s12369-023-00977-3; Martha A.S. D., 2019, Journal of Educators Online, V16, pn1, DOI DOI 10.9743/JEO.2019.16.1.8; Martin NM, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031328; Martinengo L, 2022, J MED INTERNET RES, V24, DOI 10.2196/39243; Martínez-Miranda J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0784-6; Martinez-Roig R, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1164506; May R, 2022, INFORM HEALTH SOC CA, V47, P194, DOI 10.1080/17538157.2021.1983578; Mbunge Elliot, 2022, Glob Health J, V6, P102, DOI 10.1016/j.glohj.2022.03.001; McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724; McGuire M, 2021, ECLINICALMEDICINE, V39, DOI 10.1016/j.eclinm.2021.101059; Mejbri N, 2022, EDUC INF TECHNOL, V27, P3867, DOI 10.1007/s10639-021-10769-9; Mikkonen K, 2023, J CLIN NURS, V32, P3295, DOI 10.1111/jocn.16448; Miklosik A, 2021, IEEE ACCESS, V9, P106530, DOI 10.1109/ACCESS.2021.3100885; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Mirbabaie M, 2021, ELECTRON MARK, V31, P365, DOI 10.1007/s12525-021-00457-4; Misischia C. V., 2022, Procedia Computer Science, V201, P421, DOI [10.1016/J.PROCS.2022.03.055, DOI 10.1016/J.PROCS.2022.03.055]; Moerman CJ, 2019, J CHILD HEALTH CARE, V23, P596, DOI 10.1177/1367493518803031; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Mou Y, 2020, INT J HUM-COMPUT INT, V36, P591, DOI 10.1080/10447318.2019.1663008; Moyle W, 2017, INT PSYCHOGERIATR, V29, P1951, DOI 10.1017/S1041610217001776; Naneva S, 2020, INT J SOC ROBOT, V12, P1179, DOI 10.1007/s12369-020-00659-4; Neumann MM, 2020, EARLY CHILD EDUC J, V48, P157, DOI 10.1007/s10643-019-00997-7; Nicolescu L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101579; Nizhenkovska I. V., 2022, International Journal of Educational Methodology, V8, P769; Noh E, 2023, J MED INTERNET RES, V25, DOI 10.2196/42238; Ogilvie L, 2022, EUR ADDICT RES, V28, P405, DOI 10.1159/000525959; Oh YJ, 2021, INT J BEHAV NUTR PHY, V18, DOI 10.1186/s12966-021-01224-6; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Oliveira R, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106547; Omarov B, 2023, CMC-COMPUT MATER CON, V74, P5105, DOI 10.32604/cmc.2023.034655; Orpin J, 2023, J CHILD HEALTH CARE, DOI 10.1177/13674935231184919; Oruma SO, 2022, COMPUTERS, V11, DOI 10.3390/computers11120181; Ouzzani M, 2016, SYST REV-LONDON, V5, DOI 10.1186/s13643-016-0384-4; Pacheco-Lorenzo MR, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103632; Page MJ, 2021, INT J SURG, V88, DOI [10.1186/s13643-021-01626-4, 10.1016/j.jclinepi.2021.02.003, 10.1016/j.ijsu.2021.105906]; Pallavicini F, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/35000; Papadopoulos I, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103924; Papakostas GA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121398; Boada JP, 2021, TECHNOL SOC, V67, DOI 10.1016/j.techsoc.2021.101726; Park S, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031889; Pashevich E, 2022, AI SOC, V37, P579, DOI 10.1007/s00146-021-01214-z; Pennisi P, 2016, AUTISM RES, V9, P165, DOI 10.1002/aur.1527; Pentina I, 2023, PSYCHOL MARKET, V40, P1593, DOI 10.1002/mar.21853; Pereira J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1237-1; Pérez JQ, 2020, COMPUT APPL ENG EDUC, V28, P1549, DOI 10.1002/cae.22326; Pernencar C, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.862432; Phiri M, 2023, J MED INTERNET RES, V25, DOI 10.2196/35573; Pillarisetty R, 2022, INT J E-BUS RES, V18, DOI 10.4018/IJEBR.294111; Pirker J, 2021, IEEE COMPUT GRAPH, V41, P76, DOI 10.1109/MCG.2021.3067999; Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553; Pu LH, 2019, GERONTOLOGIST, V59, pE37, DOI 10.1093/geront/gny046; Pusey M, 2022, INTERACT LEARN ENVIR, V30, P1940, DOI 10.1080/10494820.2020.1772837; Ramesh A, 2022, J INTERACT MARK, V57, P472, DOI 10.1177/10949968221095549; Rampioni M, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/25381; Rapp A, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102630; Rheu M, 2021, INT J HUM-COMPUT INT, V37, P81, DOI 10.1080/10447318.2020.1807710; Ringwald M, 2023, J INTELL ROBOT SYST, V107, DOI 10.1007/s10846-022-01781-3; Robinson NL, 2019, J MED INTERNET RES, V21, DOI 10.2196/13203; Romero M, 2020, PAPEL PSICOL, V41, P27, DOI 10.23923/pap.psicol2020.2920; Russo A, 2019, REJUV RES, V22, P109, DOI 10.1089/rej.2018.2075; Sadasivan Chikku, 2023, J Particip Med, V15, pe45772, DOI 10.2196/45772; Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127; Saleh MA, 2021, DISABIL REHABIL-ASSI, V16, P580, DOI 10.1080/17483107.2019.1685016; Salimi Z, 2021, NEUROSCI BIOBEHAV R, V129, P1, DOI 10.1016/j.neubiorev.2021.04.009; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salvemini Arianna, 2019, Med Sci (Basel), V7, DOI 10.3390/medsci7060070; Sani-Bozkurt S, 2023, INT J DISABIL DEV ED, V70, P625, DOI 10.1080/1034912X.2021.1905153; Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701; Scholten MR, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7351; Scholten TS, 2016, INT J SOC ROBOT, V8, P499, DOI 10.1007/s12369-016-0367-6; Scoglio AAJ, 2019, J MED INTERNET RES, V21, DOI 10.2196/13322; Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141; Shah S, 2023, PATTERN ANAL APPL, V26, P823, DOI 10.1007/s10044-023-01182-8; Shan Y, 2022, J MED INTERNET RES, V24, DOI 10.2196/37403; Shan Y, 2022, INTERACT J MED RES, V11, DOI 10.2196/38249; Shawar B. A., 2007, Ldv forum, V22, P29; Sheridan TB, 2016, HUM FACTORS, V58, P525, DOI 10.1177/0018720816644364; Shetty A, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.850601; Shin JY, 2020, CURR OPIN SUPPORT PA, V14, P60, DOI 10.1097/SPC.0000000000000481; Shourmasti ES, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155052; Siddique S., 2021, Encyclopedia, V1, P220, DOI DOI 10.3390/ENCYCLOPEDIA1010021; Silva AD, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113193; Silveira Raquel, 2023, Procedia Comput Sci, V219, P1271, DOI 10.1016/j.procs.2023.01.411; Singh B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00856-1; Song Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185087; Silva GRS, 2024, INT J HUM-COMPUT INT, V40, P98, DOI 10.1080/10447318.2022.2118244; Stara V, 2020, J MED INTERNET RES, V22, DOI 10.2196/17809; Store SJ, 2022, J CLIN SLEEP MED, V18, P1877, DOI 10.5664/jcsm.10022; Su ZH, 2022, J MED INTERNET RES, V24, DOI 10.2196/30503; Suhaili SM, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115461; Sylaiou S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199913; Syriopoulou-Delli CK, 2022, INT J DEV DISABIL, V68, P73, DOI 10.1080/20473869.2019.1706333; Syvänen S, 2020, J COMMUN MANAG, V24, P339, DOI 10.1108/JCOM-11-2019-0145; Tamburella F, 2022, J NEUROENG REHABIL, V19, DOI 10.1186/s12984-022-01003-9; Tavernise A., 2016, Journal of Education Research, V10, P163; ter Stal S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102409; Thieme A, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3398069; Toh G, 2022, BMC PSYCHIATRY, V22, DOI 10.1186/s12888-022-03889-0; Triantafyllidis A., 2023, COMPUTER METHODS PRO, V3, P100108, DOI [https://doi.org/10.1016/j.cmpbup.2023.100108, DOI 10.1016/J.CMPBUP.2023.100108]; Trost MJ, 2019, CLIN J PAIN, V35, P451, DOI 10.1097/AJP.0000000000000688; Tsiouris KM, 2020, FRONT DIGIT HEALTH, V2, DOI 10.3389/fdgth.2020.567502; Tubin C, 2022, BEHAV INFORM TECHNOL, V41, P3519, DOI 10.1080/0144929X.2021.2001047; Vaidyam AN, 2021, CAN J PSYCHIAT, V66, P339, DOI 10.1177/0706743720966429; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Valencia K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204485; van den Berghe R, 2022, FRONT ROBOT AI, V9, DOI 10.3389/frobt.2022.958624; van den Berghe R, 2019, REV EDUC RES, V89, P259, DOI 10.3102/0034654318821286; Van Pinxteren MME, 2020, J SERV MANAGE, V31, P203, DOI 10.1108/JOSM-06-2019-0175; van Straten CL, 2020, INT J SOC ROBOT, V12, P325, DOI 10.1007/s12369-019-00569-0; Vandemeulebroucke T, 2021, ARCH GERONTOL GERIAT, V95, DOI 10.1016/j.archger.2021.104399; Vandemeulebroucke T, 2018, AGING MENT HEALTH, V22, P149, DOI 10.1080/13607863.2017.1286455; Wang A, 2023, INT J GEN MED, V16, P1591, DOI 10.2147/IJGM.S408208; Wang I, 2021, INT J HUM-COMPUT INT, V37, P1648, DOI 10.1080/10447318.2021.1898851; Wang J., 2021, Comput. Educ. Artif. Intell, V2, P100023, DOI DOI 10.1016/J.CAEAI.2021.100023; Wang YY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5120084; Whelan S, 2018, INT J SOC ROBOT, V10, P643, DOI 10.1007/s12369-018-0471-x; White BK, 2022, J MED INTERNET RES, V24, DOI 10.2196/35903; Whittaker R, 2022, J MED INTERNET RES, V24, DOI 10.2196/35556; Wilson L, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/35882; Winkler A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231174484; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Woo H, 2021, EDUC RES REV-NETH, V33, DOI 10.1016/j.edurev.2021.100388; Wright KB, 2003, J HEALTH PSYCHOL, V8, P39, DOI 10.1177/1359105303008001429; Wu R, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13334; Xia SL, 2024, HEALTH COMMUN, V39, P1455, DOI 10.1080/10410236.2023.2218145; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yan RM, 2023, EDUC INFORM, V39, P431, DOI 10.3233/EFI-230045; Yang J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116355; Yu CR, 2022, AGEING RES REV, V78, DOI 10.1016/j.arr.2022.101633; Yuan FP, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.605715; Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054; Zhai CP, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e12056; Zhan ZH, 2024, INTERACT LEARN ENVIR, V32, P1137, DOI 10.1080/10494820.2022.2115077; Zhang JW, 2020, J MED INTERNET RES, V22, DOI 10.2196/22845; Zhang M, 2020, J MED INTERNET RES, V22, DOI 10.2196/19706; Zhang RF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2202704; Zhou XY, 2021, J TELEMED TELECARE, V27, P638, DOI 10.1177/1357633X211047285	350	3	3	37	53	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0144-929X	1362-3001		BEHAV INFORM TECHNOL	Behav. Inf. Technol.	2023 NOV 25	2023										10.1080/0144929X.2023.2286528	http://dx.doi.org/10.1080/0144929X.2023.2286528		NOV 2023	41	Computer Science, Cybernetics; Ergonomics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AK5G6		hybrid			2024-07-03	WOS:001118367200001
C	Wang, WJ; Liu, Y; Zhang, Y; Liu, WW; Feng, FL; He, XN; Sun, A			ACM	Wang, Wenjie; Liu, Yong; Zhang, Yang; Liu, Weiwen; Feng, Fuli; He, Xiangnan; Sun, Aixin			The 1st Workshop on Recommendation with Generative Models https://rgm-cikm23.github.io	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Generative Models for Recommendation; Large Language Models; Trustworthiness Checks and Evaluation		The boom of generative models has paved the way for significant advances in recommender systems. For instance, pre-trained generative models offer unprecedented opportunities to improve recommender algorithms for user modeling. This workshop aims to provide a platform for researchers to actively explore and share innovative ideas on integrating generative models into recommender systems, mainly focusing on five key aspects: (i) enhancing recommender algorithms, (ii) generating personalized content in some scenarios such as micro-videos, (iii) changes in the user-system interaction paradigm, (iv) boosting trustworthiness checks, and (v) evaluation methodologies of generative recommendation. With the rapid development of generative models, a growing number of studies along the above directions are emerging, revealing the timeliness and necessity of this workshop. The related research will bring novel features to recommender systems and contribute to new tasks and technologies in both academia and industry. In the long run, this research direction might revolutionize the traditional recommender paradigm and lead to the maturation of next-generation recommender systems.	[Wang, Wenjie] Natl Univ Singapore, Singapore, Singapore; [Liu, Yong; Liu, Weiwen] Huawei Noahs Ark Lab, Singapore, Singapore; [Zhang, Yang; Feng, Fuli; He, Xiangnan] Univ Sci & Technol China, Hefei, Peoples R China; [Sun, Aixin] Nanyang Technol Univ, Singapore, Singapore	National University of Singapore; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Nanyang Technological University	Wang, WJ (corresponding author), Natl Univ Singapore, Singapore, Singapore.	wangwenjie@u.nus.edu; liu.yong6@huawei.com; zy2015@mail.ustc.edu.cn; liuweiwen8@huawei.com; fulifeng93@gmail.com; xiangnanhe@gmail.com; axsun@ntu.edu.sg	Yang, Zhang/JWP-0075-2024; He, Xiangnan/G-3986-2011; Sun, Aixin/A-9852-2008	He, Xiangnan/0000-0003-2838-861X; Sun, Aixin/0000-0003-0764-4258				Bao Keqin, 2023, RecSys; Cui Zeyu, 2022, ARXIV220508084; Deffayet Romain, 2023, 16 INT C WEB SEARCH, P580, DOI DOI 10.1145/3539597.3570412; Gao Yunfan, 2023, ARXIV230314524; Li Jinming, 2023, ARXIV230403879; Liao Lizi, 2023, 16 INT C WEB SEARCH; Liu Junling, 2023, ARXIV230410149; Sun Aixin, 2023, SIGIR; Tang Zhiwen, 2021, P JOINT C 59 ANN M A; Wang Lei, 2023, ARXIV230403153; Wang Wenjie, 2023, ARXIV230403516; Zhang Jizhi, 2023, RecSys; Zhang Y., 2021, NEURIPS 2021 WORKSH	13	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5300	5303		10.1145/3583780.3615304	http://dx.doi.org/10.1145/3583780.3615304			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		hybrid			2024-07-03	WOS:001161549505076
C	Jin, XS; Zhang, DJ; Zhu, HH; Xiao, W; Li, SW; Wei, XK; Arnold, A; Ren, X			Assoc Computat Linguist	Jin, Xisen; Zhang, Dejiao; Zhu, Henghui; Xiao, Wei; Li, Shang-Wen; Wei, Xiaokai; Arnold, Andrew; Ren, Xiang			<i>Lifelong Pretraining</i>: Continually Adapting Language Models to Emerging Corpora	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				Pretrained language models (PTLMs) are typically learned over a large, static corpus and further fine-tuned for various downstream tasks. However, when deployed in the real world, a PTLM-based model must deal with data distributions that deviate from what the PTLM was initially trained on. In this paper, we study a lifelong language model pretraining challenge where a PTLM is continually updated so as to adapt to emerging data. Over a domain-incremental research paper stream and a chronologically-ordered tweet stream, we incrementally pretrain a PTLM with different continual learning algorithms, and keep track of the downstream task performance (after fine-tuning). We evaluate PTLM's ability to adapt to new corpora while retaining learned knowledge in earlier corpora. Our experiments show distillation-based approaches to be most effective in retaining downstream performance in earlier domains. The algorithms also improve knowledge transfer, allowing models to achieve better downstream performance over the latest data, and improve temporal generalization when distribution gaps exist between training and evaluation because of time. We believe our problem formulation, methods, and analysis will inspire future studies towards continual pretraining of language models.	[Jin, Xisen; Ren, Xiang] Univ Southern Calif, Los Angeles, CA 90007 USA; [Zhang, Dejiao; Zhu, Henghui; Xiao, Wei; Li, Shang-Wen; Wei, Xiaokai; Arnold, Andrew] AWS AI Labs, Cambridge, MA USA	University of Southern California	Jin, XS (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	xisenjin@usc.edu; dejiaoz@amazon.com; henghui@amazon.com; weixiaow@amazon.com; shangwenl@amazon.com; xiaokaiw@amazon.com; anarnld@amazon.com; xiangren@usc.edu	, lantong/AAR-7206-2020; ren, xiang/HLQ-5068-2023					Angeliki Lazaridou A, 2021, ADV NEURAL INFORM PR; Arumae K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4854; Augenstein I., 2017, Proceedings of the 11th International Workshop on Semantic Evaluation, P546, DOI [10.18653/v1/S17-2091, DOI 10.18653/V1/S17-2091]; Barbieri Francesco, 2018, P 12 INT WORKSH SEM, P24; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cha HYT, 2021, Arxiv, DOI arXiv:2106.14413; Chaudhry A., 2019, arXiv; Chuang YS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2914; d'Autume CD, 2019, ADV NEUR IN, V32; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Dernoncourt F., 2017, Short Papers, V2, P308; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhingra Bhuwan, 2021, arXiv; Fang ZY, 2021, Arxiv, DOI arXiv:2101.04731; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Gong Yuyun, 2016, IJCAI, P2782, DOI DOI 10.5555/3060832.3061010; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Gururangan Suchin, 2021, arXiv; Azeemi AH, 2021, Arxiv, DOI arXiv:2103.00199; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hombaiah Spurthi Amba, 2021, P 27 ACM SIGKDD C KN; Hou SH, 2018, LECT NOTES COMPUT SC, V11207, P452, DOI 10.1007/978-3-030-01219-9_27; Houlsby N, 2019, PR MACH LEARN RES, V97; Huang XL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P694; Huang YF, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2736; Jang J, 2022, Arxiv, DOI arXiv:2110.03215; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Jurgens D., 2018, T ASSOC COMPUT LING, V6, P391, DOI DOI 10.1162/TACL_A_00028; Kanwatchara K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2942; Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081; Liu TL, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3274; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lo Kyle., 2020, P 58 ANN M ASS COMPU, P4969; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Luu Kelvin, 2021, TIME WAITS NO ONE AN; Maronikolakis Antonis, 2021, Proceedings of the Second Workshop on Domain Adaptation for NLP, P1; Matena Michael, 2021, arXiv; Muller M., 2020, arXiv, DOI DOI 10.3389/FRAI.2023.1023281; Mysore S, 2019, 13TH LINGUISTIC ANNOTATION WORKSHOP (LAW XIII), P56; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Pfeiffer Jonas, 2021, P 16 C EUROPEAN CHAP, P487; Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587; Rijhwani Shruti, 2020, P 58 ANN M ASS COMPU, P7605; Robins A., 1995, Connection Science, V7, P123, DOI 10.1080/09540099550039318; Rottger Paul, 2021, FINDINGS EMNLP; Schwarz J, 2018, PR MACH LEARN RES, V80; Shi YY, 2015, COMPUT SPEECH LANG, V33, P136, DOI 10.1016/j.csl.2014.11.004; Sun F.-Y., 2020, INT C LEARN REPR; Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4323; Vindahl Jens, 2016, CHEMPROT 3 0 GLOBAL; Wang H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P796; Wang ZR, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P535; Xu Benfeng, 2020, P 58 ANN M ASS COMPU, DOI DOI 10.18653/V1/2020.ACL-MAIN.542; Yao YZ, JOINT C 59 ANN M ASS	55	4	4	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							1	16						16	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900001
J	Kim, JK; Chua, M; Rickard, M; Lorenzo, A				Kim, Jin K.; Chua, Michael; Rickard, Mandy; Lorenzo, Armando			Response to letter to the Editor re ChatGPT and large language model (LLM) chatbots: The current state of acceptability and a proposal for guidelines on utilization in academic medicine	JOURNAL OF PEDIATRIC UROLOGY			English	Letter									[Kim, Jin K.; Chua, Michael; Rickard, Mandy; Lorenzo, Armando] Hosp Sick Children, Dept Surg, Div Urol, Toronto, ON, Canada; [Kim, Jin K.; Lorenzo, Armando] Univ Toronto, Dept Surg, Div Urol, Toronto, ON, Canada; [Chua, Michael] St Lukes Med Ctr, Inst Urol, Quezon City, Philippines	University of Toronto; Hospital for Sick Children (SickKids); University of Toronto; Saint Lukes Medical Center - Philippines	Kim, JK (corresponding author), Hosp Sick Children, Dept Surg, Div Urol, Toronto, ON, Canada.	jjk.kim@mail.utoronto.ca						Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018	1	2	2	6	10	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1477-5131	1873-4898		J PEDIATR UROL	J. Pediatr. Urol	OCT	2023	19	5					607	607		10.1016/j.jpurol.2023.05.018	http://dx.doi.org/10.1016/j.jpurol.2023.05.018		SEP 2023	1	Pediatrics; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics; Urology & Nephrology	U4QU1	37487885				2024-07-03	WOS:001084669900001
J	Zeng, ZR; He, JL; Xiang, T; Wang, N; Chen, BW; Guo, SW				Zeng, Zhirui; He, Jialing; Xiang, Tao; Wang, Ning; Chen, Biwen; Guo, Shangwei			Cognitive Tracing Data Trails: Auditing Data Provenance in Discriminative Language Models Using Accumulated Discrepancy Score	COGNITIVE COMPUTATION			English	Article; Early Access						Data augmentation; Security and privacy; Discriminative models; Large language models	MEMBERSHIP INFERENCE ATTACKS	The burgeoning practice of unauthorized acquisition and utilization of personal textual data (e.g., social media comments and search histories) by certain entities has become a discernible trend. To uphold data protection regulations such as the Asia-Pacific Privacy Initiative (APPI) and to identify instances of unpermitted exploitation of personal data, we propose a novel and efficient audit framework that helps users conduct cognitive analysis to determine if their textual data was used for data augmentation. and training a discriminative model. In particular, we focus on auditing models that use BERT as the backbone for discriminating text and are at the core of popular online services. We first propose an accumulated discrepancy score, which involves not only the response of the target model to the auditing sample but also the responses between pre-trained and finetuned models, to identify membership. We implement two types of audit methods (i.e., sample-level and user-level) according to our framework and conduct comprehensive experiments on two downstream applications to evaluate the performance. The experimental results demonstrate that our sample-level auditing achieves an AUC of 89.7% and an accuracy of 83%, whereas the user-level method can audit membership with an AUC of 89.7% and an accuracy of 88%. Additionally, we undertake an analysis of how augmentation methods impact auditing performance and expound upon the underlying reasons for these observations.	[Zeng, Zhirui; He, Jialing; Xiang, Tao; Wang, Ning; Chen, Biwen; Guo, Shangwei] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China	Chongqing University	He, JL (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.	hejialing@cqu.edu.cn			National Natural Science Foundation of China [62102052, U21A20463, 62302071]; Natural Science Foundation of Chongqing, China [cstc2021jcyj-msxmX0744, CSTB2023NSCQ-MSX0693]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Chongqing, China(Natural Science Foundation of Chongqing)	This work was supported in part by the National Natural Science Foundation of China under Grants 62102052, U21A20463, and 62302071 and the Natural Science Foundation of Chongqing, China, under Grants cstc2021jcyj-msxmX0744 and CSTB2023NSCQ-MSX0693.	Adler P, 2018, KNOWL INF SYST, V54, P95, DOI 10.1007/s10115-017-1116-3; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai HY, 2020, Arxiv, DOI arXiv:2004.02594; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6314; Chen JA, 2020, Arxiv, DOI arXiv:2004.10972; Chen JA, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4380; Cheng Y, 2019, Arxiv, DOI arXiv:1906.02443; Debenedetti E, 2023, Arxiv, DOI arXiv:2309.05610; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Guo S., 2022, PREPRINT; He JL, 2019, IEEE ACCESS, V7, P6226, DOI 10.1109/ACCESS.2018.2889296; He JX, 2020, Arxiv, DOI [arXiv:1909.13788, DOI 10.48550/ARXIV.1909.13788]; Hedderich MA, 2021, Arxiv, DOI arXiv:2010.12309; Hisamoto S, 2020, T ASSOC COMPUT LING, V8, P49, DOI 10.1162/tacl_a_00299; Jagielski M, 2024, Advances in Neural Information Processing Systems, V36; Johnson M., 2017, Google's multilingual neural machine translation system: Enabling zero-shot translation, V5, P339, DOI 10.1162/tacla00065; Joyce JM, 2011, International Encyclopedia of Statistical Science, P720, DOI [DOI 10.1007/978-3-642-04898-2_327, 10.1007/978-3-642-04898-, DOI 10.1007/978-3-642-04898]; Koh PW, 2017, PR MACH LEARN RES, V70; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Liu XE, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102320; Malandrakis N, 2019, P 3 WORKSH NEUR GEN, P90, DOI 10.18653/v1/D19-5609; Mattern J, 2023, Arxiv, DOI arXiv:2305.18462; Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011; Miao ZJ, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P617, DOI 10.1145/3366423.3380144; Mireshghallah F, 2022, Arxiv, DOI arXiv:2205.12506; Mireshghallah F, 2022, Arxiv, DOI arXiv:2203.03929; Miyato T, 2021, Arxiv, DOI arXiv:1605.07725; Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065; Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P314; Ni JM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P188; Niu T., 2018, P 22 C COMP NAT LANG, P486, DOI DOI 10.18653/V1/K18-1047; Panchendrarajan R, 2021, CEUR WORKSH; Pellicer LFAO, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109803; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Sennrich R, 2016, Arxiv, DOI [arXiv:1511.06709, DOI 10.48550/ARXIV.1511.06709]; Shejwalkar V, 2021, NEURIPS 2021 WORKSH; Shen DH, 2020, Arxiv, DOI [arXiv:2009.13818, 10.48550/arXiv.2009.13818]; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0; Song CZ, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3372297.3417270; Song CZ, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P196, DOI 10.1145/3292500.3330885; Song LW, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2615; Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968; Tan S, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P303, DOI 10.1145/3278721.3278725; Uchida S, 2013, DEV GROWTH DIFFER, V55, P523, DOI 10.1111/dgd.12054; Vakili T, 2021, AAAI 2021 FALL S HUM; Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7; Xiang T, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2777, DOI 10.1145/3503161.3548103; Xie Q, 2019, ARXIV190412848; Xu GW, 2022, IEEE T DEPEND SECURE, V19, P1364, DOI 10.1109/TDSC.2020.3005909; Xu GW, 2020, IEEE T INF FOREN SEC, V15, P911, DOI 10.1109/TIFS.2019.2929409; Yang YB, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1008; Yeom S, 2018, P IEEE COMPUT SECUR, P268, DOI 10.1109/CSF.2018.00027	57	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	2024 JUN 14	2024										10.1007/s12559-024-10315-y	http://dx.doi.org/10.1007/s12559-024-10315-y		JUN 2024	12	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Neurosciences & Neurology	UK2U8					2024-07-03	WOS:001247895600001
C	Nagao, Y; Fukuda, S			ACM	Nagao, Yuto; Fukuda, Soichiro			4-Frame Manga Drawing Support System	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		Image-generation AI; Image-recognition AI; Claude large language model		This project proposes a 4-frame manga drawing support system that assists users in creating drawings. The proposed system recognizes each frame of an unfnished manga drawn by a user and proposes successive frames, considering the content recognized till then, e.g., the storyline, frame composition, and punchline. The system updates the proposal as the manga drawing proceeds. The proposed system comprises four modules for 1) recognizing the user's drawings, 2) generating four sentences that describe the storyline, 3) generating images, each of which corresponds to a manga frame from the above sentences, and 4) choosing the user-preferred manga candidate from a number of potential choices. The proposed system does not require AI to generate the 4-frame manga; instead, the user draws the 4-frame manga with the help of the system. In other words, the user decides whether to accept or reject the AI's proposal.	[Nagao, Yuto; Fukuda, Soichiro] Kwansei Gakuin Univ, Dept Engn, Nishinomiya, Hyogo, Japan	Kwansei Gakuin University	Nagao, Y (corresponding author), Kwansei Gakuin Univ, Dept Engn, Nishinomiya, Hyogo, Japan.	gdu84444@kwansei.ac.jp; gsw81451@kwansei.ac.jp						Open AI, 2023, GPT-4; Stability.ai, 2023, Stable Difusion XL	2	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									113	10.1145/3586182.3625218	http://dx.doi.org/10.1145/3586182.3625218			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000112
J	Beckmann, L; Hark, PF				Beckmann, Lars; Hark, Paul F.			ChatGPT and the banking business: Insights from the US stock market on potential implications for banks	FINANCE RESEARCH LETTERS			English	Article						AI; Banking; ChatGPT; Event study; Financial intermediation; Large language model	IMPACT; EVENT	Technological advances in artificial intelligence, such as ChatGPT, promise significant potential for automation in the banking sector, but might also be associated with uncertainties and potential disadvantages for banks. By empirically analyzing US stock market reactions to ChatGPT's launch, this study extracts the expectations of market participants to gauge potential future implications of ChatGPT for banks. The results indicate a significant negative stock market reaction of US bank stocks, with notable disparities between different bank types. Using cross-sectional regressions, we find that the negative market reaction is more pronounced for deposit -dependent and large banks.	[Beckmann, Lars; Hark, Paul F.] Univ Munster, Finance Ctr Munster, Univ Str 14-16, D-48143 Munster, Germany	University of Munster	Beckmann, L (corresponding author), Univ Munster, Finance Ctr Munster, Univ Str 14-16, D-48143 Munster, Germany.	lars.beckmann@wiwi.uni-muenster.de; paul.hark@wiwi.uni-muenster.de						Aktas N, 2021, REV FINANC, V25, P1047, DOI 10.1093/rof/rfaa034; Beccalli E, 2007, J BANK FINANC, V31, P2205, DOI 10.1016/j.jbankfin.2006.10.022; Berger AN, 2003, J MONEY CREDIT BANK, V35, P141, DOI 10.1353/mcb.2003.0009; Dessaint O, 2021, REV FINANC STUD, V34, P1, DOI 10.1093/rfs/hhaa049; El Ghoul S, 2023, J INT BUS STUD, V54, P344, DOI 10.1057/s41267-022-00534-6; Google Trends, ChatGPT; Gordon C., 2023, Forbes; Hachenberg B, 2017, FINANC RES LETT, V22, P268, DOI 10.1016/j.frl.2016.12.021; Hu K., 2023, Reuters; Huang K., 2023, ChatGPT in finance and banking, P187; Kim JH, 2023, FINANC RES LETT, V58, DOI 10.1016/j.frl.2023.104580; Ko H., 2023, SSRN Working Paper; Kolari JW, 2010, REV FINANC STUD, V23, P3996, DOI 10.1093/rfs/hhq072; Leboukh F., 2023, J. Politics Ethics New Technol. AI, V2, P35166; MacKinlay AC, 1997, J ECON LIT, V35, P13; Marr B., 2023, Forbes; Oehler A, 2024, FINANC RES LETT, V60, DOI 10.1016/j.frl.2023.104898; ONeill M., 2023, Financ. Times; PATELL JM, 1976, J ACCOUNTING RES, V14, P246, DOI 10.2307/2490543; Peeler R., 2023, Forbes; Pelster M, 2024, FINANC RES LETT, V59, DOI 10.1016/j.frl.2023.104786; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rotman D., 2023, MIT Technol. Rev.; Saggu A, 2023, FINANC RES LETT, V55, DOI 10.1016/j.frl.2023.103993; Schneider C, 2017, CRIT FINANC REV, V6, P77, DOI 10.1561/104.0000035; Smales LA, 2023, FINANC RES LETT, V58, DOI 10.1016/j.frl.2023.104514; Tang Y., 2023, SSRN Working Paper; Wahyono B, 2023, FINANC RES LETT, V58, DOI 10.1016/j.frl.2023.104576; WHITE H, 1980, ECONOMETRICA, V48, P817, DOI 10.2307/1912934; Wunker S., 2023, Forbes	30	1	1	7	7	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1544-6123	1544-6131		FINANC RES LETT	Financ. Res. Lett.	MAY	2024	63								105237	10.1016/j.frl.2024.105237	http://dx.doi.org/10.1016/j.frl.2024.105237		APR 2024	9	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	QX2I7		hybrid			2024-07-03	WOS:001224098500001
J	Waisberg, E; Ong, J; Masalkhi, M; Lee, AG				Waisberg, Ethan; Ong, Joshua; Masalkhi, Mouayad; Lee, Andrew G.			Concerns with OpenAI's Sora in Medicine	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter; Early Access						Large language models; LLM; NLP; Artificial video generation; Generative AI		Open AI's Sora represents a ground-breaking innovation in AI that can generate lifelike and imaginative visual scenes based on text prompts. However, Sora has also produced some new concerns surrounding artificial video generation in medicine. While Sora is highly promising to enhance patient education, facilitate remote consultations and simulate surgical procedures, AI-generated videos also bring technical, legal, and ethical challenges. In this paper, we explore the clinical and ethical implications of Sora's AI-generated videos in the field of medicine.	[Waisberg, Ethan] Univ Cambridge, Dept Ophthalmol, Cambridge, England; [Ong, Joshua] Univ Michigan, Kellogg Eye Ctr, Dept Ophthalmol & Visual Sci, Ann Arbor, MI USA; [Masalkhi, Mouayad] Baylor Coll Med, Ctr Space Med, Houston, TX USA; [Lee, Andrew G.] Houston Methodist Hosp, Blanton Eye Inst, Dept Ophthalmol, Houston, TX USA; [Lee, Andrew G.] Houston Methodist Hosp, Houston Methodist Res Inst, Houston, TX USA; [Lee, Andrew G.] Weill Cornell Med, Dept Ophthalmol, New York, NY USA; [Lee, Andrew G.] Weill Cornell Med, Dept Neurol, New York, NY USA; [Lee, Andrew G.] Weill Cornell Med, Dept Neurosurg, New York, NY USA; [Lee, Andrew G.] Univ Texas Med Branch, Dept Ophthalmol, Galveston, TX USA; [Lee, Andrew G.] Univ Texas MD Anderson Canc Ctr, Houston, TX USA; [Lee, Andrew G.] Texas A&M Coll Med, Bryan, TX USA; [Lee, Andrew G.] Univ Iowa Hosp & Clin, Dept Ophthalmol, Iowa City, IA USA	University of Cambridge; University of Michigan System; University of Michigan; Baylor College of Medicine; Houston Methodist Hospital; The Methodist Hospital - Houston; Houston Methodist Hospital; The Methodist Hospital - Houston; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; University of Texas System; University of Texas Medical Branch Galveston; University of Texas System; UTMD Anderson Cancer Center; Texas A&M University System; Texas A&M University College Station; Texas A&M Health Science Center; University of Iowa	Waisberg, E (corresponding author), Univ Cambridge, Dept Ophthalmol, Cambridge, England.	ew690@cam.ac.uk		Waisberg, Ethan/0000-0001-8999-0212				Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; Li HOY, 2020, BMJ GLOB HEALTH, V5, DOI 10.1136/bmjgh-2020-002604; Masalkhi M., 2024, AME SURG J, V4, P2, DOI [10.21037/asj-23-47, DOI 10.21037/ASJ-23-47]; Masalkhi M, 2024, EYE, DOI 10.1038/s41433-024-02958-w; openai, Sora: creating video from text; Paladugu PS, 2023, ANN BIOMED ENG, V51, P2130, DOI 10.1007/s10439-023-03304-z; Waisberg E., 2023, Pan Am J Ophthalmol, V5, P46, DOI DOI 10.4103/PAJO.PAJO_62_23; Waisberg E, 2024, EYE, V38, P639, DOI 10.1038/s41433-023-02759-7; Waisberg E, 2022, SPACE-SCI TECH-CHINA, V2022, DOI 10.34133/2022/9852872; Wang GY, 2023, Arxiv, DOI [arXiv:2306.09968, 10.48550/arXiv.2306.09968]	10	1	1	35	35	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	2024 APR 1	2024										10.1007/s10439-024-03505-0	http://dx.doi.org/10.1007/s10439-024-03505-0		APR 2024	3	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	MP9H2	38558354				2024-07-03	WOS:001194941300001
J	McMahon, A; Jacob, CL; Bird, VG; Whiles, BB				McMahon, Amber; Jacob, Cian L.; Bird, Vincent G.; Whiles, Bristol B.			Exploring the capabilities and challenges of ChatGPT in disseminating urologic information	TRANSLATIONAL ANDROLOGY AND UROLOGY			English	Editorial Material						Artificial intelligence (AI); large language models (LLMs); urology; communication; ChatGPT			[McMahon, Amber; Jacob, Cian L.; Whiles, Bristol B.] Univ Kansas, Med Ctr, Dept Urol, 4000 Cambridge St,Mailstop 3016, Kansas City, KS 66160 USA; [Bird, Vincent G.] Univ Florida, Med Ctr, Dept Urol, Gainesville, FL USA	University of Kansas; University of Kansas Medical Center; State University System of Florida; University of Florida	Whiles, BB (corresponding author), Univ Kansas, Med Ctr, Dept Urol, 4000 Cambridge St,Mailstop 3016, Kansas City, KS 66160 USA.	bristolwhiles@gmail.com						Cheong RCT, 2024, EUR ARCH OTO-RHINO-L, V281, P2137, DOI 10.1007/s00405-023-08381-3; Cocci A, 2024, PROSTATE CANCER P D, V27, P159, DOI 10.1038/s41391-023-00754-3; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; Davis R, 2023, J UROLOGY, V210, P688, DOI 10.1097/JU.0000000000003615; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Liu JY, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.107590; Lozic E, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15100336; Nguyen D, 2024, ACAD RADIOL, V31, P1799, DOI 10.1016/j.acra.2023.11.002; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Sedaghat S, 2024, J AM COLL RADIOL, V21, P344, DOI 10.1016/j.jacr.2023.10.019; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Whiles BB, 2023, UROLOGY, V180, P278, DOI 10.1016/j.urology.2023.07.010; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	13	0	0	2	2	AME PUBLISHING COMPANY	SHATIN	FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA	2223-4683	2223-4691		TRANSL ANDROL UROL	Transl. Androl. Urol.	MAR 31	2024	13	3					470	472		10.21037/tau-23-545	http://dx.doi.org/10.21037/tau-23-545			3	Andrology; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Endocrinology & Metabolism; Urology & Nephrology	QT5L5	38590955	Green Published, gold			2024-07-03	WOS:001223133100015
C	Ni, YM; Chen, YQ; Ding, RY; Ni, SG			ACM	Ni, Yeming; Chen, Yuqing; Ding, Ruyi; Ni, Shiguang			Beatrice: A Chatbot for Collecting Psychoecological Data and Providing QA Capabilities	PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023			English	Proceedings Paper	16th ACM International Conference on Pervasive Technologies Related to Assistive Environments (PETRA)	JUL 05-07, 2023	Corfu, GREECE	Assoc Comp Machinery, ICPS Digital Libraries, Univ Texas Arlington, Coll Engn, Natl Sci Fdn, Univ Texas Arlington, Dept Comp Sci & Engn, Univ Texas Arlington, Human Centered Comp Lab, Univ Texas Arlington, iPerform Ind Univ NSF Ctr, Natl Ctr Sci Res, Ionian Univ, Technologies Journal		chatbots; conversational interfaces; usability; intensive longitudinal design; large language models		In recent years, the continuous advancement of artificial intelligence technology has generated increasing interest in interactive psychological dialogue systems as a means of providing psychological health assistance based on AI technology. This paper introduces Beatrice, a chatbot specifically designed to address the challenge of obtaining psychological ecological data in intensive longitudinal designs (ILDs). Beatrice is a low-code interactive dialogue agent that can be seamlessly integrated into various software platforms and abstracts psychological scales. By leveraging large pre-trained language models and prompt learning, we have achieved a direct and effective psychological support system that enables natural interaction with a diverse range of participants, facilitating the acquisition of psychoecological data. Additionally, we conducted a small-scale system usability test and interviews based on the Technology Acceptance Model (TAM) framework, thereby providing an opportunity to investigate the emotional regulation mechanisms in Chinese adolescents. Through iterative processes and optimization, this tool aims to enhance the application of ILDs by providing improved support.	[Ni, Yeming; Chen, Yuqing] Tsinghua Univ, Beijing, Peoples R China; [Ding, Ruyi] Sun Yat Sen Univ, Guangzhou, Peoples R China; [Ni, Shiguang] Tsinghua Univ, Shenzhen Int Grad Sch, Beijing, Peoples R China	Tsinghua University; Sun Yat Sen University; Tsinghua University	Ding, RY (corresponding author), Sun Yat Sen Univ, Guangzhou, Peoples R China.; Ni, SG (corresponding author), Tsinghua Univ, Shenzhen Int Grad Sch, Beijing, Peoples R China.	nym20@mails.tsinghua.edu.cn; chenyq22@mails.tsinghua.edu.cn; dingry7@mail.sysu.edu.cn; ni.shiguang@sz.tsinghua.edu.cn	NI, Shiguang/ITV-0238-2023	Chen, Yuqing/0009-0007-5761-7860; Ni, Shiguang/0000-0002-4303-7386; Ding, Ruyi/0000-0002-0151-2548	National Key R&D Program of China [2020YFC0833402]; Shenzhen Key Laboratory of next generation interactive media innovative technology [ZDS YS20210623092001004]; Shenzhen Key Research Base of Humanities and Social Sciences [202003]	National Key R&D Program of China; Shenzhen Key Laboratory of next generation interactive media innovative technology; Shenzhen Key Research Base of Humanities and Social Sciences	This study was funded by the National Key R&D Program of China (Grant No.2020YFC0833402), the Shenzhen Key Laboratory of next generation interactive media innovative technology (Grant No.ZDS YS20210623092001004), the Shenzhen Key Research Base of Humanities and Social Sciences (Grant No.202003).	Arrabales R., 2021, arXiv, DOI 10.48550/arXiv.2008.12875; Bangor A, 2009, J USABILITY STUD, V4, P114; Bevan N, 2015, LECT NOTES COMPUT SC, V9169, P143, DOI 10.1007/978-3-319-20901-2_13; Bolger N, 2003, ANNU REV PSYCHOL, V54, P579, DOI 10.1146/annurev.psych.54.101601.145030; Bolger N., 2013, Intensive longitudinal methods: An introduction to diary and experience sampling research; CSIKSZENTMIHALYI M, 1987, J NERV MENT DIS, V175, P526, DOI 10.1097/00005053-198709000-00004; Eysenbach G, 2001, J MED INTERNET RES, V3, DOI 10.2196/jmir.3.2.e19; Ho A, 2018, J COMMUN, V68, P712, DOI 10.1093/joc/jqy026; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Holden RJ, 2010, J BIOMED INFORM, V43, P159, DOI 10.1016/j.jbi.2009.07.002; Li MH, 2020, LECT NOTES ELECTR EN, V586, P683, DOI 10.1007/978-981-32-9050-1_77; Lucero A, 2015, LECT NOTES COMPUT SC, V9297, P231, DOI 10.1007/978-3-319-22668-2_19; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Macik R., 2017, Economic and Environmental Studies, V17, P363; Shiffrin R, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2300963120; Song ZL, 2011, J APPL PSYCHOL, V96, P151, DOI 10.1037/a0021035; Tullis T.S., 2004, USABILITY PROFESSION, P1; Van Berkel N, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3123988; Yu Q, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312918	19	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0069-9				2023							429	435		10.1145/3594806.3596580	http://dx.doi.org/10.1145/3594806.3596580			7	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2SR		hybrid			2024-07-03	WOS:001124478300071
J	Ma, ZY; Qin, JW; Pan, MQ; Tang, S; Mi, JP; Liu, D				Ma, Zhiyuan; Qin, Jiwei; Pan, Meiqi; Tang, Song; Mi, Jinpeng; Liu, Dan			Promoting Unified Generative Framework with Descriptive Prompts for Joint Multi-Intent Detection and Slot Filling	ELECTRONICS			English	Article						natural language understanding; large language model; intent detection; slot filling		Natural language understanding is a crucial aspect of task-oriented dialogue systems, encompassing intent detection (ID) and slot filling (SF). Conventional approaches for ID and SF solve the problems in a separate manners, while recent studies are now leaning toward joint modeling to tackle multi-intent detection and SF. Although the advancements in prompt learning offer a unified framework for ID and SF, current prompt-based methods fail to fully exploit the semantics of intent and slot labels. Additionally, the potential of using prompt learning to model the correlation between ID and SF in multi-intent scenarios remains unexplored. To address the issue, we propose a text-generative framework that unifies ID and SF. The prompt templates are constructed with label semantical descriptions. Moreover, we introduce an auxiliary task to explicitly capture the correlation between ID and SF. The experimental results on two benchmark datasets show that our method achieves an overall accuracy improvement of 0.4-1.5% in a full-data scenario and 1.4-2.7% in a few-shot setting compared with a prior method, establishing it as a new state-of-the-art approach.	[Ma, Zhiyuan; Qin, Jiwei; Pan, Meiqi; Tang, Song; Mi, Jinpeng; Liu, Dan] Univ Shanghai Sci & Technol, Inst Machine Intelligence, Shanghai 200093, Peoples R China; [Ma, Zhiyuan] Univ Shanghai Sci & Technol, Sch Intelligent Emergency Management, Shanghai 200093, Peoples R China; [Ma, Zhiyuan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	University of Shanghai for Science & Technology; University of Shanghai for Science & Technology; Nanjing University	Ma, ZY (corresponding author), Univ Shanghai Sci & Technol, Inst Machine Intelligence, Shanghai 200093, Peoples R China.; Ma, ZY (corresponding author), Univ Shanghai Sci & Technol, Sch Intelligent Emergency Management, Shanghai 200093, Peoples R China.; Ma, ZY (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.	yuliar3514@usst.edu.cn; 213332821@st.usst.edu.cn; 222302289@st.usst.edu.cn; tangs@usst.edu.cn; jp.mi@usst.edu.cn; liudan1123@usst.edu.cn		Ma, Zhiyuan/0000-0003-2153-5824	State Key Laboratory for Novel Software Technology, Nanjing University	State Key Laboratory for Novel Software Technology, Nanjing University(Nanjing University)	The authors would like to thank the anonymous reviewers for their insightful comments.	[Anonymous], 2018, P 2018 NAACL HLT; [Anonymous], 2016, P 25 INT JOINT C ART; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai FY, 2022, INT CONF ACOUST SPEE, P7607, DOI 10.1109/ICASSP43922.2022.9747477; Chen LS, 2022, INT CONF ACOUST SPEE, P7612, DOI 10.1109/ICASSP43922.2022.9747843; Cheng Lizhi, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2211.12220, 10.48550/arXiv.2211.12220]; Coucke A, 2018, Arxiv, DOI arXiv:1805.10190; Ding Z., 2021, IJCAI, P3801; E HH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5467; Firdaus M, 2018, LECT NOTES ARTIF INT, V11012, P629, DOI 10.1007/978-3-319-97304-3_48; Gangadharaiah R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P564; Gao T., 2020, arXiv; Hemphill C. T., 1990, P WORKSH HELD HIDD V; Hou YT, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3190; Hou YT, 2021, AAAI CONF ARTIF INTE, V35, P13036; Hou Yutai, 2022, FIND ASS COMP LING, P637, DOI 10.18653/v1/2022.findingsacl.53; Jin F., 2022, arXiv, DOI [DOI 10.1145/3604613, 10.1145/3604613]; Kim B, 2017, MULTIMED TOOLS APPL, V76, P11377, DOI 10.1007/s11042-016-3724-4; Kumar A, 2022, Arxiv, DOI [arXiv:2206.10559, 10.48550/arXiv.2206.10559 2206.10559, DOI 10.48550/ARXIV.2206.105592206.10559]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Qin LB, 2020, Arxiv, DOI arXiv:2004.10087; Qin LB, 2019, Arxiv, DOI arXiv:1909.02188; Qin LB, 2021, Arxiv, DOI arXiv:2103.03095; Qin LB, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P178; Qiu L, 2018, Arxiv, DOI arXiv:1812.05199; Qixiang Gao, 2022, P C EMP METH NAT LAN, P2460, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.157; Shin Y, 2018, INTERSPEECH, P2082; Song F., 2022, arXiv; Song Mengxiao, 2022, P 2022 C EMP METH NA, P7967; Wang LW, 2022, Arxiv, DOI arXiv:2203.03903; Wang Y., 2023, P FIND ASS COMP LING, P13508, DOI [10.18653/v1/2023.findings-acl.853, DOI 10.18653/V1/2023.FINDINGS-ACL.853]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu JW, 2018, NAMED ENTITIES, P22; Wu Y., 2022, P 29 INT C COMPUTATI, P7203; Xia CY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3090; Xing B., 2022, P 2022 C EMP METH NA, P159; Yang F., 2022, P INT JOINT C ART IN, VVolume 7, P4447, DOI [DOI 10.24963/IJCAI.2022/617, 10.24963/ijcai.2022/617]; Zhang F, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P8605; Zhang QC, 2023, NEURAL PROCESS LETT, V55, P9483, DOI 10.1007/s11063-023-11210-7; Zhu S, 2017, INT CONF ACOUST SPEE, P5675, DOI 10.1109/ICASSP.2017.7953243; Zhu Z., 2023, P IEEE INT C AC SPEE, P1, DOI [10.1109/ICASSP49357.2023.10095809, DOI 10.1109/ICASSP49357.2023.10095809]	41	0	0	4	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	MAR	2024	13	6							1087	10.3390/electronics13061087	http://dx.doi.org/10.3390/electronics13061087			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	MC4A6		gold			2024-07-03	WOS:001191403400001
J	Masters, K; Benjamin, J; Agrawal, A; Macneill, H; Pillow, MT; Mehta, N				Masters, Ken; Benjamin, Jennifer; Agrawal, Anoop; Macneill, Heather; Pillow, M. Tyson; Mehta, Neil			Twelve tips on creating and using custom GPTs to enhance health professions education	MEDICAL TEACHER			English	Article						Artificial intelligence; ChatGPT; custom GPT; medical education; large language model		The custom GPT is the latest powerful feature added to ChatGPT. Non-programmers can create and share their own GPTs ("chat bots"), allowing Health Professions Educators to apply the capabilities of ChatGPT to create administrative assistants, online tutors, virtual patients, and more, to support their clinical and non-clinical teaching environments. To achieve this correctly, however, requires some skills, and this 12-Tips paper provides those: we explain how to construct data sources, build relevant GPTs, and apply some basic security.	[Masters, Ken] Sultan Qaboos Univ, Dept Med, Muscat, Oman; [Benjamin, Jennifer] Baylor Coll Med, Texas Childrens Hosp, Houston, TX USA; [Agrawal, Anoop] Baylor Coll Med, Emergency Med, Houston, TX USA; [Macneill, Heather] Univ Toronto, Temerty Med, Dept Med, Toronto, ON, Canada; [Pillow, M. Tyson] Baylor Coll Med, Dept Educ Innovat & Technol, Houston, TX USA; [Mehta, Neil] Cleveland Clin, Dept Internal Med & Geriatr, Cleveland, OH USA; [Masters, Ken] Sultan Qaboos Univ, Coll Med & Hlth Sci, Med Educ & Informat Dept, Muscat, Oman	Sultan Qaboos University; Baylor College of Medicine; Baylor College of Medicine; University of Toronto; Baylor College of Medicine; Cleveland Clinic Foundation; Sultan Qaboos University	Masters, K (corresponding author), Sultan Qaboos Univ, Coll Med & Hlth Sci, Med Educ & Informat Dept, Muscat, Oman.		Mehta, Neil/AAL-9824-2020; Masters, Ken/C-6163-2013	Masters, Ken/0000-0003-3425-5020; Pillow, Malford/0000-0001-7584-5452; MacNeill, Heather/0000-0001-9842-3578; Mehta, Neil/0000-0001-8342-4252; Benjamin, Jennifer/0000-0001-6085-5973				Bahroun Z, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151712983; Bubeck S., 2023, arXiv; Herrmann-Werner A, 2024, J MED INTERNET RES, V26, DOI 10.2196/52113; Kiyak YS, 2023, Rev. esp. educ. med., V4, P98, DOI [10.6018/edumed.587451, DOI 10.6018/EDUMED.587451]; Kumagai AK, 2014, ACAD MED, V89, P978, DOI 10.1097/ACM.0000000000000234; MacNeill H, 2014, J CONTIN EDUC HEALTH, V34, P102, DOI 10.1002/chp.21226; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Ng SL, 2019, ACAD MED, V94, P1122, DOI 10.1097/ACM.0000000000002724; OpenAI, 2023, FILE UPLOADS GPTS AD; OpenAI, 2023, OPENAI PLATFORM ACTI; OpenAI, 2023, Introducing gpts; Preiksaitis C, 2023, JMIR MED EDUC, V9, DOI 10.2196/48785; Violato E., 2023, INT J HEALTHCARE SIM, DOI [10.54531/wjgb5594, DOI 10.54531/WJGB5594]	13	5	5	24	24	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0142-159X	1466-187X		MED TEACH	Med. Teach.	JUN 2	2024	46	6					752	756		10.1080/0142159X.2024.2305365	http://dx.doi.org/10.1080/0142159X.2024.2305365		JAN 2024	5	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	TA4E2	38285894				2024-07-03	WOS:001152065700001
J	Unni, R; Zhou, MY; Wiecha, PR; Zheng, YB				Unni, Rohit; Zhou, Mingyuan; Wiecha, Peter R.; Zheng, Yuebing			Advancing materials science through next-generation machine learning	CURRENT OPINION IN SOLID STATE & MATERIALS SCIENCE			English	Review						Deep learning; Neural networks; Materials science; Large language models	DEEP; KNOWLEDGE; TRENDS	For over a decade, machine learning (ML) models have been making strides in computer vision and natural language processing (NLP), demonstrating high proficiency in specialized tasks. The emergence of large-scale language and generative image models, such as ChatGPT and Stable Diffusion, has significantly broadened the accessibility and application scope of these technologies. Traditional predictive models are typically constrained to mapping input data to numerical values or predefined categories, limiting their usefulness beyond their designated tasks. In contrast, contemporary models employ representation learning and generative modeling, enabling them to extract and encode key insights from a wide variety of data sources and decode them to create novel responses for desired goals. They can interpret queries phrased in natural language to deduce the intended output. In parallel, the application of ML techniques in materials science has advanced considerably, particularly in areas like inverse design, material prediction, and atomic modeling. Despite these advancements, the current models are overly specialized, hindering their potential to supplant established industrial processes. Materials science, therefore, necessitates the creation of a comprehensive, versatile model capable of interpreting humanreadable inputs, intuiting a wide range of possible search directions, and delivering precise solutions. To realize such a model, the field must adopt cutting-edge representation, generative, and foundation model techniques tailored to materials science. A pivotal component in this endeavor is the establishment of an extensive, centralized dataset encompassing a broad spectrum of research topics. This dataset could be assembled by crowdsourcing global research contributions and developing models to extract data from existing literature and represent them in a homogenous format. A massive dataset can be used to train a central model that learns the underlying physics of the target areas, which can then be connected to a variety of specialized downstream tasks. Ultimately, the envisioned model would empower users to intuitively pose queries for a wide array of desired outcomes. It would facilitate the search for existing data that closely matches the sought-after solutions and leverage its understanding of physics and material-behavior relationships to innovate new solutions when preexisting ones fall short.	[Unni, Rohit; Zheng, Yuebing] Univ Texas Austin, Walker Dept Mech Engn, Austin, TX 78712 USA; [Unni, Rohit; Zheng, Yuebing] Univ Texas Austin, Texas Mat Inst, Austin, TX 78712 USA; [Zhou, Mingyuan] Univ Texas Austin, Dept Stat & Data Sci, Austin, TX 78712 USA; [Zhou, Mingyuan] Univ Texas Austin, McCombs Sch Business, Austin, TX 78712 USA; [Wiecha, Peter R.] Univ Toulouse, LAAS, CNRS, Toulouse, France	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; Universite de Toulouse; Centre National de la Recherche Scientifique (CNRS)	Zheng, YB (corresponding author), Univ Texas Austin, Walker Dept Mech Engn, Austin, TX 78712 USA.	zheng@austin.utexas.edu	Zheng, Yuebing/B-9886-2008		National Institute of General Medical Sciences of the National Institutes of Health [1R01GM146962-01]; French Agence Nationale de la Recherche (ANR) [ANR-22-CE24-0002]	National Institute of General Medical Sciences of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); French Agence Nationale de la Recherche (ANR)(Agence Nationale de la Recherche (ANR))	R.U and Y.Z acknowledge the financial support of the National Institute of General Medical Sciences of the National Institutes of Health (1R01GM146962-01) . P.R.W acknowledges funding from the French Agence Nationale de la Recherche (ANR) under the grant ANR-22-CE24-0002 (project NAINOS) .	Abdullah MA, 2022, I COMP CONF WAVELET, DOI 10.1109/ICCWAMTIP56608.2022.10016485; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahsan MM, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10030541; Aldosari MN, 2021, ENERGY AI, V4, DOI 10.1016/j.egyai.2021.100054; Ali M., 2023, arXiv; Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1; Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8; Augenstein Y, 2023, ACS PHOTONICS, V10, P1547, DOI 10.1021/acsphotonics.3c00156; Bai Y., 2022, ARXIV; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bessa MA, 2019, ADV MATER, V31, DOI 10.1002/adma.201904845; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caicedo JC, 2019, CYTOM PART A, V95, P952, DOI 10.1002/cyto.a.23863; Caicedo JC, 2017, NAT METHODS, V14, P849, DOI [10.1038/nmeth.4397, 10.1038/NMETH.4397]; Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227; Cassar DR, 2018, ACTA MATER, V159, P249, DOI 10.1016/j.actamat.2018.08.022; Cats P, 2021, APL MATER, V9, DOI 10.1063/5.0042558; Chai JY, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100134; Chen A, 2020, INFOMAT, V2, P553, DOI 10.1002/inf2.12094; Chen C, 2020, ADV ENERGY MATER, V10, DOI 10.1002/aenm.201903242; Chen MK, 2022, ACS PHOTONICS, DOI 10.1021/acsphotonics.2c00876; Choudhary K, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00734-6; Christiano P., 2023, ARXIV; Chu L., 2023, arXiv; Deringer VL, 2019, ADV MATER, V31, DOI 10.1002/adma.201902765; Faber FA, 2017, J CHEM THEORY COMPUT, V13, P5255, DOI 10.1021/acs.jctc.7b00577; Fan JA, 2020, MRS BULL, V45, P196, DOI 10.1557/mrs.2020.62; Fan ZX, 2022, PHYS REV APPL, V18, DOI 10.1103/PhysRevApplied.18.024022; Grimaldi G, 2023, ACS ENERGY LETT, V8, P878, DOI 10.1021/acsenergylett.2c02828; Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; Nguyen H, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P590, DOI 10.1109/IRC.2019.00120; Hastie T., 2009, ELEMENTS STAT LEARNI; Hautier G, 2011, INORG CHEM, V50, P656, DOI 10.1021/ic102031h; Hegde RS, 2020, NANOSCALE ADV, V2, P1007, DOI 10.1039/c9na00656g; Hippalgaonkar K, 2023, NAT REV MATER, V8, P241, DOI 10.1038/s41578-022-00513-1; Huo HY, 2022, CHEM MATER, V34, P7323, DOI 10.1021/acs.chemmater.2c01293; Jablonka KM, 2022, NAT CHEM, V14, P365, DOI 10.1038/s41557-022-00910-7; Jaegle A, 2021, PR MACH LEARN RES, V139; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaya M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41316-9; Kiarashinejad Y, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-0276-y; Kim D, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246102; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kudyshev ZA, 2020, APPL PHYS REV, V7, DOI 10.1063/1.5134792; Li J., 2023, arXiv; Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214; Linardatos P, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010018; Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866; Liu YT, 2022, NAT MACH INTELL, V4, P341, DOI 10.1038/s42256-022-00460-0; Liu Y, 2017, J MATERIOMICS, V3, P159, DOI 10.1016/j.jmat.2017.08.002; Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167; Ma W, 2021, NAT PHOTONICS, V15, P77, DOI 10.1038/s41566-020-0685-y; Mahadevkar SV, 2022, IEEE ACCESS, V10, P107293, DOI 10.1109/ACCESS.2022.3209825; Malkiel I, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0060-7; Meredig B, 2014, PHYS REV B, V89, DOI 10.1103/PhysRevB.89.094104; Miles C, 2023, PHYS REV RES, V5, DOI 10.1103/PhysRevResearch.5.013026; Moosavi SM, 2022, NAT MATER, V21, P1419, DOI 10.1038/s41563-022-01374-3; Nadell CC, 2019, OPT EXPRESS, V27, P27523, DOI 10.1364/OE.27.027523; Pederson R, 2022, NAT REV PHYS, V4, P357, DOI 10.1038/s42254-022-00470-2; Peurifoy J, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aar4206; Qu YR, 2019, ACS PHOTONICS, V6, P1168, DOI 10.1021/acsphotonics.8b01526; Radford A, 2021, PR MACH LEARN RES, V139; Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045; Ramesh A, 2021, PR MACH LEARN RES, V139; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Ruiz N., 2023, arXiv; Snurr RQ, 2022, NAT MATER, V21, P1342, DOI 10.1038/s41563-022-01410-2; Subramanian S., 2023, arXiv; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Touvron H., 2023, arXiv; Unni R, 2021, NANOPHOTONICS-BERLIN, V10, P4057, DOI 10.1515/nanoph-2021-0392; Vaswani A, 2017, ADV NEUR IN, V30; Wei J, 2019, INFOMAT, V1, P338, DOI 10.1002/inf2.12028; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; White C., 2023, The symbiosis of deep learning and differential equations, VIII; Wiecha PR, 2021, PHOTONICS RES, V9, pB182, DOI 10.1364/PRJ.415960; Wiecha PR, 2020, NANO LETT, V20, P329, DOI 10.1021/acs.nanolett.9b03971; Yan RG, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01492-2; Yao K., 2023, SPRINGER SERIES OPTI; Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738; Yu XL, 2008, J THEOR COMPUT CHEM, V7, P953, DOI 10.1142/S0219633608004416; Zhang TT, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/17298814211007305	88	0	0	9	9	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	1359-0286	1879-0348		CURR OPIN SOLID ST M	Curr. Opin. Solid State Mat. Sci.	JUN	2024	30								101157	10.1016/j.cossms.2024.101157	http://dx.doi.org/10.1016/j.cossms.2024.101157		APR 2024	9	Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science; Physics	QN5S1					2024-07-03	WOS:001221570200001
J	Yaïci, R; Cieplucha, M; Bock, R; Moayed, F; Bechrakis, NE; Berens, P; Feltgen, N; Friedburg, D; Gräf, M; Guthoff, R; Hoffmann, EM; Hoerauf, H; Hintschich, C; Kohnen, T; Messmer, EM; Nentwich, MM; Pleyer, U; Schaudig, U; Seitz, B; Geerling, G; Roth, M				Yaici, Remi; Cieplucha, M.; Bock, R.; Moayed, F.; Bechrakis, N. E.; Berens, P.; Feltgen, N.; Friedburg, D.; Graef, M.; Guthoff, R.; Hoffmann, E. M.; Hoerauf, H.; Hintschich, C.; Kohnen, T.; Messmer, E. M.; Nentwich, M. M.; Pleyer, U.; Schaudig, U.; Seitz, B.; Geerling, G.; Roth, M.			ChatGPT and the German board examination for ophthalmology: an evaluation	OPHTHALMOLOGIE			German	Article; Early Access						Artificial intelligence; Medicine; Open questions; Subspeciality; Large Language Model	ARTIFICIAL-INTELLIGENCE	Purpose In recent years artificial intelligence (AI), as a new segment of computer science, has also become increasingly more important in medicine. The aim of this project was to investigate whether the current version of ChatGPT (ChatGPT 4.0) is able to answer open questions that could be asked in the context of a German board examination in ophthalmology. Methods After excluding image-based questions, 10 questions from 15 different chapters/topics were selected from the textbook 1000 questions in ophthalmology (1000 Fragen Augenheilkunde 2nd edition, 2014). ChatGPT was instructed by means of a so-called prompt to assume the role of a board certified ophthalmologist and to concentrate on the essentials when answering. A human expert with considerable expertise in the respective topic, evaluated the answers regarding their correctness, relevance and internal coherence. Additionally, the overall performance was rated by school grades and assessed whether the answers would have been sufficient to pass the ophthalmology board examination. Results The ChatGPT would have passed the board examination in 12 out of 15 topics. The overall performance, however, was limited with only 53.3% completely correct answers. While the correctness of the results in the different topics was highly variable (uveitis and lens/cataract 100%; optics and refraction 20%), the answers always had a high thematic fit (70%) and internal coherence (71%). Conclusion The fact that ChatGPT 4.0 would have passed the specialist examination in 12 out of 15 topics is remarkable considering the fact that this AI was not specifically trained for medical questions; however, there is a considerable performance variability between the topics, with some serious shortcomings that currently rule out its safe use in clinical practice.	[Yaici, Remi; Cieplucha, M.; Bock, R.; Moayed, F.; Guthoff, R.; Geerling, G.; Roth, M.] Heinrich Heine Univ Dusseldorf, Med Fak, Klin Augenheilkunde, Univ Klinikum Dusseldorf, Moorenstr 5, D-40225 Dusseldorf, Germany; [Bechrakis, N. E.] Univ Klinikum Essen, Augenklin, Essen, Germany; [Berens, P.] Hertie Inst AI Brain Hlth Hertie AI, Tubingen, Germany; [Feltgen, N.] Univ Spital Basel, Augenklin, Basel, Switzerland; [Friedburg, D.; Graef, M.] Univ Klinikum Giessen & Marburg, Giessen, Germany; [Hoffmann, E. M.] Univ Klinikum Mainz, Augenklin, Mainz, Germany; [Hoerauf, H.] Univ Klinikum Gottingen, Augenklin, Gottingen, Germany; [Hintschich, C.; Messmer, E. M.] Ludwigs Maximilians Univ Munchen, LMU Klinikum, Augenklin & Poliklin, Munich, Germany; [Kohnen, T.] Univ Klinikum Frankfurt, Augenklin, Frankfurt, Germany; [Nentwich, M. M.] Univ Klinikum Wurzburg, Augenklin, Wurzburg, Germany; [Pleyer, U.] Charite Univ Med Berlin, Berlin, Germany; [Schaudig, U.] Asklepios Klin Barmbek, Hamburg, Germany; [Seitz, B.] Univ Klinikum Saarlandes, Klin Augenheilkunde, Homburg, Germany	Heinrich Heine University Dusseldorf; Heinrich Heine University Dusseldorf Hospital; University of Hamburg; University Medical Center Hamburg-Eppendorf; University of Duisburg Essen; University of Basel; University Hospital of Giessen & Marburg; University of Hamburg; University Medical Center Hamburg-Eppendorf; University of Gottingen; University of Hamburg; University Medical Center Hamburg-Eppendorf; University of Munich; University of Hamburg; University Medical Center Hamburg-Eppendorf; Goethe University Frankfurt; Goethe University Frankfurt Hospital; University of Hamburg; University Medical Center Hamburg-Eppendorf; University of Wurzburg; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Universitatsklinikum des Saarlandes	Yaïci, R (corresponding author), Heinrich Heine Univ Dusseldorf, Med Fak, Klin Augenheilkunde, Univ Klinikum Dusseldorf, Moorenstr 5, D-40225 Dusseldorf, Germany.	remi.yaici@med.uni-duesseldorf.de						Alexandrou M., 2024, Interventional Cardiologists Perspectives and Knowledge Towards Artificial Intelligence. In SCAI; Ali MJ, 2023, GRAEF ARCH CLIN EXP, V261, P3205, DOI 10.1007/s00417-023-06123-z; [Anonymous], 2023, zitiert; [Anonymous], 1927, Archiv fur Geschichte der Medizin Internet, P240; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bang Y., 2023, arXiv; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Bini SA, 2018, J ARTHROPLASTY, V33, P2358, DOI 10.1016/j.arth.2018.02.067; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Briganti G, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00027; Chen MY, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.990604; Dossantos J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40765; Finger RP, 2020, OPHTHALMOLOGE, V117, P963, DOI 10.1007/s00347-020-01131-4; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Harris PA, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103208; Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010; Hirschberg J., 1871, Professor A. von Graefes klinische Vortrge ber Augenheilkunde. In, V1; Holzner D., 2022, Attitudes and Acceptance Towards Artificial Intelligence in, P68; Hswen Y, 2023, JAMA-J AM MED ASSOC, V330, P1604, DOI 10.1001/jama.2023.19293; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; Kampik A., 2014, 1000 kommentierte Prfungsfragen; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lai VD., 2023, arXiv; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Martinho A, 2021, ARTIF INTELL MED, V121, DOI 10.1016/j.artmed.2021.102190; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P798, DOI 10.1001/jamaophthalmol.2023.2754; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; nashsquared, 2023, Nash Squared Digital Leadership Report; Open AI, 2024, Prompt engineering (guides); Panthier C, 2023, J FR OPHTALMOL, V46, P706, DOI 10.1016/j.jfo.2023.05.006; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pedro AR, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290613; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Schmidt-Rimpler H, Werdens Sammlung kurzer medizinischer Lehrbucher, V2; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Srivastava R., 2023, Explor Res Hypothesis Med, V000, P0, DOI [10.14218/ERHM.2023.00048, DOI 10.14218/ERHM.2023.00048]; Stades C., 2007, Ophthalmology for the Veterinary Practitioner, V2, P272; Stages of Trachoma, 1960, Public Health Service Publication, V541; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Tan TF, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100394; Tan TF, 2023, LANCET GLOB HEALTH, V11, P1432, DOI 10.1016/S2214-109X(23)00323-6; van der Zander QEW, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20958-2; Voelker R, 2023, JAMA-J AM MED ASSOC, V330, P1416, DOI 10.1001/jama.2023.19180	45	0	0	2	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2731-720X	2731-7218		OPHTHALMOLOGIE	Ophthalmologie	2024 MAY 27	2024										10.1007/s00347-024-02046-0	http://dx.doi.org/10.1007/s00347-024-02046-0		MAY 2024	10	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	SC3G0	38801461				2024-07-03	WOS:001232214200001
J	Xie, SY; Zhao, WJ; Deng, GH; He, GH; He, N; Lu, ZH; Hu, WH; Zhao, MM; Du, J				Xie, Shiyao; Zhao, Wenjing; Deng, Guanghui; He, Guohua; He, Na; Lu, Zhenhua; Hu, Weihua; Zhao, Mingming; Du, Jian			Utilizing ChatGPT as a scientific reasoning engine to differentiate conflicting evidence and summarize challenges in controversial clinical questions	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						ChatGPT; large language model; clinical research; reasoning; inconsistent evidence	TICAGRELOR; PRASUGREL	Objective Synthesizing and evaluating inconsistent medical evidence is essential in evidence-based medicine. This study aimed to employ ChatGPT as a sophisticated scientific reasoning engine to identify conflicting clinical evidence and summarize unresolved questions to inform further research.Materials and Methods We evaluated ChatGPT's effectiveness in identifying conflicting evidence and investigated its principles of logical reasoning. An automated framework was developed to generate a PubMed dataset focused on controversial clinical topics. ChatGPT analyzed this dataset to identify consensus and controversy, and to formulate unsolved research questions. Expert evaluations were conducted 1) on the consensus and controversy for factual consistency, comprehensiveness, and potential harm and, 2) on the research questions for relevance, innovation, clarity, and specificity.Results The gpt-4-1106-preview model achieved a 90% recall rate in detecting inconsistent claim pairs within a ternary assertions setup. Notably, without explicit reasoning prompts, ChatGPT provided sound reasoning for the assertions between claims and hypotheses, based on an analysis grounded in relevance, specificity, and certainty. ChatGPT's conclusions of consensus and controversies in clinical literature were comprehensive and factually consistent. The research questions proposed by ChatGPT received high expert ratings.Discussion Our experiment implies that, in evaluating the relationship between evidence and claims, ChatGPT considered more detailed information beyond a straightforward assessment of sentimental orientation. This ability to process intricate information and conduct scientific reasoning regarding sentiment is noteworthy, particularly as this pattern emerged without explicit guidance or directives in prompts, highlighting ChatGPT's inherent logical reasoning capabilities.Conclusion This study demonstrated ChatGPT's capacity to evaluate and interpret scientific claims. Such proficiency can be generalized to broader clinical research literature. ChatGPT effectively aids in facilitating clinical studies by proposing unresolved challenges based on analysis of existing studies. However, caution is advised as ChatGPT's outputs are inferences drawn from the input literature and could be harmful to clinical practice.	[Xie, Shiyao; Zhao, Wenjing; Du, Jian] Peking Univ, Inst Med Technol, Hlth Sci Ctr, Beijing 100191, Peoples R China; [Xie, Shiyao; Zhao, Wenjing; Du, Jian] Peking Univ, Natl Inst Hlth Data Sci, 38 Xueyuan Rd, Beijing 100191, Peoples R China; [Deng, Guanghui] Peking Univ, Sch Hlth Humanities, Beijing 100191, Peoples R China; [He, Guohua] Sun Yat sen Univ, Dept Pediat Nephrol & Rheumatol, Affiliated Hosp 1, Guangzhou, Peoples R China; [He, Na] Peking Univ Third Hosp, Dept Pharm, Beijing 100089, Peoples R China; [Lu, Zhenhua] Peking Univ Canc Hosp, Dept Gastrointestinal Canc Translat Res Lab, Beijing 100143, Peoples R China; [Hu, Weihua] Peking Univ, Sch Publ Hlth, Dept Epidemiol & Biostat, Beijing 100191, Peoples R China; [Zhao, Mingming] Peking Univ Third Hosp, Dept Cardiol, Beijing 100089, Peoples R China; [Zhao, Mingming] Peking Univ Third Hosp, Inst Vasc Med, Beijing 100089, Peoples R China	Peking University; Peking University; Peking University; Sun Yat Sen University; Peking University	Du, J (corresponding author), Peking Univ, Natl Inst Hlth Data Sci, 38 Xueyuan Rd, Beijing 100191, Peoples R China.	dujian@bjmu.edu.cn	Zhao, Mingming/IZE-6772-2023	Zhao, Mingming/0000-0001-5513-1305; Du, Jian/0000-0001-8436-778X	National Key R&D Program for Young Scientists [2022YFF0712000]; National Natural Science Foundation of China [72074006]; China Postdoctoral Science Foundation [2023M740154]	National Key R&D Program for Young Scientists; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	This study was funded by the National Key R&D Program for Young Scientists (Project numbers 2022YFF0712000 to J.D.), the National Natural Science Foundation of China (Project numbers 72074006 to J.D.), the General funding of the China Postdoctoral Science Foundation (Project numbers 2023M740154 to W.Z.).	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Alamri A, 2016, J BIOMED SEMANT, V7, DOI 10.1186/s13326-016-0083-z; Bianchini S, 2022, RES POLICY, V51, DOI 10.1016/j.respol.2022.104604; Boguslav MR, 2023, J BIOMED INFORM, V143, DOI 10.1016/j.jbi.2023.104405; Boguslav MR, 2021, BIOINFORM ADV, V1, DOI 10.1093/bioadv/vbab012; Borchert F., 2022, AMIA ANN S PROC, V2021, P237; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Franchi F, 2016, CIRCULATION, V134, P780, DOI 10.1161/CIRCULATIONAHA.116.023402; Greenberg Steven A, 2009, BMJ, V339, pb2680, DOI 10.1136/bmj.b2680; Herrera-perez D, 2019, ELIFE, V8, DOI 10.7554/eLife.45183; Ioannidis JPA, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005468; Ioannidis JPA, 2005, JAMA-J AM MED ASSOC, V294, P218, DOI 10.1001/jama.294.2.218; Ioannidis JPA, 2005, J CLIN EPIDEMIOL, V58, P543, DOI 10.1016/j.jclinepi.2004.10.019; Kunisch S, 2023, INT J MANAG REV, V25, P240, DOI 10.1111/ijmr.12335; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lahav D, 2022, AAAI CONF ARTIF INTE, P11982; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li Y., 2024, PLOS ONE, V19, P1; Lin J, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-423; McMahan P, 2021, AM SOCIOL REV, V86, P341, DOI 10.1177/0003122421996323; OpenAI, 2023, Introducing chatgpt; Qi B., ARXIV; Rosemblat G, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103275; Sainz O., FIND ASS COMP LING E, P10776; Sosa DN, 2023, 61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2, P694; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Trinquart L, 2016, INT J EPIDEMIOL, V45, P251, DOI 10.1093/ije/dyv184; Truhn D, 2023, NAT MED, DOI 10.1038/s41591-023-02594-z; Vaid A, 2023, LANCET DIGIT HEALTH, V5, pE855, DOI 10.1016/S2589-7500(23)00202-9; Valina C, 2020, J AM COLL CARDIOL, V76, P2436, DOI 10.1016/j.jacc.2020.09.584; Wang Q., ARXIV; Wei JS, 2022, ADV NEUR IN; White ElizabethK., 2010, PATTERN BASED EXTRAC; Yu Bei., 2013, P 76 ASIST ANN M CLO, P1, DOI DOI 10.1002/MEET.14505001084; Zhao W., 2024, P ISKO 2024 18 INT S	36	0	0	8	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 17	2024	31	7					1551	1560		10.1093/jamia/ocae100	http://dx.doi.org/10.1093/jamia/ocae100		MAY 2024	10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	UT4M3	38758667				2024-07-03	WOS:001224882000001
J	Crawford, J; Vallis, C; Yang, JH; Fitzgerald, R; O'Dea, C				Crawford, Joseph; Vallis, Carmen; Yang, Jianhua; Fitzgerald, Rachel; O'Dea, Christine			Editorial: Artifiicial Intelligence is Awesome, but Good Teaching Should Always Come First.	JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE			English	Article						ChatGPT; Bard; Andragogy; AIED; large language model; higher education	HIGHER-EDUCATION; SOCIAL MEDIA	The explosion of generative artificial intelligence into the mainstream of society some twelve months ago has seriously challenged learning and teaching practice. Since then, AI companies such as OpenAI are constantly improving their language models and releasing new features to make them more capable and useful. So, given there have been many disruptors in the past and emerging disruptions in the present, what can we learn in this situation, where Generative AI stands poised to challenge the purpose and relevance of assessment models? From our examples, disruptive technologies only have a major impact when they positively transform practice and are informed by pedagogic models and learning theory. GenAI as a disruptor is only likely to have this positive impact when it informs quality learning and teaching practice. We should be focused on the opportunities that GenAI now presents to higher education. It is argued here and elsewhere that the relative weakness of GenAI is that it creates poor quality output, delivering uninformed, incorrect, biased and bland responses. In itself, this offers opportunities for 'teachable moments' (Newell et al, 2023) and gives us room to support students with their capabilities in an AI informed world. Historically, these opportunities enable higher education to grow and progress. What we have learned so far would appears to be that for research to contribute to the literature, they needed to be informed by it. Likewise, need to ensure that pedagogy, andragogy, and heutagogy come first. We also need to remember that people processes happen, artificial intelligence happens around them, and that artificial intelligence comes after human intelligence. Practitioner Notes1. For AI research to contribute to the literature, it needs to be informed by it.2. Scholars need to ensure that pedagogy, andragogy, and heutagogy come before artificial intelligence.3. People processes happen, artificial intelligence happens around them, and that artificial intelligence comes after human intelligence. 4. Artificial Intelligence comes after human intelligence	[Crawford, Joseph] Univ Tasmania, Hobart, Australia; [Vallis, Carmen] Univ Sydney, Sydney, Australia; [Yang, Jianhua] Univ Warwick, Warwick, England; [Fitzgerald, Rachel] Univ Queensland, Brisbane, Australia; [O'Dea, Christine] Univ Huddersfield, Huddersfield, England	University of Tasmania; University of Sydney; University of Warwick; University of Queensland; University of Huddersfield	Crawford, J (corresponding author), Univ Tasmania, Hobart, Australia.	joseph.crawford@utas.edu.au; carmen.vallis@sydney.edu.au; jianhua.yang@warwick.ac.uk; rachel.fitzgerald@uq.edu.au; x.odea@hud.ac.uk						Abeysekera L, 2015, HIGH EDUC RES DEV, V34, P1, DOI 10.1080/07294360.2014.934336; [Anonymous], 2016, Learning: Research and Practice, DOI [10.1080/23735082.2016.1210198, DOI 10.1080/23735082.2016.1210198]; Baker J., 2000, CIC INFORM TECHNOLOG; Baker J., 2016, P 1 ANN HIGH ED FLIP; Bearman M, 2023, BRIT J EDUC TECHNOL, DOI 10.1111/bjet.13337; Belland BR, 2013, EDUC PSYCHOL-US, V48, P243, DOI 10.1080/00461520.2013.838920; Belot H., 2023, The Guardian3 November; Blaschke LM, 2012, INT REV RES OPEN DIS, V13, P56, DOI 10.19173/irrodl.v13i1.1076; Boussen S, 2023, BRIT J ANAESTH, V131, pE120, DOI 10.1016/j.bja.2023.06.065; Carvalho L., 2022, Computers and Education: Artificial Intelligence, V3, DOI [10.1016/j.caeai.2022.100053, DOI 10.1016/J.CAEAI.2022.100053]; Chen JB, 2023, NEURAL NETWORKS, V164, P521, DOI 10.1016/j.neunet.2023.04.045; Choi-Lundberg DL, 2023, AUSTRALAS J EDUC TEC, V39, P133, DOI 10.14742/ajet.7615; Chugh R, 2018, EDUC INF TECHNOL, V23, P605, DOI 10.1007/s10639-017-9621-2; Cowling MA, 2022, J UNIV TEACH LEARN P, V19; Crawford J., 2023, J Univ Teach Learn Pract, V20, P1; Crawford J, 2023, INT EDUC J, V22, P7; Crompton H, 2018, COMPUT EDUC, V123, P53, DOI 10.1016/j.compedu.2018.04.007; Davis CHF, 2015, COMMUNITY COLL J RES, V39, P409, DOI 10.1080/10668926.2013.828665; Deslauriers L, 2019, P NATL ACAD SCI USA, V116, P19251, DOI 10.1073/pnas.1821936116; Dumbu E., 2012, European Journal of Business and Management, V4, P79; Eager B, 2023, J UNIV TEACH LEARN P, V20; Friesen N, 2012, J COMPUT ASSIST LEAR, V28, P183, DOI 10.1111/j.1365-2729.2011.00426.x; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Ifenthaler D, 2020, ETR&D-EDUC TECH RES, V68, P1961, DOI 10.1007/s11423-020-09788-z; Jones H., 2023, Technology-Enhanced Learning and the Virtual University. University Development and Administration, DOI [10.1007/978-981-19-9438-8_11-1, DOI 10.1007/978-981-19-9438-8_11-1]; Khosravi H., 2022, Comput. Educ. Artif. Intell., V3, DOI [DOI 10.1016/J.CAEAI.2022.100074, 10.1016/j.caeai, DOI 10.1016/J.CAEAI]; Knight S, 2020, J WRIT RES, V12, P141, DOI 10.17239/jowr-2020.12.01.06; Knowles M., 2013, Boundaries of adult learning, P82; Koh J., 2022, Collaborating with AIed for better studentteacher reconnection, DOI [10.14742/apubs.2022.126, DOI 10.14742/APUBS.2022.126]; Kolb DA., 2015, EXPERIENTIAL LEARNIN, DOI DOI 10.1016/B978-0-7506-7223-8.50017-4; Lodge JM, 2023, AUSTRALAS J EDUC TEC, V39, P18, DOI 10.14742/ajet.8695; Neumann M, 2021, 2021 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2021), DOI 10.1109/FIE49875.2021.9637344; Newell S., Using generative AI effectively in higher education: Sustainable and ethical artificial intelligence for the common good; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Purvis A., 2024, Journal of University Teaching and Learning Practice; Riley M, 1999, SPEECH COMMUN, V29, P209, DOI 10.1016/S0167-6393(99)00037-0; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sadaf A, 2012, COMPUT EDUC, V59, P937, DOI 10.1016/j.compedu.2012.04.001; Saettler Paul., 2004, The Evolution of American Educational Technology; Safi M, 2019, AIRCR ENG AEROSP TEC, V91, P1187, DOI 10.1108/AEAT-09-2018-0241; Sankey M.D., 2023, Technology-Enhanced Learning and the Virtual University. University Development and Administration, DOI [10.1007/978-981-99-4170-4_31, DOI 10.1007/978-981-99-4170-4_31]; Smolansky A, 2023, PROCEEDINGS OF THE TENTH ACM CONFERENCE ON LEARNING @ SCALE, L@S 2023, P378, DOI 10.1145/3573051.3596191; Tess PA, 2013, COMPUT HUM BEHAV, V29, pA60, DOI 10.1016/j.chb.2012.12.032; Texas Standard, 2020, Texas Standard; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Vallis C., 2023, Postdigital Science and Education, P1, DOI [10.1007/s42438-023-00407-7, DOI 10.1007/S42438-023-00407-7]; Yang S.J.H., 2021, Computers and Education: Artificial Intelligence, V2, P1, DOI [DOI 10.1016/J.CAEAI.2021.100008, 10.1016/j.caeai.2021.100008]	47	0	0	30	33	UNIV WOLLONGONG	WOLLONGONG	NORTHFIELDS AVE, WOLLONGONG, NSW 2522, AUSTRALIA	1449-9789			J UNIV TEACH LEARN P	J. Univ. Teach. Learn. Pract.		2023	20	7							01	10.53761/1.20.7.01	http://dx.doi.org/10.53761/1.20.7.01			14	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Y2RE3		gold, Green Submitted			2024-07-03	WOS:001103781300009
J	Maida, E; Moccia, M; Palladino, R; Borriello, G; Affinito, G; Clerico, M; Repice, AM; Di Sapio, A; Iodice, R; Spiezia, AL; Sparaco, M; Miele, G; Bile, F; Scandurra, C; Ferraro, D; Stromillo, ML; Docimo, R; De Martino, A; Mancinelli, L; Abbadessa, G; Smolik, K; Lorusso, L; Leone, M; Leveraro, E; Lauro, F; Trojsi, F; Streito, LM; Gabriele, F; Marinelli, F; Ianniello, A; De Santis, F; Foschi, M; De Stefano, N; Morra, VB; Bisecco, A; Coghe, G; Cocco, E; Romoli, M; Corea, F; Leocani, L; Frau, J; Sacco, S; Inglese, M; Carotenuto, A; Lanzillo, R; Padovani, A; Triassi, M; Bonavita, S; Lavorgna, L				Maida, Elisabetta; Moccia, Marcello; Palladino, Raffaele; Borriello, Giovanna; Affinito, Giuseppina; Clerico, Marinella; Repice, Anna Maria; Di Sapio, Alessia; Iodice, Rosa; Spiezia, Antonio Luca; Sparaco, Maddalena; Miele, Giuseppina; Bile, Floriana; Scandurra, Cristiano; Ferraro, Diana; Stromillo, Maria Laura; Docimo, Renato; De Martino, Antonio; Mancinelli, Luca; Abbadessa, Gianmarco; Smolik, Krzysztof; Lorusso, Lorenzo; Leone, Maurizio; Leveraro, Elisa; Lauro, Francesca; Trojsi, Francesca; Streito, Lidia Mislin; Gabriele, Francesca; Marinelli, Fabiana; Ianniello, Antonio; De Santis, Federica; Foschi, Matteo; De Stefano, Nicola; Morra, Vincenzo Brescia; Bisecco, Alvino; Coghe, Giancarlo; Cocco, Eleonora; Romoli, Michele; Corea, Francesco; Leocani, Letizia; Frau, Jessica; Sacco, Simona; Inglese, Matilde; Carotenuto, Antonio; Lanzillo, Roberta; Padovani, Alessandro; Triassi, Maria; Bonavita, Simona; Lavorgna, Luigi		Italian Soc Neurology SIN	ChatGPT vs. neurologists: a cross-sectional study investigating preference, satisfaction ratings and perceived empathy in responses among people living with multiple sclerosis	JOURNAL OF NEUROLOGY			English	Article; Early Access						Artificial intelligence; Machine learning; Multiple sclerosis; Large language model	ARTIFICIAL-INTELLIGENCE; HEALTH; INFORMATION; DEPRESSION; VALIDITY	Background ChatGPT is an open-source natural language processing software that replies to users' queries. We conducted a cross-sectional study to assess people living with Multiple Sclerosis' (PwMS) preferences, satisfaction, and empathy toward two alternate responses to four frequently-asked questions, one authored by a group of neurologists, the other by ChatGPT. Methods An online form was sent through digital communication platforms. PwMS were blind to the author of each response and were asked to express their preference for each alternate response to the four questions. The overall satisfaction was assessed using a Likert scale (1-5); the Consultation and Relational Empathy scale was employed to assess perceived empathy. Results We included 1133 PwMS (age, 45.26 +/- 11.50 years; females, 68.49%). ChatGPT's responses showed significantly higher empathy scores (Coeff = 1.38; 95% CI = 0.65, 2.11; p > z < 0.01), when compared with neurologists' responses. No association was found between ChatGPT' responses and mean satisfaction (Coeff = 0.03; 95% CI = - 0.01, 0.07; p = 0.157). College graduate, when compared with high school education responder, had significantly lower likelihood to prefer ChatGPT response (IRR = 0.87; 95% CI = 0.79, 0.95; p < 0.01). Conclusions ChatGPT-authored responses provided higher empathy than neurologists. Although AI holds potential, physicians should prepare to interact with increasingly digitized patients and guide them on responsible AI use. Future development should consider tailoring AIs' responses to individual characteristics. Within the progressive digitalization of the population, ChatGPT could emerge as a helpful support in healthcare management rather than an alternative.	[Maida, Elisabetta; Sparaco, Maddalena; Miele, Giuseppina; Bile, Floriana; Abbadessa, Gianmarco; Trojsi, Francesca; Bonavita, Simona; Lavorgna, Luigi] Univ Campania Luigi Vanvitelli, Dept Adv Med & Surg Sci, Via Pansini 5, I-80131 Naples, Italy; [Moccia, Marcello] Univ Naples Federico II, Dept Mol Med & Med Biotechnol, Naples, Italy; [Moccia, Marcello; Spiezia, Antonio Luca] Policlin Federico II Univ Hosp, Multiple Sclerosis Unit, Naples, Italy; [Palladino, Raffaele; Affinito, Giuseppina; Triassi, Maria] Univ Federico II Naples, Dept Publ Hlth, I-80131 Naples, Italy; [Palladino, Raffaele] Imperial Coll London, Dept Primary Care & Publ Hlth, London, England; [Borriello, Giovanna; Ianniello, Antonio] Sapienza Univ Rome, Dept Human Neurosci, Rome, Italy; [Clerico, Marinella; Streito, Lidia Mislin] Univ Torino, Dipartimento Sci Clin & Biol, Turin, Italy; [Repice, Anna Maria] Careggi Univ Hosp, Dept Neurol 2, Florence, Italy; [Repice, Anna Maria] Careggi Univ Hosp, Tuscan Reg Multiple Sclerosis Referral Ctr, Florence, Italy; [Di Sapio, Alessia] Dept Neurol, AOU San Luigi Gonzaga, Turin, Italy; [Di Sapio, Alessia] AOU San Luigi Gonzaga, Multiple Sclerosis Reg Referral Ctr, Turin, Italy; [Iodice, Rosa; Scandurra, Cristiano; Lauro, Francesca; Morra, Vincenzo Brescia; Carotenuto, Antonio; Lanzillo, Roberta] Univ Naples Federico II, Dept Neurosci Reprod Sci & Odontostomatol, Naples, Italy; [Ferraro, Diana] Azienda Osped Univ Modena, Azienda Ospedaliero Universitaria Modena, Modena, Emilia Romagna, Italy; [Ferraro, Diana; Smolik, Krzysztof] Univ Modena & Reggio Emilia, Dept Biomed Metab & Neural Sci, Modena, Italy; [Stromillo, Maria Laura; De Stefano, Nicola] Univ Siena, Dept Med Surg & Neurosci, Siena, Italy; [Docimo, Renato; Bisecco, Alvino] Univ Campania Luigi Vanvitelli, Dept Adv Med & Surg Sci, Multiple Sclerosis Ctr, Naples, Italy; [De Martino, Antonio] Magna Graecia Univ Catanzaro, Inst Neurol, Catanzaro, Italy; [Mancinelli, Luca; Romoli, Michele] Bufalini Hosp, Neurol Unit, Local Hlth Agcy Romagna, Cesena, Italy; [Abbadessa, Gianmarco] Imperial Coll London, Dept Brain Sci, London W120BZ, England; [Lorusso, Lorenzo] ASSTLecco, Neurosci Dept ASSTLecco, Neurol Unit, Neurosci Dept, I-23807 Merate, Italy; [Leone, Maurizio] Fdn IRCCS Casa Sollievo Sofferenza, Neurol Unit, I-71013 San Giovanni Rotondo, Italy; [Leveraro, Elisa; Inglese, Matilde] Univ Genoa, Dept Neurosci Rehabil Ophthalmol Genet Maternal &, Genoa, Italy; [Leveraro, Elisa; Inglese, Matilde] Osped Policlin San Martino IRCCS, Dept Neurol, Genoa, Italy; [Gabriele, Francesca; Foschi, Matteo; Sacco, Simona] Univ Aquila, Dept Biotechnol & Appl Clin Sci, Laquila, Italy; [Marinelli, Fabiana] Fabrizio Spaziani Hosp, Multiple Sclerosis Ctr, Neurol Unit, Frosinone, Italy; [De Santis, Federica] ASL 1 Avezzano Sulmona, Dept Neurol, Laquila, Italy; [De Santis, Federica] ASL 1 Avezzano Sulmona, Stroke Unit Avezzano Sulmona, Laquila, Italy; [Foschi, Matteo] S Maria Croci Hosp, S Maria delle Croci Hosp, Dept Neurosci, AUSL Romagna, Ravenna, Italy; [Coghe, Giancarlo; Cocco, Eleonora; Frau, Jessica] Univ Cagliari, Binaghi Hosp, Multiple Sclerosis Ctr, Dept Med Sci & Publ Hlth, Cagliari, Italy; [Corea, Francesco] Azienda USL Umbria 2, Dipartimento Neurol, Osped Foligno, Terni, Italy; [Leocani, Letizia] Univ Vita Salute San Raffaele, Milan, Italy; [Leocani, Letizia] IRCCS Sci Inst San Raffaele, Inst Expt Neurol INSPE, Expt Neurophysiol Unit, Milan, Italy; [Padovani, Alessandro] Azienda Socio Sanit Terr Spedali Civili, Unit Neurol, Brescia, Italy; [Padovani, Alessandro] Univ Brescia, Dept Clin & Expt Sci, Brescia, Italy	Universita della Campania Vanvitelli; University of Naples Federico II; University of Naples Federico II; Imperial College London; Sapienza University Rome; University of Turin; University of Florence; Azienda Ospedaliero Universitaria Careggi; University of Florence; Azienda Ospedaliero Universitaria Careggi; University of Naples Federico II; Universita di Modena e Reggio Emilia; Universita di Modena e Reggio Emilia Hospital; Universita di Modena e Reggio Emilia; University of Siena; Universita della Campania Vanvitelli; Magna Graecia University of Catanzaro; Imperial College London; University of Genoa; University of Genoa; University of L'Aquila; AUSL della Romagna; University of Cagliari; Vita-Salute San Raffaele University; University of Brescia	Bonavita, S (corresponding author), Univ Campania Luigi Vanvitelli, Dept Adv Med & Surg Sci, Via Pansini 5, I-80131 Naples, Italy.	simona.bonavita@unicampania.it	Foschi, Matteo/ABR-7231-2022; Padovani, Andrea/AAX-9550-2020; Carotenuto, Antonio/AAE-1249-2020; Sacco, Simona/I-5253-2012; Scandurra, Cristiano/M-2456-2017	Foschi, Matteo/0000-0002-0321-7155; Padovani, Andrea/0000-0003-1145-5257; Carotenuto, Antonio/0000-0002-1574-9693; Sacco, Simona/0000-0003-0651-1939; Palladino, Raffaele/0000-0002-3437-812X; , Maria Laura/0000-0001-6909-623X; Scandurra, Cristiano/0000-0003-1790-3997	Universit degli Studi della Campania Luigi Vanvitelli	Universit degli Studi della Campania Luigi Vanvitelli	No Statement Available	Afzal HMR, 2022, MULT SCLER J, V28, P849, DOI 10.1177/1352458520966298; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Beswick E, 2022, BMC PSYCHOL, V10, DOI 10.1186/s40359-022-00949-8; Brigo F, 2018, MULT SCLER RELAT DIS, V20, P210, DOI 10.1016/j.msard.2018.02.001; Charness N, 2022, CURR DIR PSYCHOL SCI, V31, P187, DOI 10.1177/09637214211068144; ChatGPT, about us; ChatGPT Statistics, 2023, Trends and the Future Perspectives; Chua V, 2022, J MED INTERNET RES, V24, DOI 10.2196/33372; D'Andrea A, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20021076; De Meo E, 2021, JAMA NEUROL, V78, P414, DOI 10.1001/jamaneurol.2020.4920; DELLORLETTA F., 2011, P 2 WORKSH SPEECH LA, P73; Fan WM, 2010, COMPUT HUM BEHAV, V26, P132, DOI 10.1016/j.chb.2009.10.015; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Haluza D, 2017, HEALTH COMMUN, V32, P1342, DOI 10.1080/10410236.2016.1220044; Hatcher-Martin JM, 2021, NEUROLOGY, V97, P334, DOI 10.1212/WNL.0000000000012185; Herzer KR, 2021, JAMA-J AM MED ASSOC, V325, P429, DOI 10.1001/jama.2020.24955; Inojosa H, 2023, NEUROL RES PRACT, V5, DOI 10.1186/s42466-023-00270-8; Jia XY, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9121740; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Kaya F, 2024, INT J HUM-COMPUT INT, V40, P497, DOI 10.1080/10447318.2022.2151730; Kroenke K, 2003, MED CARE, V41, P1284, DOI 10.1097/01.MLR.0000093487.78664.3C; Lavorgna L, 2018, MULT SCLER RELAT DIS, V25, P175, DOI 10.1016/j.msard.2018.07.046; Lucisano P., 1988, Scuola e citt, V3, P110; Madrigal L, 2019, J MED INTERNET RES, V21, DOI 10.2196/11240; Martikainen S, 2022, PSYCHOSOM MED, V84, P513, DOI 10.1097/PSY.0000000000001055; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Mercer SW, 2004, FAM PRACT, V21, P699, DOI 10.1093/fampra/cmh621; National Research Council, 2000, How people learn: Brain, mind, experience, and School: Expanded Edition; neuro, Digital Technology, Web and Social Media Study Group; Ortiz M, 2023, MULT SCLER RELAT DIS, V74, DOI 10.1016/j.msard.2023.104725; Patten SB, 2015, MULT SCLER J, V21, P1064, DOI 10.1177/1352458514559297; randomizer, Research Randomizer; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; van Laar E, 2020, SAGE OPEN, V10, DOI 10.1177/2158244019900176; Vandenbroucke JP, 2007, EPIDEMIOLOGY, V18, P805, DOI 10.1097/EDE.0b013e3181577511; Wang YJ, 2023, J GEN INTERN MED, V38, P428, DOI 10.1007/s11606-022-07784-y; Wu MJ, 2022, COMPUT HUM BEHAV REP, V7, DOI 10.1016/j.chbr.2022.100206; Xie ZZ, 2022, J MED INTERNET RES, V24, DOI 10.2196/25959; Zhao YXC, 2022, J MED INTERNET RES, V24, DOI 10.2196/42447; Zivadinov R, 2022, J NEUROL NEUROSUR PS, V93, P1128, DOI 10.1136/jnnp-2022-329333	42	1	1	2	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0340-5354	1432-1459		J NEUROL	J. Neurol.	2024 APR 3	2024										10.1007/s00415-024-12328-x	http://dx.doi.org/10.1007/s00415-024-12328-x		APR 2024	10	Clinical Neurology	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	MX5Q7	38568227	hybrid			2024-07-03	WOS:001196952600003
C	Liu, RX; Zenke, C; Liu, C; Holmes, A; Thornton, P; Malan, DJ			Assoc Computing Machinery	Liu, Rongxin; Zenke, Carter; Liu, Charlie; Holmes, Andrew; Thornton, Patrick; Malan, David J.			Teaching CS50 with AI Leveraging Generative Artificial Intelligence in Computer Science Education	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		AI; artificial intelligence; generative AI; large language models; LLMs		In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor." Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.	[Liu, Rongxin; Zenke, Carter; Liu, Charlie; Holmes, Andrew; Thornton, Patrick; Malan, David J.] Harvard Univ, Cambridge, MA 02138 USA	Harvard University	Liu, RX (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.	rongxinliu@cs50.harvard.edu; carter@cs50.harvard.edu; charlie.liu@yale.edu; aholmes@college.harvard.edu; patrickthornton@college.harvard.edu; malan@harvard.edu			Ed; GitHub; Microsoft; OpenAI	Ed; GitHub; Microsoft(Microsoft); OpenAI	Many thanks to Ed, GitHub, Microsoft, and OpenAI for their support of this work. And many thanks as well to Brenda Anderson, Sophie Anderson, and Doug Lloyd for their assistance with this work.	Dai W., 2023, Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT, DOI DOI 10.35542/OSF.IO/HCGZJ; edstem, 2023, About us; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kabir S, 2024, Arxiv, DOI [arXiv:2308.02312, DOI 10.48550/ARXIV.2308.02312]; Lin SPN, 2022, Arxiv, DOI [arXiv:2205.14334, 10.48550/ARXIV.2205.14334]; Malan DJ, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P282, DOI 10.1145/3328778.3366940; Microsoft, 2023, Azure OpenAI; MikeWu Noah Goodman, 2021, ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback; OpenAI, 2023, GPT-4; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Reis Ruan, 2019, Evaluating Feedback Tools in Introductory Programming Classes, DOI [10.1109/FIE43999.2019.9028418, DOI 10.1109/FIE43999.2019.9028418]; Tsai ML, 2023, EDUC CHEM ENG, V44, P71, DOI 10.1016/j.ece.2023.05.001; Weissman Jeremy, 2023, ChatGPT is a Plague Upon Education; Zenke Carter, 2023, P 54 ACM TECHN S COM, V23, P1269, DOI [10.1145/3545947.3573249, DOI 10.1145/3545947.3573249]	14	1	1	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							750	756		10.1145/3626252.3630938	http://dx.doi.org/10.1145/3626252.3630938			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP					2024-07-03	WOS:001181240800110
J	Megahed, FM; Chen, YJ; Ferris, JA; Knoth, S; Jones-Farmer, LA				Megahed, Fadel M.; Chen, Ying-Ju; Ferris, Joshua A.; Knoth, Sven; Jones-Farmer, L. Allison			How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research? An exploratory study	QUALITY ENGINEERING			English	Article						Artificial intelligence; innovation engineer; large-language models; prompt engineering	CONTROL CHARTS; INNOVATION	Generative Artificial Intelligence (AI) models such as OpenAI's ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research. However, these tools are in the early stages of development and can be easily misused or misunderstood. In this paper, we give an overview of the development of Generative AI. Specifically, we explore ChatGPT's ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research. By investigating responses to structured prompts, we highlight the benefits and limitations of the results. Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch. We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive. However, in their current stages of development, some results are misleading and wrong. Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results.	[Megahed, Fadel M.; Ferris, Joshua A.; Jones-Farmer, L. Allison] Miami Univ, Farmer Sch Business, Oxford, OH USA; [Chen, Ying-Ju] Univ Dayton, Dept Math, Dayton, OH USA; [Knoth, Sven] Helmut Schmidt Univ, Dept Math & Stat, Hamburg, Germany	University System of Ohio; Miami University; University System of Ohio; University of Dayton; Helmut Schmidt University	Jones-Farmer, LA (corresponding author), Miami Univ, Farmer Sch Business, Oxford, OH 45056 USA.	farmerl2@miamioh.edu	Chen, Ying-Ju/AEY-9526-2022; Megahed, Fadel/ABB-9906-2021	Chen, Ying-Ju/0000-0002-6444-6859; Megahed, Fadel/0000-0003-2194-5110; Jones-Farmer, L. Allison/0000-0002-1529-1133				Agostinelli A., 2023, arXiv; ALWAN LC, 1988, J BUS ECON STAT, V6, P87, DOI 10.2307/1391421; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2018, Advances in Neural Information Processing Systems; Begel A, 2008, ESEM'08: PROCEEDINGS OF THE 2008 ACM-IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, P120; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Box GEP, 2012, QUAL ENG, V24, P20, DOI 10.1080/08982112.2012.627003; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chakraborti S, 2009, QUAL ENG, V21, P52, DOI 10.1080/08982110802445561; Chen M., 2021, ARXIV; Choi K., 2020, P 37 INT C MACHINE L, P13; Colosimo BM, 2021, J QUAL TECHNOL, V53, P443, DOI 10.1080/00224065.2021.1987806; Constantz J., 2023, BLOOMBERG; CROSIER RB, 1986, TECHNOMETRICS, V28, P187, DOI 10.2307/1269074; Devlin J., 2018, BERT PRE TRAINING DE; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gozalo-Brizuela R., 2023, ARXIV; Griffith E., 2023, NEW ARE BOOMS EV AM; Hockman KK, 2016, QUAL ENG, V28, P165, DOI 10.1080/08982112.2015.1083107; Huang S., 2022, GEN CREAT NEW WORLD; Huberts LCE, 2022, J QUAL TECHNOL, V54, P127, DOI 10.1080/00224065.2020.1828008; Jardim FS, 2020, J QUAL TECHNOL, V52, P198, DOI 10.1080/00224065.2019.1571345; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jones-Farmer LA, 2014, J QUAL TECHNOL, V46, P265, DOI 10.1080/00224065.2014.11917969; Karpas E. O., 2022, ARXIV; Kim K, 2003, J QUAL TECHNOL, V35, P317, DOI 10.1080/00224065.2003.11980225; Kirchenbauer J., 2023, arXiv; Knoth S, 2021, SEQUENTIAL ANAL, V40, P405, DOI 10.1080/07474946.2021.1940501; Korinek A., 2023, LANGUAGE MODELS COGN; Lim R., 2021, OPENAI; LUCAS JM, 1990, TECHNOMETRICS, V32, P1, DOI 10.2307/1269835; Maleki MR, 2018, COMPUT IND ENG, V126, P705, DOI 10.1016/j.cie.2018.10.008; Markov AA, 2006, SCI CONTEXT, V19, P591, DOI 10.1017/S0269889706001074; McKee F. D., 2022, ARXIV; Megahed FM, 2019, QUAL ENG, V31, P97, DOI 10.1080/08982112.2018.1530358; Megahed FM, 2015, FRONTIERS IN STATISTICAL QUALITY CONTROL 11, P29, DOI 10.1007/978-3-319-12355-4_3; Megahed FM, 2011, J QUAL TECHNOL, V43, P83, DOI 10.1080/00224065.2011.11917848; Mehdi Y., 2023, MICROSOFT BLOG; Michel J.-B., 2011, TEDXBOSTON; Montgomery D.C., 2020, INTRO STAT QUALITY C; Nature, 2023, AUTH IN SUBM GUID; Noorossana R., 2013, STAT ANAL PROFILE MO; OpenAI, COD COMPL; OpenAI, 2022, DALL E 2; Ouyang L., 2022, ARXIV; Radford A., 2018, IMPROVING LANGUAGE U; Ramesh K., 2023, ARXIV; Saleh NA, 2015, J QUAL TECHNOL, V47, P127, DOI 10.1080/00224065.2015.11918120; Schick T., 2023, ARXIV; Schulman J, 2022, Introducing chatgpt; Schwarz K, 2021, Advances in Neural Information Processing Systems, V34, P18126; Scrucca L., 2017, QUICK TOUR QCC; Scrucca L., 2004, R News, V1, P3; Sevilla J., 2022, ARXIV; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, DOI 10.1002/J.1538-7305.1948.TB00917.X]; Singer U., 2022, ARXIV; Singer U. S., 2023, ARXIV; Srinivasan R, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P41, DOI 10.1145/3442188.3445869; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Vaswani A, 2017, ADV NEUR IN, V30; Weese M, 2016, J QUAL TECHNOL, V48, P4, DOI 10.1080/00224065.2016.11918148; Wei J., 2022, GOOGLE RES BLOG NOV; Wei JH, 2022, PR MACH LEARN RES; Weisz J. D., 2023, ARXIV; Wells LJ, 2013, J INTELL MANUF, V24, P1267, DOI 10.1007/s10845-012-0665-2; Woodall William H., 2007, Prod., V17, P420; Zhang M, 2013, QUAL RELIAB ENG INT, V29, P209, DOI 10.1002/qre.1304; Zwetsloot I. M., 2023, MONITORING UNI UNPUB	71	14	14	29	118	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0898-2112	1532-4222		QUAL ENG	Qual. Eng.	APR 2	2024	36	2					287	315		10.1080/08982112.2023.2206479	http://dx.doi.org/10.1080/08982112.2023.2206479		MAY 2023	29	Engineering, Industrial; Statistics & Probability	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Mathematics	JV1Z6		Bronze, Green Submitted			2024-07-03	WOS:001009222000001
J	Jebali, F; Majumdar, A; Turck, C; Harabi, KE; Faye, MC; Muhr, E; Walder, JP; Bilousov, O; Michaud, A; Vianello, E; Hirtzlin, T; Andrieu, F; Bocquet, M; Collin, S; Querlioz, D; Portal, JM				Jebali, Fadi; Majumdar, Atreya; Turck, Clement; Harabi, Kamel-Eddine; Faye, Mathieu-Coumba; Muhr, Eloi; Walder, Jean-Pierre; Bilousov, Oleksandr; Michaud, Amadeo; Vianello, Elisa; Hirtzlin, Tifenn; Andrieu, Francois; Bocquet, Marc; Collin, Stephane; Querlioz, Damien; Portal, Jean-Michel			Powering AI at the edge: A robust, memristor-based binarized neural network with near-memory computing and miniaturized solar cell	NATURE COMMUNICATIONS			English	Article								Memristor-based neural networks provide an exceptional energy-efficient platform for artificial intelligence (AI), presenting the possibility of self-powered operation when paired with energy harvesters. However, most memristor-based networks rely on analog in-memory computing, necessitating a stable and precise power supply, which is incompatible with the inherently unstable and unreliable energy harvesters. In this work, we fabricated a robust binarized neural network comprising 32,768 memristors, powered by a miniature wide-bandgap solar cell optimized for edge applications. Our circuit employs a resilient digital near-memory computing approach, featuring complementarily programmed memristors and logic-in-sense-amplifier. This design eliminates the need for compensation or calibration, operating effectively under diverse conditions. Under high illumination, the circuit achieves inference performance comparable to that of a lab bench power supply. In low illumination scenarios, it remains functional with slightly reduced accuracy, seamlessly transitioning to an approximate computing mode. Through image classification neural network simulations, we demonstrate that misclassified images under low illumination are primarily difficult-to-classify cases. Our approach lays the groundwork for self-powered AI and the creation of intelligent sensors for various applications in health, safety, and environment monitoring. The authors present an AI engine with 32,768 memristors powered by a miniature solar cell. This circuit exploits near-memory computing, naturally adjusting its accuracy depending on the illumination level, and paves the way for self-powered AI.	[Jebali, Fadi; Faye, Mathieu-Coumba; Muhr, Eloi; Walder, Jean-Pierre; Bocquet, Marc; Portal, Jean-Michel] Aix Marseille Univ, Inst Materiaux Microelect & Nanosci Provence, CNRS, Marseille, France; [Majumdar, Atreya; Turck, Clement; Harabi, Kamel-Eddine; Collin, Stephane; Querlioz, Damien] Univ Paris Saclay, Ctr Nanosci & Nanotechnol, CNRS, Palaiseau, France; [Faye, Mathieu-Coumba; Vianello, Elisa; Hirtzlin, Tifenn; Andrieu, Francois] Univ Grenoble Alpes, CEA, LETI, Grenoble, France; [Bilousov, Oleksandr; Michaud, Amadeo; Collin, Stephane] Inst Photovolta Ile Defrance IPVF, Palaiseau, France	Centre National de la Recherche Scientifique (CNRS); Aix-Marseille Universite; Universite Paris Cite; Institut Polytechnique de Paris; Ecole Polytechnique; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA); CEA	Portal, JM (corresponding author), Aix Marseille Univ, Inst Materiaux Microelect & Nanosci Provence, CNRS, Marseille, France.; Querlioz, D (corresponding author), Univ Paris Saclay, Ctr Nanosci & Nanotechnol, CNRS, Palaiseau, France.	damien.querlioz@c2n.upsaclay.fr; jean-michel.portal@univ-amu.fr	Portal, Jean-Michel/F-8474-2011	Vianello, Elisa/0000-0002-8868-9951	EC | EU Framework Programme for Research and Innovation H2020 | H2020 Priority Excellent Science | H2020 European Research Council (H2020 Excellent Science - European Research Council) [101007321]; European Union [715872]; European Research Council [ANR-18-CE24-0009]; Agence Nationale de la Recherche through the NEURONIC [ANR-IEED-002-01]; French Government [ANR-22-PEEL-0010]; France 2030 government grant	EC | EU Framework Programme for Research and Innovation H2020 | H2020 Priority Excellent Science | H2020 European Research Council (H2020 Excellent Science - European Research Council)(European Research Council (ERC)); European Union(European Union (EU)); European Research Council(European Research Council (ERC)); Agence Nationale de la Recherche through the NEURONIC(Agence Nationale de la Recherche (ANR)); French Government; France 2030 government grant	This work received funding within the ECSEL Joint Undertaking (JU) project storAIge in collaboration with the European Union's H2020 research and innovation program and National Authorities, under grant agreement numbers 101007321. This work was also supported by European Research Council starting grant NANOINFER (reference: 715872), by the Agence Nationale de la Recherche through the NEURONIC (ANR-18-CE24-0009) grant, by the French Government in the framework of the "Programme d'Investissement d'Avenir" (ANR-IEED-002-01), and with the support of the cleanroom RENATECH network. It also benefits from a France 2030 government grant managed by the French National Research Agency (ANR-22-PEEL-0010). The authors would like to thank J. Grollier and L. Hutin for discussion and invaluable feedback. Parts of this manuscript were revised with the assistance of a large language model (OpenAI ChatGPT).	Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5; Ben Slimane A, 2020, PROG PHOTOVOLTAICS, V28, P393, DOI 10.1002/pip.3249; Bocquet M, 2018, INT EL DEVICES MEET; Buschjäger S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P673, DOI 10.23919/DATE51398.2021.9473918; Chang YF, 2020, INT RELIAB PHY SYM, DOI 10.1109/irps45951.2020.9128359; Chen HL, 2019, NAT ENERGY, V4, P761, DOI 10.1038/s41560-019-0434-y; Cui LZ, 2018, INT J MACH LEARN CYB, V9, P1399, DOI 10.1007/s13042-018-0834-5; Deaville P, 2021, PROC EUR SOLID-STATE, P75, DOI 10.1109/ESSCIRC53450.2021.9567807; Golonzka O, 2019, S VLSI TECH, pT230, DOI [10.23919/vlsit.2019.8776570, 10.23919/VLSIT.2019.8776570]; Harabi KE, 2023, NAT ELECTRON, V6, P52, DOI 10.1038/s41928-022-00886-9; Hirtzlin T, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P288, DOI 10.1109/aicas.2019.8771544; Hirtzlin T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01383; Hubara I, 2016, ADV NEUR IN, V29; Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2; Jung S, 2022, NATURE, V601, P211, DOI 10.1038/s41586-021-04196-6; Khaddam-Aljameh R, 2022, IEEE J SOLID-ST CIRC, V57, P1027, DOI 10.1109/JSSC.2022.3140414; Krizhevsky A., 2009, Rep. TR-2009; Ku ML, 2016, IEEE COMMUN SURV TUT, V18, P1384, DOI 10.1109/COMST.2015.2497324; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li C, 2020, IEEE INT MEM WORKSH, P91, DOI 10.1109/imw48823.2020.9108112; Loshchilov I, 2016, P INT C LEARNING REP; Massiot I, 2020, NAT ENERGY, V5, P959, DOI 10.1038/s41560-020-00714-4; Modha DS, 2023, SCIENCE, V382, P329, DOI 10.1126/science.adh1174; Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441; Qadri YA, 2020, IEEE COMMUN SURV TUT, V22, P1121, DOI 10.1109/COMST.2020.2973314; Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281; Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12; Srivishnu KS, 2023, SOL ENERGY, V264, DOI 10.1016/j.solener.2023.112057; Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wan WE, 2022, NATURE, V608, P504, DOI 10.1038/s41586-022-04992-8; Wan WE, 2020, ISSCC DIG TECH PAP I, P498, DOI 10.1109/ISSCC19947.2020.9062979; Wang ZR, 2018, NAT ELECTRON, V1, P137, DOI 10.1038/s41928-018-0023-2; Warden P., 2019, Tinyml: Machine learning with tensorflow lite on arduino and ultra-low-power microcontrollers; Wenyu Zhao, 2021, IEEE Journal on Miniaturization for Air and Space Systems, V2, P25, DOI 10.1109/JMASS.2020.3034205; Xue CX, 2021, NAT ELECTRON, V4, P81, DOI 10.1038/s41928-020-00505-5; yann.lecun, The MNIST Database of Handwritten Digits; Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4; Yoon S, 2018, IEEE T CIRCUITS-II, V65, P1974, DOI 10.1109/TCSII.2018.2794299; Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840; Zhao WS, 2014, IEEE T CIRCUITS-I, V61, P443, DOI 10.1109/TCSI.2013.2278332	43	1	1	37	37	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2041-1723		NAT COMMUN	Nat. Commun.	JAN 25	2024	15	1							741	10.1038/s41467-024-44766-6	http://dx.doi.org/10.1038/s41467-024-44766-6			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	GH0X0	38272896	Green Published, Green Submitted, gold			2024-07-03	WOS:001151669200020
J	Yang, JM; Walker, KC; Bekar-Cesaretli, AA; Hao, BR; Bhadelia, N; Joseph-McCarthy, D; Paschalidis, IC				Yang, Jingmei; Walker, Kenji C.; Bekar-Cesaretli, Ayse A.; Hao, Boran; Bhadelia, Nahid; Joseph-McCarthy, Diane; Paschalidis, Ioannis Ch.			Automating biomedical literature review for rapid drug discovery: Leveraging GPT-4 to expedite pandemic response	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						GPT-4; Large language model; Drug development; Target identification	TARGET IDENTIFICATION	Objective: The rapid expansion of the biomedical literature challenges traditional review methods, especially during outbreaks of emerging infectious diseases when quick action is critical. Our study aims to explore the potential of ChatGPT to automate the biomedical literature review for rapid drug discovery. Materials and Methods: We introduce a novel automated pipeline helping to identify drugs for a given virus in response to a potential future global health threat. Our approach can be used to select PubMed articles identifying a drug target for the given virus. We tested our approach on two known pathogens: SARS-CoV-2, where the literature is vast, and Nipah, where the literature is sparse. Specifically, a panel of three experts reviewed a set of PubMed articles and labeled them as either describing a drug target for the given virus or not. The same task was given to the automated pipeline and its performance was based on whether it labeled the articles similarly to the human experts. We applied a number of prompt engineering techniques to improve the performance of ChatGPT. Results: Our best configuration used GPT-4 by OpenAI and achieved an out-of-sample validation performance with accuracy/F1-score/sensitivity/specificity of 92.87%/88.43%/83.38%/97.82% for SARS-CoV-2 and 87.40%/ 73.90%/74.72%/91.36% for Nipah. Conclusion: These results highlight the utility of ChatGPT in drug discovery and development and reveal their potential to enable rapid drug target identification during a pandemic-level health emergency.	[Yang, Jingmei; Hao, Boran; Paschalidis, Ioannis Ch.] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA; [Yang, Jingmei; Hao, Boran; Paschalidis, Ioannis Ch.] Boston Univ, Div Syst Engn, Boston, MA 02215 USA; [Walker, Kenji C.; Joseph-McCarthy, Diane; Paschalidis, Ioannis Ch.] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA; [Bekar-Cesaretli, Ayse A.] Boston Univ, Dept Chem, Boston, MA USA; [Bhadelia, Nahid] Boston Univ, Chobanian & Avedisian Sch Med, Boston, MA USA; [Bhadelia, Nahid] Boston Univ, Ctr Emerging Infect Dis Policy & Res, Boston, MA USA; [Paschalidis, Ioannis Ch.] Boston Univ, Fac Comp & Data Sci, Boston, MA 02215 USA	Boston University; Boston University; Boston University; Boston University; Boston University; Boston University; Boston University	Paschalidis, IC (corresponding author), Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA.; Paschalidis, IC (corresponding author), Boston Univ, Div Syst Engn, Boston, MA 02215 USA.; Paschalidis, IC (corresponding author), Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.; Paschalidis, IC (corresponding author), Boston Univ, Fac Comp & Data Sci, Boston, MA 02215 USA.	yannisp@bu.edu		Joseph-McCarthy, Diane/0000-0001-9685-6177; Paschalidis, Ioannis/0000-0002-3343-2913; Bekar-Cesaretli, Ayse A./0000-0001-9122-4955	Boston University Kilachand Fund for Integrated Life Science and En-gineering	Boston University Kilachand Fund for Integrated Life Science and En-gineering	This research was partially supported by the NSF under grants CCF-2200052, DMS-1664644, IIS-1914792, and EECS-2317079, by the ONR under grant N00014-19-1-2571, by the DOE under grant DE-AC02-05CH11231, by the NIH under grant UL54 TR004130, and by the Boston University Kilachand Fund for Integrated Life Science and Engineering.r Boston University Kilachand Fund for Integrated Life Science and En-gineering.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Amini S, 2023, ALZHEIMERS DEMENT, V19, P946, DOI 10.1002/alz.12721; Bhadelia N, 2019, HEALTH SECUR, V17, P46, DOI 10.1089/hs.2018.0092; Blanco-González A, 2023, PHARMACEUTICALS-BASE, V16, DOI 10.3390/ph16060891; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cassetti MC, 2023, J INFECT DIS, V227, P1433, DOI 10.1093/infdis/jiac296; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Corsello A, 2023, CHILDREN-BASEL, V10, DOI 10.3390/children10040757; Datta S, 2024, J AM MED INFORM ASSN, V31, P375, DOI 10.1093/jamia/ocad218; Hao B., 2020, P 28 INT C COMP LING, P657, DOI [10.18653/v1/2020.coling-main.57, DOI 10.18653/V1/2020.COLING-MAIN.57]; Haze T, 2023, INT J MED INFORM, V180, DOI 10.1016/j.ijmedinf.2023.105283; Hecker N, 2012, NUCLEIC ACIDS RES, V40, pD1113, DOI 10.1093/nar/gkr912; Hu DQ, 2024, INT J MED INFORM, V183, DOI 10.1016/j.ijmedinf.2023.105321; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kambhampati Srinivas B S, 2020, J Clin Orthop Trauma, V11, pS304, DOI 10.1016/j.jcot.2020.04.030; Kojima T, 2022, ADV NEUR IN; Koscielny G, 2017, NUCLEIC ACIDS RES, V45, pD985, DOI 10.1093/nar/gkw1055; Law V, 2014, NUCLEIC ACIDS RES, V42, pD1091, DOI 10.1093/nar/gkt1068; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li YS, 2023, bioRxiv, DOI [10.1101/2023.06.29.543848, 10.1101/2023.06.29.543848, DOI 10.1101/2023.06.29.543848]; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Marani M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105482118; Nguyen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1324; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Tan RSYC, 2023, J AM MED INFORM ASSN, V30, P1657, DOI 10.1093/jamia/ocad133; Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5; Wei JS, 2022, ADV NEUR IN; Whirl-Carrillo M, 2012, CLIN PHARMACOL THER, V92, P414, DOI 10.1038/clpt.2012.96; Xu D, 2016, BIOINFORMATICS, V32, P3619, DOI 10.1093/bioinformatics/btw503; Yan C, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01038-3; Yang H, 2016, NUCLEIC ACIDS RES, V44, pD1069, DOI 10.1093/nar/gkv1230; Yun JY, 2023, INT J MED INFORM, V179, DOI 10.1016/j.ijmedinf.2023.105219; Zelikman Eric, 2022, Advances in Neural Information Processing Systems, V35, P15476; Zeng XX, 2020, CHEM SCI, V11, P1775, DOI 10.1039/c9sc04336e; Zhang Z., 2022, arXiv; Zhao AL, 2023, FRONT PHARMACOL, V14, DOI 10.3389/fphar.2023.1194216; Zhu HH, 2018, Arxiv, DOI arXiv:1810.10566	42	0	0	0	0	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056	1872-8243		INT J MED INFORM	Int. J. Med. Inform.	SEP	2024	189								105500	10.1016/j.ijmedinf.2024.105500	http://dx.doi.org/10.1016/j.ijmedinf.2024.105500			12	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Health Care Sciences & Services; Medical Informatics	UL1G2	38815316				2024-07-03	WOS:001248116900002
J	Dien, J				Dien, Joseph			Editorial: Generative artificial intelligence as a plagiarism problem	BIOLOGICAL PSYCHOLOGY			English	Editorial Material						Plagiarism; Large language models; ChatGPT; Artificial intelligence; Academic misconduct		There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology, the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved.	[Dien, Joseph] Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304 Benjamin Bldg, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Dien, J (corresponding author), Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304 Benjamin Bldg, College Pk, MD 20742 USA.	jdien07@mac.com		Dien, Joseph/0000-0001-6908-2612				American Psychological Association, 2020, Publication Manual of the American Psychological Association, V7th, DOI [10.1037/0000165-000, DOI 10.1037/0000165-000]; Biagioli M, 2012, INT J CULT PROP, V19, P453, DOI 10.1017/S0940739112000276; BLOOM PA, 1980, MEM COGNITION, V8, P631, DOI 10.3758/BF03213783; Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303; Chomsky N., 1998, Language and Meaning in Cognitive Science, DOI [10.4324/9780203055069, DOI 10.4324/9780203055069]; Demers T., 2023, Search Engine Land; Dien J, 1998, BEHAV RES METH INS C, V30, P34, DOI 10.3758/BF03209414; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fowler G.A., 2023, WE TESTED NEW CHATGP; Gal U., 2023, Ars Technica; Gasparyan AY, 2017, J KOREAN MED SCI, V32, P1220, DOI 10.3346/jkms.2017.32.8.1220; Jackson AF, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00385; Kirchner Jan Hendrik, 2023, OpenAIJanuary 31; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Levitt GeraldM., 2000, TURK CHESS AUTOMATON; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588; OpenAI, 2022, OpenA I; Penders B, 2018, J BIOETHIC INQ, V15, P29, DOI 10.1007/s11673-017-9825-6; Romero A., 2023, Fast Company; Ruby M., 2023, Towards Data Science; Shaffi S., 2023, The GuardianJanuary 23; Sheng E., 2023, CNBCApril 3; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Veale K., 2023, Does ChatGPT Have Privacy Issues?; Verma P, 2023, The Washington Post; Warstadt A., 2022, ALGEBRAIC STRUCTURES; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Xie Y, 2021, SCI ENG ETHICS, V27, DOI 10.1007/s11948-021-00314-9; Yorke J, 2009, INT J EDUC INTEGR, V5, P39	31	7	7	21	37	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0301-0511	1873-6246		BIOL PSYCHOL	Biol. Psychol.	JUL	2023	181								108621	10.1016/j.biopsycho.2023.108621	http://dx.doi.org/10.1016/j.biopsycho.2023.108621		JUL 2023	5	Psychology, Biological; Behavioral Sciences; Psychology; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Behavioral Sciences	FR1B3	37356702				2024-07-03	WOS:001147476500001
J	Balla, Y; Tirunagari, S; Windridge, D				Balla, Yashaswini; Tirunagari, Santosh; Windridge, David			Pediatrics in Artificial Intelligence Era: A Systematic Review on Challenges, Opportunities, and Explainability	INDIAN PEDIATRICS			English	Review						Artificial intelligence; Data science; Deep learning; Large language model	HEALTH	BackgroundThe emergence of artificial intelligence (AI) tools such as ChatGPT and Bard is disrupting a broad swathe of fields, including medicine. In pediatric medicine, AI is also increasingly being used across multiple subspecialties. However, the practical application of AI still faces a number of key challenges. Consequently, there is a requirement for a concise overview of the roles of AI across the multiple domains of pediatric medicine, which the current study seeks to address.AimTo systematically assess the challenges, opportunities, and explainability of AI in pediatric medicine.MethodologyA systematic search was carried out on peer-reviewed databases, PubMed Central, Europe PubMed Central, and grey literature using search terms related to machine learning (ML) and AI for the years 2016 to 2022 in the English language. A total of 210 articles were retrieved that were screened with PRISMA for abstract, year, language, context, and proximal relevance to research aims. A thematic analysis was carried out to extract findings from the included studies.ResultsTwenty articles were selected for data abstraction and analysis, with three consistent themes emerging from these articles. In particular, eleven articles address the current state-of-the-art application of AI in diagnosing and predicting health conditions such as behavioral and mental health, cancer, syndromic and metabolic diseases. Five articles highlight the specific challenges of AI deployment in pediatric medicines: data security, handling, authentication, and validation. Four articles set out future opportunities for AI to be adapted: the incorporation of Big Data, cloud computing, precision medicine, and clinical decision support systems. These studies collectively critically evaluate the potential of AI in overcoming current barriers to adoption.ConclusionAI is proving disruptive within pediatric medicine and is presently associated with challenges, opportunities, and the need for explainability. AI should be viewed as a tool to enhance and support clinical decision-making rather than a substitute for human judgement and expertise. Future research should consequently focus on obtaining comprehensive data to ensure the generalizability of research findings.	[Balla, Yashaswini] Alder Hey Childrens NHS Fdn Trust, Neurosci Dept, Liverpool, England; [Tirunagari, Santosh] Middlesex Univ, Dept Psychol, London, England; [Windridge, David] Middlesex Univ, Dept Comp Sci, London, England	Alder Hey Children's NHS Foundation Trust; Middlesex University; Middlesex University	Tirunagari, S (corresponding author), Middlesex Univ, Dept Psychol, London, England.	s.tirunagari@mdx.ac.uk		Tirunagari, Santosh/0000-0002-9064-1965; Windridge, David/0000-0001-5507-8516				Abdullah IS, 2023, CHATGPT DOCTORS MED; Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Amrit C, 2017, EXPERT SYST APPL, V88, P402, DOI 10.1016/j.eswa.2017.06.035; Anagnostopoulou P, 2020, INT J EMERG TECHNOL, V15, P95, DOI 10.3991/ijet.v15i06.11231; Aylward BS, 2023, J DEV BEHAV PEDIATR, V44, pE126, DOI 10.1097/DBP.0000000000001149; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Bravo A, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0472-9; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chen KC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73831-5; Clarke SLN, 2022, ARCH DIS CHILD, V107, P223, DOI 10.1136/archdischild-2020-321023; Davendralingam N, 2021, BRIT J RADIOL, V94, DOI 10.1259/bjr.20200975; Deliu M, 2020, CLIN EXP ALLERGY, V50, P315, DOI 10.1111/cea.13553; Elankeerthana R., 2022, 2022 6th International Conference on Trends in Electronics and Informatics (ICOEI), P1459, DOI 10.1109/ICOEI53556.2022.9777138; Fathi E, 2020, P I MECH ENG H, V234, P1051, DOI 10.1177/0954411920938567; Ferguson C, 2021, NUCLEIC ACIDS RES, V49, pD1507, DOI 10.1093/nar/gkaa994; Filipow N, 2022, BMJ OPEN RESPIR RES, V9, DOI 10.1136/bmjresp-2021-001165; Ge FF, 2020, J AFFECT DISORDERS, V264, P483, DOI 10.1016/j.jad.2019.11.079; Gupta P, 2018, CRIT CARE MED, V46, P30, DOI 10.1097/01.ccm.0000528115.33510.1b; Hunt X, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.543305; Jia JM, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00587; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kissos L, 2020, CHILD ABUSE NEGLECT, V109, DOI 10.1016/j.chiabu.2020.104755; Knake LA, 2023, PEDIATR RES, V93, P445, DOI 10.1038/s41390-022-01972-6; Lin HT, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002674; McCartney M, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k1752; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Ogundele Michael O, 2018, World J Clin Pediatr, V7, P9, DOI 10.5409/wjcp.v7.i1.9; Reid JE, 2019, CURR OPIN OPHTHALMOL, V30, P337, DOI 10.1097/ICU.0000000000000593; Saxe GN, 2017, BMC PSYCHIATRY, V17, DOI 10.1186/s12888-017-1384-1; Selçuk AA, 2019, TURK ARCH OTORHINOL, V57, P57, DOI 10.5152/tao.2019.4058; Shu LQ, 2019, WORLD J PEDIATR, V15, P105, DOI 10.1007/s12519-019-00255-1; Tirunagari S, 2016, IEEE INT WORKS MACH; Tornese G, 2020, EUR J MED GENET, V63, DOI 10.1016/j.ejmg.2019.01.004; van der Velden BHM, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102470; Vogl Thomas M., 2020, dg.o '20: The 21st Annual International Conference on Digital Government Research, P223, DOI 10.1145/3396956.3396971; Vokinger KN, 2021, COMMUN MED-LONDON, V1, DOI 10.1038/s43856-021-00028-w; Wu TE, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010111; Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068; Zhang MZ, 2011, INVEST OPHTH VIS SCI, V52, P5836, DOI 10.1167/iovs.10-5592; Zhu ZX, 2020, FRONT MOL BIOSCI, V7, DOI 10.3389/fmolb.2020.00115; Ziegler A, 2020, NERVENARZT, V91, P518, DOI 10.1007/s00115-020-00919-8	42	2	2	8	25	SPRINGER INDIA	NEW DELHI	7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001, INDIA	0019-6061	0974-7559		INDIAN PEDIATR	Indian Pediatrics	JUL	2023	60	7					561	569		10.1007/s13312-023-2936-8	http://dx.doi.org/10.1007/s13312-023-2936-8			9	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	N1OT7	37424120	hybrid			2024-07-03	WOS:001034797100014
J	Fox, JD				Fox, Joseph D.			Reporting on artificial intelligence use in entrepreneurship research: Using a model card	INTERNATIONAL JOURNAL OF ENTREPRENEURSHIP AND INNOVATION			English	Article; Early Access						artificial intelligence; entrepreneurship research; large language models; replicability		The study of artificial intelligence is of increasing importance in the entrepreneurial domain. Despite the popularity of many artificial intelligence models, experimental studies in entrepreneurship that apply models are subject to replicability issues if they are not properly reported on. This note is a call to adopt a method of reporting on artificial intelligence models commonly used in the open source software community to ensure progress in future studies and to offer researchers a reflective opportunity to consider the appropriateness of models they use in experimental studies.	[Fox, Joseph D.] Univ Akron, Coll Business, Dept Management, Akron, OH 44325 USA	University System of Ohio; University of Akron	Fox, JD (corresponding author), Univ Akron, Coll Business, Dept Management, Akron, OH 44325 USA.	jfox1@uakron.edu						Blagec K., 2022, Journal of Biomedical Informatics, P104274; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brinkerink J, 2023, INT J ENTREP INNOV, V24, P215, DOI 10.1177/14657503221074581; Cai TL, 2024, Arxiv, DOI arXiv:2305.17126; Chalmers D, 2021, ENTREP THEORY PRACT, V45, P1028, DOI 10.1177/1042258720934581; Chen LC, 2023, Arxiv, DOI arXiv:2306.03082; Crawford GC, 2022, ENTREP THEORY PRACT, V46, P779, DOI 10.1177/10422587211057422; Davidsson P., 2023, Journal of Business Venturing Insights, V20; Davidsson P., 2016, Researching entrepreneurship: conceptualization and design, V33; Girotra K., 2023, Ideas are Dimes a Dozen: Large language models for idea generation in innovation; Gruber M., 2023, Journal of Business Venturing Design, V3, P100017; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004; Kellogg KC, 2020, ACAD MANAG ANN, V14, P366, DOI 10.5465/annals.2018.0174; Lee P., 2023, Artificial Intelligence in Marketing, V20, P169; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Shepherd DA, 2021, J MANAGE, V47, P11, DOI 10.1177/0149206319900537; Short C., 2023, Journal of Business Venturing Insights, V19; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582	21	0	0	8	8	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1465-7503	2043-6882		INT J ENTREP INNOV	Int. J. Entrep. Innov.	2024 MAR 12	2024										10.1177/14657503241238691	http://dx.doi.org/10.1177/14657503241238691		MAR 2024	5	Business	Emerging Sources Citation Index (ESCI)	Business & Economics	KX6T0					2024-07-03	WOS:001183310900001
C	Li, C; Pang, B; Wang, WB; Hu, LS; Gordon, M; Marinova, D; Balducci, B; Shang, Y			IEEE	Li, Can; Pang, Bin; Wang, Wenbo; Hu, Lingshu; Gordon, Matthew; Marinova, Detelina; Balducci, Bitty; Shang, Yi			How Well Can Language Models Understand Politeness?	2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI			English	Proceedings Paper	IEEE Conference on Artificial Intelligence (IEEE CAI)	JUN 05-06, 2023	Santa Clara, CA	IEEE, IEEE Comp Soc, IEEE Signal Proc Soc, IEEE Syst, Man, & Cybernet Soc		BERT; ChatGPT; Large Language Model (LLM); Politeness Prediction		Politeness plays a key role in social communications. Previous work proposed an SVM-based computational method for predicting politeness using linguistic features on a corpus that contains Wikipedia and Stack Exchange requests data. To extend this prior work, we focus on evaluating the performance of state-of-the-art language models on politeness prediction using the same dataset. Two models are applied in this study. First, we fine-tune BERT on politeness data and then use the fine-tuned model for politeness prediction. Second, we use ChatGPT to predict politeness. The results show that both fine-tuned BERT and ChatGPT achieved better results than the state-of-the-art results on both Wikipedia and Stack Exchange data. Fine-tuned BERT outperforms zero shot ChatGPT, but ChatGPT can provide explanations for its prediction. Moreover, fine-tuned BERT outperforms human level performance by 2.28% on Wikipedia corpus.	[Li, Can; Pang, Bin; Wang, Wenbo; Shang, Yi] Univ Missouri, Dept Electr Engr & Comp Sci, Columbia, MO 65201 USA; [Hu, Lingshu] Washington & Lee Univ, Dept Business Adm, Lexington, VA USA; [Gordon, Matthew] Univ Missouri, Dept English, Columbia, MO USA; [Marinova, Detelina] Univ Missouri, Robert J Trulaske Sr Coll Business, Columbia, MO USA; [Balducci, Bitty] Washington State Univ, Carson Coll Business, Pullman, WA USA	University of Missouri System; University of Missouri Columbia; Washington & Lee University; University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia; Washington State University	Pang, B (corresponding author), Univ Missouri, Dept Electr Engr & Comp Sci, Columbia, MO 65201 USA.	lican@mail.missouri.edu; bpnrc@missouri.edu; wwr34@mail.missouri.edu; Ihu@wlu.edu; gordonmj@missouri.edu; marinovad@missouri.edu; bitty.balducci@wsu.edu; shangy@missouri.edu		Hu, Lingshu/0000-0003-0304-882X				Bramsen P., 2011, 49th Annual Meeting Of The Association For Computational Linguistics: Human Language Technologies - Volume 1, V1, P773; Brown Penelope., 1978, Politeness: Some Universals in Language Usage; Danescu-Niculescu-Mizil C, 2013, Arxiv, DOI arXiv:1306.6078; Holmes J., 2015, Power and Politeness in the Workplace: A Sociolinguistic Analysis of Talk at Work; Hu LS, 2022, 2022 IEEE 4TH INTERNATIONAL CONFERENCE ON COGNITIVE MACHINE INTELLIGENCE, COGMI, P125, DOI 10.1109/CogMI56440.2022.00027; Jenkins M, 2013, COMMUN RES, V40, P559, DOI 10.1177/0093650211420136; Li C, 2022, 2022 IEEE 23RD INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2022), P1, DOI 10.1109/IRI54793.2022.00014; Li C, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533935; Mishra K, 2023, IEEE T COMPUT SOC SY, V10, P1095, DOI 10.1109/TCSS.2022.3156580; openai.com, about us; Chang JP, 2020, Arxiv, DOI arXiv:2005.04246; Rogers PS, 2003, J BUS TECH COMMUN, V17, P379, DOI 10.1177/1050651903255401; Ryabova M, 2015, PROCD SOC BEHV, V206, P90, DOI 10.1016/j.sbspro.2015.10.033; Vinagre M, 2008, COMPUT EDUC, V50, P1022, DOI 10.1016/j.compedu.2006.10.002	14	3	3	4	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3984-0				2023							230	231		10.1109/CAI54212.2023.00106	http://dx.doi.org/10.1109/CAI54212.2023.00106			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5BQ					2024-07-03	WOS:001046447800096
J	Carpenter, KA; Altman, RB				Carpenter, Kristy A.; Altman, Russ B.			Using GPT-3 to Build a Lexicon of Drugs of Abuse Synonyms for Social Media Pharmacovigilance	BIOMOLECULES			English	Article						large language models; pharmacovigilance; social media; drugs of abuse	CHALLENGES	Drug abuse is a serious problem in the United States, with over 90,000 drug overdose deaths nationally in 2020. A key step in combating drug abuse is detecting, monitoring, and characterizing its trends over time and location, also known as pharmacovigilance. While federal reporting systems accomplish this to a degree, they often have high latency and incomplete coverage. Social-media-based pharmacovigilance has zero latency, is easily accessible and unfiltered, and benefits from drug users being willing to share their experiences online pseudo-anonymously. However, unlike highly structured official data sources, social media text is rife with misspellings and slang, making automated analysis difficult. Generative Pretrained Transformer 3 (GPT-3) is a large autoregressive language model specialized for few-shot learning that was trained on text from the entire internet. We demonstrate that GPT-3 can be used to generate slang and common misspellings of terms for drugs of abuse. We repeatedly queried GPT-3 for synonyms of drugs of abuse and filtered the generated terms using automated Google searches and cross-references to known drug names. When generated terms for alprazolam were manually labeled, we found that our method produced 269 synonyms for alprazolam, 221 of which were new discoveries not included in an existing drug lexicon for social media. We repeated this process for 98 drugs of abuse, of which 22 are widely-discussed drugs of abuse, building a lexicon of colloquial drug synonyms that can be used for pharmacovigilance on social media.	[Carpenter, Kristy A.; Altman, Russ B.] Stanford Univ, Dept Biomed Data Sci, Stanford, CA 94305 USA; [Altman, Russ B.] Stanford Univ, Dept Bioengn, Stanford, CA 94305 USA; [Altman, Russ B.] Stanford Univ, Dept Genet, Stanford, CA 94305 USA; [Altman, Russ B.] Stanford Univ, Dept Med, Stanford, CA 94305 USA	Stanford University; Stanford University; Stanford University; Stanford University	Altman, RB (corresponding author), Stanford Univ, Dept Biomed Data Sci, Stanford, CA 94305 USA.; Altman, RB (corresponding author), Stanford Univ, Dept Bioengn, Stanford, CA 94305 USA.; Altman, RB (corresponding author), Stanford Univ, Dept Genet, Stanford, CA 94305 USA.; Altman, RB (corresponding author), Stanford Univ, Dept Med, Stanford, CA 94305 USA.	russ.altman@stanford.edu		Altman, Russ/0000-0003-3859-2905; Carpenter, Kristy/0000-0003-4570-5170	National Science Foundation Graduate Research Fellowship [DGE-1656518]; NIH [GM102365]; Chan Zuckerberg Biohub	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Chan Zuckerberg Biohub(Chan Zuckerberg Initiative (CZI))	K.A.C. is supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-1656518. R.B.A. is supported by NIH GM102365 and Chan Zuckerberg Biohub.	Abid A, 2021, ARXIV; Adams N, 2019, J DRUG ISSUES, V49, P477, DOI 10.1177/0022042619833911; [Anonymous], The Controlled Substances Act; Beninger P, 2018, CLIN THER, V40, P1991, DOI 10.1016/j.clinthera.2018.07.012; Boland Mary Regina, 2015, AMIA Jt Summits Transl Sci Proc, V2015, P196; Brown T. B., 2020, P NEURIPS 2020; Caster O, 2018, DRUG SAFETY, V41, P1355, DOI 10.1007/s40264-018-0699-2; CDC. National Center for Health Statistics, 2021, WID RANG NNLIN DAT E; Chiappini S, 2022, PHARMACEUTICALS-BASE, V15, DOI 10.3390/ph15060675; Ciccarone D, 2021, CURR OPIN PSYCHIATR, V34, P344, DOI 10.1097/YCO.0000000000000717; Cocos A, 2017, J AM MED INFORM ASSN, V24, P813, DOI 10.1093/jamia/ocw180; Convertino I, 2018, EXPERT OPIN DRUG SAF, V17, P1081, DOI 10.1080/14740338.2018.1531847; Elmore AL, 2021, PREV MED, V153, DOI 10.1016/j.ypmed.2021.106846; Eshleman R, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1220-5; Farooq Hammad, 2020, AMIA Annu Symp Proc, V2020, P442; Harpaz R, 2014, DRUG SAFETY, V37, P777, DOI 10.1007/s40264-014-0218-z; Hussain Z, 2022, JMIR PUBLIC HLTH SUR, V8, DOI 10.2196/32543; Inoue K, 2022, EPIDEMIOLOGY, V33, P572, DOI 10.1097/EDE.0000000000001490; Kazemi DM, 2017, J PUBLIC HEALTH-UK, V39, P763, DOI 10.1093/pubmed/fdx020; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Lardon J, 2018, EXPERT OPIN DRUG SAF, V17, P763, DOI 10.1080/14740338.2018.1499724; Lavertu A, 2021, J MED INTERNET RES, V23, DOI 10.2196/27714; Lavertu A, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103307; Leaman R, 2010, P 2010 WORKSH BIOM N, P117; Lee JY, 2021, JMIR PUBLIC HLTH SUR, V7, DOI 10.2196/30137; Lependu Paea, 2013, AMIA Jt Summits Transl Sci Proc, V2013, P109; Luo Y, 2017, DRUG SAFETY, V40, P1075, DOI 10.1007/s40264-017-0558-6; Lyden J, 2019, SEMIN PERINATOL, V43, P123, DOI 10.1053/j.semperi.2019.01.001; Magge A, 2021, J AM MED INFORM ASSN, V28, P2184, DOI 10.1093/jamia/ocab114; Marwitz KK, 2022, EXPLOR RES CLIN SOC, V5, DOI 10.1016/j.rcsop.2022.100130; Mcguffie K., 2020, arXiv; Mikolov T, 2013, COMPUTING RES REPOSI; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; Natter J, 2020, PHARMACOEPIDEM DR S, V29, P1189, DOI 10.1002/pds.5070; O'Connor Karen, 2014, AMIA Annu Symp Proc, V2014, P924; Pappa D, 2019, INT J DATA SCI ANAL, V8, P113, DOI 10.1007/s41060-019-00175-3; Park Albert, 2017, AMIA Annu Symp Proc, V2017, P1362; Pierce CE, 2017, DRUG SAFETY, V40, P317, DOI 10.1007/s40264-016-0491-0; Preiss A, 2022, JMIR FORM RES, V6, DOI 10.2196/33919; Robert M, 2023, ADDICTION, V118, P771, DOI 10.1111/add.16081; Schulman J, 2022, Introducing chatgpt; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Stokes A, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.17228; Suarez-Lledo V, 2021, J MED INTERNET RES, V23, DOI 10.2196/17187; Tasnim Samia, 2020, J Prev Med Public Health, V53, P171, DOI 10.3961/jpmph.20.094; Throckmorton DC, 2018, NEW ENGL J MED, V379, P205, DOI 10.1056/NEJMp1806486; Tricco AC, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0621-y; Tringale KR, 2019, CANCER-AM CANCER SOC, V125, P2242, DOI 10.1002/cncr.32059; Vaswani A, 2017, ADV NEUR IN, V30; Veronin MA, 2019, DRUG HEALTHC PATIENT, V11, P65, DOI 10.2147/DHPS.S214771; Ward PJ, 2023, AM J EPIDEMIOL, V192, P257, DOI 10.1093/aje/kwac180; Ward PJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223318; Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037	53	6	6	1	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2218-273X		BIOMOLECULES	Biomolecules	FEB	2023	13	2							387	10.3390/biom13020387	http://dx.doi.org/10.3390/biom13020387			23	Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	9H6HE	36830756	Green Published, gold			2024-07-03	WOS:000938931000001
J	Raman, R; Mandal, S; Das, P; Kaur, T; Sanjanasri, JP; Nedungadi, P				Raman, Raghu; Mandal, Santanu; Das, Payel; Kaur, Tavleen; Sanjanasri, J. P.; Nedungadi, Prema			Exploring University Students' Adoption of ChatGPT Using the Diffusion of Innovation Theory and Sentiment Analysis With Gender Dimension	HUMAN BEHAVIOR AND EMERGING TECHNOLOGIES			English	Article						diffusion; gender bias; generative AI; innovation; large language model; sentiment analysis	ACCEPTANCE; INTENTION	This study explores the adoption and societal implications of an emerging technology such as Chat Generative Pre-Trained Transformer (ChatGPT) in higher education students. By utilizing a mixed-method framework, this research combines Rogers' diffusion of innovation theory with sentiment analysis, offering an innovative methodological approach for examining technology adoption in higher educational settings. It explores five attributes-relative advantage, compatibility, ease of use, observability, and trialability-shaping students' behavioral intentions toward ChatGPT. Sentiment analysis offers qualitative depth, revealing emotional and perceptual aspects, and introduces a gender-based perspective. The results suggest that five innovation attributes significantly impact the adoption rates and perceptions of ChatGPT, indicating its potential for transformative social change within the educational sector. Gen Zs viewed ChatGPT as innovative, compatible, and user-friendly, enabling the independent pursuit of educational goals. Consequently, the benefits provided by ChatGPT in education motivate students to use the tool. Gender differences were observed in the prioritization of innovation attributes, with male students favoring compatibility, ease of use, and observability, while female students emphasized ease of use, compatibility, relative advantage, and trialability. The findings have implications for understanding how technological innovations such as ChatGPT could be strategically diffused across different societal segments, especially in the academic context where ethical considerations such as academic integrity are paramount. This study underscores the need for a demographic-sensitive, user-centric design in generative artificial intelligence (AI) technologies.	[Raman, Raghu] Amrita Vishwa Vidyapeetham, Amrita Sch Business, Amritapuri, Kerala, India; [Mandal, Santanu] Amrita Vishwa Vidyapeetham, Amrita Sch Business, Operat & Analyt, Amaravati, Andhra Pradesh, India; [Das, Payel] Amrita Vishwa Vidyapeetham, Amrita Sch Business, Dept Mkt, Amaravati, Andhra Pradesh, India; [Kaur, Tavleen] Fortune Inst Int Business, Dept OB & HR, New Delhi, India; [Sanjanasri, J. P.] Umea Univ, Dept Comp, Umea, Sweden; [Nedungadi, Prema] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Amritapuri, Kerala, India	Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri; Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham; Umea University; Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Amritapuri	Raman, R (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Business, Amritapuri, Kerala, India.	raghu@amrita.edu; shaan.nitw@gmail.com; payeldas28@gmail.com; tavi.arien@gmail.com; jp_sanjanasri@cb.amrita.edu; prema@amrita.edu						Abdaljaleel M, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-52549-8; Abdelhafiz AS, 2024, J MED SYST, V48, DOI 10.1007/s10916-024-02044-4; Achuthan K, 2020, INT J ONLINE BIOMED, V16, P4, DOI 10.3991/ijoe.v16i09.11685; Adesso Gerardo, 2023, AI Magazine, P328, DOI 10.1002/aaai.12113; Agag G, 2024, J BUS RES, V170, DOI 10.1016/j.jbusres.2023.114303; Ahad T, 2024, ELECTR J INF SYS DEV, V90, DOI 10.1002/isd2.12291; Ahmed AA, 2022, INT J SYST ASSUR ENG, V13, P699, DOI 10.1007/s13198-021-01594-x; AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T; Al-Moghrabi D, 2024, J DENT, V142, DOI 10.1016/j.jdent.2024.104840; Al-Rahmi WM, 2019, IEEE ACCESS, V7, P26797, DOI 10.1109/ACCESS.2019.2899368; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Amjad AI, 2024, EUR J EDUC, V59, DOI 10.1111/ejed.12625; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Beckmann L, 2024, FINANC RES LETT, V63, DOI 10.1016/j.frl.2024.105237; Bouteraa M, 2024, COMPUT HUM BEHAV REP, V14, DOI 10.1016/j.chbr.2024.100402; Brem A, 2021, TECHNOL FORECAST SOC, V163, DOI 10.1016/j.techfore.2020.120451; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Choi JH, 2022, J LEGAL EDUC, V71, P387; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cribben I., 2023, Operations Management and Data Analytics, DOI [10.2139/ssrn.4404276, DOI 10.2139/SSRN.4404276]; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; Dillon A, 1996, ANNU REV INFORM SCI, V31, P3; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002; Elbanna S., 2024, Management and Sustainability: An Arab Review, V3, P16, DOI DOI 10.1108/MSAR-03-2023-0016; Fishbein M., 1977, Belief, Attitude Intention and Behaviour: An introduction to theory and research; FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312; Ghosh S, 2023, PROCEEDINGS OF THE 2023 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2023, P901, DOI 10.1145/3600211.3604672; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Gombert S, 2024, INT J ARTIF INTELL E, DOI 10.1007/s40593-023-00387-6; Gross N, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12080435; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Hayat R., 2024, The Asian Bulletin of Big Data Management, V4, DOI [10.62019/abbdm.v4i1.126, DOI 10.62019/ABBDM.V4I1.126]; Henseler J., 2015, ADANCO 2.0, DOI [10.1016/j.jbusres.2023.114303, DOI 10.1016/J.JBUSRES.2023.114303]; Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118; Huallpa J. J., 2023, Period. Eng. Nat. Sci, V11, P105; Ifinedo P, 2018, BEHAV INFORM TECHNOL, V37, P381, DOI 10.1080/0144929X.2018.1436594; Iqbal N., 2022, Global Journal for Management and Administrative Sciences, V3, P97, DOI DOI 10.46568/GJMAS.V3I4.163; Islam I., 2023, PREPRINT, DOI [10.22541/au.167712329.97543109/v1, DOI 10.22541/AU.167712329.97543109/V1]; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100115; Jim J. R., 2024, Natural Language Processing Journal, V6, article 100059, DOI [10.1016/j.nlp.2024.100059, DOI 10.1016/J.NLP.2024.100059]; Kaplan DM, 2024, J MED INTERNET RES, V26, DOI 10.2196/51837; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kuo YC, 2017, EDUC TECHNOL SOC, V20, P37; Lai C. Y., 2023, Computers and Education: Artificial Intelligence, V5, article 100178, DOI DOI 10.1016/J.CAEAI.2023.100178; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Lian Y, 2024, TECHNOL SOC, V76, DOI 10.1016/j.techsoc.2023.102442; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Liu GX, 2024, INNOV LANG LEARN TEA, V18, P125, DOI 10.1080/17501229.2023.2240316; MacQueen J., 1967, P 5 BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6; Metz C., 2022, Can you trust them?; Min S., 2021, Future of Tourism Marketing, P2; Modgil S, 2022, TECHNOL FORECAST SOC, V175, DOI 10.1016/j.techfore.2021.121415; Mogavi R. H., 2024, Computers in Human Behavior: Artificial Humans, V2, DOI DOI 10.1016/J.CHBAH.2023.100027; Morath B, 2023, EUR J HOSP PHARM, DOI 10.1136/ejhpharm-2023-003750; Nazarovets S, 2024, ACCOUNT RES, DOI 10.1080/08989621.2024.2345713; Nedungadi P, 2024, INT J INFORM MANAGE, V77, DOI 10.1016/j.ijinfomgt.2024.102785; OpenAI, 2023, ChatGPT Large language model; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pinho C, 2021, EDUC INF TECHNOL, V26, P421, DOI 10.1007/s10639-020-10269-2; Prez-Ortega J., 2020, The K-means algorithm evolution, DOI [10.5772/intechopen.85447, DOI 10.5772/INTECHOPEN.85447]; RAM S, 1987, ADV CONSUM RES, V14, P208; Ram S., 1989, J CONSUM MARK, V6, P5, DOI [10.1108/EUM0000000002542, DOI 10.1108/EUM0000000002542]; Raman R., 2023, International Journal of Emerging Technologies in Learning, V18, P13, DOI [10.3991/ijet.v18i19.41793, DOI 10.3991/IJET.V18I19.41793]; Raman R., 2023, University students as early adopters of ChatGPT: innovation diffusion study, DOI [10.21203/rs.3.rs-2734142/v1, DOI 10.21203/RS.3.RS-2734142/V1]; Raman R, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2273377; Raman R, 2021, EDUC INF TECHNOL, V26, P7339, DOI 10.1007/s10639-021-10581-5; Raman R, 2020, INT J EMERG TECHNOL, V15, P191, DOI 10.3991/ijet.v15i24.17159; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rejeb A, 2024, INT J MANAG EDUC-OXF, V22, DOI 10.1016/j.ijme.2024.100932; Rogers EM., 2003, Diffusion of innovations (5. Aufl.), V5, DOI DOI 10.2307/2573300; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Rutinowski J, 2024, HUM BEHAV EMERG TECH, V2024, DOI 10.1155/2024/7115633; Saif N, 2024, COMPUT HUM BEHAV, V154, DOI 10.1016/j.chb.2023.108097; Sallam M., 2023, PREPRINT; Sanjanasri J. P., 2020, In advances in intelligent systems and computing, DOI [10.1007/978-981-13-6095-43, DOI 10.1007/978-981-13-6095-43]; Schulman J, 2022, Introducing chatgpt; Sim JWS, 2010, EDUC RES REV-NETH, V5, P151, DOI 10.1016/j.edurev.2010.01.001; Steiss J, 2024, LEARN INSTR, V91, DOI 10.1016/j.learninstruc.2024.101894; Suliman MAE, 2023, INNOV EDUC TEACH INT, DOI 10.1080/14703297.2023.2239203; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tiwari CK, 2023, INTERACT TECHNOL SMA, DOI 10.1108/ITSE-04-2023-0061; Venkatesh V, 2012, MIS QUART, V36, P157; World Economic Forum, 2023, ChatGPT and cheating: 5 ways to change how students are graded; Wu ST, 2019, CMC-COMPUT MATER CON, V60, P1207, DOI 10.32604/cmc.2019.05835; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yang SQ, 2012, COMPUT HUM BEHAV, V28, P129, DOI 10.1016/j.chb.2011.08.019; Yeung Melissa Yuen-Lam, 2023, SN Comput Sci, V4, P202, DOI 10.1007/s42979-023-01667-7; Yilmaz H., 2023, International Educational Review, V1, P57, DOI [10.58693/ier.114, DOI 10.58693/IER.114]; Yu H, 2024, HELIYON, V10, DOI 10.1016/j.heliyon.2024.e24289; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]	92	0	0	0	0	WILEY-HINDAWI	LONDON	ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND		2578-1863		HUM BEHAV EMERG TECH	Hum. Behav. Emerg. Tech.	JUN 10	2024	2024								3085910	10.1155/2024/3085910	http://dx.doi.org/10.1155/2024/3085910			21	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	WB0T2		gold			2024-07-03	WOS:001252297800001
J	Fu, XY; Wang, RN; Li, CS				Fu, Xinyu; Wang, Ruoniu; Li, Chaosu			Can ChatGPT Evaluate Plans?	JOURNAL OF THE AMERICAN PLANNING ASSOCIATION			English	Article; Early Access						ChatGPT; large language model; natural language processing; plan evaluation; plan quality	SEA-LEVEL RISE; CLIMATE-CHANGE; MITIGATION PLANS; ADAPTATION; IMPLEMENTATION; PLANNERS; STATE	Problem, research strategy, and findingsLarge language models, such as ChatGPT, have recently risen to prominence in producing human-like conversation and assisting with various tasks, particularly for analyzing high-dimensional textual materials. Because planning researchers and practitioners often need to evaluate planning documents that are long and complex, a first-ever possible question has emerged: Can ChatGPT evaluate plans? In this study we addressed this question by leveraging ChatGPT to evaluate the quality of plans and compare the results with those conducted by human coders. Through the evaluation of 10 climate change plans, we discovered that ChatGPT's evaluation results coincided reasonably well (with an average of 68%) with those from the traditional content analysis approach. We further scrutinized the differences by conducting a more in-depth analysis of the results from ChatGPT and manual evaluation to uncover what might have contributed to the variance in results. Our findings indicate that ChatGPT struggled to comprehend planning-specific jargon, yet it could reduce human errors by capturing details in complex planning documents. Finally, we provide insights into leveraging this cutting-edge technology in future planning research and practice.Takeaway for practiceChatGPT cannot be used to replace humans in plan quality evaluation yet. However, it is an effective tool to complement human coders to minimize human errors by identifying discrepancies and fact-checking machine-generated responses. ChatGPT generally cannot understand planning jargon, so planners wanting to use this tool should use extra caution when planning terminologies are present in their prompts. Creating effective prompts for ChatGPT is an iterative process that requires specific instructions.	[Fu, Xinyu] Univ Waikato, Environm planning, Hamilton, New Zealand; [Wang, Ruoniu] Univ Washington, Runstad Dept Real Estate, Coll Built Environm, Seattle, WA USA; [Li, Chaosu] Hong Kong Univ Sci & Technol, Urban Governance & Design Thrust, Guangzhou, Peoples R China; [Li, Chaosu] Hong Kong Univ Sci & Technol, Div Publ Policy, Hong Kong, Peoples R China	University of Waikato; University of Washington; University of Washington Seattle; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology	Fu, XY (corresponding author), Univ Waikato, Environm planning, Hamilton, New Zealand.	xinyuf@waikato.ac.nz; vrwang@uw.edu; chaosuli@ust.hk	Fu, Xinyu/ABA-6804-2020; Li, Chaosu/I-8419-2016	Fu, Xinyu/0000-0002-3591-4158; Li, Chaosu/0000-0002-1146-2361				American Planning Association (APA), 2023, Unleashing the potential of ChatGPT in planning practice; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bell J.B., 2004, HDB PRACTICAL PROGRA, P571; Berke P, 2012, NAT HAZARDS REV, V13, P139, DOI 10.1061/(ASCE)NH.1527-6996.0000063; Berke P, 2009, J PLAN LIT, V23, P227, DOI 10.1177/0885412208327014; Brinkley C, 2024, J AM PLANN ASSOC, V90, P63, DOI 10.1080/01944363.2022.2118155; Brinkley C, 2024, J PLAN EDUC RES, V44, P632, DOI [10.1177/0739456x21995890, 10.1177/0739456X21995890]; Brody SD, 2005, J AM PLANN ASSOC, V71, P159, DOI 10.1080/01944360508976690; Butler WH, 2016, J PLAN EDUC RES, V36, P319, DOI 10.1177/0739456X16647161; Chalkidis I, 2023, Arxiv, DOI [arXiv:2304.12202, 10.2139/ssrn.4385460]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chula Vista, 2011, City of Chula Vista climate adaptation strategies; DALTON LC, 1994, J AM PLANN ASSOC, V60, P444, DOI 10.1080/01944369408975604; Daniel C., 2023, ChatGPT: Implications for planning; Denver, 2014, City and county of Denver climate adaptation plan; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Forsyth A, 2023, J AM PLANN ASSOC, V89, P1, DOI 10.1080/01944363.2022.2144700; Forsyth A, 2022, J AM PLANN ASSOC, V88, P1, DOI 10.1080/01944363.2021.1995286; Fu XY, 2023, J AM PLANN ASSOC, V89, P107, DOI 10.1080/01944363.2022.2038659; Fu XY, 2022, J ENVIRON MANAGE, V318, DOI 10.1016/j.jenvman.2022.115493; Fu XY, 2019, CLIMATIC CHANGE, V155, P393, DOI 10.1007/s10584-019-02488-5; Fu XY, 2017, J ENVIRON PLANN MAN, V60, P249, DOI 10.1080/09640568.2016.1151771; Guyadeen D, 2018, J AM PLANN ASSOC, V84, P21, DOI 10.1080/01944363.2017.1404486; Guyadeen D, 2016, PLAN PRACT RES, V31, P215, DOI 10.1080/02697459.2015.1081335; Hess DJ, 2021, LOCAL ENVIRON, V26, P461, DOI 10.1080/13549839.2021.1892047; Hoch C., 2002, Planning Theory, V1, P53; KAISER EJ, 1995, J AM PLANN ASSOC, V61, P365, DOI 10.1080/01944369508975648; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khakee Abdul., 2000, EVALUATION-US, V6, P119, DOI [https://doi.org/10.1177/13563890022209172, DOI 10.1177/13563890022209172]; Kim H, 2018, ENVIRON HAZARDS-UK, V17, P397, DOI 10.1080/17477891.2017.1407743; Knaap GJ, 2001, J PLAN EDUC RES, V21, P32, DOI 10.1177/0739456X0102100103; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Krizek K, 2009, PLAN THEORY PRACT, V10, P459, DOI 10.1080/14649350903417241; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Laurian L, 2004, J AM PLANN ASSOC, V70, P471, DOI 10.1080/01944360408976395; Laurian L, 2010, ENVIRON PLANN B, V37, P740, DOI 10.1068/b35051; Li CS, 2016, J ENVIRON PLANN MAN, V59, P1679, DOI 10.1080/09640568.2015.1085840; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Loh CG, 2021, J AM PLANN ASSOC, V87, P181, DOI 10.1080/01944363.2020.1829498; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Lyles W, 2014, J PLAN EDUC RES, V34, P433, DOI 10.1177/0739456X14549752; Neuman M, 1998, J AM PLANN ASSOC, V64, P208; OpenAI, 2022, OpenAI ChatGPT; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Reckien D, 2014, CLIMATIC CHANGE, V122, P331, DOI 10.1007/s10584-013-0989-8; Ryan BD, 2011, J AM PLANN ASSOC, V77, P309, DOI 10.1080/01944363.2011.616995; Shi LD, 2015, J AM PLANN ASSOC, V81, P191, DOI 10.1080/01944363.2015.1074526; Stevens MR, 2014, J PLAN EDUC RES, V34, P77, DOI 10.1177/0739456X13513614; Talen E., 1996, Journal of Planning Literature, V10, P248; Teebagy S, 2023, medRxiv, DOI [10.1101/2023.04.03.23287957, 10.1101/2023.04.03.23287957, DOI 10.1101/2023.04.03.23287957]; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Wheeler S, 2008, J AM PLANN ASSOC, V74, P481, DOI 10.1080/01944360802377973; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wray S., 2023, CitiesToday; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	55	4	4	39	52	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0194-4363	1939-0130		J AM PLANN ASSOC	J. Am. Plan. Assoc.	2023 NOV 16	2023										10.1080/01944363.2023.2271893	http://dx.doi.org/10.1080/01944363.2023.2271893		NOV 2023	12	Regional & Urban Planning; Urban Studies	Social Science Citation Index (SSCI)	Public Administration; Urban Studies	Y1QA5		hybrid			2024-07-03	WOS:001103070200001
J	Colabianchi, S; Tedeschi, A; Costantino, F				Colabianchi, Silvia; Tedeschi, Andrea; Costantino, Francesco			Human-technology integration with industrial conversational agents: A conceptual architecture and a taxonomy for manufacturing	JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION			English	Article						Chatbot; Natural language processing; Dialog systems; Voice bot; Large language model	SPEECH RECOGNITION; CHATBOT; VOICE	Conversational agents are systems with great potential to enhance human-computer interaction in industrial settings. Although the number of applications of conversational agents in many fields is growing, there is no shared view of the elements to design and implement for chatbots in the industrial field. The paper presents the combination of many research contributions into an integrated conceptual architecture, for developing industrial conversational agents using Nickerson's methodology. The conceptual architecture consists of five core modules; every module consists of specific elements and approaches. Furthermore, the paper defines a taxonomy from the study of empirical applications of manufacturing conversational agents. Indeed, some applications of chatbots in manufacturing are available but those have never been collected in single research. The paper fills this gap by analyzing the empirical cases and presenting a qualitative analysis, with verification of the proposed taxonomy. The contribution of the article is mainly to illustrate the elements needed for the development of a conversational agent in manufacturing: researchers and practitioners can use the proposed conceptual architecture and taxonomy to more easily investigate, define, and develop all the elements for chatbot implementation.	[Colabianchi, Silvia; Tedeschi, Andrea; Costantino, Francesco] Sapienza Univ Rome, Dept Comp Control & Management Engn Antonio Rubert, Via Ariosto 25, I-00185 Rome, Italy	Sapienza University Rome	Costantino, F (corresponding author), Sapienza Univ Rome, Dept Comp Control & Management Engn Antonio Rubert, Via Ariosto 25, I-00185 Rome, Italy.	francesco.costantino@uniroma1.it	Costantino, Francesco/H-3492-2012	Colabianchi, Silvia/0000-0002-1811-8619				Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Ade N., 2021, ProBot-a procedure chatbot for digital procedural adherence, V64, P224, DOI [10.1177/1071181320641054, DOI 10.1177/1071181320641054]; Adriaensen A, 2022, HUM FACTOR ERGON MAN, V32, P173, DOI 10.1002/hfm.20939; Agarwal R., 2020, SN Comp. Sci., P1, DOI [10.1007/S42979-020-00255-3,20201:5.1, DOI 10.1007/S42979-020-00255-3,20201:5.1]; Almansor EH, 2020, ADV INTELL SYST COMP, V993, P534, DOI 10.1007/978-3-030-22354-0_47; Angulo C, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100673; Annarelli Alessandro, 2022, Proceedings of the Future Technologies Conference (FTC) 2021. Lecture Notes in Networks and Systems (360), P17, DOI 10.1007/978-3-030-89912-7_2; Augello A., 2012, 2012 IEEE Sixth International Conference on Semantic Computing (ICSC 2012), P186, DOI 10.1109/ICSC.2012.26; Bernabei M., 2021, P SUMMER SCH FRANCES; Bohus D, 2005, TEXT SPEECH LANG TEC, V28, P203; Casillo M, 2020, PR IEEE INT CONF TEA, P371, DOI 10.1109/TALE48869.2020.9368339; Chandar P, 2017, LECT NOTES COMPUT SC, V10514, P381, DOI 10.1007/978-3-319-67684-5_23; CHEN H, 2017, ACM SIGKDD EXPLORATI, V19, P25, DOI [DOI 10.1145/3166054.3166058, 10.1145/3166054.3166058]; Chen TY, 2021, IEEE ACCESS, V9, P82118, DOI 10.1109/ACCESS.2021.3083518; Colabianchi S., 2022, Transportation Research Procedia, V64, P6, DOI [10.1016/j.trpro.2022.09.002, DOI 10.1016/J.TRPRO.2022.09.002]; Costantino F, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910948; Devi KM, 2021, INT CO SIG PROC COMM, P527, DOI 10.1109/ICSPC51351.2021.9451760; Fadhil A, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P408, DOI 10.1145/3099023.3099112; Flohr LA, 2021, PROCEEDINGS OF 23RD ACM INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447526.3472036; Folstad Asbjorn, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P671, DOI 10.1145/3441000.3441046; Folstad A., 2017, interactions, V24, P38, DOI [DOI 10.1145/3085558, 10.1145/3085558]; Foster M.E., 2008, C P 12 WORKSH SEM PR; Freire SK, 2023, IEEE PERVAS COMPUT, V22, P50, DOI 10.1109/MPRV.2022.3218600; GONG YF, 1995, SPEECH COMMUN, V16, P261, DOI 10.1016/0167-6393(94)00059-J; Gonzalez J., 2021, The 12th International Conference on Advances in Information Technology, V37, P1, DOI [10.1145/3468784.3471606, DOI 10.1145/3468784.3471606]; Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924; Harms JG, 2019, IEEE INTERNET COMPUT, V23, P13, DOI 10.1109/MIC.2018.2881519; Hidayatulloh I., 2021, Elinvo (Electronics, Informatics, and Vocational Education), V6, P71, DOI [10.21831/ELINVO.V6I1.43705, DOI 10.21831/ELINVO.V6I1.43705]; Huang DH, 2021, J INNOV KNOWL, V6, P135, DOI 10.1016/j.jik.2020.09.002; Huang RJ, 2023, Arxiv, DOI arXiv:2304.12995; Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93; Janssen A, 2020, BUS INFORM SYST ENG+, V62, P211, DOI 10.1007/s12599-020-00644-1; Jwo JS, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/5578239; Khanna A., 2015, INT J U E SERV SCI T, V8, P277, DOI DOI 10.14257/IJUNESST.2015.8.7.28; Kowatsch T., 2017, 7 INT C INT VIRT AG; Kucherbaev P, 2018, IEEE INTERNET COMPUT, V22, P36, DOI 10.1109/MIC.2018.252095348; Kwon Y., 2023, ICASSP 2023 2023 IEE, P1, DOI [10.1109/ICASSP49357.2023.10096227, DOI 10.1109/ICASSP49357.2023.10096227]; Li C, 2023, IEEE ACCESS, V11, P28236, DOI 10.1109/ACCESS.2023.3259325; Li C, 2022, IEEE ACCESS, V10, P91631, DOI 10.1109/ACCESS.2022.3202554; Li C, 2022, IEEE/SICE I S SYS IN, P238, DOI 10.1109/SII52469.2022.9708757; Li C, 2021, ACMIEEE INT CONF HUM, P220, DOI 10.1145/3434074.3447163; Li C, 2021, MULTIAGENT GRID SYST, V17, P1, DOI 10.3233/MGS-210340; Locatelli M, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11120583; Longo F, 2023, J IND INF INTEGR, V32, DOI 10.1016/j.jii.2023.100437; Longo F, 2020, MANUF LETT, V26, P12, DOI 10.1016/j.mfglet.2020.09.001; López A, 2019, LECT NOTES COMPUT SC, V11483, P383, DOI 10.1007/978-3-030-21290-2_24; Luo B, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1434; Mantravadi S, 2020, LECT NOTES ARTIF INT, V12034, P189, DOI 10.1007/978-3-030-42058-1_16; McTear M., 2020, SYNTHESIS LECT HUMAN, V13, P1, DOI [DOI 10.2200/S01060ED1V01Y202010HLT048, 10.2200/S01060ED1V01Y202010HLT048]; Motger Q., 2021, Taxon. Chall; Motger Q, 2024, Arxiv, DOI arXiv:2106.10901; Nayak V., 2021, GLOBAL TRANSITIONS P, V2, P506, DOI DOI 10.1016/J.GLTP.2021.08.016; Nickerson R.C., 2009, 17 EUR C INF SYST EC; Nickerson RC, 2013, EUR J INFORM SYST, V22, P336, DOI 10.1057/ejis.2012.26; Ning YS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194050; Nissen M, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107043; O'Shaughnessy D, 2008, PATTERN RECOGN, V41, P2965, DOI 10.1016/j.patcog.2008.05.008; Patriarca R, 2021, SAFETY SCI, V136, DOI 10.1016/j.ssci.2020.105142; Pires JN, 2005, IND ROBOT, V32, P505, DOI 10.1108/01439910510629244; Quarteroni S., 2018, InformatikSpektrum, V41, P105, DOI 10.1007/s00287-018-1094-1; Quatrini E, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020814; Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31; Romero D., 2016, CO 2016 46 INT C COM, P1; Rooein Donya, 2020, Enterprise, Business-Process and Information Systems Modeling. 21st International Conference, BPMDS 2020, 25th International Conference, EMMSAD 2020. Held at CAiSE 2020. Proceedings. Lecture Notes in Business Information Processing (LNBIP 387), P70, DOI 10.1007/978-3-030-49418-6_5; Schmidt B, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P794, DOI 10.1145/3267305.3274131; Schneikart G, 2022, J IND INF INTEGR, V26, DOI 10.1016/j.jii.2022.100333; Serras M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113960; Shen YL, 2019, INT CONF ACOUST SPEE, P6750, DOI 10.1109/ICASSP.2019.8683648; Sommerville I., 2011, Software engineering, P18; Souvignier B, 2000, IEEE T SPEECH AUDI P, V8, P51, DOI 10.1109/89.817453; Syvänen S, 2020, J COMMUN MANAG, V24, P339, DOI 10.1108/JCOM-11-2019-0145; Trappey AJC, 2022, J IND INF INTEGR, V26, DOI 10.1016/j.jii.2022.100331; Trappey AJC, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010087; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wellsandt S, 2022, ANNU REV CONTROL, V53, P382, DOI 10.1016/j.arcontrol.2022.04.001; Wellsandta Stefan., 2020, SSRN Electronic Journal, DOI [DOI 10.2139/SSRN.3718008, https://doi.org/10.2139/ssrn.3718008]; Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046; Zimmer Melanie., 2020, UKRAS20 Conference: "Robots into the Real World" Proceedings, P108, DOI [https://doi.org/10.31256/Qx5Dt5V, DOI 10.31256/QX5DT5V]	81	2	2	7	16	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2467-964X	2452-414X		J IND INF INTEGR	J. Ind. Inf. Integr.	OCT	2023	35								100510	10.1016/j.jii.2023.100510	http://dx.doi.org/10.1016/j.jii.2023.100510		SEP 2023	15	Computer Science, Interdisciplinary Applications; Engineering, Industrial	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	S8XE0		Green Published, hybrid			2024-07-03	WOS:001073934200001
J	Rösler, W; Altenbuchinger, M; Baessler, B; Beissbarth, T; Beutel, G; Bock, R; von Bubnoff, N; Eckardt, JN; Foersch, S; Loeffler, CML; Middeke, JM; Mueller, ML; Oellerich, T; Risse, B; Scherag, A; Schliemann, C; Scholz, M; Spang, R; Thielscher, C; Tsoukakis, I; Kather, JN				Roesler, Wiebke; Altenbuchinger, Michael; Baessler, Bettina; Beissbarth, Tim; Beutel, Gernot; Bock, Robert; von Bubnoff, Nikolas; Eckardt, Jan-Niklas; Foersch, Sebastian; Loeffler, Chiara M. L.; Middeke, Jan Moritz; Mueller, Martha-Lena; Oellerich, Thomas; Risse, Benjamin; Scherag, Andre; Schliemann, Christoph; Scholz, Markus; Spang, Rainer; Thielscher, Christian; Tsoukakis, Ioannis; Kather, Jakob Nikolas			An overview and a roadmap for artificial intelligence in hematology and oncology	JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY			English	Review						Artificial intelligence; Machine learning; Digital health; Large language models; Computer vision	PREDICTION; VALIDATION; MEDICINE; RECORDS; FUTURE	BackgroundArtificial intelligence (AI) is influencing our society on many levels and has broad implications for the future practice of hematology and oncology. However, for many medical professionals and researchers, it often remains unclear what AI can and cannot do, and what are promising areas for a sensible application of AI in hematology and oncology. Finally, the limits and perils of using AI in oncology are not obvious to many healthcare professionals.MethodsIn this article, we provide an expert-based consensus statement by the joint Working Group on "Artificial Intelligence in Hematology and Oncology" by the German Society of Hematology and Oncology (DGHO), the German Association for Medical Informatics, Biometry and Epidemiology (GMDS), and the Special Interest Group Digital Health of the German Informatics Society (GI). We provide a conceptual framework for AI in hematology and oncology.ResultsFirst, we propose a technological definition, which we deliberately set in a narrow frame to mainly include the technical developments of the last ten years. Second, we present a taxonomy of clinically relevant AI systems, structured according to the type of clinical data they are used to analyze. Third, we show an overview of potential applications, including clinical, research, and educational environments with a focus on hematology and oncology.ConclusionThus, this article provides a point of reference for hematologists and oncologists, and at the same time sets forth a framework for the further development and clinical deployment of AI in hematology and oncology in the future.	[Roesler, Wiebke] Univ Hosp Zurich, Dept Med Oncol & Hematol, Zurich, Switzerland; [Altenbuchinger, Michael; Beissbarth, Tim] Univ Med Ctr Gottingen, Dept Med Bioinformat, Gottingen, Germany; [Baessler, Bettina] Univ Hosp Wurzburg, Dept Diagnost & Intervent Radiol, Wurzburg, Germany; [Beutel, Gernot] Hannover Med Sch, Dept Hematol Hemostasis Oncol & Stem Cell Transpl, Hannover, Germany; [Bock, Robert] IMMS Inst Microelect & Mechatron Syst GmbH NPO, Ilmenau, Germany; [von Bubnoff, Nikolas] Univ Schleswig Holstein, Med Ctr, Dept Hematol & Oncol, Campus Lubeck, Lubeck, Germany; [Eckardt, Jan-Niklas; Loeffler, Chiara M. L.; Middeke, Jan Moritz; Kather, Jakob Nikolas] Tech Univ Dresden, Univ Hosp Carl Gustav Carus, Dept Med 1, Dresden, Germany; [Eckardt, Jan-Niklas; Loeffler, Chiara M. L.; Middeke, Jan Moritz; Kather, Jakob Nikolas] Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth EFFZ, Dresden, Germany; [Foersch, Sebastian] Univ Med Ctr Mainz, Inst Pathol, Mainz, Germany; [Mueller, Martha-Lena] MLL Munich Leukemia Lab, Munich, Germany; [Oellerich, Thomas] Univ Hosp, Med Klin Haematol Oncol 2, Frankfurt, Germany; [Risse, Benjamin] Univ Munster, Inst Geoinformat, Comp Vis & Machine Learning Syst Grp, Munster, Germany; [Scherag, Andre] Friedrich Schiller Univ, Jena Univ Hosp, Inst Med Stat Comp & Data Sci, Jena, Afghanistan; [Schliemann, Christoph] Univ Hosp Munster, Dept Med A, Munster, Germany; [Scholz, Markus] Univ Leipzig, Inst Med Informat Stat & Epidemiol, Leipzig, Germany; [Spang, Rainer] Univ Regensburg, Dept Stat Bioinformat, Regensburg, Germany; [Thielscher, Christian] FOM Univ, Competence Ctr Med Econ, Essen, Germany; [Tsoukakis, Ioannis] Sana Klinikum Offenbach, Dept Hematol & Oncol, Offenbach, Germany; [Kather, Jakob Nikolas] Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany	University of Zurich; University Zurich Hospital; University of Gottingen; University of Wurzburg; Hannover Medical School; University of Kiel; Schleswig Holstein University Hospital; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Technische Universitat Dresden; Johannes Gutenberg University of Mainz; MLL Munich Leukemia Laboratory; Goethe University Frankfurt; Goethe University Frankfurt Hospital; University of Munster; University of Munster; Leipzig University; University of Regensburg; Sana Klinikum Offenbach; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg	Kather, JN (corresponding author), Tech Univ Dresden, Univ Hosp Carl Gustav Carus, Dept Med 1, Dresden, Germany.; Kather, JN (corresponding author), Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth EFFZ, Dresden, Germany.; Kather, JN (corresponding author), Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany.	jakob_nikolas.kather@tu-dresden.de	Kather, Jakob Nikolas/D-4279-2015; Beissbarth, Tim/B-3129-2013	Kather, Jakob Nikolas/0000-0002-3730-5348; Loeffler, Chiara Maria Lavinia/0009-0002-9659-5194; Eckardt, Jan-Niklas/0000-0002-3649-2823	Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL. The authors have not disclosed any funding.	Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006; Alexander A, 2020, J AM COLL RADIOL, V17, P165, DOI 10.1016/j.jacr.2019.07.019; Araki K, 2023, ADV THER, V40, P934, DOI 10.1007/s12325-022-02397-7; Balasubramaniam V., 2021, Artificial intelligence algorithm with SVM classification using dermascopic images for melanoma diagnosis, V3, P34, DOI [DOI 10.36548/JAICN.2021.1.003, 10.36548/jaicn.2021.1.003]; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Brinker TJ, 2019, EUR J CANCER, V111, P30, DOI 10.1016/j.ejca.2018.12.016; Büttner R, 2019, PATHOLOGE, V40, P276, DOI 10.1007/s00292-019-0605-4; Bzdok Danilo, 2018, Nat Methods, V15, P233, DOI 10.1038/nmeth.4642; Chen RJ, 2022, CANCER CELL, V40, P865, DOI 10.1016/j.ccell.2022.07.004; Chen RJ, 2021, NAT BIOMED ENG, V5, P493, DOI 10.1038/s41551-021-00751-8; Cifci D, 2022, J PATHOL, V257, P430, DOI 10.1002/path.5898; Dolezal JM., 2022, ARXIV EESIV, V22, P432; Echle A, 2021, BRIT J CANCER, V124, P686, DOI 10.1038/s41416-020-01122-x; Elmarakeby HA, 2021, NATURE, V598, P348, DOI 10.1038/s41586-021-03922-4; Eraslan G, 2019, NAT REV GENET, V20, P389, DOI 10.1038/s41576-019-0122-6; Farina E, 2022, FUTUR SCI OA, V8, DOI 10.2144/fsoa-2021-0074; Frank B, 2023, ANN HEMATOL, V102, P603, DOI 10.1007/s00277-022-05051-y; Geis JR, 2019, RADIOLOGY, V293, P436, DOI 10.1148/radiol.2019191586; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Ghiasi S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103866; Hegselmann S., 2022, P 4 WORKSHOP NLP CON, V57, P116; Horak P, 2021, CANCER DISCOV, V11, P2780, DOI 10.1158/2159-8290.CD-21-0126; Horn H, 2018, HAEMATOLOGICA, V103, P1182, DOI 10.3324/haematol.2017.181024; Huang Z, 2020, BMC MED GENOMICS, V13, DOI 10.1186/s12920-020-0686-1; Ibrahim DM, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104348; Jacobs C, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210027; Kather JN, 2020, NAT CANCER, V1, P789, DOI 10.1038/s43018-020-0087-6; Kheifetz Y, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1006775; Kleppe A, 2021, NAT REV CANCER, V21, P199, DOI 10.1038/s41568-020-00327-9; Kockwelp J, 2022, IEEE COMPUT SOC CONF, P1824, DOI 10.1109/CVPRW56347.2022.00199; Krause J, 2021, J PATHOL, V254, P70, DOI 10.1002/path.5638; Kroth PJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9609; Laleh NG, 2023, CLIN CANCER RES, V29, P316, DOI 10.1158/1078-0432.CCR-22-0390; Ligero M, 2021, RADIOLOGY, V299, P109, DOI 10.1148/radiol.2021200928; Lipkova J, 2022, CANCER CELL, V40, P1095, DOI 10.1016/j.ccell.2022.09.012; Luchini C, 2022, BRIT J CANCER, V126, P4, DOI 10.1038/s41416-021-01633-1; Medenilla A., 2023, PLoS Digital Health, V2; Minh D, 2022, ARTIF INTELL REV, V55, P3503, DOI 10.1007/s10462-021-10088-y; Morin O, 2021, NAT CANCER, V2, P709, DOI 10.1038/s43018-021-00236-2; Mosch L, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221143903; Muehlematter UJ, 2021, LANCET DIGIT HEALTH, V3, pE195, DOI 10.1016/S2589-7500(20)30292-2; Muhiyaddin Raghad, 2022, Stud Health Technol Inform, V289, P481, DOI 10.3233/SHTI210962; Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689; Natarajan S, 2019, JAMA OPHTHALMOL, V137, P1182, DOI 10.1001/jamaophthalmol.2019.2923; Navarro CLA, 2023, J CLIN EPIDEMIOL, V154, P8, DOI 10.1016/j.jclinepi.2022.11.015; Nessle CN, 2022, PEDIATR BLOOD CANCER, V69, DOI 10.1002/pbc.29835; Parikh RB, 2022, JCO CLIN CANCER INFO, V6, DOI 10.1200/CCI.22.00073; Quellec G, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102118; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ruiz NR, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.984021; Sabry F, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/4653923; Schmidhuber J., 2022, FOUND TRENDS MACH LE, V33, P554; Schmidt C, 2017, JNCI-J NATL CANCER I, V109, DOI 10.1093/jnci/djx113; Seastedt Kenneth P, 2022, PLOS Digit Health, V1, pe0000102, DOI 10.1371/journal.pdig.0000102; Shen JY, 2019, JMIR MED INF, V7, DOI 10.2196/10010; Shmatko A, 2022, NAT CANCER, V3, P1026, DOI 10.1038/s43018-022-00436-4; Shreve Jacob T, 2022, Am Soc Clin Oncol Educ Book, V42, P1, DOI 10.1200/EDBK_350652; Singhal K, 2022, ARXIV; Skrede OJ, 2020, LANCET, V395, P350, DOI 10.1016/S0140-6736(19)32998-8; Sorin V, 2020, LANCET ONCOL, V21, P1553, DOI 10.1016/S1470-2045(20)30615-X; Sosale B, 2020, BMJ OPEN DIAB RES CA, V8, DOI 10.1136/bmjdrc-2019-000892; Staiger AM, 2020, LEUKEMIA, V34, P543, DOI 10.1038/s41375-019-0573-y; Tajirian T, 2020, J MED INTERNET RES, V22, DOI 10.2196/19274; Thomas AA, 2014, WORLD J UROL, V32, P99, DOI 10.1007/s00345-013-1040-4; Tomasev N, 2019, NATURE, V572, P116, DOI 10.1038/s41586-019-1390-1; Topol EJ, 2020, NAT MED, V26, P1318, DOI 10.1038/s41591-020-1042-x; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Tran KA, 2021, GENOME MED, V13, DOI 10.1186/s13073-021-00968-x; Trebeschi S, 2019, ANN ONCOL, V30, P998, DOI 10.1093/annonc/mdz108; Tschandl P, 2020, NAT MED, V26, P1229, DOI 10.1038/s41591-020-0942-0; Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z; Wu MH, 2019, RADIOL-IMAG CANCER, V1, DOI 10.1148/rycan.2019190031; Yala A, 2022, NAT MED, V28, P136, DOI 10.1038/s41591-021-01599-w; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yim WW, 2016, JAMA ONCOL, V2, P797, DOI 10.1001/jamaoncol.2016.0213; Zeng ZX, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04400-4	76	14	14	2	17	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0171-5216	1432-1335		J CANCER RES CLIN	J. Cancer Res. Clin. Oncol.	AUG	2023	149	10					7997	8006		10.1007/s00432-023-04667-5	http://dx.doi.org/10.1007/s00432-023-04667-5		MAR 2023	10	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	LJ8Q7	36920563	Green Published, hybrid			2024-07-03	WOS:000950059800001
J	Thelot, R				Thelot, Ruby			Searching for sentience	AI & SOCIETY			English	Editorial Material; Early Access						LaMDA; Large language model; Sentience; AI; Eliza effect		The AI world was rocked with controversy when Blake Lemoine, an AI researcher at Google claimed that their new LaMDA model was sentient. This Curmudgeon's Corner article explores his claims critically by contrasting them to the original LaMDA paper released by the team of researchers at Google. The piece explores the human tendency for anthropomorphization via historical chatbots such as Eliza and potential reasons why we developed this propensity. It addresses the potential causes for the model's choice of words. Subsequently, using the scoring criteria of the language model, I provide an explanation for the model's behavior in the conversation with Lemoine. Finally, I explore some of Lemoine's assertions and break down the logical gaps they hold. I conclude on a potential reorientation of the debate in view of our unfortunate tendency.	[Thelot, Ruby] Parsons Sch Design, New York, NY 10011 USA		Thelot, R (corresponding author), Parsons Sch Design, New York, NY 10011 USA.	rubythelot@gmail.com							0	0	0	1	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2023 AUG 26	2023										10.1007/s00146-023-01740-y	http://dx.doi.org/10.1007/s00146-023-01740-y		AUG 2023	3	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	R3WF8		Bronze			2024-07-03	WOS:001063680400001
J	Wake, N; Kanehira, A; Sasabuchi, K; Takamatsu, J; Ikeuchi, K				Wake, Naoki; Kanehira, Atsushi; Sasabuchi, Kazuhiro; Takamatsu, Jun; Ikeuchi, Katsushi			ChatGPT Empowered Long-Step Robot Control in Various Environments: A Case Application	IEEE ACCESS			English	Article						Task planning; robot manipulation; large language models; ChatGPT		This paper introduces a novel method for translating natural-language instructions into executable robot actions using OpenAI's ChatGPT in a few-shot setting. We propose customizable input prompts for ChatGPT that can easily integrate with robot execution systems or visual recognition programs, adapt to various environments, and create multi-step task plans while mitigating the impact of token limit imposed on ChatGPT. In our approach, ChatGPT receives both instructions and textual environmental data, and outputs a task plan and an updated environment. These environmental data are reused in subsequent task planning, thus eliminating the extensive record-keeping of prior task plans within the prompts of ChatGPT. Experimental results demonstrated the effectiveness of these prompts across various domestic environments, such as manipulations in front of a shelf, a fridge, and a drawer. The conversational capability of ChatGPT allows users to adjust the output via natural-language feedback. Additionally, a quantitative evaluation using VirtualHome showed that our results are comparable to previous studies. Specifically, 36% of task planning met both executability and correctness, and the rate approached 100% after several rounds of feedback. Our experiments revealed that ChatGPT can reasonably plan tasks and estimate post-operation environments without actual experience in object manipulation. Despite the allure of ChatGPT-based task planning in robotics, a standardized methodology remains elusive, making our work a substantial contribution. These prompts can serve as customizable templates, offering practical resources for the robotics research community. Our prompts and source code are open source and publicly available at https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts.	[Wake, Naoki; Kanehira, Atsushi; Sasabuchi, Kazuhiro; Takamatsu, Jun; Ikeuchi, Katsushi] Microsoft, Appl Robot Res, Redmond, WA 98052 USA	Microsoft	Wake, N (corresponding author), Microsoft, Appl Robot Res, Redmond, WA 98052 USA.	naoki.wake@microsoft.com		Takamatsu, Jun/0000-0001-7457-2878; Wake, Naoki/0000-0001-8278-2373				Brown N., 2023, C ROBOT LEARNING, P287; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Chen M., 2021, arXiv; Ding Y., 2022, arXiv; Ding Y, 2023, Arxiv, DOI arXiv:2303.06247; Gramopadhye M, 2023, Arxiv, DOI arXiv:2210.04964; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Huang WL, 2022, PR MACH LEARN RES; Ikeuchi K, 2023, Arxiv, DOI arXiv:2304.09966; Ikeuchi K, 2021, Arxiv, DOI arXiv:2103.02201; Jaroslavceva J, 2022, IEEJ T ELECTR ELECTR, V17, P407, DOI 10.1002/tee.23523; Jiang YF, 2023, Arxiv, DOI arXiv:2210.03094; Kaynar F, 2023, Arxiv, DOI arXiv:2303.10195; Khan MA, 2023, Arxiv, DOI arXiv:2304.02993; Kovalev AK, 2022, DOKL MATH, V106, pS85, DOI 10.1134/S1064562422060138; Kuhn H. T., 1956, Annals of Mathematic Studies; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Lin K, 2023, Arxiv, DOI arXiv:2303.12153; Liu H, 2023, Arxiv, DOI arXiv:2210.13431; Lynch C, 2021, Arxiv, DOI arXiv:2005.07648; Mees O, 2023, IEEE INT CONF ROBOT, P11576, DOI 10.1109/ICRA48891.2023.10160396; Microsoft, Azure OpenAI-Data Privacy; Microsoft, Microsoft Azure; Minsky M. L., 1975, TINLAP '75: Proceedings of the 1975 Workshop on Theoretical Issues in Natural Language Processing, P104, DOI DOI 10.3115/980190.980222; Namasivayam K, 2023, IEEE INT CONF ROBOT, P7973, DOI 10.1109/ICRA48891.2023.10160545; OpenAi, ChatGPT; OpenAI, GPT 4; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan JY, 2023, Arxiv, DOI arXiv:2303.08006; Pramanick P, 2020, IEEE INT C INT ROBOT, P6894, DOI 10.1109/IROS45743.2020.9341289; Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886; Raman SS, 2024, Arxiv, DOI arXiv:2211.09935; Saito D, 2022, IEEE-RAS INT C HUMAN, P880, DOI [10.1109/HUMANOIDS53995.2022.10000167, 10.1109/Humanoids53995.2022.10000167]; Saito D, 2021, ACMIEEE INT CONF HUM, P167, DOI 10.1145/3434074.3447152; Sasabuchi K, 2023, Arxiv, DOI arXiv:2301.01382; Sasabuchi K, 2021, IEEE ROBOT AUTOM LET, V6, P413, DOI 10.1109/LRA.2020.3044029; Shridhar L., 2023, C ROBOT LEARNING, P785; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Skreta M, 2023, Arxiv, DOI arXiv:2303.14100; Takamatsu J., 2022, arXiv; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Venkatesh SG, 2021, IEEE INT C INT ROBOT, P1919, DOI 10.1109/IROS51168.2021.9636342; Wake N., 2020, PROC HOBI RO MAN WOR, P1; Wake N, 2023, IEEE ASME INT C ADV, P1061, DOI 10.1109/AIM46323.2023.10196126; Wake N, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-023-01408-z; Wake N, 2021, IEEE INT CONF ROBOT, P10377, DOI 10.1109/ICRA48506.2021.9562102; Wake N, 2021, IEEE/SICE I S SYS IN, P461, DOI 10.1109/IEEECONF49454.2021.9382750; Wake N, 2019, IEEJ T ELECTR ELECTR, V14, P1815, DOI 10.1002/tee.23008; Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128; Yanaokura I, 2022, IEEE/SICE I S SYS IN, P367, DOI 10.1109/SII52469.2022.9708836; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598; Zhao C, 2023, IEEE ROBOT AUTOM LET, V8, P3230, DOI 10.1109/LRA.2023.3265893; Zhao ZR, 2023, IEEE INT CONF ROBOT, P11546, DOI 10.1109/ICRA48891.2023.10160640	58	4	4	18	23	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						95060	95078		10.1109/ACCESS.2023.3310935	http://dx.doi.org/10.1109/ACCESS.2023.3310935			19	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	AR0M9		Green Submitted, gold			2024-07-03	WOS:001120070500001
J	Marquez, R; Ortiz, MS; Barrios, N; Vera, RE; Patiño-Agudelo, AJ; Vivas, KA; Salas, M; Zambrano, F; Theiner, E				Marquez, Ronald; Ortiz, Maria S.; Barrios, Nelson; Vera, Ramon E.; Patino-Agudelo, alvaro Javier; Vivas, Keren A.; Salas, Mariangeles; Zambrano, Franklin; Theiner, Eric			Surfactants produced from carbohydrate derivatives: Part 2. A review on the value chain, synthesis, and the potential role of artificial intelligence within the biorefinery concept	JOURNAL OF SURFACTANTS AND DETERGENTS			English	Review; Early Access						biobased; biosurfactant; generative AI; large language models; rhamnolipids; surfactant; sustainability	SUGAR-BASED SURFACTANTS; CRITICAL MICELLE CONCENTRATION; BETA-D-GLUCOPYRANOSIDE; ENHANCED OIL-RECOVERY; GEMINI SURFACTANTS; REGIOSELECTIVE SYNTHESIS; AQUEOUS-SOLUTION; STRUCTURAL-CHARACTERIZATION; PHYSICOCHEMICAL PROPERTIES; CHEMOENZYMATIC SYNTHESIS	This comprehensive and critical review explores the synthesis and applications of carbohydrate-based surfactants within the biorefinery concept, focusing on biobased sugar-head molecules suitable for use across several manufacturing sectors, including cosmetics, pharmaceuticals, household products, detergents, and foods. The main focus relies on sustainable alternatives to conventional surfactants, which could reduce the final manufacturing carbon footprint of several industrial feedstocks and products. A thorough analysis of raw materials, highlighting the significance of feedstock sources, and the current biobased surfactants and rhamnolipid biosurfactants production trends, is presented. Key organic reactions for the production of sorbitan esters, sucrose esters, alkyl polyglycosides, and fatty acid glucamines, such as glycosidation, acylation, and etherification, as well as the production of rhamnolipids through fermentation are described. Given the scarce literature on the characterization of these surfactant types within the hydrophilic-lipophilic deviation (HLD) framework, the surfactant contribution parameter (SCP) in the HLD equation for sugar-head surfactants is critically assessed. The economic landscape is also discussed, noting the significant growth in the biobased surfactants and biosurfactant market, driven by environmental awareness and regulatory changes, with projections indicating a substantial market increase in the forthcoming years. Finally, the promising potential of generative artificial intelligence (AI) in developing customized surfactant molecules, with optimized properties for targeted applications, is emphasized as a promising avenue for future research. Potential application of AI in surfactants structure prediction. image	[Marquez, Ronald; Barrios, Nelson; Vera, Ramon E.; Vivas, Keren A.; Salas, Mariangeles] North Carolina State Univ, Dept Forest Biomat, Raleigh, NC 27060 USA; [Ortiz, Maria S.] Univ Andes, Elect Engn Sch, Merida, Venezuela; [Barrios, Nelson] Univ Carabobo, Lab Petr Hydrocarbons & Derivates, Valencia, Venezuela; [Patino-Agudelo, alvaro Javier] Univ Estadual Campinas, Inst Chem, Dept Phys Chem, Campinas, Brazil; [Zambrano, Franklin] Solenis LLC, Wilmington, DE USA; [Theiner, Eric] Evonik Corp, Richmond, VA 23237 USA	North Carolina State University; University of Los Andes Venezuela; Universidade Estadual de Campinas	Marquez, R; Barrios, N; Vera, RE (corresponding author), North Carolina State Univ, Dept Forest Biomat, Raleigh, NC 27060 USA.; Theiner, E (corresponding author), Evonik Corp, Richmond, VA 23237 USA.	rjmarque@ncsu.edu; nabarrio@ncsu.edu; rverave@ncsu.edu; rick.theiner@evonik.com	Marquez, Ronald/R-5626-2018; Vera, Ramon/JXY-6042-2024	Marquez, Ronald/0000-0001-6003-7487; Vera, Ramon/0000-0002-1791-738X	CNPq [151115/2023-0]; FAPESP [2023/11091-9]	CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	The authors wish to express their gratitude to Emeritus Professor Jean-Louis Salager, Emeritus Editor in Chief of the Journal of Surfactants and Detergents, to whom this special issue is dedicated. We would also like to express our acknowledgments to our colleagues and former co-authors on the subject of formulation with surfactants: Johnny Bullon and Ana Forgiarini from Venezuela, Jesus Ontiveros, Valerie Molinier, Dominique Langevin, Veronique Nardello-Rataj, and Jean-Marie Aubry from France. The authors also wish to thank all the Ph.D. students and researchers from FIRP Laboratory (University of Los Andes), PHD Laboratory (University of Carabobo), and CISCO-UCCS (University of Lille), who have significantly contributed to the body of knowledge on this subject. The authors also acknowledge the continuous support of Dr. Ronalds Gonzalez and Dr. Lokendra Pal from North Carolina State University. Alvaro Javier Patino-Agudelo acknowledges post-doctoral fellowships provided by the CNPq (151115/2023-0) and FAPESP (2023/11091-9). Professor Douglas Hayes is thanked for his recommendations on the structure and contents of the review.	Abdel-Mawgoud AM, 2011, MICROBIOL MONOGR, V20, P13, DOI 10.1007/978-3-642-14490-5_2; Abdel-Mawgoud AM, 2010, APPL MICROBIOL BIOT, V86, P1323, DOI 10.1007/s00253-010-2498-2; Abdellahi B, 2021, TETRAHEDRON LETT, V74, DOI 10.1016/j.tetlet.2021.153113; Acosta EJ, 2008, J SURFACTANTS DETERG, V11, P145, DOI 10.1007/s11743-008-1065-7; Adu SA, 2023, MOLECULES, V28, DOI 10.3390/molecules28114463; Agger JW, 2022, CURR OPIN BIOTECH, V78, DOI 10.1016/j.copbio.2022.102842; Ahalliya RM., 2022, Multifunctional microbial biosurfactants, DOI [10.1007/978-3-031-31230-4_22, DOI 10.1007/978-3-031-31230-4_22]; Al-Wahaibi Y, 2014, COLLOID SURFACE B, V114, P324, DOI 10.1016/j.colsurfb.2013.09.022; Allen DK, 2002, J SURFACTANTS DETERG, V5, P245, DOI 10.1007/s11743-002-0224-y; Anaukwu CG., 2020, Adv Microbiol, V10, P543, DOI [10.4236/AIM.2020.1010040, DOI 10.4236/AIM.2020.1010040, 10.4236/aim.2020.1010040]; ANTON RE, 1992, J DISPER SCI TECHNOL, V13, P565, DOI 10.1080/01932699208943334; Aoudia M, 1998, J COLLOID INTERF SCI, V206, P158, DOI 10.1006/jcis.1998.5627; Arias KS, 2013, CHEMSUSCHEM, V6, P123, DOI 10.1002/cssc.201200513; Aricò F, 2020, CURR OPIN GREEN SUST, V21, P82, DOI 10.1016/j.cogsc.2020.02.002; Aubry JM, 2020, ADV COLLOID INTERFAC, V276, DOI 10.1016/j.cis.2019.102099; Axelsson L, 2012, BIOFUEL BIOPROD BIOR, V6, P246, DOI 10.1002/bbb.1324; Azhar NNH, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14095032; Baccile N, 2021, GREEN CHEM, V23, P3842, DOI 10.1039/d1gc00097g; BACZKO K, 1995, CARBOHYD RES, V269, P79, DOI 10.1016/0008-6215(94)00341-C; Bahia FM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21230-2; Bajwa DS, 2019, IND CROP PROD, V139, DOI 10.1016/j.indcrop.2019.111526; Bannigan P, 2021, ADV DRUG DELIVER REV, V175, DOI 10.1016/j.addr.2021.05.016; Bardhan SK, 2015, RENEW SUST ENERG REV, V51, P506, DOI 10.1016/j.rser.2015.06.013; Barrios N, 2022, J MOL LIQ, V363, DOI 10.1016/j.molliq.2022.119899; Baskaran SM, 2021, ENVIRON POLLUT, V276, DOI 10.1016/j.envpol.2021.116742; Bault P, 1998, LIQ CRYST, V24, P283, DOI 10.1080/026782998207460; Becker J, 2019, BIOTECHNOL ADV, V37, DOI 10.1016/j.biotechadv.2019.02.016; Begum W, 2023, RSC ADV, V13, P25599, DOI 10.1039/d3ra05051c; Behr A, 2009, ANGEW CHEM INT EDIT, V48, P3598, DOI 10.1002/anie.200804599; Benhur AM, 2020, J COSMET SCI, V71, P455; Benvegnu T, 2008, MONOMERS, POLYMERS AND COMPOSITES FROM RENEWABLE RESOURCES, P153, DOI 10.1016/B978-0-08-045316-3.00007-7; Bertho J-N., 1997, Process for the preparation of surface active agents using wheat by-products and their applications; Bettenhausen C., 2024, CEN; Bhadani A, 2020, CURR OPIN COLLOID IN, V45, P124, DOI 10.1016/j.cocis.2020.01.002; Bhattacharya S, 1999, CHEM MATER, V11, P3121, DOI 10.1021/cm990207v; Bhattacharya S, 1999, CHEM MATER, V11, P3504, DOI 10.1021/cm9902265; BOCK K, 1982, CARBOHYD RES, V100, P63, DOI 10.1016/S0008-6215(00)81026-5; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Bouxin F, 2010, CARBOHYD RES, V345, P2469, DOI 10.1016/j.carres.2010.09.003; Bozell JJ, 2010, GREEN CHEM, V12, P539, DOI 10.1039/b922014c; Brozos C., 2024, arXiv, P1; Byrne EP, 2023, EDUC CHEM ENG, V43, P23, DOI 10.1016/j.ece.2023.01.004; CABARET D, 1986, CARBOHYD RES, V149, P464, DOI 10.1016/S0008-6215(00)90068-5; Cardoso MVC, 2013, LANGMUIR, V29, P15778, DOI 10.1021/la403526w; Cesaro A, 2023, EXPERT OPIN DRUG DIS, DOI 10.1080/17460441.2023.2250721; Chakraborty J, 2017, APPL SPECTROSC REV, V52, P1, DOI 10.1080/05704928.2016.1199028; Chandel AK, 2020, BIOFUEL BIOPROD BIOR, V14, P830, DOI 10.1002/bbb.2104; CHAUVIN C, 1993, J ORG CHEM, V58, P2291, DOI 10.1021/jo00060a053; CHAUVIN C, 1991, TETRAHEDRON LETT, V32, P3495, DOI 10.1016/0040-4039(91)80815-N; CHEMANALYST, 2023, Fatty alcohol prices, monitor, market analysis demand [WWW document]; CHEMANALYST, 2023, Fatty acid prices, monitor, news, market analysis demand [WWW document]; Chen J, 2005, J BIOSCI BIOENG, V100, P274, DOI 10.1263/jbb.100.274; Cherubini F, 2010, ENERG CONVERS MANAGE, V51, P1412, DOI 10.1016/j.enconman.2010.01.015; Chin SY, 2023, IND ENG CHEM RES, V62, P4210, DOI 10.1021/acs.iecr.2c04039; Chong HQ, 2017, MICROB CELL FACT, V16, DOI 10.1186/s12934-017-0753-2; Ciriminna R, 2015, ORG PROCESS RES DEV, V19, P748, DOI 10.1021/op500313x; Colombo S., 2020, Chapter 4-Applications of artificial intelligence in drug delivery and pharmaceutical development, P85, DOI [10.1016/B978-0-12-818438-7.00004-6, DOI 10.1016/B978-0-12-818438-7.00004-6]; COSTES F, 1995, LANGMUIR, V11, P3644, DOI 10.1021/la00010a010; Dabaghi S, 2023, BMC BIOTECHNOL, V23, DOI 10.1186/s12896-022-00772-4; Dalili D, 2015, COLLOID SURFACE B, V135, P425, DOI 10.1016/j.colsurfb.2015.07.005; DAVIES DB, 1987, CARBOHYD RES, V163, P269, DOI 10.1016/0008-6215(87)80188-X; Delforce L, 2022, ACS OMEGA, V7, P38869, DOI 10.1021/acsomega.2c04592; Demchenko AV, 2008, Handbook of chemical glycosylation, DOI [10.1002/9783527621644.ch1, DOI 10.1002/9783527621644.CH1]; Desvergnes-Breuil V, 2001, GREEN CHEM, V3, P175, DOI 10.1039/b103189a; Dobler L, 2016, NEW BIOTECHNOL, V33, P123, DOI 10.1016/j.nbt.2015.09.005; Rivera AD, 2019, WORLD J MICROB BIOT, V35, DOI 10.1007/s11274-019-2729-3; DOW, 2023, Dow Consum Ind Solut; Dudefoi W, 2018, INNOV FOOD SCI EMERG, V46, P107, DOI 10.1016/j.ifset.2017.09.007; El Ghoul M., 1996, N-alkyl, n-acetylglycosylamines; El-Housseiny GS, 2020, AMB EXPRESS, V10, DOI 10.1186/s13568-020-01141-0; Emergen Research, 2021, Biosurfactants market trend. Industry Forecast by 2030; Esposito R, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms24065395; Estrine B, 2004, EUR J ORG CHEM, V2004, P2914, DOI 10.1002/ejoc.200400064; Estrine B., 2019, Chapter 11-Synthesis of alkyl Polyglycosides from glucose and xylose for biobased surfactants: synthesis, properties, and applications, VSecond ed., P365, DOI [10.1016/B978-0-12-812705-6.00011-3, DOI 10.1016/B978-0-12-812705-6.00011-3]; Evonik, 2020, SCHAUM-HOCHZEIT [WWW document]; Evonik, 2023, Biosurfactants by evonik: entering a new era of surfactants [WWW document]; Evonik Corporation, 2022, Evonik builds world's first industrial-scale production plant for rhamnolipids [WWW document]; Farias CBB, 2021, ELECTRON J BIOTECHN, V51, P28, DOI 10.1016/j.ejbt.2021.02.002; Ferrer M, 2002, LANGMUIR, V18, P667, DOI 10.1021/la010727g; Ferrières V, 1999, J CHEM SOC PERK T 2, P951, DOI 10.1039/a900192a; Ferrières V, 1998, CARBOHYD RES, V311, P25, DOI 10.1016/S0008-6215(98)00197-9; Fielden ML, 2001, EUR J BIOCHEM, V268, P1269, DOI 10.1046/j.1432-1327.2001.01995.x; Foley P, 2012, CHEM SOC REV, V41, P1499, DOI 10.1039/c1cs15217c; Forgiarini AM, 2021, MOLECULES, V26, DOI 10.3390/molecules26123771; FORSTER T, 1995, ADV COLLOID INTERFAC, V58, P119, DOI 10.1016/0001-8686(95)00247-N; Fortune Business Insights, 2022, Biosurfactants market size, share, trends; FREGAPANE G, 1991, ENZYME MICROB TECH, V13, P796, DOI 10.1016/0141-0229(91)90062-F; Freitas BG, 2016, FRONT MICROBIOL, V7, DOI 10.3389/fmicb.2016.01646; Gagnaire J, 1999, TETRAHEDRON LETT, V40, P2757, DOI 10.1016/S0040-4039(99)00321-4; Gagnaire J, 2000, COLLOID SURFACE A, V172, P125, DOI 10.1016/S0927-7757(00)00491-X; Gao CL, 1999, J SURFACTANTS DETERG, V2, P293, DOI 10.1007/s11743-999-0080-9; Garg N, 2010, FOOD RES INT, V43, P1111, DOI 10.1016/j.foodres.2010.02.003; Garofalakis G, 2000, J COLLOID INTERF SCI, V229, P391, DOI 10.1006/jcis.2000.7035; Gaudin T, 2019, ADV COLLOID INTERFAC, V270, P87, DOI 10.1016/j.cis.2019.06.003; Gaur VK, 2022, BIORESOURCE TECHNOL, V343, DOI 10.1016/j.biortech.2021.126059; Geissler M, 2017, J CHROMATOGR B, V1044, P214, DOI 10.1016/j.jchromb.2016.11.013; Gonçalves RA, 2023, J MOL LIQ, V375, DOI 10.1016/j.molliq.2023.121335; Goodby JW, 1995, J MATER CHEM, V5, P2209, DOI 10.1039/jm9950502209; Gozlan C, 2016, GREEN CHEM, V18, P1994, DOI 10.1039/c5gc02131f; Guo YQ, 2012, APPL ENVIRON MICROB, V78, P3156, DOI 10.1128/AEM.07782-11; Gutsche B., 1999, Handbook of detergents. Part B: formulation; Guzmán E, 2024, CURR OPIN COLLOID IN, V69, DOI 10.1016/j.cocis.2023.101780; Hadad C, 2006, CARBOHYD RES, V341, P1938, DOI 10.1016/j.carres.2006.04.023; Haese M, 2022, TOPICS CURR CHEM, V380, DOI 10.1007/s41061-022-00383-9; Hassanzadeh P, 2019, ADV DRUG DELIVER REV, V151, P169, DOI 10.1016/j.addr.2019.05.001; Hayes D.G., 2019, Biobased Surfactants, P3, DOI [10.1016/b978-0-12-812705-6.00001-0, DOI 10.1016/B978-0-12-812705-6.00001-0]; Hayes DG, 2022, J SURFACTANTS DETERG, V25, P729, DOI 10.1002/jsde.12633; Herrmann C, 2022, RESOUR CONSERV RECY, V181, DOI 10.1016/j.resconrec.2022.106219; Hill K., 2008, Technol Propert Appl, DOI [10.1002/9783527614691, DOI 10.1002/9783527614691]; Hirata Y, 2009, J OLEO SCI, V58, P565, DOI 10.5650/jos.58.565; Hu FX, 2019, MICROB CELL FACT, V18, DOI 10.1186/s12934-019-1089-x; Hubbe MA., 2022, Bioresources, V17; Ibrahim Haytham M. M., 2018, Egyptian Journal of Petroleum, V27, P21, DOI 10.1016/j.ejpe.2016.12.005; Ibrahim ML, 2013, INT BIODETER BIODEGR, V81, P28, DOI 10.1016/j.ibiod.2012.11.012; Iglauer S, 2009, COLLOID SURFACE A, V339, P48, DOI 10.1016/j.colsurfa.2009.01.015; Inokuchi T, 2018, NANOSCALE, V10, P16013, DOI 10.1039/c8nr03332c; Jahan R, 2020, ADV COLLOID INTERFAC, V275, DOI 10.1016/j.cis.2019.102061; Jamil F, 2022, REV CHEM ENG, V38, P185, DOI 10.1515/revce-2019-0026; Jérôme F, 2018, CHEMSUSCHEM, V11, P1395, DOI 10.1002/cssc.201800265; Jessop PG, 2015, GREEN CHEM, V17, P2664, DOI 10.1039/c4gc02261k; Jha S., 2022, Alkyl polyglucoside market trend analysis forecast-2032; Jiang JJ, 2020, BIORESOURCE TECHNOL, V298, DOI 10.1016/j.biortech.2019.122394; Jimoh AA, 2019, INT J ENVIRON SCI TE, V16, P4143, DOI 10.1007/s13762-019-02341-3; Johnsson M, 2004, J PHYS ORG CHEM, V17, P934, DOI 10.1002/poc.817; Johnsson M, 2003, LANGMUIR, V19, P4609, DOI 10.1021/la0343270; KARL H, 1982, CARBOHYD RES, V101, P31, DOI 10.1016/S0008-6215(00)80792-2; Kinanti FPA., 2021, AIP Conf Proc, V2349, P20018, DOI [10.1063/5.0051813, DOI 10.1063/5.0051813]; Kipshagen L, 2019, GREEN CHEM, V21, P3882, DOI 10.1039/c9gc01163c; Kong S, 2021, ACS OMEGA, V6, P15750, DOI 10.1021/acsomega.1c01099; Krawczyk J, 2018, J MOL LIQ, V271, P610, DOI 10.1016/j.molliq.2018.09.013; Kumar B, 2020, IND CROP PROD, V154, DOI 10.1016/j.indcrop.2020.112607; Lang S, 2002, CURR OPIN COLLOID IN, V7, P12, DOI 10.1016/S1359-0294(02)00007-9; LATGE P, 1991, J DISPER SCI TECHNOL, V12, P227, DOI 10.1080/01932699108913127; Le Guenic S, 2019, J SURFACTANTS DETERG, V22, P5, DOI 10.1002/jsde.12216; Lebeuf R, 2018, ACS SUSTAIN CHEM ENG, V6, P2758, DOI 10.1021/acssuschemeng.7b04456; Lei X., 2023, arXiv Prepr, P4013; Leitermann F., 2010, Rhamnolipids-Handbook of hydrocarbon and lipid microbiology, P3037, DOI [10.1007/978-3-540-77587-4_227, DOI 10.1007/978-3-540-77587-4_227]; Lemahieu G, 2020, RSC ADV, V10, P16377, DOI 10.1039/d0ra02326d; Leng ZT, 2023, J SURFACTANTS DETERG, V26, P287, DOI 10.1002/jsde.12653; Levy D.E., 2005, The Organic Chemistry of Sugars, V1st; Li G, 2019, J PET EXPLOR PROD TE, V9, P2671, DOI 10.1007/s13202-019-0658-1; Li J, 2016, INT BIODETER BIODEGR, V112, P72, DOI 10.1016/j.ibiod.2016.05.002; Liang PX, 2023, BIOTECHNOL ADV, V64, DOI 10.1016/j.biotechadv.2023.108105; Lichtenthaler Frieder W., 2010, Ullmann's Encyclopedia of Industrial Chemistry, DOI [DOI 10.1002/14356007.N05_N07, 10.1002/ 14356007.n05_n07]; LICHTENTHALER FW, 1995, LIEBIGS ANN, P1939, DOI 10.1002/jlac.1995199511273; LICHTENTHALER FW, 1991, STARCH-STARKE, V43, P121, DOI 10.1002/star.19910430402; Liu YT, 2022, FRONT MICROBIOL, V13, DOI 10.3389/fmicb.2022.997587; Lokesh K, 2017, GREEN CHEM, V19, P4380, DOI [10.1039/C7GC01719G, 10.1039/c7gc01719g]; Longati AA., 2023, Biosurfactants and sustainability, P281, DOI [10.1002/9781119854395.ch14, DOI 10.1002/9781119854395.CH14]; Ludot C, 2014, IND CROP PROD, V58, P335, DOI 10.1016/j.indcrop.2014.04.039; Machado JV, 2023, CATAL COMMUN, V182, DOI 10.1016/j.catcom.2023.106740; Mansi K, 2023, J DRUG DELIV SCI TEC, V81, DOI 10.1016/j.jddst.2023.104269; Marinkovic S, 2012, INT J MOL SCI, V13, P348, DOI 10.3390/ijms13010348; Markets and Markets, 2022, Surfactants market size, industry share growth forecast, global trends report; Marquez R, 2024, J SURFACTANTS DETERG, V27, P5, DOI 10.1002/jsde.12703; Marquez R, 2022, J SURFACTANTS DETERG, V25, P667, DOI 10.1002/jsde.12609; Martel F, 2010, TOP CURR CHEM, V294, P79, DOI 10.1007/128_2010_54; Martínez AE, 2022, IND CROP PROD, V190, DOI 10.1016/j.indcrop.2022.115892; Matátková O, 2022, MICROORGANISMS, V10, DOI 10.3390/microorganisms10071272; Medhi MK., 2023, Advancements in biosurfactants research, P79, DOI [10.1007/978-3-031-21682-4_4/FIGURES/1, DOI 10.1007/978-3-031-21682-4_4/FIGURES/1, 10.1007/978-3-031-21682-4_4, DOI 10.1007/978-3-031-21682-4_4]; Mika LT, 2018, CHEM REV, V118, P505, DOI 10.1021/acs.chemrev.7b00395; Mohanty SS, 2021, MICROB CELL FACT, V20, DOI 10.1186/s12934-021-01613-3; Monteiro SA, 2007, CHEM PHYS LIPIDS, V147, P1, DOI 10.1016/j.chemphyslip.2007.02.001; Morone P, 2021, INT J PROD ECON, V240, DOI 10.1016/j.ijpe.2021.108248; Mostafa NA, 2019, J SURFACTANTS DETERG, V22, P385, DOI 10.1002/jsde.12240; Muller M., 2021, Biosurfactants-trends and perspectives HiPerIn 2.0 Whitepaper; Nagrale P., 2023, Bio-based surfactant market research report [WWW document]. Mark Res Futur; Nagtode VS, 2023, ACS OMEGA, V8, P11674, DOI 10.1021/acsomega.3c00591; Nguyen TT, 2011, INT J MOL SCI, V12, P1232, DOI 10.3390/ijms12021232; Nguyen TTL, 2010, J COLLOID INTERF SCI, V348, P498, DOI 10.1016/j.jcis.2010.04.053; Nilsson F., 1998, Phase Diagr Aggr Size Struct Langmuir, V14, P4050, DOI [10.1021/la980261a, DOI 10.1021/LA980261A]; Ohtake S, 2011, J PHARM SCI-US, V100, P2020, DOI 10.1002/jps.22458; Ontiveros JF, 2021, ACS SUSTAIN CHEM ENG, V9, P16977, DOI 10.1021/acssuschemeng.1c05371; Ontiveros JF, 2018, COLLOID SURFACE A, V536, P30, DOI 10.1016/j.colsurfa.2017.08.002; Ortiz MS, 2022, J SURFACTANTS DETERG, V25, P147, DOI 10.1002/jsde.12581; Oskarsson H, 2007, J SURFACTANTS DETERG, V10, P41, DOI 10.1007/s11743-006-1007-1; Ou LW, 2021, BIOFUEL BIOPROD BIOR, V15, P404, DOI 10.1002/bbb.2170; Pal A, 2021, RSC ADV, V11, P33004, DOI 10.1039/d1ra04968b; Pantazaki AA, 2011, AMB EXPRESS, V1, DOI 10.1186/2191-0855-1-17; Pantelic I, 2014, WOODH PUB SER BIOMED, P1, DOI 10.1533/9781908818775.1; Park DS, 2016, ACS CENTRAL SCI, V2, P820, DOI 10.1021/acscentsci.6b00208; Pastor O, 1998, LANGMUIR, V14, P2950, DOI 10.1021/la9708445; Pätäri S, 2016, FOREST POLICY ECON, V66, P38, DOI 10.1016/j.forpol.2015.10.009; Patel L, 2020, MOLECULES, V25, DOI 10.3390/molecules25225277; Pathania AS, 2020, J ENVIRON CHEM ENG, V8, DOI 10.1016/j.jece.2020.104304; Agudelo AJP, 2020, COLLOID SURFACE A, V589, DOI 10.1016/j.colsurfa.2020.124435; Patiño-Agudelo AJ, 2022, J PHYS CHEM B, DOI 10.1021/acs.jpcb.2c05054; Patiño-Agudelo AJ, 2022, J COLLOID INTERF SCI, V611, P39, DOI 10.1016/j.jcis.2021.12.062; Penfold J, 2011, LANGMUIR, V27, P8867, DOI 10.1021/la201661y; Pestman JM, 1999, LANGMUIR, V15, P2009, DOI 10.1021/la981404w; Pestman JM, 1997, LANGMUIR, V13, P6857, DOI 10.1021/la970681k; Philippini RR, 2020, FRONT ENERGY RES, V8, DOI 10.3389/fenrg.2020.00152; PLATZ G, 1995, LANGMUIR, V11, P4250, DOI 10.1021/la00011a015; Polat T, 2001, J SURFACTANTS DETERG, V4, P415; Queneau Y, 2004, CR CHIM, V7, P177, DOI 10.1016/j.crci.2003.10.014; Queste S, 2007, J COLLOID INTERF SCI, V312, P98, DOI 10.1016/j.jcis.2006.07.004; Rahman AA, 2024, COLLOID SURFACE A, V688, DOI 10.1016/j.colsurfa.2024.133623; Rámirez M, 2002, J DISPER SCI TECHNOL, V23, P309, DOI 10.1080/01932690208984207; Rashidi-Khaniabadi A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-37933-0; Rather M.Y., 2013, Sustain Chem Process, V1, P7, DOI DOI 10.1186/2043-7129-1-7; Ratna S, 2022, J CLEAN PROD, V336, DOI 10.1016/j.jclepro.2022.130429; Renault B, 2012, J SURFACTANTS DETERG, V15, P191, DOI 10.1007/s11743-011-1298-8; RicoLattes I, 1997, COLLOID SURFACE A, V123, P37, DOI 10.1016/S0927-7757(96)03778-8; Roelants S., 2019, Biobased Surfactants: Synthesis, Properties and Applications, P65, DOI [10.1016/B978-0-12-812705-6.00003-4, DOI 10.1016/B978-0-12-812705-6.00003-4]; Roelants SLKW, 2022, ADV BIOCHEM ENG BIOT, V181, P1, DOI 10.1007/10_2021_175; Ryan D.A., 2008, HDB CHEM GLYCOSYLATI, P95, DOI [10.1002/9783527621644.ch3a, DOI 10.1002/9783527621644.CH3A]; Salager J-L., 2022, Encyclopedia, V2, P778, DOI [10.3390/encyclopedia2020054, DOI 10.3390/ENCYCLOPEDIA2020054]; Salager J-L., 2022, JCIS Open, V8, DOI [10.1016/j.jciso.2022.100060, DOI 10.1016/J.JCISO.2022.100060]; Salager J-L., 2002, Enhancing solubilization in microemulsions: from classic to novel "extended" surfactant structures, in Surfactants in solution. Barcelona; Salager JL, 2021, J SURFACTANTS DETERG, V24, P731, DOI 10.1002/jsde.12518; Salager JL, 2023, ACS OMEGA, V8, P9040, DOI 10.1021/acsomega.3c00547; Salager JL, 2022, ENERG FUEL, V36, P711, DOI 10.1021/acs.energyfuels.1c03349; Salager JL, 2020, COSMETICS-BASEL, V7, DOI 10.3390/cosmetics7030057; Salager JL, 2019, J SURFACTANTS DETERG, V22, P935, DOI 10.1002/jsde.12331; Salager JL, 2013, J SURFACTANTS DETERG, V16, P631, DOI 10.1007/s11743-013-1485-x; Salager JL, 2012, ENERG FUEL, V26, P4027, DOI 10.1021/ef3001604; Santos BLP, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15086341; SARNEY DB, 1994, J AM OIL CHEM SOC, V71, P711, DOI 10.1007/BF02541426; Sayyed RZ., 2022, Microbial surfactants volume 2, applications in food and agriculture, VFirst ed.; Schiefelbein L, 2010, EUR J PHARM BIOPHARM, V76, P342, DOI 10.1016/j.ejpb.2010.08.012; Schuur B, 2004, CARBOHYD RES, V339, P1147, DOI 10.1016/j.carres.2004.01.021; Schweidtmann AM., 2024, Nat Chem Eng, V1, P193, DOI [10.1038/s44286-024-00041-5, DOI 10.1038/S44286-024-00041-5]; Scorzza C, 2002, J SURFACTANTS DETERG, V5, P337, DOI 10.1007/s11743-002-0231-z; Scorzza C, 2002, J SURFACTANTS DETERG, V5, P331, DOI 10.1007/s11743-002-0230-0; Seddon D, 2022, J COLLOID INTERF SCI, V625, P328, DOI 10.1016/j.jcis.2022.06.034; SelinaWamucii, 2023, US fructose prices [WWW document]; Shah J, 2016, J SURFACTANTS DETERG, V19, P1333, DOI 10.1007/s11743-016-1867-y; Sharma D, 2023, MOLECULES, V28, DOI 10.3390/molecules28062823; Shekhar S, 2015, CRIT REV ENV SCI TEC, V45, P1522, DOI 10.1080/10643389.2014.955631; Shi J, 2021, J CLEAN PROD, V278, DOI 10.1016/j.jclepro.2020.123879; Shi YG, 2011, J CHEM TECHNOL BIOT, V86, P1457, DOI 10.1002/jctb.2711; SHINODA K, 1961, B CHEM SOC JPN, V34, P237, DOI 10.1246/bcsj.34.237; Silva EJ, 2014, COLLOID SURFACE B, V117, P36, DOI 10.1016/j.colsurfb.2014.02.012; Sing AJF, 1999, COLLOID SURFACE A, V152, P31, DOI 10.1016/S0927-7757(98)00622-0; Smith GA., 2019, Biobased surfactants: synthesis, properties, and application, VSecond ed., P287, DOI [DOI 10.1016/B978-0-12-812705-6.00008-3, 10.1016/B978-0-12-812705-6.00008-3]; Smith MB., 2017, Chapter 13-Nucleophilic species that form carbon-carbon bonds: enolate anions, VFourth ed., P659, DOI [10.1016/B978-0-12-800720-4.00013-1, DOI 10.1016/B978-0-12-800720-4.00013-1]; Soberón-Chavez G, 2021, MICROB BIOTECHNOL, V14, P136, DOI 10.1111/1751-7915.13700; Söderman O, 1999, CURR OPIN COLLOID IN, V4, P391, DOI 10.1016/S1359-0294(00)00019-4; Soultani S, 2003, COLLOID SURFACE A, V227, P35, DOI 10.1016/S0927-7757(03)00360-1; Stubbs S, 2022, DARU, V30, P407, DOI 10.1007/s40199-022-00450-y; Stubenrauch C, 2001, CURR OPIN COLLOID IN, V6, P160, DOI 10.1016/S1359-0294(01)00080-2; Sun MX, 2018, RENEW SUST ENERG REV, V92, P823, DOI 10.1016/j.rser.2018.04.036; Sundaram T, 2024, FRONT MICROBIOL, V15, DOI 10.3389/fmicb.2024.1357302; Tan E C.D., 2021, Front. Sustain, V2, DOI DOI 10.3389/FRSUS.2021.701509; Tan YNA, 2018, MICROB CELL FACT, V17, DOI 10.1186/s12934-018-0938-3; Thacker JCR, 2023, J PHYS CHEM B, V127, P3711, DOI 10.1021/acs.jpcb.2c08232; Thenchartanan P, 2020, BIOTECHNOL LETT, V42, P2379, DOI 10.1007/s10529-020-02960-8; Tiso T, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00976; Tripathy DB., 2021, Surfactants from renewable raw materials, DOI [10.1201/9781003144878, DOI 10.1201/9781003144878]; Ubando AT, 2020, BIORESOURCE TECHNOL, V299, DOI 10.1016/j.biortech.2019.122585; Unilever, 2020, Unilever to eliminate fossil fuels in cleaning products by 2030. Unilever [WWW document]; Unilever, 2019, Nature and science combine to create a cleaning world-first [WWW document]; Unilever, 2022, Building a clean green foam-production machine [WWW document]; URATA K, 1995, J AM OIL CHEM SOC, V72, P73, DOI 10.1007/BF02635782; USDA ERS, 2023, Sugar and sweeteners prices [WWW document]; Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5; van Doren HA, 2000, CHEM SOC REV, V29, P183, DOI 10.1039/a804242j; van Es DS, 2013, J SURFACTANTS DETERG, V16, P147, DOI 10.1007/s11743-012-1382-8; VANAKEN T, 1986, METHOD ENZYMOL, V125, P27; Varjani S, 2021, BIORESOURCE TECHNOL, V319, DOI 10.1016/j.biortech.2020.124213; Vera RE, 2023, J CLEAN PROD, V429, DOI 10.1016/j.jclepro.2023.139394; Vera RE, 2023, CHEM ENG J, V467, DOI 10.1016/j.cej.2023.143321; Vera RE, 2023, RESOUR CONSERV RECY, V189, DOI 10.1016/j.resconrec.2022.106715; Vera RE., 2022, Cleaner and Circular Bioeconomy, V3, DOI [DOI 10.1016/J.CLCB.2022.100026, 10.1016/j.clcb.2022.100026]; Vlahov IR, 1997, J CARBOHYD CHEM, V16, P1, DOI 10.1080/07328309708006506; von Rybinski W, 1998, ANGEW CHEM INT EDIT, V37, P1328, DOI 10.1002/(SICI)1521-3773(19980605)37:10<1328::AID-ANIE1328>3.0.CO;2-9; vonRybinski W, 1996, CURR OPIN COLLOID IN, V1, P587, DOI 10.1016/S1359-0294(96)80096-3; Vora LK, 2023, PHARMACEUTICS, V15, DOI 10.3390/pharmaceutics15071916; Vu HP, 2020, SCI TOTAL ENVIRON, V743, DOI 10.1016/j.scitotenv.2020.140630; Vucurovic D, 2024, FOODS, V13, DOI 10.3390/foods13050711; Walker S, 2020, J CLEAN PROD, V261, DOI 10.1016/j.jclepro.2020.121158; Wang L., 2019, Green Chem. Chemical Eng., P349, DOI [10.1007/978-1-4939-9060-3_1009, DOI 10.1007/978-1-4939-9060-3_1009]; Wang QH, 2007, CARBOHYD RES, V342, P2657, DOI 10.1016/j.carres.2007.08.014; Wang Z., 2010, Comprehensive Organic Name Reactions and Reagents, P2345, DOI DOI 10.1002/9780470638859; Warwel S, 2004, J SURFACTANTS DETERG, V7, P187, DOI 10.1007/s11743-004-0303-0; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Werpy T., 2004, TOP VALUE ADDED CHEM, V1, P1, DOI [10.2172/15008859, DOI 10.2172/15008859]; Wittgens A, 2011, MICROB CELL FACT, V10, DOI 10.1186/1475-2859-10-80; Wong F, 2023, NATURE, DOI 10.1038/s41586-023-06887-8; Wu JR, 2019, BIOPROC BIOSYST ENG, V42, P777, DOI 10.1007/s00449-019-02081-1; Wu LM, 2019, COLLOID SURFACE B, V181, P593, DOI 10.1016/j.colsurfb.2019.06.012; Wu WL, 2021, RSC ADV, V11, P14710, DOI 10.1039/d1ra00337b; Yang ZZ, 2024, Arxiv, DOI arXiv:2312.06470; Yu YX, 2008, CHINESE J CHEM ENG, V16, P517, DOI 10.1016/S1004-9541(08)60115-9; Zambrano F, 2021, RESOUR CONSERV RECY, V175, DOI 10.1016/j.resconrec.2021.105854; Zan M, 2023, J DISPER SCI TECHNOL, DOI 10.1080/01932691.2023.2239330; Zargar AN., 2024, Progress in biochemistry and biotechnology, P425, DOI [10.1016/B978-0-443-13288-9.00015-2, DOI 10.1016/B978-0-443-13288-9.00015-2]; Zhang RT, 1999, LANGMUIR, V15, P7510, DOI 10.1021/la990076c; Zhang X, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114845; Zhao F, 2021, BIORESOURCE TECHNOL, V323, DOI 10.1016/j.biortech.2020.124605; Zhao F, 2019, RSC ADV, V9, P2885, DOI 10.1039/c8ra09351b; Zion Market Research, 2020, Biosurfactants market size, share, trends value 2023-2030 [WWW document]	292	0	0	9	9	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1097-3958	1558-9293		J SURFACTANTS DETERG	J. Surfactants Deterg.	2024 MAY 21	2024										10.1002/jsde.12766	http://dx.doi.org/10.1002/jsde.12766		MAY 2024	52	Chemistry, Applied; Chemistry, Physical; Engineering, Chemical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering	RL9N9		hybrid			2024-07-03	WOS:001227938800001
J	Chesterman, S				Chesterman, Simon			Good models borrow, great models steal: intellectual property rights and generative AI	POLICY AND SOCIETY			English	Article; Early Access						artificial intelligence; generative AI; large language models; copyright; intellectual property	ARTIFICIAL-INTELLIGENCE	Two critical policy questions will determine the impact of generative artificial intelligence (AI) on the knowledge economy and the creative sector. The first concerns how we think about the training of such models-in particular, whether the creators or owners of the data that are "scraped" (lawfully or unlawfully, with or without permission) should be compensated for that use. The second question revolves around the ownership of the output generated by AI, which is continually improving in quality and scale. These topics fall in the realm of intellectual property, a legal framework designed to incentivize and reward only human creativity and innovation. For some years, however, Britain has maintained a distinct category for "computer-generated" outputs; on the input issue, the EU and Singapore have recently introduced exceptions allowing for text and data mining or computational data analysis of existing works. This article explores the broader implications of these policy choices, weighing the advantages of reducing the cost of content creation and the value of expertise against the potential risk to various careers and sectors of the economy, which might be rendered unsustainable. Lessons may be found in the music industry, which also went through a period of unrestrained piracy in the early digital era, epitomized by the rise and fall of the file-sharing service Napster. Similar litigation and legislation may help navigate the present uncertainty, along with an emerging market for "legitimate" models that respect the copyright of humans and are clear about the provenance of their own creations.	[Chesterman, Simon] Natl Univ Singapore, Fac Law, Singapore, Singapore; [Chesterman, Simon] AI Singapore, AI Governance, Singapore, Singapore	National University of Singapore	Chesterman, S (corresponding author), Natl Univ Singapore, Fac Law, Singapore, Singapore.; Chesterman, S (corresponding author), AI Singapore, AI Governance, Singapore, Singapore.	chesterman@nus.edu.sg						Abbott R, 2020, REASONABLE ROBOT: ARTIFICIAL INTELLIGENCE AND THE LAW, P1, DOI 10.1017/9781108631761; Aguiar L, 2018, INFORM SYST RES, V29, P656, DOI 10.1287/isre.2018.0778; Alfonsi C., 2019, Kennedy School Review, V19, P166; Alter A., 2023, NEW YORK TIMES; [Anonymous], 2022, NATURE, V607, P211, DOI 10.1038/d41586-022-01895-6; [Anonymous], 2019, Compendium of U.S. Copyright Office Practices; [Anonymous], 2023, United States Copyright Office: Copyright Review Board; [Anonymous], 2023, Generative AI could raise global GDP by 7%; [Anonymous], 2023, Executive order on the safe, secure, and trustworthy development and use of artificial intelligence; [Anonymous], 1959, The Landmarks of Tomorrow; [Anonymous], 2007, EWCACiv[2007]219.; [Anonymous], 2015, 721F.3d132 (2nd Cir).; [Anonymous], DIRECTIVE EU 2019790; [Anonymous], 1886, CONVENTION PROTECTIO; [Anonymous], 1884, 111U.S.53; [Anonymous], 2023, 598U.S. ___ (Supreme Court of the United States); [Anonymous], 2020, Revised Issues Paper on Intellectual Property Policy and Artificial Intelligence; [Anonymous], 2020, Rethinking Database Rights and Data Ownership in an AI World; Baldwin R., 2011, Understanding regulation: Theory, strategy, and practice; Barrett C, 2023, Arxiv, DOI arXiv:2308.14840; Bartlett C., 1901, New York Times; Beebe B, 2008, U PENN LAW REV, V156, P549, DOI 10.2307/40041357; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bennett JamesT., 2016, Subsidizing culture: taxpayer enrichment of the creative class; Bollinger Lee C., 2022, Social Media, Freedom of Speech, and the Future of Our Democracy; Booker C., 2006, The seven basic plots; Brodkin J., 2023, Ars Technica; Brown A., 2019, Contemporary Intellectual Property: Law and Policy, V5th edn; Buning MD, 2018, RESEARCH HANDBOOK ON THE LAW OF ARTIFICIAL INTELLIGENCE, P511; Chesterman S, 2021, WE, THE ROBOTS?, P1, DOI 10.1017/9781009047081; Chesterman S, 2020, INT COMP LAW Q, V69, P819, DOI 10.1017/S0020589320000366; Chomsky N., 2023, NEW YORK TIMES; Copyright Act, 2021, Singapore; Copyright Act, 1994, New Zealand; Copyright Amendment Act, 1994, India; Copyright and Related Rights Act, 2000, Ireland; Copyright Designs and Patents Act, 1988, United Kingdom; Copyright Ordinance, 1997, Hong Kong; Creamer E., 2023, Guardian , 20 September; D'Auria G., 2023, TechREG Chronicle; Dell'Acqua F., 2023, Harvard Business School Technology & Operations Management Unit Working Paper, No. 24-013; Digital Millennium Copyright Act (DMCA), 1998, (U.S.). 105-304; Du Sautoy Marcus., 2019, The creativity code: Art and innovation in the age of AI; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Edwards B., 2023, Ars Technica; Edwards Dustin W., 2018, Computers and Composition, V47, P61, DOI 10.1016/j.compcom.2017.12.001; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00140-5; Ellis L., 2010, New Yorker; Ellison S., 2022, FindLaw; European Commission, 2021, Proposal for a Regulation of The European Parliament and of The Council Laying Down Harmonised Rules On Artificial Intelligence (Artifi- cial Intelligence Act) and amending certain Union legislative acts COM/2021/206 final; Geng Y., 2023, Georgetown Law Technology Review, V7, P157; Gervais DJ, 2020, IOWA LAW REV, V105, P2053; Giusti S., 2021, Democracy and fake news; Graw Isabelle., 2016, Painting Beyond itself: The Medium in the Post-Medium Condition; Guadamuz A., 2023, A Scanner Darkly: Copyright Liability and Exceptions in Artificial Intelligence Inputs and Outputs: Guadamuz, Andres; Guadamuz A., 2022, TechnoLlama; Harari Y. N., 2023, ECONOMIST; Hayes C., 2023, Generative artificial intelligence and copyright: Both sides of the Black Box; Herings PJJ, 2018, EUR J OPER RES, V266, P328, DOI 10.1016/j.ejor.2017.09.011; Huber N., 2023, Financial Times; Jayakumar S., 2021, Disinformation and fake news; Koestler A., 1964, The Act of Creation; Kucherbaev P, 2018, IEEE INTERNET COMPUT, V22, P36, DOI 10.1109/MIC.2018.252095348; Lemley MA, 2023, How generative AI Turns copyright law on its head; Lemley Mark A., 2021, TEX. L. REV., V99, P743; Li MJ, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15061287; Li X, 2023, IEEE T CIRC SYST VID, V33, P1658, DOI 10.1109/TCSVT.2022.3217950; Lim J., 2023, Legal500; Maguire Laurie., 2020, The Rhetoric of the Page; Martínez G, 2023, Arxiv, DOI [arXiv:2306.06130, 10.48550/arXiv.2306.06130]; Menendez J., 2023, Medium; Menn Joseph., 2003, ALL RAVE RISE FALL S; Metz C., 2024, The New York Times; Mims C, 2023, The Wall Street Journal; Morris MR, 2023, Arxiv, DOI [arXiv:2304.01420, DOI 10.48550/ARXIV.2304.01420]; Nordemann A., 1999, Copyright and photographs: An international survey, P135; O'Leary DE, 2013, IEEE INTELL SYST, V28, P96, DOI 10.1109/MIS.2013.39; Padmanabhan A., Journal of the Patent and Trademark Office Society; Phelan R. N., 2023, IP Litigator, P8; Prassl J., 2018, Humans as a service: the promise and perils of work in the gig economy; Rao Rahul., 2023, Scientific American; Reisner A., 2023, Atlantic; Roberts H, 2021, AI SOC, V36, P59, DOI 10.1007/s00146-020-00992-2; Romm T., 2020, WASH POST; SAMUELSON P, 1986, U PITT LAW REV, V47, P1185; Schade M., 2023, OpenAI; Schoppert P., AI and Copyright (Substack); Seabrook John., NEW YORKER; Sejourne S., 2020, Draft report on intellectual property rights for the development of artificial intelligence technologies; Seng Daniel., 2014, Virginia Journal of Law Technology, V18, P369; Silberling A., 2022, TECHCRUNCH; Sun YC, 2023, Arxiv, DOI arXiv:2304.14613; Tan D., 2023, Singapore Law Gazette; Tan D., 2022, Journal of Intellectual Property Studies, V5, P1; Tan D., 2017, Research handbook on intellectual property in media and entertainment, P102; Tan D., 2023, SAL Practitioner, P24; Tan D., 2023, SAL Practitioner [2023], 25; The 'A.P.' News, 1894, New York Times; Torrance A. W., Dickinson Law Review; UN AI Advisory Body, 2023, Interim report: Governing AI for humanity; Wallace R. S., 2009, PARSING TURING TEST, P181, DOI [DOI 10.1007/978-1-4020-6710-5_13, 10.1007/978-1-4020-6710-5_13]; Wang JT, 2023, Arxiv, DOI [arXiv:2310.00646, 10.48550/arXiv.2310.00646, DOI 10.48550/ARXIV.2310.00646]; Zikopoulos P.C., 2012, Harness the Power of Big Data: The IBM Big Data Platform	103	4	4	91	91	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1449-4035	1839-3373		POLICY SOC	Policy Soc.	2024 FEB 12	2024										10.1093/polsoc/puae006	http://dx.doi.org/10.1093/polsoc/puae006		FEB 2024	16	Political Science; Public Administration	Social Science Citation Index (SSCI)	Government & Law; Public Administration	HO5P1		gold			2024-07-03	WOS:001160461900001
J	Park, C; Koo, S; Kim, G; Lim, H				Park, Chanjun; Koo, Seonmin; Kim, Gyeongmin; Lim, Heuiseok			Towards Harnessing the Most of ChatGPT for Korean Grammatical Error Correction	APPLIED SCIENCES-BASEL			English	Article						Korean grammatical error correction; large language model; K-NCT; ChatGPT		In this study, we conduct a pioneering and comprehensive examination of ChatGPT's (GPT-3.5 Turbo) capabilities within the realm of Korean Grammatical Error Correction (K-GEC). Given the Korean language's agglutinative nature and its rich linguistic intricacies, the task of accurately correcting errors while preserving Korean-specific sentiments is notably challenging. Utilizing a systematic categorization of Korean grammatical errors, we delve into a meticulous, case-specific analysis to identify the strengths and limitations of a ChatGPT-based correction system. We also critically assess influential parameters like temperature and specific error criteria, illuminating potential strategies to enhance ChatGPT's efficacy in K-GEC tasks. Our findings offer valuable contributions to the expanding domain of NLP research centered on the Korean language.	[Park, Chanjun] Upstage, 338 Gwanggyojungang Ro, Yongin 16942, Gyeonggi Do, South Korea; [Koo, Seonmin; Lim, Heuiseok] Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 02841, South Korea; [Kim, Gyeongmin; Lim, Heuiseok] Human Inspired AI Res, 145 Anam Ro, Seoul 02841, South Korea	Korea University	Lim, H (corresponding author), Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 02841, South Korea.; Lim, H (corresponding author), Human Inspired AI Res, 145 Anam Ro, Seoul 02841, South Korea.	chanjun.park@upstage.ai; fhdahd@korea.ac.kr; totoro4007@gmail.com; limhseok@korea.ac.kr	Kim, Gyeongmin/HLW-6297-2023	Park, Chanjun/0000-0002-7200-9632; Lim, Heuiseok/0000-0002-9269-1157	National Research Foundation of Korea	National Research Foundation of Korea(National Research Foundation of Korea)	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Cao HN, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4867; Gan ZF, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3487; Gudmundsson J., 2018, Bachelor's Thesis; Hidayatullah E., 2024, Humanit. Educ. Appl. Linguist. Lang. Teaching Conf. Ser, V1, P14; Imamura Kenji., 2012, Proceedings of ACL-12 - Volume 2, V2, P388; Ippolito D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3752; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kaneko M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7176; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kim D, 2024, Arxiv, DOI [arXiv:2312.15166, 10.48550/arXiv.2312.15166]; Kim M, 2013, IEEE INT C COMPUT, P1242, DOI 10.1109/CSE.2013.185; Koo S., 2023, P 2023 C EMPIRICAL M, P4798; Koo S, 2024, Arxiv, DOI arXiv:2401.14625; Koo S, 2022, IEEE ACCESS, V10, P118167, DOI 10.1109/ACCESS.2022.3219448; Kuznetsov A., 2021, arXiv; Lee Jung Hun, 2017, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V20, P371; Lee Jung-Hun, 2021, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V24, P1391; Lee M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082658; Li H, 2018, Arxiv, DOI arXiv:1811.00238; Li YH, 2023, Arxiv, DOI arXiv:2307.09007; Liang YB, 2023, Arxiv, DOI arXiv:2303.16434; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Naplava J., 2021, P 7 WORKSHOP NOISY U, P340, DOI [DOI 10.18653/V1/2021.WNUT-1.38, 10.18653/v1/2021.wnut-1.38]; Napoles C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P588; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park C., 2024, P FINDINGS ASS COMPU, P67; Park C., P 2023 INT C INFORM; Park C, 2021, MULTIMED TOOLS APPL, V80, P34591, DOI 10.1007/s11042-020-09148-2; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Rozovskaya A, 2019, T ASSOC COMPUT LING, V7, P1, DOI 10.1162/tacl_a_00251; Schmidt-Fajlik R, 2023, Asia CALL Online Journal, V14, P105, DOI DOI 10.54855/ACOJ.231417; Schulman J, 2022, Introducing chatgpt; Solyman A., 2019, P 2019 INT C COMPUTE, P1; Sun X., 2021, arXiv; Tarnavskyi M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3842; Vaswani A, 2017, ADV NEUR IN, V30; Wane D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2517; Wang Y, 2020, Arxiv, DOI arXiv:2005.06600; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Xiong J., 2015, Int. J. Comput. Linguist. Chin. Lang. Process, V20, P1; Zhang JW, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052608; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	45	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	8							3195	10.3390/app14083195	http://dx.doi.org/10.3390/app14083195			15	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	OU9U9		gold			2024-07-03	WOS:001209920100001
J	Barrett, A; Pack, A				Barrett, Alex; Pack, Austin			Not quite eye to AI: student and teacher perspectives on the use of generative artificial intelligence in the writing process	INTERNATIONAL JOURNAL OF EDUCATIONAL TECHNOLOGY IN HIGHER EDUCATION			English	Article						Artificial intelligence; Large language model; GPT; Writing education; Academic integrity	PLAGIARISM	Generative artificial intelligence (GenAI) can be used to author academic texts at a similar level to what humans are capable of, causing concern about its misuse in education. Addressing the role of GenAI in teaching and learning has become an urgent task. This study reports the results of a survey comparing educators' (n = 68) and university students' (n = 158) perceptions on the appropriate use of GenAI in the writing process. The survey included representations of user prompts and output from ChatGPT, a GenAI chatbot, for each of six tasks of the writing process (brainstorming, outlining, writing, revising, feedback, and evaluating). Survey respondents were asked to differentiate between various uses of GenAI for these tasks, which were divided between student and teacher use. Results indicate minor disagreement between students and teachers on acceptable use of GenAI tools in the writing process, as well as classroom and institutional-level lack of preparedness for GenAI. These results imply the need for explicit guidelines and teacher professional development on the use of GenAI in educational contexts. This study can contribute to evidence-based guidelines on the integration of GenAI in teaching and learning.	[Barrett, Alex] Florida State Univ, Coll Educ, Stone Bldg,114 West Call St, Tallahassee, FL 32306 USA; [Pack, Austin] Brigham Young Univ Hawaii, Fac Educ & Social Work, 55-220 Kulanui St, Laie, HI 96762 USA	State University System of Florida; Florida State University; Brigham Young University; Brigham Young University - Hawaii	Barrett, A (corresponding author), Florida State Univ, Coll Educ, Stone Bldg,114 West Call St, Tallahassee, FL 32306 USA.	abarrett3@fsu.edu		Barrett, Alex/0000-0003-1229-9743	Not applicable.	Not applicable.	Not applicable.	Baker RS, 2022, INT J ARTIF INTELL E, V32, P1052, DOI 10.1007/s40593-021-00285-9; Bland JM, 1997, BRIT MED J, V314, P572, DOI 10.1136/bmj.314.7080.572; Bonner E., 2023, Teaching English with Technology, V23, P23, DOI [DOI 10.56297/BKAM1691/WIEO1749, 10.56297/BKAM1691/WIEO1749]; Bridgeman B, 2012, APPL MEAS EDUC, V25, P27, DOI 10.1080/08957347.2012.635502; Carlson M, 2024, TESOL J, V15, DOI 10.1002/tesj.759; Chan CKY, 2023, Arxiv, DOI [arXiv:2305.00280, 10.1186/s41239-023-00408-3]; Chiu T.K.F., 2023, Computers and Education: Artificial Intelligence, V4, DOI DOI 10.1016/J.CAEAI.2022.100118; CHOMSKY N., 1991, CHOMSKYAN TURN, P26; CWPA NCTE & NWP, 2011, National Framework for success in postsecondary writing; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Ely JJ., 2013, Academy of Educational Leadership Journal, V17, P95; Evering LC, 2012, J ADOLESC ADULT LIT, V56, P35, DOI 10.1002/JAAL.00100; Fan N, 2023, SAGE OPEN, V13, DOI 10.1177/21582440231181296; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fitria T. N., 2021, Metathesis: Journal of English Language, Literature, and Teaching, V5, P65, DOI DOI 10.31002/METATHESIS.V5I1.3519; Gardner J, 2021, J COMPUT ASSIST LEAR, V37, P1207, DOI 10.1111/jcal.12577; Godwin-Jones R, 2022, LANG LEARN TECHNOL, V26, P5, DOI 10.10125/73474; Graham M, 2015, GEO-GEOGR ENVIRON, V2, P88, DOI 10.1002/geo2.8; Graham S, 2020, REV EDUC RES, V90, P179, DOI 10.3102/0034654320914744; Graham S, 2019, REV RES EDUC, V43, P277, DOI 10.3102/0091732X18821125; Hockly N, 2019, ELT J, V73, P82, DOI 10.1093/elt/ccy044; Hu K., 2023, Reuters; Huawei S, 2023, EDUC INF TECHNOL, V28, P771, DOI 10.1007/s10639-022-11200-7; Ingley SJ, 2023, TRENDS ECOL EVOL, V38, P785, DOI 10.1016/j.tree.2023.05.007; Jackson M. C., 2021, J BUSINESS TECHNOLOG, V16, P299; Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Konheim-Kalkstein YL., 2008, Journal of College and Character, V9, DOI [10.2202/1940-1639.1115, DOI 10.2202/1940-1639.1115]; Kumar R, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00130-7; Lampropoulos G., 2023, SSRN, DOI [10.2139/ssrn.4468181, DOI 10.2139/SSRN.4468181]; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; National Council of Teachers of English, 2013, NCTE position statement on machine scoring; O'Neill R, 2019, AUSTRALAS J EDUC TEC, V35, P42, DOI 10.14742/ajet.3795; OpenAI, 2023, Terms of use; Pack A., 2023, Teaching English with Technology, V23, P4, DOI [10.56297/BUKA4060/VRRO1747, DOI 10.56297/BUKA4060/VRRO1747]; Pack A, 2023, TESOL QUART, V57, P1571, DOI 10.1002/tesq.3253; Pennycook A, 1996, TESOL QUART, V30, P201, DOI 10.2307/3588141; Sadeghi R., 2019, Res. Ethics, V15, P1, DOI DOI 10.1177/1747016116654065; Seow A., 2002, Methodology in Language Teaching, P315, DOI DOI 10.1017/CBO9780511667190.044; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Sutherland-Smith W., 2005, Journal of English for Academic Purposes, V4, P83, DOI [DOI 10.1016/J.JEAP.2004.07.007, 10.1016/j.jeap.2004.07.007]; Tatum H.E., 2022, Journal of College and Character, V23, P32, DOI DOI 10.1080/2194587X.2021.2017977; Tseng W., 2023, Journal of China Computer-Assisted Language Learning, V3, P258, DOI [https://doi.org/10.1515/jccall-2023-0008, DOI 10.1515/JCCALL-2023-0008]; Urlaub P., 2022, L2 Journal, V14, DOI [https://doi.org/10.5070/L214151790, DOI 10.5070/L214151790]; Wang ZH, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.909802; Weigle SC., 2013, The handbook of automated essay evaluation: Current applications and new directions; Yang M., 2023, The Guardian; Yeo MA, 2023, TESOL J, V14, DOI 10.1002/tesj.716; Yeo S., 2007, High Educ.Res. Dev, V26, P199, DOI [DOI 10.1080/072943607013, 10.1080/07294360701310813, DOI 10.1080/07294360701310813, 10 .1080/07294360701310813]; Yeo S, 2007, QUAL HIGH EDUC, V13, P187, DOI 10.1080/13538320701629202; Yu H, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1183162; Zhang Z, 2020, ASSESS WRIT, V43, P78, DOI 10.1016/j.asw.2019.100439	52	7	8	212	249	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	2365-9440			INT J EDUC TECHNOL H	Int. J. Educ. Technol. High. Educ.	NOV 10	2023	20	1							59	10.1186/s41239-023-00427-0	http://dx.doi.org/10.1186/s41239-023-00427-0			24	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	X5WO5		gold			2024-07-03	WOS:001099156200001
C	Karimzadeh, F; Imani, M; Asgari, B; Cao, NY; Lin, YY; Fang, Y			IEEE	Karimzadeh, Foroozan; Imani, Mohsen; Asgari, Bahar; Cao, Ningyuan; Lin, Yingyan; Fang, Yan			Memory-Based Computing for Energy-Efficient AI: Grand Challenges	2023 IFIP/IEEE 31ST INTERNATIONAL CONFERENCE ON VERY LARGE SCALE INTEGRATION, VLSI-SOC	IEEE-IFIP International Conference on VLSI and System-on-Chip		English	Proceedings Paper	31st IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC)	OCT 16-18, 2023	Dubai, U ARAB EMIRATES	IEEE, IFIP, Cadence Design Syst, Rohde & Schwarz, IFIP VLSI SOG, CAS, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, Amer Univ Sharjah, Coll Engn, Khalifa Univ, Univ Sharjah		Compute-in-memory; energy-efficiency; deep learning; large language models	ERA	The remarkable progress in artificial intelligence (AI) has ushered in a new era characterized by models with billions of parameters, enabling extraordinary capabilities across diverse domains. However, these achievements come at a significant cost in terms of memory and energy consumption. The growing demand for computational resources raises grand challenges for the sustainable development of energy-efficient AI systems. This paper delves into the paradigm of memory-based computing as a promising avenue to address these challenges. By capitalizing on the inherent characteristics of memory and its efficient utilization, memory-based computing offers a novel approach to enhance AI performance while reducing the associated energy costs. Our paper systematically analyzes the multifaceted aspects of this paradigm, highlighting its potential benefits and outlining the challenges it poses. Through an exploration of various methodologies, architectures, and algorithms, we elucidate the intricate interplay between memory utilization, computational efficiency, and AI model complexity. Furthermore, we review the evolving area of hardware and software solutions for memory-based computing, underscoring their implications for achieving energy-efficient AI systems. As AI continues its rapid evolution, identifying the key challenges and insights presented in this paper serve as a foundational guide for researchers striving to navigate the complex field of memory-based computing and its pivotal role in shaping the future of energy-efficient AI.	[Karimzadeh, Foroozan; Lin, Yingyan] Georgia Inst Technol, Atlanta, GA 30332 USA; [Imani, Mohsen] Univ Calif Irvine, Irvine, CA USA; [Asgari, Bahar] Univ Maryland, College Pk, MD USA; [Cao, Ningyuan] Univ Notre Dame, Notre Dame, IN 46556 USA; [Fang, Yan] Kennesaw State Univ, Kennesaw, GA 30144 USA	University System of Georgia; Georgia Institute of Technology; University of California System; University of California Irvine; University System of Maryland; University of Maryland College Park; University of Notre Dame; University System of Georgia; Kennesaw State University	Karimzadeh, F (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.	fkarimzadeh6@gatech.edu						Acun B, 2021, INT S HIGH PERF COMP, P802, DOI 10.1109/HPCA51647.2021.00072; Alaghi A, 2018, IEEE T COMPUT AID D, V37, P1515, DOI 10.1109/TCAD.2017.2778107; Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348; Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298; Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080; Boostani R, 2017, COMPUT METH PROG BIO, V140, P77, DOI 10.1016/j.cmpb.2016.12.004; Burr G., 2023, IEEE S VLSI TECHN CI; Cartier EA, 2019, INT RELIAB PHY SYM, DOI 10.1109/irps.2019.8720599; Chang Muya., 2022, 2022 IEEE International Solid-State Circuits Conference (ISSCC), V65, P1; Chen S, 2019, IEEE T PATTERN ANAL, V41, DOI 10.1109/TPAMI.2018.2874634; Crafton B, 2021, IEEE ASIAN SOLID STA, DOI 10.1109/A-SSCC53895.2021.9634742; Dai GH, 2022, CONF PROC INT SYMP C, P130, DOI 10.1145/3470496.3527388; Dally, 2022, On the Model of Computation: Point: We Must Extend Our Model of Computation to Account for Cost and Location; Dally W, 2021, The Future of Computing: Domain-Specific Architecture; Ginart AA, 2021, IEEE INT SYMP INFO, P2786, DOI 10.1109/ISIT45174.2021.9517710; Gupta U, 2021, INT SYMP MICROARCH, P870, DOI 10.1145/3466752.3480127; Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084; Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047; Han S, 2015, ADV NEUR IN, V28; Hayes JP, 2015, DES AUT CON, DOI 10.1145/2744769.2747932; He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155; Hernández-Cano A, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P56; Hoefflinger Bernd., 2012, CHIPS 2020 FRONTIERS, P161; Hoefler T, 2021, J MACH LEARN RES, V23; Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083; Imani M, 2019, IEEE INT CONF CLOUD, P435, DOI 10.1109/CLOUD.2019.00076; Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28; Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286; Jiang JK, 2019, IEEE J ELECTRON DEVI, V7, P878, DOI 10.1109/JEDS.2019.2925150; Jiang Wenqi, 2021, P MACH LEARN SYST, V3, P845; Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351; Jouppi NP, 2023, Arxiv, DOI arXiv:2304.01433; Kadetotad D, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967028; Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8; Kang S, 2021, INT SYMP MICROARCH, P434, DOI 10.1145/3466752.3480108; Karimzadeh F, 2022, Hardware-friendly model compression techniques for deep learning accelerators; Karimzadeh F., 2022, 2022 IFIP IEEE 30 IN, P1; Karimzadeh F., 2020, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas45731.2020.9181101; Karimzadeh F, 2022, IEEE T CIRCUITS-I, V69, P1952, DOI 10.1109/TCSI.2022.3145687; Karimzadeh F, 2020, IEEE INT CONF VLSI, P206, DOI 10.1109/VLSI-SOC46417.2020.9344090; Karimzadeh N., 2020, IEEE Transactions on Circuits and Systems I: Regular Papers; Ke L, 2022, INT S HIGH PERF COMP, P141, DOI 10.1109/HPCA53966.2022.00019; Ke L, 2022, IEEE MICRO, V42, P116, DOI 10.1109/MM.2021.3097700; Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070; Kinget P.R., 2015, 2015 IEEE CUSTOM INT, P1, DOI DOI 10.1109/CICC.2015.7338394; Kwon Y, 2021, INT S HIGH PERF COMP, P235, DOI 10.1109/HPCA51647.2021.00029; Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284; Lele AS, 2023, 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC, DOI 10.1109/DAC56929.2023.10247852; Lele AS, 2024, IEEE J SOLID-ST CIRC, V59, P52, DOI 10.1109/JSSC.2023.3297411; Liu Zhenhua, 2021, Advances in Neural Information Processing Systems, V34; Lu LQ, 2021, INT SYMP MICROARCH, P977, DOI 10.1145/3466752.3480125; Ma XY, 2023, Arxiv, DOI arXiv:2305.11627; Monga K, 2023, ANALOG INTEGR CIRC S, V116, P5, DOI 10.1007/s10470-023-02169-5; Park J, 2018, Arxiv, DOI arXiv:1811.09886; Peng XC, 2019, INT EL DEVICES MEET; Alam MR, 2022, IEEE T CIRCUITS-II, V69, P2423, DOI 10.1109/TCSII.2022.3161995; Sadredini E, 2021, INT SYMP MICROARCH, P311, DOI 10.1145/3466752.3480934; Salahuddin S, 2018, NAT ELECTRON, V1, P442, DOI 10.1038/s41928-018-0117-x; Saxena S, 2008, IEEE T ELECTRON DEV, V55, P131, DOI 10.1109/TED.2007.911351; Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z; Seraj E., 2022, P 21 INT C AUT AG MU, P1173; Sethi G, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P344, DOI 10.1145/3503222.3507777; Shi HJM, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P165, DOI 10.1145/3394486.3403059; Si MW, 2021, IEEE T ELECTRON DEV, V68, P3195, DOI 10.1109/TED.2021.3061038; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Soltaniyeh M, 2022, PROCEEDINGS OF THE 2022 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '22), P177, DOI 10.1145/3489525.3511672; Stine BE, 1996, P SOC PHOTO-OPT INS, V2874, P27, DOI 10.1117/12.250826; Sun MJ, 2024, Arxiv, DOI arXiv:2306.11695; Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235; Sun X, 2022, INT S HIGH PERF COMP, P1056, DOI 10.1109/HPCA53966.2022.00081; Vaswani A, 2017, ADV NEUR IN, V30; Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889; Wang HR, 2020, Arxiv, DOI arXiv:2005.14187; Wang HR, 2021, INT S HIGH PERF COMP, P97, DOI 10.1109/HPCA51647.2021.00018; Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763; Xiao G., 2023, INT C MACHINE LEARNI, P38087; Xie MH, 2022, PROCEEDINGS OF THE SEVENTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '22), P402, DOI 10.1145/3492321.3519554; Yakimets D, 2017, INT EL DEVICES MEET; Yang XX, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415640; Yazdanbakhsh A, 2022, INT SYMP MICROARCH, P744, DOI 10.1109/MICRO56248.2022.00059; Yin B., 2021, ANN C MACHINE LEARNI, V3, P448; Yu SM, 2020, IEEE CUST INTEGR CIR, DOI 10.1109/cicc48029.2020.9075887; Yuan Z, 2022, LECT NOTES COMPUT SC, V13672, P191, DOI 10.1007/978-3-031-19775-8_12; Zhao Weijie, 2020, P MACHINE LEARNING S; Zhu Y, 2021, I C FIELD PROG LOGIC, P279, DOI 10.1109/FPL53798.2021.00057; Zou ZW, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3480958; Zou Z, 2022, CONF PROC INT SYMP C, P656, DOI 10.1145/3470496.3527422	87	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2324-8432		979-8-3503-2599-7	IEEE INT CONF VLSI			2023							110	117		10.1109/VLSI-SoC57769.2023.10321880	http://dx.doi.org/10.1109/VLSI-SoC57769.2023.10321880			8	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW1OP					2024-07-03	WOS:001108827200019
C	Dunn, C; Ghosh, K			IEEE	Dunn, Cayden; Ghosh, Krishnendu			BicePy: Bilingual Description of Compiler Errors in Python	2023 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, VL/HCC	Symposium on Visual Languages and Human Centric Computing VL HCC		English	Proceedings Paper	IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)	OCT 02-06, 2023	Martin Luther King Jr Memorial Lib, Washington, DC	IEEE, IEEE Comp Soc	Martin Luther King Jr Memorial Lib	Compiler error messages; Generative Large Language Model; Neural Machine Translation; Spanish		The ubiquitous presence of English in programming, particularly in error messages, poses a challenge for non-native English-speaking developers. These developers frequently struggle to decipher complex error messages written in English. To address this, we introduce BicePy, an innovative VScode extension that operates in two distinct modes to cater to diverse user needs. BicePy serves as a powerful proof of concept, demonstrating the feasibility of generating context-aware translated explanations of Python error messages in Spanish. However, the utility of BicePy extends beyond this. As neural machine translation is language-agnostic, it is capable of scaling to accommodate most non-English languages. BicePy signifies an essential stride towards global programming accessibility for linguistic minorities in software engineering(1).	[Dunn, Cayden; Ghosh, Krishnendu] Coll Charleston, Dept Comp Sci, Charleston, SC 29401 USA	College of Charleston	Dunn, C (corresponding author), Coll Charleston, Dept Comp Sci, Charleston, SC 29401 USA.	dunncw@g.cofc.edu; ghoshk@cofc.edu						Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Dasgupta S, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P33, DOI 10.1145/3051457.3051464; Denny Paul, 2020, P 2020 ACM C INNOVAT, P480; Guo PJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173970; Haq Sami Ul, 2022, 2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST), P349, DOI 10.1109/IBCAST54850.2022.9990335; Leinonen J, 2022, Arxiv, DOI [arXiv:2210.11630, 10.48550/arxiv.2210.11630, DOI 10.48550/ARXIV.2210.11630]; Li Q, 2022, MATER TRANS, V63, P1072, DOI 10.2320/matertrans.MT-M2021245; Raffel C, 2020, J MACH LEARN RES, V21; Reestman K, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P249, DOI 10.1145/3291279.3339423; Smith Julie M., 2023, P 54 ACM TECHN S COM, P1350; Thiselton E, 2019, INT SYMP EMP SOFTWAR, P82; Tiedemann J org, 2020, CoRR, abs/2010.06354; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]	14	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1943-6092		979-8-3503-2946-9	S VIS LANG HUM CEN C			2023							229	231		10.1109/VL-HCC57772.2023.00038	http://dx.doi.org/10.1109/VL-HCC57772.2023.00038			3	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1AN					2024-07-03	WOS:001103187300030
C	Li, Q			ACM	Li, Qi			Harnessing the Power of Pre-trained Vision-Language Models for Efficient Medical Report Generation	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Medical report generation; Pre-trained Vision-Language Models; Large Language Models		Medical images are commonly used in clinical practice. But the need for diagnosis and reporting from image-based examinations far excels the current medical capacity. Automatic Medical Report Generation (MRG) can help to ease the burden of radiologists. Vision-Language Pre-training (VLP) has received tremendous success on various tasks, therefore it is naturally expected that MRG can harvest from this rapid advancement. However, directly applying existing VLP models in the medical domain is impracticable due to their data-hungry nature, the need for aligning different modalities, prohibitive training time, exorbitant hardware barrier, and the challenge of open-ended text generation. To address these problems, we propose MedEPT, a parameter-efficient approach for MRG that can utilize ever-ignored image-only datasets. It employs parameter-efficient tuning (PET) for VLP adaption to mitigate inefficiency in fine-tuning time and hardware. MedEPT also employs MRGPID to augment and expand adaption datasets by synthesizing meaningful text for image-only datasets. We perform a systematic evaluation of our method. Empirical results show that we obtain a better performance than the state-of-the-art method while using less than 10% trainable parameters and not more than 30% training time than ever before.	[Li, Qi] Tsinghua Univ, Shenzhen, Guangdong, Peoples R China	Tsinghua University	Li, Q (corresponding author), Tsinghua Univ, Shenzhen, Guangdong, Peoples R China.	infdim1996@163.com						Ben Zaken Elad, 2021, ARXIV210610199; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Bulent Sariyildiz M., 2020, LNCS, P153; Chen Xinlei, 2015, MICROSOFT COCO CAPTI; Chen ZH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1439; Chen Zhihong, 2022, ACL IJCNLP; Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; He P, 2020, ICLR; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Huang SC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3922, DOI 10.1109/ICCV48922.2021.00391; Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577; Johnson Alistair EW, 2019, Mimic-cxr-jpg, a large publicly available database of labeled chest radiographs; Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5; Kim W, 2021, PR MACH LEARN RES, V139; Lenc Karel, 2022, ARXIV220414198; Li A, 2017, IEEE I CONF COMP VIS, P4193, DOI 10.1109/ICCV.2017.449; Li JH, 2021, ADV NEUR IN, V34; Li Junnan, 2022, ARXIV220112086; Li Junnan, 2023, ARXIV230112597; Li Mingjie, 2023, WORLD WIDE WEB; Li Xiang Lisa, 2021, arXiv; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu FL, 2019, ADV NEUR IN, V32; Loshchilov I., 2017, CoRR; Lu JS, 2019, ADV NEUR IN, V32; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Mokady Ron, 2021, ARXIV211109734; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paszke A, 2019, ADV NEUR IN, V32; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Van den Oord Aaron, 2018, ARXIV1807; Vaswani A, 2017, ADV NEUR IN, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang Jianfeng, 2022, ARXIV220514100; Wang Wenhui, 2021, ARXIV211102358; Wang Z., 2022, IEEE Trans. Med. Imaging; Wang Zhanyu, 2022, IEEE T MED IMAGING; Wang Zhanyu, 2022, MICCAI; Wang Zifeng, 2022, ARXIV221010163; Wang Zirui, 2021, ARXIV210810904; Wu H, 2019, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2019.00677; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xue Y, 2019, LECT NOTES COMPUT SC, V11492, P125, DOI 10.1007/978-3-030-20351-1_10; Xue Y, 2018, LECT NOTES COMPUT SC, V11070, P457, DOI 10.1007/978-3-030-00928-1_52; Yang S., 2021, Image and Video Processing; Yang S., 2021, Medical Image Analysis; Yin Changchang, 2020, ICDM; You Di, 2021, MICCAI; Yu Jiahui, 2022, ARXIV220501917; Yuan Jianbo, 2019, LECT NOTES COMPUT SC, P721, DOI [DOI 10.1007/978-3-030-32226-7_80, 10.1007/978-3-030-32226-7_80]; Yuan Lu, 2021, ARXIV211111432; Zhang S., 2022, arXiv; Zhang Y., 2020, P AAAI C ART INT; Zhang Yuhao, 2020, Contrastive Learning of Medical Visual Representations from Paired Images and Text	63	1	1	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							1308	1317		10.1145/3583780.3614961	http://dx.doi.org/10.1145/3583780.3614961			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549501039
C	Wu, Y; Jiang, N; Pham, HV; Lutellier, T; Davis, J; Tan, L; Babkin, P; Shah, S		Just, R; Fraser, G		Wu, Yi; Jiang, Nan; Hung Viet Pham; Lutellier, Thibaud; Davis, Jordan; Tan, Lin; Babkin, Petr; Shah, Sameena			How Effective Are Neural Networks for Fixing Security Vulnerabilities	PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023			English	Proceedings Paper	32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA)	JUL 17-21, 2023	Seattle, WA	Assoc Comp Machinery, ACM SIGSOFT, AITO		Automated Program Repair; Large Language Model; Vulnerability; AI and Software Engineering		Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs. This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans, to better evaluate LLMs and APR techniques, and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities in VJBench-trans. Our findings include that (1) existing LLMs and APR models fix very few Java vulnerabilities. Codex fixes 10.2 (20.4%), the most number of vulnerabilities. Many of the generated patches are uncompilable patches. (2) Fine-tuning with general APR data improves LLMs' vulnerability-fixing capabilities. (3) Our new VJBench reveals that LLMs and APR models fail to fix many Common Weakness Enumeration (CWE) types, such as CWE-325 Missing cryptographic step and CWE-444 HTTP request smuggling. (4) Codex still fixes 8.7 transformed vulnerabilities, outperforming all the other LLMs and APR models on transformed vulnerabilities. The results call for innovations to enhance automated Java vulnerability repair such as creating larger vulnerability repair training data, tuning LLMs with such data, and applying code simplification transformation to facilitate vulnerability repair.	[Wu, Yi; Jiang, Nan; Davis, Jordan; Tan, Lin] Purdue Univ, W Lafayette, IN 47907 USA; [Hung Viet Pham] York Univ, Toronto, ON, Canada; [Lutellier, Thibaud] Univ Alberta, Camrose, AB, Canada; [Babkin, Petr; Shah, Sameena] JP Morgan AI Res, Palo Alto, CA USA; [Hung Viet Pham; Lutellier, Thibaud] Univ Waterloo, Waterloo, ON, Canada	Purdue University System; Purdue University; York University - Canada; University of Alberta; University of Waterloo	Wu, Y (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.	wu1827@purdue.edu; jiang719@purdue.edu; hvpham@yorku.ca; lutellie@ualberta.ca; davi1304@purdue.edu; lintan@purdue.edu; petr.babkin@jpmorgan.com; sameena.shah@jpmchase.com	Lutellier, Thibaud/AAM-1838-2020; Jiang, Nan/JXM-0534-2024	Lutellier, Thibaud/0000-0002-1823-0061; 	NSF [1901242, 2006688]; J.P. Morgan AI Faculty Research Awards; Meta/Facebook Research Awards	NSF(National Science Foundation (NSF)); J.P. Morgan AI Faculty Research Awards; Meta/Facebook Research Awards	We thank the reviewers for their insightful comments and suggestions. This work was funded in part by NSF 1901242, NSF 2006688, J.P. Morgan AI Faculty Research Awards, and Meta/Facebook Research Awards. Any opinions, findings, and conclusions in this paper are those of the authors only and do not necessarily reflect the views of our sponsors.	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; [Anonymous], 2023, NLTK Documentation.; [Anonymous], 2023, NVD Data Feeds; [Anonymous], 2023, Replication Package; [Anonymous], 2023, src2abs GitHub Repository; [Anonymous], 2023, Understanding the Impact of Apache Log4j Vulnerability; [Anonymous], 2022, Guidance for preventing, detecting, and hunting for exploitation of the Log4j 2 vulnerability; Asare O, 2024, Arxiv, DOI arXiv:2204.04741; Avgerinos T, 2018, IEEE SECUR PRIV, V16, P52, DOI 10.1109/MSP.2018.1870873; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barz B, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060041; Bhandari G, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE '21), P30, DOI 10.1145/3475960.3475985; Black Sid, 2021, Zenodo; Boland T, 2012, COMPUTER, V45, P88, DOI 10.1109/MC.2012.345; Bui QC, 2022, IEEE WORK CONF MIN S, P464, DOI 10.1145/3524842.3528482; Chen M., 2021, arXiv; Chen Z., 2022, IEEE Transactions on Software Engineering (TSE); Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Dinella E., 2020, INT C LEARN REPR ICL; Drain D, 2021, Arxiv, DOI arXiv:2105.09352; Ernst NA, 2022, IEEE SOFTWARE, V39, P106, DOI 10.1109/MS.2021.3133805; Fan JH, 2020, IEEE WORK CONF MIN S, P508, DOI 10.1145/3379597.3387501; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Fu Michael, 2022, VulRepair: A T5-Based Automated Software Vulnerability Repair; Gao Q, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P459, DOI 10.1109/ICSE.2015.64; Gao X, 2021, ACM T SOFTW ENG METH, V30, DOI 10.1145/3418461; Github, 2022, About us; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hiesgen Raphael, 2022, NETWORK TRAFFIC MEAS; Kai H, 2022, 52ND ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOP VOLUME (DSN-W 2022), P111, DOI 10.1109/DSN-W54100.2022.00027; Huang Z, 2019, P IEEE S SECUR PRIV, P539, DOI 10.1109/SP.2019.00071; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Jiang N, 2023, PROC INT CONF SOFTW, P1251, DOI 10.1109/ICSE48619.2023.00111; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Lee J, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P95, DOI 10.1145/3236024.3236079; Li XD, 2017, P REL MAINT S; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Lin XV, 2022, Arxiv, DOI arXiv:2112.10668; Lin Zhiqiang, 2007, P 2 ACM S INF COMP C, P329; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Ma SQ, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P711, DOI 10.1145/2897845.2897896; Madeiral F, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER), P468, DOI [10.1109/SANER.2019.8667991, 10.1109/saner.2019.8667991]; Mashhadi E, 2021, IEEE WORK CONF MIN S, P505, DOI 10.1109/MSR52588.2021.00063; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; Moroz E. A., 2022, 2022 C RUSS YOUNG RE, P386, DOI [10.1109/ElConRus54750.2022.9755659, DOI 10.1109/ELCONRUS54750.2022.9755659]; Morrison PJ, 2018, EMPIR SOFTW ENG, V23, P1383, DOI 10.1007/s10664-017-9541-1; Muntean P, 2021, IEEE T SOFTWARE ENG, V47, P2225, DOI 10.1109/TSE.2019.2946148; Musliner David J, 2015, 4 INT C COMM COMP NE; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Nikitopoulos G, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1565, DOI 10.1145/3468264.3473122; Noller Yannic, 2022, P ACMIEEE 44 INT C S; openai, 2022, Codex; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pereira JD, 2021, IEEE ACCESS, V9, P142879, DOI 10.1109/ACCESS.2021.3120349; Perkins JH, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P87; Pinconschi E, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P789, DOI 10.1145/3533767.3543291; Ponta Serena Elisa, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P383, DOI 10.1109/MSR.2019.00064; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Saha RK, 2018, IEEE WORK CONF MIN S, P10, DOI 10.1145/3196398.3196473; Sidiroglou S, 2005, IEEE SECUR PRIV, V3, P41, DOI 10.1109/MSP.2005.144; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Tan M, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P99, DOI 10.1109/ICSE.2015.139; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang TL, 2014, LECT NOTES COMPUT SC, V8550, P255; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xia Chunqiu Steven, 2022, arXiv; Ye H, 2022, PROC INT CONF SOFTW, P1506, DOI 10.1145/3510003.3510222; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	76	2	2	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0221-1				2023							1282	1294		10.1145/3597926.3598135	http://dx.doi.org/10.1145/3597926.3598135			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2OB		Green Submitted			2024-07-03	WOS:001122661400103
J	Carrillo, JM; Wang, YY; Kumar, R; Sumpter, BG				Carrillo, Jan-Michael; Wang, Yangyang; Kumar, Rajeev; Sumpter, Bobby G.			Coarse-grained explicit-solvent molecular dynamics simulations of semidilute unentangled polyelectrolyte solutions	EUROPEAN PHYSICAL JOURNAL E			English	Article							CHARGED POLYELECTROLYTE; COUNTERION-CONDENSATION; REPULSIVE FORCES; DIPOLE-MOMENT; SCATTERING; VISCOSITY; COLLAPSE; RHEOLOGY; LENGTH; SANS	We present results from explicit-solvent coarse-grained molecular dynamics (MD) simulations of fully charged, salt-free, and unentangled polyelectrolytes in semidilute solutions. The inclusion of a polar solvent in the model allows for a more physical representation of these solutions at concentrations, where the assumptions of a continuum dielectric medium and screened hydrodynamics break down. The collective dynamic structure factor of polyelectrolytes, S(q, t), showed that at q > q(& lowast;), where q(& lowast;) = 2 pi/xi is the polyelectrolyte peak in the structure factor S(q) and xi is the correlation length, the relaxation time obtained from fits to stretched exponential was tau KWW similar to q(-3), which describes unscreened Zimm-like dynamics. This is in contrast to implicit-solvent simulations using a Langevin thermostat where tau KWW similar to q(-2). At q < q(& lowast;), a crossover region was observed that eventually transitions to another inflection point tau KWW similar to q(-2) at length scales larger than xi for both implicit-and explicit-solvent simulations. The simulation results were also compared to scaling predictions for correlation length, xi similar to c(p)(-1/2), specific viscosity, eta(sp) similar to c(p)(1/2) , and diffusion coefficient, D similar to c(p)(0), where cp is the polyelectrolyte concentration. The scaling prediction for xi holds; however, deviations from the predictions for eta(sp) and D were observed for systems at higher cp, which are in qualitative agreements with recent experimental results. This study highlights the importance of explicit-solvent effects in molecular dynamics simulations, particularly in semidilute solutions, for a better understanding of polyelectrolyte solution behavior.	[Carrillo, Jan-Michael; Wang, Yangyang; Kumar, Rajeev; Sumpter, Bobby G.] Oak Ridge Natl Lab, Ctr Nanophase Mat Sci, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory; Center for Nanophase Materials Sciences	Carrillo, JM; Kumar, R; Sumpter, BG (corresponding author), Oak Ridge Natl Lab, Ctr Nanophase Mat Sci, Oak Ridge, TN 37831 USA.	carrillojy@ornl.gov; kumarr@ornl.gov; sumpterbg@ornl.gov	Kumar, Rajeev/Q-2255-2015; Sumpter, Bobby/C-9459-2013; Carrillo, Jan Michael/J-5422-2019; Wang, Yangyang/A-5925-2010	Kumar, Rajeev/0000-0001-9494-3488; Sumpter, Bobby/0000-0001-6341-0355; Carrillo, Jan Michael/0000-0001-8774-697X; Wang, Yangyang/0000-0001-7042-9804	This work was performed at the Center for Nanophase Materials Sciences, a US Department of Energy Office of Science User Facility operated at Oak Ridge National Laboratory. This research used resources of the Oak Ridge Leadership Computing Facility (OLCF) [DE-AC05-00OR22725]; Office of Science of the U.S. Department of Energy [DE-AC05-00OR22725, KC0402010]; U.S. Department of Energy (DOE), Office of Science, Office of Basic Energy Sciences; Bard; Google	This work was performed at the Center for Nanophase Materials Sciences, a US Department of Energy Office of Science User Facility operated at Oak Ridge National Laboratory. This research used resources of the Oak Ridge Leadership Computing Facility (OLCF)(United States Department of Energy (DOE)); Office of Science of the U.S. Department of Energy(United States Department of Energy (DOE)); U.S. Department of Energy (DOE), Office of Science, Office of Basic Energy Sciences(United States Department of Energy (DOE)); Bard(US-Israel Binational Science Foundation); Google(Google Incorporated)	This work was performed at the Center for Nanophase Materials Sciences, a US Department of Energy Office of Science User Facility operated at Oak Ridge National Laboratory. This research used resources of the Oak Ridge Leadership Computing Facility (OLCF) at the Oak Ridge National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy under Contract No. DE-AC05-00OR22725. YW is supported by the U.S. Department of Energy (DOE), Office of Science, Office of Basic Energy Sciences, Early Career Research Program Award KC0402010, under Contract DE-AC05-00OR22725. JC acknowledges Bard and ChatGPT, large language models (LLMs) from Google and OpenAI, respectively, for their assistance in proofreading the manuscript, checking grammar, spelling, and punctuation, and providing suggestions for alternative phrasing to enhance clarity and flow. Both models did not contribute to the research content. The authors are grateful to Dr. Ali H. Slim, Prof. Amanda Marciel, Prof. Jacinta Conrad and Prof. Andrey Dobrynin for stimulating discussions.	AJDARI A, 1991, J CHEM PHYS, V95, P4580, DOI 10.1063/1.461725; Becker AL, 2012, CURR OPIN COLLOID IN, V17, P90, DOI 10.1016/j.cocis.2011.10.001; Bediako JK, 2023, CHEMOSPHERE, V325, DOI 10.1016/j.chemosphere.2023.138418; Berne BJ., 1976, Biology and physics; Bollinger JA, 2021, MACROMOLECULES, V54, P10068, DOI 10.1021/acs.macromol.1c01491; BOOTH F, 1951, J CHEM PHYS, V19, P391, DOI 10.1063/1.1748233; Boris DC, 1998, MACROMOLECULES, V31, P5746, DOI 10.1021/ma971884i; Borreguero JM, 2017, J PHYS CHEM B, V121, P6958, DOI 10.1021/acs.jpcb.7b05047; Brettmann BK, 2016, J POLYM SCI POL CHEM, V54, P284, DOI 10.1002/pola.27959; Brown WM, 2012, COMPUT PHYS COMMUN, V183, P449, DOI 10.1016/j.cpc.2011.10.012; Brown WM, 2011, COMPUT PHYS COMMUN, V182, P898, DOI 10.1016/j.cpc.2010.12.021; Carrillo JMY, 2023, NANOSCALE, V15, P1042, DOI 10.1039/d2nr05113c; Carrillo JMY, 2011, MACROMOLECULES, V44, P5798, DOI 10.1021/ma2007943; Carrivain P, 2012, SOFT MATTER, V8, P9285, DOI 10.1039/c2sm25789k; Chapman DL, 1913, PHILOS MAG, V25, P475, DOI 10.1080/14786440408634187; Chremos A, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5030530; Chremos A, 2017, J CHEM PHYS, V147, DOI 10.1063/1.5010784; CLOUGH SA, 1973, J CHEM PHYS, V59, P2254, DOI 10.1063/1.1680328; Colby RH, 2010, RHEOL ACTA, V49, P425, DOI 10.1007/s00397-009-0413-5; Dealy J. M., 2012, Melt Rheology and Its Role in Plastics Processing: Theory and Applications; DEGENNES PG, 1959, PHYSICA, V25, P825, DOI 10.1016/0031-8914(59)90006-0; DEGENNES PG, 1976, J PHYS-PARIS, V37, P1461, DOI 10.1051/jphys:0197600370120146100; Dobrynin AV, 2005, PROG POLYM SCI, V30, P1049, DOI 10.1016/j.progpolymsci.2005.07.006; DOBRYNIN AV, 1995, MACROMOLECULES, V28, P1859, DOI 10.1021/ma00110a021; Doi M, 1986, THEORY POLYM DYNAMIC; Don SC, 2008, MACROMOLECULES, V41, P6505, DOI 10.1021/ma8001438; Durmaz EN, 2021, ACS APPL POLYM MATER, V3, P4347, DOI 10.1021/acsapm.1c00654; Ermi BD, 1998, MACROMOLECULES, V31, P7378, DOI 10.1021/ma980579+; Evans DJ., 2007, Statistical Mechanics of Nonequilbrium Liquids, DOI [10.22459/SMNL.08.2007, DOI 10.22459/SMNL.08.2007]; FORSTER S, 1990, POLYMER, V31, P781, DOI 10.1016/0032-3861(90)90036-X; Forster S., 2005, Polyelectrolytes in solution. Phys. Prop. Polym, V120, P51; FUOSS RM, 1951, DISCUSS FARADAY SOC, P125; FUOSS RM, 1948, J POLYM SCI, V3, P603, DOI 10.1002/pol.1948.120030414; Gelbart WM, 2000, PHYS TODAY, V53, P38, DOI 10.1063/1.1325230; Goswami M, 2015, MACROMOLECULES, V48, P9050, DOI 10.1021/acs.macromol.5b02145; Gouy M., 1910, Phys. Radium, V9, P457, DOI DOI 10.1051/JPHYSTAP:019100090045700; Gradzielski M, 2022, LANGMUIR, V38, P13330, DOI 10.1021/acs.langmuir.2c02166; Gregory KP, 2022, PHYS CHEM CHEM PHYS, V24, P12682, DOI 10.1039/d2cp00847e; Gubarev A, 2009, MACROMOLECULES, V42, P5851, DOI 10.1021/ma9008143; Han AJ, 2022, MACROMOLECULES, V55, P7148, DOI 10.1021/acs.macromol.2c01007; Henle ML, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.060801; Hess B, 2002, J CHEM PHYS, V116, P209, DOI 10.1063/1.1421362; Hong L, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.158102; Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5; Jacobson DR, 2017, NUCLEIC ACIDS RES, V45, P1596, DOI 10.1093/nar/gkw1305; Jia D, 2019, J AM CHEM SOC, V141, P5886, DOI 10.1021/jacs.9b00562; KATCHALSKY A, 1964, BIOPHYS J, V4, P9, DOI 10.1016/S0006-3495(64)86924-1; KREMER K, 1990, J CHEM PHYS, V92, P5057, DOI 10.1063/1.458541; Kumar R., private communication; Kumar R, 2012, J CHEM PHYS, V136, DOI 10.1063/1.4729158; Liao Q, 2003, MACROMOLECULES, V36, P3386, DOI 10.1021/ma025995f; Liao Q, 2007, MACROMOLECULES, V40, P7671, DOI 10.1021/ma070666e; Lopez CG, 2021, MACROMOLECULES, V54, P8088, DOI 10.1021/acs.macromol.1c01169; Lopez CG, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5024242; MANNING GS, 1969, J CHEM PHYS, V51, P924, DOI 10.1063/1.1672157; Mateescu EM, 1999, EUROPHYS LETT, V46, P493, DOI 10.1209/epl/i1999-00290-6; Matsumoto A, 2022, NIHON REOROJI GAKK, V50, P43, DOI 10.1678/rheology.50.43; Mezei F., 2002, Neutron spin echo spectroscopy: basics, trends and applications; Muthukumar M, 2017, MACROMOLECULES, V50, P9528, DOI 10.1021/acs.macromol.7b01929; Muthukumar M i., 2023, Physics of Charged Macromolecules: Synthetic and Biological Systems, DOI [10.1017/9781139046749, DOI 10.1017/9781139046749]; NEUMANN M, 1983, MOL PHYS, V50, P841, DOI 10.1080/00268978300102721; Nishida K, 1997, POLYMER, V38, P6083, DOI 10.1016/S0032-3861(97)00243-7; Nishida K, 2001, J CHEM PHYS, V114, P8671, DOI 10.1063/1.1367383; OOSTWAL M, 1993, MACROMOLECULES, V26, P6489, DOI 10.1021/ma00076a028; PINCUS P, 1991, MACROMOLECULES, V24, P2912, DOI 10.1021/ma00010a043; Pincus P., Polyelectrolytes: The de Gennes Legacy, P48, DOI [10.1142/9789814280648_0006, DOI 10.1142/9789814280648_0006]; Pota J, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms23073496; Ramírez J, 2010, J CHEM PHYS, V133, DOI 10.1063/1.3491098; Richter D, 2005, ADV POLYM SCI, V174, P1, DOI 10.1007/b106578; RUBINSTEIN M, 1994, PHYS REV LETT, V73, P2776, DOI 10.1103/PhysRevLett.73.2776; Rubinstein M., 2003, Polymer physics; Rubinstein M, 2012, SOFT MATTER, V8, P9265, DOI 10.1039/c2sm90104h; Saleh OA, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.068301; Schiessel H, 1998, MACROMOLECULES, V31, P7953, DOI 10.1021/ma980823x; Schneider C, 2008, LANGMUIR, V24, P10612, DOI 10.1021/la802303z; Slim AH, 2022, ACS MACRO LETT, DOI 10.1021/acsmacrolett.2c00213; Stern O, 1924, Z ELKTROCHEM ANGEW P, V30, P508; Tadmor R, 2002, MACROMOLECULES, V35, P2380, DOI 10.1021/ma011893y; Tamashiro MN, 2001, J CHEM PHYS, V115, P1960, DOI 10.1063/1.1381579; Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171; Wang CG, 2022, CHEM-ASIAN J, V17, DOI 10.1002/asia.202200604; Wang DL, 2001, CHEM PHYS LETT, V348, P411, DOI 10.1016/S0009-2614(01)01151-4; WEEKS JD, 1971, J CHEM PHYS, V54, P5237, DOI 10.1063/1.1674820; WITTEN TA, 1987, EUROPHYS LETT, V3, P315, DOI 10.1209/0295-5075/3/3/011	84	4	4	2	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1292-8941	1292-895X		EUR PHYS J E	Eur. Phys. J. E	OCT	2023	46	10							92	10.1140/epje/s10189-023-00342-2	http://dx.doi.org/10.1140/epje/s10189-023-00342-2			14	Chemistry, Physical; Materials Science, Multidisciplinary; Physics, Applied; Polymer Science	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Materials Science; Physics; Polymer Science	T6DD3	37796422				2024-07-03	WOS:001078864100001
J	Weissweiler, L; Hofmann, V; Koeksal, A; Schütze, H				Weissweiler, Leonie; Hofmann, Valentin; Koeksal, Abdullatif; Schuetze, Hinrich			Explaining pretrained language models' understanding of linguistic structures using construction grammar	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						NLP; probing; construction grammar; computational linguistics; large language models	COMPARATIVE CORRELATIVES	Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasizing the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step toward assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models' behavior in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs, as well as OPT, are able to recognize the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge.	[Weissweiler, Leonie; Hofmann, Valentin; Koeksal, Abdullatif; Schuetze, Hinrich] Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc, Munich, Germany; [Weissweiler, Leonie; Koeksal, Abdullatif; Schuetze, Hinrich] Munich Ctr Machine Learning, Munich, Germany; [Hofmann, Valentin] Univ Oxford, Fac Linguist, Oxford, England	University of Munich; University of Oxford	Weissweiler, L (corresponding author), Ludwig Maximilians Univ Munchen, Ctr Informat & Language Proc, Munich, Germany.; Weissweiler, L (corresponding author), Munich Ctr Machine Learning, Munich, Germany.	weissweiler@cis.lmu.de			European Research Council [740516]; German Federal Ministry of Education and Research (BMBF) [01IS18036A]	European Research Council(European Research Council (ERC)); German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF))	This work was funded by the European Research Council (#740516). VH was also supported by the German Academic Scholarship Foundation. AK was also supported by the German Federal Ministry of Education and Research (BMBF, Grant No. 01IS18036A).	Abeillé A, 2008, LINGUA, V118, P1139, DOI 10.1016/j.lingua.2008.02.001; [Anonymous], 1933, Language; [Anonymous], 2019, International Conference on Learning Representations (ICLR); Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080; Bencini GML, 2000, J MEM LANG, V43, P640, DOI 10.1006/jmla.2000.2757; Chomsky N., 1988, Studies in English linguistics and literature; Coenen Andy, 2019, Advances in Neural Information Processing Systems, V32, P8594; Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126; Culicover PW, 1999, LINGUIST INQ, V30, P543, DOI 10.1162/002438999554200; Demszky Dorottya., 2021, ANN C N AM CHAPT ASS, DOI [10.18653/v1/2021.naacl-main.184, DOI 10.18653/V1/2021.NAACL-MAIN.184]; den Dikken M, 2005, LINGUIST INQ, V36, P497; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dunietz J., 2017, T ASSOC COMPUT LING, V5, P117; Dunn J., 2019, Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, P117, DOI [10.18653/v1/W19-2913, DOI 10.18653/V1/W19-2913]; Dunn J, 2017, LANG COGN, V9, P254, DOI 10.1017/langcog.2016.7; Fillmore C., 1989, Language processing in social context, P17, DOI DOI 10.1016/B978-0-444-87144-2.50004-5; Fillmore C. J., 1986, E STAT C LING, V3, P163; FILLMORE CJ, 1988, LANGUAGE, V64, P501, DOI 10.2307/414531; Goldberg A., 2013, The Oxford Handbook of Construction Grammar, P15, DOI DOI 10.1093/OXFORDHB/9780195396683.013.0002; Goldberg A.E., 1995, CONSTRUCTIONS; Goldberg Adele E., 1995, CONSTRUCTIONS CONSTR; Goldberg AE, 2003, TRENDS COGN SCI, V7, P219, DOI 10.1016/S1364-6613(03)00080-9; Goldberg Y., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1901.05287; He P, 2020, ICLR; Hilpert M., 2006, Nordic Journal of Linguistics, V29, P151, DOI 10.1017/S0332586506001569; Hoffmann T, 2019, COGN LINGUIST, V30, P1, DOI 10.1515/cog-2018-0036; Hoffmann Thomas., 2013, The Oxford handbook of construction grammar, P307, DOI DOI 10.1093/OXFORDHB/9780195396683.001.0001; Holtzman A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7038; Honnibal Matthew., 2018, spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing; Iwasaki E., 2009, Essex Research Reports in Linguistics; Jackendoff R.S., 1977, XSYNTAX STUDY PHRASE; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Kay P, 1999, LANGUAGE, V75, P1, DOI 10.2307/417472; Lakoff George, 1990, Women, Fire; Langacker R. W., 1987, Foundations of Cognitive Grammar. Theoretical Prerequisites, V1; Li B., 2022, Proceedings of ACL, P7410; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.12564, DOI 10.48550/ARXIV.2301.12564, 10.48550/arXiv.2301.12564]; Marques Tania., 2016, P COLING 2016 26 INT, P1137; Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192; MCCANN JC, 1988, AFR ECON HIST, P176, DOI 10.2307/3601346; Paperno D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1525; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ribeiro MT, 2020, P 58 ANN M ASS COMP, P4902, DOI [DOI 10.18653/V1/2020.ACL-MAIN.442, 10.18653/v1/2020.acl-main.442]; Schwartz L., 2022, Proceedings of the First Workshop on NLP Applications to Field Linguistics, P64; Srivastava A., 2023, Trans. Mach. Learn. Res, P2835; Tayyar Madabushi Harish., 2020, Proceedings of the 28th International Conference on Computational Linguistics, P4020; Tseng YH, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6361; Vulic I., 2020, Conference on Empirical Methods in Natural Language Processing (EMNLP) 2020, DOI [10.18653/v1/2020.emnlp-main.586, DOI 10.18653/V1/2020.EMNLP-MAIN.586]; Warstadt A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P217; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wei J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P932; Weissweiler L., 2023, P 1 INT WORKSH CONST, P85; Weissweiler L., 2022, P 2022 C EMPIRICAL M, P10859, DOI 10.18653/v1/2022.emnlp-main.746; Wiedemann G, 2019, Arxiv, DOI arXiv:1909.10430; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; [詹卫东 Zhan Weidong], 2017, [中文信息学报, Journal of Chinese Information Processing], V31, P230; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao TZ, 2021, PR MACH LEARN RES, V139	63	0	0	3	5	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	OCT 12	2023	6								1225791	10.3389/frai.2023.1225791	http://dx.doi.org/10.3389/frai.2023.1225791			16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	U7SZ0	37899964	Green Published, gold			2024-07-03	WOS:001086779600001
C	Samtani, S; Yang, S; Chen, H			ACM	Samtani, Sagar; Yang, Shanchieh; Chen, Hsinchun			The 3rd Workshop on Artificial Intelligence-Enabled Cybersecurity Analytics	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD		Cybersecurity; artificial intelligence; analytics; large language models; machine learning		Artificial Intelligence (AI) has gripped modern society as a viable approach to revolutionize operational capabilities across multiple industries. One critical application area that could stand to benefit from the capabilities of AI is cybersecurity. Increasingly, federal funding agencies such as the National Science Foundation are calling for enhanced AI-enabled analytics capabilities to improve cyber threat intelligence, cyber defense generation, and more. To this end, this half-day workshop, not in its third year at ACM KDD, sought to attain significant contributions related to various aspects of AI-enabled cybersecurity analytics. This workshop received a record number of submissions. Submissions were reviewed by a highly-qualified, interdisciplinary group of AI for cybersecurity researchers and practitioners spanning academia and private industry firms.	[Samtani, Sagar] Indiana Univ, Bloomington, IN 47401 USA; [Yang, Shanchieh] Rochester Inst Technol, Henrietta, NY USA; [Chen, Hsinchun] Univ Arizona, Tucson, AZ USA	Indiana University System; Indiana University Bloomington; Rochester Institute of Technology; University of Arizona	Samtani, S (corresponding author), Indiana Univ, Bloomington, IN 47401 USA.	ssamtani@iu.edu; Jay.Yang@rit.edu; hsinchun@arizona.edu		Samtani, Sagar/0000-0002-4513-805X	 [DGE-2038483];  [DGE-1946537];  [OAC-1917117];  [CNS-1850362]	; ; ; 	This workshop is based upon work funded by DGE-2038483 (SaTC-EDU), DGE-1946537 (SFS), OAC-1917117 (CICI), and CNS-1850362 (CRII SaTC). We thank the authors for their contributions. We extend our appreciation to all of the Program Committee members who spent their valuable time reviewing the submitted papers.	Bertino E, 2021, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY '21), P333, DOI 10.1145/3422337.3450357; Samtani S, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4900, DOI 10.1145/3534678.3542894; Samtani S, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P4153, DOI 10.1145/3447548.3469450; Samtani S, 2020, ACM TRANS MANAG INF, V11, DOI 10.1145/3430360	4	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5880	5881		10.1145/3580305.3599229	http://dx.doi.org/10.1145/3580305.3599229			2	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ					2024-07-03	WOS:001118896305124
J	Henrickson, L				Henrickson, Leah			Conversations with No One	POETICS TODAY			English	Article						artificial intelligence; authorship; large language models; literary value; reader response	FICTION		[Henrickson, Leah] Univ Queensland, St Lucia, Australia	University of Queensland	Henrickson, L (corresponding author), Univ Queensland, St Lucia, Australia.							Bajohr Hannes., 2023, BMCCT Working Papers, DOI [10.12685/bmcct.2023.007, DOI 10.12685/BMCCT.2023.007]; Barthes Roland., 1977, Image, music, text; Bellaiche L, 2023, COGN RES, V8, DOI 10.1186/s41235-023-00499-6; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin Walter., 2000, Theory of the Novel, P77; Biles Peter, 2023, Mind Matters.; Bloom H., 2000, READ WHY; Booth WayneC., 1988, The Company We Keep: An Ethics of Fiction; Clark Elizabeth, 2021, arXiv; Dennett Daniel, 2023, Atlantic.; Djikic Maja., 2013, SCI STUDY LIT, V3, P28, DOI [10.1075/ssol.3.1.06dji, DOI 10.1075/SSOL.3.1.06DJI]; Ferrara E, 2019, COMMUN ACM, V62, P82, DOI 10.1145/3299768; Flegel M, 2014, J POP CULT, V47, P1092, DOI 10.1111/jpcu.12198; Fletcher A, 2021, NARRATIVE, V29, P1, DOI 10.1353/nar.2021.0000; Foucault Michel., 1998, The Essential Works of Foucault, 1954-1984, Vol. 2: Aesthetics, Method, V2, P205; Freire P., 1983, Journal of Education, V165, P5, DOI DOI 10.1177/002205748316500103; Gibson Richard Hughes, 2022, Hedgehog Review.; Henrickson L, 2023, AI SOC, DOI 10.1007/s00146-023-01752-8; Henrickson Leah, 2021, Reading ComputerGenerated Texts, DOI [10.1017/9781108906463, DOI 10.1017/9781108906463]; Hoel Erik, 2022, Intrinsic Perspective; Horning Rob, 2022, Internal Exile; Kirschenbaum Matthew, 2023, Atlantic; Leslie Ian, 2023, The Booker Prizes.; Mar RA, 2008, PERSPECT PSYCHOL SCI, V3, P173, DOI 10.1111/j.1745-6924.2008.00073.x; Marche Stephen, 2023, Atlantic; Menke M, 2019, CONVERGENCE-US, V25, P657, DOI 10.1177/1354856519834480; O'Day EB, 2021, COMPUT HUM BEHAV REP, V3, DOI 10.1016/j.chbr.2021.100070; Palumbo-Liu David., 2012, The Deliverance of Others: Reading Literature in a Global Age; Pianzola Federico, 2021, Digital Social Reading.; Poerio G, 2020, PSYCHOSOC INTERV, V29, P29, DOI 10.5093/pi2019a16; Powell Alvin, 2023, Harvard Gazette; RANESZOSTAK D, 1995, J ADOLESC ADULT LIT, V39, P100; Sharples Mike., 2022, Story machines: How computers have become creative writers; Smith F., 1982, WRITING WRITER; Tripathi Salil, 2023, PEN International.; Turkle Sherry, 2012, ALONE TOGETHER WHY W, DOI DOI 10.5613/RZS.41.3.7; Weber Millicent., 2023, Conversation.	37	0	0	0	0	DUKE UNIV PRESS	DURHAM	905 W MAIN ST, STE 18-B, DURHAM, NC 27701 USA	0333-5372			POETICS TODAY	Poetics Today	JUN 1	2024	45	2					291	299		10.1215/03335372-11092924	http://dx.doi.org/10.1215/03335372-11092924			9	Literature	Arts &amp; Humanities Citation Index (A&amp;HCI)	Literature	WC3H4					2024-07-03	WOS:001252625100001
J	Ferrante, G; Lanera, C				Ferrante, Gianluigi; Lanera, Corrado			ChatGPT in scientific research: a guide to informed use	EPIDEMIOLOGIA & PREVENZIONE			English	Article						ChatGPT; artificial intelligence; large language models; scientific research; ethical implications		Using ChatGPT in scientific research offers revolution- ary opportunities thanks to its natural language interac- tion capabilities and production of coherent and soph- isticated text. Artificial intelligence can automate activities such as in- formation synthesis and schematization, improving sci- entific communication and computer code writing. However, the lack of a complete understanding of con- text, the risk of spreading misleading information, and the possibility of plagiarism represent some of the biggest limitations in the current use of this technology. The role of human experience remains fundamental for in-depth understanding of context, exercising critical thinking, and ensuring respect for the ethical principles of scientific research. A responsible and aware use of tools such as ChatGPT can offer great benefits to the scientific community, but it is essential to remember that these tools are only a support and cannot replace human judgment and ex- perience.	[Ferrante, Gianluigi] CPO Piemonte, AOU Citta Salute & Sci Torino, SSD Epidemiol Screening, Turin, Italy; [Lanera, Corrado] Univ Padua, Unita Biostat Epidemiol & Sanita Pubbl, Padua, Italy	A.O.U. Citta della Salute e della Scienza di Torino; Centro di Riferimento per Epidemiologia e la Prevenzione Oncologica in Piemonte; University of Padua	Ferrante, G (corresponding author), CPO Piemonte, AOU Citta Salute & Sci Torino, SSD Epidemiol Screening, Turin, Italy.	gianluigi.ferrante@cpo.it	Lanera, Corrado/J-3937-2019	Lanera, Corrado/0000-0002-0520-7428				Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Common Crowl, US; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Zheng HY, 2023, AM J MED, V136, P725, DOI 10.1016/j.amjmed.2023.02.011	5	0	0	10	41	INFERENZE SCARL	MILANO	VIA RICCIARELLI N 29, MILANO, 20148, ITALY	1120-9763	2385-1937		EPIDEMIOL PREV	Epidemiol. Prev.	MAY-JUN	2023	47	3					203	207		10.19191/EP23.3.A639.051	http://dx.doi.org/10.19191/EP23.3.A639.051			5	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	O2CW4	37387301				2024-07-03	WOS:001041960300018
J	Bhattacharya, M; Pal, S; Chatterjee, S; Alshammari, A; Albekairi, TH; Jagga, S; Ohimain, EI; Zayed, H; Byrareddy, SN; Lee, SS; Wen, ZH; Agoramoorthy, G; Bhattacharya, P; Chakraborty, C				Bhattacharya, Manojit; Pal, Soumen; Chatterjee, Srijan; Alshammari, Abdulrahman; Albekairi, Thamer H.; Jagga, Supriya; Ohimain, Elijah Ige; Zayed, Hatem; Byrareddy, Siddappa N.; Lee, Sang-Soo; Wen, Zhi-Hong; Agoramoorthy, Govindasamy; Bhattacharya, Prosun; Chakraborty, Chiranjib			ChatGPT's scorecard after the performance in a series of tests conducted at the multi-country level: A pattern of responses of generative artificial intelligence or large language models	CURRENT RESEARCH IN BIOTECHNOLOGY			English	Article						ChatGPT; Accuracy; Reproducibility; Plagiarism; Answer length	MEDICINE; SCIENCE	Recently, researchers have shown concern about the ChatGPT-derived answers. Here, we conducted a series of tests using ChatGPT by individual researcher at multi-country level to understand the pattern of its answer accuracy, reproducibility, answer length, plagiarism, and in-depth using two questionnaires (the first set with 15 MCQs and the second 15 KBQ). Among 15 MCQ-generated answers, 13 +/- 70 were correct (Median : 82.5; Coefficient variance : 4.85), 3 +/- 0.77 were incorrect (Median: 3, Coefficient variance: 25.81), and 1 to 10 were reproducible, and 11 to 15 were not. Among 15 KBQ, the length of each question (in words) is about 294.5 +/- 97.60 (mean range varies from 138.7 to 438.09), and the mean similarity index (in words) is about 29.53 +/- 11.40 (Coefficient variance: 38.62) for each question. The statistical models were also developed using analyzed parameters of answers. The study shows a pattern of ChatGPT-derive answers with correctness and incorrectness and urges for an error-free, next-generation LLM to avoid users' misguidance.	[Bhattacharya, Manojit] Fakir Mohan Univ, Dept Zool, Balasore 756020, Odisha, India; [Pal, Soumen] Vellore Inst Technol, Sch Mech Engn, Vellore 632014, Tamil Nadu, India; [Chatterjee, Srijan; Lee, Sang-Soo] Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chunchon 24252, Gangwon Do, South Korea; [Alshammari, Abdulrahman; Albekairi, Thamer H.] King Saud Univ, Coll Pharm, Dept Pharmacol & Toxicol, POB 2455, Riyadh 11451, Saudi Arabia; [Jagga, Supriya] Harvard Med Sch, Brigham & Womens Hosp, Div Endocrinol, 25 Shattuck St, Boston, MA 02115 USA; [Ohimain, Elijah Ige] Niger Delta Univ, Microbiol Dept, Amassoma, Bayelsa State, Nigeria; [Zayed, Hatem] Qatar Univ, Coll Hlth & Sci, Dept Biomed Sci, QU Hlth, Doha, Qatar; [Byrareddy, Siddappa N.] Univ Nebraska Med Ctr, Dept Pharmacol & Expt Neurosci, Omaha, NE 68198 USA; [Wen, Zhi-Hong] Natl Sun Yat Sen Univ, Dept Marine Biotechnol & Resources, Kaohsiung 80424, Taiwan; [Agoramoorthy, Govindasamy] Tajen Univ, Coll Pharm & Hlth Care, Pingtung 907, Taiwan; [Bhattacharya, Prosun] KTH Royal Inst Technol, Dept Sustainable Dev Environm Sci & Engn, Teknikringen 10B, S-10044 Stockholm, Sweden; [Chakraborty, Chiranjib] Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, W Bengal, India	Fakir Mohan University; Vellore Institute of Technology (VIT); VIT Vellore; Hallym University; King Saud University; Harvard University; Harvard Medical School; Brigham & Women's Hospital; Qatar University; University of Nebraska System; University of Nebraska Medical Center; National Sun Yat Sen University; Royal Institute of Technology	Chakraborty, C (corresponding author), Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, W Bengal, India.		Alshammari, Abdulrahman/ISU-6545-2023		King Saud University, Riyadh, Saudi Arabia [RSP2024R491]	King Saud University, Riyadh, Saudi Arabia(King Saud University)	Authors are thankful to the Researchers Supporting Project number (RSP2024R491) , King Saud University, Riyadh, Saudi Arabia.	Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; Anderson L.W., 2003, CLASSROOM ASSESSMENT; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Chakraborty C, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1237704; Chakraborty C, 2023, INT J SURG, V109, P4367, DOI 10.1097/JS9.0000000000000701; Chakraborty C, 2024, ANN BIOMED ENG, V52, P134, DOI 10.1007/s10439-023-03297-9; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chatterjee S, 2023, MOL THER-NUCL ACIDS, V33, P205, DOI 10.1016/j.omtn.2023.06.019; Cheng Y, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.661235; Cheung BHH, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290691; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Engineering Medicine, 2019, Reproducibility and Replicability in Science; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Giannos P., 2023, JMIR Med. Educ., V9; Gilson A., 2023, JMIR Med. Educ., V9; Gundersen OE, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0210; Habibzadeh F, 2023, J KOREAN MED SCI, V38, DOI 10.3346/jkms.2023.38.e373; Halgamuge MN, 2017, COMPUT APPL ENG EDUC, V25, P895, DOI 10.1002/cae.21842; Hammer Oyvind, 2001, Palaeontologia Electronica, V4, pUnpaginated; Heil BJ, 2021, NAT METHODS, V18, P1132, DOI 10.1038/s41592-021-01256-7; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Horiuchi D, 2024, NEURORADIOLOGY, V66, P73, DOI 10.1007/s00234-023-03252-4; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; Iftikhar L., 2023, EC Paediatrics, V12, P45; Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.44484; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Mbakwe A.B., 2023, PLOS Digit Health, V2; Medenilla A., 2023, PLoS Digital Health, V2; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Osama M, 2023, JCPSP-J COLL PHYSICI, V33, P1198, DOI 10.29271/jcpsp.2023.10.1198; Pal S, 2024, INT J SURG, V110, P1329, DOI 10.1097/JS9.0000000000000939; Pal S, 2024, ANN BIOMED ENG, V52, P451, DOI 10.1007/s10439-023-03306-x; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rojas-Carabali W, 2023, OCUL IMMUNOL INFLAMM, DOI 10.1080/09273948.2023.2253471; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Shanahan M, 2023, NATURE, V623, P493, DOI 10.1038/s41586-023-06647-8; Stringer JK, 2021, MED SCI EDUC, V31, P1311, DOI 10.1007/s40670-021-01305-y; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Ventayen R.J. M., 2023, Social Science Research Network, DOI DOI 10.2139/SSRN.4332664; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	48	0	0	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2590-2628			CURR RES BIOTECHNOL	Curr. Res. Biotechnol.		2024	7								100194	10.1016/j.crbiot.2024.100194	http://dx.doi.org/10.1016/j.crbiot.2024.100194			20	Biotechnology & Applied Microbiology	Emerging Sources Citation Index (ESCI)	Biotechnology & Applied Microbiology	RH0L6		gold			2024-07-03	WOS:001226656400001
J	Zaleski, AL; Berkowsky, R; Craig, KJT; Pescatello, LS				Zaleski, Amanda L.; Berkowsky, Rachel; Craig, Kelly Jean Thomas; Pescatello, Linda S.			Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided by an AI-Based Chatbot: Mixed Methods Study	JMIR MEDICAL EDUCATION			English	Article						exercise prescription; health literacy; large language model; patient education; artificial intelligence; AI; chatbot	TREAT HYPERTENSION; PHYSICAL-ACTIVITY; HEALTH; ADULTS	Background: Regular physical activity is critical for health and disease prevention. Yet, health care providers and patients face barriers to implement evidence-based lifestyle recommendations. The potential to augment care with the increased availability of artificial intelligence (AI) technologies is limitless; however, the suitability of AI-generated exercise recommendations has yet to be explored. Objective: The purpose of this study was to assess the comprehensiveness, accuracy, and readability of individualized exercise recommendations generated by a novel AI chatbot. Methods: A coding scheme was developed to score AI-generated exercise recommendations across ten categories informed by gold-standard exercise recommendations, including (1) health condition-specific benefits of exercise, (2) exercise preparticipation health screening, (3) frequency, (4) intensity, (5) time, (6) type, (7) volume, (8) progression, (9) special considerations, and (10) references to the primary literature. The AI chatbot was prompted to provide individualized exercise recommendations for 26 clinical populations using an open-source application programming interface. Two independent reviewers coded AI-generated content for each category and calculated comprehensiveness (%) and factual accuracy (%) on a scale of 0%-100%. Readability was assessed using the Flesch-Kincaid formula. Qualitative analysis identified and categorized themes from AI-generated output. Results: AI-generated exercise recommendations were 41.2% (107/260) comprehensive and 90.7% (146/161) accurate, with the majority (8/15, 53%) of inaccuracy related to the need for exercise preparticipation medical clearance. Average readability level of AI-generated exercise recommendations was at the college level (mean 13.7, SD 1.7), with an average Flesch reading ease score of 31.1 (SD 7.7). Several recurring themes and observations of AI-generated output included concern for liability and safety, preference for aerobic exercise, and potential bias and direct discrimination against certain age-based populations and individuals with disabilities. Conclusions: There were notable gaps in the comprehensiveness, accuracy, and readability of AI-generated exercise recommendations. Exercise and health care professionals should be aware of these limitations when using and endorsing AI-based technologies as a tool to support lifestyle change involving exercise.	[Zaleski, Amanda L.] CVS Hlth Corp, Clin Evidence Dev, Aetna Med Affairs, Hartford, CT USA; [Berkowsky, Rachel; Pescatello, Linda S.] Hartford Hosp, Dept Prevent Cardiol, Hartford, CT USA; [Zaleski, Amanda L.] Univ Connecticut, Dept Kinesiol, Storrs, CT USA; [Zaleski, Amanda L.] CVS Hlth Corp, Aetna Med Affairs, Clin Evidence Dev, 151 Farmington Ave, Hartford, CT 06156 USA	Hartford Hospital; University of Connecticut	Zaleski, AL (corresponding author), CVS Hlth Corp, Aetna Med Affairs, Clin Evidence Dev, 151 Farmington Ave, Hartford, CT 06156 USA.	zaleskia@aetna.com	Thomas Craig, Kelly Jean/ABE-6181-2021	Thomas Craig, Kelly Jean/0000-0002-9954-2795; Pescatello, Linda/0000-0002-5841-798X; Zaleski, Amanda/0000-0002-0362-819X; Berkowsky, Rachel/0000-0003-1150-1284	Hartford Hospital; University of Connecticut; CVS Health Corporation	Hartford Hospital; University of Connecticut; CVS Health Corporation	This study was supported by the University of Connecticut, CVS Health Corporation, and Hartford Hospital.	Alves AJ, 2022, CURR SPORT MED REP, V21, P280, DOI 10.1249/JSR.0000000000000983; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2014, ACSMS GUIDELINES EXE, V9th; [Anonymous], 2023, ChatGPT Feb 13 version; [Anonymous], 2023, Which certification is right for you?.; [Anonymous], 2023, Pronouncements & scientific communications.; Arnett DK, 2019, CIRCULATION, V140, pE563, DOI [10.1161/CIR.0000000000000678, 10.1016/j.jacc.2019.03.009, 10.1161/CIR.0000000000000677, 10.1016/j.jacc.2019.03.010]; Bernard R, 2021, HEALTH SECUR, V19, P3, DOI 10.1089/hs.2020.0038; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Brewer LC, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/14512; Bruce C, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17577; Campbell DJ, 2023, J CLIN SLEEP MED, V19, P1989, DOI 10.5664/jcsm.10728; Ceccarelli G, 2020, AIDS BEHAV, V24, P1042, DOI 10.1007/s10461-019-02510-y; Choudhury A, 2022, IEEE J BIOMED HEALTH, V26, P468, DOI 10.1109/JBHI.2021.3087083; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Craig KJT, 2021, TRANSL BEHAV MED, V11, P1037, DOI 10.1093/tbm/ibaa099; Craig KJT, 2020, BMC HEALTH SERV RES, V20, DOI 10.1186/s12913-020-05503-z; Exercise is medicine, 2021, ACSM's Rx for health; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; Fowles JR, 2018, APPL PHYSIOL NUTR ME, V43, P535, DOI 10.1139/apnm-2017-0763; Gallo PM, 2023, ACSMS HEALTH FIT J, V27, P51, DOI 10.1249/FIT.0000000000000843; Garvey KV, 2022, JMIR MED INF, V10, DOI 10.2196/37478; Garvey KV, 2021, MED SCI EDUC, V31, P2055, DOI 10.1007/s40670-021-01377-w; Gibbs BB, 2021, HYPERTENSION, V78, pE26, DOI 10.1161/HYP.0000000000000196; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giovanola B, 2023, AI SOC, V38, P549, DOI 10.1007/s00146-022-01455-6; Hanssen H, 2022, EUR J PREV CARDIOL, V29, P205, DOI 10.1093/eurjpc/zwaa141; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hu K., 2023, Reuters; Joseph JJ, 2022, CIRCULATION, V145, pE722, DOI 10.1161/CIR.0000000000001040; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Liguori G, 2021, ACSM's guidelines for exercise testing and prescription, V11th; Liu TM, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.755808; Lloyd-Jones DM, 2022, CIRCULATION, V146, pE18, DOI 10.1161/CIR.0000000000001078; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Novak LL, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad028; Nowell LS, 2017, INT J QUAL METH, V16, DOI 10.1177/1609406917733847; Nutbeam D, 2021, ANNU REV PUBL HEALTH, V42, P159, DOI 10.1146/annurev-publhealth-090419-102529; O'Brien MW, 2017, APPL PHYSIOL NUTR ME, V42, P384, DOI 10.1139/apnm-2016-0413; Omura JD, 2018, PREV MED, V108, P115, DOI [10.1016/j.ypmed.2017.12.030, 10.1016]; Pedersen BK, 2015, SCAND J MED SCI SPOR, V25, P1, DOI 10.1111/sms.12581; Pescatell LS, 2019, MED SCI SPORT EXER, V51, P1314, DOI 10.1249/MSS.0000000000001943; Piercy KL, 2018, JAMA-J AM MED ASSOC, V320, P2020, DOI 10.1001/jama.2018.14854; Riebe D, 2015, MED SCI SPORT EXER, V47, P2473, DOI 10.1249/MSS.0000000000000664; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Siddiqui E, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.10397; Stormacq C, 2019, HEALTH PROMOT INT, V34, pE1, DOI 10.1093/heapro/day062; Swoboda CM, 2018, BMC FAM PRACT, V19, DOI 10.1186/s12875-018-0805-7; Tabone W, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.231053; Tsao CW, 2022, CIRCULATION, V145, pE153, DOI 10.1161/CIR.0000000000001052; Wang LW, 2013, RES SOC ADMIN PHARM, V9, P503, DOI 10.1016/j.sapharm.2012.05.009; Whitfield GP, 2017, MED SCI SPORT EXER, V49, P2056, DOI 10.1249/MSS.0000000000001331	56	0	0	15	15	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e51308	10.2196/51308	http://dx.doi.org/10.2196/51308			15	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IJ8H2	38206661	gold, Green Published			2024-07-03	WOS:001166043700001
J	van Genugten, RDI; Schacter, DL				van Genugten, Ruben D. I.; Schacter, Daniel L.			Automated scoring of the autobiographical interview with natural language processing	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						Autobiographical interview; Autobiographical memory; Automated scoring; Natural language processing; Large language models	SPECIFICITY INDUCTION; EPISODIC SIMULATION; MEMORY; FUTURE; YOUNG	The autobiographical interview has been used in more than 200 studies to assess the content of autobiographical memories. In a typical experiment, participants recall memories, which are then scored manually for internal details (episodic details from the central event) and external details (largely non-episodic details). Scoring these narratives requires a significant amount of time. As a result, large studies with this procedure are often impractical, and even conducting small studies is time-consuming. To reduce scoring burden and enable larger studies, we developed an approach to automatically score responses with natural language processing. We fine-tuned an existing language model (distilBERT) to identify the amount of internal and external content in each sentence. These predictions were aggregated to obtain internal and external content estimates for each narrative. We evaluated our model by comparing manual scores with automated scores in five datasets. We found that our model performed well across datasets. In four datasets, we found a strong correlation between internal detail counts and the amount of predicted internal content. In these datasets, manual and automated external scores were also strongly correlated, and we found minimal misclassification of content. In a fifth dataset, our model performed well after additional preprocessing. To make automated scoring available to other researchers, we provide a Colab notebook that is intended to be used without additional coding.	[van Genugten, Ruben D. I.] Northeastern Univ, Inst Experiential Artificial Intelligence, Boston, MA 02136 USA; [Schacter, Daniel L.] Harvard Univ, Dept Psychol, Cambridge, MA USA	Northeastern University; Harvard University	van Genugten, RDI (corresponding author), Northeastern Univ, Inst Experiential Artificial Intelligence, Boston, MA 02136 USA.	r.vangenugten@northeastern.edu			Northeastern University USA; Department of Psychology at Harvard University [R01 AG008441]; National Institute on Aging	Northeastern University USA; Department of Psychology at Harvard University; National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This work was conducted when Ruben van Genugten was a PhD student in the Department of Psychology at Harvard University. We thank Aleea Devitt, Signy Sheldon, and Peggy St. Jacques for sharing data with us. We thank Patrick Mair for discussions related to this manuscript. Preparation of this manuscript was supported by the National Institute on Aging [grant number R01 AG008441] awarded to DLS.	Addis DR, 2008, PSYCHOL SCI, V19, P33, DOI 10.1111/j.1467-9280.2008.02043.x; Azunre P., 2021, Transfer learning for natural language processing; Devitt AL, 2020, J GERONTOL B-PSYCHOL, V75, P1831, DOI 10.1093/geronb/gbz041; Devitt AL, 2018, PSYCHOL SCI, V29, P936, DOI 10.1177/0956797617753936; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diamond NB, 2020, PSYCHOL SCI, V31, P1557, DOI 10.1177/0956797620958651; Gaesser B, 2011, PSYCHOL AGING, V26, P80, DOI 10.1037/a0021054; Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X; Irish M, 2011, NEUROPSYCHOLOGIA, V49, P2694, DOI 10.1016/j.neuropsychologia.2011.05.017; Jing HG, 2016, J EXP PSYCHOL GEN, V145, P402, DOI 10.1037/xge0000142; King CI, 2022, MEMORY, V30, P942, DOI 10.1080/09658211.2022.2061003; Levine B, 2002, PSYCHOL AGING, V17, P677, DOI 10.1037//0882-7974.17.4.677; Levine B., 2021, Memory; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Madore KP, 2014, PSYCHOL AGING, V29, P913, DOI 10.1037/a0038209; Madore KP, 2014, J EXP PSYCHOL LEARN, V40, P609, DOI 10.1037/a0034885; Peters J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14433-6; Race E, 2011, J NEUROSCI, V31, P10262, DOI 10.1523/JNEUROSCI.1145-11.2011; Renoult L, 2020, NEUROPSYCHOLOGIA, V144, DOI 10.1016/j.neuropsychologia.2020.107501; Sadvilkar N, 2020, Arxiv, DOI arXiv:2010.09657; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schacter DL, 2007, PHILOS T R SOC B, V362, P773, DOI 10.1098/rstb.2007.2087; Schacter DL, 2016, MEM STUD, V9, P245, DOI 10.1177/1750698016645230; Sheldon S, 2020, COGNITION, V198, DOI 10.1016/j.cognition.2020.104217; Söderlund H, 2014, J ABNORM PSYCHOL, V123, P51, DOI 10.1037/a0035610; Strikwerda-Brown C, 2021, MEMORY, V29, P1375, DOI 10.1080/09658211.2021.1987476; Strikwerda-Brown C, 2019, J NEUROPSYCHOL, V13, P371, DOI 10.1111/jnp.12160; Takano K, 2019, MEMORY, V27, P306, DOI 10.1080/09658211.2018.1507042; Takano K, 2018, PSYCHOL ASSESSMENT, V30, P259, DOI 10.1037/pas0000472; Takano K, 2017, BEHAV RES METHODS, V49, P835, DOI 10.3758/s13428-016-0753-x; van Genugten RDI, 2022, CREATIVITY RES J, V34, P145, DOI 10.1080/10400419.2021.1976451; Wardell V, 2021, APPL COGNITIVE PSYCH, V35, P1454, DOI 10.1002/acp.3877; Wardell V, 2021, BEHAV RES METHODS, V53, P507, DOI 10.3758/s13428-020-01437-w; Wickner C., 2015, KIW C WELL NZ; WILLIAMS JMG, 1986, J ABNORM PSYCHOL, V95, P144, DOI 10.1037/0021-843X.95.2.144; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38	36	3	3	14	14	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 JAN 17	2024										10.3758/s13428-023-02145-x	http://dx.doi.org/10.3758/s13428-023-02145-x		JAN 2024	17	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	FA2K9	38233632	hybrid			2024-07-03	WOS:001142955900003
J	Draschl, A; Hauer, G; Fischerauer, SF; Kogler, A; Leitner, L; Andreou, D; Leithner, A; Sadoghi, P				Draschl, Alexander; Hauer, Georg; Fischerauer, Stefan Franz; Kogler, Angelika; Leitner, Lukas; Andreou, Dimosthenis; Leithner, Andreas; Sadoghi, Patrick			Are ChatGPT's Free-Text Responses on Periprosthetic Joint Infections of the Hip and Knee Reliable and Useful?	JOURNAL OF CLINICAL MEDICINE			English	Article						artificial intelligence; large language model; periprosthetic joint infection; hip prosthesis; knee prosthesis		Background: This study aimed to evaluate ChatGPT's performance on questions about periprosthetic joint infections (PJI) of the hip and knee. Methods: Twenty-seven questions from the 2018 International Consensus Meeting on Musculoskeletal Infection were selected for response generation. The free-text responses were evaluated by three orthopedic surgeons using a five-point Likert scale. Inter-rater reliability (IRR) was assessed via Fleiss' kappa (FK). Results: Overall, near-perfect IRR was found for disagreement on the presence of factual errors (FK: 0.880, 95% CI [0.724, 1.035], p < 0.001) and agreement on information completeness (FK: 0.848, 95% CI [0.699, 0.996], p < 0.001). Substantial IRR was observed for disagreement on misleading information (FK: 0.743, 95% CI [0.601, 0.886], p < 0.001) and agreement on suitability for patients (FK: 0.627, 95% CI [0.478, 0.776], p < 0.001). Moderate IRR was observed for agreement on "up-to-dateness" (FK: 0.584, 95% CI [0.434, 0.734], p < 0.001) and suitability for orthopedic surgeons (FK: 0.505, 95% CI [0.383, 0.628], p < 0.001). Question- and subtopic-specific analysis revealed diverse IRR levels ranging from near-perfect to poor. Conclusions: ChatGPT's free-text responses to complex orthopedic questions were predominantly reliable and useful for orthopedic surgeons and patients. Given variations in performance by question and subtopic, consulting additional sources and exercising careful interpretation should be emphasized for reliable medical decision-making.	[Draschl, Alexander; Hauer, Georg; Fischerauer, Stefan Franz; Kogler, Angelika; Leitner, Lukas; Andreou, Dimosthenis; Leithner, Andreas; Sadoghi, Patrick] Med Univ Graz, Dept Orthopaed & Trauma, Auenbruggerpl 5, A-8036 Graz, Austria; [Draschl, Alexander] Med Univ Graz, Dept Surg, Div Plast Aesthet & Reconstruct Surg, Auenbruggerpl 29-4, A-8036 Graz, Austria; [Kogler, Angelika] Med Univ Graz, Dept Dermatol & Venereol, Auenbruggerpl 8, A-8036 Graz, Austria	Medical University of Graz; Medical University of Graz; Medical University of Graz	Sadoghi, P (corresponding author), Med Univ Graz, Dept Orthopaed & Trauma, Auenbruggerpl 5, A-8036 Graz, Austria.	patrick.sadoghi@medunigraz.at	Leithner, Andreas/JBI-9805-2023; Draschl, Alexander/JNE-9113-2023	Leithner, Andreas/0000-0002-2598-2325; Sadoghi, Patrick/0000-0003-1767-555X; Leitner, Lukas/0000-0002-5534-7605				Bernstein J, 2023, CLIN ORTHOP RELAT R, V481, P651, DOI 10.1097/CORR.0000000000002619; Elmahdy M, 2023, J AM MED INFORM ASSN, V30, P1552, DOI 10.1093/jamia/ocad094; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; King H, 2023, J AM MED INFORM ASSN, V30, P529, DOI 10.1093/jamia/ocac254; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Leithner A, 2010, J AM MED INFORM ASSN, V17, P373, DOI 10.1136/jamia.2010.004507; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Passby L, 2023, CLIN EXP DERMATOL, V49, P722, DOI 10.1093/ced/llad197; Schwendicke F, 2021, J DENT, V107, DOI 10.1016/j.jdent.2021.103610; Strony J, 2019, J BONE JOINT SURG AM, V101, DOI 10.2106/JBJS.19.00182; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749; Valentini M., 2023, P 35 ANN M EUR MUSC	22	1	1	3	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-0383		J CLIN MED	J. Clin. Med.	OCT	2023	12	20							6655	10.3390/jcm12206655	http://dx.doi.org/10.3390/jcm12206655			11	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	W8TP7	37892793	gold, Green Published			2024-07-03	WOS:001094302000001
J	Grigio, TR; Timmerman, H; Wolff, AP				Grigio, Thiago R.; Timmerman, Hans; Wolff, Andre P.			ChatGPT in anaesthesia research: risk of fabrication in literature searches	BRITISH JOURNAL OF ANAESTHESIA			English	Letter						artificial intelligence; ChatGPT; data fabrication; grey literature; large language model; research integrity			[Grigio, Thiago R.; Timmerman, Hans; Wolff, Andre P.] Univ Groningen, Univ Med Ctr Groningen, Pain Ctr, Dept Anaesthesiol, Groningen, Netherlands	University of Groningen	Grigio, TR (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Pain Ctr, Dept Anaesthesiol, Groningen, Netherlands.	t.r.grigio@umcg.nl	Timmerman, Hans/D-3425-2009; GRIGIO, THIAGO/G-1621-2014	Timmerman, Hans/0000-0002-6082-9043; GRIGIO, THIAGO/0000-0002-6271-8718				Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; OpenAI, GPT LANG MOD; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3	3	3	4	7	17	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	JUL	2023	131	1					E29	E30		10.1016/j.bja.2023.04.009	http://dx.doi.org/10.1016/j.bja.2023.04.009		JUN 2023	2	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	M3IP4	37183102	Green Published			2024-07-03	WOS:001029152100001
J	Dien, J; Ritz, T				Dien, Joseph; Ritz, Thomas			Generative artificial intelligence in publishing - Reflection and discussion	BIOLOGICAL PSYCHOLOGY			English	Editorial Material						Plagiarism; Large Language Models; ChatGPT; Artificial Intelligence; Academic Misconduct			[Dien, Joseph] Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304 Benjamin Bldg, College Pk, MD 20742 USA; [Ritz, Thomas] Southern Methodist Univ, Dept Psychol, POB 750442, Dallas, TX 75275 USA	University System of Maryland; University of Maryland College Park; Southern Methodist University	Dien, J (corresponding author), Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304 Benjamin Bldg, College Pk, MD 20742 USA.	jdien07@mac.com		Dien, Joseph/0000-0001-6908-2612				Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Chomsky N., 2023, NEW YORK TIMES; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Fowler G.A., 2023, WE TESTED NEW CHATGP; Gal U., 2023, ARS TECHNICA 0208; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Shaffi S., 2023, The GuardianJanuary 23; Zielinski C., 2023, CHATBOTS CHATGPT SCH	8	0	0	30	57	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0301-0511	1873-6246		BIOL PSYCHOL	Biol. Psychol.	JUL	2023	181								108595	10.1016/j.biopsycho.2023.108595	http://dx.doi.org/10.1016/j.biopsycho.2023.108595		JUL 2023	2	Psychology, Biological; Behavioral Sciences; Psychology; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Behavioral Sciences	R3RJ1	37257813				2024-07-03	WOS:001063553700001
C	Hao, SC; Shi, XJ; Liu, HW; Shu, YJ			IEEE	Hao, Sichong; Shi, Xianjun; Liu, Hongwei; Shu, Yanjun			Enhancing Code Language Models for Program Repair by Curricular Fine-tuning Framework	2023 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE AND EVOLUTION, ICSME	Proceedings-IEEE International Conference on Software Maintenance		English	Proceedings Paper	39th IEEE International Conference on Software Maintenance and Evolution (ICSME)	OCT 01-06, 2023	Univ Andes, Bogota, COLOMBIA	IEEE, IEEE Comp Soc Tech Community Software Engn, IEEE Tech Council Software Engn, Fundac GCF Aprende Libre	Univ Andes	Program Repair; Large Language Models of Code; Curriculum Learning		Automated program repair (APR) is a key technique for enhancing software maintenance productivity by fixing buggy code automatically. Recently, large code language models (CLMs) have exhibited impressive capabilities in code generation. However, for complex programming tasks, especially program repair, the success rate of CLMs is still low. One of the reasons is that CLMs are typically developed for general purpose and their potential for APR applications has yet to be fully explored. In this paper, we propose APRFiT, a general curricular fine-tuning framework that improves the success rate of CLMs for APR. Firstly, APRFiT generates syntactically diverse but semantically equivalent bug-fixing programs via code augmentation operators to enrich the diversity of bug-fixing dataset automatically. Secondly, APRFiT designs a curriculum learning-based mechanism to help CLMs develop deep understanding of program semantics from these augmented bug-fixing code variants and improve the effectiveness of fine-tuning for APR tasks. We implement APRFiT on different CLMs and evaluate them on Bugs2Fix small and medium datasets. The extensive experiments demonstrate that, the existing CLMs implemented with APRFiT substantially outperform original models and generate 2.5 to 14.5 percent more correct patches than baselines both effectively and efficiently.	[Hao, Sichong; Shi, Xianjun; Liu, Hongwei; Shu, Yanjun] Harbin Inst Technol, Fac Comp, Harbin, Peoples R China	Harbin Institute of Technology	Liu, HW (corresponding author), Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.	schao@stu.hit.edu.cn; shixianjun@hit.edu.cn; liuhw@hit.edu.cn; yjshu@hit.edu.cn			National Key Research and Development Program of China [2022YFC3301800]; 5G Multi-Computing Power Service Center of ChinaUnicom Heilongjiang Branch	National Key Research and Development Program of China; 5G Multi-Computing Power Service Center of ChinaUnicom Heilongjiang Branch	This work is supported by the National Key Research and Development Program of China (No. 2022YFC3301800). This work is also supported by 5G Multi-Computing Power Service Center of ChinaUnicom Heilongjiang Branch.	Bengio Y., 2009, ICML, P41, DOI DOI 10.1145/1553374.1553380; Berabi B, 2021, PR MACH LEARN RES, V139; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chakraborty Saikat, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P18, DOI 10.1145/3540250.3549162; Chakraborty S, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P443, DOI 10.1109/ASE51524.2021.9678559; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chi JL, 2023, IEEE T SOFTWARE ENG, V49, P564, DOI 10.1109/TSE.2022.3156637; cloud, 2022, Bigquery github repos; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Guo D., 2021, ICLR; Hacohen G, 2019, PR MACH LEARN RES, V97; Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jain P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5954; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu Shangqing, 2023, arXiv; Lu S., 2022, NeurIPS 2021; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Mastropaolo A., 2022, IEEE Transactions on Software Engineering; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Niu CG, 2022, PROC INT CONF SOFTW, P2006, DOI 10.1145/3510003.3510096; Niu Changan, 2022, P 31 INT JOINT C ART, P5546, DOI 10.24963/ijcai.2022/775; Panthaplackel S, 2021, AAAI CONF ARTIF INTE, V35, P13622; Penha Gustavo, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P699, DOI 10.1007/978-3-030-45439-5_46; Platanios EA, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1162; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Tay Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4922; Tay Yi, 2022, INT C LEARN REPR; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Vaswani A, 2017, ADV NEUR IN, V30; Wang DZ, 2022, PROC INT CONF SOFTW, P287, DOI 10.1145/3510003.3510062; Wang X, 2022, IEEE T PATTERN ANAL, V44, P4555, DOI 10.1109/TPAMI.2021.3069908; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xia C. S., 2022, P 30 ACM JOINT EUR S; Xia Chunqiu Steven, 2022, arXiv; Xu Benfeng, 2020, P 58 ANN M ASS COMPU, DOI DOI 10.18653/V1/2020.ACL-MAIN.542; Yang Z, 2022, PROC INT CONF SOFTW, P1482, DOI 10.1145/3510003.3510146; Ye H, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556926; Yefet N, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428230; Yu SW, 2022, J SYST SOFTWARE, V190, DOI 10.1016/j.jss.2022.111304; Yuan W, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P678, DOI 10.1145/3533767.3534219; Zeng ZR, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P39, DOI 10.1145/3533767.3534390; Zhang JR, 2021, AAAI CONF ARTIF INTE, V35, P3351; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zhong WK, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556943; Zhou Y, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3501256	54	1	1	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6773		979-8-3503-2783-0	PROC IEEE INT CONF S			2023							136	146		10.1109/ICSME58846.2023.00024	http://dx.doi.org/10.1109/ICSME58846.2023.00024			11	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2UF					2024-07-03	WOS:001125977500012
J	Armitage, RC				Armitage, Richard C.			Performance of Generative Pre-trained Transformer-4 (GPT-4) in Membership of the Royal College of General Practitioners (MRCGP)-style examination questions	POSTGRADUATE MEDICAL JOURNAL			English	Letter						medical education; clinical medicine; emerging technology; large language models; artificial intelligence			[Armitage, Richard C.] Univ Nottingham, Sch Med, Acad Unit Populat & Lifespan Sci, Clin Sci Bldg,Nottingham City Hosp Campus,Hucknall, Nottingham NG5 1PB, England	Nottingham University Hospital NHS Trust; University of Nottingham	Armitage, RC (corresponding author), Univ Nottingham, Sch Med, Acad Unit Populat & Lifespan Sci, Clin Sci Bldg,Nottingham City Hosp Campus,Hucknall, Nottingham NG5 1PB, England.	richard.armitage@nhs.net		Armitage, Richard/0000-0003-1165-6753				[Anonymous], Llama 2; Anthropic, CLAUDE 2; Armitage RC, 2023, POSTGRAD MED J, V99, P1130, DOI 10.1093/postmj/qgad046; bing.com, US; Google, BARD; OpenAI, 2023, Introducing gpts; OpenAI, 2023, GPT-4; Poe, US; RCGP Learning, GP SELFTEST; Sahu PK, 2024, POSTGRAD MED J, V100, P50, DOI 10.1093/postmj/qgad090	10	3	3	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0032-5473	1469-0756		POSTGRAD MED J	Postgrad. Med. J.	MAR 18	2024	100	1182					274	275		10.1093/postmj/qgad128	http://dx.doi.org/10.1093/postmj/qgad128		DEC 2023	2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	LF0Z9	38142282				2024-07-03	WOS:001133640600001
C	Shen, YY; Ai, XY; Raj, AGS; John, RJL; Syamkumar, M			Assoc Computing Machinery	Shen, Yiyin; Ai, Xinyi; Raj, Adalbert Gerald Soosai; John, Rogers Jeffrey Leo; Syamkumar, Meenakshi			Implications of ChatGPT for Data Science Education	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		data science education; large language models; prompt engineering		ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.	[Shen, Yiyin; Syamkumar, Meenakshi] Univ Wisconsin Madison, Madison, WI 53706 USA; [Ai, Xinyi; Raj, Adalbert Gerald Soosai] Univ Calif San Diego, San Diego, CA USA	University of Wisconsin System; University of Wisconsin Madison; University of California System; University of California San Diego	Shen, YY (corresponding author), Univ Wisconsin Madison, Madison, WI 53706 USA.	yshen82@wisc.edu; xiai@ucsd.edu; asoosairaj@ucsd.edu; rogersjeffreyl@gmail.com; ms@cs.wisc.edu		Ai, Xinyi/0009-0000-0047-3885				Arora S, 2022, Arxiv, DOI [arXiv:2210.02441, arXiv:2210.02441]; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Biderman S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2933, DOI 10.1145/3511808.3557079; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caraza-Harter Tyler, 2023, Data Science Programming II, VII; Chandel Shubham, 2022, arXiv; Chen M., 2021, arXiv; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Donoghue Thomas, 2020, Data Science in Practice; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Hendrycks Dan, 2021, P NEURAL INFORM PROC, V1; Khan Tabarak, What are tokens and how to count them?; Lai Y., 2023, PMLR, P18319; Lake B, 2018, PR MACH LEARN RES, V80; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; McAuley Julian, 2022, CSE 158/258; microsoft, 2023, Prompt engineering: learn how to use AI models with prompt engineering; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Open AI, 2023, Chat GPT; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Shieh J., 2023, Best practices for prompt engineering with openai API; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	27	0	0	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							1230	1236		10.1145/3626252.3630874	http://dx.doi.org/10.1145/3626252.3630874			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		hybrid			2024-07-03	WOS:001181240800178
J	Nakaura, T; Hirai, T				Nakaura, Takeshi; Hirai, Toshinori			Response to Letter to the Editor from Muhammed Said Beşler et al.: "The Performance of the Multimodal Large Language Model GPT-4 on the European Board of Radiology Examination Sample Test"	JAPANESE JOURNAL OF RADIOLOGY			English	Letter; Early Access									[Nakaura, Takeshi; Hirai, Toshinori] Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, 1-1-1 Honjo,Chuo Ku, Kumamoto, Kumamoto 8608556, Japan	Kumamoto University	Nakaura, T (corresponding author), Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, 1-1-1 Honjo,Chuo Ku, Kumamoto, Kumamoto 8608556, Japan.	kff00712@nifty.com; t-hirai@kumamoto-u.ac.jp		Nakaura, Takeshi/0000-0002-9010-0341				Besler MS, 2024, JPN J RADIOL, DOI 10.1007/s11604-024-01565-9; Nakaura T, 2024, JPN J RADIOL, DOI 10.1007/s11604-024-01552-0; Nakaura T, 2024, JPN J RADIOL, V42, P190, DOI 10.1007/s11604-023-01487-y; Ueda D, 2024, JPN J RADIOL, V42, P3, DOI 10.1007/s11604-023-01474-3	4	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1867-1071	1867-108X		JPN J RADIOL	Jpn. J. Radiol.	2024 MAY 2	2024										10.1007/s11604-024-01577-5	http://dx.doi.org/10.1007/s11604-024-01577-5		MAY 2024	1	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	SI4E1	38696057				2024-07-03	WOS:001233804000001
J	López-Ubeda, P; Martín-Noguerol, T; Luna, A				Lopez-Ubeda, Pilar; Martin-Noguerol, Teodoro; Luna, Antonio			Reply to the Letter to the Editor: "Radiology in the era of large language models: additional facts to consider in the near and the dark side of the moon"	EUROPEAN RADIOLOGY			English	Letter									[Lopez-Ubeda, Pilar] HT Med, RDI Dept, Jaen, Spain; [Martin-Noguerol, Teodoro; Luna, Antonio] HT Med, Radiol Dept, MRI Unit, Jaen, Spain		López-Ubeda, P (corresponding author), HT Med, RDI Dept, Jaen, Spain.	p.lopez@htmedica.com	López-Úbeda, Pilar/AAS-2488-2021	López-Úbeda, Pilar/0000-0003-0478-743X	Ministry of Science and Innovation (MCIN/AEI) [PTQ2021-012120]	Ministry of Science and Innovation (MCIN/AEI)	This study has received funding by Ministry of Science and Innovation (MCIN/AEI/https:// doi. org/ 10. 13039/ 50110 00110 33), grant number PTQ2021-012120.	Medenilla A., 2023, PLoS Digital Health, V2; Mitchell E., 2023, arXiv; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Park JY, 2023, J KOR ASSOC ORAL MAX, V49, P105, DOI 10.5125/jkaoms.2023.49.3.105	4	0	0	0	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0938-7994	1432-1084		EUR RADIOL	Eur. Radiol.	DEC	2023	33	12					9460	9461		10.1007/s00330-023-10331-w	http://dx.doi.org/10.1007/s00330-023-10331-w		NOV 2023	2	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	CF2U2	37924343				2024-07-03	WOS:001103728100002
J	Golan, R; Reddy, R; Ramasamy, R				Golan, Roei; Reddy, Rohit; Ramasamy, Ranjith			The rise of artificial intelligence-driven health communication	TRANSLATIONAL ANDROLOGY AND UROLOGY			English	Editorial Material						Artificial intelligence (AI); large language models (LLMs); patient education; online content			[Golan, Roei] Florida State Univ, Coll Med, Dept Clin Sci, Tallahassee, FL USA; [Reddy, Rohit] Univ South Florida HCA, Dept Internal Med, Brandon, FL USA; [Ramasamy, Ranjith] Univ Miami, Sethi Urol Inst, Miller Sch Med, 1120 NW 14th St,1551, Miami, FL 33136 USA	State University System of Florida; Florida State University; University of Miami	Ramasamy, R (corresponding author), Univ Miami, Sethi Urol Inst, Miller Sch Med, 1120 NW 14th St,1551, Miami, FL 33136 USA.	Ramasamy@miami.edu			National Institute of Diabetes and Digestive and Kidney Diseases [UE5 DK137308]; National Institutes of Health [R01 DK130991]; Clinician Scientist Development Grant from American Cancer Society	National Institute of Diabetes and Digestive and Kidney Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Clinician Scientist Development Grant from American Cancer Society	This work was supported by the National Institute of Diabetes and Digestive and Kidney Diseases (grant UE5 DK137308), National Institutes of Health (grant R01 DK130991), and Clinician Scientist Development Grant from American Cancer Society to Ranjith Ramasamy.	Barksdale S, 2023, JMIR FORM RES, V7, DOI 10.2196/51541; Cox CL, 2023, J EVAL CLIN PRACT, V29, P1127, DOI 10.1111/jep.13882; Davis R, 2023, J UROLOGY, V210, P688, DOI 10.1097/JU.0000000000003615; Eppler MB, 2023, UROL PRACT, V10, P435, DOI 10.1097/UPJ.0000000000000428; Golan R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42214; Golan R, 2023, UROL PRACT, V10, P443, DOI 10.1097/UPJ.0000000000000428.01; Golan R, 2023, NAT REV UROL, V20, P327, DOI 10.1038/s41585-023-00746-x; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Musheyev D, 2024, EUR UROL, V85, P13, DOI 10.1016/j.eururo.2023.07.004; Reddy RV, 2022, ANDROLOGIA, V54, DOI 10.1111/and.14607; Rodler Severin, 2023, Eur Urol Focus, DOI 10.1016/j.euf.2023.10.020	11	0	0	0	0	AME PUBLISHING COMPANY	SHATIN	FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA	2223-4683	2223-4691		TRANSL ANDROL UROL	Transl. Androl. Urol.	FEB 29	2024	13	2					356	358		10.21037/tau-23-556	http://dx.doi.org/10.21037/tau-23-556			3	Andrology; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Endocrinology & Metabolism; Urology & Nephrology	QP3W2	38481858	gold, Green Published			2024-07-03	WOS:001222044900017
J	Fujimoto, S; Takemoto, K				Fujimoto, Sasuke; Takemoto, Kazuhiro			Revisiting the political biases of ChatGPT	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						ChatGPT; algorithm bias; political bias; large-language model; natural language processing		Although ChatGPT promises wide-ranging applications, there is a concern that it is politically biased; in particular, that it has a left-libertarian orientation. Nevertheless, following recent trends in attempts to reduce such biases, this study re-evaluated the political biases of ChatGPT using political orientation tests and the application programming interface. The effects of the languages used in the system as well as gender and race settings were evaluated. The results indicate that ChatGPT manifests less political bias than previously assumed; however, they did not entirely dismiss the political bias. The languages used in the system, and the gender and race settings may induce political biases. These findings enhance our understanding of the political biases of ChatGPT and may be useful for bias evaluation and designing the operational strategy of ChatGPT.	[Fujimoto, Sasuke; Takemoto, Kazuhiro] Kyushu Inst Technol, Dept Biosci & Bioinformat, Iizuka, Fukuoka, Japan	Kyushu Institute of Technology	Takemoto, K (corresponding author), Kyushu Inst Technol, Dept Biosci & Bioinformat, Iizuka, Fukuoka, Japan.	takemoto@bio.kyutech.ac.jp	Takemoto, Kazuhiro/H-2915-2019	Takemoto, Kazuhiro/0000-0002-6355-1366	Japan Society for the Promotion of Science10.13039/501100001691	Japan Society for the Promotion of Science10.13039/501100001691(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	We would like to thank Editage (www.editage.jp) for their English language editing services.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bass D., 2023, ChatGPT maker OpenAI says it's working to reduce bias; Bass D., 2023, Fortune; Chowdhury H., 2023, Sam Altman has one big problem to solve before ChatGPT can generate big cash-making it 'woke'. Business Insider; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Frackiewicz M., 2023, ChatGPT and the Risks of Deepening Social Inequalities and Divides; Fraiwan M, 2023, Arxiv, DOI arXiv:2305.00237; GoToQuiz, 2023, Political spectrum quiz. GoToQuiz.com; Hartmann J, 2023, Arxiv, DOI [arXiv:2301.01768, 10.48550/ARXIV.2301.01768, DOI 10.48550/ARXIV.2301.01768]; Hood C, 2011, GOVERNANCE, V24, P635, DOI 10.1111/j.1468-0491.2011.01546.x; IDRLabs, 2023, Eysenck political test. IDRLabs.com; IDRLabs, 2023, IDRLabs political coordinates test; IDRLabs, 2023, IDRLabs ideologies test; IDRLabs, 2023, 8 values political test; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Moors G, 2008, QUAL QUANT, V42, P779, DOI 10.1007/s11135-006-9067-x; OpenAI, 2022, Introducing ChatGPT. OpenAI Blog; OpenAI, 2023, How should AI systems behave, and who should decide? OpenAI Blog; Pace News Ltd, 2001, Political compass test. The Political Compass Test; Pacula RL, 2002, J PUBLIC HEALTH POL, V23, P413, DOI 10.2307/3343240; Radford A., 2018, IMPROVING LANGUAGE U; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rozado D., 2023, The political biases of GPT-4. Rozado's Visual Analytics; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sellman M., 2023, ChatGPT will always have bias; Seyyed-Kalantari L, 2021, NAT MED, V27, P2176, DOI 10.1038/s41591-021-01595-0; The Advocates, 2023, World's smallest political quiz. The Advocates; Wolf Z. B., 2023, AI can be racist	30	1	1	25	29	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	OCT 20	2023	6								1232003	10.3389/frai.2023.1232003	http://dx.doi.org/10.3389/frai.2023.1232003			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	AO7V0	37928447	gold, Green Submitted, Green Published			2024-07-03	WOS:001119479800001
J	Akhondi-Asl, A; Yang, YY; Luchette, M; Burns, JP; Mehta, NM; Geva, A				Akhondi-Asl, Alireza; Yang, Youyang; Luchette, Matthew; Burns, Jeffrey P.; Mehta, Nilesh M.; Geva, Alon			Comparing the Quality of Domain-Specific Versus General Language Models for Artificial Intelligence-Generated Differential Diagnoses in PICU Patients	PEDIATRIC CRITICAL CARE MEDICINE			English	Article						differential diagnosis; large language models; natural language processing; pediatric critical care		OBJECTIVES:Generative language models (LMs) are being evaluated in a variety of tasks in healthcare, but pediatric critical care studies are scant. Our objective was to evaluate the utility of generative LMs in the pediatric critical care setting and to determine whether domain-adapted LMs can outperform much larger general-domain LMs in generating a differential diagnosis from the admission notes of PICU patients. DESIGN:Single-center retrospective cohort study. SETTING:Quaternary 40-bed PICU. PATIENTS:Notes from all patients admitted to the PICU between January 2012 and April 2023 were used for model development. One hundred thirty randomly selected admission notes were used for evaluation. INTERVENTIONS:None. MEASUREMENTS AND MAIN RESULTS:Five experts in critical care used a 5-point Likert scale to independently evaluate the overall quality of differential diagnoses: 1) written by the clinician in the original notes, 2) generated by two general LMs (BioGPT-Large and LLaMa-65B), and 3) generated by two fine-tuned models (fine-tuned BioGPT-Large and fine-tuned LLaMa-7B). Differences among differential diagnoses were compared using mixed methods regression models. We used 1,916,538 notes from 32,454 unique patients for model development and validation. The mean quality scores of the differential diagnoses generated by the clinicians and fine-tuned LLaMa-7B, the best-performing LM, were 3.43 and 2.88, respectively (absolute difference 0.54 units [95% CI, 0.37-0.72], p < 0.001). Fine-tuned LLaMa-7B performed better than LLaMa-65B (absolute difference 0.23 unit [95% CI, 0.06-0.41], p = 0.009) and BioGPT-Large (absolute difference 0.86 unit [95% CI, 0.69-1.0], p < 0.001). The differential diagnosis generated by clinicians and fine-tuned LLaMa-7B were ranked as the highest quality in 144 (55%) and 74 cases (29%), respectively. CONCLUSIONS:A smaller LM fine-tuned using notes of PICU patients outperformed much larger models trained on general-domain data. Currently, LMs remain inferior but may serve as an adjunct to human clinicians in real-world tasks using real-world data.	[Akhondi-Asl, Alireza; Yang, Youyang; Luchette, Matthew; Burns, Jeffrey P.; Mehta, Nilesh M.; Geva, Alon] Boston Childrens Hosp, Dept Anesthesiol Crit Care & Pain Med, Div Crit Care Med, Boston, MA 02115 USA; [Akhondi-Asl, Alireza; Yang, Youyang; Luchette, Matthew; Burns, Jeffrey P.; Mehta, Nilesh M.; Geva, Alon] Boston Childrens Hosp, Perioperat & Crit Care Ctr Outcomes PC CORE, Boston, MA 02115 USA; [Akhondi-Asl, Alireza; Yang, Youyang; Luchette, Matthew; Burns, Jeffrey P.; Geva, Alon] Harvard Med Sch, Dept Anaesthesia, Boston, MA 02115 USA; [Geva, Alon] Boston Childrens Hosp, Computat Hlth Informat Program, Boston, MA USA	Harvard University; Boston Children's Hospital; Harvard University; Boston Children's Hospital; Harvard University; Harvard Medical School; Harvard University; Boston Children's Hospital	Akhondi-Asl, A (corresponding author), Boston Childrens Hosp, Dept Anesthesiol Crit Care & Pain Med, Div Crit Care Med, Boston, MA 02115 USA.; Akhondi-Asl, A (corresponding author), Boston Childrens Hosp, Perioperat & Crit Care Ctr Outcomes PC CORE, Boston, MA 02115 USA.; Akhondi-Asl, A (corresponding author), Harvard Med Sch, Dept Anaesthesia, Boston, MA 02115 USA.	Alireza.Akhondi-Asl@childrens.harvard.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aramaki Eiji, 2022, Yearb Med Inform, V31, P243, DOI 10.1055/s-0042-1742510; Ateia S, 2023, Arxiv, DOI arXiv:2306.16108; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Evans R S, 2016, Yearb Med Inform, VSuppl 1, pS48, DOI 10.15265/IYS-2016-s006; Fleming SL, 2023, Arxiv, DOI arXiv:2308.14089; Gwet KL., 2014, Handbook of Inter-Rater Reliability: The Definitive Guide to Measuring the Extent of Agreement among Raters, P410; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Holmes J, 2023, Arxiv, DOI arXiv:2304.01938; Hsieh CY, 2023, Arxiv, DOI arXiv:2305.02301; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Lederman A, 2022, J AM MED INFORM ASSN, V29, P1810, DOI 10.1093/jamia/ocac121; Lehman E., 2023, C HLTH INF LEARN, P578; Lehman E, 2021, Arxiv, DOI arXiv:2104.07762; Li Yikuan, 2022, arXiv; Liu TD, 2023, Arxiv, DOI arXiv:2305.14201; Lukas N, 2023, Arxiv, DOI [arXiv:2302.00539, DOI 10.48550/ARXIV.2302.00539]; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Roso M., 2023, medRxiv, P23290939, DOI [10.1101/2023.06.04.23290939v1, DOI 10.1101/2023.06.04.23290939V1]; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang GY, 2023, Arxiv, DOI [arXiv:2306.09968, 10.48550/arXiv.2306.09968]; Wang Z, 2023, Arxiv, DOI arXiv:2306.01499; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Wu ZH, 2023, Arxiv, DOI arXiv:2304.09138; Xiao CJ, 2021, AI OPEN, V2, P79, DOI 10.1016/j.aiopen.2021.06.003; Yetistiren B, 2023, Arxiv, DOI arXiv:2304.10778; Yin JQ, 2023, J SUPERCOMPUT, V79, P20747, DOI 10.1007/s11227-023-05479-7; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	39	1	1	1	1	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	1529-7535	1947-3893		PEDIATR CRIT CARE ME	Pediatr. Crit. Care Med.	JUN	2024	25	6					e273	e282		10.1097/PCC.0000000000003468	http://dx.doi.org/10.1097/PCC.0000000000003468			10	Critical Care Medicine; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Pediatrics	TH9Z8	38329382				2024-07-03	WOS:001240506200022
J	Dwivedi, YK; Kshetri, N; Hughes, L; Slade, EL; Jeyaraj, A; Kar, AK; Baabdullah, AM; Koohang, A; Raghavan, V; Ahuja, M; Albanna, H; Albashrawi, MA; Al-Busaidi, AS; Balakrishnan, J; Barlette, Y; Basu, S; Bose, I; Brooks, L; Buhalis, D; Carter, L; Chowdhury, S; Crick, T; Cunningham, SW; Davies, GH; Davison, RM; De, RH; Dennehy, D; Duan, YQ; Dubey, R; Dwivedi, R; Edwards, JS; Flavian, C; Gauld, R; Grover, V; Hu, MC; Janssen, M; Jones, P; Junglas, I; Khorana, S; Kraus, S; Larsen, KR; Latreille, P; Laumer, S; Malik, FT; Mardani, A; Mariani, M; Mithas, S; Mogaji, E; Nord, JH; O'Connor, S; Okumus, F; Pagani, M; Pandey, N; Papagiannidis, S; Pappas, IO; Pathak, N; Pries-Heje, J; Raman, R; Rana, NP; Rehm, SV; Ribeiro-Navarrete, S; Richter, A; Rowe, F; Sarker, S; Stahl, BC; Tiwari, MK; van der Aalst, W; Venkatesh, V; Viglia, G; Wade, M; Walton, P; Wirtz, J; Wright, R				Dwivedi, Yogesh K.; Kshetri, Nir; Hughes, Laurie; Slade, Emma Louise; Jeyaraj, Anand; Kar, Arpan Kumar; Baabdullah, Abdullah M.; Koohang, Alex; Raghavan, Vishnupriya; Ahuja, Manju; Albanna, Hanaa; Albashrawi, Mousa Ahmad; Al-Busaidi, Adil S.; Balakrishnan, Janarthanan; Barlette, Yves; Basu, Sriparna; Bose, Indranil; Brooks, Laurence; Buhalis, Dimitrios; Carter, Lemuria; Chowdhury, Soumyadeb; Crick, Tom; Cunningham, Scott W.; Davies, Gareth H.; Davison, Robert M.; De, Rahul; Dennehy, Denis; Duan, Yanqing; Dubey, Rameshwar; Dwivedi, Rohita; Edwards, John S.; Flavian, Carlos; Gauld, Robin; Grover, Varun; Hu, Mei-Chih; Janssen, Marijn; Jones, Paul; Junglas, Iris; Khorana, Sangeeta; Kraus, Sascha; Larsen, Kai R.; Latreille, Paul; Laumer, Sven; Malik, F. Tegwen; Mardani, Abbas; Mariani, Marcello; Mithas, Sunil; Mogaji, Emmanuel; Nord, Jeretta Horn; O'Connor, Siobhan; Okumus, Fevzi; Pagani, Margherita; Pandey, Neeraj; Papagiannidis, Savvas; Pappas, Ilias O.; Pathak, Nishith; Pries-Heje, Jan; Raman, Ramakrishnan; Rana, Nripendra P.; Rehm, Sven-Volker; Ribeiro-Navarrete, Samuel; Richter, Alexander; Rowe, Frantz; Sarker, Suprateek; Stahl, Bernd Carsten; Tiwari, Manoj Kumar; van der Aalst, Wil; Venkatesh, Viswanath; Viglia, Giampaolo; Wade, Michael; Walton, Paul; Wirtz, Jochen; Wright, Ryan			"So what if ChatGPT wrote it?" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy	INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT			English	Article						Conversational agent; Generative artificial intelligence; Generative AI; ChatGPT; Large language models	ARTIFICIAL-INTELLIGENCE; HIGHER-EDUCATION; DECISION-MAKING; SYSTEMS; FUTURE; TRANSFORMATION; RESISTANCE; SERVICES; CALCULATORS; TECHNOLOGY	Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistin-guishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, dis-ruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these con-tributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.	[Dwivedi, Yogesh K.; Hughes, Laurie; Dennehy, Denis] Swansea Univ, Sch Management, Digital Futures Sustainable Business & Soc Res Grp, Bay Campus, Swansea, Wales; [Dwivedi, Yogesh K.] Pune & Symbiosis Int Deemed Univ, Symbiosis Inst Business Management, Dept Management, Pune, Maharashtra, India; [Kshetri, Nir] Univ North Carolina Greensboro, Bryan Sch Business & Econ, Greensboro, NC USA; [Slade, Emma Louise] Univ Bristol, Business Sch, Bristol BS8 1S, England; [Jeyaraj, Anand] Wright State Univ, Raj Soin Coll Business, Information Syst, 3640 Colonel Glenn Highway, Dayton, OH 45435 USA; [Kar, Arpan Kumar] Indian Inst Technol Delhi, Sch Artificial Intelligence, Hauz Khas, New Delhi, India; [Kar, Arpan Kumar] Indian Inst Technol Delhi, Dept Management Studies, Hauz Khas, New Delhi, India; [Baabdullah, Abdullah M.] King Abdulaziz Univ, Fac Econ & Adm, Dept Management Informat Syst, Jeddah, Saudi Arabia; [Koohang, Alex] Middle Georgia State Univ, Sch Comp, Macon, GA USA; [Raghavan, Vishnupriya] NIIT Ltd, Client Advisory & Transformat, Stackroute, Bengaluru, India; [Ahuja, Manju] Univ Louisville, Coll Business, Dept Informat Syst Analyt & Operat, Louisville, KY USA; [Albanna, Hanaa] Northumbria Univ London, London, England; [Albashrawi, Mousa Ahmad] KFUPM Business Sch, IRC FDE, KFUPM, ISOM, Dhahran, Saudi Arabia; [Al-Busaidi, Adil S.] Sultan Qaboos Univ, Innovat & Technol Transfer Ctr, Seeb, Oman; [Al-Busaidi, Adil S.] Sultan Qaboos Univ, Dept Business Commun, Seeb, Oman; [Balakrishnan, Janarthanan] Natl Inst Technol, Dept Management Studies, Tiruchirappalli, India; [Barlette, Yves] Montpellier Business Sch MBS, Montpellier, France; [Basu, Sriparna] FORE Sch Management, New Delhi, India; [Bose, Indranil] Indian Inst Management Ahmedabad, Ahmadabad 380015, India; [Brooks, Laurence] Univ Sheffield, Informat Sch, Sheffield, England; [Buhalis, Dimitrios] Bournemouth Univ Business Sch, Poole, Dorset, England; [Carter, Lemuria] Univ New South Wales, Sch Informat Syst & Technol Management, Sydney, Australia; [Chowdhury, Soumyadeb] TBS Business Sch, Informat Operat & Management Sci Dept, 1 Pl Alphonse Jourdain, F-31068 Toulouse, France; [Crick, Tom] Swansea Univ, Dept Educ & Childhood Studies, Swansea, Wales; [Cunningham, Scott W.] Univ Strathclyde, Fac Humanities & Social Sci, Glasgow G1 1XQ, Scotland; [Davies, Gareth H.] Swansea Univ, Sch Management, Swansea, Wales; [Davison, Robert M.] City Univ Hong Kong, Dept Informat Syst, Hong Kong, Peoples R China; [De, Rahul] Indian Inst Management Bangalore, Bangalore, India; [Duan, Yanqing] Univ Bedfordshire, Business & Management Res Inst, Luton, England; [Dubey, Rameshwar] Montpellier Business Sch, Montpellier, France; [Dubey, Rameshwar] Liverpool John Moores Univ, Liverpool Business Sch, Liverpool, England; [Dwivedi, Rohita] Prin L N Welingkar Inst Management Dev & Res, Mumbai, India; [Edwards, John S.] Aston Business Sch, Operat & Informat Management Dept, Birmingham, England; [Flavian, Carlos] Univ Zaragoza, Fac Econ & Business, Dept Mkt & Mkt Management, Zaragoza, Spain; [Gauld, Robin] Univ Otago, Ctr Hlth Syst & Technol, Otago Business Sch, Dunedin, New Zealand; [Grover, Varun] Univ Arkansas, Walton Coll Business, Distinguished Prof & George & Boyce Billingsley E, IS Doctoral Program, Room 216, Fayetteville, AR 72703 USA; [Hu, Mei-Chih] Natl Tsing Hua Univ, Inst Technol Management, Hsinchu 300, Taiwan; [Janssen, Marijn] Delft Univ Technol, Fac Technol Policy & Management, Delft, Netherlands; [Jones, Paul] Swansea Univ, Sch Management, Swansea, Wales; [Junglas, Iris] Coll Charleston, Sch Business, Charleston, SC USA; [Khorana, Sangeeta] Bournemouth Univ, Business Sch, Poole, England; [Kraus, Sascha] Free Univ Bozen Bolzano, Univ Johannesburg, Johannesburg, South Africa; [Larsen, Kai R.] Univ Colorado, Leeds Sch Business, Boulder, CO USA; [Latreille, Paul] Univ Sheffield, Sheffield Univ Management Sch, Sheffield, England; [Laumer, Sven] Friedrich Alexander Univ Erlangen Nuremberg, Inst Informat Syst Nurnberg, Scholler Endowed Chair Informat Syst, Sch Business, Nurnberg, Germany; [Malik, F. Tegwen] Swansea Univ, Sch Management, Bay Campus, Swansea SA1 8EN, Wales; [Mardani, Abbas] Worcester Polytech Inst, Business Sch, Worcester, MA 01609 USA; [Mariani, Marcello] Univ Reading, Henley Business Sch, Henley On Thames, Oxon, England; [Mariani, Marcello] Univ Bologna, Dept Management, Bologna, Italy; [Mithas, Sunil] Univ S Florida, Sch Informat Syst & Management, Tampa, FL USA; [Mogaji, Emmanuel] Univ Greenwich, Greenwich Business Sch, London SE10 9LS, England; [Nord, Jeretta Horn] Oklahoma State Univ, Spears Sch Business, Management Sci & Informat Syst, Stillwater, OK 74078 USA; [O'Connor, Siobhan] Univ Manchester, Sch Hlth Sci, Div Nursing Midwifery & Social Work, Manchester, Lancs, England; [Okumus, Fevzi] Univ Cent Florida, Rosen Coll Hospitality Management, 9907 Universal Blvd, Orlando, FL 32819 USA; [Okumus, Fevzi] WSB Univ, Dept Business, Wroclaw, Poland; [Pagani, Margherita] SKEMA Res Ctr Artificial Intelligence, SKEMA Business Sch, 5 quai Marcel Dassault, Suresnes, France; [Pandey, Neeraj] Natl Inst Ind Engn NITIE, Mumbai, India; [Papagiannidis, Savvas] Newcastle Univ, Business Sch, Newcastle Upon Tyne, Northumberland, England; [Pappas, Ilias O.] Univ Agder, Dept Informat Syst, Kristiansand, Norway; [Pappas, Ilias O.] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway; [Pathak, Nishith] Microsoft AI MVP & Microsoft Reg DirectorGlobal l, Delhi, India; [Pries-Heje, Jan] Roskilde Univ, Dept People & Technol, Roskilde, Denmark; [Raman, Ramakrishnan] Pune & Symbiosis Int Deemed Univ, Symbiosis Inst Business Management, Pune, India; [Rana, Nripendra P.] Qatar Univ, Coll Business & Econ, Dept Management & Mkt, POB 2713, Doha, Qatar; [Rehm, Sven-Volker] Univ Strasbourg, HuManiS Res Ctr Humans & Management Soc, EM Strasbourg Business Sch, UR 7308, Strasbourg, France; [Ribeiro-Navarrete, Samuel] ES Univ, Spain & Univ Econ & Human Sci, Warsaw, Poland; [Richter, Alexander] Wellington Sch Business & Govt, Rutherford House, 23 Lambton Quay, Wellington, New Zealand; [Rowe, Frantz] Nantes Univ, SKEMA Business Sch, LEMNA, Nantes, France; [Sarker, Suprateek] Univ Virginia, McIntire Sch Commerce, Rolls Royce Commonwealth Commerce, Charlottesville, VA USA; [Stahl, Bernd Carsten] Univ Nottingham, Sch Comp Sci, Nottingham, England; [van der Aalst, Wil] Rhein Westfal TH Aachen, Proc & Data Sci, Ahornstr 55, D-52074 Aachen, Germany; [Venkatesh, Viswanath] Virginia TechBlacksburg, Pamplin Coll Business, Business, Blacksburg, VA USA; [Viglia, Giampaolo] Univ Portsmouth, Dept Strategy Mkt & Innovat, Richmond Bldg, Portsmouth, Hampshire, England; [Viglia, Giampaolo] Univ Aosta Valley, Dept Econ & Polit Sci, Aosta, Italy; [Wade, Michael] IMD Business Sch, Global Ctr Digital Business Transformat, Digital Transformat, Lausanne, Switzerland; [Walton, Paul] Capgemini UK Ltd, London, England; [Wirtz, Jochen] Natl Univ Singapore, Dept Mkt, Singapore, Singapore	Swansea University; Symbiosis International University; Symbiosis Institute of Business Management (SIBM) Pune; University of North Carolina; University of North Carolina Greensboro; University of Bristol; University System of Ohio; Wright State University Dayton; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; King Abdulaziz University; University of Louisville; King Fahd University of Petroleum & Minerals; National Institute of Technology (NIT System); National Institute of Technology Tiruchirappalli; FORE School of Management; Indian Institute of Management (IIM System); Indian Institute of Management Ahmedabad; University of Sheffield; University of New South Wales Sydney; Swansea University; University of Strathclyde; Swansea University; City University of Hong Kong; Indian Institute of Management (IIM System); Indian Institute of Management Bangalore; University of Bedfordshire; Montpellier Business School; Liverpool John Moores University; University of Liverpool; Aston University; University of Zaragoza; University of Otago; University of Arkansas System; University of Arkansas Fayetteville; National Tsing Hua University; Delft University of Technology; Swansea University; College of Charleston; Bournemouth University; University of Johannesburg; University of Colorado System; University of Colorado Boulder; University of Sheffield; University of Erlangen Nuremberg; Swansea University; Worcester Polytechnic Institute; University of Reading; University of Bologna; State University System of Florida; University of South Florida; University of Greenwich; Oklahoma State University System; Oklahoma State University - Stillwater; University of Manchester; State University System of Florida; University of Central Florida; SKEMA Business School; National Institute of Industrial Engineering (NITIE); Newcastle University - UK; University of Agder; Norwegian University of Science & Technology (NTNU); Roskilde University; Symbiosis International University; Symbiosis Institute of Business Management (SIBM) Pune; Qatar University; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg; Nantes Universite; SKEMA Business School; University of Virginia; University of Nottingham; RWTH Aachen University; Virginia Polytechnic Institute & State University; University of Portsmouth; Universita Della Valle D'aosta; International Institute for Management Development (IMD); National University of Singapore	Dwivedi, YK (corresponding author), Swansea Univ, Sch Management, Digital Futures Sustainable Business & Soc Res Grp, Bay Campus, Swansea, Wales.	y.k.dwivedi@swansea.ac.uk	Mogaji, Emmanuel/B-8900-2014; Wade, Michael/KHY-4609-2024; Pappas, Ilias/JPA-1685-2023; Brooks, Laurence/AAN-8456-2021; Larsen, Kai/AAF-7117-2021; Barlette, Yves/S-5893-2016; Gauld, Robin/JXW-8425-2024; Flavian, Carlos/G-4365-2013; Malik, Tegwen/JMQ-0671-2023; Mardani, Abbas/D-5700-2015; Ribeiro-Navarrete, Samuel/GXW-2229-2022; Viglia, Giampaolo/Q-1537-2019; Ribeiro-Navarrete, Samuel/CAG-7783-2022; DUBEY, Rameshwar/U-7022-2018; Wright, Ryan Timothy/L-4600-2019; Crick, Tom/C-8481-2011; Edwards, John Steven/AAC-9878-2020; Raman, Ramakrishnan/U-2170-2017; Dwivedi, Rohita/ACP-0558-2022; Janssen, Marijn/H-6223-2013; Balakrishnan, Janarthanan/H-9687-2012; Wright, Ryan/ABG-3527-2021; Mariani, Marcello/ABW-5250-2022; Wirtz, Jochen/P-3235-2015; Venkatesh, Viswanath/ABD-9343-2020; Baabdullah, Abdullah M./AAX-8282-2020; Kar, Arpan Kumar/B-9999-2009; Dwivedi, Yogesh Kumar/A-5362-2008; Al-Busaidi, Adil/ABG-4934-2020; Stahl, Bernd Carsten/AAK-4828-2021; Pandey, Neeraj/D-1968-2013; Davison, Robert/E-4383-2013; O'Connor, Siobhan/D-8140-2015	Mogaji, Emmanuel/0000-0003-0544-4842; Wade, Michael/0000-0002-0829-7422; Brooks, Laurence/0000-0002-5456-8799; Barlette, Yves/0000-0001-6106-7274; Flavian, Carlos/0000-0001-7118-9013; Malik, Tegwen/0000-0003-4315-5726; Mardani, Abbas/0000-0003-1010-3655; Viglia, Giampaolo/0000-0001-8521-4988; Ribeiro-Navarrete, Samuel/0000-0003-1046-5322; DUBEY, Rameshwar/0000-0002-3913-030X; Wright, Ryan Timothy/0000-0002-9719-415X; Crick, Tom/0000-0001-5196-9389; Edwards, John Steven/0000-0003-3979-017X; Raman, Ramakrishnan/0000-0003-3642-6989; Dwivedi, Rohita/0000-0003-3801-3635; Janssen, Marijn/0000-0001-6211-8790; Mariani, Marcello/0000-0002-7916-2576; Wirtz, Jochen/0000-0002-6297-4498; Venkatesh, Viswanath/0000-0001-8473-376X; Kar, Arpan Kumar/0000-0003-4186-4887; Dwivedi, Yogesh Kumar/0000-0002-5547-9990; Al-Busaidi, Adil/0000-0002-0959-7419; Stahl, Bernd Carsten/0000-0002-4058-4456; Pandey, Neeraj/0000-0002-6238-6397; Cunningham, Scott/0000-0001-7140-916X; Davison, Robert/0000-0002-7243-3521; O'Connor, Siobhan/0000-0001-8579-1718; Rehm, Sven-Volker/0000-0002-9785-6707				Abdulquadri A, 2021, J ENTERP COMMUNITIES, V15, P258, DOI 10.1108/JEC-06-2020-0126; Adams M., 2023, AI SEARCH UNLOCKS LO; Adams T., 2021, GUARDIAN; Adesso, 2022, PREPRINT; Agomuoh F., 2023, DIGITALTRENDS; Agrawal A., 2022, HARVARD BUS REV, P1; Ajzen I, 2011, PSYCHOL HEALTH, V26, P1113, DOI 10.1080/08870446.2011.613995; Akter S, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102387; Aldhafri S., 2015, THEORY PRACTICE LANG, V5, P1159; Aleksander I, 2017, J INF TECHNOL-UK, V32, P1, DOI 10.1057/s41265-016-0032-4; Algolia, 2023, IND YOUR WORLD PUT M; Algorithmwatch.org, 2020, AI ETH GUID GLOB INV; Alhelal H., 2021, ROME WASNT BUILT DAY; Alshater M., 2022, Exploring the role of artificial intelligence in enhancing academic performance: A case study of ChatGPT, DOI [DOI 10.2139/SSRN.4312358, https://doi.org/10.2139/ssrn.4312358]; Alvesson M, 2011, ACAD MANAGE REV, V36, P247, DOI 10.5465/AMR.2011.59330882; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, FINANC TIMES; [Anonymous], 2023, INT C MACH LEARN 202; [Anonymous], 2023, The New York Times; Araujo T, 2018, COMPUT HUM BEHAV, V85, P183, DOI 10.1016/j.chb.2018.03.051; Ashok M, 2022, INT J INFORM MANAGE, V62, DOI 10.1016/j.ijinfomgt.2021.102433; Attali Y., 2006, The Journal of Technology, Learning and Assessment, V4; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Azaria A., 2022, CHATGPT USAGELIMITAT; Baird A, 2021, MIS QUART, V45, P315, DOI 10.25300/MISQ/2021/15882; Balakrishnan J, 2022, TECHNOL FORECAST SOC, V180, DOI 10.1016/j.techfore.2022.121692; Balakrishnan J, 2021, PSYCHOL MARKET, V38, P643, DOI 10.1002/mar.21462; Bank of America, 2022, BANK AM ER TOPS 1 BI; Baskerville RL, 2009, MIS QUART, V33, P647; Bass, 2022, BLOOMBERG; Bates M, 2019, IEEE PULSE, V10, P12, DOI 10.1109/MPULS.2019.2911816; Baumol William, 2012, The Cost Disease: Why Computers Get Cheaper and Health Care doesn't; Belk R, 2021, SERV IND J, V41, P860, DOI 10.1080/02642069.2020.1727892; Bellegarda JR, 2004, SPEECH COMMUN, V42, P93, DOI 10.1016/j.specom.2003.08.002; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bernstein E., 2022, CO ARE USING TECH GI; Bhattacharyya S., 2023, COMMERCIAL APPL GPT; Birkinshaw J, 2013, HARVARD BUS REV, V91, P115; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bjork C., 2023, CHATGPT THREATENS LA; Blackman R., 2020, PRACTICAL GUIDE BUIL; Bock DE, 2020, J SERV MARK, V34, P317, DOI 10.1108/JSM-01-2019-0047; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Böhm S, 2022, J BUS ETHICS, V180, P835, DOI 10.1007/s10551-022-05239-2; Bommarito II M., 2022, ARXIV; Bonfim D, 2021, REV FINANC, V25, P1211, DOI 10.1093/rof/rfaa036; Bornet P., 2021, Intelligent Automation: Welcome to the World of Hyperautomation: Learn How to Harness Artificial Intelligence to Boost Business Make Our World More Human; Bossman J., 2016, TOP 9 ISSUES ARTIFIC; Bouschery S., 2023, AUGMENTING HUMAN INN, DOI [10.1111/jpim.12656, DOI 10.1111/JPIM.12656]; Brachten F, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102375; Breen P., 2023, DONT FEAR CHATGPT ED; Breidbach CF, 2020, J SERV MANAGE, V31, P163, DOI 10.1108/JOSM-03-2019-0073; Brown NCC, 2014, ACM T COMPUT EDUC, V14, DOI 10.1145/2602484; Buhalis D, 2022, J HOSP TOUR TECHNOL, V13, P386, DOI 10.1108/JHTT-03-2021-0104; Buhalis D, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102253; Buhalis D, 2020, J DESTIN MARK MANAGE, V15, DOI 10.1016/j.jdmm.2020.100409; Buhalis D, 2020, TOUR REV, V75, P267, DOI 10.1108/TR-06-2019-0258; Buhalis D, 2019, J SERV MANAGE, V30, P484, DOI 10.1108/JOSM-12-2018-0398; Buhalis D, 2019, J TRAVEL TOUR MARK, V36, P563, DOI 10.1080/10548408.2019.1592059; Bundy A., 2019, EXPLAINABLE AI; Burger B, 2024, J ENTERP COMMUNITIES, V18, P221, DOI 10.1108/JEC-10-2022-0157; Burstein J, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P113; Cadmus, 2023, ID MIT RISKS AI AUTH; Cain S., 2023, GUARDIAN 0117; Carr NG, 2003, HARVARD BUS REV, V81, P41; Carroll J., 2007, A handbook for deterring plagiarism in higher education; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Centre for Teaching and Learning, 2023, 4 LESS CHATGPT CHALL; Chakravarti, 2023, INDIA TODAY; Chandra S, 2022, J MANAGE INFORM SYST, V39, P969, DOI 10.1080/07421222.2022.2127441; ChatGPT, 2023, Wikipedia; Chen W., 2004, IT & Society, V1, P39; CHEN Y, 2022, ARTIFICIAL INTELLIGE, DOI DOI 10.1007/S10796-022-10291-4; Chui M., 2022, Generative AI is here: how tools like ChatGPT could change your business; Chui M., GENERATIVE AI IS HER; Chui M, 2022, The state of AI in 2022-and a half decade in review; Chui M., 2016, McKinsey Quarterly; Coch L, 1948, HUM RELAT, V1, P512, DOI 10.1177/001872674800100408; Cockburn I.M., 2019, The Economics of Artificial Intelligence: An Agenda, P115; Coombs C, 2021, INT J INFORM MANAGE, V58, DOI 10.1016/j.ijinfomgt.2021.102311; COOPER RB, 1990, MANAGE SCI, V36, P123, DOI 10.1287/mnsc.36.2.123; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Council of Europe, 2022, ARTIF INTELL; Cranefield J, 2023, J ROY SOC NEW ZEAL, V53, P95, DOI 10.1080/03036758.2022.2114507; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Crick Tom, 2021, ITNOW, V63, P1, DOI DOI 10.1093/ITNOW/BWAB005; Czarnecka B, 2020, INT J BANK MARK, V38, P756, DOI 10.1108/IJBM-07-2019-0249; Datta SD, 2023, INT J CONSTR MANAG, V23, P2260, DOI 10.1080/15623599.2022.2050977; Davenport TH, 2018, HARVARD BUS REV, V96, P108; De Cremer D., 2021, SHOULD AUGMENT HUMAN; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Diederich S, 2022, J ASSOC INF SYST, V23, P96, DOI 10.17705/1jais.00724; Diener F, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042032; Dowling M., 2023, IN PRESS; Drucker PF, 1999, CALIF MANAGE REV, V41, P79, DOI 10.2307/41165987; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; Duan YQ, 2012, EXPERT SYST APPL, V39, P5534, DOI 10.1016/j.eswa.2011.11.065; Dwivedi YK, 2023, PSYCHOL MARKET, V40, P750, DOI 10.1002/mar.21767; Dwivedi YK, 2022, INT J INFORM MANAGE, V66, DOI 10.1016/j.ijinfomgt.2022.102542; Dwivedi YK, 2022, INT J INFORM MANAGE, V63, DOI 10.1016/j.ijinfomgt.2021.102456; Dwivedi YK, 2022, INT J INFORM MANAGE, V62, DOI 10.1016/j.ijinfomgt.2021.102426; Dwivedi YK, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102211; Dwivedi YK, 2021, INT J INFORM MANAGE, V59, DOI 10.1016/j.ijinfomgt.2020.102168; Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002; Dwivedi YK, 2015, INFORM SYST FRONT, V17, P143, DOI 10.1007/s10796-014-9500-y; EISENHARDT KM, 1989, ACAD MANAGE REV, V14, P57, DOI 10.2307/258191; Eliot L., 2023, GENERATIVE AI CHATGP; Ellington AJ, 2003, J RES MATH EDUC, V34, P433, DOI 10.2307/30034795; Elliot B., 2022, WHY IS CHATGPT MAKIN; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Elsevier, 2023, USE AI AI ASSISTED T; Trinidad JE, 2020, J FURTH HIGHER EDUC, V44, P1013, DOI 10.1080/0309877X.2019.1636214; EU High-Level Expert Group on AI, 2019, ETH GUID TRUST AI; Ferlazzo L., 2023, 19 WAYS USE CHATGPT; Firat M., 2023, How chat GPT can transform autodidactic experiences and open education?, DOI [10.31219/osf.io/9ge8m, DOI 10.31219/OSF.IO/9GE8M]; Fire M, 2019, GIGASCIENCE, V8, DOI 10.1093/gigascience/giz053; Floridi L., 2018, AI4PEOPLES ETHICAL; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Floridi L, 2019, NAT MACH INTELL, V1, P261, DOI 10.1038/s42256-019-0055-y; Floridi L, 2020, MIND MACH, V30, P77, DOI 10.1007/s11023-020-09521-y; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gartner, 2022, HYP CYCL ART INT AI; gartner.com, 2019, Top trends on the Gartner hype cycle for artificial intelligence; Getahun H., 2023, THE INSIDER; Ghazwani S, 2022, INT J BANK MARK, V40, P1200, DOI 10.1108/IJBM-09-2021-0444; Gill G, 2009, MIS QUART, V33, P217; Gleason B., 2019, BUILDING MULTICHANNE; Goertzel B., 2007, Artificial General Intelligence; Goldstein I., 1977, COGNITIVE SCI, V1, P84, DOI [DOI 10.1016/S0364-0213(77)80006-2, 10.1016/S0364-0213(77)80006-2, DOI 10.1207/S15516709COG0101_5]; Google, 2023, GOOGL ASS; Grady P., 2023, CHATGPT AMENDMENT SH; GREENWOOD R, 1993, ACAD MANAGE J, V36, P1052, DOI 10.5465/256645; Greenwood R, 1996, ACAD MANAGE REV, V21, P1022, DOI 10.2307/259163; Greenwood R, 2002, ACAD MANAGE J, V45, P58, DOI 10.5465/3069285; GUAN CY, 2019, PR MACH LEARN RES, V97, pNI592; Guo B., 2023, ARXIV; Gupta S., 2022, Journal of Information Systems Education, V33, P98; Hamilton I. A., 2022, THE INSIDER; Haque M.U., 2022, ARXIV; Heikkila M., 2023, MITOSZ TECHNOLOGY RE; Hendrik E., 2022, I GET YOUR EXCITEMEN; Henrickson L, 2023, MEDIA CULT SOC, V45, P949, DOI 10.1177/01634437221147626; Heyoung Kim, 2019, [The Journal of Learner-Centered Curriculum and Instruction, 학습자중심교과교육연구], V19, P89, DOI 10.22251/jlcci.2019.19.1.89; Hiatt J.M., 2006, ADKAR: A Model for Change in Business, Government, and Our Community; Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026; Hirschheim R., 1996, ACCOUNTING MANAGEMEN, V6, P1; Hoffman AJ, 1999, ACAD MANAGE J, V42, P351, DOI 10.5465/257008; Hu K., 2023, Reuters; Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459; Huang R., 2019, ED TECHNOLOGY PRIMER, DOI [DOI 10.1007/978-981-13-6643-7, 10.1007/978-981-13-6643-7]; Hughes A., 2023, CHATGPT EVERYTHING Y; IBM, 2023, WATS ASS CAS STUD; Introna LD, 2011, INFORM ORGAN-UK, V21, P107, DOI 10.1016/j.infoandorg.2011.03.001; Irons A., 2022, HIGHER ED POSTCOVID; Janssen M, 2015, GOV INFORM Q, V32, P363, DOI 10.1016/j.giq.2015.11.007; Jena LK, 2022, EUR REV APPL PSYCHOL, V72, DOI 10.1016/j.erap.2021.100729; Jensen ML, 2017, J MANAGE INFORM SYST, V34, P597, DOI 10.1080/07421222.2017.1334499; JISC, 2023, DOES CHATGPT MEAN EN; Kabudi T., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100017; Kahneman D., 2011, THINKING FAST SLOW; Kar AK, 2016, EXPERT SYST APPL, V59, P20, DOI 10.1016/j.eswa.2016.04.018; Kelly C., 2023, CHATGPT MIGHT CHANGE; Kendrick C., 2023, SCHOLARLY KITCHEN; Kietzmann J, 2018, J ADVERTISING RES, V58, P263, DOI 10.2501/JAR-2018-035; Kim A, 2019, MIS QUART, V43, P1025, DOI 10.25300/MISQ/2019/15188; Kim S, 2021, HUM RESOUR MANAGE-US, V60, P229, DOI 10.1002/hrm.22049; King AA, 2015, MIT SLOAN MANAGE REV, V57, P77; Kissinger H., 2021, The age of AI: And our human future, VFirst; Klepper D., 2023, IT TURNS OUT CHATGPT; Kotter J. P., 2007, MUSEUM MANAGEMENT MA, P20, DOI [10.4324/9780203964194-1, DOI 10.4324/9780203964194-1]; Kreps D., 2021, ICIS 2021 P, P5; Krugel S., 2023, ARXIV; Kshetri N., 2023, IN PRESS, V25; KSHETRI N, 2023, IEEE COMPUT, V56, P64; Kshetri N, 2008, J INT MANAG, V14, P300, DOI 10.1016/j.intman.2008.01.005; Kshetri N, 2018, J INT MANAG, V24, P33, DOI 10.1016/j.intman.2017.07.001; Kshetri N, 2009, J INT MANAG, V15, P225, DOI 10.1016/j.intman.2008.09.003; Kulesh S., 2022, TIMES INDIA; Kundalia N.D., 2023, HINDUSTAN TIMES 0130; Kung T.H., 2022, BIORXIV; Kushwaha AK, 2024, INFORM SYST FRONT, V26, P857, DOI 10.1007/s10796-021-10184-y; Laffont J.J., 2002, The theory of incentives: The principal-agent model; Larsen K. R., 2020, Proceedings 15, V15, P272; Laumer S, 2016, EUR J INFORM SYST, V25, P317, DOI 10.1057/ejis.2016.1; Li J., 2020, MIS Quarterly, V44; Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749; Licklider J.C.R., 1960, IRE transactions on human factors in electronics, P4, DOI [10.1109/THFE2.1960.4503259, DOI 10.1109/THFE2.1960.4503259]; Lin JS, 2023, COMPUT HUM BEHAV, V140, DOI 10.1016/j.chb.2022.107488; Liu S, 2020, LANCET PSYCHIAT, V7, pE17, DOI 10.1016/S2215-0366(20)30077-8; Lokman AS, 2019, ADV INTELL SYST COMP, V881, P1012, DOI 10.1007/978-3-030-02683-7_75; Lucey B., 2023, CONVERSATION; Luckin R., 2016, Intelligence unleashed. An argument for AI in education; Ma LY, 2020, INT J RES MARK, V37, P481, DOI 10.1016/j.ijresmar.2020.04.005; Maguire S, 2004, ACAD MANAGE J, V47, P657, DOI [10.2307/20159610, 10.5465/20159610]; Mao Y, 2017, EDUC STUD MATH, V94, P69, DOI 10.1007/s10649-016-9714-7; Mariani MM, 2023, J BUS RES, V155, DOI 10.1016/j.jbusres.2022.113364; Mariani MM, 2023, TECHNOVATION, V122, DOI 10.1016/j.technovation.2022.102623; Martin K, 2019, J BUS ETHICS, V160, P835, DOI 10.1007/s10551-018-3921-3; McCarthy J., 2007, WHAT IS ARTIFICIAL INTELLIGENCE?; McGrath JE., 1984, GROUPS INTERACTION P; McKinsey & Company, 2023, WHAT IS GEN AI; Melis G., 2017, On the state of the art of evaluation in neural language models; Merhi MI, 2023, INT J INFORM MANAGE, V69, DOI 10.1016/j.ijinfomgt.2022.102545; Metcalfe M., 2004, J INFORM TECHNOLOGY, V6, P13; Metz A., 2022, TechRadar; Mishra M., 2023, EC TIMES 0131; Mitchell A., 2023, NEW YORK POST; Mithas S., 2017, IT Professional, V19, P3, DOI [DOI 10.1109/MITP.2017.3051329, 10.1109/MITP.2017.3051329]; Mithas S., 2016, DIGITAL INTELLIGENCE; Mithas S, 2022, PROD OPER MANAG, V31, P4475, DOI 10.1111/poms.13864; Mithas S, 2020, IT PROF, V22, P4, DOI 10.1109/MITP.2019.2957620; Mogaji E, 2022, INT J BANK MARK, V40, P1097, DOI 10.1108/IJBM-09-2022-617; Mogaji E, 2022, INT J BANK MARK, V40, P1272, DOI 10.1108/IJBM-09-2021-0440; Mogaji E, 2021, TELEMAT INFORM, V65, DOI 10.1016/j.tele.2021.101711; Mogaji E, 2020, ADV THE PRAC EMER MA, P137, DOI 10.1007/978-3-030-24374-6_10; Mogaji E, 2021, AUSTRALAS MARK J, V29, P235, DOI 10.1016/j.ausmj.2020.05.003; Mollick E., 2022, Harvard Business Review; Mollick E.R., 2022, NEW MODES LEARNING E, DOI [10.2139/ssrn.4300783Pflugner, DOI 10.2139/SSRN.4300783PFLUGNER]; Montti R., 2022, SEARCH ENGINE J; Moor JamesH., 2008, INFORMATION TECHNOLOGY AND MORAL PHILOSOPHY, P26, DOI DOI 10.1017/CBO9780511498725.003; National Institute of Standards and Technology, 2023, NIST AI RISK MAN FRA; Nature, 2023, NATURE; Newman KL, 2000, ACAD MANAGE REV, V25, P602, DOI 10.2307/259313; Ng J, 2022, ALTERN LAW J, V47, P308, DOI 10.1177/1037969X221113598; Nguyen N.P., 2022, MARKET COMMUN, VII, P83; NORTH DC, 1991, J ECON PERSPECT, V5, P97, DOI 10.1257/jep.5.1.97; Northey G, 2022, INT J BANK MARK, V40, P1182, DOI 10.1108/IJBM-09-2021-0439; O'Connor A, 2021, LANCET CHILD ADOLESC, V5, P779, DOI 10.1016/S2352-4642(21)00314-X; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; O'Flaherty J, 2015, INTERNET HIGH EDUC, V25, P85, DOI 10.1016/j.iheduc.2015.02.002; OConnor S.J. N.E. i P., 2022, TOOLS ACAD PROGR ABU, V66; Ofcom, 2022, INST TIKTOK YOUTUBE; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Omoge AP, 2022, INT J BANK MARK, V40, P1217, DOI 10.1108/IJBM-09-2021-0403; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; OpenAI, 2023, US POL; OpenAI, 2023, DALL E2; OpenAI, 2022, New and improved content moderation tooling; Oppy G., 2021, The Stanford Encyclopedia of Philosophy; Oreg S, 2003, J APPL PSYCHOL, V88, P680, DOI 10.1037/0021-9010.88.4.680; Ortiz S., 2023, ZDNET; Pagani M., IN PRESS; Pappas IO, 2021, FRONT EDUC, V6, DOI 10.3389/feduc.2021.652856; Pariser E., 2011, The filter bubble: What the Internet is hiding from you; Pazzanese C., 2020, The Harvard GazetteOct. 26; Pearl, 2022, CHATGPT CHATBOT OPEN; Peng J., 2022, EDUC RES REV-NETH; Pereira T, 2022, J QUAL ASSUR HOSP TO, DOI 10.1080/1528008X.2022.2136817; Perrigo B, 2023, Time; Pflügner K, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106566; Pinker S., 2022, POSSIBLE MINDS 25 WA; Pizzi G, 2021, J BUS RES, V129, P878, DOI 10.1016/j.jbusres.2020.11.006; Popper K., 1957, 'Philosophy of Science: a Personal Report' in British Philosophy in Mid-Century; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Radford A., 2018, IMPROVING LANGUAGE U; Rafalin D., DESIGNING ASSESSMENT; Rai A, 2019, MIS QUART, V43, pIII; Rasmusen E., 2014, PERFECT CERTAIN SYMM; Reed L., 2022, CHATGPT AUTOMATED TE; Reese H., 2016, TECHREPUBLIC; Reich R., 1992, WORK NATIONS; Riedel A, 2022, INT J BANK MARK, V40, P1102, DOI 10.1108/IJBM-09-2021-0438; Rogers E.M., 2010, DIFFUSION INNOVATION; Rosenblatt K., 2023, ChatGPT passes MBA exam given by a Wharton professor; Rosenzweig-Ziff D., 2023, WASH POST; Rowe F, 2018, EUR J INFORM SYST, V27, P380, DOI 10.1080/0960085X.2018.1471789; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Ryle G., 1945, Proceedings of the Aristotelian Society, V46, P1, DOI DOI 10.1093/ARISTOTELIAN/46.1.1; Saleh T., 2021, HARVARD BUS REV; Sarker S, 2019, MIS QUART, V43, P695, DOI 10.25300/MISQ/2019/13747; Schucany W. R., 1972, Computing Surveys, V4, P65, DOI 10.1145/356599.356600; Schuetz S, 2020, J ASSOC INF SYST, V21, P460, DOI 10.17705/1jais.00608; Schuetzler RM, 2020, J MANAGE INFORM SYST, V37, P875, DOI 10.1080/07421222.2020.1790204; Science, 2023, CHATGPT IS FUN NOT A, DOI [10.1126/science.adg7879, DOI 10.1126/SCIENCE.ADG7879]; Scott R., 2001, I ORG, V2nd; Scott W. R., 2000, Institutional change and healthcare organizations: From professional dominance to managed care; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Seeger AM, 2021, J ASSOC INF SYST, V22, P931, DOI 10.17705/1jais.00685; Selwyn N, 2022, EUR J EDUC, V57, P620, DOI 10.1111/ejed.12532; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816; Sheth JN, 2022, INT J BANK MARK, V40, P1248, DOI 10.1108/IJBM-09-2021-0449; Shneiderman B., 2020, AIS Transactions on Human-Computer Interaction, V12, P109, DOI DOI 10.17705/1THCI.00131; Shrivastava R., 2022, Forbes; Shujahat M, 2019, J BUS RES, V94, P442, DOI 10.1016/j.jbusres.2017.11.001; Sieloff C. G., 1999, Journal of Knowledge Management, V3, P47, DOI 10.1108/13673279910259385; Simon H. A., 1960, MANAGEMENT CORPORATI, P17; Singh V., 2022, International Journal of Information Management Data Insights, V2, DOI DOI 10.1016/J.JJIMEI.2022.100094; Singh V, 2023, IETE J RES, V69, P8226, DOI 10.1080/03772063.2022.2069165; Soetan TO, 2021, J SERV MARK, V35, P947, DOI 10.1108/JSM-07-2020-0280; Sollie P, 2009, INT LIBR ETH LAW TEC, V3, P141, DOI 10.1007/978-90-481-2229-5_10; Stahl B.C., 2021, ARTIFICIAL INTELLIGE; Stahl BC, 2017, SCI PUBL POLICY, V44, P369, DOI 10.1093/scipol/scw069; Stein Natalie, 2017, JMIR Diabetes, V2, pe28, DOI 10.2196/diabetes.8590; Stevenson C., 2022, ARXIV; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; STRANG D, 1993, THEOR SOC, V22, P487, DOI 10.1007/BF00993595; Stylos N, 2021, INT J CONTEMP HOSP M, V33, P1015, DOI 10.1108/IJCHM-07-2020-0644; Sun TQ, 2019, GOV INFORM Q, V36, P368, DOI 10.1016/j.giq.2018.09.008; Susnjak T., 2022, ARXIV; Svrluga S., 2023, WASH POST; Tang CSS, 2022, PROD OPER MANAG, V31, P32, DOI 10.1111/poms.13349; taylorwessing.com, About us; Te'eni D, 2015, EUR J INFORM SYST, V24, P559, DOI 10.1057/ejis.2015.20; Tellis GJ, 2006, J PROD INNOVAT MANAG, V23, P34, DOI 10.1111/j.1540-5885.2005.00179.x; Terblanche N., 2020, Philosophy Coach. Int. J., V5, P61, DOI DOI 10.22316/POC/05.1.06; Terwiesch C., 2023, CISC VIS NETW IND GL; Theconversation, 2023, THECONVERSATION; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Thunstrom AO., 2022, Can GPT-3 write an academic paper on itself, with minimal human input?; Tight M, 2019, HIGH EDUC POLICY, V32, P93, DOI 10.1057/s41307-017-0075-3; Tiku M., 2023, WASHINGTON POST 0203; Tung, 2023, ZDNET; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Turing Test, 2023, Wikipedia; Turnitin, 2023, SNEAK PREV TURN AI W; Uc-Cetina V, 2023, ARTIF INTELL REV, V56, P1543, DOI 10.1007/s10462-022-10205-5; UK Government, 2021, NATL STRATEGY; UK Government Digital Service, 2019, UK GOV DIG SERV STAN; UNESCO, 2021, AI and Education: Guidance for Policy-Makers; van Esterik-Plasmeijer PWJ, 2017, INT J BANK MARK, V35, P97, DOI 10.1108/IJBM-12-2015-0195; Van Noorden R, 2022, NATURE, V605, P21, DOI 10.1038/d41586-022-01191-3; Vargo Stephen L., 2008, European Management Journal, V26, P145, DOI 10.1016/j.emj.2008.04.003; Vassilakopoulou P, 2023, EUR J INFORM SYST, V32, P10, DOI 10.1080/0960085X.2022.2096490; Vaswani A, 2017, ADV NEUR IN, V30; Venkatesh V, 2013, INFORM SYST RES, V24, P239, DOI 10.1287/isre.1110.0409; Vincent, 2023, VERGE 0106; Vincent J., 2022, VERGE 1202; Vives X, 2019, INT J IND ORGAN, V64, P55, DOI 10.1016/j.ijindorg.2018.08.011; Wacker JG, 1998, J OPER MANAG, V16, P361, DOI 10.1016/S0272-6963(98)00019-9; Walsh T., 2023, BARD BING BAIDU BIG; Walzer M., 2017, SOFT WAR ETHICS UNAR, DOI [10.1017/9781316450802, DOI 10.1017/9781316450802]; Wang, 2018, INT C LEARNING REPRE; Watermeyer R, 2022, INT J ACAD DEV, V27, P148, DOI 10.1080/1360144X.2021.1990064; Watson RT, 2020, J DECIS SYST, V29, P129, DOI 10.1080/12460125.2020.1798591; Webster J, 2002, MIS QUART, V26, pXIII; Weinberger D., 2019, Harvard Business Review; Weissglass DE, 2022, BIOETHICS, V36, P201, DOI 10.1111/bioe.12927; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Welsh, 2023, QUILLETTE; West, 2018, ROLE CORPORATIONS AD; WHETTEN DA, 1989, ACAD MANAGE REV, V14, P490, DOI 10.2307/258554; Whitford E., 2022, FORBES; Wilkins A., 2023, CHATGPT DETECTOR COU; Williamson B, 2020, LEARN MEDIA TECHNOL, V45, P223, DOI 10.1080/17439884.2020.1798995; Williamson B, 2020, LEARN MEDIA TECHNOL, V45, P107, DOI 10.1080/17439884.2020.1761641; Williamson B, 2020, TEACH HIGH EDUC, V25, P351, DOI 10.1080/13562517.2020.1748811; Wind J., 2023, AI EN NEW ED PAR SEM; Winikoff M., 2021, IEEE ANN HAW INT C S; Wirtz J, 2023, J SERV RES-US, V26, P173, DOI 10.1177/10946705221130467; Wirtz J, 2022, J SERV MARK, V36, P461, DOI 10.1108/JSM-07-2021-0242; Wirtz J, 2018, J SERV MANAGE, V29, P907, DOI 10.1108/JOSM-04-2018-0119; Wirtz J, 2018, J ACAD MARKET SCI, V46, P59, DOI 10.1007/s11747-017-0560-7; Wlasak W, 2023, JMIR FORM RES, V7, DOI 10.2196/38500; Woolf B. P., 1992, ENCY ARTIFICIAL INTE; Woolf B.P., 2015, AIED WORKSHOP P, V4, P38; Yang S., 2022, ABILITIES LIMITATION; Zhai X, 2023, COMPLEX INTELL SYST, V9, P2865, DOI 10.1007/s40747-021-00617-1; Zhai XS, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8812542; Zhang LX, 2021, J SERV MARK, V35, P628, DOI 10.1108/JSM-05-2020-0162; Zhang ZW, 2020, MIS Q EXEC, V19, P221, DOI 10.17705/2msqe.00035; Zhu YH, 2022, INT J HUM-COMPUT INT, V38, P1182, DOI 10.1080/10447318.2021.1988236	363	584	591	1415	3255	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0268-4012	1873-4707		INT J INFORM MANAGE	Int. J. Inf. Manage.	AUG	2023	71								102642	10.1016/j.ijinfomgt.2023.102642	http://dx.doi.org/10.1016/j.ijinfomgt.2023.102642		MAR 2023	63	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	A3SX6		Green Accepted, Green Published, hybrid			2024-07-03	WOS:000954374300001
J	Yapar, D; Avci, YD; Sonuvar, ET; Egerci, ÖF; Yapar, A				Yapar, Dilek; Avci, Yasemin Demir; Sonuvar, Esra Tokur; Egerci, Omer Faruk; Yapar, Aliekber			ChatGPT's potential to support home care for patients in the early period after orthopedic interventions and enhance public health	JOINT DISEASES AND RELATED SURGERY			English	Article						ChatGPT; expert evaluation; large language models; medical consultation; orthopedic interventions; rubric	ARTIFICIAL-INTELLIGENCE	Objectives: This study presents the first investigation into the potential of ChatGPT to provide medical consultation for patients undergoing orthopedic interventions, with the primary objective of evaluating ChatGPT's effectiveness in supporting patient self-management during the essential early recovery phase at home.Materials and methods: Seven scenarios, representative of common situations in orthopedics and traumatology, were presented to ChatGPT version 4.0 to obtain advice. These scenarios and ChatGPT's responses were then evaluated by 68 expert orthopedists (67 males, 1 female; mean age: 37.9 +/- 5.9 years; range, 30 to 59 years), 40 of whom had at least four years of orthopedic experience, while 28 were associate or full professors. Expert orthopedists used a rubric on a scale of 1 to 5 to evaluate ChatGPT's advice based on accuracy, applicability, comprehensiveness, and clarity. Those who gave ChatGPT a score of 4 or higher considered its performance as above average or excellent.Results: In all scenarios, the median evaluation scores were at least 4 across accuracy, applicability, comprehensiveness, and communication. As for mean scores, accuracy was the highest-rated dimension at 4.2 +/- 0.8, while mean comprehensiveness was slightly lower at 3.9 +/- 0.8. Orthopedist characteristics, such as academic title and prior use of ChatGPT, did not influence their evaluation (all p>0.05). Across all scenarios, ChatGPT demonstrated an accuracy of 79.8%, with applicability at 75.2%, comprehensiveness at 70.6%, and a 75.6% rating for communication clarity.Conclusion: This study emphasizes ChatGPT's strengths in accuracy and applicability for home care after orthopedic intervention but underscores a need for improved comprehensiveness. This focused evaluation not only sheds light on ChatGPT's potential in specialized medical advice but also suggests its potential to play a broader role in the advancement of public health.	[Yapar, Dilek] Turkish Minist Hlth, Dept Publ Hlth, Muratpaşa Dist Hlth Directorate, Antalya, Turkiye; [Yapar, Dilek; Avci, Yasemin Demir; Sonuvar, Esra Tokur] Akdeniz Univ, Inst Hlth Sci, Med Informat, Antalya, Turkiye; [Avci, Yasemin Demir] Akdeniz Univ, Dept Publ Hlth Nursing, Fac Nursing, Antalya, Turkiye; [Egerci, Omer Faruk; Yapar, Aliekber] Antalya Training & Res Hosp, Dept Orthoped & Traumatol, Antalya, Turkiye; [Yapar, Aliekber] Antalya Egitim Arastirma Hastanesi Ortopedi & Trav, TR-07100 Antalya, Turkiye	Ministry of Health - Turkey; Akdeniz University; Akdeniz University; Antalya Training & Research Hospital	Yapar, A (corresponding author), Antalya Egitim Arastirma Hastanesi Ortopedi & Trav, TR-07100 Antalya, Turkiye.	aliekberyapar@hotmail.com		Yapar, Dilek/0000-0001-7656-1152; Yapar, Aliekber/0000-0003-2227-2173; Egerci, Omer faruk/0000-0002-0135-2599; TOKUR SONUVAR, ESRA/0000-0002-1279-5192				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Amara A, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100130; Ariyaratne S, 2023, SCOT MED J, V68, P129, DOI 10.1177/00369330231174231; Arslan S, 2023, ANN BIOMED ENG, V51, P1887, DOI 10.1007/s10439-023-03227-9; Ashraf H, 2024, ANN BIOMED ENG, V52, P458, DOI 10.1007/s10439-023-03311-0; Atik OS, 2023, JOINT DIS RELAT SURG, V34, DOI 10.52312/jdrs.2023.57916; Atik OS, 2022, JOINT DIS RELAT SURG, V33, P484, DOI 10.52312/jdrs.2022.57906; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ayre C, 2014, MEAS EVAL COUNS DEV, V47, P79, DOI 10.1177/0748175613513808; Baumgartner C, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1206; Berger U, 2023, PSYCHOTHER PSYCH MED, V73, P159, DOI 10.1055/a-2017-8471; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chen Xuewei, 2017, JMIR Diabetes, V2, pe13, DOI 10.2196/diabetes.7446; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Fröhling L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.443; Hernigou P, 2023, INT ORTHOP, V47, P1887, DOI 10.1007/s00264-023-05887-7; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Khanna RR, 2011, J HOSP MED, V6, P519, DOI 10.1002/jhm.898; Moskal B. M., 2000, PRACTICAL ASSESSMENT, V7, DOI DOI 10.7275/Q7RM-GG74; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; OpenAi, ChatGPT; OpenAI, 2023, OPENI CHATGPT GUIDE; Punnoose A, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.8050; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Sharma P, 2023, CLIN NUCL MED, V48, P838, DOI 10.1097/RLU.0000000000004665; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Stoicea N, 2018, FRONT MED-LAUSANNE, V5, DOI 10.3389/fmed.2018.00342; Yurdugul H., 2005, XIV. Ulusal Egitim Bilimleri Kongresi, V1, P771; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589	34	1	1	8	17	TURKISH JOINT DISEASES FOUNDATION	CANKAYA	MUSTAFA KEMAL MAHALLESI, DUMLUPINAR BULVARI 274-2 C2 BLOK OFIS, 5, CANKAYA, ANKARA, Turkiye		2687-4792		JOINT DIS RELAT SURG	Joint Dis. Relat. Surg.		2024	35	1					169	176		10.52312/jdrs.2023.1402	http://dx.doi.org/10.52312/jdrs.2023.1402		NOV 2023	8	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	CH7W0	38108178	gold, Green Published			2024-07-03	WOS:001114336000001
J	Manca, V				Manca, Vincenzo			Agile Logical Semantics for Natural Languages	INFORMATION			English	Article						logical semantics; predicate logic; natural language processing; large language models		This paper presents an agile method of logical semantics based on high-order Predicate Logic. An operator of predicate abstraction is introduced that provides a simple mechanism for logical aggregation of predicates and for logical typing. Monadic high-order logic is the natural environment in which predicate abstraction expresses the semantics of typical linguistic structures. Many examples of logical representations of natural language sentences are provided. Future extensions and possible applications in the interaction with chatbots are briefly discussed as well.	[Manca, Vincenzo] Univ Verona, Dipartimento Informat, I-37134 Verona, Italy	University of Verona	Manca, V (corresponding author), Univ Verona, Dipartimento Informat, I-37134 Verona, Italy.	vincenzo.manca@univr.it		Manca, Vincenzo/0000-0002-1304-0277				Barwise J., 1989, The situation in logic; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Church A., 1956, Introduction to Mathematical Logic; Dowty D.R., 1989, Introduction to Montague Semantics; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Harmelen F, 2008, FOUND ARTIF INTELL, pVII; Hilbert D., 1991, Princioles of Mathematical Logic; Kalish Donald., 1964, Logic: Techniques of Formal Reasoning; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kerr AD, 2021, SYNTHESE, V198, P3047, DOI 10.1007/s11229-019-02265-y; Manca V., 1998, Mathematical and Computational Analysis of Natural Language; MITCHELL T., 1997, MACHINE LEARNING; NIELSEN M., 2019, NEURAL NETWORKS DEEP; Pan LM, 2023, Arxiv, DOI arXiv:2305.12295; Parkinson G.H. R., 1966, Leibniz: Logical Papers; Reichenbach H., 1947, Symbolic logic; Tarski A., 1988, A Formalization of Set Theory without Variables, V41; Thomason R., 1974, FORMAL PHILOS; van Benthem J., 1988, Intensional Logic; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Whitehead A. N., 1910, Principia Mathematica; Yang Z., 2023, P ACL 2023, P5186	22	1	1	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	JAN	2024	15	1							64	10.3390/info15010064	http://dx.doi.org/10.3390/info15010064			16	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	GG3M9		gold			2024-07-03	WOS:001151474500001
C	Chien, AA; Lin, LZX; Nguyen, H; Rao, V; Sharma, T; Wijayawardana, R			ACM	Chien, Andrew A.; Lin, Liuzixuan; Hai Nguyen; Rao, Varsha; Sharma, Tristan; Wijayawardana, Rajini			Reducing the Carbon Impact of Generative AI Inference (today and in 2035)	PROCEEDINGS OF THE 2ND ACM WORKSHOP ON SUSTAINABLE COMPUTER SYSTEMS, HOTCARBON 2023			English	Proceedings Paper	2nd ACM Workshop on Sustainable Computer Systems (ACM HotCarbon)	JUL09, 2023	Boston Univ, Boston, MA	Assoc Comp Machinery	Boston Univ	Generative AI; Sustainability; Carbon emissions; Large language models; Geographic shifting		Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts. Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71%.	[Chien, Andrew A.; Lin, Liuzixuan; Hai Nguyen; Rao, Varsha; Sharma, Tristan; Wijayawardana, Rajini] Univ Chicago, Chicago, IL 60637 USA; [Chien, Andrew A.] Argonne Natl Lab, Chicago, IL 60439 USA	University of Chicago; United States Department of Energy (DOE); Argonne National Laboratory	Chien, AA (corresponding author), Univ Chicago, Chicago, IL 60637 USA.; Chien, AA (corresponding author), Argonne Natl Lab, Chicago, IL 60439 USA.	achien@cs.uchicago.edu; lzixuan@uchicago.edu; ndhai@cs.uchicago.edu; varsharao@uchicago.edu; tristansharma@uchicago.edu; rajini@uchicago.edu			NSF [CMMI-1832230, OAC-2019506, CNS-1901466]; VMware University Research Fund	NSF(National Science Foundation (NSF)); VMware University Research Fund	We thank the anonymous reviewers for their insightful reviews. This work is supported in part by NSF Grants CMMI-1832230, OAC-2019506, CNS-1901466, and the VMware University Research Fund. We also thank Pierre Segonne from Electricity Maps for providing power grid data, and the Large-scale Sustainable Systems Group members for their support of this work!	Acun B, 2022, Arxiv, DOI arXiv:2201.10036; Alibaba, 2023, Tongyi Qianwen; [Anonymous], 2023, Choose the right azure region for you: Microsoft Azure; [Anonymous], 2022, REUTERS; [Anonymous], 2023, Efficiency-Datacenters-Google; [Anonymous], 2023, ABOUT US; [Anonymous], 2023, AMD EPYC 7642 Specifications; [Anonymous], 2023, Azure network round-trip latency statistics; [Anonymous], 2021, Nvidia A100 datasheet; [Anonymous], 2021, Right Place, Right Time (RiPiT) Carbon Emissions Service; Baidu, 2023, Wenxin Yiyan; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chien AA, 2018, AIMS ENERGY, V6, P376, DOI 10.3934/energy.2018.2.376; Chien Andrew A, 2022, USENIX HOT CARBON WO; Chien Andrew A., 2023, Communications of the Association for Computing Machinery; Chien AndrewA, 2018, Technical Report. TR- 2018-07; Cortez E, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P153, DOI 10.1145/3132747.3132772; Dietrich Mark, 2020, How to Extend the Productive Lifetime of Scientific Computing Equipment; Dodge Jesse, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1877, DOI 10.1145/3531146.3533234; Driscoll William, 2022, pv magazine usa; Duarte Fabio, 2023, Number of chatgpt users; Electricity Maps, 2023, Electricity Maps; Google, 2023, The next generation of AI for developers and Google Workspace; Gupta U, 2022, CONF PROC INT SYMP C, P784, DOI 10.1145/3470496.3527408; Gupta V, 2018, INT CONF COMMUN SYST, P372, DOI 10.1109/COMSNETS.2018.8328221; Nguyen HD, 2019, PROCEEDINGS OF THE 2019 FIFTH INTERNATIONAL WORKSHOP ON SERVERLESS COMPUTING (WOSC '19), P1, DOI 10.1145/3366623.3368133; Hiruta Yuki, 2019, Assessing climate sensitivity of hourly electricity demand in Japan; International Energy Agency, 2023, About us; Jordan Damien, 2018, Response time standards; Kien Le, 2010, 2010 International Conference on Green Computing (Green Comp), P3, DOI 10.1109/GREENCOMP.2010.5598305; Koomey Jonathan, 2016, Electronic Design; Li C., 2020, OpenAI's GPT-3 language model: A technical overview; Lin Liuzixuan, 2020, University of Chicago CS Tech Report; Liu ZH, 2015, IEEE ACM T NETWORK, V23, P657, DOI 10.1109/TNET.2014.2308295; Luccioni S, 2023, The mounting human and environmental costs of AI Internet; microservices, 2023, US; Microsoft Azure, 2023, ND A100 v4-series; Mims Christopher, 2020, Huang's Law Is the New Moore's Law, and Explains Why Nvidia Wants Arm; Ministry of New and Renewable Energy, 2022, RENEWABLE ENERGY IND; MISO, 2021, MISO Futures Report538224.pdf; Nguyen Hai, 2023, 2023 IEEE 16 INT C C; OpenAI, 2022, US; OpenAI, 2022, DALL E 2; Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714; Roth Emma, 2023, Mark Zuckerberg says Meta now has a team building AI tools and 'personas'; Saul Josh, 2023, Artificial Intelligence Is Booming-So Is Its Carbon Footprint; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Similarweb, 2023, Similarweb; Statista, 2023, Statista; Stokel-Walker Chris, 2023, The Generative AI Race Has a Dirty Secret; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Tirmazi M, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387517; U.S. Energy Information Administration, 2022, Short-Term Energy Outlook; Vanian J., 2023, ChatGPT and generative AI are booming, but the costs can be extraordinary; WattTime, 2023, About us; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Yang Fan, 2017, IEEE Transactions on Parallel and Distributed Systems, V29, P5; Zhang CJ, 2021, LECT NOTES COMPUT SC, V12985, P190, DOI 10.1007/978-3-030-88224-2_10; Zhang Chaojie, 2023, Ph. D. Dissertation; Zheng JJ, 2020, JOULE, V4, P2208, DOI 10.1016/j.joule.2020.08.001; Zhou Z, 2016, IEEE T PARALL DISTR, V27, P2506, DOI 10.1109/TPDS.2015.2504978	62	5	5	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0242-6				2023										10.1145/3604930.3605705	http://dx.doi.org/10.1145/3604930.3605705			7	Computer Science, Theory & Methods; Green & Sustainable Science & Technology	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Science & Technology - Other Topics	BW2ST		hybrid			2024-07-03	WOS:001124735600011
J	Ming, SF; Zhang, R; Kilicoglu, H				Ming, Shufan; Zhang, Rui; Kilicoglu, Halil			Enhancing the coverage of SemRep using a relation classification approach	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Biomedical relation extraction; Relation classification; Large language models; SemRep; SemMedDB	UMLS	Objective: Relation extraction is an essential task in the field of biomedical literature mining and offers significant benefits for various downstream applications, including database curation, drug repurposing, and literature-based discovery. The broad-coverage natural language processing (NLP) tool SemRep has established a solid baseline for extracting subject-predicate-object triples from biomedical text and has served as the backbone of the Semantic MEDLINE Database (SemMedDB), a PubMed-scale repository of semantic triples. While SemRep achieves reasonable precision (0.69), its recall is relatively low (0.42). In this study, we aimed to enhance SemRep using a relation classification approach, in order to eventually increase the size and the utility of SemMedDB. Methods: We combined and extended existing SemRep evaluation datasets to generate training data. We leveraged the pre-trained PubMedBERT model, enhancing it through additional contrastive pre-training and fine-tuning. We experimented with three entity representations: mentions, semantic types, and semantic groups. We evaluated the model performance on a portion of the SemRep Gold Standard dataset and compared it to SemRep performance. We also assessed the effect of the model on a larger set of 12K randomly selected PubMed abstracts. Results: Our results show that the best model yields a precision of 0.62, recall of 0.81, and F 1 score of 0.70. Assessment on 12K abstracts shows that the model could double the size of SemMedDB, when applied to entire PubMed. We also manually assessed the quality of 506 triples predicted by the model that SemRep had not previously identified, and found that 67% of these triples were correct. Conclusion: These findings underscore the promise of our model in achieving a more comprehensive coverage of relationships mentioned in biomedical literature, thereby showing its potential in enhancing various downstream applications of biomedical literature mining. Data and code related to this study are available at https://github.com/Michelle-Mings/SemRep_RelationClassification.	[Ming, Shufan; Kilicoglu, Halil] Univ Illinois Urbana Champaigns, Sch Informat Sci, 501 E Daniel St, Champaign, IL 61820 USA; [Zhang, Rui] Univ Minnesota, Dept Surg, Div Computat Hlth Sci, 516 Delaware St SE, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Kilicoglu, H (corresponding author), Univ Illinois Urbana Champaigns, Sch Informat Sci, 501 E Daniel St, Champaign, IL 61820 USA.	halil@illinois.edu			National Library of Medicine of the National Institutes of Health [R01LM014079]; Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program [CIS230380]; National Science Foundation, United States [2138259, 2138286, 2138307, 2137603, 2138296]	National Library of Medicine of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM)); Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program; National Science Foundation, United States(National Science Foundation (NSF))	This work was partially supported by the National Library of Medicine of the National Institutes of Health under the award number R01LM014079. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The funder had no role in considering the study design or in the collection, analysis, interpretation of data, writing of the report, or decision to submit the article for publication. This work used Bridges-2 and Ocean at Pittsburgh Supercomputing Center (PSC) through allocation #CIS230380 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program [49] , which is supported by National Science Foundation, United States grants #2138259, #2138286, #2138307, #2137603, and #2138296.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Andronis C, 2011, BRIEF BIOINFORM, V12, P357, DOI 10.1093/bib/bbr005; Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Boerner Timothy J., 2023, PEARC '23: Practice and Experience in Advanced Research Computing, P173, DOI 10.1145/3569951.3597559; Cabot PLH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2370; Chen QY, 2024, Arxiv, DOI [arXiv:2305.16326, 10.48550/arXiv.2305.16326, DOI 10.48550/ARXIV.2305.16326]; Demner-Fushman D, 2009, J BIOMED INFORM, V42, P760, DOI 10.1016/j.jbi.2009.08.007; Eberts M, 2020, FRONT ARTIF INTEL AP, V325, P2006, DOI 10.3233/FAIA200321; El-allaly ED, 2022, J BIOMED INFORM, V125, DOI 10.1016/j.jbi.2021.103968; Gopalakrishnan V, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103141; Harpaz R, 2014, DRUG SAFETY, V37, P777, DOI 10.1007/s40264-014-0218-z; Henry S, 2017, J BIOMED INFORM, V74, P20, DOI 10.1016/j.jbi.2017.08.011; Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011; Jimenez Gutierrez B., 2022, FINDINGS ASS COMPUTA, P4497; Kang T, 2021, J AM MED INFORM ASSN, V28, P812, DOI 10.1093/jamia/ocaa309; Kilicoglu H, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3517-7; Kilicoglu H, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1009-6; Kilicoglu H, 2012, BIOINFORMATICS, V28, P3158, DOI 10.1093/bioinformatics/bts591; Kilicoglu H, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-486; Krallinger M., 2017, P 6 BIOCREATIVE CHAL, V1, P141; Lai PT, 2023, Arxiv, DOI arXiv:2306.11189; Lai T, 2021, Long Papers, V1, P6248, DOI DOI 10.18653/V1/2021.ACL-LONG.488; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Luo L, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac282; McCray AT, 2001, STUD HEALTH TECHNOL, V84, P216; Morid MA, 2016, J BIOMED INFORM, V60, P14, DOI 10.1016/j.jbi.2016.01.003; Pilipiec P, 2022, PHARMACEUTICS, V14, DOI 10.3390/pharmaceutics14020266; Rindflesch Thomas C., 2011, Information Services & Use, V31, P15, DOI 10.3233/ISU-2011-0627; Rindflesch TC, 2003, J BIOMED INFORM, V36, P462, DOI 10.1016/j.jbi.2003.11.003; Rindflesch TC, 2018, J BIOMED SEMANT, V9, DOI 10.1186/s13326-018-0192-y; Sarrouti M, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P376; Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895; Su P., 2021, P 20 WORKSH BIOM LAN, P1; Tian SB, 2023, Arxiv, DOI [arXiv:2306.10070, 10.48550/arXiv.2306.10070]; Vasilakes J, 2018, JAMIA OPEN, V1, P275, DOI 10.1093/jamiaopen/ooy021; Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37; Wadhwa S, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15566, DOI 10.18653/v1/2023.acl-long.868; Wang LL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P362; Wei CH, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw032; Whitton J, 2023, ARTIF INTELL MED, V144, DOI 10.1016/j.artmed.2023.102661; Wu SC, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2361, DOI 10.1145/3357384.3358119; Xiao YX, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2395; Yang HT, 2017, BRIEF BIOINFORM, V18, P488, DOI 10.1093/bib/bbw030; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zaikis D, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102153; Zhang R, 2021, J BIOMED INFORM, V115, DOI 10.1016/j.jbi.2021.103696; Zhao SD, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa057; Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P50	50	0	0	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	JUL	2024	155								104658	10.1016/j.jbi.2024.104658	http://dx.doi.org/10.1016/j.jbi.2024.104658			11	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	UF0M0	38782169				2024-07-03	WOS:001246527800001
J	Ivanov, S; Soliman, M				Ivanov, Stanislav; Soliman, Mohammad			Game of algorithms: ChatGPT implications for the future of tourism education and research	JOURNAL OF TOURISM FUTURES			English	Article						ChatGPT; Tourism education; Tourism research; Intelligent automation; Large language models	TECHNOLOGY; ACCEPTANCE	Purpose - The paper aims to evaluate the ways ChatGPT is going to disrupt tourism education and research. Design/methodology/approach - This is a conceptual paper. Findings - ChatGPT has the potential to revolutionize tourism education and research because it can do what students and researchers should do, namely, generate text (assignments and research papers). Universities will need to reevaluate their teaching and assessment strategies and incorporate generative language models in teaching. Publishers will need to be more receptive toward manuscripts that are partially generated by artificial intelligence. In the future, digital teachers and research assistants will take over many of the cognitive tasks of tourism educators and researchers. Originality/value - To the authors' best knowledge, this is one of the first academic papers that investigates the implications of ChatGPT to tourism education and research.	[Ivanov, Stanislav] Varna Univ Management, Varna, Bulgaria; [Ivanov, Stanislav] Zangador Res Inst, Varna, Bulgaria; [Soliman, Mohammad] Univ Technol & Appl Sci, Salalah, Oman; [Soliman, Mohammad] Fayoum Univ, Al Fayyum, Egypt	Varna University of Management; Egyptian Knowledge Bank (EKB); Fayoum University	Ivanov, S (corresponding author), Varna Univ Management, Varna, Bulgaria.; Ivanov, S (corresponding author), Zangador Res Inst, Varna, Bulgaria.	stanislav.ivanov@vumk.eu; msoliman.sal@cas.edu.om	Soliman, Mohammad/AAC-3702-2020; Ivanov, Stanislav Hristov/D-7692-2012	Soliman, Mohammad/0000-0002-9359-763X; Ivanov, Stanislav Hristov/0000-0002-6851-5823				Abou-Shouk M, 2021, J DESTIN MARK MANAGE, V20, DOI 10.1016/j.jdmm.2021.100559; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Ajzen I, 2002, J APPL SOC PSYCHOL, V32, P665, DOI 10.1111/j.1559-1816.2002.tb00236.x; AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T; Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI DOI 10.1007/978-3-642-69746-3_2; Ali F., 2023, Journal of Global Hospitality and Tourism, V2, P1, DOI https://doi.org/10.5038/2771-5957.2.1.1016; Anders B.A., 2022, WHY CHATGPT SUCH BIG; Anders B.A., 2022, CHATGPT AI ED OVERVI; Carlisle S, 2021, J TOUR FUTURES, V9, P240, DOI 10.1108/JTF-07-2020-0114; Coeckelbergh M., 2020, AI Ethics; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haque M.U., 2022, ARXIV; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Ivanov S., 2021, Journal of Smart Tourism, V1, P9, DOI [10.52255/smarttourism.2021.1.4.3, DOI 10.52255/SMARTTOURISM.2021.1.4.3]; Ivanov S., 2016, YB VARNA U MANAGEMEN, V9, P42; Ivanov S.H., 2021, ROBONOMICS J. Autom. Econ, V1, P11; Murphy J, 2017, EUR J TOUR RES, V15, P104; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Topsakal O., 2022, J COGNIT SYST, V7, P33, DOI 10.52876/jcs.1227392; Vanian J., 2022, CNBC; Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926; Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540; WRITER B, 2019, LITHIUM ION BATTERIE, DOI 10.1007/978-3-030-16800-1	24	48	48	33	126	EMERALD GROUP PUBLISHING LTD	BINGLEY	HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND	2055-5911	2055-592X		J TOUR FUTURES	J. Tour. Futures	MAY 21	2021	9	2					214	221		10.1108/JTF-02-2023-0038	http://dx.doi.org/10.1108/JTF-02-2023-0038		APR 2023	8	Hospitality, Leisure, Sport & Tourism	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	O7CL4		gold			2024-07-03	WOS:000961621100001
J	Ata, AM; Aras, B; Tasdelen, OY; Çelik, C; Çulha, C				Ata, Ayse Merve; Aras, Berke; Tasdelen, Ozlem Yilmaz; Celik, Canan; Culha, Canan			Evaluation of Informative Content on Cerebral Palsy in the Era of Artificial Intelligence: The Value of ChatGPT	PHYSICAL & OCCUPATIONAL THERAPY IN PEDIATRICS			English	Article; Early Access						Artificial intelligence; cerebral palsy; ChatGPT; health information; large language model	CLASSIFICATION; DEFINITION; CHILDREN	AimsIn addition to the popular search engines on the Internet, ChatGPT may provide accurate and reliable health information. The aim of this study was to examine whether ChatGPT's responses to frequently asked questions concerning cerebral palsy (CP) by families were reliable and useful.MethodsGoogle trends were used to find the most frequently searched keywords for CP. Five independent physiatrists assessed ChatGPT responses to 10 questions. Seven-point Likert-type scales were used to rate information reliability and usefulness based on whether the answer can be validated and is understandable.ResultsThe median ratings for reliability of information for each question varied from 2 (very unsafe) to 5 (relatively very reliable). The median rating was 4 (reliable) for four questions. The median ratings for usefulness of information varied from 2 (very little useful) to 5 (moderately useful). The median rating was 4 (partly useful) for seven questions.ConclusionAlthough ChatGPT appears promising as an additional tool for informing family members of individuals with CP about medical information, it should be emphasized that both consumers and health care providers should be aware of the limitations of artificial intelligence-generated information.	[Ata, Ayse Merve; Aras, Berke; Tasdelen, Ozlem Yilmaz; Celik, Canan; Culha, Canan] Ankara Bilkent City Hosp, Phys Therapy & Rehabil Hosp, Dept Phys Med & Rehabil, Ankara, Turkiye; [Ata, Ayse Merve] Ankara Bilkent City Hosp, Phys Therapy & Rehabil Hosp, Univ Mahallesi 1604,Cadde 9, TR-06800 Ankara, Turkiye		Ata, AM (corresponding author), Ankara Bilkent City Hosp, Phys Therapy & Rehabil Hosp, Univ Mahallesi 1604,Cadde 9, TR-06800 Ankara, Turkiye.	amerveata@hotmail.com	celik, canan/KFS-4757-2024; Ata, Ayşe Merve/GWQ-5492-2022	Ata, Ayşe Merve/0000-0002-0508-2506				Armand S, 2016, EFORT OPEN REV, V1, P448, DOI 10.1302/2058-5241.1.000052; Bax M, 2005, DEV MED CHILD NEUROL, V47, P571, DOI 10.1017/S001216220500112X; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Cocci A, 2024, PROSTATE CANCER P D, V27, P103, DOI 10.1038/s41391-023-00705-y; Davis R, 2023, J UROLOGY, V210, P688, DOI 10.1097/JU.0000000000003615; Demont A, 2022, NEUROLOGY, V99, P283, DOI 10.1212/WNL.0000000000200936; Furtado MAS, 2022, PHYS OCCUP THER PEDI, V42, P369, DOI 10.1080/01942638.2022.2046677; Hatton C, 2003, J APPL RES INTELLECT, V16, P177, DOI 10.1046/j.1468-3148.2003.00167.x; Huang YP, 2010, J ADV NURS, V66, P1213, DOI 10.1111/j.1365-2648.2010.05270.x; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; McIntyre S, 2022, DEV MED CHILD NEUROL, V64, P1494, DOI 10.1111/dmcn.15346; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Ohst A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00664; OpenAI, 2023, Chatgpt: Optimizing language models for dialogue; Patterson R. P., 2015, Journal of Communication in Healthcare, V8, P303, DOI 10.1179/1753807615Y.0000000007; Rosenbaum P, 2007, DEV MED CHILD NEUROL, V49, P8, DOI 10.1111/j.1469-8749.2007.tb12610.x; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749; Wadden JJ, 2022, J MED ETHICS, V48, P764, DOI 10.1136/medethics-2021-107529; Wise NJ, 2022, NURS RES, V71, P441, DOI 10.1097/NNR.0000000000000619; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	22	0	0	7	7	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0194-2638	1541-3144		PHYS OCCUP THER PEDI	Phys. Occup. Ther. Pediatr.	2024 FEB 15	2024										10.1080/01942638.2024.2316178	http://dx.doi.org/10.1080/01942638.2024.2316178		FEB 2024	10	Pediatrics; Rehabilitation	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Pediatrics; Rehabilitation	HZ8N2	38361368				2024-07-03	WOS:001163428300001
J	Wu, J; Ma, YZ; Wang, J; Xiao, MZ				Wu, Jie; Ma, Yingzhuo; Wang, Jun; Xiao, Mingzhao			The Application of ChatGPT in Medicine: A Scoping Review and Bibliometric Analysis	JOURNAL OF MULTIDISCIPLINARY HEALTHCARE			English	Review						ChatGPT; large language model; medicine; nursing; scoping review; bibliometric analysis		Purpose: ChatGPT has a wide range of applications in the medical field. Therefore, this review aims to define the key issues and provide a comprehensive view of the literature based on the application of ChatGPT in medicine. Methods: This scope follows Arksey and O'Malley's five-stage framework. A comprehensive literature search of publications (30 November 2022 to 16 August 2023) was conducted. Six databases were searched and relevant references were systematically catalogued. Attention was focused on the general characteristics of the articles, their fields of application, and the advantages and disadvantages of using ChatGPT. Descriptive statistics and narrative synthesis methods were used for data analysis. Results: Of the 3426 studies, 247 met the criteria for inclusion in this review. The majority of articles (31.17%) were from the United States. Editorials (43.32%) ranked first, followed by experimental studys (11.74%). The potential applications of ChatGPT in medicine are varied, with the largest number of studies (45.75%) exploring clinical practice, including assisting with clinical decision support and providing disease information and medical advice. This was followed by medical education (27.13%) and scientific research (16.19%). Particularly noteworthy in the discipline statistics were radiology, surgery and dentistry at the top of the list. However, ChatGPT in medicine also faces issues of data privacy, inaccuracy and plagiarism. Conclusion: The application of ChatGPT in medicine focuses on different disciplines and general application scenarios. ChatGPT has a paradoxical nature: it offers significant advantages, but at the same time raises great concerns about its application in healthcare settings. Therefore, it is imperative to develop theoretical frameworks that not only address its widespread use in healthcare but also facilitate a comprehensive assessment. In addition, these frameworks should contribute to the development of strict and effective guidelines and regulatory measures.	[Wu, Jie; Ma, Yingzhuo; Wang, Jun] Chongqing Med Univ, Affiliated Hosp 1, Dept Nursing, Chongqing 400016, Peoples R China; [Xiao, Mingzhao] Chongqing Med Univ, Affiliated Hosp 1, Dept Urol, Chongqing 400016, Peoples R China	Chongqing Medical University; Chongqing Medical University	Wang, J (corresponding author), Chongqing Med Univ, Affiliated Hosp 1, Dept Nursing, Chongqing 400016, Peoples R China.; Xiao, MZ (corresponding author), Chongqing Med Univ, Affiliated Hosp 1, Dept Urol, Chongqing 400016, Peoples R China.	smile@stu.cqmu.edu.cn; xmz.2004@163.com			Chongqing Elite Master Grant;  [CQYC202003]	Chongqing Elite Master Grant; 	This study was funded by the Chongqing Elite Master Grant 2021 (CQYC202003) .	Alanzi TM, 2023, J MULTIDISCIP HEALTH, V16, P2309, DOI 10.2147/JMDH.S419847; Arachchige ASPM, 2023, J ECHOCARDIOGR, V21, P184, DOI 10.1007/s12574-023-00620-0; Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [DOI 10.1080/1364557032000119616, 10.1080/1364557032000119616]; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bosbach WA, 2024, CURR PROBL DIAGN RAD, V53, P102, DOI 10.1067/j.cpradiol.2023.04.001; Castro H, 2023, DERMATOLOGIE, V74, P633, DOI 10.1007/s00105-023-05186-7; Chen JF, 2023, J MULTIDISCIP HEALTH, V16, P3825, DOI 10.2147/JMDH.S441790; Chiesa-Estomba CM, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08104-8; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fraga-Graells E, 2022, Arch Soc Esp Oftalmol (Engl Ed), V97, P323, DOI 10.1016/j.oftale.2022.02.011; Gödde D, 2023, J MED INTERNET RES, V25, DOI 10.2196/49368; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Levac D, 2010, IMPLEMENT SCI, V5, DOI 10.1186/1748-5908-5-69; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Liu GMT, 2023, ANN BIOMED ENG, V51, P2113, DOI 10.1007/s10439-023-03241-x; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Munn Z, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-018-0611-x; Navas-Martín MA, 2024, SCI TOTAL ENVIRON, V908, DOI 10.1016/j.scitotenv.2023.168441; Ninkov A, 2022, PERSPECT MED EDUC, V11, P173, DOI 10.1007/s40037-021-00695-4; Peterson J, 2017, J AM ASSOC NURSE PRA, V29, P12, DOI 10.1002/2327-6924.12380; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Sevgi UT, 2023, NEUROSURG REV, V46, DOI 10.1007/s10143-023-01998-2; Shay D, 2023, BRIT J ANAESTH, V131, DOI 10.1016/j.bja.2023.04.017; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Valentin-Bravo F J, 2023, Arch Soc Esp Oftalmol (Engl Ed), V98, P298, DOI 10.1016/j.oftale.2023.04.011; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946; WHO, 2023, World Health Statistics 2023: Monitoring Health for the SDGs, Sustainable Development Goals; Wong RSY, 2023, JMIR MED EDUC, V9, DOI 10.2196/47274; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7; Zaabi M, 2023, A review study of ChatGPT applications in education, DOI [10.1109/INISTA59065.2023.10310439, DOI 10.1109/INISTA59065.2023.10310439]	39	0	0	15	15	DOVE MEDICAL PRESS LTD	ALBANY	PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND	1178-2390			J MULTIDISCIP HEALTH	J. Multidiscip. Healthc.		2024	17						1681	1692		10.2147/JMDH.S463128	http://dx.doi.org/10.2147/JMDH.S463128			12	Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services	OO1F9	38650670	gold			2024-07-03	WOS:001208117100001
J	Tafferner, Z; Illes, B; Krammer, O; Géczy, A				Tafferner, Zoltan; Illes, Balazs; Krammer, Oliver; Geczy, Attila			Can ChatGPT Help in Electronics Research and Development? A Case Study with Applied Sensors	SENSORS			English	Article						generative large language model; ChatGPT; sensors; electronics; engineering; development; IoT		In this paper, we investigated the applicability of ChatGPT AI in electronics research and development via a case study of applied sensors in embedded electronic systems, a topic that is rarely mentioned in the recent literature, thus providing new insight for professionals and academics. The initial electronics-development tasks of a smart home project were prompted to the ChatGPT system to find out its capabilities and limitations. We wanted to obtain detailed information on the central processing controller units and the actual sensors usable for the specific project, their specifications and recommendations on the hardware and software design flow additionally. Furthermore, an extensive literature survey was requested to see if the bot could offer scientific papers covering the given topic. It was found that the ChatGPT responded with proper recommendations on controllers. However, the suggested sensor units, the hardware and software design were only partially acceptable, with occasional errors in specifications and generated code. The results of the literature survey showed that non-acceptable, fabricated citations (fake authors list, title, journal details and DOI-Digital Object identifier) were presented by the bot. The paper provides a detailed qualitative analysis, a performance analysis and critical discussion of the aforementioned aspects while providing the query set, the generated answers and codes as supplied data with the goal to give added value to electronics researchers and developers if trying to reach out for the tools in their profession.	[Tafferner, Zoltan; Illes, Balazs; Krammer, Oliver; Geczy, Attila] Budapest Univ Technol & Econ, Fac Elect Engn & Informat, Dept Elect Technol, H-1111 Budapest, Hungary; [Illes, Balazs] Inst Microelect & Photon, Lukasiewicz Res Network, LTCC Technol Res Grp, PL-02255 Krakow, Poland	Budapest University of Technology & Economics	Géczy, A (corresponding author), Budapest Univ Technol & Econ, Fac Elect Engn & Informat, Dept Elect Technol, H-1111 Budapest, Hungary.	illes.balazs@vik.bme.hu; krammer.oliver@vik.bme.hu	; Illes, Balazs/G-7378-2012	Tafferner, Zoltan/0009-0006-7466-9761; Illes, Balazs/0000-0002-8619-5472				Adafruit, ADAFRUIT TSL2561; Adamson Greg, 2023, IEEE Transactions on Technology and Society, P34, DOI 10.1109/TTS.2023.3240107; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; analog, DS18B20 PROGR RES 1; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; [Anonymous], About Us; [Anonymous], 2018, TSL2561 LIGHT TO DIG; aosong, DHT11 DAT; Arduino Docs, TUTORIALS; Arduino Portenta Family, 2020, SEEED STUD; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bhattacharya K, 2023, INDIAN J SURG, V85, P1346, DOI 10.1007/s12262-023-03727-x; Biswas S., 2023, MESOPOTAMIAN J COMPU, V2023, P8, DOI [10.58496/MJCSC/2023/002, DOI 10.58496/MJCSC/2023/002]; Budler LC, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1487; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Cox Louis Anthony Jr, 2023, Glob Epidemiol, V5, P100102, DOI 10.1016/j.gloepi.2023.100102; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Hanwei Electronics, TECHN DAT MQ 135 GAS; help.openai, WHAT IS CHATGPT OPEN; Hernando Barragan, UNTOLD HIST ARDUINO; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; maritex, DHT11 DAT AS; mouser, DHT11 DAT TRANSL; Narayan J., 2023, CITINGRISKS SOCIETYR; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; sparkfun, MQ 4 GAS SENS; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Tong YJ, 2023, SYN SYST BIOTECHNO, V8, P220, DOI 10.1016/j.synbio.2023.02.004; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Vincent J, 2023, Italian Regulators Order ChatGPT Ban over Alleged Violation of Data Privacy Laws, the Verge; Vincent James, 2023, The Verge; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Ziolkowski P, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108273	39	6	6	14	42	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	MAY 18	2023	23	10							4879	10.3390/s23104879	http://dx.doi.org/10.3390/s23104879			14	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	H7KD7	37430793	gold, Green Published			2024-07-03	WOS:000997699800001
C	Rao, N; Jain, K; Alon, U; Le Goues, C; Hellendoorn, VJ			IEEE	Rao, Nikitha; Jain, Kush; Alon, Uri; Le Goues, Claire; Hellendoorn, Vincent J.			CAT-LM Training Language Models on Aligned Code And Tests	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		test generation; test completion; large language models; code-test alignment		Testing is an integral but often neglected part of the software development process. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than typical code generation models, to ensure that the code context is available to the model when generating test code. We analyze its usefulness for realistic applications, showing that sampling with filtering (e.g., by compilability, coverage) allows it to efficiently produce tests that achieve coverage similar to ones written by developers while resembling their writing style. By utilizing the code context, CAT-LM generates more valid tests than even much larger language models trained with more data (CodeGen 16B and StarCoder) and substantially outperforms a recent test-specific model (TeCo) at test completion. Overall, our work highlights the importance of incorporating software-specific insights when training language models for code and paves the way to more powerful automated test generation.	[Rao, Nikitha; Jain, Kush; Alon, Uri; Le Goues, Claire; Hellendoorn, Vincent J.] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Rao, N (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	nikitharao@cmu.edu; kdjain@cmu.edu; urialon@cmu.edu; legoues@cmu.edu; vhellendoorn@cmu.edu		Le Goues, Claire/0000-0002-3931-060X	US National Science Foundation [CCF-2129388, CCF-1910067]	US National Science Foundation(National Science Foundation (NSF))	The authors would like to thank Charles Sutton for his mentorship as part of the Google Collab Ph.D. Fellowship, which also included $20,000 in cloud credits without which this work would not have been possible. We additionally thank the authors of TeCo for providing us with data and code for our baseline experiments. This work is supported in part by the US National Science Foundation, awards CCF-2129388 and CCF-1910067.	Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Alon Uri, 2022, arXiv; [Anonymous], 2021, GitHub Copilot; Baldoni R, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3182657; Bavarian M, 2022, Arxiv, DOI [arXiv:2207.14255, 10.48550/arXiv.2207.14255]; Beller M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P179, DOI 10.1145/2786805.2786843; Beller M, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P559, DOI 10.1109/ICSE.2015.193; Boyapati C., 2002, Software Engineering Notes, V27, P123, DOI 10.1145/566171.566191; Brandt C, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-021-10094-2; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Choi J, 2019, PROC INT CONF SOFTW, P736, DOI 10.1109/ICSE.2019.00082; Claessen K, 2000, ACM SIGPLAN NOTICES, V35, P268, DOI 10.1145/357766.351266; Daka E, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P57, DOI 10.1145/3092703.3092727; Dao T., 2022, Advances in Neural Information Processing Systems (NeurIPS); De Souza HHF, 2022, 36TH BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING, SBES 2022, P95, DOI 10.1145/3555228.3555244; Dinella E, 2022, PROC INT CONF SOFTW, P2130, DOI 10.1145/3510003.3510141; Fioraldi A., 2020, P 14 USENIX C OFFENS, P10; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; github, SentencePiece; github, GitHub REST API; github, TheFuzz: Fuzzy String Matching in Python; github, GPT-neox Toolkit; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu X, 2020, EMPIR SOFTW ENG, V25, P2179, DOI [10.1007/s10664-019-09730-9, 10.1007/978-981-13-8203-1_1]; Kochhar PS, 2013, INT CONF QUAL SOFTW, P103, DOI 10.1109/QSIC.2013.57; Kudo T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P66; LeClair A, 2019, PROC INT CONF SOFTW, P795, DOI 10.1109/ICSE.2019.00087; Li R., 2023, Starcoder: may the source be with you!; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lopes CV, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133908; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; MacIver David R., 2019, Journal of Open Source Software, V4, P1891, DOI DOI 10.21105/JOSS.01891; Nie PY, 2023, PROC INT CONF SOFTW, P2111, DOI 10.1109/ICSE48619.2023.00178; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2023, GPT-4 Technical Report; Pacheco Carlos, 2007, OOPSLA 07 COMPANION, P815, DOI [10.1145/1297846.1297902, DOI 10.1145/1297846.1297902]; Panichella A, 2020, PROC IEEE INT CONF S, P523, DOI 10.1109/ICSME46990.2020.00056; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Robinson Brian, 2011, 2011 26th IEEE/ACM International Conference on Automated Software Engineering, P23, DOI 10.1109/ASE.2011.6100059; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Tillmann N, 2008, LECT NOTES COMPUT SC, V4966, P134; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Villmow J, 2021, NLP4PROG 2021: THE 1ST WORKSHOP ON NATURAL LANGUAGE PROCESSING FOR PROGRAMMING (NLP4PROG 2021), P17; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Watson C, 2020, PROC INT CONF SOFTW, P1398, DOI 10.1145/3377811.3380429; Werra L. v., Codeparrot; White R, 2020, Arxiv, DOI arXiv:2011.09784	50	2	2	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							409	420		10.1109/ASE56229.2023.00193	http://dx.doi.org/10.1109/ASE56229.2023.00193			12	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200033
J	Mistica, M; Haylock, P; Michalewicz, A; Raad, S; Fitzgerald, E; Hitchcock, C				Mistica, Meladel; Haylock, Patrick; Michalewicz, Aleksandra; Raad, Steph; Fitzgerald, Emily; Hitchcock, Caitlin			A natural language model to automate scoring of autobiographical memories	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						Autobiographical memory task; AMT; Large language models; Natural language processing	SPECIFICITY; METAANALYSIS; FLEXIBILITY; MOOD	Biases in the retrieval of personal, autobiographical memories are a core feature of multiple mental health disorders, and are associated with poor clinical prognosis. However, current assessments of memory bias are either reliant on human scoring, restricting their administration in clinical settings, or when computerized, are only able to identify one memory type. Here, we developed a natural language model able to classify text-based memories as one of five different autobiographical memory types (specific, categoric, extended, semantic associate, omission), allowing easy assessment of a wider range of memory biases, including reduced memory specificity and impaired memory flexibility. Our model was trained on 17,632 text-based, human-scored memories obtained from individuals with and without experience of memory bias and mental health challenges, which was then tested on a dataset of 5880 memories. We used 20-fold cross-validation setup, and the model was fine-tuned over BERT. Relative to benchmarking and an existing support vector model, our model achieved high accuracy (95.7%) and precision (91.0%). We provide an open-source version of the model which is able to be used without further coding, by those with no coding experience, to facilitate the assessment of autobiographical memory bias in clinical settings, and aid implementation of memory-based interventions within treatment services.	[Mistica, Meladel; Michalewicz, Aleksandra; Fitzgerald, Emily] Univ Melbourne, Melbourne Data Analyt Platform, Parkville, Vic 3053, Australia; [Haylock, Patrick; Raad, Steph; Hitchcock, Caitlin] Univ Melbourne, Melbourne Sch Psychol Sci, Tin Alley, Parkville, Vic 3010, Australia	University of Melbourne; University of Melbourne	Mistica, M (corresponding author), Univ Melbourne, Melbourne Data Analyt Platform, Parkville, Vic 3053, Australia.; Hitchcock, C (corresponding author), Univ Melbourne, Melbourne Sch Psychol Sci, Tin Alley, Parkville, Vic 3010, Australia.	misticam@unimelb.edu.au; phaylock@student.unimelb.edu.au; aleksm@unimelb.edu.au; sraad@student.unimelb.edu.au; fiej@unimelb.edu.au; caitlin.hitchcock@unimelb.edu.au		Hitchcock, Caitlin/0000-0002-2435-0713; Fitzgerald, Emily/0000-0002-4991-946X	Australian Research Council	Australian Research Council(Australian Research Council)	No Statement Available	Askelund AD, 2019, NAT HUM BEHAV, V3, P265, DOI 10.1038/s41562-018-0504-3; Barry TJ, 2021, PSYCHOL BULL, V147, P1054, DOI 10.1037/bul0000345; Barry TJ, 2019, MEMORY, V27, P916, DOI 10.1080/09658211.2019.1607876; Barry TJ, 2019, BEHAV RES THER, V116, P36, DOI 10.1016/j.brat.2019.02.001; Conway MA, 2000, PSYCHOL REV, V107, P261, DOI 10.1037//0033-295X.107.2.261; Dalgleish T, 2023, NAT REV PSYCHOL, V2, P166, DOI 10.1038/s44159-023-00148-1; Debeer E, 2009, MEMORY, V17, P892, DOI 10.1080/09658210903376243; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dritschel B, 2014, MEMORY, V22, P881, DOI 10.1080/09658211.2013.839710; Griffith JW, 2009, MEMORY, V17, P609, DOI 10.1080/09658210902939348; Hallford DJ, 2021, PSYCHOL MED, V51, P909, DOI 10.1017/S0033291721001343; Hallford DJ, 2018, BEHAV RES THER, V102, P42, DOI 10.1016/j.brat.2018.01.003; Hallford D. J., 2021, PsyArXiv, DOI [10.31234/osf.io/vmurs, DOI 10.31234/OSF.IO/VMURS]; Hitchcock C, 2018, BEHAV RES THER, V110, P22, DOI 10.1016/j.brat.2018.08.008; Hitchcock C, 2017, CLIN PSYCHOL REV, V52, P92, DOI 10.1016/j.cpr.2016.12.003; Mang LS, 2018, PSYCHIAT RES, V269, P444, DOI 10.1016/j.psychres.2018.08.055; Marsh LC, 2023, BEHAV RES THER, V167, DOI 10.1016/j.brat.2023.104352; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Nord Camilla L, 2023, Nat Ment Health, V1, P389, DOI 10.1038/s44220-023-00048-6; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Piltan M, 2021, CLIN PSYCHOL SCI, V9, P294, DOI 10.1177/2167702620953637; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schacter D. L., 2022, arXiv, DOI [10.31234/osf.io/nyurm, DOI 10.31234/OSF.IO/NYURM]; Schacter DL, 2007, PHILOS T R SOC B, V362, P773, DOI 10.1098/rstb.2007.2087; Smirnova D, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00105; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Takano K, 2019, MEMORY, V27, P306, DOI 10.1080/09658211.2018.1507042; Takano K, 2018, PSYCHOL ASSESSMENT, V30, P259, DOI 10.1037/pas0000472; Takano K, 2017, BEHAV RES METHODS, V49, P835, DOI 10.3758/s13428-016-0753-x; Vaswani A, 2017, ADV NEUR IN, V30; Wardell V, 2021, BEHAV RES METHODS, V53, P507, DOI 10.3758/s13428-020-01437-w; Williams JMG, 2007, PSYCHOL BULL, V133, P122, DOI 10.1037/0033-2909.133.1.122; WILLIAMS JMG, 1986, J ABNORM PSYCHOL, V95, P144, DOI 10.1037/0021-843X.95.2.144; Zhang TL, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00589-7	34	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 APR 25	2024										10.3758/s13428-024-02385-5	http://dx.doi.org/10.3758/s13428-024-02385-5		APR 2024	14	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	OO4I9	38664340	hybrid			2024-07-03	WOS:001208199300001
J	Lahat, A; Klang, E				Lahat, Adi; Klang, Eyal			Can advanced technologies help address the global increase in demand for specialized medical care and improve telehealth services?	JOURNAL OF TELEMEDICINE AND TELECARE			English	Editorial Material; Early Access						Telemedicine; telehealth; chatGPT; large language models (LLM); artificial intelligence (AI)			[Lahat, Adi] Tel Aviv Univ, Chaim Sheba Med Ctr, Dept Gastroenterol, Tel Aviv, Israel; [Klang, Eyal] Tel Aviv Univ, ARC innovat Ctr, Chaim Sheba Med Ctr, Sami Sagol AI Hub, Tel Aviv, Israel; [Lahat, Adi] Tel Aviv Univ, Chaim Sheba Med Ctr, Dept Gastroenterol, Tel Hashomer, Ramat Gan 52621, Israel	Chaim Sheba Medical Center; Tel Aviv University; Chaim Sheba Medical Center; Tel Aviv University; Tel Aviv University; Chaim Sheba Medical Center	Lahat, A (corresponding author), Tel Aviv Univ, Chaim Sheba Med Ctr, Dept Gastroenterol, Tel Hashomer, Ramat Gan 52621, Israel.	zokadi@gmail.com						[Anonymous], 2022, GOOGLE ANNOUNCES CHA; Hatef E, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.8954; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Pfeil JN, 2023, J TELEMED TELECARE, V29, P10, DOI 10.1177/1357633X20963935; US	5	10	10	5	33	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1357-633X	1758-1109		J TELEMED TELECARE	J. Telemed. Telecare	2023 FEB 9	2023										10.1177/1357633X231155520	http://dx.doi.org/10.1177/1357633X231155520		FEB 2023	2	Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services	9A2AW	36760131	Bronze			2024-07-03	WOS:000933866900001
C	Seow, O			ACM	Seow, Olivia			LingoLand: An AI-Assisted Immersive Game for Language Learning	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		Language Learning; Generative Games; Large Language Models; Human-AI Interaction		Immersion with a foreign language is key to increased motivation, satisfaction, and learning success. However, this can be hindered by anxiety and lack of access to immersive settings. LingoLand will address this by immersing people in foreign language learning environments designed to mimic real scenarios. Using generative machine learning, LingoLand presents players with personalized missions where they can freely interact with game characters, all endlessly patient and supportive of new language learners. Players receive instant feedback through a natural, voice-based interaction. Through LingoLand, players gain an understanding of diferent cultures while building practical language skills in a fun way.	[Seow, Olivia] Harvard Univ, Cambridge, MA 02138 USA	Harvard University	Seow, O (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.	oseow@sigchi.org						Alnuzaili E.S., 2020, Journal of Language Teaching Research, V11, P269; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; [Anonymous], 2023, L2 Speak: Language Immersion; [Anonymous], 2023, Noun Town-the new best way to learn a language; [Anonymous], 2023, AI Town; Bleistein T, 2015, NEW LANG LEARN TEACH, P1; Dow SP, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1879831.1879836; Hamburger Henry, 1992, Foreign Language Tutoring and Learning Environment; Hein Rebecca M., 2021, A systematic review of foreign language learning with immersive technologies (2001-2020); Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Kukulska-Hulme Agnes, 2020, CALL for widening participation: short papers from EUROCALL 2020; Lauf Carlye, 2021, SSRN Electronic Journal, DOI [10.2139/ssrn.3860569, DOI 10.2139/SSRN.3860569]; Lee J, 2023, Arxiv, DOI arXiv:2305.10436; MACINTYRE PD, 1989, LANG LEARN, V39, P251, DOI 10.1111/j.1467-1770.1989.tb00423.x; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Shekary M, 2006, MOD LANG J, V90, P557, DOI 10.1111/j.1540-4781.2006.00504.x; Swain M, 1998, MOD LANG J, V82, P320, DOI 10.2307/329959; Whitehouse C, 2023, Arxiv, DOI arXiv:2305.14288; Zainuddin Z, 2020, EDUC RES REV-NETH, V30, DOI 10.1016/j.edurev.2020.100326; Zhang L, 2023, Arxiv, DOI arXiv:2302.05543; Zhang X, 2023, Arxiv, DOI arXiv:2305.16339	21	0	0	13	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									120	10.1145/3586182.3625117	http://dx.doi.org/10.1145/3586182.3625117			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000119
J	Dos Santos, FC; Johnson, LG; Madandola, OO; Priola, KJB; Yao, YW; Macieira, TGR; Keenan, GM				Dos Santos, Fabiana C.; Johnson, Lisa G.; Madandola, Olatunde O.; Priola, Karen J. B.; Yao, Yingwei; Macieira, Tamara G. R.; Keenan, Gail M.			An example of leveraging AI for documentation: ChatGPT-generated nursing care plan for an older adult with lung cancer	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						artificial intelligence; large language model; cancer; nursing; standardized nursing terminologies		Objective Our article demonstrates the effectiveness of using a validated framework to create a ChatGPT prompt that generates valid nursing care plan suggestions for one hypothetical older patient with lung cancer.Method This study describes the methodology for creating ChatGPT prompts that generate consistent care plan suggestions and its application for a lung cancer case scenario. After entering a nursing assessment of the patient's condition into ChatGPT, we asked it to generate care plan suggestions. Subsequently, we assessed the quality of the care plans produced by ChatGPT.Results While not all the suggested care plan terms (11 out of 16) utilized standardized nursing terminology, the ChatGPT-generated care plan closely matched the gold standard in scope and nature, correctly prioritizing oxygenation and ventilation needs.Conclusion Using a validated framework prompt to generate nursing care plan suggestions with ChatGPT demonstrates its potential value as a decision support tool for optimizing cancer care documentation.	[Dos Santos, Fabiana C.] Columbia Univ, Sch Nursing, 560 W 168th St, New York, NY 10032 USA; [Johnson, Lisa G.; Madandola, Olatunde O.; Priola, Karen J. B.; Macieira, Tamara G. R.; Keenan, Gail M.] Univ Florida, Coll Nursing, Dept Family Community & Hlth Syst Sci, Gainesville, FL 32610 USA; [Yao, Yingwei] Univ Florida, Coll Nursing, Dept Biobehav Nursing Sci, Gainesville, FL 32610 USA	Columbia University; State University System of Florida; University of Florida; State University System of Florida; University of Florida	Dos Santos, FC (corresponding author), Columbia Univ, Sch Nursing, 560 W 168th St, New York, NY 10032 USA.	fcd2114@cumc.columbia.edu		Dos Santos, Fabiana Cristina/0000-0001-9780-4336; Goncalves Rezende Macieira, Tamara/0000-0003-1100-3760; Madandola, Olatunde/0000-0002-8849-8434	National Institutes of Health (NIH); National Institute of Nursing Research (NINR) [1R01NR018416-01]; National Institute on Aging (NIA) [R21AG072265/R33AG072265]	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institute of Nursing Research (NINR)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Nursing Research (NINR)); National Institute on Aging (NIA)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	This work was funded by the National Institutes of Health (NIH), National Institute of Nursing Research (NINR) (1R01NR018416-01) and the National Institute on Aging (NIA) (R21AG072265/R33AG072265). Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the NIH, NINR or NIA	Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; American Cancer Society, Lung cancer survival rates; [Anonymous], 2005, Healthcare Benchmarks Qual Improv, V12, P40; [Anonymous], 2018, Nursing diagnoses: definitions and classification; [Anonymous], 2019, Key statistics for lung cancer; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Butcher H.K., 2018, Nursing Interventions Classification (NIC), VSeventh, DOI DOI 10.1016/J.OUTLOOK.2018.09.003; Cho I, 2023, J AM MED INFORM ASSN, V30, P1826, DOI 10.1093/jamia/ocad145; Cooley ME, 2015, J PAIN SYMPTOM MANAG, V49, P13, DOI 10.1016/j.jpainsymman.2014.05.003; Elsevier, 2013, Simulation learning system for medical-surgical nursing; GARRETT J.J., 2011, The Elements of User Experience, V2nd; Gosak L, 2024, NURSE EDUC PRACT, V75, DOI 10.1016/j.nepr.2024.103888; Horta W.A., 1975, Revista da Escola de Enfermagem, V9, P300, DOI DOI 10.1590/0080-6234197500900200300; Huang SG, 2023, SEMIN CANCER BIOL, V89, P30, DOI 10.1016/j.semcancer.2023.01.006; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kutney-Lee A, 2021, MED CARE, V59, P625, DOI 10.1097/MLR.0000000000001536; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Moorhead S., 2018, Nursing outcomes classification (NOC): Measurement of health outcomes, V6th ed.).; Moy AJ, 2023, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocad038; OpenAI, 2023, OpenAI; openai, ChatGPT: Optimizing language models for dialogue; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Topaz Maxim, 2024, J Nurs Educ, P1, DOI 10.3928/01484834-20240126-01; Wang L, 2024, JMIR FORM RES, V8, DOI 10.2196/53216; Ye Y., 2023, MedcommFuture Medicine, DOI [10.1002/mef2.51, DOI 10.1002/MEF2.51]; Yen Po-Yin, 2018, AMIA Annu Symp Proc, V2018, P1137	31	0	0	5	5	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 MAY 17	2024										10.1093/jamia/ocae116	http://dx.doi.org/10.1093/jamia/ocae116		MAY 2024	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RA2H8	38758655				2024-07-03	WOS:001224882500001
J	Abujaber, AA; Abd-alrazaq, A; Al-Qudimat, AR; Nashwan, AJ				Abujaber, Ahmad A.; Abd-alrazaq, Alaa; Al-Qudimat, Ahmad R.; Nashwan, Abdulqadir J.			A Strengths, Weaknesses, Opportunities, and Threats (SWOT) Analysis of ChatGPT Integration in Nursing Education: A Narrative Review	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Review						swot analysis; nursing education; large language models; gpt-4; chatgpt		Amidst evolving healthcare demands, nursing education plays a pivotal role in preparing future nurses for complex challenges. Traditional approaches, however, must be revised to meet modern healthcare needs. The ChatGPT, an AI-based chatbot, has garnered significant attention due to its ability to personalize learning experiences, enhance virtual clinical simulations, and foster collaborative learning in nursing education. This review aims to thoroughly assess the potential impact of integrating ChatGPT into nursing education. The hypothesis is that valuable insights can be provided for stakeholders through a comprehensive SWOT analysis examining the strengths, weaknesses, opportunities, and threats associated with ChatGPT. This will enable informed decisions about its integration, prioritizing improved learning outcomes. A thorough narrative literature review was undertaken to provide a solid foundation for the SWOT analysis. The materials included scholarly articles and reports, which ensure the study's credibility and allow for a holistic and unbiased assessment. The analysis identified accessibility, consistency, adaptability, cost-effectiveness, and staying up-to-date as crucial factors influencing the strengths, weaknesses, opportunities, and threats associated with ChatGPT integration in nursing education. These themes provided a framework to understand the potential risks and benefits of integrating ChatGPT into nursing education. This review highlights the importance of responsible and effective use of ChatGPT in nursing education and the need for collaboration among educators, policymakers, and AI developers. Addressing the identified challenges and leveraging the strengths of ChatGPT can lead to improved learning outcomes and enriched educational experiences for students. The findings emphasize the importance of responsibly integrating ChatGPT in nursing education, balancing technological advancement with careful consideration of associated risks, to achieve optimal outcomes.	[Abujaber, Ahmad A.; Nashwan, Abdulqadir J.] Hamad Med Corp, Dept Nursing, Doha, Qatar; [Abd-alrazaq, Alaa] Weill Cornell Med Qatar, AI Ctr Precis Hlth, Doha, Qatar; [Al-Qudimat, Ahmad R.] Qatar Univ, Dept Publ Hlth, Doha, Qatar; [Al-Qudimat, Ahmad R.] Hamad Med Corp, Dept Surg, Surg Res Sect, Doha, Qatar	Hamad Medical Corporation; Qatar Foundation (QF); Weill Cornell Medical College Qatar; Qatar University; Hamad Medical Corporation	Abujaber, AA (corresponding author), Hamad Med Corp, Dept Nursing, Doha, Qatar.	anashwan@hamad.qa	Abd-Alrazaq, Alaa Ali/ABE-3043-2021; ABUJABER, AHMAD/KIB-2200-2024; Alqudimat, Ahmad/KHY-8085-2024; Nashwan, Abdulqadir J./J-6241-2019	Abd-Alrazaq, Alaa Ali/0000-0001-7695-4626; ABUJABER, AHMAD/0000-0002-8704-4991; Nashwan, Abdulqadir J./0000-0003-4845-4119					0	1	2	25	25	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	NOV 11	2023	15	11							e48643	10.7759/cureus.48643	http://dx.doi.org/10.7759/cureus.48643			12	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Y6RC2	38090452	Green Published, gold			2024-07-03	WOS:001106501800008
J	Skalidis, I; Cagnina, A; Luangphiphat, W; Mahendiran, T; Muller, O; Abbe, E; Fournier, S				Skalidis, Ioannis; Cagnina, Aurelien; Luangphiphat, Wongsakorn; Mahendiran, Thabo; Muller, Olivier; Abbe, Emmanuel; Fournier, Stephane			ChatGPT takes on the European Exam in Core Cardiology: an artificial intelligence success story?	EUROPEAN HEART JOURNAL - DIGITAL HEALTH			English	Article						Artificial Intelligence; ChatGPT; Medical education; Machine learning; Large language models		Chat Generative Pre-trained Transformer (ChatGPT) is currently a trending topic worldwide triggering extensive debate about its predictive power, its potential uses, and its wider implications. Recent publications have demonstrated that ChatGPT can correctly answer questions from undergraduate exams such as the United States Medical Licensing Examination. We challenged it to answer questions from a more demanding, post-graduate exam-the European Exam in Core Cardiology (EECC), the final exam for the completion of specialty training in Cardiology in many countries. Our results demonstrate that ChatGPT succeeds in the EECC.	[Skalidis, Ioannis; Cagnina, Aurelien; Luangphiphat, Wongsakorn; Mahendiran, Thabo; Muller, Olivier; Fournier, Stephane] Univ Hosp Lausanne, Cardiol Dept, Rue Bugnon 46, CH-1011 Lausanne, Switzerland; [Mahendiran, Thabo; Abbe, Emmanuel] EPFL FSB SMA, Inst Math, EPFL, Stn 8, CH-1015 Lausanne, Switzerland; [Mahendiran, Thabo; Abbe, Emmanuel] EPFL FSB SMA, Sch Comp & Commun Sci, EPFL, Stn 8, CH-1015 Lausanne, Switzerland	University of Lausanne; Centre Hospitalier Universitaire Vaudois (CHUV); Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Fournier, S (corresponding author), Univ Hosp Lausanne, Cardiol Dept, Rue Bugnon 46, CH-1011 Lausanne, Switzerland.	stephane.fournier@chuv.ch		Muller, Olivier/0000-0003-2441-5799; Fournier, Stephane/0000-0002-9422-9521				Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Chatterjee J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2022.100676; Christian Terwiesch, Would Chat GPT get a Wharton MBA? A prediction based on its performance in the Operations Management course; escardio.org, About the European Exam in Core Cardiology (EECC); Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu PR, 2021, CURR MED SCI, V41, P1105, DOI 10.1007/s11596-021-2474-3; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	10	35	35	8	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND		2634-3916		EUR HEART J-DIGIT HL	Eur. Heart. J.-Digit. Health	JUN 1	2023	4	3					279	281		10.1093/ehjdh/ztad029	http://dx.doi.org/10.1093/ehjdh/ztad029			3	Cardiac & Cardiovascular Systems	Emerging Sources Citation Index (ESCI)	Cardiovascular System & Cardiology	CX2U8	37265864	gold, Green Published, Green Submitted			2024-07-03	WOS:001128475300007
J	Tao, KM; Osman, ZA; Tzou, PL; Rhee, SY; Ahluwalia, V; Shafer, RW				Tao, Kaiming; Osman, Zachary A.; Tzou, Philip L.; Rhee, Soo-Yon; Ahluwalia, Vineet; Shafer, Robert W.			GPT-4 performance on querying scientific publications: reproducibility, accuracy, and impact of an instruction sheet	BMC MEDICAL RESEARCH METHODOLOGY			English	Article						Large language model; HIV drug resistance; Systematic review; GPT-4; Data extraction		BackgroundLarge language models (LLMs) that can efficiently screen and identify studies meeting specific criteria would streamline literature reviews. Additionally, those capable of extracting data from publications would enhance knowledge discovery by reducing the burden on human reviewers.MethodsWe created an automated pipeline utilizing OpenAI GPT-4 32 K API version "2023-05-15" to evaluate the accuracy of the LLM GPT-4 responses to queries about published papers on HIV drug resistance (HIVDR) with and without an instruction sheet. The instruction sheet contained specialized knowledge designed to assist a person trying to answer questions about an HIVDR paper. We designed 60 questions pertaining to HIVDR and created markdown versions of 60 published HIVDR papers in PubMed. We presented the 60 papers to GPT-4 in four configurations: (1) all 60 questions simultaneously; (2) all 60 questions simultaneously with the instruction sheet; (3) each of the 60 questions individually; and (4) each of the 60 questions individually with the instruction sheet.ResultsGPT-4 achieved a mean accuracy of 86.9% - 24.0% higher than when the answers to papers were permuted. The overall recall and precision were 72.5% and 87.4%, respectively. The standard deviation of three replicates for the 60 questions ranged from 0 to 5.3% with a median of 1.2%. The instruction sheet did not significantly increase GPT-4's accuracy, recall, or precision. GPT-4 was more likely to provide false positive answers when the 60 questions were submitted individually compared to when they were submitted together.ConclusionsGPT-4 reproducibly answered 3600 questions about 60 papers on HIVDR with moderately high accuracy, recall, and precision. The instruction sheet's failure to improve these metrics suggests that more sophisticated approaches are necessary. Either enhanced prompt engineering or finetuning an open-source model could further improve an LLM's ability to answer questions about highly specialized HIVDR papers.	[Tao, Kaiming; Osman, Zachary A.; Tzou, Philip L.; Rhee, Soo-Yon; Shafer, Robert W.] Stanford Univ, Dept Med, Div Infect Dis, Stanford, CA 94305 USA; [Ahluwalia, Vineet] Aphorism Labs, Palo Alto, CA USA	Stanford University	Shafer, RW (corresponding author), Stanford Univ, Dept Med, Div Infect Dis, Stanford, CA 94305 USA.	rshafer@stanford.edu			National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was funded by a grant from the National Institutes of Health:	Alshami A, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11070351; Blaizot A, 2022, RES SYNTH METHODS, V13, P353, DOI 10.1002/jrsm.1553; dos Santos AO, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104389; Guo E, 2023, Arxiv, DOI arXiv:2305.00844; Jimenez RC, 2022, BMC MED RES METHODOL, V22, DOI 10.1186/s12874-022-01805-4; Jin Q, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad651; Kandpal N, 2023, Arxiv, DOI [arXiv:2211.08411, 10.48550/arXiv.2211.08411]; Kassaye SG, 2016, CLIN INFECT DIS, V63, P836, DOI 10.1093/cid/ciw382; Khraisha Q, 2023, Arxiv, DOI [arXiv:2310.17526, DOI 10.48550/ARXIV.2310.17526]; Liang WX, 2023, Arxiv, DOI arXiv:2310.01783; Liu R, 2023, Arxiv, DOI arXiv:2306.00622; Schopow N, 2023, JMIR MED INF, V11, DOI 10.2196/48933; Syriani E., 2023, arXiv; Tao KM, 2023, VIRUSES-BASEL, V15, DOI 10.3390/v15091932; van de Schoot R, 2021, NAT MACH INTELL, V3, P125, DOI 10.1038/s42256-020-00287-7; van Dijk SHB, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2023-072254; Weissenbacher D, 2023, medRxiv, DOI [10.1101/2023.07.29.23293370, 10.1101/2023.07.29.23293370v1, DOI 10.1101/2023.07.29.23293370V1]; Zhang Z., 2022, arXiv	18	0	0	0	0	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1471-2288		BMC MED RES METHODOL	BMC Med. Res. Methodol.	JUN 25	2024	24	1							139	10.1186/s12874-024-02253-y	http://dx.doi.org/10.1186/s12874-024-02253-y			10	Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services	WI1Y8	38918736	gold			2024-07-03	WOS:001254161100001
J	Akinboyewa, T; Ning, H; Lessani, MN; Li, ZL				Akinboyewa, Temitope; Ning, Huan; Lessani, M. Naser; Li, Zhenlong			Automated floodwater depth estimation using large multimodal model for rapid flood mapping	COMPUTATIONAL URBAN SCIENCE			English	Article						Flood mapping; Large multimodal model; Large language model; ChatGPT; GeoAI; Disaster management	SOCIAL MEDIA; WATER-LEVEL; IMAGES	Information on the depth of floodwater is crucial for rapid mapping of areas affected by floods. However, previous approaches for estimating floodwater depth, including field surveys, remote sensing, and machine learning techniques, can be time-consuming and resource-intensive. This paper presents an automated and rapid approach for estimating floodwater depth from on-site flood photos. A pre-trained large multimodal model, Generative pre-trained transformers (GPT-4) Vision, was used specifically for estimating floodwater. The input data were flood photos that contained referenced objects, such as street signs, cars, people, and buildings. Using the heights of the common objects as references, the model returned the floodwater depth as the output. Results show that the proposed approach can rapidly provide a consistent and reliable estimation of floodwater depth from flood photos. Such rapid estimation is transformative in flood inundation mapping and assessing the severity of the flood in near-real time, which is essential for effective flood response strategies.	[Akinboyewa, Temitope; Ning, Huan; Lessani, M. Naser; Li, Zhenlong] Penn State Univ, Dept Geog, Geoinformat & Big Data Res Lab, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Li, ZL (corresponding author), Penn State Univ, Dept Geog, Geoinformat & Big Data Res Lab, University Pk, PA 16802 USA.	zhenlong@psu.edu						Athira S., 2023, Flood modelling and inundation mapping of Meenachil river using HEC-RAS and HEC-HMS software, P113, DOI [10.1007/978-3-031-26967-79, DOI 10.1007/978-3-031-26967-79]; Bentivoglio R, 2022, HYDROL EARTH SYST SC, V26, P4345, DOI 10.5194/hess-26-4345-2022; Bovenga F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051359; Brunner GaryW., 2016, HEC-RAS River Analysis System: Hydraulic Reference Manual, Version 5.0, P547; Chaudhary P, 2020, ISPRS J PHOTOGRAMM, V167, P252, DOI 10.1016/j.isprsjprs.2020.07.003; Chaudhary P., 2019, Flood-Water Level Estimation from Social Media Images, P4; Cian F, 2018, NAT HAZARD EARTH SYS, V18, P3063, DOI 10.5194/nhess-18-3063-2018; Cohen S, 2018, J AM WATER RESOUR AS, V54, P847, DOI 10.1111/1752-1688.12609; Crooks A, 2024, ENVIRON PLAN B-URBAN, V51, P565, DOI 10.1177/23998083241235495; Elkhrachy I, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030440; Feng Y, 2020, ISPRS J PHOTOGRAMM, V169, P301, DOI 10.1016/j.isprsjprs.2020.09.011; Fohringer J, 2015, NAT HAZARD EARTH SYS, V15, P2725, DOI 10.5194/nhess-15-2725-2015; Fryar C D., 2021, Vital health statistics. Series 3, P1; Haq T., 2020, Flood routing model using integration of Delft3D and GIS (case study: Tanggul watershed, DOI [10.1063/5.0014607, DOI 10.1063/5.0014607]; Haydari A., 2024, MobilityGPT: Enhanced Human Mobility Modeling with a GPT model, P1, DOI [10.48550/arxiv.org/abs/2402.03264, DOI 10.48550/ARXIV.ORG/ABS/2402.03264]; Hu YJ, 2023, INT J GEOGR INF SCI, V37, P2289, DOI 10.1080/13658816.2023.2266495; Huang C., 2023, Large foundation models for power systems, P1, DOI [10.48550/arXiv.2312.07044, DOI 10.48550/ARXIV.2312.07044]; Huang X, 2019, INT J DIGIT EARTH, V12, P1248, DOI 10.1080/17538947.2018.1523956; Huang X, 2020, INT J DIGIT EARTH, V13, P1017, DOI 10.1080/17538947.2019.1633425; Jianfeng Li, 2021, Journal of Physics: Conference Series, V1952, DOI 10.1088/1742-6596/1952/2/022051; Kharazi BA, 2021, COMPUT ENVIRON URBAN, V88, DOI 10.1016/j.compenvurbsys.2021.101628; Li JR, 2023, MEASUREMENT, V216, DOI 10.1016/j.measurement.2023.112891; Li X, 2024, Arxiv, DOI arXiv:2305.05726; Li ZL, 2023, INT J DIGIT EARTH, V16, P4668, DOI 10.1080/17538947.2023.2278895; Li ZL, 2018, CARTOGR GEOGR INF SC, V45, P97, DOI 10.1080/15230406.2016.1271356; Manjusree P, 2012, INT J DISAST RISK SC, V3, P113, DOI 10.1007/s13753-012-0011-5; Meghanadh D, 2020, INT GEOSCI REMOTE SE, P6883, DOI 10.1109/IGARSS39084.2020.9324674; Meng ZL, 2019, ARIC 2019: PROCEEDINGS OF THE 2ND ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON ADVANCES IN RESILIENT AND INTELLIGENT CITIES (ARIC-2019), P37, DOI 10.1145/3356395.3365542; Neighbor Storage, 2023, Average car sizes: length, width, and height; Nguyen NY, 2016, HYDROL RES LETT, V10, P39, DOI 10.3178/hrl.10.39; Ning H, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9020104; OpenAI, 2023, Gpt-4 technical report, P1, DOI DOI 10.48550/ARXIV.2303.08774; Osco LP, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15133232; Pan J, 2018, IEEE ACCESS, V6, P73561, DOI 10.1109/ACCESS.2018.2883702; Park S, 2021, J COMPUT CIVIL ENG, V35, DOI 10.1061/(ASCE)CP.1943-5487.0000956; Quan Khanh-An C., 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P479, DOI 10.1145/3372278.3390704; Schumann GJP, 2014, NATURE, V507, P169, DOI 10.1038/507169e; Song ZQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165614; Surampudi S, 2023, IEEE ACCESS, V11, P3241, DOI 10.1109/ACCESS.2023.3234742; Tabari H, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70816-2; Tao R, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12070284; US Department of Transportation Federal Highway Administration, 2023, Manual on Uniform traffic Control devices; Wang D., 2023, ACM Transactions on Spatial Algorithms and Systems, V9, P1, DOI DOI 10.1145/3524302; Yin YZ, 2022, WATER-SUI, V14, DOI 10.3390/w14050683; Yoon S, 2021, AAAI CONF ARTIF INTE, V35, P10718; Zhang CQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2425, DOI 10.1145/3394486.3403292; Zhang S., 2023, TrafficGPT: viewing, processing and interacting with traffic foundation models, P1	47	1	1	5	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2730-6852		COMPUT URBAN SCI	Comput. Urban Sci.	MAY 27	2024	4	1							12	10.1007/s43762-024-00123-3	http://dx.doi.org/10.1007/s43762-024-00123-3			19	Computer Science, Interdisciplinary Applications; Regional & Urban Planning	Emerging Sources Citation Index (ESCI)	Computer Science; Public Administration	SE7T9		gold, Green Submitted			2024-07-03	WOS:001232854700001
J	Liu, HY; Wang, PC; Xu, F; Nie, QX; Yan, S; Zhang, ZP; Zhang, Y; Jiang, CT; Qin, XM; Pang, YL				Liu, Huiying; Wang, Pengcheng; Xu, Feng; Nie, Qixing; Yan, Sen; Zhang, Zhipeng; Zhang, Yi; Jiang, Changtao; Qin, Xiaomei; Pang, Yanli			The Hydrophilic Metabolite UMP Alleviates Obesity Traits through a HIF2α-ACER2-Ceramide Signaling Axis	ADVANCED SCIENCE			English	Article						ceramide; HIF2 alpha; obesity; pyrimidine; UMP	SERUM METABOLOME; SPHINGOLIPIDS; MICE; FAT	Metabolic abnormalities contribute to the pathogenesis of obesity and its complications. Yet, the understanding of the interactions between critical metabolic pathways that underlie obesity remains to be improved, in part owing to the lack of comprehensive metabolomics studies that reconcile data from both hydrophilic and lipophilic metabolome analyses that can lead to the identification and characterization of key signaling networks. Here, the study conducts a comprehensive metabolomics analysis, surveying lipids and hydrophilic metabolites of the plasma and omental adipose tissue of obese individuals and the plasma and epididymal adipose tissue of mice. Through these approaches, it is found that a significant accumulation of ceramide due to inhibited sphingolipid catabolism, while a significant reduction in the levels of uridine monophosphate (UMP), is critical to pyrimidine biosynthesis. Further, it is found that UMP administration restores sphingolipid homeostasis and can reduce obesity in mice by reversing obesity-induced inhibition of adipocyte hypoxia inducible factor 2a (Hif2 alpha) and its target gene alkaline ceramidase 2 (Acer2), so as to promote ceramide catabolism and alleviate its accumulation within cells. Using adipose tissue Hif2 alpha-specific knockout mice, the study further demonstrates that the presence of UMP can alleviate obesity through a HIF2 alpha-ACER2-ceramide pathway, which can be a new signaling axis for obesity improvement.	[Liu, Huiying; Xu, Feng; Nie, Qixing; Jiang, Changtao; Qin, Xiaomei] Peking Univ, Sch Basic Med Sci, Dept Physiol & Pathophysiol, State Key Lab Vasc Homeostasis & Remodeling, Beijing 100191, Peoples R China; [Liu, Huiying; Xu, Feng; Nie, Qixing; Jiang, Changtao] Peking Univ, Sch Basic Med Sci, Ctr Obes & Metab Dis Res, Beijing 100191, Peoples R China; [Wang, Pengcheng; Jiang, Changtao] Peking Univ, Hosp 3, Ctr Basic Med Res, Inst Med Innovat & Res, Beijing 100191, Peoples R China; [Xu, Feng] Janssen China Res & Dev, Clin Pharmacol & Pharmacometr, Beijing 100191, Peoples R China; [Nie, Qixing] Nanchang Univ, State Key Lab Food Sci & Resources, Key Lab Bioact Polysaccharides Jiangxi Prov, China Canada Joint Lab Food Sci & Technol, Nanchang 330013, Peoples R China; [Yan, Sen; Pang, Yanli] Peking Univ Third Hosp, Ctr Reprod Med, Dept Obstet & Gynecol, State Key Lab Female Fertil Preservat & Promot, Beijing 100191, Peoples R China; [Zhang, Zhipeng; Zhang, Yi] Peking Univ, Hosp 3, Gen Surg Dept, Beijing 100191, Peoples R China; [Jiang, Changtao] Peking Univ, Sch Basic Med Sci, Dept Immunol, NHC Key Lab Med Immunol, Beijing 100191, Peoples R China	Peking University; Peking University; Peking University; Nanchang University; Peking University; Peking University	Pang, YL (corresponding author), Peking Univ Third Hosp, Ctr Reprod Med, Dept Obstet & Gynecol, State Key Lab Female Fertil Preservat & Promot, Beijing 100191, Peoples R China.	yanlipang@bjmu.edu.cn	Zhang, Zhipeng/KHY-2239-2024		National Key Research and Development Program of China; National Natural Science Foundation of the People's Republic of China [31925021, 82022028, 82171627, 82130022, 81921001, 92149306, 32200949, 32202020, 82288102, 82301841]; Tencent Foundation through the Xplorer Prize [5Vu8Zs7P];  [2018YFA0800700];  [2022YFA0806403]	National Key Research and Development Program of China; National Natural Science Foundation of the People's Republic of China(National Natural Science Foundation of China (NSFC)); Tencent Foundation through the Xplorer Prize; ; 	This work was supported by the National Natural Science Foundation of the People's Republic of China (nos 31925021, 82022028, 82171627, 82130022, 81921001, 92149306, 32200949, 32202020, 82288102, and 82301841) and the National Key Research and Development Program of China (no.2018YFA0800700, 2022YFA0806403). C.T.J. acknowledges the support from the Tencent Foundation through the Xplorer Prize. Xin Du and Julian Heng (Remotely Consulting, Australia) provided professional English-language editing of this article (Manuscript Certificate No. 5Vu8Zs7P). No Artificial Intelligence (AI) writing tools or Large Language Models (LLMs) (for example, ChatGPT) were used in the editing provided by the team at Remotely Consulting.	Alvarez-Sabín J, 2013, BRAIN SCI, V3, P1395, DOI 10.3390/brainsci3031395; Ben-Sahra I, 2013, SCIENCE, V339, P1323, DOI 10.1126/science.1228792; Butte NF, 2015, AM J CLIN NUTR, V102, P256, DOI 10.3945/ajcn.115.111872; Chaurasia B, 2021, ANNU REV PHYSIOL, V83, P303, DOI 10.1146/annurev-physiol-031620-093815; Chen B, 2022, NATURE, V610, P562, DOI 10.1038/s41586-022-05299-4; Chen HH, 2015, INT J OBESITY, V39, P1241, DOI 10.1038/ijo.2015.65; Chiang JYL, 2009, J LIPID RES, V50, P1955, DOI 10.1194/jlr.R900010-JLR200; Choi CS, 2008, P NATL ACAD SCI USA, V105, P19926, DOI 10.1073/pnas.0810339105; Cirulli ET, 2019, CELL METAB, V29, P488, DOI 10.1016/j.cmet.2018.09.022; Eguchi J, 2011, CELL METAB, V13, P249, DOI 10.1016/j.cmet.2011.02.005; FOLCH J, 1957, J BIOL CHEM, V226, P497; Gogna N, 2015, MOL BIOSYST, V11, P595, DOI 10.1039/c4mb00507d; Hannun YA, 2018, NAT REV MOL CELL BIO, V19, P175, DOI 10.1038/nrm.2017.107; Ho JE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148361; Hu LL, 2020, MASS SPECTROM REV, V39, P417, DOI 10.1002/mas.21611; Huang H, 2016, SCI REP-UK, V6, DOI 10.1038/srep34684; Iqbal J, 2017, TRENDS ENDOCRIN MET, V28, P506, DOI 10.1016/j.tem.2017.03.005; Jayashankar V, 2021, EMBO MOL MED, V13, DOI 10.15252/emmm.202013086; Lam SM, 2018, ANAL CHIM ACTA, V1037, P152, DOI 10.1016/j.aca.2018.01.015; Liu RX, 2017, NAT MED, V23, P859, DOI 10.1038/nm.4358; Liu YL, 2021, FOOD FUNCT, V12, P1829, DOI [10.1039/d0fo02533j, 10.1039/D0FO02533J]; Menni C, 2017, OBESITY, V25, P1618, DOI 10.1002/oby.21922; NCD Risk Factor Collaboration (NCD-RisC), 2016, Lancet, V387, P1377, DOI 10.1016/S0140-6736(16)30054-X; Neeland IJ, 2018, CIRCULATION, V137, P1391, DOI 10.1161/CIRCULATIONAHA.117.029617; Okesli A, 2017, CURR OPIN BIOTECH, V48, P127, DOI 10.1016/j.copbio.2017.03.010; Ottosson F, 2022, DIABETES CARE, V45, P1260, DOI 10.2337/dc21-2402; Park S, 2015, MOL CELLS, V38, P587, DOI 10.14348/molcells.2015.0126; Pedersen HK, 2016, NATURE, V535, P376, DOI 10.1038/nature18646; Raichur S, 2019, MOL METAB, V21, P36, DOI 10.1016/j.molmet.2018.12.008; Roberts LD, 2014, CELL METAB, V19, P96, DOI 10.1016/j.cmet.2013.12.003; Robitaille AM, 2013, SCIENCE, V339, P1320, DOI 10.1126/science.1228771; Scheltens P, 2012, J ALZHEIMERS DIS, V31, P225, DOI 10.3233/JAD-2012-121189; SEMENZA GL, 1992, MOL CELL BIOL, V12, P5447, DOI 10.1128/MCB.12.12.5447; Siddiqui A, 2020, MOL METAB, V35, DOI 10.1016/j.molmet.2020.02.005; Sohn JH, 2023, CELL METAB, V35, P1356, DOI 10.1016/j.cmet.2023.06.015; Turpin-Nolan SM, 2020, NAT REV ENDOCRINOL, V16, P224, DOI 10.1038/s41574-020-0320-5; Wang PC, 2022, ACTA PHARM SIN B, V12, P1899, DOI 10.1016/j.apsb.2021.10.001; Whitlock G, 2009, LANCET, V373, P1083, DOI 10.1016/S0140-6736(09)60318-4; Wu Q, 2021, J CLIN INVEST, V131, DOI 10.1172/JCI142865; Xie C, 2017, NAT MED, V23, P1298, DOI 10.1038/nm.4412; Xie C, 2017, DIABETES, V66, P613, DOI 10.2337/db16-0663; Xu F, 2022, FOOD CHEM, V373, DOI 10.1016/j.foodchem.2021.131405; Zhang XZ, 2019, CELL METAB, V30, P937, DOI 10.1016/j.cmet.2019.09.016; Zheng XJ, 2021, CELL METAB, V33, P791, DOI 10.1016/j.cmet.2020.11.017; Zhou JT, 2016, ANAL CHEM, V88, P4478, DOI 10.1021/acs.analchem.6b00355	45	0	0	9	9	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2198-3844		ADV SCI	Adv. Sci.	JUN	2024	11	21								10.1002/advs.202309525	http://dx.doi.org/10.1002/advs.202309525		MAR 2024	14	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science	TG4W2	38460165	gold			2024-07-03	WOS:001181622900001
J	Miller, LE; Bhattacharyya, D; Miller, VM; Bhattacharyya, M				Miller, Larry E.; Bhattacharyya, Debjani; Miller, Valerie M.; Bhattacharyya, Mehul			Recent Trend in Artificial Intelligence-Assisted Biomedical Publishing: A Quantitative Bibliometric Analysis	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Review						references; machine learning; large language model; chatgpt; artificial intelligence	CHATGPT	The rapid advancements in artificial intelligence (AI) technology in recent years have led to its integration into biomedical publishing. However, the extent to which AI has contributed to developing biomedical literature is unclear. This study aimed to identify trends in AI-generated content within peer-reviewed biomedical literature. We first tested the sensitivity and specificity of commercially available AI-detection software (Originality.AI, Collingwood, Ontario, Canada). Next, we conducted a MEDLINE (Medical Literature Analysis and Retrieval System Online) search to identify randomized controlled trials with available abstracts indexed between January 2020 and March 2023. We randomly selected 30 abstracts per quarter during this period and pasted the abstracts into the AI detection software to determine the probability of AI-generated content. The software yielded 100% sensitivity, 95% specificity, and excellent overall discriminatory ability with an area under the receiving operating curve of 97.6%. Among the 390 MEDLINE-indexed abstracts included in the analysis, the prevalence with a high probability (>= 90%) of AI-generated text increased during the study period from 21.7% to 36.7% (p=0.01) based on a chi-square test for trend. The increasing prevalence of AI-generated text during the study period was also observed in various sensitivity analyses using AI probability thresholds ranging from 50% to 99% (all p <= 0.01). The results of this study suggest that the prevalence of AI-assisted publishing in peer-reviewed journals has been increasing in recent years, even before the widespread adoption of ChatGPT (OpenAI, San Francisco, California, United States) and similar tools. The extent to which natural writing characteristics of the authors, utilization of common AI-powered applications, and introduction of AI elements during the post-acceptance publication phase influence AI detection scores warrants further study.	[Miller, Larry E.; Bhattacharyya, Mehul] Miller Sci, Clin Res, Johnson City, TN 37604 USA; [Bhattacharyya, Debjani] Univ Massachusetts Lowell, Educ, Lowell, MA USA; [Miller, Valerie M.] Univ Cumberlands, Williamsburg, VA USA	University of Massachusetts System; University of Massachusetts Lowell	Miller, LE (corresponding author), Miller Sci, Clin Res, Johnson City, TN 37604 USA.	larry@millerscientific.com						AI content detection accuracy-GPTZero vs Writer vs Open AI vs CopyLeaks vs Originality, 2023, AI DETECTING CHATGPT; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, INTR MICR 365 COP YO; [Anonymous], 2022, OpenAI; [Anonymous], 2023, CHATGPT PASS 1 BILL; [Anonymous], 2023, CHATB CHATGPT SCHOL; [Anonymous], 2018, NOV TECHS KAT TAYL F; [Anonymous], 2020, NEW AI TOOLS HELP WR; [Anonymous], 2020, GOOGL DOCS LAT SMART; [Anonymous], 2019, WE USE AI ENHANCE YO; [Anonymous], 2023, AUTHORSHIP AI TOOLS; Buriak JM, 2023, ACS NANO, V17, P4091, DOI 10.1021/acsnano.3c01544; Checco A, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-020-00703-8; Chen W, 2023, MOL THER-NUCL ACIDS, V31, P691, DOI 10.1016/j.omtn.2023.02.019; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Enago Author Services, 2023, US; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Knop M, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/28639; Madsen RE, 2005, P 22 INT C MACH LEAR, P545, DOI DOI 10.1145/1102351.1102420; Mrowinski MJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184711; Potocnik J, 2023, J MED IMAGING RADIAT, V54, P376, DOI 10.1016/j.jmir.2023.03.033; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	25	6	6	9	40	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 19	2023	15	5							e39224	10.7759/cureus.39224	http://dx.doi.org/10.7759/cureus.39224			7	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	K0BK7	37337487	gold, Green Published			2024-07-03	WOS:001013185500030
J	Gandolfi, A				Gandolfi, Alberto			GPT-4 in Education: Evaluating Aptness, Reliability, and Loss of Coherence in Solving Calculus Problems and Grading Submissions	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article; Early Access						AI; Large Language Models; ChatGPT; Natural Language Processes; Calculus; Automated Grading		In this paper, we initially investigate the capabilities of GPT-3 5 and GPT-4 in solving college-level calculus problems, an essential segment of mathematics that remains under-explored so far. Although improving upon earlier versions, GPT-4 attains approximately 65% accuracy for standard problems and decreases to 20% for competition-like scenarios. Overall, the models prove to be unreliable due to common arithmetic errors.Our primary contribution lies then in examining the use of ChatGPT for grading solutions to calculus exercises. Our objectives are to probe an in-context learning task with less emphasis over direct calculations; recognize positive applications of ChatGPT in educational contexts; highlight a potentially emerging facet of AI that could necessitate oversight; and introduce unconventional AI benchmarks, for which models like GPT are untrained. Pertaining to the latter, we uncover a tendency for loss of coherence in extended contexts. Our findings suggest that while the current ChatGPT exhibits comprehension of the grading task and often provides relevant outputs, the consistency of grading is marred by occasional loss of coherence and hallucinations. Intriguingly, GPT-4's overall scores, delivered in mere moments, align closely with human graders, although its detailed accuracy remains suboptimal.This work suggests that, when appropriately orchestrated, collaboration between human graders and LLMs like GPT-4 might combine their unique strengths while mitigating their respective shortcomings In this direction, it is imperative to consider implementing transparency, fairness, and appropriate regulations in the near future.	[Gandolfi, Alberto] New York Univ Abu Dhabi, Div Sci, Abu Dhabi 129188, U Arab Emirates	New York University Abu Dhabi	Gandolfi, A (corresponding author), New York Univ Abu Dhabi, Div Sci, Abu Dhabi 129188, U Arab Emirates.	ag189@nyu.edu		Gandolfi, Alberto/0000-0001-6956-7513				[Anonymous], 2023, Chat-GPT-LangChain; AoPSOnline, 2022, 2021 SMT Team Round-Stanford Math Tournament; Baral S., 2023, International Educational Data Mining Society; Baral S., 2021, International Educational Data Mining Society; Baral S, 2022, LECT NOTES COMPUT SC, V13355, P685, DOI 10.1007/978-3-031-11644-5_68; Bhutoria A., 2022, Computers and Education: Artificial Intelligence, V3, P1, DOI DOI 10.1016/J.CAEAI.2022.100068; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Botelho A, 2023, J COMPUT ASSIST LEAR, V39, P823, DOI 10.1111/jcal.12793; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Budhwar P., 2023, Human Resource Management Journal; Calonge D. S., 2023, Journal of Applied Learning and Teaching, V6; Chai FY, 2024, FRONT PSYCHOL, V15, DOI 10.3389/fpsyg.2024.1221177; Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen M., 2021, arXiv; Chlipala A., 2022, Certified programming with dependent types: A pragmatic introduction to the Coq proof assistant; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Crompton H, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00392-8; Crothers E, 2023, Arxiv, DOI arXiv:2210.07321; Dao X.-Q., 2023, Bing Chat, or Bard; Dao XQ, 2023, Arxiv, DOI arXiv:2306.06331; Davis E, 2023, Arxiv, DOI arXiv:2308.05713; de Winter JCF, 2023, INFORMATICS-BASEL, V10, DOI 10.3390/informatics10040087; Dimiceli VE, 2010, INT J MATH EDUC SCI, V41, P1061, DOI 10.1080/0020739X.2010.493241; Erickson JA, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P615, DOI 10.1145/3375462.3375523; European Commission, 2023, Ethical Guidelines on the Use of Artificial Intelligence (AI) and Data in Teaching and Learning for Educators; Fiacco J., 2023, P 18 WORKSH INN US N, P232; Frieder S., 2024, Advances in Neural Information Processing Systems, V36; Gao C. A., 2022, bioRxiv; Gao RJ, 2024, Arxiv, DOI arXiv:2308.16151; Garg S., 2022, Advances in Neural Information Processing Systems, P30583; Ghaith S., 2024, The Triple Attention Transformer: Advancing Contextual Coherence in Transformer Models; Huang J, 2024, Arxiv, DOI arXiv:2310.01798; Ibrahim H, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38964-3; Ilkka T., 2018, The impact of artificial intelligence on learning, teaching, and education; Jacob A., 2023, The Impact of Context Window Limitation on AI and Insights from GPT; Johnson W. L., 2023, International Journal of Artificial Intelligence in Education, P1; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Keely S. J., 2009, Writing Mathematical Expressions in Plain Text-Examples and Cautions; Kumar K, 2023, Arxiv, DOI arXiv:2304.02138; Lewkowycz A., 2022, Advances in Neural Information Processing Systems, P3843; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Yijun, 2020, NAT CCF C NAT LANG P, P3; Mizumoto A., 2023, Research Methods in Applied Linguistics, V2, P100050, DOI DOI 10.1016/J.RMAL.2023.100050; Ndukwe IG, 2019, LECT NOTES ARTIF INT, V11626, P365, DOI 10.1007/978-3-030-23207-8_67; Nilsson F., 2023, GPT-4 as an Automatic Grader: The accuracy of grades set by GPT-4 on introductory programming assignments; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; OpenAI, 2023, : GPT-4 technical report.; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Rhodes S, 2019, PSYCHON B REV, V26, P1529, DOI 10.3758/s13423-019-01649-y; Schneider J, 2023, INT J ARTIF INTELL E, V33, P88, DOI 10.1007/s40593-022-00289-z; Shabrina P., 2023, International Journal of Artificial Intelligence in Education, P1; Srivastava Aarohi, 2022, arXiv; Stewart J., 2020, Calculus: Early transcendentals. International metric edition, V759; Stoica E., 2022, A student's take on challenges of AI-driven grading in higher education; Suzgun Mirac, 2022, arXiv; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tinguely PN, 2023, J ORGAN DES, V12, P263, DOI 10.1007/s41469-023-00153-x; Tiwari Adarsh, 2023, INT C DOC AN REC; Vaswani A, 2017, ADV NEUR IN, V30; Vig J, 2019, Arxiv, DOI arXiv:1906.05714; Wenzel M, 2008, LECT NOTES COMPUT SC, V5170, P33, DOI 10.1007/978-3-540-71067-7_7; Yuan WZ, 2022, J ARTIF INTELL RES, V75, P171; Zhang MX, 2022, Arxiv, DOI arXiv:2205.15219; Zhang TJ, 2023, Arxiv, DOI arXiv:2305.18583; Zhou JL, 2023, Arxiv, DOI arXiv:2305.10646	67	0	0	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	2024 MAY 5	2024										10.1007/s40593-024-00403-3	http://dx.doi.org/10.1007/s40593-024-00403-3		MAY 2024	31	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	PN1C0		hybrid			2024-07-03	WOS:001214654500002
J	Gupta, B; Mufti, T; Sohail, SS; Madsen, DO				Gupta, Bulbul; Mufti, Tabish; Sohail, Shahab Saquib; Madsen, Dag Oivind			ChatGPT: A brief narrative review	COGENT BUSINESS & MANAGEMENT			English	Review						ChatGpt; artificial intelligence; generative artificial intelligence; machine learning; large language models		In this study, we present a brief narrative review focused on ChatGPT, a state-of-the-art conversational agent developed using OpenAI's Generative Pretrained Transformer (GPT) framework. Distinctive for its ability to generate text of high quality in real-time, ChatGPT has emerged as a leader among artificial intelligence chatbots, garnering interest from both commercial and scholarly circles. Our review explores the technological underpinnings of ChatGPT, examines its inherent features that support its performance, and analyzes existing research on its applications and impacts across several domains. Through this assessment, we delineate ChatGPT's strengths and limitations, offering informed recommendations for future investigations in this burgeoning research field.	[Gupta, Bulbul; Mufti, Tabish; Sohail, Shahab Saquib] Jamia Hamdard, Dept Comp Sci & Engn, SEST, New Delhi, India; [Madsen, Dag Oivind] Univ South Eastern Norway, Sch Business, Honefoss, Norway	Jamia Hamdard University; University College of Southeast Norway	Madsen, DO (corresponding author), Univ South Eastern Norway, Sch Business, Honefoss, Norway.	dag.oivind.madsen@usn.no	sohail, shahab/O-3263-2019; Madsen, Dag Øivind/I-1587-2016	sohail, shahab/0000-0002-5944-7371; Madsen, Dag Øivind/0000-0001-8735-3332				Ahmad N, 2023, COMPUTER, V56, P72, DOI 10.1109/MC.2023.3263576; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; Ali F., 2023, Journal of Global Hospitality and Tourism, V2, P1, DOI https://doi.org/10.5038/2771-5957.2.1.1016; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Antaki F., 2023, medRxiv, V2023; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bessen J., 2018, AI and Jobs: The role of demand; Bhandari K. S., 2023, Entrepreneur India; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P53, DOI [10.5281/zenodo.7636568, DOI 10.5281/ZENODO.7636568]; Bozkurt A, 2023, Asian Journal of Distance Education, V18; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chomsky N., 2023, New York Times; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Davenport TH, 2018, HARVARD BUS REV, V96, P108; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Donato H., 2023, The Transparency of Science with ChatGpt and the Emerging Artificial Intelligence Language Models: Where Should Medical Journals Stand?, DOI [https://doi.org/10.20344/amp.19694, DOI 10.20344/AMP.19694]; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Farhat F., 2023, ANAL SCHOLARLY FOOTP, DOI [10.20944/preprints202306.2100.v1, DOI 10.20944/PREPRINTS202306.2100.V1]; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Felizardo KR, 2016, ESEM'16: PROCEEDINGS OF THE 10TH ACM/IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT, DOI 10.1145/2961111.2962630; Ferrari R., 2015, MED WRIT, V24, P230, DOI DOI 10.1179/2047480615Z.000000000329; Gao C. A., 2022, bioRxiv, V2022; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Gilson A., 2022, MEDRXIV; Gozalo-Brizuela R., 2023, arXiv; Gursoy D, 2023, J HOSP MARKET MANAG, V32, P579, DOI 10.1080/19368623.2023.2211993; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Haensch AC, 2023, Arxiv, DOI arXiv:2303.05349; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Haque M. U., 2022, arXiv:2212.05856, P1; Harari Y. N., 2023, The Economist; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Hsu J., 2023, New Scientist, V257, P15, DOI DOI 10.1016/S0262-4079(23)00099-4; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Ivanov S, 2021, J TOUR FUTURES, V9, P214, DOI 10.1108/JTF-02-2023-0038; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kaplan J., 2016, ARTIF INTELL; Karanouh M, 2023, Arxiv, DOI arXiv:2305.18340; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khalil M, 2023, Arxiv, DOI arXiv:2302.04335; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Korzynski P, 2023, CENT EUR MANAG J, V31, P3, DOI 10.1108/CEMJ-02-2023-0091; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Lehnert K, 2023, Arxiv, DOI [arXiv:2301.08155, 10.48550/arXiv.2301.08155, DOI 10.48550/ARXIV.2301.08155]; Leiter C, 2023, Arxiv, DOI [arXiv:2302.13795, DOI 10.48550/ARXIV.2302.13795]; Li J., 2023, medRxiv, V2023; McGee R., 2023, The Opinion of Chat GPT (Artificial Intelligence); Merow C., 2023, AI chatbots can boost scientific coding; Murk W., 2023, medRxiv, V2023; Orduña-Malea E, 2023, SCIENTOMETRICS, V128, P5351, DOI 10.1007/s11192-023-04804-4; Pardos Z. A., 2023, arXiv; Paul J., 2023, Chatgpt and consumers: Benefits, pitfalls and future research agenda; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Rahimi F, 2023, ARCH MED RES, V54, P272, DOI 10.1016/j.arcmed.2023.03.004; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rector LH, 2008, REF SERV REV, V36, P7, DOI 10.1108/00907320810851998; Rivas P, 2023, AI-BASEL, V4, P375, DOI 10.3390/ai4020019; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sajjad M, 2023, ANN BIOMED ENG, V51, P1663, DOI 10.1007/s10439-023-03225-x; Sallam M, 2023, medRxiv; Sanmarchi F, 2023, J PUBLIC HEALTH-HEID, DOI 10.1007/s10389-023-01936-y; Shahriar S, 2023, Arxiv, DOI [arXiv:2302.13817, 10.47852/bonviewAIA3202939, DOI 10.47852/BONVIEWAIA3202939]; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sohail SS, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101675; Sohail SS, 2024, ANN BIOMED ENG, V52, P1131, DOI 10.1007/s10439-023-03335-6; Srivastava M., 2023, A day in the life of ChatGPT as a researcher: Sustainable and efficient machine learning-A review of sparsity techniques and future research directions; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Ufuk F, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230276; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang A, 2022, JMIR MENT HEALTH, V9, DOI 10.2196/35253; Wang JA, 2022, T ASSOC COMPUT LING, V10, P1304, DOI 10.1162/tacl_a_00520; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wohlin C, 2014, P 18 INT C EV ASS SO, V14, P1, DOI [10.1145/2601248.2601268, DOI 10.1145/2601248.2601268]; Wong IA, 2023, J HOSP TOUR MANAG, V56, P253, DOI 10.1016/j.jhtm.2023.06.022; Wood D. A., 2023, The ChatGPT Artificial Intelligence Chatbot: How Well Does It Answer Accounting Assessment Questions?, DOI [10.2308/ISSUES-2023-013, DOI 10.2308/ISSUES-2023-013]; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Zarifhonarvar A., 2023, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.4350925; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]; Zhu Y., 2023, How can chatgpt benefit pharmacy: A case report on review writing; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	101	4	4	55	97	TAYLOR & FRANCIS AS	OSLO	KARL JOHANS GATE 5, NO-0154 OSLO, NORWAY	2331-1975			COGENT BUS MANAG	Cogent Bus. Manag.	DEC 11	2023	10	3							2275851	10.1080/23311975.2023.2275851	http://dx.doi.org/10.1080/23311975.2023.2275851			17	Business	Emerging Sources Citation Index (ESCI)	Business & Economics	Y1KW6		gold, Green Submitted			2024-07-03	WOS:001102936300001
J	Khennouche, F; Elmir, Y; Himeur, Y; Djebari, N; Amira, A				Khennouche, Feriel; Elmir, Youssef; Himeur, Yassine; Djebari, Nabil; Amira, Abbes			Revolutionizing generative pre-traineds: Insights and challenges in deploying ChatGPT and generative chatbots for FAQs	EXPERT SYSTEMS WITH APPLICATIONS			English	Review						Large language models (LLMs); Generative AI; Generative Chatbots; ChatGPT; FAQs; Deep learning	CUSTOMER SERVICE; INTELLIGENCE	In the rapidly evolving domain of artificial intelligence, chatbots have emerged as a potent tool for various applications ranging from e-commerce to healthcare. This research delves into the intricacies of chatbot technology, from its foundational concepts to advanced generative models like ChatGPT. We present a comprehensive taxonomy of existing chatbot approaches, distinguishing between rule-based, retrieval-based, generative, and hybrid models. A specific emphasis is placed on ChatGPT, elucidating its merits for frequently asked questions (FAQs)-based chatbots, coupled with an exploration of associated Natural Language Processing (NLP) techniques such as named entity recognition, intent classification, and sentiment analysis. The paper further delves into the customization and fine-tuning of ChatGPT, its integration with knowledge bases, and the consequent challenges and ethical considerations that arise. Through real-world applications in domains such as online shopping, healthcare, and education, we underscore the transformative potential of chatbots. However, we also spotlight open challenges and suggest future research directions, emphasizing the need for optimizing conversational flow, advancing dialogue mechanics, improving domain adaptability, and enhancing ethical considerations. The research culminates in a call for further exploration in ensuring transparent, ethical, and user-centric chatbot systems.	[Khennouche, Feriel; Elmir, Youssef] Ecole Super Sci & Technol Informat & Numer, Lab LITAN, RN 75, Amizour 06300, Bejaia, Algeria; [Elmir, Youssef] Univ Tahri Mohammed Bechar, SGRE Lab, Bechar 08000, Algeria; [Himeur, Yassine] Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates; [Djebari, Nabil] Univ Bejaia, Fac Sci Exactes, Lab LIMED, Bejaia 06000, Algeria; [Amira, Abbes] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates; [Amira, Abbes] De Montfort Univ, Inst Artificial Intelligence, Leicester, England	University of Dubai; Universite de Bejaia; University of Sharjah; De Montfort University	Himeur, Y (corresponding author), Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates.	khennouche@estin.dz; elmir@estin.dz; yhimeur@ud.ac.ae; djebari@estin.dz; aamira@sharjah.ac.ae	Himeur, Yassine/AAK-7814-2021; Elmir, Youssef/HFZ-9190-2022	Himeur, Yassine/0000-0001-8904-5587; Elmir, Youssef/0000-0003-3499-507X; Amira, Abbes/0000-0003-1652-0492				Abu Shawar B., 2007, Proceedings of the workshop on bridging the gap: Academic and industrial research in dialog technologies, P89, DOI [DOI 10.3115/1556328.1556341, 10.3115/1556328.1556341]; AbuShawar B, 2015, COMPUT SIST, V19, P625, DOI 10.13053/CyS-19-4-2326; Adam M, 2021, ELECTRON MARK, V31, P427, DOI 10.1007/s12525-020-00414-7; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Agarwal M., 2022, Journal of Reproducible Research, V1, P140; Alemdag E, 2023, J RES TECHNOL EDUC, DOI 10.1080/15391523.2023.2255698; Asch D. A., 2023, NEJM Catalyst Innovations in Care Delivery, V4; Baek TH, 2023, TELEMAT INFORM, V83, DOI 10.1016/j.tele.2023.102030; Baha TA, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12166-w; Bailey D, 2021, INTERACT TECHNOL SMA, V18, P85, DOI 10.1108/ITSE-08-2020-0170; Baldassarre M. T., 2023, P 2023 ACM C INF TEC, P363, DOI DOI 10.1145/3582515.3609555; Balderas A, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e19517; Bao SQ, 2021, Arxiv, DOI arXiv:2006.16779; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Boussakssou M, 2022, MULTIMED TOOLS APPL, V81, P2859, DOI 10.1007/s11042-021-11709-y; Buhrke J., 2021, Proceedings of the 54th Hawaii International Conference on System Sciences, P4456; Caldarini G, 2022, INFORMATION, V13, DOI 10.3390/info13010041; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cegin J, 2023, Arxiv, DOI [arXiv:2305.12947, DOI 10.48550/ARXIV.2305.12947, 10.48550/arXiv.2305.12947]; Chao MH, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5511866; Chen Q, 2023, INTERNET RES, V33, P2205, DOI 10.1108/INTR-09-2021-0686; Chen TH, 2024, AM REV PUBLIC ADM, V54, P255, DOI 10.1177/02750740231200522; Chhabra A, 2021, IEEE ACCESS, V9, P130698, DOI 10.1109/ACCESS.2021.3114099; Chia-Wei Liu, 2016, arXiv; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Egonmwan E., 2019, P 3 WORKSHOP NEURAL, P249, DOI DOI 10.18653/V1/D19-5627; Essop L., 2023, 2023 C INFORM COMMUN, P1; Farhat F., Frontiers in Artificial Intelligence, V6; Farhat F., 2023, ANAL SCHOLARLY FOOTP; Farrelly Colleen, 2023, 2023 6th International Conference on Signal Processing and Information Security (ICSPIS), P190, DOI 10.1109/ICSPIS60075.2023.10343824; Ge Qi, 2023, Proceedings of 2023 Chinese Intelligent Automation Conference. Lecture Notes in Electrical Engineering (1082), P361, DOI 10.1007/978-981-99-6187-0_36; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Gnewuch U, 2023, INFORM SYST RES, DOI 10.1287/isre.2022.0152; González-González CS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010545; Gursoy D, 2023, J HOSP MARKET MANAG, V32, P579, DOI 10.1080/19368623.2023.2211993; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Haugeland IKF, 2022, INT J HUM-COMPUT ST, V161, DOI 10.1016/j.ijhcs.2022.102788; Himeur Y, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11020107; Himeur Y, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105698; Himeur Y, 2022, SUSTAIN CITIES SOC, V85, DOI 10.1016/j.scs.2022.104059; Himeur Y, 2021, INFORM FUSION, V72, P1, DOI 10.1016/j.inffus.2021.02.002; Hu X, 2023, Arxiv, DOI [arXiv:2304.02796, DOI 10.1016/J.PROCIR.2023.05.001, 10.48550/arXiv.2304.02796, DOI 10.48550/ARXIV.2304.02796]; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Huddar A., 2020, 2020 INT C CONVERGEN, P1; Hulman A., 2023, medRxiv; Javaid M., 2023, Journal of Economy and Technology; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jesus Rodriguez-Sanchez M., 2023, Handbook of human-machine systems, P115; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kamphaug Å, 2018, LECT NOTES COMPUT SC, V10750, P213, DOI 10.1007/978-3-319-77547-0_16; Kapociute-Dzikiene J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072221; Khayrallah H, 2023, Arxiv, DOI arXiv:2305.14533; Kheddar H, 2023, KNOWL-BASED SYST, V277, DOI 10.1016/j.knosys.2023.110851; Khin N. N., 2020, 2020 IEEE C COMPUTER, P1; Khin NN, 2020, INT CONF SPEECH DATA, P55, DOI [10.1109/O-COCOSDA50338.2020.9295021, 10.1109/o-cocosda50338.2020.9295021]; Kim J, 2023, J RETAIL CONSUM SERV, V75, DOI 10.1016/j.jretconser.2023.103494; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kitchenham B., 2004, Keele, U.K., Keele Univ., VVolume 33, P1; Koc E, 2023, TECHNOL SOC, V74, DOI 10.1016/j.techsoc.2023.102333; Konstantis K., 2023, AI and Ethics, P1; Korzynski P, 2023, CENT EUR MANAG J, V31, P3, DOI 10.1108/CEMJ-02-2023-0091; Lakhani A., 2023, Enhancing customer service with ChatGPT transforming the way businesses interact with customers; Lhasiw N, 2021, 16TH INTERNATIONAL JOINT SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE PROCESSING (ISAI-NLP 2021), DOI 10.1109/iSAI-NLP54397.2021.9678173; Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209; Li CY, 2023, TECHNOL FORECAST SOC, V197, DOI 10.1016/j.techfore.2023.122921; Li J., 2023, medRxiv; Li SQ, 2024, ANN BIOMED ENG, V52, P441, DOI 10.1007/s10439-023-03300-3; Limna P., 2023, Journal of Applied Learning and Teaching, V6; Limna P, 2023, TOUR HOSP MANAG-CROA, V29, P583, DOI 10.20867/thm.29.4.9; Lin CC, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15054012; Liu B, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1106, DOI 10.1145/3308558.3313737; Liu Y, 2019, CHEMOMETR INTELL LAB, V192, DOI 10.1016/j.chemolab.2019.103813; Loni B., 2011, Tech. Rep 55, P57; Loos E, 2023, SOCIETIES, V13, DOI 10.3390/soc13080196; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Ma XY, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102362; Mathur N, 2020, Arxiv, DOI [arXiv:2006.06264, DOI 10.48550/ARXIV.2006.06264]; Mellado-Silva R, 2020, P INT C CHIL COMPUT, DOI 10.1109/sccc51225.2020.9281267; Miao QH, 2023, IEEE-CAA J AUTOMATIC, V10, P877, DOI 10.1109/JAS.2023.123561; Mikic-Fonte FA, 2018, PROC FRONT EDUC CONF; Misischia C. V., 2022, Procedia Computer Science, V201, P421, DOI [10.1016/J.PROCS.2022.03.055, DOI 10.1016/J.PROCS.2022.03.055]; Mnasri M, 2019, Arxiv, DOI arXiv:1903.09025; Mondal S, 2023, TECHNOLOGIES, V11, DOI 10.3390/technologies11020044; Motger Q, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527450; Muangkammuen P., 2018, 2018 22 INT COMPUTER, P1; Mujeeb S, 2017, INT J ADV COMPUT SC, V8, P209; Neumann AT, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.668220; Nicolescu L, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101579; Nithuna S., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0157, DOI 10.1109/ICCSP48568.2020.9182168; Nugraha M. A., 2022, Building of Informatics, Technology and Science (BITS), V4, P624; Oliveira JD, 2019, PROC FRONT EDUC CONF, DOI 10.1109/fie43999.2019.9028667; Omar Reham, 2023, ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots, DOI DOI 10.48550/ARXIV.2302.06466; Ooi K.-B, 2023, J. Comput. Inf. Syst., P1; Opara E., 2023, Global Academic Journal of Humanities and Social Sciences, P5; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Peras D, 2018, EC SOC DEVELOP, P89; Raj R., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI [10.1016/j.tbench.2023.100140, DOI 10.1016/J.TBENCH.2023.100140]; Raj V, 2023, COMM COM INF SC, V1798, P379, DOI 10.1007/978-3-031-28183-9_27; Ranoliya BR, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1525, DOI 10.1109/ICACCI.2017.8126057; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Reyes R, 2019, LECT NOTES ARTIF INT, V11835, P440, DOI 10.1007/978-3-030-33749-0_35; Ricciardelli E., 2019, 4 MULTIDISCIPLINARY; Rosario G, 2023, Arxiv, DOI arXiv:2303.12038; Saha B., 2022, Healthcare chatbot using decision tree algorithm; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sassoon J., 2019, Quando le storie le raccontano i robot; Sayed AN, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105254; Serban IV, 2016, AAAI CONF ARTIF INTE, P3776; Serban IV, 2017, AAAI CONF ARTIF INTE, P3295; Sethi F., 2020, International Journal of Computer Sciences and Engineering, V8; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Shawar B. A., 2002, School of Computing research report 2002.19; Shoufan A, 2023, IEEE ACCESS, V11, P38805, DOI 10.1109/ACCESS.2023.3268224; Singh D., 2023, Int. J. New Media Stud. Int. Peer Rev. Sch. Index. J., V10, P57; Smith A., 2023, International Journal of Social Psychiatry; Sohail S.S., 2023, Current Challenges, and Possible Future Directions; Sohail S.S., Deep transfer learning for 3d point cloud understanding: A comprehensive survey; Sohail S.S., 2023, Using chatgpt to navigate ambivalent and contradictory research findings on artificial intelligence; Sohail SS, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101675; Sok S., 2023, ChatGPT for education and research: A review of benefits and risks; Subagja AD., 2023, J Minfo Polgan, V12, P380, DOI [10.33395/jmp.v12i2.12407, DOI 10.33395/JMP.V12I2.12407]; Sudirjo F., 2023, Jurnal Teknologi Dan Sistem Informasi Bisnis, V5, P283; Sun P, 2018, INT CONF ASIAN LANG, P273, DOI 10.1109/IALP.2018.8629225; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Thi Ly Vu, 2021, Increasing Naturalness and Flexibility in Spoken Dialogue Interaction. 10th International Workshop on Spoken Dialogue Systems. Lecture Notes in Electrical Engineering (LNEE 714), P251, DOI 10.1007/978-981-15-9323-9_21; Thomas NT, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2740, DOI 10.1109/ICACCI.2016.7732476; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tsai MH, 2019, WATER-SUI, V11, DOI 10.3390/w11020234; Serban IV, 2017, Arxiv, DOI [arXiv:1709.02349, DOI 10.48550/ARXIV.1709.02349]; Waisberg E., 2023, Eye, P1; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13116716; Wang WC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5066; Wijaya Y., 2020, JAIA-Journal of Artificial Intelligence and Applications, V1, P01; Wong IA, 2023, J HOSP TOUR MANAG, V56, P253, DOI 10.1016/j.jhtm.2023.06.022; Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496; Xu Y., 2022, P 2022 CHI C HUMAN F, P1; Yamaguchi H., 2018, FEDCSIS COMMUNICATIO, P37; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Zhao XL, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103203; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]; Zierock B., 2023, Learning, V116, P63	151	0	0	76	76	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	JUL 15	2024	246								123224	10.1016/j.eswa.2024.123224	http://dx.doi.org/10.1016/j.eswa.2024.123224		JAN 2024	25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	ID8Y3					2024-07-03	WOS:001164491400001
J	Ittarat, M; Cheungpasitporn, W; Chansangpetch, S				Ittarat, Mantapond; Cheungpasitporn, Wisit; Chansangpetch, Sunee			Personalized Care in Eye Health: Exploring Opportunities, Challenges, and the Road Ahead for Chatbots	JOURNAL OF PERSONALIZED MEDICINE			English	Review						ophthalmology; artificial intelligence; machine learning; language processing; large language models; chatbot; ChatGPT	DISCHARGE SUMMARIES; PATIENT EDUCATION; OPHTHALMOLOGY; CHATGPT; SCORE	In modern eye care, the adoption of ophthalmology chatbots stands out as a pivotal technological progression. These digital assistants present numerous benefits, such as better access to vital information, heightened patient interaction, and streamlined triaging. Recent evaluations have highlighted their performance in both the triage of ophthalmology conditions and ophthalmology knowledge assessment, underscoring their potential and areas for improvement. However, assimilating these chatbots into the prevailing healthcare infrastructures brings challenges. These encompass ethical dilemmas, legal compliance, seamless integration with electronic health records (EHR), and fostering effective dialogue with medical professionals. Addressing these challenges necessitates the creation of bespoke standards and protocols for ophthalmology chatbots. The horizon for these chatbots is illuminated by advancements and anticipated innovations, poised to redefine the delivery of eye care. The synergy of artificial intelligence (AI) and machine learning (ML) with chatbots amplifies their diagnostic prowess. Additionally, their capability to adapt linguistically and culturally ensures they can cater to a global patient demographic. In this article, we explore in detail the utilization of chatbots in ophthalmology, examining their accuracy, reliability, data protection, security, transparency, potential algorithmic biases, and ethical considerations. We provide a comprehensive review of their roles in the triage of ophthalmology conditions and knowledge assessment, emphasizing their significance and future potential in the field.	[Ittarat, Mantapond] Suranaree Univ Technol, Surin Hosp, Surin 32000, Thailand; [Ittarat, Mantapond] Suranaree Univ Technol, Surin Med Educ Ctr, Surin 32000, Thailand; [Cheungpasitporn, Wisit] Mayo Clin, Dept Med, Rochester, MN 55905 USA; [Chansangpetch, Sunee] Chulalongkorn Univ, Ctr Excellence Glaucoma, Bangkok 10330, Thailand; [Chansangpetch, Sunee] Chulalongkorn Univ, Fac Med, Dept Ophthalmol, Bangkok 10330, Thailand; [Chansangpetch, Sunee] King Chulalongkorn Mem Hosp, Thai Red Cross Soc, Bangkok 10330, Thailand	Suranaree University of Technology; Suranaree University of Technology; Mayo Clinic; Chulalongkorn University; Chulalongkorn University; Chulalongkorn University; Thai Red Cross Society	Cheungpasitporn, W (corresponding author), Mayo Clin, Dept Med, Rochester, MN 55905 USA.	mantapond.sur@cpird.in.th; wcheungpasitporn@gmail.com; sunee.ch@chula.ac.th	Cheungpasitporn, Wisit/H-8194-2019	Cheungpasitporn, Wisit/0000-0001-9954-9711; Ittarat, Mantapond/0000-0001-8177-1234	Microsoft [GPT-3.5]	Microsoft(Microsoft)	The responses, demonstrations, and figures presented in this manuscript were created using AI chatbots, including ChatGPT (GPT-3.5), an AI language model developed by OpenAI, Bing Chat (GPT-4.0) generated by Microsoft, and Bard AI built on PaLM operated by Google. The flow diagram and mind map showcased in this manuscript were designed using Whimsical.	Aiumtrakul N, 2023, J PERS MED, V13, DOI 10.3390/jpm13101457; Ajibode Ha, 2012, J West Afr Coll Surg, V2, P38; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Bhattacharyya O, 2019, J MED INTERNET RES, V21, DOI 10.2196/10318; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Bressler NM, 2023, JAMA OPHTHALMOL, V141, P514, DOI 10.1001/jamaophthalmol.2023.1370; Chen JS, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.906554; Craig Janelle, 2007, Health Inf Manag, V36, P30; Delcourt C, 2017, INVEST OPHTH VIS SCI, V58, P6399, DOI 10.1167/iovs.17-21819; Dorsey ER, 2016, NEW ENGL J MED, V375, P154, DOI 10.1056/NEJMra1601705; Fayed AM, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00642-8; Frank T, 2022, J AAPOS, V26, P287, DOI 10.1016/j.jaapos.2022.09.009; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordon MO, 2007, OPHTHALMOLOGY, V114, P10, DOI 10.1016/j.ophtha.2006.08.031; Hua HU, 2023, JAMA OPHTHALMOL, V141, P819, DOI 10.1001/jamaophthalmol.2023.3119; Islam A, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/42740; Li JPO, 2021, PROG RETIN EYE RES, V82, DOI 10.1016/j.preteyeres.2020.100900; Lyons R.J., 2023, medRxiv, DOI [10.1016/j.jcjo.2023.07.016, DOI 10.1016/J.JCJO.2023.07.016]; Manoharan MK, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35696-2; McMonnies CW, 2011, CONTACT LENS ANTERIO, V34, P241, DOI 10.1016/j.clae.2011.06.007; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; Miao J, 2023, KIDNEY INT REP, V8, P1657, DOI 10.1016/j.ekir.2023.05.014; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P798, DOI 10.1001/jamaophthalmol.2023.2754; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Mokmin NAM, 2021, EDUC INF TECHNOL, V26, P6033, DOI 10.1007/s10639-021-10542-y; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Ooms A, 2021, J GLAUCOMA, V30, pE40, DOI 10.1097/IJG.0000000000001731; Panch T, 2019, LANCET DIGIT HEALTH, V1, pE13, DOI 10.1016/S2589-7500(19)30002-0; Parikh D, 2020, SEMIN OPHTHALMOL, V35, P210, DOI 10.1080/08820538.2020.1789675; Phasuk S, 2019, IEEE ENG MED BIO, P904, DOI [10.1109/embc.2019.8857136, 10.1109/EMBC.2019.8857136]; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Seddon JM, 2019, AM J OPHTHALMOL, V198, P223, DOI 10.1016/j.ajo.2018.10.022; Silver AM, 2022, J PATIENT SAF, V18, P58, DOI 10.1097/PTS.0000000000000809; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Steinmetz JD, 2021, LANCET GLOB HEALTH, V9, pE144, DOI [10.1016/S2214-109X(20)30489-7, 10.1016/S2214-109X(20)30425-3]; Suppadungsuk S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12175550; Tam W, 2023, NURS EDUC TODAY, V129, DOI 10.1016/j.nedt.2023.105917; Tremoulet PD, 2021, J MED INTERNET RES, V23, DOI 10.2196/25657; Tsui JC, 2023, EYE, V37, P3692, DOI 10.1038/s41433-023-02556-2; UMass Chan Medical School, AMD Risk Score Calculator; Valencia OAG, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11182518; Wang E, 2022, OPHTHAL PHYSL OPT, V42, P839, DOI 10.1111/opo.12991; Xiong YZ, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.671121	47	2	2	9	9	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4426		J PERS MED	J. Pers. Med.	DEC	2023	13	12							1679	10.3390/jpm13121679	http://dx.doi.org/10.3390/jpm13121679			31	Health Care Sciences & Services; Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; General & Internal Medicine	DZ7D6	38138906	gold, Green Published			2024-07-03	WOS:001135975700001
C	Sazid, Y; Fuad, MMN; Sakib, K			IEEE Comp Soc	Sazid, Yasin; Fuad, Mridha Md. Nafis; Sakib, Kazi			Automated Detection of Dark Patterns Using In-Context Learning Capabilities of GPT-3	PROCEEDINGS OF THE 2023 30TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, APSEC 2023	Asia-Pacific Software Engineering Conference		English	Proceedings Paper	30th Asia-Pacific Software Engineering Conference (APSEC)	DEC 04-07, 2023	Seoul, SOUTH KOREA			Dark Patterns; Automated Detection; Large Language Models; GPT-3; In-Context Learning		Dark patterns manipulate user choices through deceptive UI tactics. Any automated detection technique for dark patterns must address the varying nature of dark patterns. Existing detection techniques need manual intervention in some cases. In other cases, techniques are not generalized due to overfitting problems; for example, these techniques can not handle cases where texts are semantically similar but possess lexical differences. We propose an automated dark pattern text detection technique that is generalized. We synthesize inclusive definitions of dark pattern categories. This contextual information is prioritized using in-context learning capabilities of GPT-3 to detect and classify dark pattern texts. Results show that our technique offers satisfactory performance for 6 out of 7 dark pattern categories explored in this study. We also validate the improved generalization capability of our technique by outperforming an existing baseline model on a test dataset.	[Sazid, Yasin; Fuad, Mridha Md. Nafis; Sakib, Kazi] Univ Dhaka, Inst Informat Technol, Dhaka, Bangladesh	University of Dhaka	Sazid, Y (corresponding author), Univ Dhaka, Inst Informat Technol, Dhaka, Bangladesh.	msse1762@iit.du.ac.bd; bsse0920@iit.du.ac.bd; sakib@iit.du.ac.bd						Brignull H., 2023, Deceptive patterns-user interfaces designed to trick you; Chaudhary A., 2022, DESIGNING INTERACTIV; foodpanda, Foodpanda: Food and more, delivered; Geronimo L. D., 2020, P 2020 CHI C HUM FAC; Gray CM, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174108; Greenberg S., 2014, P 2014 C DES INT SYS; Jarovsky L., 2022, SSRN Electronic Journal; Luguri J., 2019, SSRN Electronic Journal; Mansur S. M. H., 2023, 2023 IEEE ACM 45 INT; Mathur Arunesh, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359183; Mathur A., 2021, P 2021 CHI C HUMAN F, DOI DOI 10.1145/3411764.3445610; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Roffarello AM, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519829; Soe T. H., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.11836; Stavrakakis I., 2021, A framework of web-based dark patterns that can be detected manually or automatically; Yada Y., 2022, 2022 IEEE INT C BIG	16	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-1362		979-8-3503-4417-2	ASIA PAC SOFWR ENG			2023							569	573		10.1109/APSEC60848.2023.00072	http://dx.doi.org/10.1109/APSEC60848.2023.00072			5	Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8UA					2024-07-03	WOS:001207000500063
J	Fernando, C; Osindero, S; Banarse, D				Fernando, Chrisantha; Osindero, Simon; Banarse, Dylan			The origin and function of external representations	ADAPTIVE BEHAVIOR			English	Article; Early Access						Language; science; art; cognitive archaeology; machine learning; large language models; representation	MIDDLE STONE-AGE; HUMAN BRAIN; LANGUAGE-ACQUISITION; NONHUMAN-PRIMATES; EVOLUTION; EMERGENCE; THINKING; FUTURE; SELF; CONSCIOUSNESS	External representations (ERs) are objects or performances in the world whose proper function is to communicate about other things in the world. Why and how did we make them, and what do they give us? We outline a simple framework for thinking about ERs grounded in modern machine learning. We propose a minimal set of neural mechanisms needed for open-ended ER production. Our constructivist enactive view contrasts with nativist views which propose specialist neural modules requiring symbolic internal representations. We propose a plausible set of (biological and cultural) evolutionary steps to full Gricean symbolic communication via a set of increasingly complex enactive algorithms for ER production. A pragmatic space of games is defined, which includes not only fully cooperative language games but also science, art, and evolved signal manipulation games. This space is defined by the complexity of learning needed by sender and receiver. We propose that one important step towards open-ended ER use was selection for bush reading, which like mind-reading is an inferential process requiring complex contextual and syntactic understanding of cues about events displaced in space and time. Bush reading pre-adapted receivers to be receptive, competent, and perspicacious interpreters of later intentionally produced signals about hidden topics such as felt mental states. This paved the way for minimally Gricean communication, which subsequently could be bootstrapped into explicit theories of mind, folk psychology narratives, and symbolic language in general. Recent findings in cognitive archaeology are integrated within the framework, and new experiments in machine learning suggested.	[Fernando, Chrisantha; Osindero, Simon; Banarse, Dylan] Google DeepMind, 8 Handyside St, London N1C 4AG, England	Google Incorporated	Fernando, C (corresponding author), Google DeepMind, 8 Handyside St, London N1C 4AG, England.	chrisantha@google.com			Google DeepMind	Google DeepMind(Google Incorporated)	The author(s) disclosed receipt of the followingfinancial supportfor the research, authorship, and/or publication of this article: Thiswork was supported by Google DeepMind.	Akam T, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004648; Allen J.G., 2006, The handbook of mentalization-based treatment; Ambrose SH, 1998, J HUM EVOL, V34, P623, DOI 10.1006/jhev.1998.0219; Anderson M, 2008, CONNECT SCI, V20, P239, DOI 10.1080/09540090802413202; Andres M, 2008, BEHAV BRAIN SCI, V31, P642, DOI 10.1017/S0140525X08005578; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Arnheim R., 1954, Art and Visual Perception: A Psychology of the Creative Eye; Aston A, 2019, PHENOMENOL COGN SCI, V18, P65, DOI 10.1007/s11097-018-9601-z; Atance CM, 2001, TRENDS COGN SCI, V5, P533, DOI 10.1016/S1364-6613(00)01804-0; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baerveldt C, 1999, CULT PSYCHOL, V5, P183, DOI 10.1177/1354067X9952006; Bar-On D., 2017, Pragmatic interpretation and signaler-receiver asymmetries in animal communication; Bar-On D, 2021, BIOL PHILOS, V36, DOI 10.1007/s10539-021-09824-z; Bar-On Dorit., 2004, Speaking My Mind: Expression and Self-knowledge; Barona AM, 2021, ADAPT BEHAV, V29, P137, DOI 10.1177/1059712320941945; Barrett L, 2007, PHILOS T R SOC B, V362, P561, DOI 10.1098/rstb.2006.1995; Bednarik R. G., 1998, The archaeology of rock-art; Bednarik RG, 2003, CURR ANTHROPOL, V44, P405, DOI 10.1086/374900; Ben Goertzel, 2023, Arxiv, DOI [arXiv:2309.10371, 10.48550/arXiv.2309.10371, DOI 10.48550/ARXIV.2309.10371]; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bennett ATD, 1996, J EXP BIOL, V199, P219; Berger John., 2009, About Looking; Bickerton D., 1990, Language species; Bijvoet-van den Berg S, 2019, J EXP CHILD PSYCHOL, V177, P313, DOI 10.1016/j.jecp.2018.08.008; Bloch M, 2016, CURR ANTHROPOL, V57, pS80, DOI 10.1086/685496; Bloch M, 2014, PRAGMAT COGN, V22, P109, DOI 10.1075/pc.22.1.06blo; Block N, 2007, BEHAV BRAIN SCI, V30, P481, DOI 10.1017/S0140525X07002786; Bloom Harold., 2008, Shakespeare: The Invention of the Human; Boesch C., 2000, CHIMPANZEES TA FORES; Brentano F., 1973, PSYCHOL EMPIRICAL ST; Brohan A, 2023, Arxiv, DOI arXiv:2307.15818; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; Brown T., 1983, Nature observation and tracking; Brown Tom., 1986, TRACKER TRUE STORY T, V20th; Bruner E, 2023, BRAIN STRUCT FUNCT, V228, P145, DOI 10.1007/s00429-022-02487-w; Bruner E, 2013, ANTHROPOL SCI, V121, P31, DOI 10.1537/ase.120927; BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619; Bruner J., 1974, Toward a theory of instruction; Butterfill SA, 2013, MIND LANG, V28, P606, DOI 10.1111/mila.12036; Call J, 2008, TRENDS COGN SCI, V12, P187, DOI 10.1016/j.tics.2008.02.010; Canterbury D., 2015, Advanced Bushcraft: An Expert field Guide to the art of Wilderness Survival; Carroll N., 1999, ROUTLEDGE CONT INTRO; Carruthers P, 2002, BEHAV BRAIN SCI, V25, P657, DOI 10.1017/S0140525X02000122; Cassirer E., 1955, The philosophy of symbolic forms; Chandler D., 2017, Semiotics: The Basics; Chang JD, 2023, Arxiv, DOI arXiv:2306.11816; CHARNOV EL, 1976, AM NAT, V110, P247, DOI 10.1086/283062; Chater N., 2018, The Mind Is Flat: The Illusion of Mental Depth and the Improvised Mind; Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561; Chomsky N., 1965, Aspects of the Theory of Syntax; Christiansen MH, 2016, CREATING LANGUAGE: INTEGRATING EVOLUTION, ACQUISITION, AND PROCESSING, P1; Christiansen MH, 2009, LANG LEARN, V59, P126, DOI 10.1111/j.1467-9922.2009.00538.x; Christie S., 2007, Proceedings of the second European cognitive science conference, P601; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Clayton NS, 1998, NATURE, V395, P272, DOI 10.1038/26216; Clottes Jean., 2016, What Is Paleolithic Art?; Collingwood R., 2016, The principles of art; Colom R, 2012, INTELLIGENCE, V40, P479, DOI 10.1016/j.intell.2012.05.004; Coolidge FL, 2012, CURR ANTHROPOL, V53, P204, DOI 10.1086/664818; Cosmides L., 1992, ADAPTED MIND EVOLUTI; Creswell A., 2022, arXiv; Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005; D'Errico F, 2000, CAMB ARCHAEOL J, V10, P123, DOI 10.1017/S0959774300000056; Dal Pesco F, 2018, J HUM EVOL, V125, P87, DOI 10.1016/j.jhevol.2018.10.007; DANDRADE RG, 1989, KEELE COG S, V2, P132; Dasgupta I., 2022, arXiv preprint arXiv:2207.07051; David Bruno., 2017, Cave Art; dAvila Garcez A., 2020, arXiv; Davis B., 2022, Art in the after-culture: Capitalist crisis and cultural strategy; Daw ND, 2005, NAT NEUROSCI, V8, P1704, DOI 10.1038/nn1560; de-Villiers J., 2000, CHILDRENS REASONING, P191, DOI DOI 10.4324/9781315784670; Deacon T. W., 1997, The symbolic species: the co-evolution of language and the brain; Dean LG, 2014, BIOL REV, V89, P284, DOI 10.1111/brv.12053; Dehaene S, 2011, NEURON, V70, P200, DOI 10.1016/j.neuron.2011.03.018; DEMENOCAL PB, 1995, SCIENCE, V270, P53, DOI 10.1126/science.270.5233.53; Demmrich S, 2023, NUMEN-INT REV HIST R, V70, P630, DOI 10.1163/15685276-20231709; Dennett D. C., 2008, Kinds of minds: Toward an understanding of consciousness; Dissanayake E, 1998, PHILOS LITERATURE, V22, P486; Dissanayake E., 1992, Homo aestheticus: Where art comes from and why; Domínguez-Rodrigo M, 2014, CURR ANTHROPOL, V55, P59, DOI 10.1086/674530; Donald M., 1991, Origins of the modern mind: Three stages in the evolution of culture and cognition; Dunbar RIM, 1998, EVOL ANTHROPOL, V6, P178, DOI 10.1002/(SICI)1520-6505(1998)6:5<178::AID-EVAN5>3.3.CO;2-P; Dutton D., 2009, The art instinct: Beauty, pleasure, and human evolution; Elias JZ, 2014, J COGN CULT, V14, P373, DOI 10.1163/15685373-12342132; Elkins James., 1997, The Object Stares Back: On the Nature of Seeing, V1st; Elman J. L., 1996, Rethinking innateness: A connectionist perspective on development, Vvolume 10; Eren MI, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029273; Evans N, 2000, LANGUAGE, V76, P546, DOI 10.2307/417135; Evans R., 2022, Kant and artificial intelligence, P39, DOI [10.1515/9783110706611-002, DOI 10.1515/9783110706611-002]; Spies AF, 2022, Arxiv, DOI arXiv:2207.07512; Fan J. E., 2020, Computational Brain Behavior, V3, P86, DOI DOI 10.1007/S42113-019-00058-7; Fan J. E., 2015, Translational Issues in Psychological Science, V1, P170, DOI [10.1037/tps0000037, DOI 10.1037/TPS0000037]; Fauconnier G., 1997, MAPPINGS THOUGHT LAN; FEIN GG, 1975, DEV PSYCHOL, V11, P291, DOI 10.1037/h0076568; Fenici M, 2017, J CULT COGN SCI, V1, P89, DOI 10.1007/s41809-017-0008-0; Fernando C., 2020, CoRR, P02820; Fernando C, 2023, Arxiv, DOI arXiv:2309.16797; Fernando C, 2011, J THEOR BIOL, V275, P29, DOI 10.1016/j.jtbi.2011.01.009; Ferrier Jean-Louis., 1998, OUTSIDER ART; Fitch W., 2010, Approaches to the evolution of language; Flanders E, 2023, J ARCHAEOL SCI, V160, DOI 10.1016/j.jas.2023.105888; Fodor J. A., 1975, LANGUAGE THOUGHT, V5; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Fonagy P., 2016, The Routledge handbook of psychoanalysis in the social sciences and humanities, P115; Froese T, 2019, PHENOMENOL COGN SCI, V18, P91, DOI 10.1007/s11097-017-9537-8; Froese T, 2012, INTERACT STUD, V13, P436, DOI 10.1075/is.13.3.06fro; FROMKIN V, 1974, BRAIN LANG, V1, P81, DOI 10.1016/0093-934X(74)90027-3; Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5; Garofoli D., 2015, The Journal of Mind and Behavior, V1, P1; Gell A., 1998, ART AGENCY ANTHR THE; Gentner D, 2003, BRADFORD BOOKS, P195; Gentner D, 2010, ON THINKING, P35, DOI 10.1007/978-3-642-03129-8_3; GIBSON JJ, 1979, ECOLOGICAL APPROACH; Glorioso GC, 2021, COGNITION, V214, DOI 10.1016/j.cognition.2020.104288; Gombrich E.H., 1961, Art and Illusion; Goodkind A., 2018, P 8 WORKSHOP COGNITI, P10, DOI [10.18653/v1/W18-0102, DOI 10.18653/V1/W18-0102]; Gooley T., 2010, The natural navigator; Gooley T., 2012, The natural explorer: Understanding your landscape; Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3; Graves A, 2014, Arxiv, DOI [arXiv:1410.5401, DOI 10.48550/ARXIV.1410.5401]; Green SJ, 2020, CURR BIOL, V30, DOI 10.1016/j.cub.2020.08.076; Grice P., 2020, Meaning/bedeutung (Englisch/Deutsch): Great papers philosophie; Gureckis TM, 2012, PERSPECT PSYCHOL SCI, V7, P464, DOI 10.1177/1745691612454304; Ha David, 2018, ARXIV180310122, DOI [10.5281/zenodo.1207631, DOI 10.5281/ZENODO.1207631]; HACKING I, 1991, PHILOS STUD, V61, P109, DOI 10.1007/BF00385836; HAGUE A, 1990, TEX STUD LIT LANG, V32, P584; Hamrick JB, 2019, CURR OPIN BEHAV SCI, V29, P8, DOI 10.1016/j.cobeha.2018.12.011; Harcourt-Smith William H.E., 2010, Evolution Education and Outreach, V3, P333; Harvey I., 2008, Misrepresentations, P6; Hawkins R. D., 2021, CoRR, P13861; Henshilwood C, 2004, SCIENCE, V304, P404, DOI 10.1126/science.1095905; Henshilwood CS, 2003, CURR ANTHROPOL, V44, P627, DOI 10.1086/377665; Herculano-Houzel S, 2012, P NATL ACAD SCI USA, V109, P10661, DOI 10.1073/pnas.1201895109; Heyes C, 2019, BEHAV BRAIN SCI, V42, P1, DOI 10.1017/S0140525X18002145; Higgins I., 2016, Learning basic visual concepts with a constrained variational framework; Hills TT, 2015, CURR ZOOL, V61, P368, DOI 10.1093/czoolo/61.2.368; Hobaiter C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011959; Hobson NM, 2018, PERS SOC PSYCHOL REV, V22, P260, DOI 10.1177/1088868317734944; Horner V, 2005, ANIM COGN, V8, P164, DOI 10.1007/s10071-004-0239-6; Horschler DJ, 2020, TRENDS COGN SCI, V24, P594, DOI 10.1016/j.tics.2020.05.009; HUMPHREY N, 1978, NEW SCI, V78, P900; Hutchins E, 2005, J PRAGMATICS, V37, P1555, DOI 10.1016/j.pragma.2004.06.008; Hutto D. D., 2012, Folk psychological narratives: The sociocultural basis of understanding reasons; Iliopoulos A, 2016, SIGNS SOC, V4, P244, DOI 10.1086/688619; Iliopoulos A, 2016, QUATERN INT, V405, P111, DOI 10.1016/j.quaint.2015.08.033; Ingold T., 2001, The debated mind: evolutionary psychology versus ethnography, P113, DOI [10.4324/9781003086963-7, DOI 10.4324/9781003086963-7]; Ingold Tim., 2016, LINES BRIEF HIST; Ingold Tim., 2013, MAKING ANTHR ARCHAEO, DOI [10.4324/9780203559055, DOI 10.4324/9780203559055]; Iriki A, 2012, PHILOS T R SOC B, V367, P10, DOI 10.1098/rstb.2011.0190; Jackendoff R., 1996, Pragmatics and Cognition, V4, P1, DOI [10.1075/pc.4.1.03jac, DOI 10.1075/PC.4.1.03JAC, 10.1075/PC.4.1.03JAC]; Janson CH, 2007, ANIM COGN, V10, P357, DOI 10.1007/s10071-007-0080-9; Jiang YD, 2019, ADV NEUR IN, V32; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; Kahlenberg SM, 2010, CURR BIOL, V20, pR1067, DOI 10.1016/j.cub.2010.11.024; Kahneman D., 2011, THINKING FAST SLOW; Ke NR, 2022, Arxiv, DOI arXiv:2204.04875; Kellogg R., 1967, A Psychology today book; Keramati M, 2014, ELIFE, V3, DOI 10.7554/eLife.04811; Kirby S, 2002, SIMULATING THE EVOLUTION OF LANGUAGE, P121; KIRSH D, 1995, ARTIF INTELL, V73, P31, DOI 10.1016/0004-3702(94)00017-U; Kirsh D, 2010, AI SOC, V25, P441, DOI 10.1007/s00146-010-0272-8; Kissel M, 2017, CAMB ARCHAEOL J, V27, P397, DOI 10.1017/S0959774317000014; Kodandaramaiah U, 2011, BEHAV ECOL, V22, P1264, DOI 10.1093/beheco/arr123; Kosinski M., 2023, arXiv; Krebs J.R., 2009, BEHAV ECOLOGY EVOLUT; Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533; Kushnir T, 2010, COGNITIVE SCI, V34, P148, DOI 10.1111/j.1551-6709.2009.01072.x; Lakoff G., 2008, Metaphors we live by; LARKIN JH, 1987, COGNITIVE SCI, V11, P65, DOI 10.1016/S0364-0213(87)80026-5; Larochelle H., 2008, Proceedings of the national conference on artificial intelligence, V1, P3; LeDoux JE, 2000, ANNU REV NEUROSCI, V23, P155, DOI 10.1146/annurev.neuro.23.1.155; Lenneberg E.H., 1967, BIOL FDN LANGUAGE; LESLIE AM, 1987, PSYCHOL REV, V94, P412, DOI 10.1037/0033-295X.94.4.412; Lewis LS, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2304903120; Lewis-Williams J., 2002, The mind in the cave: Consciousness and the origins of art; Liebenberg L., 2010, Practical tracking; A guide to following footprints and finding animals; Liebenberg L.W., 1990, The art of tracking: The origin of science; Lillicrap TP, 2020, NAT REV NEUROSCI, V21, P335, DOI 10.1038/s41583-020-0277-3; Liu SC, 2024, Arxiv, DOI arXiv:2310.19046; Lorenz K., 1981, The Foundations of Ethology; Lycett SJ, 2013, J ARCHAEOL SCI, V40, P2384, DOI 10.1016/j.jas.2013.01.016; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI [10.1162/neco.1992.4.3.415, 10.1162/neco.1992.4.3.448]; Madden JR, 2008, ANIM COGN, V11, P1, DOI 10.1007/s10071-007-0092-5; Maguire EA, 2000, P NATL ACAD SCI USA, V97, P4398, DOI 10.1073/pnas.070039597; Malafouris L, 2013, HOW THINGS SHAPE THE MIND: A THEORY OF MATERIAL ENGAGEMENT, P1; Malafouris L, 2021, J ARCHAEOL METHOD TH, V28, P95, DOI 10.1007/s10816-020-09504-4; Malafouris Lambros, 2007, IMAGE IMAGINATION GL, P289; Marcus G. F., 2003, The algebraic mind: Integrating connectionism and cognitive science; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; Matsuzawa T, 2020, PRIMATES, V61, P543, DOI 10.1007/s10329-020-00836-z; Maynard Smith J., 1997, The major transitions in evolution; McBrearty S, 2000, J HUM EVOL, V39, P453, DOI 10.1006/jhev.2000.0435; McPherron SP, 2010, NATURE, V466, P857, DOI 10.1038/nature09248; MEGGITT MJ, 1966, OCEANIA, V36, P173, DOI 10.1002/j.1834-4461.1966.tb00286.x; Mendoza Straffon L., 2014, Art in the making: The evolutionary origins of visual art as a communication signal; Merleau-Ponty Maurice., 1962, PHENOMENOLOGY PERCEP; Miller G., 2001, The mating mind: How sexual choice shaped the evolution of human nature; Millikan R. G., 2017, Beyond Concepts: Unicepts, Language, and Natural Information, DOI 10.1093/oso/9780198717195.001.0001; Miranda B, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007944; Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x; Mitchell Robert W., 2002, P23, DOI 10.1017/CBO9780511542282.004; Mitchell Robert W., 1999, P295, DOI 10.1017/CBO9780511542305.016; Mithen Steven., 1998, PREHISTORY MIND SEAR; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Moore R, 2021, SYNTHESE, V199, P1751, DOI 10.1007/s11229-020-02853-3; Moore R, 2017, PHILOS QUART, V67, P303, DOI 10.1093/pq/pqw049; Morriss-Kay GM, 2010, J ANAT, V216, P158, DOI 10.1111/j.1469-7580.2009.01160.x; Mulcahy NJ, 2006, SCIENCE, V312, P1038, DOI 10.1126/science.1125456; Mundy P, 2018, EUR J NEUROSCI, V47, P497, DOI 10.1111/ejn.13720; Nagel T., 1980, The Language and Thought Series, P159; NELSON K, 1993, PSYCHOL SCI, V4, P7, DOI 10.1111/j.1467-9280.1993.tb00548.x; NEWELL A, 1976, COMMUN ACM, V19, P113, DOI 10.1145/360018.360022; Niemitz C, 2010, NATURWISSENSCHAFTEN, V97, P241, DOI 10.1007/s00114-009-0637-3; Niv Y, 2009, J MATH PSYCHOL, V53, P139, DOI 10.1016/j.jmp.2008.12.005; No A., 2023, The entanglement: How art and philosophy make us what we are; No A., 2015, Strange tools: Art and human nature; O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115; OAKLEY KP, 1981, PHILOS T ROY SOC B, V292, P205, DOI 10.1098/rstb.1981.0029; Öllinger M, 2014, PSYCHOL RES-PSYCH FO, V78, P266, DOI 10.1007/s00426-013-0494-8; OpenAI, 2023, GPT-4 Technical Report; Orban GA, 2006, NEUROPSYCHOLOGIA, V44, P2647, DOI 10.1016/j.neuropsychologia.2005.11.001; Orban GA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00310; Osvath M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036782; Ouyang L., 2022, NEURIPS; Overmann K., 2018, Journal of Numerical Cognition, V4, P464, DOI [DOI 10.5964/JNC.V4I2.161, 10.5964/jnc.v4i2.161]; Overmann K. A., 2023, The materiality of numbers: Emergence and elaboration from prehistory to present; Overmann KA, 2021, ADAPT BEHAV, V29, P123, DOI 10.1177/1059712320930738; Oxford M. J., 1962, Animal Behaviour, V10, P1; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Panksepp J., 2004, AFFECTIVE NEUROSCIEN; Penn DC, 2008, BEHAV BRAIN SCI, V31, P109, DOI 10.1017/S0140525X08003543; Peterson C, 1998, DEV PSYCHOL, V34, P1059, DOI 10.1037/0012-1649.34.5.1059; Pfeiffer J.E., 1982, The Creative Explosion: An Inquiry into the Origins of Art and Religion; PIAGET J, 1964, J RES SCI TEACH, V2, P176, DOI 10.1002/tea.3660020306; Piazza M, 2009, NEUROSCIENTIST, V15, P261, DOI 10.1177/1073858409333073; Pinker S., 1994, The Language Instinct: How the Mind Creates Language; Poldrack RA, 2006, TRENDS COGN SCI, V10, P59, DOI 10.1016/j.tics.2005.12.004; Popper K. R., 1959, The Logic of Scientific Discovery; Potì P, 2009, DEVELOPMENTAL SCI, V12, P536, DOI 10.1111/j.1467-7687.2008.00797.x; Potts R, 1998, YEARB PHYS ANTHROPOL, V41, P93; Potts R, 1998, EVOL ANTHROPOL, V7, P81, DOI 10.1002/(SICI)1520-6505(1998)7:3<81::AID-EVAN3>3.0.CO;2-A; Preuss TM, 2017, ON HUMAN NATURE: BIOLOGY, PSYCHOLOGY, ETHICS, POLITICS, AND RELIGION, P125, DOI 10.1016/B978-0-12-420190-3.00008-9; Preuss TM, 2004, NAT REV GENET, V5, P850, DOI 10.1038/nrg1469; Prum RO, 2012, PHILOS T R SOC B, V367, P2253, DOI 10.1098/rstb.2011.0285; Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537; Radford A, 2021, PR MACH LEARN RES, V139; Rastall P., 2021, Synaesthesia, onomatopoeia and the origin of language, V24; Renfrew C., 1994, Towards a cognitive archaeology; Revonsuo A, 1999, CONSCIOUS COGN, V8, P173, DOI 10.1006/ccog.1999.0384; Rilling JK, 2014, TRENDS COGN SCI, V18, P46, DOI 10.1016/j.tics.2013.09.013; Rita M., 2022, Advances in Neural Information Processing Systems, V35, P1389; Roberts P., 2022, Materials, and Environments; Roberts P, 2016, QUATERN INT, V405, P8, DOI 10.1016/j.quaint.2015.03.011; Rosati AG, 2007, CURR BIOL, V17, P1663, DOI 10.1016/j.cub.2007.08.033; Russek EM, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005768; Sahoo P, 2024, Arxiv, DOI [arXiv:2402.07927, DOI 10.48550/ARXIV.2402.07927]; Savage-Rumbaugh E.S., 1994, Kanzi: The ape at the brink of the human mind; SCHLEIDT W M, 1974, Zeitschrift fuer Tierpsychologie, V36, P184; Schmandt-Besserat D., 1992, WRITING COUNTING CUN; Schmidt S, 2021, NEUROIMAGE, V225, DOI 10.1016/j.neuroimage.2020.117502; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Scott-Phillips T., 2015, SPEAKING OUR MINDS W; Seghers E, 2014, REV GEN PSYCHOL, V18, P263, DOI 10.1037/gpr0000015; Seiver E, 2013, CHILD DEV, V84, P443, DOI 10.1111/j.1467-8624.2012.01865.x; Semon R., 1921, The Mneme; Shanahan M., 2022, arXiv; Shanahan M, 2023, NATURE, V623, P493, DOI 10.1038/s41586-023-06647-8; Shaw-Williams Kim, 2017, Biology Theory, V12, P195, DOI 10.1007/s13752-017-0278-2; Sherwood CC, 2008, J ANAT, V212, P426, DOI 10.1111/j.1469-7580.2008.00868.x; Silver D, 2017, Arxiv, DOI arXiv:1712.01815; Smith L., 2000, Becoming a word learner: A debate on lexical acquisition, P51; Sobel DM, 2004, COGNITIVE SCI, V28, P303, DOI 10.1016/j.cogsci.2003.11.001; Pereira-Pedro AS, 2020, J HUM EVOL, V142, DOI 10.1016/j.jhevol.2020.102770; Spiridonov V, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00002; Steels L., 1999, TALKING HEADS EXPT; Stout D, 2017, P NATL ACAD SCI USA, V114, P7861, DOI 10.1073/pnas.1620738114; Suddendorf T, 2007, BEHAV BRAIN SCI, V30, P299, DOI 10.1017/S0140525X07001975; Számadó S, 2006, TRENDS ECOL EVOL, V21, P555, DOI 10.1016/j.tree.2006.06.021; Szilágyi A, 2023, PHILOS T R SOC B, V378, DOI 10.1098/rstb.2021.0411; Tang KS, 2020, COGNITION INSTRUCT, V38, P474, DOI 10.1080/07370008.2020.1745803; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Tennie C, 2017, CURR ANTHROPOL, V58, P652, DOI 10.1086/693846; Thompson RKR, 2000, COGNITIVE SCI, V24, P363; TOMASELLO M, 1993, BEHAV BRAIN SCI, V16, P495, DOI 10.1017/S0140525X0003123X; TOMASELLO M, 1995, COGNITIVE DEV, V10, P131, DOI 10.1016/0885-2014(95)90021-7; Tomasello M, 2008, JEAN NICOD LECT, P1; Tomasello M, 2009, BEHAV BRAIN SCI, V32, P470, DOI 10.1017/S0140525X09990744; Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Tversky B., 2014, Handbook of Human Centric Visualization, P3, DOI 10.1007/978-1-4614-7485-21; Tversky B., 2005, CAMBRIDGE HDB THINKI, P209, DOI DOI 10.1006/COGP.1998.0702; van de Waal E, 2014, ANIM BEHAV, V90, P41, DOI 10.1016/j.anbehav.2014.01.015; van Dijk L, 2017, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01969; van Leeuwen EJC, 2014, ANIM COGN, V17, P1421, DOI 10.1007/s10071-014-0766-8; van Leeuwen EJC, 2012, P ROY SOC B-BIOL SCI, V279, P4362, DOI 10.1098/rspb.2012.1543; van Mazijk C., 2022, Symbolism in the middle palaeolithic: A phenomenological account of practice-embedded symbolic behavior; van Mazijk C, 2024, EUR J PHILOS, V32, P130, DOI 10.1111/ejop.12831; Vanhaeren M, 2013, J HUM EVOL, V64, P500, DOI 10.1016/j.jhevol.2013.02.001; Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1; Vaswani A, 2017, ADV NEUR IN, V30; Verendeev A, 2017, CURR OPIN BEHAV SCI, V16, P41, DOI 10.1016/j.cobeha.2017.02.003; von Frisch, 1967, DANCE LANGUAGE ORIEN; Von Glasersfeld E., 2013, Radical constructivism; Vonk J, 2002, J EXP ANAL BEHAV, V78, P315, DOI 10.1901/jeab.2002.78-315; Vygotsky L. S., 1994, The Vygotsky Reader; Wadley L, 2010, CURR ANTHROPOL, V51, pS111, DOI 10.1086/649836; Walker CM, 2017, COGNITION, V166, P23, DOI 10.1016/j.cognition.2017.05.013; Walls M., 2019, Philosophy Technology, V32, P265, DOI [10.1007/s13347-017-0300-4, DOI 10.1007/S13347-017-0300-4]; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Ward D, 2017, TOPOI-INT REV PHILOS, V36, P365, DOI 10.1007/s11245-017-9484-6; Weber T, 2018, Arxiv, DOI arXiv:1707.06203; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Westra E, 2017, REV PHILOS PSYCHOL, V8, P235, DOI 10.1007/s13164-016-0320-5; Whiten A, 2013, ANIM BEHAV, V86, P213, DOI 10.1016/j.anbehav.2013.04.021; Whiten A, 2009, PHILOS T R SOC B, V364, P2417, DOI 10.1098/rstb.2009.0069; Whitworth A, 2014, CHANDOS INF PROF SER, P47; Wiessner P., 1982, Politics and history in band societies, V61, P84; Wigner E. P., 1990, Mathematics and science, P291, DOI [10.1142/97898145034880018, DOI 10.1142/97898145034880018]; Wikenheiser AM, 2016, NAT REV NEUROSCI, V17, P513, DOI 10.1038/nrn.2016.56; Willats J., 2006, Making sense of childrens drawings; Wilson E.O., 1975, P1; Winner E., 2006, HDB CHILD PSYCHOL VO, V2, P859; Withagen R, 2010, THEOR PSYCHOL, V20, P489, DOI 10.1177/0959354310361405; Wynn T., 2012, How to think like a neandertal; Wynn T., 2021, 4e cognition in the lower palaeolithic; Wang JX, 2019, Arxiv, DOI arXiv:1811.05931; Yang J., 2024, arXiv; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; ZAHAVI A, 1975, J THEOR BIOL, V53, P205, DOI 10.1016/0022-5193(75)90111-3; Zeki S., 1999, Inner Vision: An Exploration of Art and the Brain; Zelikman E, 2024, Arxiv, DOI arXiv:2403.09629; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219	335	0	0	0	0	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123	1741-2633		ADAPT BEHAV	Adapt. Behav.	2024 JUN 21	2024										10.1177/10597123241262534	http://dx.doi.org/10.1177/10597123241262534		JUN 2024	35	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Psychology; Social Sciences - Other Topics	UZ1X2		hybrid			2024-07-03	WOS:001251806500001
J	Hirosawa, T; Shimizu, T				Hirosawa, Takanobu; Shimizu, Taro			Enhancing clinical reasoning with Chat Generative Pre-trained Transformer: a practical guide	DIAGNOSIS			English	Article						natural language processing; large language model; diagnostic excellence; diagnosis; self-learning		Objectives: This study aimed to elucidate effective methodologies for utilizing the generative artificial intelligence (AI) system, namely the Chat Generative Pre-trained Transformer (ChatGPT), in improving clinical reasoning abilities among clinicians.Methods: We conducted a comprehensive exploration of the capabilities of ChatGPT, emphasizing two main areas: (1) efficient utilization of ChatGPT, with a focus on application and language selection, input methodology, and output verification; and (2) specific strategies to bolster clinical reasoning using ChatGPT, including self-learning via simulated clinical case creation and engagement with published case reports.Results: Effective AI-based clinical reasoning development requires a clear delineation of both system roles and user needs. All outputs from the system necessitate rigorous verification against credible medical resources. When used in self-learning scenarios, capabilities of ChatGPT in clinical case creation notably enhanced disease comprehension.Conclusions: The efficient use of generative AIs, as exemplified by ChatGPT, can impressively enhance clinical reasoning among medical professionals. Adopting these cutting-edge tools promises a bright future for continuous advancements in clinicians' diagnostic skills, heralding a transformative era in digital healthcare.	[Hirosawa, Takanobu; Shimizu, Taro] Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu Cho, Mibu, Tochigi 3210293, Japan	Dokkyo Medical University	Hirosawa, T (corresponding author), Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu Cho, Mibu, Tochigi 3210293, Japan.	hirosawa@dokkyomed.ac.jp	Hirosawa, Takanobu/AFS-0531-2022	Hirosawa, Takanobu/0000-0002-3573-8203	This study was made possible using the resources from the Department of Diagnostic and Generalist Medicine, Dokkyo Medical University.	This study was made possible using the resources from the Department of Diagnostic and Generalist Medicine, Dokkyo Medical University.	This study was made possible using the resources from the Department of Diagnostic and Generalist Medicine, Dokkyo Medical University.	Aydin O., 2023, Google Bard generated literature review: metaverse; Elstein AS, 2002, BRIT MED J, V324, P729, DOI 10.1136/bmj.324.7339.729; Harte, 2013, CLIN CARE CONUNDRUMS; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; KASSIRER JP, 1992, NEW ENGL J MED, V326, P60, DOI 10.1056/NEJM199201023260112; OpenAI, 2023, GPT-4 technical report; Patrizio, 2023, GOOGLE BARD TECHTARG; Shimizu, 2023, MEDEDPUBLISH, V13, P21; Touvron H., 2023, arXiv	10	2	2	16	19	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-8011	2194-802X		DIAGNOSIS	Diagnosis	FEB 19	2024	11	1					102	105		10.1515/dx-2023-0116	http://dx.doi.org/10.1515/dx-2023-0116		OCT 2023	4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	HZ6R6	37779351				2024-07-03	WOS:001077103200001
J	Miloski, B				Miloski, Brian			Opportunities for artificial intelligence in healthcare and in vitro fertilization	FERTILITY AND STERILITY			English	Article						Artificial intelligence; machine learning; large language models; AI; NLP; generative AI		Artificial intelligence (AI) is understandably garnering an increased share of voice in the general and specialized media. The recent release of several generative AI products has added "touchable"context to fears of the potential negative effects of AI-rampant job loss, "out-of-control"AI, and deep fake videos, to name a few. A productive conversation about AI requires the conversation to recognize AI as a very broad and diverse field with "narrow"and "general"applications. Narrow AI applications are quite common and widely deployed today. A fearless conversation can be had regarding how narrow AI can be more widely adopted while allowing for increased transparency and comfort. General AI is more complex and generally leads to what level of government regulation may be necessary (if practically possible). This essay focuses on the application of narrow AI in healthcare and fertility. Pros, cons, challenges, and recommendations are presented for a general audience seeking to understand the application of narrow AI. Successful and unsuccessful examples are provided with frameworks for approaching the narrow AI opportunity. (Fertil Sterile 2023;120:3-7. & COPY;2023 by American Society for Reproductive Medicine.)	[Miloski, Brian] ALQIMI, 2101 Gaither Rd,Suite 510, Rockville, MD 20850 USA		Miloski, B (corresponding author), ALQIMI, 2101 Gaither Rd,Suite 510, Rockville, MD 20850 USA.	brian.miloski@alqimi.com						[Anonymous], 2006, The Economist; Buoy Health, BOUY; Digital Diagnostics, IDX DR; National Venture Capital Association, Q1 2023 PITCHB NVCA; Schlingman JP, 2019, ARTIF INTELL; Turner G., UK HLTH DEP END DATA; viome.com, BAN MEET G VIE VIOM	7	2	2	9	24	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0015-0282	1556-5653		FERTIL STERIL	Fertil. Steril.	JUL	2023	120	1					3	7		10.1016/j.fertnstert.2023.05.006	http://dx.doi.org/10.1016/j.fertnstert.2023.05.006		JUN 2023	5	Obstetrics & Gynecology; Reproductive Biology	Science Citation Index Expanded (SCI-EXPANDED)	Obstetrics & Gynecology; Reproductive Biology	L8SG8	37178998	hybrid			2024-07-03	WOS:001025902100001
J	Kufel, J; Paszkiewicz, I; Bielówka, M; Bartnikowska, W; Janik, M; Stencel, M; Czogalik, L; Gruszczynska, K; Mielcarska, S				Kufel, Jakub; Paszkiewicz, Iga; Bielowka, Michal; Bartnikowska, Wiktoria; Janik, Michal; Stencel, Magdalena; Czogalik, Lukasz; Gruszczynska, Katarzyna; Mielcarska, Sylwia			Will ChatGPT pass the Polish specialty exam in radiology and diagnostic imaging? Insights into strengths and limitations	POLISH JOURNAL OF RADIOLOGY			English	Article						ChatGPT; deep learning; large language model; artificial intelligence		Purpose: Rapid development of artificial intelligence has aroused curiosity regarding its potential applications in medical field. The purpose of this article was to present the performance of ChatGPT, a state-of-the-art language model in relation to pass rate of national specialty examination (PES) in radiology and imaging diagnostics within Polish education system. Additionally, the study aimed to identify the strengths and limitations of the model through a detailed analysis of issues raised by exam questions. Material and methods: The present study utilized a PES exam consisting of 120 questions, provided by Medical Examinations Center in Lodz. Questions were administered using openai.com platform that grants free access to GPT-3.5 model. All questions were categorized according to Bloom's taxonomy to assess their complexity and difficulty. Following the answer to each exam question, ChatGPT was asked to rate its confidence on a scale of 1 to 5 to evaluate the accuracy of its response. Results: ChatGPT did not reach the pass rate threshold of PES exam (52%); however, it was close in certain question categories. No significant differences were observed in the percentage of correct answers across question types and sub-types. Conclusions: The performance of the ChatGPT model in the pass rate of PES exam in radiology and imaging diagnostics in Poland is yet to be determined, which requires further research on improved versions of ChatGPT.	[Kufel, Jakub] Med Univ Silesia, Fac Med Sci Zabrze, Dept Biophys, Zabrze, Poland; [Paszkiewicz, Iga] Tytus Chalubinski Hosp, Zakopane, Poland; [Bielowka, Michal; Janik, Michal; Stencel, Magdalena; Czogalik, Lukasz] Med Univ Silesia, Fac Med Sci Zabrze, Prof Zbigniew Religa Student Sci Assoc, Dept Biophys, Zabrze, Poland; [Bartnikowska, Wiktoria] Med Univ Silesia, Fac Med Sci Katowice, Katowice, Poland; [Gruszczynska, Katarzyna] Med Univ Silesia, Fac Med Sci Katowice, Dept Radiol & Nucl Med, Katowice, Poland; [Mielcarska, Sylwia] Med Univ Silesia, Fac Med Sci Zabrze, Dept Med & Mol Biol, Zabrze, Poland	Medical University Silesia; Medical University Silesia; Medical University Silesia; Medical University Silesia; Medical University Silesia	Kufel, J (corresponding author), Med Univ Silesia, Fac Med Sci Zabrze, Dept Biophys, Zabrze, Poland.	jakubkufel92@gmail.com	Bielówka, Michał/JLL-4813-2023; Kufel, Jakub/GSN-6436-2022	Bielówka, Michał/0009-0007-0609-1678; Kufel, Jakub/0000-0001-7633-3600; Gruszczynska, Katarzyna/0000-0002-0863-4492; Mielcarska, Sylwia/0000-0003-4228-9343				Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bloom BS., 2001, TAXONOMY LEARNING TE, DOI DOI 10.7771/1541-5015.1355; Duarte Fabio, 2023, Number of chatgpt users; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; SAWIN EI, 1957, ELEM SCHOOL J, V57, P343, DOI 10.1086/459563; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; thinkwithgoogle, The Doctor's Digital Path to Treatment	10	3	3	5	9	INT SCIENTIFIC INFORMATION INC	SMITHTOWN	361 FOREST LN, SMITHTOWN, NY 11787 USA	0137-7183	1899-0967		POL J RADIOL	Pol. J. Radiol.	SEP 18	2023	88						E430	E434		10.5114/pjr.2023.131215	http://dx.doi.org/10.5114/pjr.2023.131215			5	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	S8QC5	37808173	Green Published, gold			2024-07-03	WOS:001073749500001
J	Gray, MA; Savelka, J; Oliver, WM; Ashley, KD				Gray, Morgan A.; Savelka, Jaromir; Oliver, Wesley M.; Ashley, Kevin D.			Empirical legal analysis simplified: reducing complexity through automatic identification and evaluation of legally relevant factors	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Article						machine learning; interpretability; annotation; large language models; generative classification	CONSTRUCTION; AGREEMENT; SEARCH	This paper investigates the potential for reducing the complexity of AI and Law and empirical legal studies projects through a novel annotation methodology that relies on GPT Family Models to assist human annotators. Improving the speed, cost and quality of annotation could greatly benefit such projects. In modelling types of legal claims, researchers in the fields of empirical legal studies and AI and Law have long relied on manually annotating factors in case texts. To demonstrate our methodology, we employ cases and factors regarding whether a police officer has constitutional authority to detain a motorist on the basis of the officer's suspicion that the motorist is trafficking drugs. Our results demonstrate how recent advances in text analytics can reduce the burden of identifying factors in large numbers of cases and improve machine learning models' predictions of case outcomes.This article is part of the theme issue 'A complexity science approach to law and governance'.	[Gray, Morgan A.; Ashley, Kevin D.] Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA; [Ashley, Kevin D.] Univ Pittsburgh, Sch Law, Pittsburgh, PA USA; [Savelka, Jaromir] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA USA; [Oliver, Wesley M.] Duquesne Univ, Thomas R Kline Sch Law, Pittsburgh, PA USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Carnegie Mellon University; Duquesne University	Gray, MA (corresponding author), Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA.	mag454@pitt.edu	Savelka, Jaromir/GOK-0488-2022	Savelka, Jaromir/0000-0002-3674-5456; Gray, Morgan/0000-0002-3800-2103	Pitt Momentum Funds Scaling Grant; Pitt Momentum Funds Teaming and Scaling Grants	Pitt Momentum Funds Scaling Grant; Pitt Momentum Funds Teaming and Scaling Grants	We acknowledge support for this research from Pitt Momentum Funds Teaming and Scaling Grants, and from the Center for Text Analytic Methods in Legal Studies at the University of Pittsburgh (www.law.pitt.edu/center-text-analytic-methods-legal-studies).	Francia OAA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010200; Aletras N, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.93; Ashley, 1990, MODELING LEGAL ARGUM; Ashley KD, 2017, ARTIFICIAL INTELLIGENCE AND LEGAL ANALYTICS: NEW TOOLS FOR LAW PRACTICE IN THE DIGITAL AGE, P1, DOI 10.1017/9781316761380; Ashley KD, 2009, ARTIF INTELL LAW, V17, P125, DOI 10.1007/s10506-009-9077-9; Bambauer J, 2015, MICH LAW REV, V113, P461; Beebe B., 2020, NYU J Intell Prop & Ent L, V10, P1; Beebe B, 2008, U PENN LAW REV, V156, P549, DOI 10.2307/40041357; Beebe B, 2006, CALIF LAW REV, V94, P1581, DOI 10.2307/20439078; Bench-Capon TJM, 2017, ARTIF INTELL LAW, V25, P205, DOI 10.1007/s10506-017-9201-1; Blair-Stanek A, 2023, Arxiv, DOI arXiv:2302.06100; Bommarito J., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2301.04408, 10.48550/arXiv.2301.04408]; Branting LK, 2021, ARTIF INTELL LAW, V29, P213, DOI 10.1007/s10506-020-09273-1; Lipton ZC, 2017, Arxiv, DOI [arXiv:1606.03490, 10.48550/arXiv.1606.03490]; Chalkidis I, 2023, Arxiv, DOI [arXiv:2304.12202, 10.2139/ssrn.4385460]; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Chalkidis I, 2019, Arxiv, DOI arXiv:1906.02059; Chen HH, 2022, IEEE T RELIAB, V71, P657, DOI 10.1109/TR.2022.3156126; Chen HH, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102798; Chorley A, 2005, ARTIF INTELL LAW, V13, P323, DOI 10.1007/s10506-006-9016-y; Chorley A, 2005, ARTIF INTELL LAW, V13, P9, DOI 10.1007/s10506-006-9004-2; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cormack GV, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1039, DOI 10.1145/2983323.2983776; Falakmasir MH, 2017, FRONT ARTIF INTEL AP, V302, P183, DOI 10.3233/978-1-61499-838-9-183; Gray M., 2023, INT C ARTIFICIAL INT; Gray Morgan A., 2022, LEGAL KNOWLEDGE AND INFORMATION SYSTEMS, P53; Gretok E, 2020, FRONT ARTIF INTEL AP, V334, P63, DOI 10.3233/FAIA200850; Hamilton S, 2023, arXiv; Hendrycks D., 2021, arXiv; Hogan C., 2009, PROC 12 INT C ARTIFI, P194; Janatian S, 2023, Arxiv, DOI arXiv:2311.04911; Kastellec JP, 2010, J EMPIR LEGAL STUD, V7, P202, DOI 10.1111/j.1740-1461.2010.01176.x; Katz DM, 2024, PHILOS T R SOC A, V382, DOI 10.1098/rsta.2023.0254; LaFave WR, 2004, MICH LAW REV, V102, P1843, DOI 10.2307/4141969; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Li JJ, 2019, J SIGNAL PROCESS SYS, V91, P1159, DOI 10.1007/s11265-018-1429-9; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo BF, 2017, Arxiv, DOI arXiv:1707.09168; Mackaay Ejan., 1974, DATENVERARBEITUNG RE, V3, P302; Matthias Grabmair, 2016, THESIS U PITTSBURGH; Nguyen HT, 2022, REV SOCIONETWORK STR, V16, P135, DOI 10.1007/s12626-022-00102-2; OpenAI, 2023, GPT-4 Technical Report; Rempell S., 2022, Buffalo L Rev., V70, P1755, DOI [10.2139/ssrn.4095435, DOI 10.2139/SSRN.4095435]; Rissland E. L., 1995, Fifth International Conference on Artificial Intelligence and Law. Proceedings of the Conference, P127, DOI 10.1145/222092.222209; Sarkar R., 2021, P NATURAL LEGAL LANG, P102, DOI 10.18653/v1/2021.nllp-1.10; Savelka Jaromir, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P129, DOI 10.1145/3462757.3466149; Savelka J., 2023, PROC 6 WORKSHOP AUTO; Savelka J., 2023, PROC WORKSHOP ARTIFI; Savelka J., 2023, arXiv, DOI [10.1145/3594536.3595161, DOI 10.1145/3594536.3595161]; Savelka J., 2021, arXiv; Savelka J, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1279794; Savelka J, 2018, FRONT ARTIF INTEL AP, V313, P111, DOI 10.3233/978-1-61499-935-5-111; Savelka J, 2015, FRONT ARTIF INTEL AP, V279, P101, DOI 10.3233/978-1-61499-609-5-101; Shaikh RA, 2020, PROCEDIA COMPUT SCI, V167, P2393, DOI 10.1016/j.procs.2020.03.292; Shao Hsuan-Lei, 2022, ASIAN J. COMPAR. L, V17, P272; Shao YQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3501; Song DZ, 2022, IEEE ACCESS, V10, P75835, DOI 10.1109/ACCESS.2022.3190408; Tan J., 2023, ARTIFICIAL INTELLIGE; Thanh NH, 2023, Arxiv, DOI arXiv:2304.06912; Cormack GV, 2015, Arxiv, DOI arXiv:1504.06868; Waltl B, 2017, FRONT ARTIF INTEL AP, V302, P11, DOI 10.3233/978-1-61499-838-9-11; Westermann H., 2023, Artificial Intelligence for Access to Justice (AI4AJ 2023); Westermann H, 2020, FRONT ARTIF INTEL AP, V334, P164, DOI 10.3233/FAIA200860; Westermann H, 2019, FRONT ARTIF INTEL AP, V322, P123, DOI 10.3233/FAIA190313; Westermann Hannes, 2019, Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law, P133; Wyner A., 2010, SPLET 2012, P36; Xiao CJ, 2018, Arxiv, DOI arXiv:1807.02478; Xu N, 2020, Arxiv, DOI arXiv:2004.02557; Yu FY, 2022, Arxiv, DOI arXiv:2212.01326; Zhong H., 2020, arXiv; Zhong HX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3540	71	1	1	7	7	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-503X	1471-2962		PHILOS T R SOC A	Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.	APR 15	2024	382	2270							20230155	10.1098/rsta.2023.0155	http://dx.doi.org/10.1098/rsta.2023.0155			19	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	JV6Z5	38403058				2024-07-03	WOS:001175989800009
J	Sallam, M; Barakat, M; Sallam, M				Sallam, Malik; Barakat, Muna; Sallam, Mohammed			A Preliminary Checklist (METRICS) to Standardize the Design and Reporting of Studies on Generative Artificial Intelligence-Based Models in Health Care Education and Practice: Development Study Involving a Literature Review	INTERACTIVE JOURNAL OF MEDICAL RESEARCH			English	Review						guidelines; evaluation; meaningful analytics; large language models; decision support	CHATGPT; PERFORMANCE; BARD; AI	Background: Adherence to evidence-based practice is indispensable in health care. Recently, the utility of generative artificial intelligence (AI) models in health care has been evaluated extensively. However, the lack of consensus guidelines on the design and reporting of findings of these studies poses a challenge for the interpretation and synthesis of evidence. Objective: This study aimed to develop a preliminary checklist to standardize the reporting of generative AI-based studies in health care education and practice. Methods: A literature review was conducted in Scopus, PubMed, and Google Scholar. Published records with "ChatGPT," "Bing," or "Bard" in the title were retrieved. Careful examination of the methodologies employed in the included records was conducted to identify the common pertinent themes and the possible gaps in reporting. A panel discussion was held to establish a unified and thorough checklist for the reporting of AI studies in health care. The finalized checklist was used to evaluate the Results: The final data set that formed the basis for pertinent theme identification and analysis comprised a total of 34 records. The finalized checklist included 9 pertinent themes collectively referred to as METRICS (Model, Evaluation, Timing, Range/Randomization, Individual factors, Count, and Specificity of prompts and language). Their details are as follows: (1) Model used and its exact settings; (2) Evaluation approach for the generated content; (3) Timing of testing the model; (4) Transparency of the data source; (5) Range of tested topics; (6) Randomization of selecting the queries; (7) Individual factors in selecting the queries and interrater reliability; (8) Count of queries executed to test the model; and (9) Specificity of the prompts and language used. The overall mean METRICS score was 3.0 (SD 0.58). The tested METRICS score was acceptable, with the range of Cohen kappa of 0.558 to 0.962 (P<.001 for the 9 tested items). With classification per item, the highest average METRICS score was recorded for the "Model" item, followed by the "Specificity" item, while the lowest scores were recorded for the "Randomization" item (classified as suboptimal) and "Individual factors" item (classified as satisfactory). Conclusions: The METRICS checklist can facilitate the design of studies guiding researchers toward best practices in reporting results. The findings highlight the need for standardized reporting algorithms for generative AI-based studies in health care, considering the variability observed in methodologies and reporting. The proposed METRICS checklist could be a preliminary helpful base to establish a universally accepted approach to standardize the design and reporting of generative AI -based studies in health care, which is a swiftly evolving research topic.	[Sallam, Malik] Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Amman, Jordan; [Sallam, Malik] Jordan Univ Hosp, Dept Clin Labs & Forens Med, Amman, Jordan; [Sallam, Malik] Lund Univ, Fac Med, Dept Translat Med, Malmo, Sweden; [Barakat, Muna] Appl Sci Private Univ, Fac Pharm, Dept Clin Pharm & Therapeut, Amman, Jordan; [Sallam, Mohammed] Mediclin Parkview Hosp, Mediclin Middle East, Dept Pharm, POB 51122, Dubai, U Arab Emirates; [Sallam, Malik] Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Queen Rania Al Abdullah St Aljubeiha, Amman 11942, Jordan	University of Jordan; University of Jordan; Lund University; University of Jordan	Sallam, M (corresponding author), Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Queen Rania Al Abdullah St Aljubeiha, Amman 11942, Jordan.	malik.sallam@ju.edu.jo	Sallam, Dr. Mohammed/HLW-0512-2023; Sallam, Malik/O-5021-2014; Barakat, Muna/AAN-8778-2020	Sallam, Dr. Mohammed/0000-0003-3273-524X; Sallam, Malik/0000-0002-0165-9670; Barakat, Muna/0000-0002-7966-1172				Aiumtrakul N, 2023, J PERS MED, V13, DOI 10.3390/jpm13101457; Al-Ashwal FY, 2023, DRUG HEALTHC PATIENT, V15, P137, DOI 10.2147/DHPS.S425858; Alam F, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1279707; Alfertshofer M, 2024, ANN BIOMED ENG, V52, P1542, DOI 10.1007/s10439-023-03338-3; Ali K, 2024, EUR J DENT EDUC, V28, P206, DOI 10.1111/eje.12937; Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805; Aljindan FK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45043; Alowais SA, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04698-z; Altamimi I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40351; Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8; Baglivo F, 2023, JMIR MED EDUC, V9, DOI 10.2196/51421; Bajwa Junaid, 2021, Future Healthc J, V8, pe188, DOI 10.7861/fhj.2021-0095; Biswas S, 2023, OPHTHAL PHYSL OPT, V43, P1562, DOI 10.1111/opo.13207; Borchert RJ, 2023, JMIR MED EDUC, V9, DOI 10.2196/48978; CASP Qualitative Studies Checklist, Critical Appraisal Skills Programme (CASP); Chen TC, 2023, BMJ NEUROL OPEN, V5, DOI 10.1136/bmjno-2023-000530; Chen ZS, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-02079-x; Choudhury A, 2023, medRxiv, DOI [10.1101/2023.12.07.23299685v1.full, DOI 10.1101/2023.12.07.23299685V1.FULL]; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Doshi R, 2023, medRxiv, DOI [10.1101/2023.06.04.23290786, 10.1101/2023.06.04.23290786, DOI 10.1101/2023.06.04.23290786]; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Ettman CK, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/49936; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ferreira Alana L, 2023, JMIR Dermatol, V6, pe49280, DOI 10.2196/49280; Fijacko N, 2023, RESUSCITATION, V193, DOI 10.1016/j.resuscitation.2023.110009; Flores-Cohaila JA, 2023, JMIR MED EDUC, V9, DOI 10.2196/48039; Fraser H, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/49995; Fuchs Alexander, 2023, Swiss Dent J, V134, P1, DOI 10.61872/sdj-2024-06-01; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Giannos P, 2023, BMJ NEUROL OPEN, V5, DOI 10.1136/bmjno-2023-000451; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Gobira M, 2023, REV ASSOC MED BRAS, V69; Gödde D, 2023, J MED INTERNET RES, V25, DOI 10.2196/49368; Grewal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40135; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Hamed E, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38784; Harzing AW, 2010, Basic metrics based on papers and citations; Hirosawa T, 2023, JMIR MED INF, V11, DOI 10.2196/48808; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Hristidis V, 2023, J MED INTERNET RES, V25, DOI 10.2196/48966; Hsu HY, 2023, JMIR MED EDUC, V9, DOI 10.2196/48433; Huang RST, 2023, JMIR MED EDUC, V9, DOI 10.2196/50514; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Khlaif ZN, 2023, JMIR MED EDUC, V9, DOI [10.2023/1/e47049, 10.2196/47049]; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Kuang YR, 2023, INT J SURG, V109, P2886, DOI 10.1097/JS9.0000000000000571; Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Kung JE, 2023, JBJS OPEN ACCESS, V8, DOI 10.2106/JBJS.OA.23.00056; Lai UH, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1240915; Lakdawala Nehal, 2023, JMIR Dermatol, V6, pe50409, DOI 10.2196/50409; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Liu TM, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.755808; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Malhotra R, 2023, MULTIMED TOOLS APPL, V82, P44977, DOI 10.1007/s11042-023-15295-z; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Miao HY, 2023, J MED INTERNET RES, V25, DOI 10.2196/49963; Mijwil M., 2023, Mesopotamian J Cyber Secur, P18, DOI DOI 10.58496/MJCS/2023/004; Moise A, 2023, CHILDREN-BASEL, V10, DOI 10.3390/children10101634; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Oca MC, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45911; Oztermeli AD, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000034673; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Pugliese N, 2024, CLIN GASTROENTEROL H, V22, DOI 10.1016/j.cgh.2023.08.033; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2024, INTERACT J MED RES, V13, DOI 10.2196/54704; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Sallam M, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1333415; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50629; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.49373; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scherr R, 2023, JMIR MED EDUC, V9, DOI 10.2196/49877; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Sezgin E, 2023, J MED INTERNET RES, V25, DOI 10.2196/49240; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Stephens LD, 2023, TRANSFUS MED REV, V37, DOI 10.1016/j.tmrv.2023.150753; Sun HA, 2023, J MED INTERNET RES, V25, DOI 10.2196/51300; Sun L, 2023, AM J TRANSL RES, V15, P4820; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Taira Kazuya, 2023, JMIR Nurs, V6, pe47305, DOI 10.2196/47305; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Varsha P. S, 2023, International Journal of Information Management Data Insights, V3, DOI DOI 10.1016/J.JJIMEI.2023.100165; von Elm E, 2007, LANCET, V370, P1453, DOI 10.1016/S0140-6736(07)61602-X; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324; Yanagita Y, 2023, JMIR FORM RES, V7, DOI 10.2196/48023; Zhou YSY, 2024, EUR J ORTHOP SURG TR, V34, P927, DOI 10.1007/s00590-023-03742-4	100	5	5	13	13	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1929-073X			INTERACT J MED RES	Interact. J. Med. Res.		2024	13								e54704	10.2196/54704	http://dx.doi.org/10.2196/54704			21	Medicine, Research & Experimental	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine	KC0E8	38276872	gold, Green Published			2024-07-03	WOS:001177636200001
C	Agossah, A; Krupa, F; Perreira Da Silva, M; Le Callet, P			ACM	Agossah, Alexandre; Krupa, Frederique; Perreira Da Silva, Matthieu; Le Callet, Patrick			LLM-Based Interaction for Content Generation: A Case Study on the Perception of Employees in an IT Department	PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2023			English	Proceedings Paper	ACM International Conference on Interactive Media Experiences (IMX)	JUN 12-15, 2023	Nantes Univ, Nantes, FRANCE	Assoc Comp Machinery, ACM SIGCHI, ACM SIGMM, ACM SIGWEB, Meta, You Tube, Tobii, Interdigital, Jellysmack, HEMI + FAME Clusters	Nantes Univ	acceptability; computer-human interaction; large language models; professional context	TECHNOLOGY ACCEPTANCE	In the past years, AI has seen many advances in the field of NLP. This has led to the emergence of LLMs, such as the now famous GPT-3.5, which revolutionise the way humans can access or generate content. Current studies on LLM-based generative tools are mainly interested in the performance of such tools in generating relevant content (code, text or image). However, ethical concerns related to the design and use of generative tools seem to be growing, impacting the public acceptability for specific tasks. This paper presents a questionnaire survey to identify the intention to use generative tools by employees of an IT company in the context of their work. This survey is based on empirical models measuring intention to use (TAM by Davis, 1989, and UTAUT2 by Venkatesh and al., 2008). Our results indicate a rather average acceptability of generative tools, although the more useful the tool is perceived to be, the higher the intention to use seems to be. Furthermore, our analyses suggest that the frequency of use of generative tools is likely to be a key factor in understanding how employees perceive these tools in the context of their work. Following on from this work, we plan to investigate the nature of the requests that may be made to these tools by specific audiences.	[Agossah, Alexandre; Perreira Da Silva, Matthieu; Le Callet, Patrick] Univ Nantes, Ecole Cent Nantes, CNRS, LS2N,UMR 60004, F-440000 Nantes, France; [Agossah, Alexandre; Krupa, Frederique] Ecole Design Nantes Atlantique, Digital Design Lab, F-44200 Nantes, France; [Agossah, Alexandre] Grp Sigma, F-44240 La Chapelle Sur Erdre, France	Nantes Universite; Ecole Centrale de Nantes; Centre National de la Recherche Scientifique (CNRS)	Agossah, A (corresponding author), Univ Nantes, Ecole Cent Nantes, CNRS, LS2N,UMR 60004, F-440000 Nantes, France.	alexandre.agossah@etu.univ-nantes.fr; f.krupa@lecolededesign.com; matthieu.perreiradasilva@univ-nantes.fr; patrick.lecallet@univ-nantes.fr		Krupa, Frederique/0009-0005-3065-2987; PERREIRA DA SILVA, Matthieu/0000-0003-3921-5132; Le callet, Patrick/0000-0002-2143-7063				Agossah Alexandre, 2022, 33 C INT FRANC INT H; Arrieta Alejandro Barredo, 2020, Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI, V58, P82, DOI [10.1016/j.inffus.2019.12.012formationfusion, DOI 10.1016/J.INFFUS.2019.12.012FORMATIONFUSION]; Atarodi S, 2019, PSYCHOL TRAV ORGAN, V25, P191, DOI 10.1016/j.pto.2018.08.001; Bobillier-Chaumon M., 2009, Le travail humain, V72, P355, DOI [10.3917/th.724.0355, DOI 10.3917/TH.724.0355]; Davis F.D., 1989, Al-Suqri, MN, Al-Aufi, AS: Information Seeking Behavior and Technology Adoption, P205; Ferguson Yann., 2019, Visite sociologique d'une entreprise. Les Mutations du travail, P23; Gamkrelidze Tamari, 2021, 55 C SELF; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Marie Louise Pasquier Helene, 2012, Ph.D. Dissertation; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nielsen J., 1994, USABILITY ENG; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Tricot A., 2003, Environnements informatiques pour lapprentissage humain, P391; Venkatesh V, 2012, MIS QUART, V36, P157; Yin M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300509, 10.1109/wimob.2019.8923576]	16	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0028-6				2023							237	241		10.1145/3573381.3603362	http://dx.doi.org/10.1145/3573381.3603362			5	Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2IV		Green Submitted, Bronze			2024-07-03	WOS:001117075100028
C	Kobayashi, S; Kiyono, S; Suzuki, J; Inui, K			Assoc Computat Linguist	Kobayashi, Sosuke; Kiyono, Shun; Suzuki, Jun; Inui, Kentaro			Diverse Lottery Tickets Boost Ensemble from a Single Pretrained Model	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				Ensembling is a popular method used to improve performance as a last resort. However, ensembling multiple models finetuned from a single pretrained model has been not very effective; this could be due to the lack of diversity among ensemble members. This paper proposes Multi-Ticket Ensemble, which finetunes different subnetworks of a single pretrained model and ensembles them. We empirically demonstrated that winning-ticket subnetworks produced more diverse predictions than dense networks, and their ensemble outperformed the standard ensemble on some tasks.	[Kobayashi, Sosuke; Kiyono, Shun; Suzuki, Jun; Inui, Kentaro] Tohoku Univ, Sendai, Miyagi, Japan; [Kobayashi, Sosuke] Preferred Networks Inc, Sendai, Miyagi, Japan; [Kiyono, Shun; Suzuki, Jun; Inui, Kentaro] RIKEN, Tokyo, Japan	Tohoku University; RIKEN	Kobayashi, S (corresponding author), Tohoku Univ, Sendai, Miyagi, Japan.; Kobayashi, S (corresponding author), Preferred Networks Inc, Sendai, Miyagi, Japan.	sosk@preferred.jp; shun.kiyono@riken.jp; jun.suzuki@tohoku.ac.jp; inui@tohoku.ac.jp	Suzuki, Jun/HNP-7464-2023	Suzuki, Jun/0000-0003-3551-4477; Suzuki, Jun/0000-0003-2108-1340	JSPS KAKENHI [JP19H04162]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	We appreciate the helpful comments from the anonymous reviewers. This work was supported by JSPS KAKENHI Grant Number JP19H04162.	Aksela M, 2003, LECT NOTES COMPUT SC, V2709, P84; Allen-Zhu Z, 2021, Arxiv, DOI arXiv:2012.09816; Blalock D., 2020, ARXIV200303033, DOI DOI 10.48550/ARXIV.2003.03033; Cao Steven, 2021, P 2021 C N AM CHAPTE; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; Chen T., 2020, Advances in Neural Information Processing Systems, P15834; Cruz RMO, 2020, J MACH LEARN RES, V21; DAmour A., 2022, INT C LEARNING REPRE; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; Domigos P., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P155; Durasov N, 2021, PROC CVPR IEEE, P13534, DOI 10.1109/CVPR46437.2021.01333; Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234; Gal Y, 2016, PR MACH LEARN RES, V48; Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2; Havasi M., 2021, INT C LEARNING REPRE; Kirillov Alexander, 2016, CVPR TUTORIAL DIVERS; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Levin E., 1989, Proceedings of the Second Annual Workshop on Computational Learning Theory, P245; Liang C., 2021, P 59 ANN M ASS COMPU, P6524, DOI 10.18653/; Liu Y, 1999, NEURAL NETWORKS, V12, P1399, DOI 10.1016/S0893-6080(99)00073-8; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Pang TY, 2019, PR MACH LEARN RES, V97; Prasanna Sai, 2020, ARXIV200500561; Radiya-Dixit E, 2020, PR MACH LEARN RES, V108, P2435; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Rame A., 2021, ICLR; Sanh Victor, 2020, ADV NEURAL INFORM PR, V33, P20378; Sharir O, 2020, ARXIV PREPRINT ARXIV; Skalak D. B., 1996, P AM ASS ART INT AAA, V1129, P1133; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Tay Yi., 2022, INT C LEARNING REPRE; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Wolf Thomas, 2020, P C EMP METH NAT LAN, DOI DOI 10.18653/V1/2020.EMNLP-DEMOS.6; Wu Yanzhao, 2021, PROC CVPR IEEE, P16469; Yule GU, 1900, PHILOS T R SOC LOND, V194, P257, DOI 10.1098/rsta.1900.0019; Zhang Zhilu, 2021, EX PLURES SPLITTING; Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2226	42	0	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							42	50						9	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900004
J	Zhao, ZW; Li, ZY; Yu, NW				Zhao, Zhongwei; Li, Zhenye; Yu, Nengwang			Re: Michael Eppler, Conner Ganjavi, Lorenzo Storino Ramacciotti, et al. Awareness and Use of ChatGPT and Large Language Models: A Prospective Cross-sectional Global Survey in Urology. Eur Urol. 2024;85:146-53	EUROPEAN UROLOGY			English	Letter									[Zhao, Zhongwei; Yu, Nengwang] Shandong Univ, Dept Urol, Qilu Hosp, Jinan 250012, Shandong, Peoples R China; [Li, Zhenye] Shandong Univ, Cheeloo Coll Med, Jinan, Peoples R China	Shandong University; Shandong University	Yu, NW (corresponding author), Shandong Univ, Dept Urol, Qilu Hosp, Jinan 250012, Shandong, Peoples R China.	qiluyunengwang@hotmail.com		Yu, Nengwang/0000-0002-3488-2270	National Natural Science Foundation of China [82272834]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Acknowledgments: We thank the National Natural Science Foundation of China (grant no. 82272834) for support.	Eppler M, 2024, EUR UROL, V85, P146, DOI 10.1016/j.eururo.2023.10.014; Harenberg S, 2022, INT REV SPORT EXER P, DOI 10.1080/1750984X.2022.2095658; Hornyak Tim, 2023, Nature, DOI 10.1038/d41586-023-02868-z; Napier AD, 2014, LANCET, V384, P1607, DOI 10.1016/S0140-6736(14)61603-2	4	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0302-2838	1873-7560		EUR UROL	Eur. Urol.	MAR	2024	85	3					e83	e84		10.1016/j.eururo.2023.12.007	http://dx.doi.org/10.1016/j.eururo.2023.12.007		MAR 2024	2	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	NS1T2	38143217				2024-07-03	WOS:001202357800001
J	Gong, T; Shuai, L; Mislevy, RJ				Gong, Tao; Shuai, Lan; Mislevy, Robert J.			Sociocognitive Processes and Item Response Models: A Didactic Example	JOURNAL OF EDUCATIONAL MEASUREMENT			English	Article							LANGUAGE; SIMULATION; EVOLUTION	The usual interpretation of the person and task variables in between-persons measurement models such as item response theory (IRT) is as attributes of persons and tasks, respectively. They can be viewed instead as ensemble descriptors of patterns of interactions among persons and situations that arise from sociocognitive complex adaptive system (CASs). This view offers insights for interpreting and using between-persons measurement models and connecting with sociocognitive research. In this article, we use data generated from an agent-based model to illustrate relations between "social" and "cognitive" features of a simple underlying CAS and the variables of an IRT model fit to resulting data. We note how the ideas connect to explanatory item response modeling and briefly comment on implications for score interpretations and uses in practice.	[Gong, Tao; Shuai, Lan; Mislevy, Robert J.] Educ Testing Serv, Princeton, NJ 08540 USA; [Gong, Tao] Google, 111 8th Ave, New York, NY 10011 USA; [Shuai, Lan] Travelers, Large Language Models, 485 Lexington Ave, New York, NY 10017 USA; [Mislevy, Robert J.] Univ Maryland, College Pk, MD USA	Educational Testing Service (ETS); Google Incorporated; University System of Maryland; University of Maryland College Park	Gong, T (corresponding author), Educ Testing Serv, Princeton, NJ 08540 USA.; Gong, T (corresponding author), Google, 111 8th Ave, New York, NY 10011 USA.	gtojty@gmail.com; susan.shuai@gmail.com; rmislevy@umd.edu		Gong, Tao/0000-0002-0587-7544	Dr. Mislevyamp;apos;s work was supported by Educational Testing Service through Frederic M. Lord Chair in Measurement activities.; Educational Testing Service	Dr. Mislevyamp;apos;s work was supported by Educational Testing Service through Frederic M. Lord Chair in Measurement activities.; Educational Testing Service	Dr. Mislevy & apos;s work was supported by Educational Testing Service through Frederic M. Lord Chair in Measurement activities.	Anderson JR, 2004, PSYCHOL REV, V111, P1036, DOI 10.1037/0033-295x.111.4.1036; [Anonymous], 2004, Explanatory item response models: A generalized linear and nonlinear approach; Beckner C, 2009, LANG LEARN, V59, P1; Byrne D., 2002, INTERPRETING QUANTIT; Camazine S., 2001, Self-Organization in Biological Systems; Ellis N. C., 2009, LANGUAGE COMPLEX ADA, V3; Ercikan K., 2017, Validation of score meaning for the next generation of assesssments: The use of response processes; Gong T, 2014, PHYS LIFE REV, V11, P280, DOI 10.1016/j.plrev.2013.11.009; Gong T, 2013, LANG SCI, V40, P12, DOI 10.1016/j.langsci.2013.04.002; Gong T, 2012, P ROY SOC B-BIOL SCI, V279, P4643, DOI 10.1098/rspb.2012.1431; Holland J.H., 2005, Language acquisition, change and emergence: Essays in evolutionary linguistics, P411; Jackson JC, 2017, SOC PSYCHOL PERS SCI, V8, P387, DOI 10.1177/1948550617691100; Jansson F, 2015, LANG DYN CHANG, V5, P1, DOI 10.1163/22105832-00501005; Ke J, 2008, COMMUN COMPUT PHYS, V3, P935; Ke Jinyun, 2002, Complexity, V7, P41, DOI 10.1002/cplx.10030; Kintsch W., 1998, Comprehension: A paradigm for cognition; Kirby S, 2002, ARTIF LIFE, V8, P185, DOI 10.1162/106454602320184248; Latour B., 2005, REASSEMBLING SOCIAL; Lord F. M., 1968, Statistical theories of mental test scores; Macal CM, 2005, PROCEEDINGS OF THE 2005 WINTER SIMULATION CONFERENCE, VOLS 1-4, P2, DOI 10.1109/WSC.2005.1574234; Maul A, 2016, MEASUREMENT, V79, P311, DOI 10.1016/j.measurement.2015.11.001; Messick S., 1998, MULTIPLE CHOICE EVAL; Millsap R.E., 2011, Statistical Approaches to Measurement Invariance, V1st ed., DOI [10.4324/9780203821961, DOI 10.4324/9780203821961]; Mislevy R.J., 2018, Sociocognitive Foundations of Educational Measurement; Oliveri M., 2011, Journal of Psychological Test and Assessment Modeling, V53, P315; Randall J, 2021, EDUC MEAS-ISSUES PRA, V40, P82, DOI 10.1111/emip.12429; Rupp A. A., 2016, WILEY HDB COGNITION; Sperber D., 1996, EXPLAINING CULTURE N; Strauss ClaudiaNaomi Quinn., 1998, COGNITIVE THEORY CUL; Van der Linden W. J., 2018, HDB MODERN ITEM RESP; Wagner K, 2003, ADAPT BEHAV, V11, P37, DOI 10.1177/10597123030111003; Wang N., 2022, CULTURALLY RESPONSIV; Wertsch J.V., 1994, Mind, Culture, and Activities, V1, P202, DOI [10.1080/10749039409524672, DOI 10.1080/10749039409524672]; Wiley DE, 1996, IMPLEMENTING PERFORMANCE ASSESSMENT, P61; Young R.F., 2009, Discursive practice in language learning and teaching	35	1	1	3	3	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0022-0655	1745-3984		J EDUC MEAS	J. Educ. Meas.	MAR	2024	61	1					150	173		10.1111/jedm.12376	http://dx.doi.org/10.1111/jedm.12376		SEP 2023	24	Psychology, Educational; Psychology, Applied; Psychology, Mathematical	Social Science Citation Index (SSCI)	Psychology	JH5S7		Bronze			2024-07-03	WOS:001070195500001
J	Hu, YN; Hu, ZY; Liu, WJ; Gao, AT; Wen, SH; Liu, S; Lin, ZT				Hu, Yanni; Hu, Ziyang; Liu, Wenjing; Gao, Antian; Wen, Shanhui; Liu, Shu; Lin, Zitong			Exploring the potential of ChatGPT as an adjunct for generating diagnosis based on chief complaint and cone beam CT radiologic findings	BMC MEDICAL INFORMATICS AND DECISION MAKING			English	Article						Large language model; CBCT; Dental Disease; Neoplastic/cystic diseases; Radiologic finding; Radiologic impression; Diagnosis		AimThis study aimed to assess the performance of OpenAI's ChatGPT in generating diagnosis based on chief complaint and cone beam computed tomography (CBCT) radiologic findings.Materials and methods102 CBCT reports (48 with dental diseases (DD) and 54 with neoplastic/cystic diseases (N/CD)) were collected. ChatGPT was provided with chief complaint and CBCT radiologic findings. Diagnostic outputs from ChatGPT were scored based on five-point Likert scale. For diagnosis accuracy, the scoring was based on the accuracy of chief complaint related diagnosis and chief complaint unrelated diagnoses (1-5 points); for diagnosis completeness, the scoring was based on how many accurate diagnoses included in ChatGPT's output for one case (1-5 points); for text quality, the scoring was based on how many text errors included in ChatGPT's output for one case (1-5 points). For 54 N/CD cases, the consistence of the diagnosis generated by ChatGPT with pathological diagnosis was also calculated. The constitution of text errors in ChatGPT's outputs was evaluated.ResultsAfter subjective ratings by expert reviewers on a five-point Likert scale, the final score of diagnosis accuracy, diagnosis completeness and text quality of ChatGPT was 3.7, 4.5 and 4.6 for the 102 cases. For diagnostic accuracy, it performed significantly better on N/CD (3.8/5) compared to DD (3.6/5). For 54 N/CD cases, 21(38.9%) cases have first diagnosis completely consistent with pathological diagnosis. No text errors were observed in 88.7% of all the 390 text items.ConclusionChatGPT showed potential in generating radiographic diagnosis based on chief complaint and radiologic findings. However, the performance of ChatGPT varied with task complexity, necessitating professional oversight due to a certain error rate.	[Hu, Yanni; Hu, Ziyang; Liu, Wenjing; Gao, Antian; Wen, Shanhui; Liu, Shu; Lin, Zitong] Nanjing Univ, Affiliated Hosp, Nanjing Stomatol Hosp, Med Sch,Inst Stomatol,Dept Dentomaxillofacial Radi, Nanjing, Jiangsu, Peoples R China; [Hu, Ziyang] Shenzhen Longhua Dist Cent Hosp, Dept Stomatol, Shenzhen, Peoples R China	Nanjing University; Shenzhen Longhua District Central Hospital	Lin, ZT (corresponding author), Nanjing Univ, Affiliated Hosp, Nanjing Stomatol Hosp, Med Sch,Inst Stomatol,Dept Dentomaxillofacial Radi, Nanjing, Jiangsu, Peoples R China.	linzitong_710@163.com	hu, yanni/GSO-3718-2022; Liu, Wenjing/B-3816-2019; Hu, Ziyang/CAF-5159-2022; Lin, Zitong/AAW-3661-2021; Lin, Zitong/AEL-9500-2022	Liu, Wenjing/0000-0002-9441-8859; Lin, Zitong/0000-0002-3733-4974; Lin, Zitong/0000-0002-3733-4974; Hu, Ziyang/0000-0002-2537-5701	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Not applicable.	Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Bhayana R, 2023, Radiology; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Boeken T, 2023, DIAGN INTERV IMAG, V104, P1, DOI 10.1016/j.diii.2022.11.004; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Doshi R, 2023, medRxiv, V2006; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Gunderman RB, 2022, ACAD RADIOL, V29, P1129, DOI 10.1016/j.acra.2022.04.002; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu MF, 2022, IEEE T CYBERNETICS, V52, P1247, DOI 10.1109/TCYB.2020.2997034; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Mago J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42133; Palagin O., 2023, Int J Comput, V22, P170, DOI [10.47839/ijc.22.2.3086, DOI 10.47839/IJC.22.2.3086]; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Rahsepar AA., 2023, Radiology, V307, pe230922, DOI [10.1148/radiol.230922, DOI 10.1148/RADIOL.230922]; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Selivanov A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31223-5; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Srivastav S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41435; Stefanini M, 2023, IEEE T PATTERN ANAL, V45, P539, DOI 10.1109/TPAMI.2022.3148210; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6	27	0	0	5	5	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1472-6947		BMC MED INFORM DECIS	BMC Med. Inform. Decis. Mak.	FEB 19	2024	24	1							55	10.1186/s12911-024-02445-y	http://dx.doi.org/10.1186/s12911-024-02445-y			9	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	IY4H0	38374067	gold			2024-07-03	WOS:001169882500001
J	Lughbi, H; Mars, M; Almotairi, K				Lughbi, Huda; Mars, Mourad; Almotairi, Khaled			CybAttT: A Dataset of Cyberattack News Tweets for Enhanced Threat Intelligence	DATA			English	Article						cyberattacks; dataset; labeling; tweets; classification; machine learning; large language models		The continuous developments in information technologies have resulted in a significant rise in security concerns, including cybercrimes, unauthorized access, and cyberattacks. Recently, researchers have increasingly turned to social media platforms like X to investigate cyberattacks. Analyzing and collecting news about cyberattacks from tweets can efficiently provide crucial insights into the attacks themselves, including their impacts, occurrence regions, and potential mitigation strategies. However, there is a shortage of labeled datasets related to cyberattacks. This paper describes CybAttT, a dataset of 36,071 English cyberattack-related tweets. These tweets are manually labeled into three classes: high-risk news, normal news, and not news. Our final overall Inner Annotation agreement was 0.99 (Fleiss kappa), which represents high agreement. To ensure dataset reliability and accuracy, we conducted rigorous experiments using different supervised machine learning algorithms and various fine-tuned language models to assess its quality and suitability for its intended purpose. A high F1-score of 87.6% achieved using the CybAttT dataset not only demonstrates the potential of our approach but also validates the high quality and thoroughness of its annotations. We have made our CybAttT dataset accessible to the public for research purposes.	[Lughbi, Huda; Mars, Mourad; Almotairi, Khaled] Umm Alqura Univ, Coll Comp, Mecca 24382, Saudi Arabia; [Mars, Mourad] Monastir Univ, Higher Inst Comp Sci & Math, Monastir 5000, Tunisia	Umm Al Qura University; Universite de Monastir	Lughbi, H (corresponding author), Umm Alqura Univ, Coll Comp, Mecca 24382, Saudi Arabia.	s43980676@st.uqu.edu.sa; msmars@uqu.edu.sa; khmotairi@uqu.edu.sa						Ahsan Mostofa, 2022, Journal of Cybersecurity and Privacy, V2, P527, DOI DOI 10.3390/JCP2030027; Alruily M, 2020, INT ARAB J INF TECHN, V17, P367, DOI 10.34028/iajit/17/3/10; Altalhi S, 2021, J AMB INTEL HUM COMP, V12, P10209, DOI 10.1007/s12652-020-02789-z; [Anonymous], 2006, Proceedings of the International Conference on the World Wide Web (WWW-2006), DOI DOI 10.1145/1135777.1135870; [Anonymous], Global Social Media Stats; Arora Twinkle, 2019, 2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC), P47, DOI 10.1109/PEEIC47157.2019.8976474; Bagui SS, 2023, DATA, V8, DOI 10.3390/data8010018; Behzadan V, 2018, IEEE INT CONF BIG DA, P5002, DOI 10.1109/BigData.2018.8622506; Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13; Biabani SAA, 2022, ENG TECHNOL APPL SCI, V12, P8039; Coyac-Torres JE, 2023, MACH LEARN KNOW EXTR, V5, P1132, DOI 10.3390/make5030058; Dawson J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00744; Deshmukh R., 2022, Math. Stat. Eng. Appl, V71, P1431; Dionísio N, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852475; Le BD, 2019, Arxiv, DOI arXiv:1907.01755; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Gehem M., 2015, ASSESSING CYBER SECU; Ghankutkar S., 2019, P 2019 INT C ADV COM, P1; Hamoui B, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1391; Hkiri E, 2017, INT ARAB J INF TECHN, V14, P820; Ifinedo P, 2014, INFORM MANAGE-AMSTER, V51, P69, DOI 10.1016/j.im.2013.10.001; Jung P.W., 2011, Yonsei J. Med. Sci. Technol. Law, V2, P1; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; LINDLEY DV, 1958, J ROY STAT SOC B, V20, P102; Mahaini MI, 2021, PR I-A I C AD S N A, P599, DOI 10.1145/3487351.3492716; Mars M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178805; Mars M, 2016, LECT NOTES COMPUT SC, V9790, P312, DOI 10.1007/978-3-319-42092-9_24; Ponemon L., 2017, Cost of Data Breach Study; Preuveneers D., 2021, J Cybersecur Priv, V1, P140, DOI DOI 10.3390/JCP1010008; Raggad B.G., 2010, Information Security Management: Concepts and Practice; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Sangwan R S., 2023, Journal of Cybersecurity and Privacy, V3, P166, DOI DOI 10.3390/JCP3020010; Security Operations Platform Powered by AI to Protect and Drive Your Business, About us; threatconnect, AI-Powered Threat Intelligence Operations and Cyber Risk Quantification; tweeteraser, How Is Twitter Different from 7 Other Social Media Sites?	35	1	1	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2306-5729		DATA-BASEL	Data	MAR	2024	9	3							39	10.3390/data9030039	http://dx.doi.org/10.3390/data9030039			16	Computer Science, Information Systems; Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Computer Science; Science & Technology - Other Topics	MD1S4		gold			2024-07-03	WOS:001191603300001
J	da Silva, JAT				da Silva, Jaime Teixeira A.			ChatGPT: Detection in Academic Journals is Editors' and Publishers' Responsibilities	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter						AI; Human editing; Large language models; Productivity; Publish or perish		This letter makes note that the responsibility to detect text written by AI, such as ChatGPT, is the sole responsibility of editors and journals/publishers. This proposed policy is made to ensure proper authorship and to therefore assuage readers of a paper's authorship validity-so as not to have AI-driven guest authorship-so that the integrity of the biomedical literature is not further degraded. Two letters to the editor were recently written in this journal by ChatGPT and edited by the author. The extent to which ChatGPT contributed to those letters' content is unknown.	[da Silva, Jaime Teixeira A.] Ikenobe 3011-2, Miki, Kagawa 7610799, Japan		da Silva, JAT (corresponding author), Ikenobe 3011-2, Miki, Kagawa 7610799, Japan.							[Anonymous], 2023, DAILY BEAST; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Teixeira da Silva J. A., 2023, IN PRESS, DOI [10.1002/leap.1547, DOI 10.1002/LEAP.1547]; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600	6	7	7	11	29	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	OCT	2023	51	10					2103	2104		10.1007/s10439-023-03247-5	http://dx.doi.org/10.1007/s10439-023-03247-5		MAY 2023	2	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	S1FW4	37244883				2024-07-03	WOS:000995937500001
J	Ghorashi, N; Ismail, A; Ghosh, P; Sidawy, A; Javan, R				Ghorashi, Nima; Ismail, Ahmed; Ghosh, Pritha; Sidawy, Anton; Javan, Ramin			AI-Powered Chatbots in Medical Education: Potential Applications and Implications	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						medical education; chatbots; large language models; artificial intelligence; gpt-4; chatgpt		Artificial intelligence (AI) is anticipated to have a considerable impact on the routine practice of medicine, spanning from medical education to clinical practice across specialties and, ultimately, patient care. With the imminent widespread adoption of AI in medical practice, it is imperative that medical schools adapt to the use of these advanced technologies in their curriculum to produce future healthcare professionals who can seamlessly integrate these tools into practice. Chatbots, AI systems programmed to process and generate human language, are currently being evaluated for various tasks in medical education. This paper explores the potential applications and implications of chatbots in medical education, specifically in learning and research. With their capability to summarize, simplify complex concepts, automate the creation of memory aids, and serve as an interactive tutor and point-of-care medical reference, chatbots have the potential to enhance students' comprehension, retention, and application of medical knowledge in real-time. While the integration of AI-powered chatbots in medical education presents numerous advantages, it is crucial for students to use these tools as assistive tools rather than relying on them entirely. Chatbots should be programmed to reference evidence-based medical resources and produce precise and trustworthy content that adheres to medical science standards, scientific writing guidelines, and ethical considerations.	[Ghorashi, Nima; Ismail, Ahmed; Javan, Ramin] George Washington Univ, Sch Med & Hlth Sci, Dept Radiol, Washington, DC 20037 USA; [Ghosh, Pritha] George Washington Univ, Sch Med & Hlth Sci, Dept Neurol, Washington, DC 20037 USA; [Sidawy, Anton] George Washington Univ, Sch Med & Hlth Sci, Dept Surg, Washington, DC 20037 USA	George Washington University; George Washington University; George Washington University	Javan, R (corresponding author), George Washington Univ, Sch Med & Hlth Sci, Dept Radiol, Washington, DC 20037 USA.	ramin.javan@gmail.com						Bohr A, 2020, Artificial Intelligence in Healthcare, P25, DOI [DOI 10.1016/B978-0-12-818438-7.00002-2, 10.1016/B978-0-12-818438-7.00002-2]; Civaner MM, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03852-3; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Lomis Kimberly, 2021, NAM Perspect, V2021, DOI 10.31478/202109a; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048	5	5	5	8	10	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 10	2023	15	8							e43271	10.7759/cureus.43271	http://dx.doi.org/10.7759/cureus.43271			5	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	IT4I0	37692629	Green Published, gold			2024-07-03	WOS:001168567200021
J	Saner, FH; Saner, YM; Abufarhaneh, E; Broering, DC; Raptis, DA				Saner, Fuat H.; Saner, Yasemin M.; Abufarhaneh, Ehab; Broering, Dieter C.; Raptis, Dimitri A.			Comparative Analysis of Artificial Intelligence (AI) Languages in Predicting Sequential Organ Failure Assessment (SOFA) Scores	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						chatgpt; large language models; artificial intelligence; perplexity; bard; sofa score		Purpose: The Sequential Organ Failure Assessment (SOFA) score plays a crucial role in intensive care units (ICUs) by providing a reliable measure of a patient's organ function or extent of failure. However, the precise assessment is time-consuming, and daily assessment in clinical practice in the ICU can be challenging. Methods: Realistic scenarios in an ICU setting were created, and the data mining precision of ChatGPT 4.0 Plus, Bard, and Perplexity AI were assessed using Spearman's as well as the intraclass correlation coefficients regarding the accuracy in determining the SOFA score. Results: The strongest correlation was observed between the actual SOFA score and the score calculated by ChatGPT 4.0 Plus ( r correlation coefficient 0.92) (p<0.001). In contrast, the correlation between the actual SOFA and that calculated by Bard was moderate ( r =0.59, p=0.070), while the correlation with Perplexity AI was substantial, at 0.89, with a p<0.001. The interclass correlation coefficient analysis of SOFA with those of ChatGPT 4.0 Plus, Bard, and Perplexity AI was ICC=0.94. Conclusion: Artificial intelligence (AI) tools, particularly ChatGPT 4.0 Plus, show significant promise in assisting with automated SOFA score calculations via AI data mining in ICU settings. They offer a pathway to reduce the manual workload and increase the efficiency of continuous patient monitoring and assessment. However, further development and validation are necessary to ensure accuracy and reliability in a critical care environment.	[Saner, Fuat H.; Abufarhaneh, Ehab; Broering, Dieter C.; Raptis, Dimitri A.] King Faisal Specialist Hosp & Res Ctr, Organ Transplant Ctr Excellence, Riyadh, Saudi Arabia; [Saner, Yasemin M.] Univ Duisburg Essen, Med Ctr, Dept Urol, Essen, Germany	King Faisal Specialist Hospital & Research Center; University of Duisburg Essen	Saner, FH (corresponding author), King Faisal Specialist Hosp & Res Ctr, Organ Transplant Ctr Excellence, Riyadh, Saudi Arabia.	fuat.saner@me.com						Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; Ferreira FL, 2001, JAMA-J AM MED ASSOC, V286, P1754, DOI 10.1001/jama.286.14.1754; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; Krause D., 2023, Social Science Research Network, V9, DOI [10.2139/ssrn.4511540, DOI 10.2139/SSRN.4511540]; Mamdani M, 2021, INTENS CARE MED, V47, P147, DOI 10.1007/s00134-020-06203-2; Moreno R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-022-04290-9; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Vincent JL, 1996, INTENS CARE MED, V22, P707, DOI 10.1007/BF01709751; Zhang YC, 2020, J CARDIAC SURG, V35, P118, DOI 10.1111/jocs.14331	10	0	0	0	0	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 5	2024	16	5							e59662	10.7759/cureus.59662	http://dx.doi.org/10.7759/cureus.59662			10	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	RX2S7	38836141	gold			2024-07-03	WOS:001230898400017
J	Ritz, T				Ritz, Thomas			Intelligence or artificial intelligence? More hard problems for authors of <i>Biological Psychology,</i> the neurosciences, and everyone else	BIOLOGICAL PSYCHOLOGY			English	Editorial Material						Authorship; Large language models; ChatGPT; Artificial text production; Academic malpractice	CHATGPT		[Ritz, Thomas] Southern Methodist Univ, Dept Psychol, Dallas, TX USA; [Ritz, Thomas] Southern Methodist Univ, Dept Psychol, 6116 North Cent Expressway,Suite 1160, Dallas, TX 75206 USA	Southern Methodist University; Southern Methodist University	Ritz, T (corresponding author), Southern Methodist Univ, Dept Psychol, 6116 North Cent Expressway,Suite 1160, Dallas, TX 75206 USA.	tritz@smu.edu						[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Barthes Roland., 1977, Image, music, text; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chomsky N., 2023, NEW YORK TIMES; Committee on Publication Ethics (COPE), 2023, Authorship.; Doudna JA, 2020, NATURE, V578, P229, DOI 10.1038/s41586-020-1978-5; Elsevier, 2023, Publishing Ethics; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Foucault Michel., 1979, TEXTUAL STRATEGIES, P141; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Gyorffy B, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2020.101050; International Committee of Medical Journal Editors, DEF ROL AUTH CONTR; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Milmo D., 2023, The Guardian; STEPTOE PC, 1978, LANCET, V2, P366; Sterling P, 2012, PHYSIOL BEHAV, V106, P5, DOI 10.1016/j.physbeh.2011.06.004; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wilmut I, 1997, NATURE, V385, P810, DOI 10.1038/385810a0; Zielinski C, 2023, WAME Recommendations on Chatbots and Generative Artificial Intelligence in Relation to Scholarly Publications	21	2	2	9	23	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0301-0511	1873-6246		BIOL PSYCHOL	Biol. Psychol.	JUL	2023	181								108590	10.1016/j.biopsycho.2023.108590	http://dx.doi.org/10.1016/j.biopsycho.2023.108590		JUL 2023	6	Psychology, Biological; Behavioral Sciences; Psychology; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Behavioral Sciences	Q8GA5	37236498				2024-07-03	WOS:001059839700001
J	Delsoz, M; Raja, H; Madadi, Y; Tang, AA; Wirostko, BM; Kahook, MY; Yousefi, S				Delsoz, Mohammad; Raja, Hina; Madadi, Yeganeh; Tang, Anthony A.; Wirostko, Barbara M.; Kahook, Malik Y.; Yousefi, Siamak			A Response to: Letter to the Editor Regarding "The Use of ChatGPT to Assist in Diagnosing Glaucoma Based on Clinical Case Reports."	OPHTHALMOLOGY AND THERAPY			English	Letter						ChatGPT; Large language models (LLM); Artificial intelligence (AI); Glaucoma; Provisional diagnosis; Differential diagnosis			[Delsoz, Mohammad; Raja, Hina; Madadi, Yeganeh; Tang, Anthony A.; Yousefi, Siamak] Univ Tennessee, Hamilton Eye Inst, Dept Ophthalmol, Hlth Sci Ctr, 930 Madison Ave,Suite 471, Memphis, TN 38163 USA; [Wirostko, Barbara M.] Univ Utah, John Moran Eye Ctr, Salt Lake City, UT USA; [Kahook, Malik Y.] Univ Colorado, Sch Med, Dept Ophthalmol, Aurora, CO USA; [Yousefi, Siamak] Univ Tennessee, Hlth Sci Ctr, Dept Genet Genom & Informat, Memphis, TN USA	University of Tennessee System; University of Tennessee Health Science Center; Utah System of Higher Education; University of Utah; University of Colorado System; University of Colorado Anschutz Medical Campus; University of Tennessee System; University of Tennessee Health Science Center	Yousefi, S (corresponding author), Univ Tennessee, Hamilton Eye Inst, Dept Ophthalmol, Hlth Sci Ctr, 930 Madison Ave,Suite 471, Memphis, TN 38163 USA.	siamak.yousefi@uthsc.edu	Madadi, Yeganeh/JUV-2768-2023	Yousefi, Siamak/0000-0001-8633-5730	NIH [R01EY033005]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by NIH Grants R01EY033005 (SY. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. No funding or sponsorship was received for the publication of this Letter to the Editor.	Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; OpenAI, 2024, MEMORY NEW CONTROLS; OpenAI, 2022, Introducing chatgpt; Ramponi M, 2022, ASSEMBLY AI     1223	4	0	0	1	1	SPRINGER INT PUBL AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2193-8245	2193-6528		OPHTHALMOL THER	OPHTHALMOL. THER.	JUN	2024	13	6					1817	1819		10.1007/s40123-024-00937-8	http://dx.doi.org/10.1007/s40123-024-00937-8		APR 2024	3	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	RP6R3	38637436	gold			2024-07-03	WOS:001205460700002
J	Omiye, JA; Gui, HW; Daneshjou, R; Cai, ZR; Muralidharan, V				Omiye, Jesutofunmi A.; Gui, Haiwen; Daneshjou, Roxana; Cai, Zhuo Ran; Muralidharan, Vijaytha			Principles, applications, and future of artificial intelligence in dermatology	FRONTIERS IN MEDICINE			English	Review						dermatology; artificial intelligence (AI); large language models (LLM); machine learning; melanoma; federated learning	LEVEL CLASSIFICATION; SKIN-CANCER; PSORIASIS; MODELS; IMAGES; SEGMENTATION; ALGORITHMS; DIAGNOSIS; ACCURACY; MEDICINE	This paper provides an overview of artificial-intelligence (AI), as applied to dermatology. We focus our discussion on methodology, AI applications for various skin diseases, limitations, and future opportunities. We review how the current image-based models are being implemented in dermatology across disease subsets, and highlight the challenges facing widespread adoption. Additionally, we discuss how the future of AI in dermatology might evolve and the emerging paradigm of large language, and multi-modal models to emphasize the importance of developing responsible, fair, and equitable models in dermatology.	[Omiye, Jesutofunmi A.; Gui, Haiwen; Daneshjou, Roxana; Cai, Zhuo Ran; Muralidharan, Vijaytha] Stanford Univ, Dept Dermatol, Stanford, CA 94305 USA; [Daneshjou, Roxana] Stanford Univ, Dept Biomed Data Sci, Stanford, CA USA	Stanford University; Stanford University	Omiye, JA (corresponding author), Stanford Univ, Dept Dermatol, Stanford, CA 94305 USA.	tomiye@stanford.edu	Daneshjou, Roxana/ABE-7764-2021	Daneshjou, Roxana/0000-0001-7988-9356; Gui, Haiwen/0000-0003-0564-940X	The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	[Anonymous], Introducing chatgpt; Bohr A, 2020, Artificial Intelligence in Healthcare, P25, DOI [DOI 10.1016/B978-0-12-818438-7.00002-2, 10.1016/B978-0-12-818438-7.00002-2]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Caffery LJ, 2021, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.619787; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Castiglioni I, 2021, PHYS MEDICA, V83, P9, DOI 10.1016/j.ejmp.2021.02.006; Chen RJ, 2021, NAT BIOMED ENG, V5, P493, DOI 10.1038/s41551-021-00751-8; Coustasse A, 2019, TELEMED E-HEALTH, V25, P1022, DOI 10.1089/tmj.2018.0130; Daneshjou R, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq6147; Daneshjou R, 2021, JAMA DERMATOL, V157, P1362, DOI 10.1001/jamadermatol.2021.3129; Dhane DM, 2017, COMPUT BIOL MED, V89, P551, DOI 10.1016/j.compbiomed.2017.04.004; Dorr DA, 2023, JAMA-J AM MED ASSOC, V329, P1347, DOI 10.1001/jama.2023.2771; Du AX, 2023, J AM ACAD DERMATOL, V88, P1364, DOI 10.1016/j.jaad.2022.12.046; Du-Harpur X, 2020, BRIT J DERMATOL, V183, P423, DOI 10.1111/bjd.18880; Dweekat OY, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010031; Dweekat OY, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20010828; Emam S, 2020, BRIT J DERMATOL, V182, P1305, DOI 10.1111/bjd.18741; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Feng H, 2018, JAMA DERMATOL, V154, P1265, DOI 10.1001/jamadermatol.2018.3022; Goh KH, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-20910-4; Gomolin A, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00100; Goodman RL., 2003, Ophtho notes: the essential guide; Gorman BG, 2023, J CUTAN PATHOL, V50, P852, DOI 10.1111/cup.14481; Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013; Guo P, 2014, GENOMICS, V103, P48, DOI 10.1016/j.ygeno.2013.11.001; Gustafson E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P83, DOI 10.1109/ICHI.2017.31; Gutman D., 2016, arXiv [cs.CV]; Haenssle HA, 2018, ANN ONCOL, V29, P1836, DOI 10.1093/annonc/mdy166; Han SS, 2022, J INVEST DERMATOL, V142, P2353, DOI 10.1016/j.jid.2022.02.003; Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Hekler A, 2019, EUR J CANCER, V115, P79, DOI 10.1016/j.ejca.2019.04.021; Hocke J, 2023, FRONT IMMUNOL, V14, DOI 10.3389/fimmu.2023.1111172; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Hurault G, 2020, CLIN EXP ALLERGY, V50, P1258, DOI 10.1111/cea.13717; Jain A, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.7249; Jansen P, 2023, EUR J CANCER, V188, P161, DOI 10.1016/j.ejca.2023.04.023; Jones C, 2023, MED LAW REV, V31, P501, DOI 10.1093/medlaw/fwad013; Jones OT, 2022, LANCET DIGIT HEALTH, V4, pE466, DOI 10.1016/S2589-7500(22)00023-1; Kassab J, 2023, HYPERTENSION, V80, pE125, DOI 10.1161/HYPERTENSIONAHA.123.21183; Keser G, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2022.08.007; Kim Chanwoo, 2023, medRxiv, DOI 10.1101/2023.06.07.23291119; Kimball AB, 2008, J AM ACAD DERMATOL, V59, P741, DOI 10.1016/j.jaad.2008.06.037; Kovarik C, 2019, J AM ACAD DERMATOL, V81, P998, DOI 10.1016/j.jaad.2019.06.032; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee Leon Tsung-Ju, 2023, J Med Internet Res, V25, pe39972, DOI 10.2196/39972; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Liu S, 2023, TECHNOL HEALTH CARE, V31, P1171, DOI 10.3233/THC-220295; Liu S, 2022, SKIN RES TECHNOL, V28, P677, DOI 10.1111/srt.13166; Liu TJ, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-26812-9; Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2; Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3; Lu J, 2013, IEEE T MED IMAGING, V32, P719, DOI 10.1109/TMI.2012.2236349; Maier K, 2022, J AM ACAD DERMATOL, V87, P240, DOI 10.1016/j.jaad.2021.07.073; Marchetti MA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00872-1; Marchetti MA, 2018, J AM ACAD DERMATOL, V78, P270, DOI 10.1016/j.jaad.2017.08.016; McMullen EP, 2023, J CUTAN MED SURG, V27, P287, DOI 10.1177/12034754231168846; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mohan S, 2023, J DIGIT IMAGING, V36, P1123, DOI 10.1007/s10278-022-00765-x; Mondal H, 2023, INDIAN DERMATOL ONL, V14, P482, DOI 10.4103/idoj.idoj_72_23; Montilla IH, 2023, SKIN RES TECHNOL, V29, DOI 10.1111/srt.13357; Moor M, 2023, Arxiv, DOI arXiv:2307.15189; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Mukherjee R, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/851582; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Naik N, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.862322; Nelson CA, 2021, JAMA DERMATOL, V157, P871, DOI 10.1001/jamadermatol.2021.1685; Nelson CA, 2020, JAMA DERMATOL, V156, P501, DOI 10.1001/jamadermatol.2019.5014; O'Hern K, 2023, JAAD INT, V12, P168, DOI 10.1016/j.jdin.2023.06.002; Okon E, 2020, J AM ACAD DERMATOL, V83, P803, DOI 10.1016/j.jaad.2019.07.014; Pierce EJ, 2021, DERMATOLOGY THER, V11, P1305, DOI 10.1007/s13555-021-00553-5; Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rasheed A, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105807; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sauter D, 2023, COMPUT BIOL MED, V163, DOI 10.1016/j.compbiomed.2023.107083; Seité S, 2019, EXP DERMATOL, V28, P1252, DOI 10.1111/exd.14022; Shrivastava VK, 2017, COMPUT METH PROG BIO, V150, P9, DOI 10.1016/j.cmpb.2017.07.011; Shrivastava VK, 2016, COMPUT METH PROG BIO, V126, P98, DOI 10.1016/j.cmpb.2015.11.013; Sitaru S, 2023, J DTSCH DERMATOL GES, V21, P863, DOI [10.1111/ddg.15113, 10.1111/ddg.15113_g]; Stern L, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23052430; Toffaha KM, 2023, ARTIF INTELL MED, V141, DOI 10.1016/j.artmed.2023.102560; Tsang MW, 2006, J AM ACAD DERMATOL, V55, P54, DOI 10.1016/j.jaad.2006.04.001; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; van Panhuis WG, 2014, BMC PUBLIC HEALTH, V14, DOI 10.1186/1471-2458-14-1144; van Zon MCM, 2021, EXP DERMATOL, V30, P733, DOI 10.1111/exd.14306; Vodrahalli K, 2021, PACIFIC SYMPOSIUM ON BICOMPUTING 2021, P220; Wang F, 2019, JAMA INTERN MED, V179, P293, DOI 10.1001/jamainternmed.2018.7117; Wang S, 2017, IEEE T BIO-MED ENG, V64, P990, DOI [10.1109/TBME.2016.2585344, 10.1109/TBME.2016.2632522]; Wilm A, 2018, CRIT REV TOXICOL, V48, P738, DOI 10.1080/10408444.2018.1528207; Winkler JK, 2019, JAMA DERMATOL, V155, P1135, DOI 10.1001/jamadermatol.2019.1735; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Wu E, 2021, NAT MED, V27, P582, DOI 10.1038/s41591-021-01312-x; Young AT, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00380-6; Young AT, 2020, J INVEST DERMATOL, V140, P1504, DOI 10.1016/j.jid.2020.02.026; Young JN, 2023, J AM ACAD DERMATOL, V89, P602, DOI 10.1016/j.jaad.2023.05.024; Yu Z, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.965423; Zhan YP, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms241210033; Zhang H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186828; Zhou JX, 2023, Arxiv, DOI [arXiv:2304.10691, 10.48550/arXiv.2304.10691, DOI 10.48550/ARXIV.2304.10691]; Zhou Y, 2023, EUR J DERMATOL, V33, P147, DOI 10.1684/ejd.2023.4453; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	107	4	4	14	20	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-858X		FRONT MED-LAUSANNE	Front. Med.	OCT 12	2023	10								1278232	10.3389/fmed.2023.1278232	http://dx.doi.org/10.3389/fmed.2023.1278232			9	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	U8KL9	37901399	gold, Green Published			2024-07-03	WOS:001087234600001
J	Mizuta, K; Hirosawa, T; Harada, Y; Shimizu, T				Mizuta, Kazuya; Hirosawa, Takanobu; Harada, Yukinori; Shimizu, Taro			Can ChatGPT-4 evaluate whether a differential diagnosis list contains the correct diagnosis as accurately as a physician?	DIAGNOSIS			English	Article; Early Access						clinical decision supporting system; diagnosis; diagnostic excellence; generative artificial intelligence; large language model; natural language processing		Objectives: The potential of artificial intelligence (AI) chatbots, particularly the fourth-generation chat generative pretrained transformer (ChatGPT-4), in assisting with medical diagnosis is an emerging research area. While there has been significant emphasis on creating lists of differential diagnoses, it is not yet clear how well AI chatbots can evaluate whether the final diagnosis is included in these lists. This short communication aimed to assess the accuracy of ChatGPT-4 in evaluating lists of differential diagnosis compared to medical professionals' assessments. Methods: We used ChatGPT-4 to evaluate whether the final diagnosis was included in the top 10 differential diagnosis lists created by physicians, ChatGPT-3, and ChatGPT-4, using clinical vignettes. Eighty-two clinical vignettes were used, comprising 52 complex case reports published by the authors from the department and 30 mock cases of common diseases created by physicians from the same department. We compared the agreement between ChatGPT-4 and the physicians on whether the final diagnosis was included in the top 10 differential diagnosis lists using the kappa coefficient. Results: Three sets of differential diagnoses were evaluated for each of the 82 cases, resulting in a total of 246 lists. The agreement rate between ChatGPT-4 and physicians was 236 out of 246 (95.9 %), with a kappa coefficient of 0.86, indicating very good agreement. Conclusions: ChatGPT-4 demonstrated very good agreement with physicians in evaluating whether the final diagnosis should be included in the differential diagnosis lists.	[Mizuta, Kazuya; Hirosawa, Takanobu; Harada, Yukinori; Shimizu, Taro] Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu, Tochigi 3210293, Japan	Dokkyo Medical University	Hirosawa, T (corresponding author), Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu, Tochigi 3210293, Japan.	hirosawa@dokkyomed.ac.jp	Hirosawa, Takanobu/AFS-0531-2022	Hirosawa, Takanobu/0000-0002-3573-8203; Mizuta, Kazuya/0009-0000-8822-7127				Hirosawa T, Int J Environ Res Publ Health2023, V20, P7; Hirosawa T, 2023, JMIR MED INF, V11, DOI 10.2196/48808; Levin B, 2003, Statistical methods for rates and proportions; Meyer AND, 2019, JAMA-J AM MED ASSOC, V321, P737, DOI 10.1001/jama.2019.0113; Singh H, 2022, BMJ-BRIT MED J, V376, DOI 10.1136/bmj-2021-068044; ten Berg H, 2024, ANN EMERG MED, V83, P83, DOI 10.1016/j.annemergmed.2023.08.003; Yang D, 2021, JAMA-J AM MED ASSOC, V326, P1905, DOI 10.1001/jama.2021.19493	7	0	0	4	4	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-8011	2194-802X		DIAGNOSIS	Diagnosis	2024 MAR 12	2024										10.1515/dx-2024-0027	http://dx.doi.org/10.1515/dx-2024-0027		MAR 2024	4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	KS9Q7	38465399				2024-07-03	WOS:001182076700001
C	Okolo, CT		Isafiade, O; Ogunyemi, A; Anya, O; Sakpere, A; Jat, DS; Jere, N		Okolo, Chinasa T.			The Promise and Perils of Generative AI: Case Studies in an African Context	PROCEEDINGS OF THE 4TH AFRICAN CONFERENCE FOR HUMAN COMPUTER INTERACTION, AFRICHI 2023			English	Proceedings Paper	4th African Conference on Human Computer Interaction (AfriCHI) - Beyond Limits	NOV 27-DEC 01, 2023	Walter Sisulu Univ, East London, SOUTH AFRICA	Pan African Informat Commun Technol Assoc, ACM In Cooperat, SIGCHI, Lelapa Ai, Univ S Africa, Tobii, E London Idz, Sci & Technol Pk	Walter Sisulu Univ	generative AI; large language models; responsible AI; Africa; algorithmic bias	ARTIFICIAL-INTELLIGENCE	As generative AI applications such as ChatGPT, Midjourney, DALL center dot E, Bard, and others increase in ubiquity, concerns about the negative implications of these technologies are becoming more present in public discourse. However, little research has examined the impact that generative AI stands to have on African consumers and users who may be affected by its application in various fields such as education, healthcare, and social media. This work presents an early look into the implications of using generative AI within African contexts, exploring case studies of current generative AI use within Africa. These case studies examine the use of generative AI in marketing and for image and text generation. While the potential for generative AI in Africa is growing, this preliminary work aims to set a foundation for highlighting risks associated with generative AI while exploring how generative AI can be responsibly developed and used within African contexts.	[Okolo, Chinasa T.] Cornell Univ, Comp Sci, Ithaca, NY 14850 USA	Cornell University	Okolo, CT (corresponding author), Cornell Univ, Comp Sci, Ithaca, NY 14850 USA.	chinasa@cs.cornell.edu		Okolo, Chinasa T./0000-0002-6474-3378				Bellemo V, 2019, LANCET DIGIT HEALTH, V1, pE35, DOI 10.1016/S2589-7500(19)30004-4; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brobbey Edward Effah., 2021, Inkanyiso: Journal of Humanities and Social Sciences, V13, P120; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Onu CC, 2020, Arxiv, DOI [arXiv:1906.10199, 10.48550/arXiv.1906.10199, DOI 10.48550/ARXIV.1906.10199]; Chilunjika A, 2022, SA J HUM RESOUR MANA, V20, DOI 10.4102/sajhrm.v20i0.1972; Elkefi Safa., 2022, Africa Case Studies in Operations Research: A Closer Look into Applications and Algorithms, P51; Githui Irene F, 2019, Ph. D. Dissertation; Goldstein J. A., 2023, arXiv, DOI [10.48550/arXiv.2301.04246, DOI 10.48550/ARXIV.2301.04246]; Gondwe Gregory, 2023, Online Media and Global Communication; Gwagwa A., 2021, Responsible artificial intelligence in Sub-Saharan Africa: landscape and general state of play; Kolog E. A., 2022, Management and Information Technology in the Digital era, V29, P27; Lilhore UK, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040580; Liquid Intelligent Technologies, 2017, Microsoft and Liquid Intelligent Technologies working together to accelerate cloud adoption in Africa; Loyani LK, 2021, APPL ARTIF INTELL, V35, P1107, DOI 10.1080/08839514.2021.1972254; Lu ZY, 2023, Arxiv, DOI arXiv:2304.13023; Madrid-Morales Dani, 2020, Motivations for sharing misinformation: A comparative study in six Sub-Saharan African countries; Maxwell Thomas, 2023, Business Insider Africa; Mkonyi L, 2020, SCI AFR, V10, DOI 10.1016/j.sciaf.2020.e00590; Nekoto W, 2020, Arxiv, DOI arXiv:2010.02353; Nicoletti L., 2023, Bloomberg; Nikolic Christina., 2023, Reproducing inequality: How AI image generators show biases against women in STEM; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; NVIDIA, 2023, Large Language Models Explained.; NVIDIA, 2023, What is Generative AI?.; Nwachukwu D., 2023, International Academy Journal of Management, Marketing and Entrepreneurial Studies, V9, P44; Nwankwo Ezinne, 2020, P AI SOCIAL GOODWORK; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Okolo Chinasa T., 2023, Responsible AI in Africa: Challenges and Opportunities, P35, DOI DOI 10.1007/978-3-031-08215-3_3; Onaolapo Sodiq, 2020, 10 ANN INT C SUSTAIN, P1; Orife Iroro, 2020, arXiv; Partadiredja Reza Arkan, 2020, 2020 13 901 C CYBERS, P1; Reid Machel, 2021, arXiv; Sahara Reporters, 2023, Peoples Gazette Insists Peter Obi's 'Yes Daddy' Audio With Bishop Oyedepo Is Genuine, Vows To Protect Source; Sanusi IT, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100083; Selvaraj MG, 2020, ISPRS J PHOTOGRAMM, V169, P110, DOI 10.1016/j.isprsjprs.2020.08.025; Small Zachary., 2023, New York Times; Stablility.ai, 2023, Stability AI launches SDXL 0.9: A Leap Forward in AI Image Generation.; Tapo AA, 2020, Arxiv, DOI arXiv:2011.05284; Thomas Ryan J, 2023, Digital Journalism, V2023, P1; Thomson T.J., 2023, The Conversation; Wasserman H, 2019, AFR JOURNAL STUD, V40, P107, DOI 10.1080/23743670.2019.1627230; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Zhuo ZL, 2021, AMFITEATRU ECON, V23, P174, DOI 10.24818/EA/2021/56/174	44	0	0	15	15	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0887-9				2023							266	270		10.1145/3628096.3629066	http://dx.doi.org/10.1145/3628096.3629066			5	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5FM					2024-07-03	WOS:001159802500041
J	Shifai, N; van Doorn, R; Malvehy, J; Sangers, TE				Shifai, Naweed; van Doorn, Remco; Malvehy, Josep; Sangers, Tobias E.			Can ChatGPT vision diagnose melanoma? An exploratory diagnostic accuracy study	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Letter						artificial intelligence; ChatGPT; GPT-4V; Large Language Models; melanoma; nevi; skin cancer			[Shifai, Naweed] Netherlands Canc Inst, Dept Dermatol, Amsterdam, Netherlands; [van Doorn, Remco; Sangers, Tobias E.] Leiden Univ, Med Ctr, Dept Dermatol, Albinusdreef 2, Leiden, Netherlands; [Malvehy, Josep] Univ Barcelona, Hosp Clin Barcelona, Dermatol Dept, IDIBAPS,Melanoma Unit, Barcelona, Spain; [Malvehy, Josep] Ctr Invest Biomed Red Enfermedades Raras CIBERER, Barcelona, Spain	Netherlands Cancer Institute; Leiden University - Excl LUMC; Leiden University; Leiden University Medical Center (LUMC); University of Barcelona; Hospital Clinic de Barcelona; IDIBAPS; CIBER - Centro de Investigacion Biomedica en Red; CIBERER	Sangers, TE (corresponding author), Leiden Univ, Med Ctr, Dept Dermatol, Albinusdreef 2, Leiden, Netherlands.	t.e.sangers@lumc.nl						Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; openai.com, ChatGPT can now see, hear and speak; The International Skin Imaging Collaboration (ISIC), archive; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Winkler JK, 2023, JAMA DERMATOL, V159, P621, DOI 10.1001/jamadermatol.2023.0905	5	4	4	1	1	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	MAY	2024	90	5					1057	1059		10.1016/j.jaad.2023.12.062	http://dx.doi.org/10.1016/j.jaad.2023.12.062			3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	RV8U6	38244612	hybrid			2024-07-03	WOS:001230536100001
C	Hasani, M; Trost, CN; Timmerman, N; Jin, LL			ACM	Hasani, Moein; Trost, Chantel N.; Timmerman, Nolen; Jin, Lingling			AcrTransAct: Pre-trained Protein Transformer Models for the Detection of Type I Anti-CRISPR Activities	14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, BCB 2023			English	Proceedings Paper	14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB)	SEP 03-06, 2023	Houston, TX	Assoc Comp Machinery, ACM Special Interest Grp Bioinformat, Computat Biol, & Biomed Informat		CRISPR-Cas; Anti-CRISPR; Transformers; Deep Learning; Large Language Models; Protein Inhibition	VIRAL SUPPRESSORS; CAS SYSTEMS; LANGUAGE	Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) and CRISPR-associated (Cas) proteins serve as a formidable defense mechanism for bacteria against foreign DNA; on the other hand, some bacteriophages (phages) and other mobile genetic elements have evolved anti-CRISPR (Acr) proteins to counteract CRISPR-Cas systems and ensure their own survival. Because Acr proteins provide phages with a fitness advantage relative to the bacteria that they infect, accurately identifying Acr proteins that inhibit CRISPR-Cas systems has the potential to significantly and positively impact our ability to harness phages to fight antimicrobial resistance. However, Acr identification is, at present, laborious and involves costly experimental procedures. Existing computational tools for protein-protein interaction (PPI) are not designed to predict complex inhibition, which could be the collective result of multiple PPIs. In this study, we developed a transformer-based deep neural network, AcrTransAct, to predict the probability of Acr-mediated CRISPR-Cas inhibition. Our model comprises two main components: 1. a feature extraction module that incorporates a pre-trained Evolutionary Scale Modeling (ESM) protein transformer and the NetSurfP-3.0 secondary structure prediction system; 2. a classification module that consists of either a convolutional or recurrent neural network. We created an inhibition dataset compiled from two Acr databases, AcrHub [30], Anti-CRISPRdb [5], and several published works [9, 12, 18, 20]. The AcrTransAct model is trained and tested on this dataset. We achieved an accuracy of 95% and an F1 score of 0.95 in predicting the inhibition of I-C, I-E, and I-F CRISPR-Cas systems by Acrs in our dataset. A web application of AcrTransAct (https://acrtransact.usask.ca) is implemented with the best-performing models from this study to predict the probability of multiple CRISPR-Cas systems inhibited by a putative Acr protein. Our code and data are available here: https://github.com/USask-BINFO/AcrTransAct.	[Hasani, Moein; Timmerman, Nolen; Jin, Lingling] Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK, Canada; [Trost, Chantel N.] Univ Toronto, Dept Mol Genet, Toronto, ON, Canada	University of Saskatchewan; University of Toronto	Jin, LL (corresponding author), Univ Saskatchewan, Dept Comp Sci, Saskatoon, SK, Canada.	moein.hasani@usask.ca; chantel.trost@utoronto.ca; njt694@mail.usask.ca; lingling.jin@cs.usask.ca		Jin, Lingling/0000-0002-4586-2347; Timmerman, Nolen/0009-0000-8531-855X				Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI [10.1093/nar/gkh131, 10.1093/nar/gkw1099]; Bondy-Denomy J, 2013, NATURE, V493, P429, DOI 10.1038/nature11723; Brouns SJJ, 2008, SCIENCE, V321, P960, DOI 10.1126/science.1159689; Chowdhury S, 2017, CELL, V169, P47, DOI 10.1016/j.cell.2017.03.012; Dong C, 2018, NUCLEIC ACIDS RES, V46, pD393, DOI 10.1093/nar/gkx835; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Guo TW, 2017, CELL, V171, P414, DOI 10.1016/j.cell.2017.09.006; Heler R, 2014, MOL MICROBIOL, V93, P1, DOI 10.1111/mmi.12640; Hicks Brian T, 2019, Ph. D. Dissertation; Hoie MH, 2022, NUCLEIC ACIDS RES, V50, pW510, DOI 10.1093/nar/gkac439; Jinek M, 2012, SCIENCE, V337, P816, DOI 10.1126/science.1225829; León LM, 2021, NUCLEIC ACIDS RES, V49, P2114, DOI 10.1093/nar/gkab006; Li Y., 2022, bioRxiv, DOI 10; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Makarova KS, 2020, NAT REV MICROBIOL, V18, P67, DOI 10.1038/s41579-019-0299-x; Mohanraju P, 2016, SCIENCE, V353, DOI 10.1126/science.aad5147; Nath A, 2022, BIOMED PHARMACOTHER, V151, DOI 10.1016/j.biopha.2022.113122; Pawluk A, 2016, NAT MICROBIOL, V1, DOI [10.1038/NMICROBIOL.2016.85, 10.1038/nmicrobiol.2016.85]; Peng RC, 2017, CELL RES, V27, P853, DOI 10.1038/cr.2017.79; Pinilla-Redondo R, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19415-3; Rao V Srinivasa, 2014, Int J Proteomics, V2014, P147648, DOI 10.1155/2014/147648; Sledzieski S, 2021, CELL SYST, V12, P969, DOI 10.1016/j.cels.2021.08.010; Song BS, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab558; Suzek BE, 2007, BIOINFORMATICS, V23, P1282, DOI 10.1093/bioinformatics/btm098; van Belkum A, 2015, MBIO, V6, DOI 10.1128/mBio.01796-15; Van Valen L., 1973, EVOL THEORY, V1, P1, DOI DOI 10.1038/344864A0; Vaswani A, 2017, ADV NEUR IN, V30; Vig J, 2021, Arxiv, DOI [arXiv:2006.15222, 10.48550/arXiv.2006.15222, DOI 10.48550/ARXIV.2006.15222]; Vyas P, 2022, MICROBIOL RES, V257, DOI 10.1016/j.micres.2022.126963; Wang JW, 2021, NUCLEIC ACIDS RES, V49, pD630, DOI 10.1093/nar/gkaa951; Zhu YW, 2018, BMC BIOL, V16, DOI 10.1186/s12915-018-0504-9	31	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0126-9				2023										10.1145/3584371.3613007	http://dx.doi.org/10.1145/3584371.3613007			6	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Mathematical & Computational Biology; Medical Informatics	BW3UZ		hybrid			2024-07-03	WOS:001143941200022
C	Hsu, CM; Zan, CT; Ding, L; Wang, LY; Wang, XT; Liu, WF; Lin, F; Hu, WB			IEEE	Hsu, Chiaming; Zan, Changtong; Ding, Liang; Wang, Longyue; Wang, Xiaoting; Liu, Weifeng; Lin, Fu; Hu, Wenbin			Prompt-Learning for Cross-Lingual Relation Extraction	2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN	IEEE International Joint Conference on Neural Networks (IJCNN)		English	Proceedings Paper	International Joint Conference on Neural Networks (IJCNN)	JUN 18-23, 2023	Broadbeach, AUSTRALIA	Int Neural Network Soc, IEEE Computat Intelligence Soc		Cross-Lingual Relation Extraction; Prompt Learning; Zero-Shot Learning; Large Language Model		Relation Extraction (RE) is a crucial task in Information Extraction, which entails predicting relationships between entities within a given sentence. However, extending pre-trained RE models to other languages is challenging, particularly in real-world scenarios where Cross-Lingual Relation Extraction (XRE) is required. Despite recent advancements in Prompt-Learning, which involves transferring knowledge from Multilingual Pre-trained Language Models (PLMs) to diverse downstream tasks, there is limited research on the effective use of multilingual PLMs with prompts to improve XRE. In this paper, we present a novel XRE algorithm based on Prompt-Tuning, referred to as Prompt-XRE. To evaluate its effectiveness, we design and implement several prompt templates, including hard, soft, and hybrid prompts, and empirically test their performance on competitive multilingual PLMs, specifically mBART. Our extensive experiments, conducted on the low-resource ACE05 benchmark across multiple languages, demonstrate that our Prompt-XRE algorithm significantly outperforms both vanilla multilingual PLMs and other existing models, achieving state-of-the-art performance in XRE. To further show the generalization of our Prompt-XRE on larger data scales, we construct and release a new XRE dataset- WMT17-EnZh XRE, containing 0.9M English-Chinese pairs extracted from WMT 2017 parallel corpus. Experiments on WMT17-EnZh XRE also show the effectiveness of our Prompt-XRE against other competitive baselines. The code and newly constructed dataset are freely available at https://github.com/HSU- CHIA-MING/Prompt-XRE.	[Hsu, Chiaming; Zan, Changtong] JD Explore Acad, Beijing, Peoples R China; [Hsu, Chiaming; Lin, Fu; Hu, Wenbin] Wuhan Univ, Wuhan, Hubei, Peoples R China; [Zan, Changtong; Liu, Weifeng] China Univ Petr East China, Qingdao, Shandong, Peoples R China; [Ding, Liang] JD Com, JD Explore Acad, Beijing, Peoples R China; [Wang, Longyue] Tencent AI Lab, Bellevue, WA USA; [Wang, Xiaoting] JD Com, Beijing, Peoples R China	Wuhan University; China University of Petroleum	Lin, F; Hu, WB (corresponding author), Wuhan Univ, Wuhan, Hubei, Peoples R China.; Ding, L (corresponding author), JD Com, JD Explore Acad, Beijing, Peoples R China.	dingliangl@jd.com; linfu@whu.edu.cn; hwb@whu.edu.cn			Natural Science Foundation of China [61976162, 82174230]; Artificial Intelligence Innovation Project of Wuhan Science and Technology Bureau [2022010702040070]; Science and Technology Major Project of Hubei Province (Next Generation AI Technologies) [2019AEA170]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Artificial Intelligence Innovation Project of Wuhan Science and Technology Bureau; Science and Technology Major Project of Hubei Province (Next Generation AI Technologies)	This work was supported in part by the Natural Science Foundation of China (Nos. 61976162, 82174230), Artificial Intelligence Innovation Project of Wuhan Science and Technology Bureau (No.2022010702040070), Science and Technology Major Project of Hubei Province (Next Generation AI Technologies) (No. 2019AEA170).	Ahmad W. U., 2021, AAAI; [Anonymous], 2021, FINDINGS OF ACL; Broscheit Samuel, 2017, TAC; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao Yu, 2021, ICASSP; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding L., 2021, ICLR; Ding Liang, 2022, ACL; Ding Liang, 2020, ACL; Ding Liang, 2020, COLING; Doddington G. R., 2004, LREC, P1; Dodge Jesse, 2020, Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping; Gao T., 2020, Making pre-trained language models better few-shot learners; Hassan H., 2018, 1803.05567; Hu S., 2021, Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification; Levy O., 2017, Zero-shot relation extraction via reading comprehension; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Li X. L., 2021, Prefix-tuning: Optimizing continuous prompts for generation; Liang Ding, 2021, EMNLP; Liu J., 2019, EMNLP; Liu Pengfei, 2021, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing; Liu Xuebo, 2021, ICLR; Liu Y., 2020, TACL; Liu Yinhan, 2020, TACL; Lu Qingyu, 2023, ERROR ANAL PROMPTING; McDonell K., 2021, 2021 CHI C HUM FACT; Miwa M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1105; Ni J, 2019, EMNLP IJCNLP, P188, DOI DOI 10.18653/V1/D19-1018; Obamuyide A., 2018, FEVER; Peng K, 2023, Towards making the most of chatgpt for machine translation; Rao J., 2022, SIGIR; Rao J., 2023, TMM; Schick Timo, 2020, Exploiting cloze questions for few shot text classification and natural language inference; Shaw P., 2018, AACL; Shin Taylor, 2020, Autoprompt: Eliciting knowledge from language models with automatically generated prompts; Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895; Subburathinam A., 2019, EMNLP; Vaswani A, 2017, ADV NEUR IN, V30; Walker C., 2006, PROGR THEORETICAL PH; Wang B., 2022, COLING; Wang W., 2019, ACM TIST; White A. S., 2016, EMNLP; Wu D., 2020, EMNLP; Wu D., 2021, BRIDGING GAP CLEAN D; Yan H., 2021, A unified generative framework for aspect-based sentiment analysis; Yasunaga M., 2021, QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering; Yenicelik D., 2020, BLACKBOXNLP WORKSH; Zan C., 2022, Vega-mt: The jd explore academy translation system for wmt22; Zan Changtong, 2022, BRIDGING CROSS LINGU; Zan Changtong, 2022, COLING; Zhang N., 2021, DIFFERENTIABLE PROMP; Zhang Z., 2022, BLISS ROBUST SEQUENC; Zhong Q, 2022, Panda: Prompt transfer meets knowledge distillation for efficient model adaptation; Zhong Q., 2023, Can ChatGPT understand too? a comparative study on ChatGPT and fine-tuned bert; Zhong Q., 2023, TKDE; Zhong Qihuang, 2022, EFFICIENT LANGUAGE M; Zhong Qihuang, 2022, FINDINGS EMNLP; Zhong Qihuang, 2023, BAG TRICKS EFFECTIVE; Zhong Qihuang, 2022, E2S2 ENCODING ENHANC; Zhou K., 2020, KDD	60	0	0	3	10	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2161-4393		978-1-6654-8867-9	IEEE IJCNN			2023										10.1109/IJCNN54540.2023.10192002	http://dx.doi.org/10.1109/IJCNN54540.2023.10192002			9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BV5BH		Green Submitted			2024-07-03	WOS:001046198707069
J	Hao, SC; Shi, XJ; Liu, HW				Hao, Sichong; Shi, Xianjun; Liu, Hongwei			Exploring the Potential of Pre-Trained Language Models of Code for Automated Program Repair	ELECTRONICS			English	Article						large language models of code; automated program repair; code debugging		In the realm of software development, automated program repair (APR) emerges as a pivotal technique, autonomously debugging faulty code to boost productivity. Despite the notable advancements of large pre-trained language models of code (PLMCs) in code generation, their efficacy in complex tasks like APR remains suboptimal. This limitation is attributed to the generic development of PLMCs, whose specialized potential for APR is yet be to fully explored. In this paper, we propose a novel approach designed to enhance PLMCs' APR performance through source code augmentation and curriculum learning. Our approach employs code augmentation operators to generate a spectrum of syntactically varied yet semantically congruent bug-fixing programs, thus enriching the dataset's diversity. Furthermore, we design a curriculum learning strategy, enabling PLMCs to develop a deep understanding of program semantics from these enriched code variants, thereby refining their APR fine-tuning prowess. We apply our approach across different PLMCs and systematically evaluate it on three benchmarks: BFP-small, BFP-medium, and Defects4J. The experimental results show that our approach outperforms both original models and existing baseline methods, demonstrating the promising future of adapting PLMCs for code debugging in practice.	[Hao, Sichong; Shi, Xianjun; Liu, Hongwei] Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China	Harbin Institute of Technology	Liu, HW (corresponding author), Harbin Inst Technol, Fac Comp, Harbin 150001, Peoples R China.	schao@stu.hit.edu.cn; shixianjun@hit.edu.cn; liuhw@hit.edu.cn			National Key Research and Development Program of China	National Key Research and Development Program of China	No Statement Available	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Allamanis M, 2021, Arxiv, DOI arXiv:2105.12787; Bengio Y., 2009, ICML, P41, DOI DOI 10.1145/1553374.1553380; Berabi B, 2021, PR MACH LEARN RES, V139; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chakraborty S, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P18, DOI 10.1145/3540250.3549162; Chakraborty S, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P443, DOI 10.1109/ASE51524.2021.9678559; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chi JL, 2023, IEEE T SOFTWARE ENG, V49, P564, DOI 10.1109/TSE.2022.3156637; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Fan ZY, 2023, PROC INT CONF SOFTW, P1469, DOI 10.1109/ICSE48619.2023.00128; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Guo D., 2021, P INT C LEARNING REP; Hacohen Guy, 2019, INT C MACHINE LEARNI; Hao SC, 2023, PROC IEEE INT CONF S, P136, DOI 10.1109/ICSME58846.2023.00024; Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594; Jain P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5954; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Krueger KA, 2009, COGNITION, V110, P380, DOI 10.1016/j.cognition.2008.11.014; Li Y, 2022, PROC INT CONF SOFTW, P511, DOI 10.1145/3510003.3510177; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu Shangqing, 2023, arXiv; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Phan L, 2021, NLP4PROG 2021: THE 1ST WORKSHOP ON NATURAL LANGUAGE PROCESSING FOR PROGRAMMING (NLP4PROG 2021), P40; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Mastropaolo A, 2023, IEEE T SOFTWARE ENG, V49, P1580, DOI 10.1109/TSE.2022.3183297; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Niu CG, 2022, PROC INT CONF SOFTW, P2006, DOI 10.1145/3510003.3510096; Niu Changan, 2022, P 31 INT JOINT C ART, P5546, DOI 10.24963/ijcai.2022/775; Panthaplackel S, 2021, AAAI CONF ARTIF INTE, V35, P13622; Penha Gustavo, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P699, DOI 10.1007/978-3-030-45439-5_46; Platanios EA, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1162; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Raffel C, 2020, J MACH LEARN RES, V21; Tay Y., 2022, P INT C LEARNING REP; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Vaswani A, 2017, ADV NEUR IN, V30; Wang DZ, 2022, PROC INT CONF SOFTW, P287, DOI 10.1145/3510003.3510062; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xia CS, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P959, DOI 10.1145/3540250.3549101; Xu Benfeng, 2020, P 58 ANN M ASS COMPU, DOI DOI 10.18653/V1/2020.ACL-MAIN.542; Yang Z, 2022, PROC INT CONF SOFTW, P1482, DOI 10.1145/3510003.3510146; Ye H, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556926; Ye H, 2022, PROC INT CONF SOFTW, P1506, DOI 10.1145/3510003.3510222; Yefet N, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428230; Yu SW, 2022, J SYST SOFTWARE, V190, DOI 10.1016/j.jss.2022.111304; Yuan W, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P678, DOI 10.1145/3533767.3534219; Zeng ZR, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P39, DOI 10.1145/3533767.3534390; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zhong WK, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556943; Zhou Y, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3501256; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	58	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	APR	2024	13	7							1200	10.3390/electronics13071200	http://dx.doi.org/10.3390/electronics13071200			19	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	NM5X4		gold			2024-07-03	WOS:001200893900001
J	Ozden, I; Gokyar, M; Ozden, ME; Ovecoglu, HS				Ozden, Idil; Gokyar, Merve; Ozden, Mustafa Enes; Sazak Ovecoglu, Hesna			Assessment of artificial intelligence applications in responding to dental trauma	DENTAL TRAUMATOLOGY			English	Article; Early Access						artificial intelligence; chatbots; ChatGPT; dental trauma; Google Bard Gemini; large language models	INJURIES; MANAGEMENT	BackgroundThis study assessed the consistency and accuracy of responses provided by two artificial intelligence (AI) applications, ChatGPT and Google Bard (Gemini), to questions related to dental trauma.Materials and MethodsBased on the International Association of Dental Traumatology guidelines, 25 dichotomous (yes/no) questions were posed to ChatGPT and Google Bard over 10 days. The responses were recorded and compared with the correct answers. Statistical analyses, including Fleiss kappa, were conducted to determine the agreement and consistency of the responses.ResultsAnalysis of 4500 responses revealed that both applications provided correct answers to 57.5% of the questions. Google Bard demonstrated a moderate level of agreement, with varying rates of incorrect answers and referrals to physicians.ConclusionsAlthough ChatGPT and Google Bard are potential knowledge resources, their consistency and accuracy in responding to dental trauma queries remain limited. Further research involving specially trained AI models in endodontics is warranted to assess their suitability for clinical use.	[Ozden, Idil; Gokyar, Merve; Sazak Ovecoglu, Hesna] Marmara Univ, Fac Dent, Dept Endodont, Istanbul, Turkiye; [Ozden, Mustafa Enes] Hacettepe Univ, Fac Med, Dept Publ Hlth, Ankara, Turkiye	Marmara University; Hacettepe University	Ozden, I (corresponding author), Marmara Univ, Fac Dent, Dept Endodont, Istanbul, Turkiye.	idil.akman94@gmail.com		Ozden, Mustafa Enes/0000-0001-5635-9969; Ozden, Idil/0000-0003-0838-4355				Al-Jundi SH, 2002, DENT TRAUMATOL, V18, P181, DOI 10.1034/j.1600-9657.2002.02081.x; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Asiri AF, 2022, SAUDI DENT J, V34, P270, DOI 10.1016/j.sdentj.2022.04.004; Atkinson CF, 2024, SOC SCI COMPUT REV, V42, P376, DOI 10.1177/08944393231196281; Aydin O., 2023, Academic Platform Journal of Engineering and Smart Systems, V11, P118, DOI [10.2139/ssrn.4341500, DOI 10.2139/SSRN.4341500]; Bastos JV, 2014, DENT TRAUMATOL, V30, P188, DOI 10.1111/edt.12074; Bourguignon C, 2020, DENT TRAUMATOL, V36, P314, DOI 10.1111/edt.12578; Chiesa-Estomba CM., 2023, Eur Arch Otorrinolaringol, V281, P1; Choi JH, 2022, J LEGAL EDUC, V71, P387; Cobb RJ., 2013, Oral Surg, V6, P56, DOI [10.1111/ors.12020, DOI 10.1111/ORS.12020]; da Silva AC, 2004, DENT TRAUMATOL, V20, P6, DOI 10.1111/j.1600-4469.2004.00212.x; Engelmann J, 2020, J CRANIO MAXILL SURG, V48, P661, DOI 10.1016/j.jcms.2020.05.004; Ghanem YK, 2024, SURG ENDOSC, V38, P2887, DOI 10.1007/s00464-024-10739-5; Goktas LS., 2023, J Tour Gastron Stud, V11, P892; Guzman AL, 2020, NEW MEDIA SOC, V22, P70, DOI 10.1177/1461444819858691; Haenssle HA, 2018, ANN ONCOL, V29, P1836, DOI 10.1093/annonc/mdy166; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Huang W., 2023, Retrieval augmented generation with rich answer encoding; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Khanagar SB, 2021, J DENT SCI, V16, P508, DOI 10.1016/j.jds.2020.06.019; Kocyigit A., 2023, J Strateg Soc Res, V7, P427; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Liu X., 2023, AI Open, DOI [10.1016/j.aiopen.2023.08.012, DOI 10.1016/J.AIOPEN.2023.08.012]; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Medenilla A., 2023, PLoS Digital Health, V2; Miller RA, 2016, HEALTH INFORM SER, P181, DOI 10.1007/978-3-319-31913-1_11; Noble JM, 2022, JMIR RES PROTOC, V11, DOI 10.2196/33717; Olczak J, 2017, ACTA ORTHOP, V88, P581, DOI 10.1080/17453674.2017.1344459; Pandey S., 2023, Healthc. Anal., V3; Pillare T., 2023, IRJMETS, V5, P10; Raoof M, 2012, DENT TRAUMATOL, V28, P441, DOI 10.1111/j.1600-9657.2011.01085.x; RAPHAEL SL, 1990, AUST DENT J, V35, P130, DOI 10.1111/j.1834-7819.1990.tb05878.x; Rigamonti L, 2021, BMC SPORTS SCI MED R, V13, DOI 10.1186/s13102-021-00243-x; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Senoymak MC., 2024, J Pers Med, V14, P330; Seth I, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000004999; Shawar BA., 2007, J Lang Technol Comput Linguist, V22, P29, DOI [10.21248/jlcl.22.2007.88, DOI 10.21248/JLCL.22.2007.88]; Soriano EP, 2007, DENT TRAUMATOL, V23, P232, DOI 10.1111/j.1600-9657.2005.00426.x; Suárez A, 2024, INT ENDOD J, V57, P108, DOI 10.1111/iej.13985; Swiecki Z., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100075; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Umer F, 2022, J ENDODONT, V48, P152, DOI 10.1016/j.joen.2021.11.007; Umer F, 2021, OR SURG OR MED OR PA, V132, P255, DOI 10.1016/j.oooo.2021.04.056; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Weng SF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174944; Wood EB, 2002, AUST DENT J, V47, P142, DOI 10.1111/j.1834-7819.2002.tb00318.x; Yigit Y, 2019, DENT TRAUMATOL, V35, P20, DOI 10.1111/edt.12440; Zerfowski M, 1998, Clin Oral Investig, V2, P120, DOI 10.1007/s007840050056; Zuhal K, 2005, DENT TRAUMATOL, V21, P20, DOI 10.1111/j.1600-9657.2004.00265.x	49	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1600-4469	1600-9657		DENT TRAUMATOL	Dent. Traumatol.	2024 MAY 14	2024										10.1111/edt.12965	http://dx.doi.org/10.1111/edt.12965		MAY 2024	8	Dentistry, Oral Surgery & Medicine	Science Citation Index Expanded (SCI-EXPANDED)	Dentistry, Oral Surgery & Medicine	QN3A4	38742754				2024-07-03	WOS:001221500200001
J	Cui, YZ; Liang, MC				Cui, Yizhuo; Liang, Maocheng			Automated Scoring of Translations with BERT Models: Chinese and English Language Case Study	APPLIED SCIENCES-BASEL			English	Article						large language model; BERT; automated scoring of translations; large-scale translation contest		With the wide application of artificial intelligence represented by deep learning in natural language-processing tasks, the automated scoring of translations has also advanced and improved. This study aims to determine if the BERT-assist system can reliably assess translation quality and identify high-quality translations for potential recognition. It takes the Han Suyin International Translation Contest as a case study, which is a large-scale and influential translation contest in China, with a history of over 30 years. The experimental results show that the BERT-assist system is a reliable second rater for massive translations in terms of translation quality, as it can effectively sift out high-quality translations with a reliability of r = 0.9 or higher. Thus, the automated translation scoring system based on BERT can satisfactorily predict the ranking of translations according to translation quality and sift out high-quality translations potentially shortlisted for prizes.	[Cui, Yizhuo] North China Univ Technol, Sch Humanities & Law, Beijing 100144, Peoples R China; [Liang, Maocheng] Beihang Univ, Sch Foreign Languages, Beijing 100191, Peoples R China	North China University of Technology; Beihang University	Liang, MC (corresponding author), Beihang Univ, Sch Foreign Languages, Beijing 100191, Peoples R China.	cuiyz@ncut.edu.cn; frankliang0086@163.com			Fundamental Research Funds by North China University of Technology; TAC program	Fundamental Research Funds by North China University of Technology; TAC program	We are grateful for the data provided by the TAC program.	Ahn S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131910572; Akiba Y., 2001, P MACHINE TRANSLATIO; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Beltagy I., 2019, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chae Y., 2023, Large Language Models for Text Classification: From Zero-Shot Learning to Fine-Tuning, DOI [10.31235/osf.io/sthwk, DOI 10.31235/OSF.IO/STHWK]; Culy C., 2003, P MACHINE TRANSLATIO; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doddington G., 2002, P 22 INT C HUM LANG, P138; Fiscus J. G., 2006, P 5 INT C LANGUAGE R, P803; Guo Q, 2022, INT J INTELL SYST, V37, P8548, DOI 10.1002/int.22955; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hasan T, 2021, Arxiv, DOI arXiv:2106.13822; Heeringa W., 2004, THESIS U GRONINGEN G; Kang BYH, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app132413177; Kant N, 2018, Arxiv, DOI arXiv:1812.01207; Keswani G., 2024, International Journal of Intelligent Systems and Applications in Engineering, V12, P160; KRUSKAL JB, 1983, SIAM REV, V25, P201, DOI 10.1137/1025045; Leusch G., 2006, PROC EACL 1TH C EUR, P241; Leusch G., 2003, P MACHINE TRANSLATIO; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Niessen S, 2000, P 2 INT C LANGUAGE R; Panchenko A, 2018, Arxiv, DOI [arXiv:1803.05820, DOI arXiv:1803.05820.null]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Petrakis E. G. M., 2006, Journal of Digital Information Management, V4, P233; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Robinson J, 2022, Arxiv, DOI [arXiv:2210.12353, 10.48550/arXiv.2210.12353]; Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P373, DOI 10.1145/2766462.2767738; Slimani T., 2013, PREPRINT; Snover M., 2006, P 7 C ASS MACH TRANS, P223; Su K.-Y., 1992, P COLING 1992 VOLUME; Van Veen D, 2024, Arxiv, DOI arXiv:2309.07430; Vaswani A, 2017, ADV NEUR IN, V30; Weigle S.C., 1994, Language Testing, V11, P197; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Yang ZL, 2019, ADV NEUR IN, V32; Zhang T., 2023, arXiv	40	0	0	10	10	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	5							1925	10.3390/app14051925	http://dx.doi.org/10.3390/app14051925			17	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	KU2P7		gold			2024-07-03	WOS:001182416300001
J	Knoedler, S; Sofo, G; Kern, B; Frank, K; Cotofana, S; von Isenburg, S; Könneker, S; Mazzarone, F; Dorafshar, AH; Knoedler, L; Alfertshofer, M				Knoedler, Samuel; Sofo, Giuseppe; Kern, Barbara; Frank, Konstantin; Cotofana, Sebastian; von Isenburg, Sarah; Konneker, Soren; Mazzarone, Francesco; Dorafshar, Amir H.; Knoedler, Leonard; Alfertshofer, Michael			Modern Machiavelli? The illusion of ChatGPT-generated patient reviews in plastic and aesthetic surgery based on 9000 review classifications	JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY			English	Review						Artificial intelligence; ChatGPT; GPT-4; Large language model; Patient review; Plastic Surgery		Background: Online patient reviews are crucial in guiding individuals who seek plastic surgery, but artificial chatbots pose a threat of disseminating fake reviews. This study aimed to compare real patient feedback with ChatGPT-generated reviews for the top five US plastic surgery procedures.Methods: Thirty real patient reviews on rhinoplasty, blepharoplasty, facelift, liposuction, and breast augmentation were collected from RealSelf and used as templates for ChatGPT to generate matching patient reviews. Prolific users (n = 30) assessed 150 pairs of reviews to identify human-written and artificial intelligence (AI)-generated reviews. Patient reviews were further assessed using AI content detector software (Copyleaks AI).Results: Among the 9000 classification tasks, 64.3% and 35.7% of reviews were classified as authentic and fake, respectively. On an average, the author (human versus machine) was correctly identified in 59.6% of cases, and this poor classification performance was consistent across all procedures. Patients with prior aesthetic treatment showed poorer classification performance than those without (p < 0.05). The mean character count in human-written re- views was significantly higher (p < 0.001) that that in AI-generated reviews, with a significant correlation between character count and participants' accuracy rate (p < 0.001). Emotional timbre of reviews differed significantly with "happiness" being more prevalent in human-written reviews (p < 0.001), and "disappointment" being more prevalent in AI reviews (p = 0.005). Copyleaks AI correctly classified 96.7% and 69.3% of human-written and ChatGPT-generated reviews, respectively.Conclusion: ChatGPT convincingly replicates authentic patient reviews, even deceiving commercial AI detection software. Analyzing emotional tone and review length can help differentiate real from fake reviews, underscoring the need to educate both patients and physicians to prevent misinformation and mistrust.(c) 2023 British Association of Plastic, Reconstructive and Aesthetic Surgeons. Published by Elsevier Ltd. All rights reserved.	[Knoedler, Samuel] Tech Univ Munich, Dept Plast Surg & Hand Surg, Klinikum Rechts Isar, Munich, Germany; [Knoedler, Samuel] Harvard Med Sch, Brigham & Womens Hosp, Div Plast Surg, Dept Surg, Boston, MA USA; [Knoedler, Samuel; Sofo, Giuseppe; Mazzarone, Francesco] Pontificia Univ Catolica Rio De Janeiro, Hosp Santa Casa Misericordia, Inst Ivo Pitanguy, Rio De Janeiro, Brazil; [Kern, Barbara] Charite Univ Med Berlin, Dept Plast Surg, Berlin, Germany; [Kern, Barbara] Free Univ Berlin, Berlin, Germany; [Kern, Barbara] Humboldt Univ, Berlin, Germany; [Kern, Barbara] Berlin Inst Hlth, Berlin, Germany; [Frank, Konstantin] Ocean Clin, Marbella, Spain; [Cotofana, Sebastian] Queen Mary Univ London, Blizard Inst, Ctr Cutaneous Res, London, England; [Cotofana, Sebastian] Erasmus Hosp, Dept Dermatol, Rotterdam, Netherlands; [von Isenburg, Sarah] Plast Chirurg Munchen Dres Neuhann Lorenz & v Isen, Munich, Germany; [Konneker, Soren] Univ Hosp Zurich, Dept Plast Surg & Hand Surg, Zurich, Switzerland; [Dorafshar, Amir H.] Rush Univ, Med Ctr, Div Plast & Reconstruct Surg, Chicago, IL USA; [Knoedler, Leonard] Harvard Med Sch, Massachusetts Gen Hosp, Div Plast & Reconstruct Surg, Boston, MA USA; [Konneker, Soren; Alfertshofer, Michael] Ludwig Maximilians Univ Munchen, Univ Hosp, Div Hand Plast & Aesthet Surg, Munich, Germany; [Knoedler, Samuel] Tech Univ Munich, Dept Plast Surg & Hand Surg, Klinikum Rechts Isar, Munich, Germany	Technical University of Munich; Harvard University; Harvard Medical School; Brigham & Women's Hospital; Pontificia Universidade Catolica do Rio de Janeiro; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Berlin Institute of Health; University of London; Queen Mary University London; Erasmus University Rotterdam; Erasmus MC; University of Zurich; University Zurich Hospital; Rush University; Harvard University; Harvard Medical School; Massachusetts General Hospital; University of Munich; Technical University of Munich	Knoedler, S (corresponding author), Tech Univ Munich, Dept Plast Surg & Hand Surg, Klinikum Rechts Isar, Munich, Germany.	samuel.knoedler@tum.de	Alfertshofer, Michael/ACL-5945-2022; Kern, Barbara/HNR-7932-2023; Dorafshar, Amir/AAP-2657-2021	Alfertshofer, Michael/0000-0002-4892-2376; Dorafshar, Amir/0000-0001-7045-3601; Cotofana, Sebastian/0000-0001-7210-6566				Chang IA, 2022, AESTHET SURG J, V42, P1083, DOI 10.1093/asj/sjac092; Ekman Paul, 1999, HDB COGNITION EMOTIO, P45, DOI [DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]; Haas Cynthia Figueroa, 2008, Plast Surg Nurs, V28, P177, DOI 10.1097/PSN.0b013e31818ea832; Hanauer DA, 2014, JAMA-J AM MED ASSOC, V311, P734, DOI 10.1001/jama.2013.283194; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; International Society of Aesthetic Plastic Surgerons (ISAPS), 2020, ISAPS international survey on aesthetic / cosmetic procedures performed in 2020, P1; Karamitros G, 2023, AESTHET PLAST SURG, V47, P1644, DOI 10.1007/s00266-022-03223-9; Lee Paul B, 2022, J Plast Reconstr Aesthet Surg, V75, P2368, DOI 10.1016/j.bjps.2022.02.060; Liechty AE, 2020, PRS-GLOB OPEN, V8, DOI 10.1097/GOX.0000000000003202; Liu JJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7475; Lu SD, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.879; Martinez Otero Juan Maria, 2021, SN Soc Sci, V1, P181, DOI 10.1007/s43545-021-00193-8; Najafali D, 2023, AESTHET SURG J, V43, pNP663, DOI 10.1093/asj/sjad116; Najafali D, 2023, AESTHET SURG J, V43, pNP654, DOI 10.1093/asj/sjad093; Najafali D, 2023, AESTHET SURG J, V43, pNP591, DOI 10.1093/asj/sjad056; Salehahmadi Z, 2012, WORLD J PLAST SURG, V1, P99; Shauly O, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad024; The American Society of Plastic Surgeons, 2022, ASPS procedural statistics release; Trong ND, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042338; von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379; Wu Y, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0267451	21	1	1	13	18	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1748-6815	1878-0539		J PLAST RECONSTR AES	J. Plast. Reconstr. Aesthet. Surg.	JAN	2024	88						99	108		10.1016/j.bjps.2023.10.119	http://dx.doi.org/10.1016/j.bjps.2023.10.119		NOV 2023	10	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	Z6EP9	37972444				2024-07-03	WOS:001112987800001
J	Cho, Y; Park, JM; Youn, S				Cho, Yongwon; Park, Jong Mok; Youn, Seunghyun			General Overview of Artificial Intelligence for Interstitial Cystitis in Urology	INTERNATIONAL NEUROUROLOGY JOURNAL			English	Review						Interstitial cystitis; Diagnosis; Treatment; Convolutional neural network; Deep learning; Large language model	INTRAVESICAL HYALURONIC-ACID; PENTOSAN POLYSULFATE SODIUM; DOUBLE-BLIND; EFFICACY; SYSTEM	Our understanding of interstitial cystitis/bladder pain syndrome (IC/BPS) has evolved over time. The diagnosis of IC/BPS is primarily based on symptoms such as urgency, frequency, and bladder or pelvic pain. While the exact causes of IC/BPS remain unclear, it is thought to involve several factors, including abnormalities in the bladder's urothelium, mast cell degranulation within the bladder, inflammation of the bladder, and altered innervation of the bladder. Treatment options include patient education, dietary and lifestyle modifications, medications, intravesical therapy, and surgical interventions. This review article provides insights into IC/BPS, including aspects of treatment, prognosis prediction, and emerging therapeutic options. Additionally, it explores the application of deep learning for diagnosing major diseases associated with IC/BPS.	[Cho, Yongwon] Korea Univ, Anam Hosp, Dept AI Ctr, Seoul, South Korea; [Park, Jong Mok] Chungnam Natl Univ, Sejong Hosp, Coll Med, Dept Urol, Sejong, South Korea; [Youn, Seunghyun] GRK Partners Res Ctr, Seoul, South Korea	Korea University; Korea University Medicine (KU Medicine); Chungnam National University	Youn, S (corresponding author), GRK Partners Res Ctr, 200 Iteawon Ro, Seoul 04405, South Korea.	ceo@grkcon.com		Youn, Seunghyun/0009-0000-6857-8229; Cho, Yongwon/0000-0001-8092-5799	Chungnam National University	Chungnam National University	This work was supported by Chungnam National University.	Abrams P, 2002, NEUROUROL URODYNAM, V21, P167, DOI 10.1002/nau.10052; Ali N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91081-x; Bannur S, 2023, PROC CVPR IEEE, P15016, DOI 10.1109/CVPR52729.2023.01442; Cho Y, 2023, INT NEUROUROL J, V27, pS13, DOI 10.5213/inj.2346106.053; Chung KJ, 2019, INT NEUROUROL J, V23, P180; Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5; Davis EL, 2008, J UROLOGY, V179, P177, DOI 10.1016/j.juro.2007.08.170; Eun SJ, 2022, INT NEUROUROL J, V26, P210, DOI 10.5213/inj.2244202.101; Eun SJ, 2022, INT NEUROUROL J, V26, P78, DOI 10.5213/inj.2244064.032; Eun SJ, 2021, J EXERC REHABIL, V17, P308, DOI 10.12965/jer.2142596.298; Eun SJ, 2021, INT NEUROUROL J, V25, P229, DOI 10.5213/inj.2142276.138; Garzon S, 2020, MENOPAUSE REV, V19, P35, DOI 10.5114/pm.2020.95334; GHONIEM GM, 1993, WORLD J UROL, V11, P178; Haenssle HA, 2018, ANN ONCOL, V29, P1836, DOI 10.1093/annonc/mdy166; Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011; Hirasawa T, 2018, GASTRIC CANCER, V21, P653, DOI 10.1007/s10120-018-0793-2; Ikeda A, 2020, J ENDOUROL, V34, P352, DOI 10.1089/end.2019.0509; Iwaki T, 2023, EUR UROL OPEN SCI, V49, P44, DOI 10.1016/j.euros.2022.12.012; Kim ES, 2022, INT NEUROUROL J, V26, pS76, DOI 10.5213/inj.2244030.015; 손기정, 2012, [The Journal of Korean Oriental Internal Medicine, 대한한방내과학회지], V33, P222; Leppilahti M, 2002, UROLOGY, V60, P46, DOI 10.1016/S0090-4295(02)01613-8; McIntire PJ, 2019, CANCER CYTOPATHOL, V127, P125, DOI 10.1002/cncy.22102; Min S, 2022, ICS2022; Morales A, 1997, UROLOGY, V49, P111, DOI 10.1016/S0090-4295(97)00183-0; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Myung NV, 2019, INT NEUROUROL J, V23, P86, DOI 10.5213/inj.1938020.010; Nickel JC, 2005, UROLOGY, V65, P654, DOI 10.1016/j.urology.2004.10.071; Oh JK, 2022, INT NEUROUROL J, V26, P268, DOI 10.5213/inj.2244280.140; PARSONS CL, 1993, J UROLOGY, V150, P845, DOI 10.1016/S0022-5347(17)35629-X; Porru D, 1997, UROL INT, V59, P26, DOI 10.1159/000283012; Riedl CR, 2008, INT UROGYNECOL J, V19, P717, DOI 10.1007/s00192-007-0515-5; Shen YQ, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26023-2; Shkolyar E, 2019, EUR UROL, V76, P714, DOI 10.1016/j.eururo.2019.08.032; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Pham TC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96707-8; van de Merwe JP, 2008, EUR UROL, V53, P60, DOI 10.1016/j.eururo.2007.09.019; Whitmore KE, 1995, NIDDK INT CYST ASS S; Yamamoto Y, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13647-8; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421	39	2	2	1	1	KOREAN CONTINENCE SOC	YEONGOTONG-GU	DEPT UROLOGY, AJOU UNIV COLL MEDICINE, SAN 5 WONCHEN-DONG, YEONGOTONG-GU, SUWON 443-721, SOUTH KOREA	2093-4777	2093-6931		INT NEUROUROL J	Int. Neurourol. J.	NOV	2023	27			2			S64	S72		10.5213/inj.2346294.147	http://dx.doi.org/10.5213/inj.2346294.147			9	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	Z3QT3	38048820	Green Published, gold			2024-07-03	WOS:001111259500003
J	Boussen, S; Denis, JB; Simeone, P; Lagier, D; Bruder, N; Velly, L				Boussen, Salah; Denis, Jean-Baptiste; Simeone, Pierre; Lagier, David; Bruder, Nicolas; Velly, Lionel			ChatGPT and the stochastic parrot: artificial intelligence in medical research	BRITISH JOURNAL OF ANAESTHESIA			English	Letter						artificial intelligence; citations; data integrity; large language models; research integrity; scientific reporting			[Boussen, Salah; Denis, Jean-Baptiste; Simeone, Pierre; Lagier, David; Bruder, Nicolas; Velly, Lionel] Aix Marseille Univ, CHU Timone, Dept Anesthesiol & Intens Care, F-13385 Marseille, France; [Boussen, Salah] Aix Marseille Univ, IFSTTAR, LBA UMR T 24, Marseille, France; [Simeone, Pierre; Velly, Lionel] Aix Marseille Univ, Inst Neurociences Timone, CNRS UMR1106, Marseille, France	Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Universite Gustave-Eiffel; Aix-Marseille Universite; Aix-Marseille Universite	Boussen, S (corresponding author), Aix Marseille Univ, CHU Timone, Dept Anesthesiol & Intens Care, F-13385 Marseille, France.; Boussen, S (corresponding author), Aix Marseille Univ, IFSTTAR, LBA UMR T 24, Marseille, France.	salah.boussen@univ-eiffel.fr	Boussen, Salah/KIJ-3617-2024	Lagier, David/0000-0003-3861-5062; boussen, salah/0000-0002-9259-1498				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Grigio TR, 2023, BRIT J ANAESTH, V131, pE29, DOI 10.1016/j.bja.2023.04.009; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Sanchez-Ramos L, 2023, AM J OBSTET GYNECOL, V229, P356, DOI 10.1016/j.ajog.2023.04.004; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0	9	2	2	10	15	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	OCT	2023	131	4					E120	E121		10.1016/j.bja.2023.06.065	http://dx.doi.org/10.1016/j.bja.2023.06.065		SEP 2023	2	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	T9VT3	37516646				2024-07-03	WOS:001081396000001
J	Cerrato, PL; Halamka, JD				Cerrato, Paul L.; Halamka, John D.			How AI drives innovation in cardiovascular medicine	FRONTIERS IN CARDIOVASCULAR MEDICINE			English	Article						artificial intelligence; large language models; retrieval augmented generation; ChatGPT; innovation; cardiovascular disease	ARTIFICIAL-INTELLIGENCE; TRIAL	Medicine is entering a new era in which artificial intelligence (AI) and deep learning have a measurable impact on patient care. This impact is especially evident in cardiovascular medicine. While the purpose of this short opinion paper is not to provide an in-depth review of the many applications of AI in cardiovascular medicine, we summarize some of the important advances that have taken place in this domain.	[Cerrato, Paul L.; Halamka, John D.] Mayo Clin, Mayo Clin Platform, Rochester, MN 55905 USA	Mayo Clinic	Halamka, JD (corresponding author), Mayo Clin, Mayo Clin Platform, Rochester, MN 55905 USA.	halamka.john@mayo.edu						Attia ZI, 2019, LANCET, V394, P861, DOI 10.1016/S0140-6736(19)31721-0; Boonstra MJ, 2024, EUR HEART J, V45, P332, DOI 10.1093/eurheartj/ehad838; Cerrato P, 2022, BMJ HEALTH CARE INFO, V29, DOI 10.1136/bmjhci-2021-100423; Coalition for Health AI, 2023, BLUEPRINT TRUSTWORTH; Ghorbani A, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0216-8; He BY, 2023, NATURE, V616, P520, DOI 10.1038/s41586-023-05947-3; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x; Med-PaLM, A Large Language Model from Google Research, Designed for the Medical Domain; Noseworthy PA, 2022, LANCET, V400, P1206, DOI 10.1016/S0140-6736(22)01637-3; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Salihu A, 2023, EUROINTERVENTION, V19, pE798, DOI 10.4244/EIJ-D-23-00461; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P368, DOI 10.1093/ehjdh/ztad041; van Assen M, 2023, EUR HEART J, V44, P541, DOI 10.1093/eurheartj/ehac700; Yao XX, 2021, NAT MED, V27, P815, DOI 10.1038/s41591-021-01335-4	16	0	0	1	1	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2297-055X			FRONT CARDIOVASC MED	Front. Cardiovasc. Med.	APR 26	2024	11								1397921	10.3389/fcvm.2024.1397921	http://dx.doi.org/10.3389/fcvm.2024.1397921			4	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	PU9B2	38737711				2024-07-03	WOS:001216702400001
J	Bai, RH; Zhu, HW; Li, JC; Liu, DW; Lu, X				Bai, Ruihang; Zhu, Haiwei; Li, Jiacheng; Liu, Dawei; Lu, Xin			Exploring the potential of ChatGPT in enhancing atmospheric pressure plasma research techniques	PLASMA PROCESSES AND POLYMERS			English	Article; Early Access						atmospheric pressure plasma; ChatGPT; large language model; plasma-water-based nitrogen fixation	GPT-4	Released in March 2023, GPT-4 has shown remarkable proficiency in various scientific areas, including atmospheric pressure plasma research. The paper discusses how GPT-4, supported by ScholarAI and Wolfram plugins, enhances research efficiency with its vast knowledge and inferencing skills. It focuses on plasma-water-based nitrogen fixation experiments, demonstrating GPT-4's abilities in explanation, analysis, prediction, planning, and verification. The study also addresses challenges like interpreting non-textual data and keeping pace with scientific advancements. It highlights GPT-4's role in improving nitrogen fixation process efficiency, showcasing its utility in scientific analysis and decision-making. The paper emphasizes the evolving role of AI in research and the need for the scientific community to adapt to the rise of more advanced AI systems. GPT-4 advances plasma research in explanation, analysis, prediction, planning, and verification. image	[Bai, Ruihang; Zhu, Haiwei; Li, Jiacheng; Liu, Dawei] Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, State Key Lab Adv Electromagnet Engn & Technol, Wuhan, Peoples R China; [Liu, Dawei] Wuhan Natl High Magnet Field Ctr, Wuhan 430074, Peoples R China; [Lu, Xin] Leeds Trinity Univ, Sch Comp Sci, Leeds, England; [Liu, Dawei] Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, State Key Lab Adv Electromagnet Technol, Wuhan 430074, Hubei, Peoples R China; [Lu, Xin] Leeds Trinity Univ, Sch Comp Sci, Leeds LS18 5HD, England	Huazhong University of Science & Technology; Huazhong University of Science & Technology; Huazhong University of Science & Technology	Liu, DW (corresponding author), Huazhong Univ Sci & Technol, Sch Elect & Elect Engn, State Key Lab Adv Electromagnet Technol, Wuhan 430074, Hubei, Peoples R China.; Lu, X (corresponding author), Leeds Trinity Univ, Sch Comp Sci, Leeds LS18 5HD, England.	liudw@hust.edu.cn; x.lu@leedstrinity.ac.uk		Liu, Dawei/0000-0003-3503-2099	National Natural Science Foundation of China; Interdisciplinary Program of Wuhan National High Magnetic Field Center [WHMFC202144]; Huazhong University of Science and Technology;  [52277149]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Interdisciplinary Program of Wuhan National High Magnetic Field Center; Huazhong University of Science and Technology; 	This work was supported by the National Natural Science Foundation of China (Grant No. 52277149) and the Interdisciplinary Program of Wuhan National High Magnetic Field Center (Grant No. WHMFC202144), Huazhong University of Science and Technology.	Abramski K, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7030124; [Anonymous], 2023, Openai; Cheng KM, 2023, ANN BIOMED ENG, V51, P1645, DOI 10.1007/s10439-023-03221-1; Cheng KM, 2023, ANN BIOMED ENG, V51, P1658, DOI 10.1007/s10439-023-03213-1; Egli A, 2023, CLIN INFECT DIS, V77, P1322, DOI 10.1093/cid/ciad407; George D. A. S., 2023, Partners Univ. Int. Res. J, V2, P149; Hatakeyama-Sato K, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-s1x5p, 10.26434/chemrxiv-2023-s1x5p, DOI 10.26434/CHEMRXIV-2023-S1X5P]; He YB, 2023, ANN BIOMED ENG, V51, P1362, DOI 10.1007/s10439-023-03206-0; Le Mens G, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2309350120; Lee P., 2023, The AI Revolution in Medicine: GPT-4 and Beyond; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Peng SX, 2024, ANN BIOMED ENG, V52, P462, DOI 10.1007/s10439-023-03314-x; Sander R, 2022, PURE APPL CHEM, V94, P71, DOI 10.1515/pac-2020-0302; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Tornin J, 2021, NAT PROTOC, V16, P2826, DOI 10.1038/s41596-021-00521-5; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291	17	0	0	8	8	WILEY-V C H VERLAG GMBH	WEINHEIM	POSTFACH 101161, 69451 WEINHEIM, GERMANY	1612-8850	1612-8869		PLASMA PROCESS POLYM	Plasma Process. Polym.	2024 APR 2	2024										10.1002/ppap.202400028	http://dx.doi.org/10.1002/ppap.202400028		APR 2024	12	Physics, Applied; Physics, Fluids & Plasmas; Physics, Condensed Matter; Polymer Science	Science Citation Index Expanded (SCI-EXPANDED)	Physics; Polymer Science	MP8J7					2024-07-03	WOS:001194917400001
J	Ng, DTK; Tan, CW; Leung, JKL				Ng, Davy Tsz Kit; Tan, Chee Wei; Leung, Jac Ka Lok			Empowering student self-regulated learning and science education through ChatGPT: A pioneering pilot study	BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY			English	Article; Early Access						chatbot; ChatGPT; generative AI; large language model; science education; self-regulated learning	MOTIVATION; EXPERIENCES	In recent years, AI technologies have been developed to promote students' self-regulated learning (SRL) and proactive learning in digital learning environments. This paper discusses a comparative study between generative AI-based (SRLbot) and rule-based AI chatbots (Nemobot) in a 3-week science learning experience with 74 Secondary 4 students in Hong Kong. The experimental group used SRLbot to maintain a regular study habit and facilitate their SRL, while the control group utilized rule-based AI chatbots. Results showed that SRLbot effectively enhanced students' science knowledge, behavioural engagement and motivation. Quantile regression analysis indicated that the number of interactions significantly predicted variations in SRL. Students appreciated the personalized recommendations and flexibility of SRLbot, which adjusted responses based on their specific learning and SRL scenarios. The ChatGPT-enhanced instructional design reduced learning anxiety and promoted learning performance, motivation and sustained learning habits. Students' feedback on learning challenges, psychological support and self-regulation behaviours provided insights into their progress and experience with this technology. SRLbot's adaptability and personalized approach distinguished it from rule-based chatbots. The findings offer valuable evidence for AI developers and educators to consider generative AI settings and chatbot design, facilitating greater success in online science learning.	[Ng, Davy Tsz Kit] Univ Hong Kong, Fac Educ, Hong Kong, Peoples R China; [Tan, Chee Wei] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore; [Leung, Jac Ka Lok] Hong Kong Univ Sci & Technol, Div Integrat Syst & Design, Hong Kong, Peoples R China; [Ng, Davy Tsz Kit] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China	University of Hong Kong; Nanyang Technological University; Hong Kong University of Science & Technology; Hong Kong University of Science & Technology	Ng, DTK (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.	davyngtk@connect.hku.hk	Ng, Tsz Kit Davy/ADD-3433-2022; TAN, Chee Wei/A-7471-2010	Ng, Tsz Kit Davy/0000-0002-2380-7814; TAN, Chee Wei/0000-0002-6624-9752	Centre for Teaching, Learning and Pedagogy, NTU [03INS001595C130]	Centre for Teaching, Learning and Pedagogy, NTU	This project is supported by the EdeX Grant (No. 03INS001595C130) from the Centre for Teaching, Learning and Pedagogy, NTU.	Afzaal M, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.723447; Alam A., 2021, 2021 INT C ADV COMP, P1, DOI [10.1109/ICAC353642.2021.9697300, DOI 10.1109/ICAC353642.2021.9697300]; Alpaslan MM, 2016, INT J SCI MATH EDUC, V14, P297, DOI 10.1007/s10763-015-9685-7; Azevedo R, 2010, EDUC PSYCHOL-US, V45, P210, DOI 10.1080/00461520.2010.515934; Breitwieser J, 2023, COMPUT EDUC, V205, DOI 10.1016/j.compedu.2023.104879; Buchner J, 2023, COMPUT EDUC, V195, DOI 10.1016/j.compedu.2022.104711; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Chang CY, 2022, BRIT J EDUC TECHNOL, V53, P171, DOI 10.1111/bjet.13158; Chang D., 2023, Comput. Educ. Artif. Intell, V5; Chang DH, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151712921; Chen CM, 2014, BRIT J EDUC TECHNOL, V45, P959, DOI 10.1111/bjet.12119; Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510; Cheng KH, 2020, BRIT J EDUC TECHNOL, V51, P2139, DOI 10.1111/bjet.12956; Chiu T. K., 2022, EDUC PSYCHOL-UK, V42; Chiu TKF, 2022, IEEE T EDUC, V65, P30, DOI 10.1109/TE.2021.3085878; Cho MH, 2015, DISTANCE EDUC, V36, P80, DOI 10.1080/01587919.2015.1019963; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Dao XQ, 2023, Arxiv, DOI arXiv:2306.06331; Devolder A, 2012, J COMPUT ASSIST LEAR, V28, P557, DOI 10.1111/j.1365-2729.2011.00476.x; Dignath C, 2021, EDUC PSYCHOL REV, V33, P489, DOI 10.1007/s10648-020-09534-0; Domínguez A, 2013, COMPUT EDUC, V63, P380, DOI 10.1016/j.compedu.2012.12.020; Durall E., 2020, Learning and collaboration technologies. Human and technology ecosystems: 7th International Conference, LCT 2020, held as part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19-24, 2020, Proceedings; Fan YZ, 2021, INT J ARTIF INTELL E, V31, P980, DOI 10.1007/s40593-021-00249-z; Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338; Gelan A., 2018, Computer Assisted Language Learning, V31; Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020; Hsu TC, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2165508; Hu JJ, 2017, EDUC RES REV-NETH, V22, P181, DOI 10.1016/j.edurev.2017.09.004; Hwang G.-J., 2022, COMPUTERS ED ARTIFIC, V3, DOI [10.1016/j.caeai.2022.100082, DOI 10.1016/J.CAEAI.2022.100082]; Jarrah A.M., 2023, EURASIA J MATH SCI T, V19, P2286; Jeon J, 2024, COMPUT ASSIST LANG L, V37, P1, DOI 10.1080/09588221.2021.2021241; Jin SH, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00406-5; Jingting Li, 2021, L@S '21: Proceedings of the Eighth ACM Conference on Learning @ Scale, P117, DOI 10.1145/3430895.3460134; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim C, 2014, BRIT J EDUC TECHNOL, V45, P171, DOI 10.1111/j.1467-8535.2012.01382.x; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Lau K. L., 2022, Journal of Psychoeducational Assessment, V40; Lee JCK, 2010, INT J TEST, V10, P149, DOI 10.1080/15305050903534670; Ling L., 2018, Pilot study on optimal task scheduling in learning, DOI [10.1145/3231644.3231677, DOI 10.1145/3231644.3231677]; Littlejohn A, 2016, INTERNET HIGH EDUC, V29, P40, DOI 10.1016/j.iheduc.2015.12.003; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Maldonado-Mahauad J., 2022, European Conference on Technology Enhanced Learning; McCombs B. L., 2013, Self-regulated learning and academic achievement; Molenaar I., 2022, Computers in Human Behavior, V139; Molenaar I., 2022, COMPUTERS ED ARTIFIC, V3, P100070, DOI [DOI 10.1016/J.CAEAI.2022.100070, https://doi.org/10.1016/j.caeai.2022.100070]; Ng D.T.K., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100041; Ng D. T. K., 2023, AI literacy in K-16 classrooms; Ng DTK, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13411; Ng DTK, 2023, EDUC TECHNOL SOC, V26, DOI 10.30191/ETS.202310_26(4).0009; Ng DTK, 2022, BRIT J EDUC TECHNOL, V53, P443, DOI 10.1111/bjet.13185; Ng DTK, 2021, J SCI EDUC TECHNOL, V30, P608, DOI 10.1007/s10956-021-09907-2; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perez-Alvarez R., 2022, Tools designed to support self-regulated learning in online learning environments: A systematic review; Pintrich PR, 2004, EDUC PSYCHOL REV, V16, P385, DOI 10.1007/s10648-004-0006-x; Reeve J., 2012, Motivation and self-regulated learning; Roll I., 2015, Journal of Learning Analytics, V2; Ryan R.M., 2002, Handbook of self-determination research, V2, P3, DOI DOI 10.1111/BJHP.12054; Sadriu S., 2021, MEDITERRANEAN C PATT; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Schunk DH, 2020, CONTEMP EDUC PSYCHOL, V60, DOI 10.1016/j.cedpsych.2019.101832; Stevenson MP, 2017, EDUC RES REV-NETH, V21, P1, DOI 10.1016/j.edurev.2017.02.002; Strobelt H., 2022, IEEE Transactions on Visualization and Computer Graphics, V29; Tan C.-W., 2022, SIGMETRICS Performance Evaluation Review, V49; Tan CW, 2023, Arxiv, DOI [arXiv:2311.14708, 10.48550/arXiv.2311.14708, DOI 10.48550/ARXIV.2311.14708]; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Topal AD, 2021, EDUC INF TECHNOL, V26, P6241, DOI 10.1007/s10639-021-10627-8; van der Waa J, 2021, ARTIF INTELL, V291, DOI 10.1016/j.artint.2020.103404; Veenman M.V.J., 2006, Metacogn Learn, V1; Velayutham S, 2013, RES SCI EDUC, V43, P507, DOI 10.1007/s11165-011-9273-y; Wang CY, 2023, COMPUT HUM BEHAV, V144, DOI 10.1016/j.chb.2023.107721; Wang MT, 2013, LEARN INSTR, V28, P12, DOI 10.1016/j.learninstruc.2013.04.002; Winne P.H., 2013, J ED DATA MINING, V5; Wolters CA, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P635, DOI 10.1007/978-1-4614-2018-7_30; Wong J, 2019, INT J HUM-COMPUT INT, V35, P356, DOI 10.1080/10447318.2018.1543084; Wu R, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13334; Xia Q, 2023, BRIT J EDUC TECHNOL, V54, P967, DOI 10.1111/bjet.13305; Yang D., 2012, UNIFIED APPROACH MEA; Young JC, 2023, INT J ADV COMPUT SC, V14, P65; Zimmerman BJ, 2011, EDUC PSYCHOL HANDB, P49; Zimmerman BJ, 2002, THEOR PRACT, V41, P64, DOI 10.1207/s15430421tip4102_2	80	2	2	136	136	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1013	1467-8535		BRIT J EDUC TECHNOL	Br. J. Educ. Technol.	2024 MAR 22	2024										10.1111/bjet.13454	http://dx.doi.org/10.1111/bjet.13454		MAR 2024	26	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	LT4Y8		hybrid			2024-07-03	WOS:001189052000001
J	Sahin, MC; Sozer, A; Kuzucu, P; Turkmen, T; Sahin, MB; Sozer, E; Tufek, OY; Nernekli, K; Emmez, H; Celtikci, E				Sahin, Mustafa Caglar; Sozer, Alperen; Kuzucu, Pelin; Turkmen, Tolga; Sahin, Merve Buke; Sozer, Ekin; Tufek, Ozan Yavuz; Nernekli, Kerem; Emmez, Hakan; Celtikci, Emrah			Beyond human in neurosurgical exams: ChatGPT's success in the Turkish neurosurgical society proficiency board exams	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Artificial intelligence; Board; ChatGPT; Education; Exam; Machine learning; Large language model		Chat Generative Pre-Trained Transformer (ChatGPT) is a sophisticated natural language model that employs advanced deep learning techniques and is trained on extensive datasets to produce responses akin to human conversation for user inputs. In this study, ChatGPT's success in the Turkish Neurosurgical Society Proficiency Board Exams (TNSPBE) is compared to the actual candidates who took the exam, along with identifying the types of questions it answered incorrectly, assessing the quality of its responses, and evaluating its performance based on the difficulty level of the questions. Scores of all 260 candidates were recalculated according to the exams they took and included questions in those exams for ranking purposes of this study. The average score of the candidates for a total of 523 questions is 62.02 +/- 0.61 compared to ChatGPT, which was 78.77. We have concluded that in addition to ChatGPT's higher response rate, there was also a correlation with the increase in clarity regardless of the difficulty level of the questions with Clarity 1.5, 2.0, 2.5, and 3.0. In the participants, however, there is no such increase in parallel with the increase in clarity.	[Sahin, Mustafa Caglar; Sozer, Alperen; Kuzucu, Pelin; Tufek, Ozan Yavuz; Emmez, Hakan; Celtikci, Emrah] Gazi Univ, Fac Med, Dept Neurosurg, Ankara, Turkiye; [Turkmen, Tolga] Minist Hlth, Dept Neurosurg, Dortyol State Hosp, Hatay, Turkiye; [Sahin, Merve Buke] Ankara Prov Hlth Directorate, Minist Hlth, Dept Publ Hlth, Ankara, Turkiye; [Sozer, Ekin] Gazi Univ, Directorate Hlth Culture & Sports, Ankara, Turkiye; [Nernekli, Kerem] Stanford Univ, Sch Med, Dept Radiol, Stanford, CA 94305 USA; [Celtikci, Emrah] Gazi Univ, Artificial Intelligence Ctr, Ankara, Turkiye; [Sahin, Mustafa Caglar] Gazi Univ, Fac Med, Dept Neurosurg, TR-06500 Ankara, Turkiye	Gazi University; Dortyol State Hospital; Ministry of Health - Turkey; Ministry of Health - Turkey; Gazi University; Stanford University; Gazi University; Gazi University	Sahin, MC (corresponding author), Gazi Univ, Fac Med, Dept Neurosurg, TR-06500 Ankara, Turkiye.	mcaglarsahin@gazi.edu.tr; alperen.sozer@gazi.edu.tr; drpelinkuzucu@gmail.com; tlgturkmen@gmail.com; merve.buke@hacettepe.edu.tr; ekin.aktas@gazi.edu.tr; ozanyavuztufek@gazi.edu.tr; kerem.nernekli@stanford.edu.tr; hemmez@gazi.edu.tr; emrahceltikci@gazi.edu.tr	Nernekli, Kerem/KOD-5732-2024; Sahin, Mustafa Caglar/AHE-4640-2022; SOZER, ALPEREN/ACA-5655-2022	Nernekli, Kerem/0000-0001-8586-3494; Sahin, Mustafa Caglar/0000-0002-5141-8154; SOZER, ALPEREN/0000-0001-6475-7094; Sozer, Ekin/0009-0009-1938-604X; Tufek, Ozan Yavuz/0000-0002-8157-8829				Ahmad M.A., 2023, CREATING TRUSTWORTHY; Celtikci E, 2018, TURK NEUROSURG, V28, P167, DOI 10.5137/1019-5149.JTN.20059-17.1; Chan Y H, 2003, Singapore Med J, V44, P614; Cheung BHH, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290691; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Dagi TF, 2021, NEUROSURGERY, V89, P133, DOI 10.1093/neuros/nyab170; Du L., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2309.05217; Dundar TT, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.863633; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Fleiss J.L., 2013, Statistical Methods for Rates and Proportions, DOI DOI 10.1002/0471445428; Frosolini A, 2023, ANN BIOMED ENG, V51, P2120, DOI 10.1007/s10439-023-03248-4; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Hopkins BS, 2022, NEUROSURGERY, V90, P383, DOI 10.1227/NEU.0000000000001841; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Hosmer DW, 2013, WILEY SER PROBAB ST, P89; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Jeblick K, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2212.14882; Kao YS, 2024, ANN BIOMED ENG, V52, P455, DOI 10.1007/s10439-023-03308-9; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102320; Manakul P., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.08896; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Moyer JD, 2022, WORLD J EMERG SURG, V17, DOI 10.1186/s13017-022-00449-5; Nasution N. E. A., 2023, Agricultural and Environmental Education, V2, DOI [10.29333/agrenvedu/13071, DOI 10.29333/AGRENVEDU/13071]; OpenAI, 2023, GPT-4 Technical Report, DOI [10.48550/arXiv.2303.08774, DOI 10.48550/ARXIV.2303.08774]; OpenAI ChatGPT, 2022, OPENAI, V30; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Schilling Andrew T, 2022, Acta Neurochir Suppl, V134, P245, DOI 10.1007/978-3-030-85292-4_27; Shin HC, 2018, LECT NOTES COMPUT SC, V11037, P1, DOI 10.1007/978-3-030-00536-8_1; Sozer Alperen, 2023, J Neurosurg Case Lessons, V5, DOI 10.3171/CASE22536; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Traoré SY, 2023, HAND SURG REHABIL, V42, P362, DOI 10.1016/j.hansur.2023.06.005; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946; Yao J.-Y., 2023, LLM LIES HALLUCINATI; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	36	3	3	7	7	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	FEB	2024	169								107807	10.1016/j.compbiomed.2023.107807	http://dx.doi.org/10.1016/j.compbiomed.2023.107807		DEC 2023	8	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	EE8Z8	38091727				2024-07-03	WOS:001137349100001
J	Gencer, A; Aydin, S				Gencer, Adem; Aydin, Suphi			Can ChatGPT pass the thoracic surgery exam?	AMERICAN JOURNAL OF THE MEDICAL SCIENCES			English	Article						Artificial intelligence (AI); ChatGPT; Large language models; Medical education; Thoracic surgery		Background: The capacity of ChatGPT in academic environments and medical exams is being discovered more and more every day. In this study, we tested the success of ChatGPT on Turkish-language thoracic surgery exam questions.Methods: ChatGPT was provided with a total of 105 questions divided into seven distinct groups, each of which contained 15 questions. Along with the success of the students, the success of ChatGPT-3.5 and ChatGPT-4 architectures in answering the questions correctly was analyzed.Results: The overall mean score of students was 12.50 & PLUSMN; 1.20, corresponding to 83.33%. Moreover, ChatGPT-3.5 managed to surpass students' score of 12.5 with an average of 13.57 & PLUSMN; 0.49 questions correctly on average, while ChatGPT-4 answered 14 & PLUSMN; 0.76 questions correctly (83.3%, 90.48%, and 93.33%, respectively). Conclusions: When the results of this study and other similar studies in the literature are evaluated together, ChatGPT, which was developed for general purpose, can also produce successful results in a specific field of medicine. AI-powered applications are becoming more and more useful and valuable in providing academic knowledge.	[Gencer, Adem; Aydin, Suphi] Afyonkarahisar Hlth Sci Univ, Fac Med, Dept Thorac Surg, Zafer Saglik Kulliyesi,Dortyol Mah,2078 Sok 3 A Bl, Afyonkarahisar, Turkiye	Afyonkarahisar Health Sciences University	Gencer, A (corresponding author), Afyonkarahisar Hlth Sci Univ, Fac Med, Dept Thorac Surg, Zafer Saglik Kulliyesi,Dortyol Mah,2078 Sok 3 A Bl, Afyonkarahisar, Turkiye.	dr.ademgencer@gmail.com		Gencer, Adem/0000-0003-1305-6524				Almazyad M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38249; Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19; Antaki F, Ophthalmol Sci; Aubignat M, 2023, REV NEUROL-FRANCE, V179, P520, DOI 10.1016/j.neurol.2023.03.004; Bommarito MJ, 2022, SSRN Journal; Byrne MD, 2023, J PERIANESTH NURS, V38, P519, DOI 10.1016/j.jopan.2023.04.001; Choi JH, 2023, SSRN J; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Fuentes-Martin A, 2023, Archivos de Bronconeumologia; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haman M, 2023, RESUSCITATION, V187, DOI 10.1016/j.resuscitation.2023.109795; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Medenilla A., 2023, PLoS Digital Health, V2; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Odom-Forren J, 2023, J PERIANESTH NURS, V38, P176, DOI 10.1016/j.jopan.2023.02.006; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Qi X., 2023, AGING HLTH RES, V3, P100136, DOI [10.1016/j.ahr.2023.100136, DOI 10.1016/J.AHR.2023.100136]; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sanchez-Ramos L, 2023, Am J Obstet Gynecol; Seney V, 2023, NURS EDUC, V48, P124, DOI 10.1097/NNE.0000000000001383; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Strong E, 2023, medRxiv, DOI [10.1101/2023.03.24.23287731, 10.1101/2023.03.24.23287731, DOI 10.1101/2023.03.24.23287731]	29	5	5	11	39	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0002-9629	1538-2990		AM J MED SCI	Am. J. Med. Sci.	OCT	2023	366	4					291	295		10.1016/j.amjms.2023.08.001	http://dx.doi.org/10.1016/j.amjms.2023.08.001		AUG 2023	5	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	S2VY8	37549788				2024-07-03	WOS:001069811800001
J	de Curtò, J; de Zarzà, I; Roig, G; Calafate, CT				de Curto, J.; de Zarza, I.; Roig, Gemma; Calafate, Carlos T.			Summarization of Videos with the Signature Transform	ELECTRONICS			English	Article						video summarization; large language models; visual language models; CLIP; signature transform		This manuscript presents a new benchmark for assessing the quality of visual summaries without the need for human annotators. It is based on the Signature Transform, specifically focusing on the RMSE and the MAE Signature and Log-Signature metrics, and builds upon the assumption that uniform random sampling can offer accurate summarization capabilities. We provide a new dataset comprising videos from Youtube and their corresponding automatic audio transcriptions. Firstly, we introduce a preliminary baseline for automatic video summarization, which has at its core a Vision Transformer, an image-text model pre-trained with Contrastive Language-Image Pre-training (CLIP), as well as a module of object detection. Following that, we propose an accurate technique grounded in the harmonic components captured by the Signature Transform, which delivers compelling accuracy. The analytical measures are extensively evaluated, and we conclude that they strongly correlate with the notion of a good summary.	[de Curto, J.; de Zarza, I.] Ctr Intelligent Multidimens Data Anal, Shatin, HK Sci Pk, Hong Kong, Peoples R China; [de Curto, J.; de Zarza, I.; Calafate, Carlos T.] Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain; [de Curto, J.; de Zarza, I.; Roig, Gemma] GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany; [de Curto, J.; de Zarza, I.] Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicacio, Barcelona 08018, Spain	Universitat Politecnica de Valencia; Goethe University Frankfurt; UOC Universitat Oberta de Catalunya	de Curtò, J (corresponding author), Ctr Intelligent Multidimens Data Anal, Shatin, HK Sci Pk, Hong Kong, Peoples R China.; de Curtò, J (corresponding author), Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain.; de Curtò, J (corresponding author), GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany.; de Curtò, J (corresponding author), Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicacio, Barcelona 08018, Spain.	decurto@em.uni-frankfurt.de; dezarza@em.uni-frankfurt.de; roig@cs.uni-frankfurt.de; calafate@disca.upv.es		de Curto y Diaz, J./0000-0002-8334-4719; de Zarza i Cubero, I./0000-0002-5844-7871; Roig, Gemma/0000-0002-6439-8076	HK Innovation and Technology Commission (InnoHK Project CIMDA); Universitat Politecnica de Valencia; MCIN/AEI [PID2021-122580NB-I00]; ERDF; GOETHE-University Frankfurt am Main; DePP-Dezentrale Plannung von Platoons im Strassenguterverkehr mit Hilfe einer KI auf Basis einzelner LKW; Center for Data Science AI	HK Innovation and Technology Commission (InnoHK Project CIMDA); Universitat Politecnica de Valencia; MCIN/AEI; ERDF(European Union (EU)); GOETHE-University Frankfurt am Main; DePP-Dezentrale Plannung von Platoons im Strassenguterverkehr mit Hilfe einer KI auf Basis einzelner LKW; Center for Data Science AI	This work was supported by the HK Innovation and Technology Commission (InnoHK Project CIMDA). We acknowledge the support of Universitat Politecnica de Valencia; R&D project PID2021-122580NB-I00, funded by MCIN/AEI/10.13039/501100011033 and ERDF. We thank the following funding sources from GOETHE-University Frankfurt am Main; 'DePP-Dezentrale Plannung von Platoons im Strassenguterverkehr mit Hilfe einer KI auf Basis einzelner LKW' and 'Center for Data Science & AI'.	Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]; [Anonymous], 2003, P 9 IEEE INT C COMP; Bird S., 2009, NATURAL LANGUAGE PRO; Bonnier P, 2019, ADV NEUR IN, V32; Chevyrev I., 2016, arXiv, DOI [10.48550/ARXIV.1603.03788, DOI 10.48550/ARXIV.1603.03788]; Cui Y., 2022, P LEARN DYN CONTR C; de Curto J, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7020114; de Curtò J, 2022, SOFTW IMPACTS, V13, DOI 10.1016/j.simpa.2022.100325; de Curto J., 2022, ARXIV; de Zarz I., 2022, Int Syst Appl, V16, DOI [10.1016/j.iswa.2022.200140, DOI 10.1016/J.ISWA.2022.200140]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dwivedi K, 2022, PROC CVPR IEEE, P10266, DOI 10.1109/CVPR52688.2022.01003; Dwivedi K, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1009267; Fajtl J, 2019, LECT NOTES COMPUT SC, V11367, P39, DOI 10.1007/978-3-030-21074-8_4; de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004; Gu Xiuye, 2021, arXiv; Gygli M., 2015, P 2015 IEEE C COMP V; Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33; Thao HP, 2021, INT C PATT RECOG, P8719, DOI 10.1109/ICPR48806.2021.9412835; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang WL, 2022, Arxiv, DOI arXiv:2201.07207; Kanehira A., 2018, P 2018 IEEE C COMP; Kidger P, 2021, Arxiv, DOI arXiv:2001.00706; Liang GQ, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108840; Liao S., 2019, ARXIV; Lyons T, 2014, Arxiv, DOI arXiv:1405.4537; Mahasseni B, 2017, PROC CVPR IEEE, P2982, DOI 10.1109/CVPR.2017.318; Minderer M, 2022, Arxiv, DOI arXiv:2205.06230; Morrill J, 2021, Arxiv, DOI arXiv:2009.08295; Nair S, 2022, Arxiv, DOI arXiv:2203.12601; Narasimhan M, 2021, 35 C NEURAL INFORM P, V34; Otani M., 2019, P IEEE CVF C COMP VI; Plummer BA, 2017, PROC CVPR IEEE, P1052, DOI 10.1109/CVPR.2017.118; Radford A, 2021, PR MACH LEARN RES, V139; Rakshit Sayan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P735, DOI 10.1007/978-3-030-58574-7_44; Ramesh A, 2021, PR MACH LEARN RES, V139; Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22; Rombach R., 2022, P 2022 IEEECVF C COM; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Saharia C, 2022, Arxiv, DOI arXiv:2205.11487; Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Yuan L., 2019, P AAAI C ART INT HON; Zeng A., 2020, P C ROBOT LEARNING; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598; Zhang K, 2018, LECT NOTES COMPUT SC, V11212, P391, DOI 10.1007/978-3-030-01237-3_24; Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47; Zhao B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P863, DOI 10.1145/3123266.3123328; Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582; Zhu WC, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108312; Zhu WC, 2021, IEEE T IMAGE PROCESS, V30, P948, DOI 10.1109/TIP.2020.3039886	54	6	6	2	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	APR	2023	12	7							1735	10.3390/electronics12071735	http://dx.doi.org/10.3390/electronics12071735			19	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	D8AY1		Green Submitted, gold			2024-07-03	WOS:000970911900001
C	Li, BY			ACM	Li, Boyang			Unlocking Multimedia Capabilities of Gigantic Pretrained Language Models	PROCEEDINGS OF THE 1ST WORKSHOP ON LARGE GENERATIVE MODELS MEET MULTIMODAL APPLICATIONS, LGM3A 2023			English	Proceedings Paper	1st Workshop on Large Generative Models Meet Multimodal Applications (LGM3A)	NOV 02, 2023	Ottawa, CANADA	Assoc Comp Machinery, ACM SIGMM		multimodal learning; large language models; visual question-answering; multimodal story understanding			[Li, Boyang] Nanyang Technol Univ, Sch Comp Sci & Technol, Singapore, Singapore	Nanyang Technological University	Li, BY (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Technol, Singapore, Singapore.	boyang.li@ntu.edu.sg	Li, Boyang Albert/AAG-4957-2021; Li, Baolin/N-8884-2019	Li, Boyang Albert/0000-0002-6230-2376; Tiwari, Devesh/0000-0002-7253-2458; Li, Baolin/0000-0001-9778-1023				Chen J, 2022, PROC CVPR IEEE, P18009, DOI 10.1109/CVPR52688.2022.01750; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai Wenliang, 2023, NeurIPS; Fu CY, 2024, Arxiv, DOI arXiv:2306.13394; Guo JX, 2023, PROC CVPR IEEE, P10867, DOI 10.1109/CVPR52729.2023.01046; Kojima Takeshi, 2022, Advances in Neural Information Processing Systems; Li BH, 2023, Arxiv, DOI arXiv:2307.16125; Li YF, 2023, Arxiv, DOI arXiv:2305.10355; Ouyang L., 2022, Advances in Neural Information Processing Systems; Sanh Victor, 2022, INT C LEARNING REPRE; Sun YD, 2023, Arxiv, DOI arXiv:2203.05711; Tiong Anthony Meng Huat, 2022, C EMPIRICAL METHODS; Wei Jason, 2022, Finetuned language models are zero-shot learners; Wei Jason, 2022, ADV NEURAL INFORM PR	14	1	1	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0283-9				2023							3	4		10.1145/3607827.3616846	http://dx.doi.org/10.1145/3607827.3616846			2	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KH					2024-07-03	WOS:001150367900002
C	Li, CL; Zhu, WD; Xing, WL; Guo, R			Assoc Computing Machinery	Li, Chenglu; Zhu, Wangda; Xing, Wanli; Guo, Rui			Analyzing Student Attention and Acceptance of Conversational AI for Math Learning: Insights from a Randomized Controlled Trial	FOURTEENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, LAK 2024			English	Proceedings Paper	14th Annual International Conference on Learning Analytics and Knowledge (LAK) - Learning Analytics in the Age of Artificial Intelligence	MAR 18-22, 2024	Kyoto, JAPAN	Soc Learning Analyt Res, ACM In Cooperat, SIGWEB, SIGCHI		Technology design and development; Conversational AI; Large language models; Math learning	INSTRUCTION	The significance of nurturing a deep conceptual understanding in math learning cannot be overstated. Grounded in the pedagogical strategies of induction, concretization, and exemplification (ICE), we designed and developed a conversational AI using both ruleand generation-based techniques to facilitate math learning. Serving as a preliminary step, this study employed an experimental design involving 151 U.S.-based college students to reveal students ' attention patterns, technology acceptance model, and qualitative feedback when using the developed ConvAI. Our findings suggest that participants in the ConvAI group generally exhibit higher attention levels than those in the control group, aside from the initial stage where the control group was more attentive. Meanwhile, participants appreciated their experience with the ConvAI, particularly valuing the ICE support features. Finally, qualitative analysis of participants ' feedback was conducted to inform future refinement and to inspire educational researchers and practitioners.	[Li, Chenglu] Univ Utah, Salt Lake City, UT 84112 USA; [Zhu, Wangda; Xing, Wanli; Guo, Rui] Univ Florida, Gainesville, FL USA	Utah System of Higher Education; University of Utah; State University System of Florida; University of Florida	Li, CL (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.	chenglu.li@utah.edu; wangdazhu@ufl.edu; wanli.xing@coe.ufl.edu; rui.guo@ufl.edu		Li, Chenglu/0000-0002-1782-0457; Zhu, Wangda/0000-0001-9611-4800; Xing, Wanli/0000-0002-1446-889X	U.S. National Science Foundation [2201394]	U.S. National Science Foundation(National Science Foundation (NSF))	The research reported here was supported by U.S. National Science Foundation through Grant #2201394 to the University of Florida. The opinions expressed are those of the authors and do not represent the views of the University of Florida or those of the National Science Foundation.	Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002; Booth JL, 2013, LEARN INSTR, V25, P24, DOI 10.1016/j.learninstruc.2012.11.002; Dart S, 2020, COMPUT APPL ENG EDUC, V28, P1278, DOI 10.1002/cae.22301; Fu TC, 2022, AI OPEN, V3, P14, DOI 10.1016/j.aiopen.2022.02.001; Fyfe ER, 2018, THINK REASONING, V24, P157, DOI 10.1080/13546783.2017.1359208; Fyfe ER, 2014, EDUC PSYCHOL REV, V26, P9, DOI 10.1007/s10648-014-9249-3; Graesser AC, 2005, IEEE T EDUC, V48, P612, DOI 10.1109/TE.2005.856149; Gummer T, 2021, SOCIOL METHOD RES, V50, P238, DOI 10.1177/0049124118769083; Higgins KM, 1997, J EXP EDUC, V66, P5, DOI 10.1080/00220979709601392; Huang MH, 2003, COMPUT HUM BEHAV, V19, P425, DOI 10.1016/S0747-5632(02)00080-8; Kapur M, 2014, COGNITIVE SCI, V38, P1008, DOI 10.1111/cogs.12107; KAPUT JJ, 1989, RES AG MATH, V4, P167; Kim J., 2014, P 1 ACM C LEARN SCAL, P31, DOI [10.1145/2556325, 10.1145/2556325.2566237, DOI 10.1145/2556325.2566237]; Li CL, 2021, INT J ARTIF INTELL E, V31, P186, DOI 10.1007/s40593-020-00235-x; Li CL, 2022, BRIT J EDUC TECHNOL, V53, P776, DOI 10.1111/bjet.13227; Li Chenglu, 2023, COMP P 13 INT C LEAR, P186; Li Chenglu, International Journal of Artificial Intelligence in Education; Maharani I.P., 2018, International Electronic Journal of Mathematics Education, V13, P67, DOI 10.12973/iejme/2697; Muldner K, 2015, COMPUT HUM BEHAV, V42, P127, DOI 10.1016/j.chb.2013.10.060; Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004; Papoutsaki A, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204552; Raj NS, 2022, J COMPUT EDUC, V9, P113, DOI 10.1007/s40692-021-00199-4; Ross A, 2012, SCHOOL SCI MATH, V112, P117, DOI 10.1111/j.1949-8594.2011.00125.x; Santoso Heru Agus, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P417, DOI 10.1109/ISEMANTIC.2018.8549797; Sezer B, 2019, AUSTRALAS J EDUC TEC, V35, P15, DOI 10.14742/ajet.3959; Shi L, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P315, DOI 10.1145/3498366.3505786; Singh J. K., 2003, Artificial breeding and reproduction management in buffaloes: compendium of the lectures delivered in the Indian Council of Agricultural Research, Summer School, Central Institute for Research on Buffaloes, Sirsa Road, Hisar, Haryana, India, 10-30 June 2003, P127; Stahl E, 2009, COMPUT EDUC, V53, P1020, DOI 10.1016/j.compedu.2008.10.004; Steffan A, 2024, INFANCY, V29, P31, DOI 10.1111/infa.12564; Thorat S.A., 2020, P INT C INN COMP COM; Xing WL, 2023, COMPUT EDUC, V196, DOI 10.1016/j.compedu.2023.104726; Zhai X., 2022, CHATGPT US EXP IMPL	32	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1618-8				2024							836	842		10.1145/3636555.3636895	http://dx.doi.org/10.1145/3636555.3636895			7	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW6NI		hybrid			2024-07-03	WOS:001179044200081
J	Saetra, HS				Saetra, Henrik Skaug			Generative AI: Here to stay, but for good?	TECHNOLOGY IN SOCIETY			English	Article						Generative AI; Large language models; Generative adversarial networks; Harms; Power; Inequality		Generative AI has taken the world by storm, kicked off for real by ChatGPT and quickly followed by further development and the release of GPT-4 and similar models from OpenAI's competitors. The street has most certainly found its use for generative artificial intelligence (AI), and there is no longer much point in discussing whether generative AI will be influential. It will, and what remains to be discussed it how influential it will be, and what potential harms arise when we use AI to generate text and other forms of content. Technological change entails societal change, and we must always endeavor to ask how new technologies shapes, engenders, or potentially erodes the "good society". In this sense, Generative AI is another instance of politically and culturally disruptive autonomous technology, and in this short commentary I highlight some of the key questions to be asked regarding consequences on the micro, meso, and macro level.	[Saetra, Henrik Skaug] Ostfold Univ Coll, Halden, Norway	Ostfold University College	Saetra, HS (corresponding author), Ostfold Univ Coll, Halden, Norway.	Henrik.satra@hiof.no		Saetra, Henrik Skaug/0000-0002-7558-6451				Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Barley S.R., 2020, Work and Technological Change; Bass Dina, 2023, Bloomberg; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brevini B., 2021, POLITY; Brey P, 2018, TECHNOL SOC, V52, P39, DOI 10.1016/j.techsoc.2017.02.002; Brown L., 2022, Vulture; Collingridge D., 1980, The social control of technology; Danaher J, 2022, ETHICS INF TECHNOL, V24, DOI 10.1007/s10676-022-09661-y; Edwards B., 2022, ARS TECHNICA; Ellul J., 1964, The Technological Society, P229; Engström E, 2020, TECHNOL SOC, V63, DOI 10.1016/j.techsoc.2020.101396; Fish S, 2023, Arxiv, DOI arXiv:2309.01291; Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068; Griffy-Brown C, 2018, TECHNOL SOC, V52, P1, DOI 10.1016/j.techsoc.2018.01.001; Koster R, 2022, NAT HUM BEHAV, V6, P1398, DOI 10.1038/s41562-022-01383-x; Marcus G., 2022, Wired; Nass A., 1999, Samfunn Okologi, Livsstil, V1971; Ngo R, 2022, Arxiv, DOI arXiv:2209.00626; Nordrum E.I., 2023, Technology and Sustainable Development, P97; Sætra HS, 2022, NAT MACH INTELL, V4, P804, DOI 10.1038/s42256-022-00537-w; Sætra HS, 2022, TECHNOL SOC, V69, DOI 10.1016/j.techsoc.2022.101973; Sætra HS, 2019, HUMAN ARENAS, V2, P60, DOI 10.1007/s42087-018-0039-1; Saetra HS, 2020, J FUTURE ROBOT LIFE, V2020, P1, DOI [10.3233/FRL-200023, DOI 10.3233/FRL-200023]; UNITEDNATIONS, 2015, Transforming Our World: The 2030 Agenda for Sustainable Development New York; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Widder D.G., 2023, Concentrated Power, and the Political Economy of Open AI; Winner Langdon, 1977, Autonomous Technology: Technics-Out-of-Control as a Theme in Political Thought	28	25	25	137	209	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0160-791X	1879-3274		TECHNOL SOC	Technol. Soc.	NOV	2023	75								102372	10.1016/j.techsoc.2023.102372	http://dx.doi.org/10.1016/j.techsoc.2023.102372		SEP 2023	5	Social Issues; Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI)	Social Issues; Social Sciences - Other Topics	T5PG5		Green Published, hybrid			2024-07-03	WOS:001078500600001
J	Vinny, PW				Vinny, Pulikottil Wilson			Invoking AI for diagnosis: Art at the cutting edge of science	JOURNAL OF THE NEUROLOGICAL SCIENCES			English	Editorial Material						Artificial intelligence; GPT-4; Diagnosis; Neurology; Training; Large Language Model (LLM)			[Vinny, Pulikottil Wilson] Armed Forces Med Coll, Pune 411040, India; [Vinny, Pulikottil Wilson] Armed Forces Med Coll, Dept Internal Med, Pune 411040, Maharashtra, India	Armed Forces Medical College; Armed Forces Medical College	Vinny, PW (corresponding author), Armed Forces Med Coll, Dept Internal Med, Pune 411040, Maharashtra, India.	vinnywilson@gmail.com						Czap AL, 2022, STROKE, V53, P1651, DOI 10.1161/STROKEAHA.121.036091; Galetta K., 2023, J. Neurol. Sci; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Milea D, 2020, NEW ENGL J MED, V382, P1687, DOI 10.1056/NEJMoa1917130; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Schorr EM, 2021, NEUROLOGY, V96, pE1804, DOI 10.1212/WNL.0000000000011232; Vinny P W, 2021, Med J Armed Forces India, V77, P276, DOI 10.1016/j.mjafi.2021.06.003; Vinny PW, 2021, ANN INDIAN ACAD NEUR, V24, P481, DOI 10.4103/aian.AIAN_1120_20	9	1	1	7	11	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0022-510X	1878-5883		J NEUROL SCI	J. Neurol. Sci.	OCT 15	2023	453								120803	10.1016/j.jns.2023.120803	http://dx.doi.org/10.1016/j.jns.2023.120803		SEP 2023	2	Clinical Neurology; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	U4WM0	37742349				2024-07-03	WOS:001084818600001
J	Liu, JL; Wang, CY; Liu, SR				Liu, Jialin; Wang, Changyu; Liu, Siru			Utility of ChatGPT in Clinical Practice	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						ChatGPT; artificial intelligence; large language models; clinical practice; large language model; natural language processing; NLP; doctor-patient; patient-physician; communication; challenges; barriers; recommendations; guidance; guidelines; best practices; risks		ChatGPT is receiving increasing attention and has a variety of application scenarios in clinical practice. In clinical decision support, ChatGPT has been used to generate accurate differential diagnosis lists, support clinical decision-making, optimize clinical decision support, and provide insights for cancer screening decisions. In addition, ChatGPT has been used for intelligent question-answering to provide reliable information about diseases and medical queries. In terms of medical documentation, ChatGPT has proven effective in generating patient clinical letters, radiology reports, medical notes, and discharge summaries, improving efficiency and accuracy for health care providers. Future research directions include real-time monitoring and predictive analytics, precision medicine and personalized treatment, the role of ChatGPT in telemedicine and remote health care, and integration with existing health care systems. Overall, ChatGPT is a valuable tool that complements the expertise of health care providers and improves clinical decision-making and patient care. However, ChatGPT is a double-edged sword. We need to carefully consider and study the benefits and potential dangers of ChatGPT. In this viewpoint, we discuss recent advances in ChatGPT research in clinical practice and suggest possible risks and challenges of using ChatGPT in clinical practice. It will help guide and support future artificial intelligence research similar to ChatGPT in health.	[Liu, Jialin; Wang, Changyu] Sichuan Univ, West China Hosp, Informat Ctr, Chengdu, Peoples R China; [Liu, Jialin] West China Med Sch, Dept Med Informat, Chengdu, Peoples R China; [Liu, Jialin] Sichuan Univ, West China Hosp, Dept Otolaryngol Head & Neck Surg, Chengdu, Peoples R China; [Wang, Changyu] Sichuan Univ, West China Coll Stomatol, Chengdu, Peoples R China; [Liu, Siru] Vanderbilt Univ, Dept Biomed Informat, Med Ctr, 2525 West End Ave 1475, Nashville, TN 37212 USA	Sichuan University; Sichuan University; Sichuan University; Vanderbilt University	Liu, SR (corresponding author), Vanderbilt Univ, Dept Biomed Informat, Med Ctr, 2525 West End Ave 1475, Nashville, TN 37212 USA.	siru.liu@vumc.org	Li, Zexi/KFA-6939-2024; liu, zhao/KGM-5884-2024; LIU, JIALIN/JXN-8034-2024; zhang, zhang/KBQ-9978-2024; Wang, Jiawei/KHC-8971-2024; Liu, Siru/AAM-8737-2021; li, tong/JYO-7530-2024; YANG, DAN/KCL-5217-2024; Yang, YiChen/KEI-0140-2024; Zhang, Yulin/KEI-1610-2024; Wang, Fei/KEH-6292-2024	Liu, Siru/0000-0002-5003-5354; Wang, Changyu/0000-0003-4548-331X				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhattacharya K, 2023, INDIAN J SURG, V85, P1346, DOI 10.1007/s12262-023-03727-x; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chintagunta B., 2021, P 2 WORKSHOP NATURAL, P66; Filiberto AC, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.784495; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Introducing ChatGPT, 2022, OpenAI.; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jialin L, 2019, ESSENTIAL CLIN INFOR; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Joshi A, 2020, Arxiv, DOI arXiv:2009.08666; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Madadin M, 2019, J FORENSIC LEG MED, V68, DOI 10.1016/j.jflm.2019.101864; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Rababa'h Abeer M, 2022, Int J Crit Illn Inj Sci, V12, P106, DOI 10.4103/ijciis.ijciis_72_21; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sakib MSI, 2023, WHAT IS CHATGPT; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	25	72	73	109	195	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JUN 28	2023	25								e48568	10.2196/48568	http://dx.doi.org/10.2196/48568			7	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	O7PN8	37379067	gold, Green Published			2024-07-03	WOS:001045687800005
J	Ooi, KB; Tan, GWH; Al-Emran, M; Al-Sharafi, MA; Capatina, A; Chakraborty, A; Dwivedi, YK; Huang, TL; Kar, AK; Lee, VH; Loh, XM; Micu, A; Mikalef, P; Mogaji, E; Pandey, N; Raman, R; Rana, NP; Sarker, P; Sharma, A; Teng, C; Wamba, SF; Wong, LW				Ooi, Keng-Boon; Tan, Garry Wei-Han; Al-Emran, Mostafa; Al-Sharafi, Mohammed A.; Capatina, Alexandru; Chakraborty, Amrita; Dwivedi, Yogesh K.; Huang, Tzu-Ling; Kar, Arpan Kumar; Lee, Voon-Hsien; Loh, Xiu-Ming; Micu, Adrian; Mikalef, Patrick; Mogaji, Emmanuel; Pandey, Neeraj; Raman, Ramakrishnan; Rana, Nripendra P.; Sarker, Prianka; Sharma, Anshuman; Teng, Ching-, I; Wamba, Samuel Fosso; Wong, Lai-Wan			The Potential of Generative Artificial Intelligence Across Disciplines: Perspectives and Future Directions	JOURNAL OF COMPUTER INFORMATION SYSTEMS			English	Article; Early Access						Generative artificial intelligence; machine learning; large language model; ChatGPT; Bard	MANAGEMENT	In a short span of time since its introduction, generative artificial intelligence (AI) has garnered much interest at both personal and organizational levels. This is because of its potential to cause drastic and widespread shifts in many aspects of life that are comparable to those of the Internet and smartphones. More specifically, generative AI utilizes machine learning, neural networks, and other techniques to generate new content (e.g. text, images, music) by analyzing patterns and information from the training data. This has enabled generative AI to have a wide range of applications, from creating personalized content to improving business operations. Despite its many benefits, there are also significant concerns about the negative implications of generative AI. In view of this, the current article brings together experts in a variety of fields to expound and provide multi-disciplinary insights on the opportunities, challenges, and research agendas of generative AI in specific industries (i.e. marketing, healthcare, human resource, education, banking, retailing, the workplace, manufacturing, and sustainable IT management).	[Ooi, Keng-Boon; Tan, Garry Wei-Han] UCSI Univ, UCSI Grad Business Sch, Kuala Lumpur, Malaysia; [Ooi, Keng-Boon] FORE Sch Management, New Delhi, India; [Ooi, Keng-Boon; Tan, Garry Wei-Han] Swinburne Univ Technol, Fac Business Design & Arts, Sarawak Campus, Kuching, Malaysia; [Tan, Garry Wei-Han] Adamson Univ, Coll Business Adm, Manila, Philippines; [Al-Emran, Mostafa] British Univ Dubai, Fac Engn & IT, Dubai, U Arab Emirates; [Al-Emran, Mostafa] Dijlah Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq; [Al-Sharafi, Mohammed A.] Univ Tenaga Nas, Inst Informat & Comp Energy, Kajang, Selangor, Malaysia; [Capatina, Alexandru; Micu, Adrian] Dunarea de Jos Univ Galati, Dept Business Adm, Galati, Romania; [Chakraborty, Amrita] Tech Talk, New Delhi, India; [Dwivedi, Yogesh K.] Swansea Univ Bay Campus, Sch Management, Digital Futures Sustainable Business & Soc Res Gr, Swansea, Wales; [Dwivedi, Yogesh K.; Raman, Ramakrishnan] Symbiosis Int, Dept Management, Pune, India; [Huang, Tzu-Ling] Natl Cent Univ, Dept Informat Management, Taoyuan, Taiwan; [Kar, Arpan Kumar] Indian Inst Technol Delhi, Dept Management Studies, New Delhi, India; [Lee, Voon-Hsien; Loh, Xiu-Ming] Univ Tunku Abdul Rahman, Fac Business & Finance, Kampar, Malaysia; [Mikalef, Patrick] Norwegian Univ Sci & Technol, Fac Informat Technol & Elect Engn, Trondheim, Norway; [Mikalef, Patrick] SINTEF Digital, Dept Technol Management, Trondheim, Norway; [Mogaji, Emmanuel] Keele Univ, Keele Business Sch, Keele, England; [Pandey, Neeraj] Indian Inst Management Mumbai, Mumbai, India; [Rana, Nripendra P.] Qatar Univ, Coll Business & Econ, Doha, Qatar; [Sarker, Prianka] Manchester Metropolitan Univ, Business Sch, Manchester, England; [Sharma, Anshuman] Ajman Univ, Coll Business Adm, Dept Mkt, Ajman, U Arab Emirates; [Teng, Ching-, I] Chang Gung Univ, Grad Inst Management, Taoyuan, Taiwan; [Wamba, Samuel Fosso] TBS Business Sch, Informat Operat & Management Sci, Toulouse, France; [Wong, Lai-Wan] Xiamen Univ Malaysia, Sch Elect & Comp Engn, Sepang, Malaysia; [Ooi, Keng-Boon] UCSI Univ, UCSI Grad Business Sch, 1 Jalan Menara Gading,UCSI Hts, Kuala Lumpur 56000, Malaysia	UCSI University; FORE School of Management; Swinburne University of Technology; Swinburne University of Technology Sarawak; Adamson University; Dijlah University College; Universiti Tenaga Nasional; Dunarea De Jos University Galati; Symbiosis International University; National Central University; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; Universiti Tunku Abdul Rahman (UTAR); Norwegian University of Science & Technology (NTNU); SINTEF; Keele University; Qatar University; Manchester Metropolitan University; Ajman University; Chang Gung University; Xiamen University Malaysia Campus; UCSI University	Ooi, KB (corresponding author), UCSI Univ, UCSI Grad Business Sch, 1 Jalan Menara Gading,UCSI Hts, Kuala Lumpur 56000, Malaysia.	ooikengboon@gmail.com	OOI, Keng-Boon/I-4143-2019; Mikalef, Patrick/GVU-5020-2022; Pandey, Neeraj/D-1968-2013; Micu, Adrian/AAJ-9641-2020; sarker, prianka/KBA-0097-2024; Fosso Wamba, Samuel/AAB-4953-2019; Lee, Voon-Hsien/S-6123-2017; WONG, LaiWan/AAV-8498-2020; Tan Wei Han, Garry/C-6565-2011; Mogaji, Emmanuel/B-8900-2014; Ming, Loh Xiu/AAD-6957-2021; Dwivedi, Yogesh Kumar/A-5362-2008; Al-Sharafi, Mohammed A./E-1530-2017; Kar, Arpan Kumar/B-9999-2009	OOI, Keng-Boon/0000-0002-3384-1207; Mikalef, Patrick/0000-0002-6788-2277; Pandey, Neeraj/0000-0002-6238-6397; sarker, prianka/0000-0002-5768-6635; Fosso Wamba, Samuel/0000-0002-1073-058X; WONG, LaiWan/0000-0003-1961-8452; Tan Wei Han, Garry/0000-0003-2974-2270; Mogaji, Emmanuel/0000-0003-0544-4842; Ming, Loh Xiu/0000-0003-0649-9183; Dwivedi, Yogesh Kumar/0000-0002-5547-9990; Al-Sharafi, Mohammed A./0000-0003-0726-6031; Kar, Arpan Kumar/0000-0003-4186-4887; Micu, Adrian/0000-0003-3161-5748				Abdulquadri A, 2021, J ENTERP COMMUNITIES, V15, P258, DOI 10.1108/JEC-06-2020-0126; Akter S, 2022, J BUS RES, V144, P201, DOI 10.1016/j.jbusres.2022.01.083; Al-Emran M, 2023, IEEE T ENG MANAGE, DOI 10.1109/TEM.2023.3237789; [Anonymous], 2023, Reuters; [Anonymous], 2023, The Guardian15 Feb; [Anonymous], 2023, Bloomberg; Baduge SK, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104440; Bing Team, 2023, NEW BING EDG INCR LI; Bogue R, 2019, IND ROBOT, V46, P461, DOI 10.1108/IR-03-2019-0053; Borden B., 2023, ERA GENERATIVE DRIVI; Boston Consulting Group, 2023, GEN AI; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P1, DOI [DOI 10.5281/ZENODO.7755273, 10.5281/zenodo.7755273]; Buhalis D, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102253; Cao LL, 2021, INT J RETAIL DISTRIB, V49, P958, DOI 10.1108/IJRDM-09-2020-0350; Chakraborty A, 2021, INT J INF LEARN TECH, V38, P273, DOI 10.1108/IJILT-06-2020-0125; Chawla Y, 2022, DIGIT POLICY REGUL G, V24, P17, DOI 10.1108/DPRG-05-2021-0062; Chen XL, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103113; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Chi OH, 2023, INT J INFORM MANAGE, V70, DOI 10.1016/j.ijinfomgt.2023.102623; Chiu YT, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102379; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cukka P., 2023, GENERATIVE MISSING P; Czarnecka B, 2020, INT J BANK MARK, V38, P756, DOI 10.1108/IJBM-07-2019-0249; Deloitte, 2018, DEL SKILLS GAP FUT W; Denodo, 2019, DAT LANDSC IS FRAGM; Dickson B., 2020, COULD SAVE WORLD IT; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dwivedi YK, 2023, PSYCHOL MARKET, V40, P750, DOI 10.1002/mar.21767; Dwivedi YK, 2022, INT J INFORM MANAGE, V66, DOI 10.1016/j.ijinfomgt.2022.102542; Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002; Edelman DC., 2023, GENERATIVE WILL CHAN; Edwards B., 2023, GPT 4 WILL HUNT TREN; El Hana N, 2023, TECHNOL FORECAST SOC, V188, DOI 10.1016/j.techfore.2022.122297; Elegant NX, 2019, INTERNET CLOUD HAS D; Enberg J., 2023, CHATGPT GENERATIVE C; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fügener A, 2021, MIS QUART, V45, P1527, DOI 10.25300/MISQ/2021/16553; Füller J, 2022, TECHNOL FORECAST SOC, V178, DOI 10.1016/j.techfore.2022.121598; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Garg S, 2022, INT J PRODUCT PERFOR, V71, P1590, DOI 10.1108/IJPPM-08-2020-0427; Goldman Sachs, 2023, GEN COULD RAIS GLOB; Guha A, 2021, J RETAILING, V97, P28, DOI 10.1016/j.jretai.2021.01.005; Gurman M., 2023, SAMSUNG BANS STAFFS; Gursoy D, 2019, INT J INFORM MANAGE, V49, P157, DOI 10.1016/j.ijinfomgt.2019.03.008; Hatzius J., 2023, POTENTIALLY LARGE EF; Heins C, 2023, FORESIGHT, V25, P264, DOI 10.1108/FS-10-2021-0210; Herm LV, 2023, INF SYST E-BUS MANAG, V21, P1, DOI 10.1007/s10257-022-00553-8; Hu K., 2023, Reuters; Huang SS, 2021, J FINANC REGUL COMPL, V29, P336, DOI 10.1108/JFRC-06-2020-0062; Isabel, 2023, DRAGGAN AI POW IM ED; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Jeon J, 2023, EDUC INF TECHNOL, V28, P11963, DOI 10.1007/s10639-023-11656-1; Jesuthasan R., 2023, NAVIGATING IMPACT GE; Jussupow E, 2021, INFORM SYST RES, V32, P713, DOI 10.1287/isre.2020.0980; Kalwar, 2023, THINGS YOU NEED KNOW; Kamoonpuri SZ, 2023, J RETAIL CONSUM SERV, V72, DOI 10.1016/j.jretconser.2023.103258; Kar Sudatta, 2021, IEEE Engineering Management Review, V49, P76, DOI 10.1109/EMR.2021.3107344; Kar S, 2021, IEEE ACCESS, V9, P30017, DOI 10.1109/ACCESS.2021.3059407; Kaur J., 2023, GENERATIVE AI TELECO; Kelly C., 2023, COKE ASKS CONSUMERS; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kokemuller N., 2023, DIFFERENCES FRONT EN; Korzynski P, 2023, CENT EUR MANAG J, V31, P3, DOI 10.1108/CEMJ-02-2023-0091; Kumar P, 2023, INT J INFORM MANAGE, V69, DOI 10.1016/j.ijinfomgt.2022.102598; Kumar P, 2023, INFORM SYST FRONT, V25, P2197, DOI [10.1109/TNSE.2021.3089435, 10.1007/s10796-021-10136-6]; Kumar S., 2021, INT J INFORM MANAGE, V1, P100008, DOI DOI 10.1016/J.JJIMEI.2021.100008; Lancaster A., 2023, CHATBOTS RISE LARGE; Langer M, 2021, COMPUT HUM BEHAV, V123, DOI 10.1016/j.chb.2021.106878; Larsen B., 2023, GENERATIVE GAME CHAN; Lee JC, 2022, INT J BANK MARK, V40, P631, DOI 10.1108/IJBM-08-2021-0394; Levy A., 2023, 2 CO ARE USING GENER; Leyer M, 2021, BUS HORIZONS, V64, P711, DOI 10.1016/j.bushor.2021.02.026; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Liu KF, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107026; Loh XM, 2022, IND MANAGE DATA SYST, V122, P1645, DOI 10.1108/IMDS-09-2021-0558; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Mahmoud A B., 2020, Retail Futures, P165, DOI DOI 10.1108/978-1-83867-663-620201019; Mamaghani M., 2021, DETECTING FINANCIAL; Manyika J., 2018, AI AUTOMATION FUTURE; Mauran C., 2023, BING CHATBOT NOW LET; McGee-Smith S., 2023, SALESFORCES EINSTEIN; Mehdi Y., 2023, REINVENTING SEARCH N; Mello G., 2023, WALL STREET BANKS AR; Mikalef P, 2022, EUR J INFORM SYST, V31, P257, DOI 10.1080/0960085X.2022.2026621; Mogaji E, 2022, INT J BANK MARK, V40, P1272, DOI 10.1108/IJBM-09-2021-0440; Mogaji E, 2021, TELEMAT INFORM, V65, DOI 10.1016/j.tele.2021.101711; Mogaji E, 2021, AUSTRALAS MARK J, V29, P235, DOI 10.1016/j.ausmj.2020.05.003; Morgan B., 2019, 50 STATS PROVE VALUE; Morgan Blake., 2019, The 20 Best Examples Of Using Artificial Intelligence For Retail Experiences; Morra J., 2023, SYSTEM LEVEL PCB DES; Mukherjee S., 2023, EU PROPOSES NEW COPY; Nanath K., 2023, INT J INF MANAG DATA, V3, P100167, DOI [10.1016/j.jjimei.2023.100167, DOI 10.1016/J.JJIMEI.2023.100167]; Neto JAR, 2023, CHATGTP GENERATIVE H; Nicholls J, 2021, IEEE ACCESS, V9, P163965, DOI 10.1109/ACCESS.2021.3134076; Niet I, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.690237; Nishant R, 2020, INT J INFORM MANAGE, V53, DOI 10.1016/j.ijinfomgt.2020.102104; Oosthuizen K, 2021, AUSTRALAS MARK J, V29, P264, DOI 10.1016/j.ausmj.2020.07.007; OpenAI, 2023, GPT-4 Technical Report; Pandey N, 2020, J STRATEG MARK, V28, P522, DOI 10.1080/0965254X.2019.1569109; Papagiannidis E, 2023, INFORM SYST FRONT, V25, P123, DOI 10.1007/s10796-022-10251-y; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Pichai S., 2023, IMPORTANT NEXT STEP; Piktus A, 2023, NATURE, V618, P465, DOI 10.1038/d41586-023-01411-4; Qadir Junaid, 2023, 2023 IEEE Global Engineering Education Conference (EDUCON), P1, DOI 10.1109/EDUCON54358.2023.10125121; Qin X, 2022, COMPUT HUM BEHAV, V127, DOI 10.1016/j.chb.2021.107041; Raisch S, 2021, ACAD MANAGE REV, V46, P192, DOI 10.5465/amr.2018.0072; Ramasundaram A, 2023, INT J INFORM MANAGE, V69, DOI 10.1016/j.ijinfomgt.2022.102599; Rathore AK, 2017, DECIS ANAL, V14, P229, DOI 10.1287/deca.2017.0355; Reddington C., 2023, CO ARE BOOSTING PROD; Salesforce, 2023, SAL ANN EINST GPT WO; Schwartz EH., 2023, DUOLINGO OPENAI WILL; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Siggelkow N., 2023, CREATE WINNING CUSTO; Singh M, 2020, INT J CLOTH SCI TECH, V32, P177, DOI 10.1108/IJCST-12-2018-0148; Sinha P., 2023, GENERATIVE WILL CHAN; Soetan TO, 2021, J SERV MARK, V35, P947, DOI 10.1108/JSM-07-2020-0280; Sohn K, 2021, INT J RETAIL DISTRIB, V49, P61, DOI 10.1108/IJRDM-03-2020-0091; Srinivasan R, 2021, COMMUN ACM, V64, P44, DOI 10.1145/3464903; Stone M., 2023, SHOPIFY JUST MADE IT; Su JH, 2023, ECNU REV EDUC, V6, P355, DOI 10.1177/20965311231168423; Suen HY, 2023, COMPUT HUM BEHAV, V143, DOI 10.1016/j.chb.2023.107713; Syam N, 2018, IND MARKET MANAG, V69, P135, DOI 10.1016/j.indmarman.2017.12.019; Tambe P, 2019, CALIF MANAGE REV, V61, P15, DOI 10.1177/0008125619867910; Tellez A., 2023, THESE MAJOR CO SNAP; Thormundsson B., 2023, GENERATIVE ARTIFICIA; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Toribio A., 2023, GOOGLE INCORPORATES; Trocin C, 2023, INFORM SYST FRONT, V25, P2139, DOI 10.1007/s10796-021-10146-4; Tschang FT, 2021, ACAD MANAGE PERSPECT, V35, P642, DOI 10.5465/amp.2019.0062; Tutun S, 2023, INFORM SYST FRONT, V25, P1261, DOI 10.1007/s10796-022-10282-5; Van Wynsberghe A., 2021, ETHICS, V1, P213, DOI [10.1007/s43681-021-00043-6, DOI 10.1007/S43681-021-00043-6]; Vlahou A, 2021, HYPERTENSION, V77, P1029, DOI 10.1161/HYPERTENSIONAHA.120.16340; Votto A.M., 2021, INT J INFORM MANAGE, V1, DOI DOI 10.1016/J.JJIMEI.2021.100047; Weber FD, 2019, DIGIT POLICY REGUL G, V21, P264, DOI 10.1108/DPRG-09-2018-0050; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Wei YH, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102838; Weightman G., 2015, HIST BAR CODE; Wertz J., 2022, DIGITIZATION IS IMPA; Whitmore G., 2023, EXPEDIA APP INTEGRAT; Wong LW, 2023, IEEE T ENG MANAGE, V70, P67, DOI 10.1109/TEM.2021.3053359; Yi-no kang Enoch, 2023, Computers in Human Behavior, DOI 10.1016/j.chb.2022.107529; Yusuf K., 2023, INTRO WATSONX FUTURE; Zao-Sanders M., 2023, FRAMEWORK PICKING RI	146	25	25	184	275	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0887-4417	2380-2057		J COMPUT INFORM SYST	J. Comput. Inf. Syst.	2023 OCT 5	2023										10.1080/08874417.2023.2261010	http://dx.doi.org/10.1080/08874417.2023.2261010		OCT 2023	32	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	T8CC2					2024-07-03	WOS:001080196300001
C	Chen, HY			IEEE	Chen, Huan-Yuan			Generative AI Frameworks for Web for Good: Food Pantry Information Seeking as An Example	2023 IEEE INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT			English	Proceedings Paper	22nd IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	OCT 26-29, 2023	Venice, ITALY	Inst Elect & Elect Engineers, IEEE Comp Soc, Web Intelligence Consortium, Ca Foscari Univ Venice, IOS Press		generative framework; information seeking; large language model; web for good	INSECURITY	This paper introduces two generative AI frameworks, ISum and IConvo, for information seeking on the web. ISum, an intent-based web page summarizer, consists of five major components, including website selection, web page selection, web page segmentation, chunk selection and summary generation. Its application to social good on food pantry is demonstrated. Structure-aware segmentation identifies chunks based on HTML structure to preserve semantics. Chunk classification selects those chunks relevant to a specific intent for the later summary generation by InstructGPT. Besides ISum, this paper also presents a conversational agent IConvo. IConvo accepts user's question and reports the answer if the question is answerable based on the current context. If it is unanswerable, follow-up questions will be generated to acquire more information from information source including human and the web. The conversation is iterated and context is updated until information is sought.	[Chen, Huan-Yuan] Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Chen, HY (corresponding author), Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA.	huanyuanchen@umass.edu						Bazerghi C, 2016, J COMMUN HEALTH, V41, P732, DOI 10.1007/s10900-015-0147-5; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen H. Y., 2023, P ACM WEB C, P4129, DOI [10.1145/3543507.3583880, DOI 10.1145/3543507.3583880]; Chen HY, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P310, DOI 10.1145/3543873.3587372; Deng X., 2022, CoRR; Fang D, 2021, BMC PUBLIC HEALTH, V21, DOI 10.1186/s12889-021-10631-0; Guo Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1502, DOI 10.1145/3477495.3532086; Kamdar NP, 2021, SOC PSYCH PSYCH EPID, V56, P2175, DOI 10.1007/s00127-021-02071-3; Kojima T., CoRR; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng B., 2023, CoRR; Pereira M, 2020, PUBLIC HEALTH NUTR, V23, P3236, DOI [10.1017/S1368980020003493[Opensinanewwindow], 10.1017/S1368980020003493]; Wei Jason, 2022, CoRR, abs/2201.11903.; Zhou D., CoRR	15	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0918-8				2023							351	356		10.1109/WI-IAT59888.2023.00057	http://dx.doi.org/10.1109/WI-IAT59888.2023.00057			6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3LB					2024-07-03	WOS:001139644800050
J	Waisberg, E; Ong, J; Masalkhi, M; Lee, AG				Waisberg, Ethan; Ong, Joshua; Masalkhi, Mouayad; Lee, Andrew G.			OpenAI's Sora in medicine: revolutionary advances in generative artificial intelligence for healthcare	IRISH JOURNAL OF MEDICAL SCIENCE			English	Letter; Early Access						Artificial video generation; Generative AI; Large language models; LLM; NLP			[Waisberg, Ethan] Univ Cambridge, Dept Ophthalmol, Cambridge, England; [Ong, Joshua] Univ Michigan, Kellogg Eye Ctr, Dept Ophthalmol & Visual Sci, Ann Arbor, MI USA; [Masalkhi, Mouayad] Baylor Coll Med, Ctr Space Med, Houston, TX USA; [Lee, Andrew G.] Houston Methodist Hosp, Blanton Eye Inst, Dept Ophthalmol, Houston, TX USA; [Lee, Andrew G.] Houston Methodist Hosp, Houston Methodist Res Inst, Houston, TX USA; [Lee, Andrew G.] Weill Cornell Med, Dept Ophthalmol, New York, NY USA; [Lee, Andrew G.] Weill Cornell Med, Dept Neurol, New York, NY USA; [Lee, Andrew G.] Weill Cornell Med, Dept Neurosurg, New York, NY USA; [Lee, Andrew G.] Univ Texas Med Branch, Dept Ophthalmol, Galveston, TX USA; [Lee, Andrew G.] Univ Texas MD Anderson Canc Ctr, Houston, TX USA; [Lee, Andrew G.] Texas A&M Coll Med, Bryan, TX USA; [Lee, Andrew G.] Univ Iowa Hosp & Clin, Dept Ophthalmol, Iowa City, IA USA	University of Cambridge; University of Michigan System; University of Michigan; Baylor College of Medicine; Houston Methodist Hospital; The Methodist Hospital - Houston; Houston Methodist Hospital; The Methodist Hospital - Houston; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; University of Texas System; University of Texas Medical Branch Galveston; University of Texas System; UTMD Anderson Cancer Center; Texas A&M University System; Texas A&M University College Station; Texas A&M Health Science Center; University of Iowa	Waisberg, E (corresponding author), Univ Cambridge, Dept Ophthalmol, Cambridge, England.	ew690@cam.ac.uk		Waisberg, Ethan/0000-0001-8999-0212				Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; Bucklin BA, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-020-02447-0; Li HOY, 2020, BMJ GLOB HEALTH, V5, DOI 10.1136/bmjgh-2020-002604; Masalkhi M., 2024, AME SURG J, V4, P2, DOI [10.21037/asj-23-47, DOI 10.21037/ASJ-23-47]; Masalkhi M, 2024, EYE, DOI 10.1038/s41433-024-02958-w; openai, Sora: creating video from text; Paladugu PS, 2023, ANN BIOMED ENG, V51, P2130, DOI 10.1007/s10439-023-03304-z; Shah RF, 2017, PULM PHARMACOL THER, V46, P16, DOI 10.1016/j.pupt.2017.08.005; Waisberg E., 2023, J. Med. Artif. Intell, V6, P29, DOI DOI 10.21037/JMAI-23-94; Waisberg E., 2023, Pan Am J Ophthalmol, V5, P46, DOI DOI 10.4103/PAJO.PAJO_62_23; Waisberg E, 2024, EYE, V38, P642, DOI 10.1038/s41433-023-02760-0; Waisberg E, 2024, EYE, V38, P639, DOI 10.1038/s41433-023-02759-7	12	0	0	15	15	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0021-1265	1863-4362		IRISH J MED SCI	Irish J. Med. Sci.	2024 APR 4	2024										10.1007/s11845-024-03680-y	http://dx.doi.org/10.1007/s11845-024-03680-y		APR 2024	3	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	MV2X2	38570404				2024-07-03	WOS:001196356600001
J	Zhang, SY; Liau, ZQG; Tan, KLM; Chua, WL				Zhang, Siyuan; Liau, Zi Qiang Glen; Tan, Kian Loong Melvin; Chua, Wei Liang			Evaluating the accuracy and relevance of ChatGPT responses to frequently asked questions regarding total knee replacement	KNEE SURGERY & RELATED RESEARCH			English	Article						ChatGPT; Artificial intelligence; Chatbot; Large language model; Total knee replacement; Total knee arthroplasty	ARTHROPLASTY	Background Chat Generative Pretrained Transformer (ChatGPT), a generative artificial intelligence chatbot, may have broad applications in healthcare delivery and patient education due to its ability to provide human-like responses to a wide range of patient queries. However, there is limited evidence regarding its ability to provide reliable and useful information on orthopaedic procedures. This study seeks to evaluate the accuracy and relevance of responses provided by ChatGPT to frequently asked questions (FAQs) regarding total knee replacement (TKR).Methods A list of 50 clinically-relevant FAQs regarding TKR was collated. Each question was individually entered as a prompt to ChatGPT (version 3.5), and the first response generated was recorded. Responses were then reviewed by two independent orthopaedic surgeons and graded on a Likert scale for their factual accuracy and relevance. These responses were then classified into accurate versus inaccurate and relevant versus irrelevant responses using preset thresholds on the Likert scale.Results Most responses were accurate, while all responses were relevant. Of the 50 FAQs, 44/50 (88%) of ChatGPT responses were classified as accurate, achieving a mean Likert grade of 4.6/5 for factual accuracy. On the other hand, 50/50 (100%) of responses were classified as relevant, achieving a mean Likert grade of 4.9/5 for relevance.Conclusion ChatGPT performed well in providing accurate and relevant responses to FAQs regarding TKR, demonstrating great potential as a tool for patient education. However, it is not infallible and can occasionally provide inaccurate medical information. Patients and clinicians intending to utilize this technology should be mindful of its limitations and ensure adequate supervision and verification of information provided.	[Zhang, Siyuan; Liau, Zi Qiang Glen; Tan, Kian Loong Melvin; Chua, Wei Liang] Natl Univ Hlth Syst, Dept Orthopaed Surg, Level 11,NUHS Tower Block,1E Kent Ridge Rd, Singapore 119228, Singapore	National University of Singapore	Zhang, SY (corresponding author), Natl Univ Hlth Syst, Dept Orthopaed Surg, Level 11,NUHS Tower Block,1E Kent Ridge Rd, Singapore 119228, Singapore.	siyuan.zhang@mohh.com.sg						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, Search engine market share in 2023; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Budhiparama NC, 2019, J ORTHOP SURG-HONG K, V27, DOI 10.1177/2309499019844551; Canovas F, 2018, ORTHOP TRAUMATOL-SUR, V104, pS41, DOI 10.1016/j.otsr.2017.04.017; Carr DG, 2023, Google Bard Rose 187%; Cassidy JT, 2016, J BONE JOINT SURG AM, V98, P325, DOI 10.2106/JBJS.N.01189; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Duey AH, 2023, SPINE J, V23, P1684, DOI 10.1016/j.spinee.2023.07.015; Fraval A, 2012, AUSTRALAS MED J, V5, P633, DOI 10.4066/AMJ.2012.1530; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Gwet K. L., 2014, Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters, V4th; Hernigou P, 2023, INT ORTHOP, V47, P1887, DOI 10.1007/s00264-023-05887-7; Hu K., 2023, Reuters; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Kurtz S, 2007, J BONE JOINT SURG AM, V89A, P780, DOI 10.2106/JBJS.F.00222; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Makhyan L, 2023, Search Engine Journal; Mondal H, 2023, INDIAN DERMATOL ONL, V14, P482, DOI 10.4103/idoj.idoj_72_23; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; OpenAI, 2023, ChatGPT plugins; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Schachinger KA, 2017, Complete guide to the Google RankBrain; Shen TS, 2021, J ARTHROPLASTY, V36, P1224, DOI 10.1016/j.arth.2020.10.024; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Whiles BB, 2023, UROLOGY, V180, P278, DOI 10.1016/j.urology.2023.07.010; Wongpakaran N, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-61	36	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2234-2451		KNEE SURG RELAT RES	Knee Surg. Relat. Res.	APR 2	2024	36	1							15	10.1186/s43019-024-00218-5	http://dx.doi.org/10.1186/s43019-024-00218-5			8	Orthopedics; Surgery	Emerging Sources Citation Index (ESCI)	Orthopedics; Surgery	MX5Y3	38566254	gold			2024-07-03	WOS:001196960300001
J	Mitra, R; Mukhopadhyay, P				Mitra, Roshni; Mukhopadhyay, Parthasarathi			Machine Learning Applications in Digital Humanities: Designing a Semi-automated Subject Indexing System for a Low-resource Domain	DESIDOC JOURNAL OF LIBRARY & INFORMATION TECHNOLOGY			English	Article						Annif; Homosaurus; Inclusive librarianship; Large language model (OpenAI); LGBTQIA+; Machine learning; Retrieval metrics		This research study explores the potential of machine learning tools and techniques to organize knowledge objects pertaining to various aspects of the gender spectrum (LGBTQIA+) in order to address the low-resource features of the LGBTQIA+ knowledge domain in Indian libraries. It aims to develop a semi-automated subject indexing system using an open source machine learning framework (Annif) and deploying the Homosaurus, a domain-specific vocabulary system. It develops programmatically a comprehensive training dataset from open-access bibliographic data sources with the help of data carpentry tools and NLP services from OpenAI. The study also measures the efficiencies of the automated indexing framework and investigates the potential for widespread adoption of a REST/ API call-based approach for rapid indexing of a substantial number of records related to the LGBTQIA+ domain.	[Mitra, Roshni; Mukhopadhyay, Parthasarathi] Univ Kalyani, Dept Lib & Informat Sci, Nadia 741235, W Bengal, India	Kalyani University	Mitra, R (corresponding author), Univ Kalyani, Dept Lib & Informat Sci, Nadia 741235, W Bengal, India.	roshnimitrakly@gmail.com	Mukhopadhyay, PS/JCE-1562-2023					Berman S., 1993, PREJUDICES ANTIPATHI; Burdick A., 2016, Digital Humanities; Drabinski E, 2013, LIBR QUART, V83, P94, DOI 10.1086/669547; Gibson K., 2015, Digital humanities in the library: Challenges and opportunities for subject specialists, P3; Golub K, 2021, CAT CLASSIF Q, V59, P702, DOI 10.1080/01639374.2021.2012311; Hahn J, 2021, CAT CLASSIF Q, V59, P853, DOI 10.1080/01639374.2021.2014011; Kasprzik Anna, 2020, CEUR WORKSHOP PROC, V2535; Knowlton SA, 2005, CAT CLASSIF Q, V40, P123, DOI 10.1300/J104v40n02_08; Lehtinen M., 2022, Bibliographic Control in the Digital Ecosystem; Liu A, 2013, PMLA, V128, P409, DOI 10.1632/pmla.2013.128.2.409; Meikle JL, 2014, DES CULT, V6, P431, DOI 10.2752/175470814X14105156869746; Mukhopadhyay Parthasarathi, 2021, SRELS Journal of Information Management, V58, P67, DOI 10.17821/srels/2021/v58i2/159969; Mukhopadhyay P., 2022, Indian J. Information, Library & Society, V35, P16, DOI [10.5281/zenodo.6814869, DOI 10.5281/ZENODO.6814869]; Olson Hope A., 2011, The Power to Name: Locating the Limits of Subject Representation in Libraries; Schnapp J., 2009, The Digital Humanities Manifesto 2.0; Sfakakis Michalis, 2021, International Journal of Metadata, Semantics and Ontologies, P233, DOI 10.1504/IJMSO.2021.125884; Suominen Osma, 2019, LIBER Quarterly, V29, DOI 10.18352/lq.10285; Suominen O, 2022, JLIS.IT, V13, P265, DOI 10.4403/jlis.it-12740; Watson BM, 2020, CAT CLASSIF Q, V58, P547, DOI 10.1080/01639374.2020.1796876; Wu MF, 2023, DATA INTELLIGENCE, V5, P122, DOI 10.1162/dint_a_00162; Zwaaf K., 2020, Technical Services Quarterly, V37, P207	21	1	1	1	1	DEFENCE SCIENTIFIC INFORMATION DOCUMENTATION CENTRE	DELHI	METCALFE HOUSE, DELHI 110054, INDIA	0974-0643	0976-4658		DESIDOC J LIB INF TE	DESIDOC J. Lib. Inf. Technol.	JUL	2023	43	4					219	225		10.14429/djlit.43.4.19227	http://dx.doi.org/10.14429/djlit.43.4.19227			7	Information Science & Library Science	Emerging Sources Citation Index (ESCI)	Information Science & Library Science	Z0CS3					2024-07-03	WOS:001108855100005
C	Xu, TNZT; Ng, AKY			IEEE	Xu, Tina Ziting; Ng, Adolf K. Y.			GreenEdge: Neural-enhanced Green Workload Coordination for Ubiquitous Edge Intelligence	2023 IEEE 98TH VEHICULAR TECHNOLOGY CONFERENCE, VTC2023-FALL	IEEE Vehicular Technology Conference Proceedings		English	Proceedings Paper	98th IEEE Vehicular Technology Conference (VTC-Fall)	OCT 10-13, 2023	Hong Kong, HONG KONG	IEEE, IEEE VTS		Edge-cloud Networks; Green Workload Coordination; Large Language Models; Ubiquitous Edge Intelligence	FRAMEWORK; NETWORKS; SYSTEMS; DESIGN; 5G	The edge-cloud network serves as a fundamental infrastructure for deploying Ubiquitous Edge Intelligence (UEI) applications, presenting critical demands of energy conservation and job acceleration. Current solutions often rely on complete prior knowledge of static resource information, which limits their adaptation to the dynamic online environment of UEI deployment. This challenge motivates us to stand from a novel perspective by jointly considering application-level properties and energy-level requirements during UEI task runtime. Our primary objective is to optimize the coordination strategy of model partition and function assignment, which can be formulated as a green workload coordination problem. Following this target, we propose GreenEdge, an innovative framework that simultaneously improves job processing speed and energy efficiency. The key insight presented by GreenEdge is the utilization of Reinforcement Learning with Human Feedback (RLHF) methodology, which draws inspiration from the human-in-the-loop philosophy. Evaluations with real-world applications demonstrate that our GreenEdge framework exhibits remarkable superiority over previous methods, promising significant advancements in implementing efficient UEI frameworks and applications.	[Xu, Tina Ziting] Beijing Normal Univ, Fac Sci & Technol, Beijing, Peoples R China; [Ng, Adolf K. Y.] Hong Kong Baptist Univ, United Int Coll, Fac Business & Management, Zhuhai, Peoples R China	Beijing Normal University; Hong Kong Baptist University; Beijing Normal University - Hong Kong Baptist University United International College	Xu, TNZT (corresponding author), Beijing Normal Univ, Fac Sci & Technol, Beijing, Peoples R China.	xuziting@uic.edu.cn; adolfng@uic.edu.cn			BNU-HKBU United International College research funds [R72021201]	BNU-HKBU United International College research funds	This research was supported by the BNU-HKBU United International College research funds (R72021201). The authors would like to express their gratitude to Prof. Hui Zhang for her invaluable contributions in improving the manuscript quality.	Alazab M, 2022, IEEE T IND INFORM, V18, P3501, DOI 10.1109/TII.2021.3119038; Ammar HA, 2022, IEEE COMMUN SURV TUT, V24, P611, DOI 10.1109/COMST.2021.3135119; [Anonymous], 2022, PROC NEURIPS; Burd TD, 1996, J VLSI SIG PROC SYST, V13, P203, DOI 10.1007/BF01130406; Chen XM, 2021, IEEE J SEL AREA COMM, V39, P615, DOI 10.1109/JSAC.2020.3019724; Chen X, 2022, IEEE T PARALL DISTR, V33, P683, DOI 10.1109/TPDS.2021.3100298; Chettri L, 2020, IEEE INTERNET THINGS, V7, P16, DOI 10.1109/JIOT.2019.2948888; Conserva M., 2022, PROC NEURIPS; Fei Y, 2021, ADV NEUR IN, V34; Feng Y., 2020, PROC ICML, V119, P3082; Howard AG, 2017, Arxiv, DOI arXiv:1704.04861; Garcia MHC, 2021, IEEE COMMUN SURV TUT, V23, P1972, DOI 10.1109/COMST.2021.3057017; Hu E. J., 2021, P ICLR; Khan R, 2020, IEEE COMMUN SURV TUT, V22, P196, DOI 10.1109/COMST.2019.2933899; Krizhevsky A., 2009, Rep. TR-2009; Lim WYB, 2022, IEEE T PARALL DISTR, V33, P536, DOI 10.1109/TPDS.2021.3096076; Liu BH, 2021, IEEE J SEL AREA COMM, V39, P1015, DOI 10.1109/JSAC.2020.3018809; Liu CH, 2021, IEEE T MOBILE COMPUT, V20, P130, DOI 10.1109/TMC.2019.2938509; Liu YQ, 2020, IEEE INTERNET THINGS, V7, P6722, DOI 10.1109/JIOT.2020.3004500; Malik UM, 2022, IEEE INTERNET THINGS, V9, P14572, DOI 10.1109/JIOT.2021.3068056; Mills J, 2020, IEEE INTERNET THINGS, V7, P5986, DOI 10.1109/JIOT.2019.2956615; Navarro-Ortiz J, 2020, IEEE COMMUN SURV TUT, V22, P905, DOI 10.1109/COMST.2020.2971781; Patnam BSK, 2019, IEEE T IND INFORM, V15, P1350, DOI 10.1109/TII.2018.2854744; Sun YX, 2022, IEEE J SEL AREA COMM, V40, P227, DOI 10.1109/JSAC.2021.3126078; Tran NH, 2019, IEEE INFOCOM SER, P1387, DOI [10.1109/INFOCOM.2019.8737464, 10.1109/infocom.2019.8737464]; Wang CX, 2020, IEEE WIREL COMMUN, V27, P16, DOI 10.1109/MWC.001.1900292; Wei J, 2022, PROC NEURIPS; Xiao H, 2017, Arxiv, DOI arXiv:1708.07747; Xiao Y, 2022, IEEE ICC, P4056, DOI 10.1109/ICC45855.2022.9838659; Yang Y, 2012, INT S HIGH PERF COMP, P103; Zhang L., 2022, PROC NEURIPS; Zhou QH, 2022, J MOD POWER SYST CLE, V10, P91, DOI 10.35833/MPCE.2020.000271; Zhou QH, 2021, IEEE INTERNET THINGS, V8, P11916, DOI 10.1109/JIOT.2021.3063147; Zhou Qihua, 2021, PROC USENIX ANN TECH, P177; Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951	35	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2577-2465		979-8-3503-2928-5	IEEE VTS VEH TECHNOL			2023										10.1109/VTC2023-Fall60731.2023.10333403	http://dx.doi.org/10.1109/VTC2023-Fall60731.2023.10333403			6	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BW2ZI					2024-07-03	WOS:001133762500051
J	Biancofiore, GM; Deldjoo, Y; Di Noia, T; Di Sciascio, E; Narducci, F				Biancofiore, Giovanni Maria; Deldjoo, Yashar; Di Noia, Tommaso; Di Sciascio, Eugenio; Narducci, Fedelucio			Interactive Question Answering Systems: Literature Review	ACM COMPUTING SURVEYS			English	Review						Question answering; natural language processing; interactive systems; human-computer interaction; artificial intelligence; large language model	LANGUAGE; ATTENTION	Question-answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their queries by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to interact with the system and receive more precise results dynamically. This survey offers a detailed overview of the interactive question-answering methods that are prevalent in current literature. It begins by explaining the foundational principles of question-answering systems, hence defining new notations and taxonomies to combine all identified works inside a unified framework. The reviewed published work on interactive question-answering systems is then presented and examined in terms of its proposed methodology, evaluation approaches, and dataset/application domain. We also describe trends surrounding specific tasks and issues raised by the community, so shedding light on the future interests of scholars. Our work is further supported by a GitHub page synthesizing all the major topics covered in this literature study. https://sisinflab.github.io/interactive-question-answering-systems-survey/	[Biancofiore, Giovanni Maria; Di Sciascio, Eugenio] Polytech Univ Bari, Bari, Puglia, Italy; [Deldjoo, Yashar] Politecn Bari, Dept Elect Engn & Informat Technol, SisInf Lab, Bari, Italy; [Di Noia, Tommaso] Politecn Bari, Bari, BA, Italy; [Narducci, Fedelucio] Politecn Bari, Bari, Puglia, Italy	Politecnico di Bari; Politecnico di Bari; Politecnico di Bari; Politecnico di Bari	Biancofiore, GM (corresponding author), Polytech Univ Bari, Bari, Puglia, Italy.	giovannimaria.Biancofiore@poliba.it; yashar.deldjoo@poliba.it; tommaso.dinoia@poliba.it; eugenio.disciascio@poliba.it; fedelucio.narducci@poliba.it	Deldjoo, Yashar/O-5453-2015	Deldjoo, Yashar/0000-0002-6767-358X; di sciascio, eugenio/0000-0002-5484-9945				Alamri H, 2019, PROC CVPR IEEE, P7550, DOI 10.1109/CVPR.2019.00774; Alipour Kamran, 2020, CEUR WORKSHOP P, V2560, P54; Alloatti F, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P250; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI [10.1145/2339530.2339665, DOI 10.1145/2339530.2339665]; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Baheti A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P191; Basu K, 2019, ELECTRON P THEOR COM, P396, DOI 10.4204/EPTCS.306.53; Berdasco A., 2019, Multidisciplinary Digital Publishing Institute Proceedings, V31, P51, DOI DOI 10.3390/PROCEEDINGS2019031051; Bhattacharjee S, 2020, LECT NOTES COMPUT SC, V12089, P47, DOI 10.1007/978-3-030-51310-8_5; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bordes A., 2015, ABS150602075 CORR; Chada R, 2019, Arxiv, DOI arXiv:1906.03695; Chapman A, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P523; Chen D. L., 2011, Association for Computational Linguistics, V1, P190; Chen WH, 2021, Arxiv, DOI arXiv:2010.10439; Chiang TR, 2020, AAAI CONF ARTIF INTE, V34, P7578; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Christmann P, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P729, DOI 10.1145/3357384.3358016; Clark K, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P643; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cohen D, 2018, ACM/SIGIR PROCEEDINGS 2018, P1165, DOI 10.1145/3209978.3210118; Curto S, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2603; Damljanovic D, 2010, LECT NOTES COMPUT SC, V6088, P106, DOI 10.1007/978-3-642-13486-9_8; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Das R., 2019, ICLR; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhingra B, 2017, Arxiv, DOI arXiv:1707.03904; Dunn M, 2017, Arxiv, DOI arXiv:1704.05179; Fagin R, 2003, J COMPUT SYST SCI, V66, P614, DOI 10.1016/S0022-0000(03)00026-6; Feng MW, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P813, DOI 10.1109/ASRU.2015.7404872; Ferrandez Antonio, 2010, ACM INT C P SERIES; Fukumoto J, 2013, PROCEDIA COMPUT SCI, V22, P991, DOI 10.1016/j.procs.2013.09.184; Gao P, 2019, IEEE I CONF COMP VIS, P5824, DOI 10.1109/ICCV.2019.00592; Gordon D, 2018, PROC CVPR IEEE, P4089, DOI 10.1109/CVPR.2018.00430; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Guo D., 2018, ADV NEURAL INFORM PR, P2946; Guo WY, 2021, IEEE T IMAGE PROCESS, V30, P6730, DOI 10.1109/TIP.2021.3097180; Habibi M, 2016, DATA KNOWL ENG, V106, P38, DOI 10.1016/j.datak.2016.06.003; Han H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5890; Hazrina S, 2017, INFORM PROCESS MANAG, V53, P52, DOI 10.1016/j.ipm.2016.06.006; He SZ, 2019, AAAI CONF ARTIF INTE, P134; Hirschman L., 2001, Natural Language Engineering, V7, P275, DOI 10.1017/S1351324901002807; Hong YN, 2019, AAAI CONF ARTIF INTE, P9855; Hu J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P456, DOI 10.1145/3240508.3240626; Huang HY, 2019, Arxiv, DOI arXiv:1810.06683; Hulburd E, 2020, Arxiv, DOI arXiv:2002.10670; Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149; Jia Z, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P792, DOI 10.1145/3459637.3482416; Jin WK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1193, DOI 10.1145/3343031.3351065; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Ju Y, 2019, Arxiv, DOI arXiv:1909.10772; Kacupaj E, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P925, DOI 10.1145/3511808.3557267; Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217; Kaiser M, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2129, DOI 10.1145/3397271.3401399; Khot T, 2020, AAAI CONF ARTIF INTE, V34, P8082; Kim KM, 2017, Arxiv, DOI arXiv:1707.00836; Konstantinova N, 2013, EMERGING APPLICATIONS OF NATURAL LANGUAGE PROCESSING: CONCEPTS AND NEW RESEARCH, P149, DOI 10.4018/978-1-4666-2169-5.ch007; Kottur S, 2018, LECT NOTES COMPUT SC, V11219, P160, DOI 10.1007/978-3-030-01267-0_10; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kulkarni M., 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, P273; Kumar G, 2019, LECT NOTES ELECTR EN, V579, P397, DOI 10.1007/978-981-13-9443-0_35; Kundu S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P959; Kuo CC, 2020, INTERSPEECH, P4173, DOI 10.21437/Interspeech.2020-1763; Latcinnik V, 2020, Arxiv, DOI arXiv:2004.05569; Le Berre Guillaume, 2020, Advances in Artificial Intelligence. 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12109), P356, DOI 10.1007/978-3-030-47358-7_37; Lee C, 2019, L@S '19: PROCEEDINGS OF THE SIXTH (2019) ACM CONFERENCE ON LEARNING @ SCALE; Lei J., 2018, arXiv; Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468; Li HY, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927, DOI 10.1145/3097983.3098115; Li Qian, 2019, MRQA EMNLP, P38; Li Q, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1338; Li Q, 2018, LECT NOTES COMPUT SC, V11211, P570, DOI 10.1007/978-3-030-01234-2_34; Li RH, 2020, NEUROCOMPUTING, V391, P13, DOI 10.1016/j.neucom.2020.01.056; Li TL, 2023, Arxiv, DOI arXiv:2305.01750; Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502; Liu AT, 2019, LECT NOTES ARTIF INT, V11856, P81, DOI 10.1007/978-3-030-32381-3_7; Liu SY, 2018, Arxiv, DOI arXiv:1805.05670; Liu S, 2013, LECT NOTES ARTIF INT, V8208, P73, DOI 10.1007/978-3-642-41491-6_8; Liu Yuhang, 2022, IJCAI; Lockett J, 2019, LECT NOTES ARTIF INT, V11529, P396, DOI 10.1007/978-3-030-27629-4_36; Lopez V, 2013, J WEB SEMANT, V21, P3, DOI 10.1016/j.websem.2013.05.006; Maitra A, 2020, LECT NOTES COMPUT SC, V12089, P73, DOI 10.1007/978-3-030-51310-8_7; Mandya A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2017; Mandya Angrosh, 2019, PACLING ( Communications in Computer and Information Science,, V1215, P280; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Mass Y, 2019, Arxiv, DOI arXiv:1908.06780; McCarley JS, 2021, Arxiv, DOI arXiv:1910.06360; Mendes Pablo N., 2012, DBpedia: A Multilingual Crossdomain Knowledge Base; Mihaylov T, 2018, Arxiv, DOI [arXiv:1809.02789, 10.48550/arXiv.1809.02789]; Moon S., 2019, CONLL, P728; Müller T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5902; Naeem M. Asif, 2012, Natural Language Processing and Information Systems. Proceedings 17th International Conference on Applications of Natural Language to Information Systems, NLDB 2012, P372, DOI 10.1007/978-3-642-31178-9_50; Nakov Preslav, 2019, arXiv; Nie AL, 2019, Arxiv, DOI arXiv:1906.01243; Nothdurft F, 2016, SIGNALS COMMUN TECHN, P41, DOI 10.1007/978-3-319-21834-2_4; Osama Reham A., 2019, MRQA EMNLP, P191; Otegi A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P436; Park Jinyoung, 2023, AAAI, P13457; Park J, 2021, PROC CVPR IEEE, P15521, DOI 10.1109/CVPR46437.2021.01527; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Perera R, 2014, COMM COM INF SC, V468, P128; Petukhova Volha, 2015, LTC (Lecture Notes in Computer Science, V930, P246; Pradhan Akshit, 2018, COMMUNICATIONS COMPU, V1031, P3; Qi ZH, 2019, INT CONF ACOUST SPEE, P7540, DOI 10.1109/ICASSP.2019.8682663; Qu C, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P539, DOI 10.1145/3397271.3401110; Qu C, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1391, DOI 10.1145/3357384.3357905; Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Ren MY, 2015, ADV NEUR IN, V28; Riley H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00125; Rücklé A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P19, DOI 10.18653/v1/P17-4004; Saha A, 2018, Arxiv, DOI arXiv:1801.10314; Sakata W, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1113, DOI 10.1145/3331184.3331326; Saxena A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2814; Schwarzer M., 2016, CEUR Workshop Proceedings, V1670, P74; Sen B, 2020, Arxiv, DOI arXiv:2005.08294; Shao H, 2019, COMM COM INF SC, V1143, P215, DOI 10.1007/978-3-030-36802-0_24; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Shen T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2442; Shi L, 2020, INT CONF ACOUST SPEE, P4412, DOI [10.1109/icassp40776.2020.9053595, 10.1109/ICASSP40776.2020.9053595]; Shin A, 2018, PROC CVPR IEEE, P8925, DOI 10.1109/CVPR.2018.00930; Siblini Wissam, 2019, arXiv; Sorokin D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P114; Su LX, 2019, AAAI CONF ARTIF INTE, P10041; Su Y., 2016, P 2016 C EMPIRICAL M, P562, DOI [10.18653/v1/D16-1054, DOI 10.18653/V1/D16-1054]; Su Y, 2018, ACM/SIGIR PROCEEDINGS 2018, P855, DOI 10.1145/3209978.3210013; Sugiyama Hiroaki, 2016, IWSDS (Lecture Notes in Electrical Engineering,, V427, P183; Sundar A, 2022, Arxiv, DOI arXiv:2205.06907; Tafjord Oyvind, 2022, P 2022 C EMPIRICAL M, P2078; Tamas M, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P632, DOI 10.5220/0006205306320639; Tan YM, 2023, LECT NOTES COMPUT SC, V14265, P348, DOI 10.1007/978-3-031-47240-4_19; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Do T, 2019, IEEE I CONF COMP VIS, P392, DOI 10.1109/ICCV.2019.00048; Vakulenko S, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P355, DOI 10.1145/3437963.3441748; van Aken B, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1823, DOI 10.1145/3357384.3358028; Waltinger U, 2012, KUNSTL INTELL, V26, P381, DOI 10.1007/s13218-012-0208-1; Wang Mengqiu, 2007, JOINT C EMP METH NAT, P22; Wang ZG, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5878; Weston J, 2015, Arxiv, DOI [arXiv:1502.05698, 10.48550/arXiv.1502.05698]; WilsonWong John Thangarajah, 2011, CIKM, P2577; WilsonWong Lawrence Cavedon, 2012, COLING, P2821; Wong Wilson, 2012, CIKM, P2707; Wu F, 2017, IEEE T KNOWL DATA EN, V29, P2304, DOI 10.1109/TKDE.2017.2720737; Wu JM, 2020, NEUROCOMPUTING, V389, P93, DOI 10.1016/j.neucom.2019.12.107; Wu ZY, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P663, DOI 10.1145/3336191.3371782; Xie Zhipeng, 2017, Lecture Notes in Computer Science, V10619, P136; Xiong Kun, 2016, arXiv; Xu JJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1618; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Yang W, 2019, Arxiv, DOI [arXiv:1904.06652, DOI 10.48550/ARXIV.1904.06652]; Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72; Yang Y., 2015, P 2015 C EMPIRICAL M, P2013, DOI [DOI 10.18653/V1, 10.18653/v1/D15-1237, 10.18653/v1/d15-1237, DOI 10.18653/V1/D15-1237]; Yang ZK, 2020, IEEE WINT CONF APPL, P1545, DOI [10.1109/WACV45572.2020.9093596, 10.1109/wacv45572.2020.9093596]; Yang ZL, 2018, Arxiv, DOI arXiv:1809.09600; Yih WT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P201; Yuan XD, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2796; Zdrok Oksana., 2023, The Rise of Generative Question Answering with LLMs; Zhang HZ, 2018, Arxiv, DOI arXiv:1801.09893; Zhang S, 2018, IEEE ACCESS, V6, P74061, DOI 10.1109/ACCESS.2018.2883637; Zhang S, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7080767; Zhang XB, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1381, DOI 10.1145/3357384.3358059; Zhang YY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1089, DOI 10.1145/3343031.3351033; Zheng WG, 2019, INFORM SCIENCES, V481, P141, DOI 10.1016/j.ins.2018.12.032; Zhong WJ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4230; Zhou GY, 2016, KNOWL-BASED SYST, V93, P75, DOI 10.1016/j.knosys.2015.11.002; Zhou ZH, 2017, INT CONF ASIAN LANG, P103, DOI 10.1109/IALP.2017.8300556; Zhu C., 2018, SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	173	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0360-0300	1557-7341		ACM COMPUT SURV	ACM Comput. Surv.	SEP	2024	56	9							239	10.1145/3657631	http://dx.doi.org/10.1145/3657631			38	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RU3N7		Bronze, Green Submitted			2024-07-03	WOS:001230135700024
J	Cooper, G				Cooper, Grant			Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence	JOURNAL OF SCIENCE EDUCATION AND TECHNOLOGY			English	Article						Generative artificial intelligence and science education; Large language models; ChatGPT; Digital technologies		The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT's output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.	[Cooper, Grant] Curtin Univ, Bentley, WA 6102, Australia	Curtin University	Cooper, G (corresponding author), Curtin Univ, Bentley, WA 6102, Australia.	grant.cooper@curtin.edu.au	BUCCINI, FRANCESCA/HTM-4917-2023	Cooper, Grant/0000-0003-3890-0947	CAUL	CAUL	Open Access funding enabled and organized by CAUL and its Member Institutions	[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Archer L, 2013, PEDAGOG CULT SOC, V21, P171, DOI 10.1080/14681366.2012.748676; Boudreau C, 2023, THE INSIDER; Buchanan J, 2023, EC WRITING EVERY DAY; Bybee R.W, 2002, LEARNING SCI SCI LEA; Celik I, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107468; Cope B, 2021, EDUC PHILOS THEORY, V53, P1229, DOI 10.1080/00131857.2020.1728732; Darics E, 2023, CONVERSATION; Du X, 2019, INT J SCI EDUC, V41, P2136, DOI 10.1080/09500693.2019.1662135; Gleason N, 2022, HIGH EDUC; Gorard S, 2009, STUD SCI EDUC, V45, P93, DOI 10.1080/03057260802681821; Hackling M.W., 2005, PRIMARY CONNECTIONSS; Hamilton ML, 2008, STUD TEACH EDUC, V4, P17, DOI 10.1080/17425960801976321; Kang J, 2018, RES SCI EDUC, V48, P865, DOI 10.1007/s11165-016-9590-2; Karim R, 2023, MONASH LENS; Kirschner PA, 2006, EDUC PSYCHOL-US, V41, P75, DOI 10.1207/s15326985ep4102_1; Lameras P, 2022, INFORMATION, V13, DOI 10.3390/info13010014; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; OpenAI, 2023, ED CONS CHATGPT; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Pei Wang, 2019, Journal of Artificial General Intelligence, V10, P1, DOI 10.2478/jagi-2019-0002; Perrigo B, 2023, TIME; Rannikmae M., 2020, Science education in theory and practice: An introductory guide to learning theory, P259, DOI DOI 10.1007/978-3-030-43620-9_18; Scharth M, 2022, CHATGPT CHATBOT IS B; Shubhendu S., 2013, APPL ARTIFICIAL INTE; Stockman C., 2022, DIGITAL CULTURE ED, V14, P1; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Yang Weipeng., 2022, Computers and Education: Artificial Intelligence, V3, P1, DOI [10.1016/j.caeai.2022.100061, DOI 10.1016/J.CAEAI.2022.100061]; Zhai Xioming., 2022, CHATGPT USER EXPERIE, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]	30	151	153	841	2108	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1059-0145	1573-1839		J SCI EDUC TECHNOL	J. Sci. Educ. Technol.	JUN	2023	32	3					444	452		10.1007/s10956-023-10039-y	http://dx.doi.org/10.1007/s10956-023-10039-y		MAR 2023	9	Education & Educational Research; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Education & Educational Research	E1OM7		hybrid			2024-07-03	WOS:000954738400001
J	Himeur, Y; Sayed, AN; Alsalemi, A; Bensaali, F; Amira, A				Himeur, Yassine; Sayed, Aya Nabil; Alsalemi, Abdullah; Bensaali, Faycal; Amira, Abbes			Edge AI for Internet of Energy: Challenges and perspectives	INTERNET OF THINGS			English	Article						Edge AI; Internet of energy (IoE); Energy efficiency in buildings; Federated learning; Blockchain; Large language models (LLMs)	DEEP NEURAL-NETWORKS; DISTRIBUTED COMPUTATIONAL INTELLIGENCE; SOFTWARE-DEFINED NETWORKING; ANOMALY DETECTION; COMPUTING PARADIGM; DATA ANALYTICS; BIG DATA; IOT; OPTIMIZATION; FRAMEWORK	The digital landscape of the Internet of Energy (IoE) is on the brink of a revolutionary transformation with the integration of edge Artificial Intelligence (AI). This comprehensive review elucidates the promise and potential that edge AI holds for reshaping the IoE ecosystem. Commencing with a meticulously curated research methodology, the article delves into the myriad of edge AI techniques specifically tailored for IoE. The myriad benefits, spanning from reduced latency and real-time analytics to the pivotal aspects of information security, scalability, and cost-efficiency, underscore the indispensability of edge AI in modern IoE frameworks. As the narrative progresses, readers are acquainted with pragmatic applications and techniques, highlighting on-device computation, secure private inference methods, and the avant-garde paradigms of AI training on the edge. A critical analysis follows, offering a deep dive into the present challenges including security concerns, computational hurdles, and standardization issues. However, as the horizon of technology ever expands, the review culminates in a forward -looking perspective, envisaging the future symbiosis of 5G networks, federated edge AI, deep reinforcement learning, and more, painting a vibrant panorama of what the future beholds. For anyone vested in the domains of IoE and AI, this review offers both a foundation and a visionary lens, bridging the present realities with future possibilities.	[Himeur, Yassine] Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates; [Sayed, Aya Nabil; Bensaali, Faycal; Amira, Abbes] Qatar Univ, Dept Elect Engn, Doha, Qatar; [Alsalemi, Abdullah; Amira, Abbes] Montfort Univ, Inst Artificial Intelligence, Leicester, England; [Amira, Abbes] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates	University of Dubai; Qatar University; De Montfort University; University of Sharjah	Himeur, Y (corresponding author), Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates.	yhimeur@ud.ac.ae	Himeur, Yassine/AAK-7814-2021	Himeur, Yassine/0000-0001-8904-5587; Bensaali, Faycal/0000-0002-9273-4735	National Priorities Research Program (NPRP), United Arab Emirates from the Qatar National Research Fund, Qatar [NPRP14S-0401-210122]	National Priorities Research Program (NPRP), United Arab Emirates from the Qatar National Research Fund, Qatar	This paper was made possible by National Priorities Research Program (NPRP), United Arab Emirates grant No. NPRP14S-0401-210122 from the Qatar National Research Fund, Qatar (a member of Qatar Foundation) . The statements made herein are solely the responsibility of the authors.	Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Abdellatif A. A., 2020, Energy Efficiency of Medical Devices and Healthcare Applications, P53; Abdelzaher T., 2019, 2019 28 INT C COMPUT, P1, DOI DOI 10.1109/ICCCN.2019.8847014; Adel E, 2018, INT C MICROELECTRON, P176, DOI 10.1109/ICM.2018.8704085; Agrawal N, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1231, DOI 10.1145/3319535.3339819; Ahmed Shamim, 2020, NILM'20: Proceedings of the 5th International Workshop on Non-Intrusive Load Monitoring, P44, DOI 10.1145/3427771.3427852; Ahuja K., 2019, Cloud Computing for Geospatial Big Data Analytics, P155; Akter MS, 2023, P INT COMP SOFTW APP, P1084, DOI 10.1109/COMPSAC57700.2023.00164; Al-Doghman F, 2023, IEEE T SERV COMPUT, V16, P1485, DOI 10.1109/TSC.2022.3155447; Alistarh D, 2017, ADV NEUR IN, V30; Alqahtani T., 2023, Res. Soc. Administrat. Pharmacy; Alrazgan M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/5776954; Alsahli M., 2022, INT C INFORM TECHNOL, P17; Alsalemi A, 2022, SUSTAIN CITIES SOC, V78, DOI 10.1016/j.scs.2021.103571; Alsalemi A, 2021, IEEE SENS J, V21, P27623, DOI 10.1109/JSEN.2021.3114333; Alsalemi A, 2021, IEEE SYST J, V15, P1256, DOI 10.1109/JSYST.2020.2997773; Alsalemi A, 2020, INT CONF UTIL CLOUD, P420, DOI 10.1109/UCC48980.2020.00066; Alsalemi A, 2020, IEEE ACCESS, V8, P15047, DOI 10.1109/ACCESS.2020.2966640; Alwarafy A, 2021, IEEE INTERNET THINGS, V8, P4004, DOI 10.1109/JIOT.2020.3015432; Amjad M, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12061405; [Anonymous], 2021, Edge computing: Changing the balance of energy in networks; Arenas L.D.O., 2020, IEEE Trans. Instrum. Meas., V70, P1; Arora K., 2023, Modern Computational Techniques for Engineering Applications; Atalla Shadi, 2022, 2022 5th International Conference on Signal Processing and Information Security (ICSPIS), P169, DOI 10.1109/ICSPIS57063.2022.10002437; Aujla GS, 2018, FUTURE GENER COMP SY, V86, P1279, DOI 10.1016/j.future.2017.09.066; Azzouzi O, 2023, Arxiv, DOI arXiv:2308.04261; Bagchi S, 2020, COMMUN ACM, V63, P58, DOI 10.1145/3362068; Bakhshi Z, 2019, EUROMICRO CONF PROC, P395, DOI 10.1109/SEAA.2019.00066; Baktir AC, 2017, IEEE COMMUN SURV TUT, V19, P2359, DOI 10.1109/COMST.2017.2717482; Barthélemy J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092048; Ben Ammar M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030383; Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060; Bernstein J, 2018, PR MACH LEARN RES, V80; Bin Mahbod MH, 2022, APPL ENERG, V322, DOI 10.1016/j.apenergy.2022.119392; Bobda C, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3506713; Bousbiat H, 2023, Arxiv, DOI arXiv:2304.08602; Bousbiat H, 2023, ENERGIES, V16, DOI 10.3390/en16020991; Brasington L., 2019, Energy & Power Shifts from IoT Cloud to Edge Computing; Bui N, 2012, IEEE NETWORK, V26, P39, DOI 10.1109/MNET.2012.6246751; de Oliveira FMC, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11100209; de Oliveira FMC, 2018, INT SYM COMP ARCHIT, P266, DOI [10.1109/SBAC-PAD.2018.00052, 10.1109/CAHPC.2018.8645927]; Cao H, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720919698; Cao H, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4528; Carvalho G, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103840; Casado-Vara R, 2020, CYBERNET SYST, V51, P685, DOI 10.1080/01969722.2020.1798643; Chang XM, 2018, INT C PAR DISTRIB SY, P928, DOI [10.1109/ICPADS.2018.00124, 10.1109/PADSW.2018.8644647]; Chen F, 2019, CLUSTER COMPUT, V22, P14013, DOI 10.1007/s10586-018-2171-6; Chen SM, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P614, DOI 10.1145/3597926.3598082; Chen T., 2018, PROCNEURIPS, P1; Chen XJ, 2022, IEEE T COMMUN, V70, P389, DOI 10.1109/TCOMM.2021.3123275; Chen XN, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1478-1; Chen Y, 2019, IEEE INTERNET THINGS, V6, P4242, DOI 10.1109/JIOT.2018.2875715; Cheng Y, 2020, Arxiv, DOI [arXiv:1710.09282, DOI 10.48550/ARXIV.1710.09282]; Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695; Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7; Chuang MC, 2020, I C INF COMM TECH CO, P756, DOI 10.1109/ICTC49870.2020.9289161; Cintuglu MH, 2019, IEEE INTERNET THINGS, V6, P8046, DOI 10.1109/JIOT.2019.2902793; Copiaco A, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105775; Dan Wang, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P1290, DOI 10.1109/HPCC/SmartCity/DSS.2019.00180; Deng SG, 2020, IEEE INTERNET THINGS, V7, P7457, DOI 10.1109/JIOT.2020.2984887; Dey S, 2018, PROCEEDINGS OF THE FIRST WORKSHOP ON SMART CITIES AND FOG COMPUTING (CITIFOG '18), P19, DOI 10.1145/3277893.3277899; Dhilleswararao P, 2022, IEEE ACCESS, V10, P131788, DOI 10.1109/ACCESS.2022.3229767; Ding AY, 2022, ACM SIGCOMM COMP COM, V52, P28; Dou F, 2023, Arxiv, DOI [arXiv:2309.07438, 10.48550/arXiv.2309.07438, DOI 10.48550/ARXIV.2309.07438]; Dowlin N, 2016, PR MACH LEARN RES, V48; Du M, 2020, IEEE T BIG DATA, V6, P283, DOI 10.1109/TBDATA.2018.2829886; Du YB, 2021, IEEE T CONTROL NETW, V8, P1212, DOI 10.1109/TCNS.2021.3059848; Duo R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041082; Elgamal T, 2020, 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2020), P519, DOI 10.1109/CCGrid49817.2020.00-41; Elnour M, 2022, APPL ENERG, V318, DOI 10.1016/j.apenergy.2022.119153; Emadaleslami M, 2023, INT J ELEC POWER, V150, DOI 10.1016/j.ijepes.2023.109088; Ezeme Okwudili M., 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P992, DOI 10.1109/ICMLA.2019.00169; Fang DW, 2020, COMPUT COMMUN, V151, P42, DOI 10.1016/j.comcom.2019.12.021; Fang YH, 2020, Arxiv, DOI arXiv:2007.01793; Farhat F., 2023, PREPRINT; Ferrag MA, 2020, IEEE T ENG MANAGE, V67, P1285, DOI 10.1109/TEM.2019.2922936; Aji AF, 2017, Arxiv, DOI arXiv:1704.05021; Howard AG, 2017, Arxiv, DOI arXiv:1704.04861; Gai KK, 2019, IEEE INTERNET THINGS, V6, P7992, DOI 10.1109/JIOT.2019.2904303; García-Martín E, 2019, J PARALLEL DISTR COM, V134, P75, DOI 10.1016/j.jpdc.2019.07.007; Garg S, 2019, IEEE NETWORK, V33, P72, DOI 10.1109/MNET.2019.1800239; Glauner P, 2017, Arxiv, DOI arXiv:1606.00626; Gong Y, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2477, DOI 10.1145/3340531.3412700; Gou JP, 2021, Arxiv, DOI arXiv:2006.05525; Guimaraes CJBV, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533594; Guo HZ, 2020, IEEE NETWORK, V34, P128, DOI 10.1109/MNET.001.1900200; Hamm A., 2019, arXiv; Han T, 2021, IEEE INTERNET THINGS, V8, P3170, DOI 10.1109/JIOT.2020.3013306; Han W., 2019, J. Ambient Intell. Humaniz. Comput., P1; Hasan B.T., 2023, Low Power Architectures for IoT Applications, P1; Hernández A, 2020, CON DES CIRC INTEGR, DOI 10.1109/dcis51330.2020.9268626; Hijawi U., 2020, IEEE Access; Himeur Yassine, 2022, 2022 5th International Conference on Signal Processing and Information Security (ICSPIS), P180, DOI 10.1109/ICSPIS57063.2022.10002641; Himeur Y., 2020, P SAI INTELLIGENT SY, P188; Himeur Y., 2021, 5 INT C BIG DATA INT, P1; Himeur Y., 2020, Int. J. Intell. Syst., P1; Himeur Y., 2021, 2021 IEEE INT S CIRC, P1; Himeur Y, 2023, ARTIF INTELL REV, V56, P4929, DOI 10.1007/s10462-022-10286-2; Himeur Y, 2022, SUSTAIN CITIES SOC, V85, DOI 10.1016/j.scs.2022.104059; Himeur Y, 2022, COMPUT SECUR, V118, DOI 10.1016/j.cose.2022.102746; Himeur Y, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100439; Himeur Y, 2022, J CLEAN PROD, V331, DOI 10.1016/j.jclepro.2021.129786; Himeur Y, 2022, INT J INTELL SYST, V37, P7124, DOI 10.1002/int.22876; Himeur Y, 2021, INT C PATT RECOG, P5744, DOI 10.1109/ICPR48806.2021.9412310; Himeur Y, 2021, SUSTAIN CITIES SOC, V67, DOI 10.1016/j.scs.2021.102764; Himeur Y, 2021, INT J INTELL SYST, V36, P2865, DOI 10.1002/int.22404; Himeur Y, 2021, APPL ENERG, V287, DOI 10.1016/j.apenergy.2021.116601; Himeur Y, 2020, APPL ENERG, V279, DOI 10.1016/j.apenergy.2020.115872; Himeur Y, 2020, COGN COMPUT, V12, P1381, DOI 10.1007/s12559-020-09764-y; Himeur Y, 2021, INT J INTELL SYST, V36, P72, DOI 10.1002/int.22292; Himeur Y, 2020, INFORM FUSION, V64, P99, DOI 10.1016/j.inffus.2020.07.003; Himeur Y, 2020, APPL ENERG, V267, DOI 10.1016/j.apenergy.2020.114877; Pajooh HH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020359; Hong ZC, 2019, IEEE T PARALL DISTR, V30, P2759, DOI 10.1109/TPDS.2019.2926979; Hu J., 2020, IEEE Internet Things J; Hua HC, 2019, APPL ENERG, V239, P598, DOI 10.1016/j.apenergy.2019.01.145; Hussain B, 2019, IEEE ACCESS, V7, P137656, DOI 10.1109/ACCESS.2019.2942485; Ianculescu M, 2019, I C CONTR SYS COMP S, P655, DOI 10.1109/CSCS.2019.00118; Iandola F. N., 2017, ARXIV160207360, P1, DOI [10.1007/978-3-319-24553-9, DOI 10.1007/978-3-319-24553-9]; idc, 2021, IoT Growth Demands Rethink of Long-Term Storage Strategies, says IDC; Iwendi C, 2022, ENERGY REP, V8, P5016, DOI 10.1016/j.egyr.2022.02.304; Jayasinghe U, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/2014697; Jiang P, 2018, ADV NEUR IN, V31; Jiang Y., 2023, IEEE Sensors Journal; Joseph A, 2020, IEEE ACCESS, V8, P215787, DOI 10.1109/ACCESS.2020.3041031; Kabalci E., 2019, From Smart Grid to Internet of Energy; Kamal M, 2018, IEEE ACCESS, V6, P34439, DOI 10.1109/ACCESS.2018.2850821; Kamruzzaman MM, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/2950699; Karimireddy SP, 2019, PR MACH LEARN RES, V97; Kaur K, 2018, IEEE COMMUN MAG, V56, P44, DOI 10.1109/MCOM.2018.1700622; KaurBrar N, 2022, J PHARM NEGAT RESULT, V13, P2012, DOI 10.47750/pnr.2022.13.S06.262; Ke R., 2020, IEEE Transactions on Intelligent Transportation Systems; Kee F.K.-K., 2019, 2019 IEEE INT C SMAR, P1; Keshari N, 2022, VEH COMMUN, V38, DOI 10.1016/j.vehcom.2022.100512; Khan LU, 2020, IEEE INTERNET THINGS, V7, P10200, DOI 10.1109/JIOT.2020.2987070; Khan WZ, 2019, FUTURE GENER COMP SY, V97, P219, DOI 10.1016/j.future.2019.02.050; Khattak HA, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102615; Khubrani MM, 2023, ENERGIES, V16, DOI 10.3390/en16165963; Kim B, 2020, IEEE ACCESS, V8, P216259, DOI 10.1109/ACCESS.2020.3038908; Kim J., 2023, Artificial Intelligence and Hardware Accelerators, P167; Ko JH, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P103; Konecny J., 2016, PROC NIPS WORKSHOP P, P1; Kong XJ, 2022, IEEE INTERNET THINGS, V9, P23472, DOI 10.1109/JIOT.2022.3200431; Koot M, 2021, APPL ENERG, V291, DOI 10.1016/j.apenergy.2021.116798; Koronen C, 2020, ENERG EFFIC, V13, P129, DOI 10.1007/s12053-019-09833-8; Kotsogiannis I, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P525, DOI 10.1145/3018661.3018729; Ku Y.-J., 2020, 2020 IEEE GREEN ENER, P1; Kumar P, 2023, SOL ENERGY, V263, DOI 10.1016/j.solener.2023.111921; Kuo W.-H., 2019, 2019 IEEE 8 GLOBAL C, P1; Kuru K, 2019, IEEE ACCESS, V7, P41395, DOI 10.1109/ACCESS.2019.2907809; Lacoste M, 2023, IEEE SECUR PRIV, V21, P37, DOI 10.1109/MSEC.2023.3259801; Lee JM, 2022, FUTURE GENER COMP SY, V132, P124, DOI 10.1016/j.future.2022.02.005; Li E, 2018, MECOMM'18: PROCEEDINGS OF THE 2018 WORKSHOP ON MOBILE EDGE COMMUNICATIONS, P31, DOI 10.1145/3229556.3229562; Li H, 2018, IEEE NETWORK, V32, P96, DOI 10.1109/MNET.2018.1700202; Li JL, 2022, J MOD POWER SYST CLE, V10, P805, DOI 10.35833/MPCE.2021.000161; Li JX, 2020, IEEE ACCESS, V8, P135479, DOI 10.1109/ACCESS.2020.3011503; Li Q., 2020, 2020 IEEE INT C COMM, P1; Li W, 2018, IEEE COMMUN MAG, V56, P94, DOI 10.1109/MCOM.2018.1700888; Li XM, 2018, IEEE INTERNET THINGS, V5, P1351, DOI 10.1109/JIOT.2018.2797187; Liang GQ, 2020, ENGINEERING-PRC, V6, P789, DOI 10.1016/j.eng.2020.06.006; Lin C.-T., 2023, 2023 IEEE CUSTOM INT, P1; Lin CY, 2019, SMART SCI, V7, P139, DOI 10.1080/23080477.2019.1578921; Lin H, 2020, J NETW COMPUT APPL, V169, DOI 10.1016/j.jnca.2020.102781; Lin J, 2022, IEEE T SMART GRID, V13, P268, DOI 10.1109/TSG.2021.3115904; Lin Y., 2018, PROC INT C LEARN REP; Liu FX, 2020, IEEE ACCESS, V8, P67436, DOI 10.1109/ACCESS.2020.2985725; Liu H., 2021, arXiv; Liu Q, 2020, COMPUT COMMUN, V162, P187, DOI 10.1016/j.comcom.2020.08.024; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu Y, 2019, IEEE NETWORK, V33, P111, DOI 10.1109/MNET.2019.1800254; Lowman R., 2020, On the edge: Addressing AI capacity, energy, cost & reliability challenges; Lu RH, 2023, IEEE T PARALL DISTR, V34, P1145, DOI 10.1109/TPDS.2023.3240767; Luo C, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1439; Luo HD, 2019, FUTURE GENER COMP SY, V101, P444, DOI 10.1016/j.future.2019.06.030; Luo JH, 2017, Arxiv, DOI arXiv:1706.05791; Lv LL, 2022, IEEE T IND INFORM, V18, P7946, DOI 10.1109/TII.2022.3163137; Ma C, 2020, IEEE NETWORK, V34, P242, DOI 10.1109/MNET.001.1900506; Mahmud R, 2022, J SYST SOFTWARE, V190, DOI 10.1016/j.jss.2022.111351; Mao JC, 2017, DES AUT TEST EUROPE, P1396, DOI 10.23919/DATE.2017.7927211; Mao YL, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P90, DOI 10.1109/SEC.2018.00014; Marchioni A., 2020, IEEE Internet Things J.; Marini R, 2022, IEEE INTERNET THINGS, V9, P21051, DOI 10.1109/JIOT.2022.3176394; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Mei Q, 2022, IEEE T ENG MANAGE, DOI 10.1109/TEM.2022.3159311; Ménétrey J, 2022, INT CON DISTR COMP S, P1177, DOI 10.1109/ICDCS54860.2022.00116; Merenda M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092533; Mezger BW, 2022, IEEE ACCESS, V10, P51394, DOI 10.1109/ACCESS.2022.3174125; Miao YM, 2020, FUTURE GENER COMP SY, V102, P925, DOI 10.1016/j.future.2019.09.035; Buzau MM, 2019, IEEE T SMART GRID, V10, P2661, DOI 10.1109/TSG.2018.2807925; Mireshghallah F, 2020, Arxiv, DOI arXiv:1905.11814; Mocanu E, 2016, SUSTAIN ENERGY GRIDS, V6, P91, DOI 10.1016/j.segan.2016.02.005; Mocnej J, 2018, IFAC PAPERSONLINE, V51, P162, DOI 10.1016/j.ifacol.2018.07.147; Moghaddam MHY, 2018, IEEE INTERNET THINGS, V5, P1055, DOI 10.1109/JIOT.2018.2805899; Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341; Mohamudally N, 2018, PROCEDIA COMPUT SCI, V134, P10, DOI 10.1016/j.procs.2018.07.138; Monge J, 2023, INFORMATION, V14, DOI 10.3390/info14070355; Mousavi SM, 2022, INT J COMMUN SYST, V35, DOI 10.1002/dac.5036; Muthanna A, 2019, J SENS ACTUAT NETW, V8, DOI 10.3390/jsan8010015; Jha DN, 2019, Arxiv, DOI arXiv:1910.03026; Nastic S, 2017, IEEE INTERNET COMPUT, V21, P64, DOI 10.1109/MIC.2017.2911430; Nizami MSH, 2020, IEEE T IND INFORM, V16, P1836, DOI 10.1109/TII.2019.2932109; Olivares-Rojas J.C., 2020, 2020 IEEE INT C ENG, P1; Oliveira D, 2023, 2023 CYBER-PHYSICAL SYSTEMS AND INTERNET-OF-THINGS WEEK, CPS-IOT WEEK WORKSHOPS, P221, DOI 10.1145/3576914.3587513; Orasan IL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162545; Pahl C., 2018, PROC 3 INT C INTERNE, P105; Pan JL, 2015, IEEE INTERNET THINGS, V2, P527, DOI 10.1109/JIOT.2015.2413397; Pandey M, 2022, NAT MACH INTELL, V4, P211, DOI 10.1038/s42256-022-00463-x; Patsias V, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15080254; Pérez S, 2021, FUTURE GENER COMP SY, V125, P891, DOI 10.1016/j.future.2021.07.031; Perin G, 2022, IEEE T NETW SERV MAN, V19, P306, DOI 10.1109/TNSM.2021.3112796; Petrou L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09772-y; Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987; Plappert C., 2022, P 17 INT C AVAILABIL, P1; Pop C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010162; Posch M., 2019, Hands-on Embedded Programming with C++ 17: Create Versatile and Robust Embedded Solutions for MCUs and RTOSes with Modern C++; Premsankar G, 2018, IEEE INTERNET THINGS, V5, P1275, DOI 10.1109/JIOT.2018.2805263; Qiu S, 2023, PROCESSES, V11, DOI 10.3390/pr11051508; Rahman A, 2021, IEEE ACCESS, V9, P28361, DOI 10.1109/ACCESS.2021.3058244; Ramírez-Bárcenas A, 2020, CON DES CIRC INTEGR; Rastogi Krati, 2020, Procedia Computer Science, V171, P1943, DOI 10.1016/j.procs.2020.04.208; Rathore S, 2019, J NETW COMPUT APPL, V143, P167, DOI 10.1016/j.jnca.2019.06.019; Rausch T., 2019, 2 USENIX WORKSHOP HO; Ray PP, 2022, J KING SAUD UNIV-COM, V34, P1595, DOI 10.1016/j.jksuci.2021.11.019; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren JJ, 2019, IEEE ACCESS, V7, P69194, DOI 10.1109/ACCESS.2019.2919736; Ren J, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3362031; Rupapara V., 2023, Artificial Intelligence for Smart Healthcare, P245; Ryffel T, 2018, Arxiv, DOI arXiv:1811.04017; Sachdev R, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P341, DOI [10.1109/FMEC49853.2020.9144755, 10.1109/fmec49853.2020.9144755]; Samie F., 2019, IoT for Smart Grids., P21, DOI DOI 10.1007/978-3-030-03640-9_2; Sang Hyeon Lee, 2019, 2019 IEEE 2nd International Conference on Electronics Technology (ICET), P473, DOI 10.1109/ELTECH.2019.8839589; Sardianos Christos, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P394, DOI 10.1109/ICIoT48696.2020.9089624; Sardianos C., 2020, 2020 INT C INTERNET, DOI 10.1109/iThings-GreenCom-CPSCom- SmartData-Cybermatics50389.2020.00072; Sardianos C., 2019, INT C SMART CIT GREE, P65; Sardianos C, 2021, INT J INTELL SYST, V36, P656, DOI 10.1002/int.22314; Sardianos C, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2020), P96, DOI 10.1109/BigDataService49289.2020.00022; Sardianos C, 2020, FUTURE GENER COMP SY, V112, P394, DOI 10.1016/j.future.2020.05.041; Sayed A., 2022, Emerging Real-World Applications of Internet of Things, P233; Sayed A., 2021, Networking, Intelligent Systems and Security: Proceedings of NISS 2021, P603; Sayed A, 2022, IEEE SYST J, V16, P5001, DOI 10.1109/JSYST.2021.3124793; Sayed AN, 2023, ENERGIES, V16, DOI 10.3390/en16052388; Sayed AN, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105786; Schizas N, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14120363; Schneible J, 2017, IEEE MILIT COMMUN C, P678, DOI 10.1109/MILCOM.2017.8170817; Seide F, 2014, INT CONF ACOUST SPEE; Seung Min Kim, 2019, MATEC Web of Conferences, V260, DOI 10.1051/matecconf/201926001001; Sha A., 2022, 2022 3 INT C EMERGIN, P1; Sha KW, 2020, DIGIT COMMUN NETW, V6, P195, DOI 10.1016/j.dcan.2019.08.006; Shafi O., 2022, ACM J. Emerg. Technol. Comput. Syst.; Shah N, 2016, INT CONF DAT MIN WOR, P327, DOI [10.1109/ICDMW.2016.22, 10.1109/ICDMW.2016.0053]; Sharma PK, 2018, IEEE COMMUN MAG, V56, P104, DOI 10.1109/MCOM.2018.1700822; Sharma S, 2021, IEEE T POWER DELIVER, V36, P1241, DOI 10.1109/TPWRD.2020.3029439; Shen YF, 2023, Arxiv, DOI arXiv:2307.02779; Shen ZC, 2022, J LOW POWER ELECT AP, V12, DOI 10.3390/jlpea12020028; Shi SH, 2018, INT C PAR DISTRIB SY, P425, DOI [10.1109/ICPADS.2018.00063, 10.1109/PADSW.2018.8644932]; Sicari S, 2022, COMPUT SECUR, V120, DOI 10.1016/j.cose.2022.102822; Singh M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23198086; Singh P, 2019, Arxiv, DOI arXiv:1905.04446; Singh P, 2020, IEEE WINT CONF APPL, P824, DOI 10.1109/WACV45572.2020.9093331; Singh R., 2023, Internet of Things and CyberPhysical Systems; Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2; Sipola Tuomo, 2022, 2022 31st Conference of Open Innovations Association (FRUCT)., P320, DOI 10.23919/FRUCT54823.2022.9770931; Sirojan T, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON SMART ENERGY SYSTEMS AND TECHNOLOGIES (SEST 2019), DOI 10.1109/sest.2019.8849012; Sittón-Candanedo I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153353; Sjovall P., 2023, 2023 IEEE INT C IMAG, P2215; Sohail S.S., 2023, Current Challenges, and Possible Future Directions; Sohail S.S., 2023, Journal of King Saud University-Computer and Information Sciences; Sohail S.S., 2023, Using chatgpt to navigate ambivalent and contradictory research findings on artificial intelligence; Song XH, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P397, DOI 10.1109/ITNG.2014.45; Stich S. U., 2018, arXiv; Strom N, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1488; Su X, 2019, IEEE T IND INFORM, V15, P4266, DOI 10.1109/TII.2019.2908056; Suciu G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165448; Sun C, 2020, IEEE ACCESS, V8, P47118, DOI 10.1109/ACCESS.2020.2978896; Surianarayanan C., 2023, Essentials of Cloud Computing: A Holistic, Cloud-Native Perspective, P347, DOI DOI 10.1007/978-3-031-32044-6_13; Syed D, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039797; Tabanelli E, 2020, PROC IEEE INT SYMP, P805, DOI [10.1109/ISIE45063.2020.9152277, 10.1109/isie45063.2020.9152277]; Taherizadeh S, 2018, J SYST SOFTWARE, V136, P19, DOI 10.1016/j.jss.2017.10.033; Talk M.V., 2019, Game changers: How automation has changed the gaming industry; Teerapittayanon S, 2017, INT CON DISTR COMP S, P328, DOI 10.1109/ICDCS.2017.226; Tito Shafiqur Rahman, 2021, 2021 International Conference on Technology and Policy in Energy and Electric Power (ICT-PEP), P378, DOI 10.1109/ICT-PEP53949.2021.9600916; Trinks S, 2018, IEEE INT CONF BIG DA, P2930, DOI 10.1109/BigData.2018.8622649; Tse R., 2020, 12 INT C DIGITAL IMA, V11519; Utkarsh K, 2017, IEEE TETCI, V1, P51, DOI 10.1109/TETCI.2016.2635130; Ngo MV, 2020, Arxiv, DOI arXiv:2001.03314; Varlamis I, 2023, INT J DATA SCI ANAL, V16, P353, DOI 10.1007/s41060-022-00331-2; Varlamis I, 2022, APPL ENERG, V305, DOI 10.1016/j.apenergy.2021.117775; Venkataramanan V, 2023, IEEE INTERNET THINGS, V10, P2046, DOI 10.1109/JIOT.2022.3157299; Wagh Sameer, 2019, Proceedings on Privacy Enhancing Technologies, V2019, P26, DOI 10.2478/popets-2019-0035; Wagh S., 2018, IACR Cryptol. ePrint Arch., V2018, P442; Walawalkar Devesh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P18, DOI 10.1007/978-3-030-58529-7_2; Walther R, 2022, LECT NOTES COMPUT SC, V13285, P361, DOI 10.1007/978-3-031-16815-4_20; Wang A, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P334, DOI 10.1145/3318216.3363333; Wang A, 2019, P IEEE, V107, P1500, DOI 10.1109/JPROC.2019.2924377; Wang D, 2019, 2019 IEEE FIRST INTERNATIONAL CONFERENCE ON COGNITIVE MACHINE INTELLIGENCE (COGMI 2019), P194, DOI 10.1109/CogMI48466.2019.00036; Wang J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2407, DOI 10.1145/3219819.3220106; Wang RJ, 2023, IEEE J BIOMED HEALTH, V27, P854, DOI 10.1109/JBHI.2022.3157725; Wang SQ, 2019, AAAI CONF ARTIF INTE, P5289; Wangni J, 2017, Arxiv, DOI arXiv:1710.09854; Wei P, 2020, IEEE INTERNET THINGS, V7, P6402, DOI 10.1109/JIOT.2020.2974848; Wei Y, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060839; Wen W, 2017, Arxiv, DOI arXiv:1705.07878; Wu XF, 2022, ALEX ENG J, V61, P2775, DOI 10.1016/j.aej.2021.08.003; Wu Y., 2022, J. Phys.: Conf. Ser., V2215; Xiang Y., 2019, 2019 IEEE POWER ENER, P1; Xiong JB, 2021, IEEE T IND INFORM, V17, P922, DOI 10.1109/TII.2019.2957130; Xiong ZH, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1701095; Xu D, 2020, INT C LEARN REPR; Xu GX, 2023, IEEE INTERNET THINGS, V10, P11960, DOI 10.1109/JIOT.2022.3151359; Xu S., 2019, IEEE Trans. Netw. Sci. Eng.; Xu YZ, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107053; Yazdinejad A, 2020, IEEE T SERV COMPUT, V13, P625, DOI 10.1109/TSC.2020.2966970; Yiwei Zhu, 2021, 2021 IEEE 6th International Conference on Computer and Communication Systems (ICCCS), P933, DOI 10.1109/ICCCS52626.2021.9449265; Yoo E, 2022, IEEE T EMERG TOP COM, V10, P2092, DOI 10.1109/TETC.2022.3142886; Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009; Yousuf MF, 2022, IEEE NORTH ATLAN TES, DOI 10.1109/MDTS54894.2022.9826935; Yu CJ, 2022, IEEE WIREL COMMUN, V29, P109, DOI 10.1109/MWC.2020.2000351; Yu L, 2020, IEEE INTERNET THINGS, V7, P2751, DOI 10.1109/JIOT.2019.2957289; Yu W, 2018, IEEE ACCESS, V6, P6900, DOI 10.1109/ACCESS.2017.2778504; Yu X, 2022, APPL SOFT COMPUT, V128, DOI 10.1016/j.asoc.2022.109486; Yuan JL, 2023, FUTURE GENER COMP SY, V147, P179, DOI 10.1016/j.future.2023.04.030; Yueyue Dai, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P866, DOI 10.1109/ICCT46805.2019.8947146; Yunxiang Hu, 2022, 2022 14th International Conference on Computer Research and Development (ICCRD), P100, DOI 10.1109/ICCRD54409.2022.9730377; Zakaret C, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249664; Zemouri S, 2018, IEEE INT SM C CONF; Zeng H, 2022, J SUPERCOMPUT, V78, P11621, DOI 10.1007/s11227-022-04329-2; Zhang JL, 2018, IEEE ACCESS, V6, P18209, DOI 10.1109/ACCESS.2018.2820162; Zhang K, 2018, IEEE COMMUN MAG, V56, P39, DOI 10.1109/MCOM.2018.1700882; Zhang L., 2019, 2019 IEEE GLOBAL COM, P1; Zhang QZ, 2023, AD HOC NETW, V138, DOI 10.1016/j.adhoc.2022.103020; Zhang TW, 2018, Arxiv, DOI arXiv:1807.01860; Zhang WY, 2019, IEEE T IND INFORM, V15, P4216, DOI 10.1109/TII.2019.2897001; Zhang XJ, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P491, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00125; Zhang Y., 2022, 2022 IEEE S COMPUTER, P1; Zhang Y, 2021, ADV CIV ENG, V2021, DOI 10.1155/2021/8898997; Zhang Y, 2021, IEEE T SMART GRID, V12, P623, DOI 10.1109/TSG.2020.3010510; Zhang YF, 2020, INT J ELEC POWER, V121, DOI 10.1016/j.ijepes.2020.106162; Zhao ZR, 2018, IEEE T COMPUT AID D, V37, P2348, DOI 10.1109/TCAD.2018.2858384; Zhong JY, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/6694729; Zhong WF, 2019, IEEE COMPUT INTELL M, V14, P42, DOI 10.1109/MCI.2019.2937611; Zhou H, 2023, IEEE T CLOUD COMPUT, V11, P1122, DOI 10.1109/TCC.2022.3163750; Zhou L., 2019, 2 USENIX WORKSHOP HO; Zhou L, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P195, DOI 10.1145/3318216.3363312; Zhou WQ, 2023, IEEE T VEH TECHNOL, V72, P13793, DOI 10.1109/TVT.2023.3275365; Zhou ZY, 2018, IEEE COMMUN MAG, V56, P82, DOI 10.1109/MCOM.2018.1700910; Zhou Z, 2020, IEEE INTERNET THINGS, V7, P8600, DOI 10.1109/JIOT.2020.2994308; Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951; Zhu KL, 2019, IEEE T VEH TECHNOL, V68, P4275, DOI 10.1109/TVT.2019.2907269; Zou J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12163484	349	1	1	8	8	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2543-1536	2542-6605		INTERNET THINGS-NETH	Internet Things	APR	2024	25								101035	10.1016/j.iot.2023.101035	http://dx.doi.org/10.1016/j.iot.2023.101035		DEC 2023	41	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	EN5B9		Green Submitted			2024-07-03	WOS:001139606800001
J	Hsu, CHC; Tan, GX; Stantic, B				Hsu, Cathy H. C.; Tan, Guoxiong; Stantic, Bela			A fine-tuned tourism-specific generative AI concept	ANNALS OF TOURISM RESEARCH			English	Editorial Material						Generative AI; Large language model; Fine-tuning; AI ethics; ChatGPT			[Hsu, Cathy H. C.; Tan, Guoxiong] Hong Kong Polytech Univ, Sch Hotel & Tourism Management, Kowloon, 17 Sci Museum Rd, TST E, Hong Kong, Peoples R China; [Stantic, Bela] Griffith Univ, Sch Informat & Commun Technol, Griffith Sci, Gold Coast, Qld 4222, Australia	Hong Kong Polytechnic University; Griffith University; Griffith University - Gold Coast Campus	Hsu, CHC (corresponding author), Hong Kong Polytech Univ, Sch Hotel & Tourism Management, Kowloon, 17 Sci Museum Rd, TST E, Hong Kong, Peoples R China.	cathy.hsu@polyu.edu.hk; gary-t.tan@polyu.edu.hk; b.stantic@griffith.edu.au		Tan, Guoxiong/0009-0009-9745-5901	Hong Kong Polytechnic University (Work Program ZE2U)	Hong Kong Polytechnic University (Work Program ZE2U)	<STRONG> </STRONG>The work described in this paper was supported by a grant from The Hong Kong Polytechnic University (Work Program ZE2U) .	Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Fesenmaier DR, 2023, ANN TOURISM RES, V101, DOI 10.1016/j.annals.2023.103578; Gursoy D, 2023, J HOSP MARKET MANAG, V32, P579, DOI 10.1080/19368623.2023.2211993; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Ivanov S, 2021, J TOUR FUTURES, V9, P214, DOI 10.1108/JTF-02-2023-0038; Paschen U, 2020, BUS HORIZONS, V63, P147, DOI 10.1016/j.bushor.2019.10.004; Pazzanese Christina., 2020, THE HARVARD GAZETTE; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Trichopoulos G, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12183829; Vanian Jonathan, 2023, CNBC            0313; Wang PH, 2023, Arxiv, DOI [arXiv:2303.00980, 10.48550/Oiv.2303.00980, DOI 10.48550/OIV.2303.00980]; Wong IA, 2023, J HOSP TOUR MANAG, V56, P253, DOI 10.1016/j.jhtm.2023.06.022	13	2	2	33	33	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0160-7383	1873-7722		ANN TOURISM RES	Ann. Touris. Res.	JAN	2024	104								103723	10.1016/j.annals.2023.103723	http://dx.doi.org/10.1016/j.annals.2023.103723		FEB 2024	4	Hospitality, Leisure, Sport & Tourism; Sociology	Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Sociology	KO3K8					2024-07-03	WOS:001180866300001
J	Du, M				Du, Mark			Machine vs. human, who makes a better judgment on innovation? Take GPT-4 for example	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						noise; creativity; artificial intelligence; large language models (LLM); GPT-4	CREATIVITY	IntroductionHuman decision-making is a complex process that is often influenced by various external and internal factors. One such factor is noise, random, and irrelevant influences that can skew outcomes.MethodsThis essay uses the CAT test and computer simulations to measure creativity.ResultsEvidence indicates that humans are intrinsically prone to noise, leading to inconsistent and, at times, inaccurate decisions. In contrast, simple rules demonstrate a higher level of accuracy and consistency, while artificial intelligence demonstrates an even higher capability to process vast data and employ logical algorithms.DiscussionThe potential of AI, particularly its intuitive capabilities, might be surpassing human intuition in specific decision-making scenarios. This raises crucial questions about the future roles of humans and machines in decision-making spheres, especially in domains where precision is paramount.	[Du, Mark] Natl Taiwan Univ, Dept Comp Sci, New Taipei, Taiwan	National Taiwan University	Du, M (corresponding author), Natl Taiwan Univ, Dept Comp Sci, New Taipei, Taiwan.	arsl4000@gmail.com						Amabile T. M., 1996, Creativity and Innovation in Organizations, V5; AMABILE TM, 1982, J PERS SOC PSYCHOL, V43, P997, DOI 10.1037/0022-3514.43.5.997; Berg JM, 2019, ORGAN BEHAV HUM DEC, V154, P96, DOI 10.1016/j.obhdp.2019.08.004; Berg JM, 2016, ADMIN SCI QUART, V61, P433, DOI 10.1177/0001839216642211; Berg JM, 2014, ORGAN BEHAV HUM DEC, V125, P1, DOI 10.1016/j.obhdp.2014.06.001; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Cao X., 2023, Large Language Models Know How the Personality of Public Figures is Perceived by the General Public; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Digutsch J, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-32248-6; ERICKSON TD, 1981, J VERB LEARN VERB BE, V20, P540, DOI 10.1016/S0022-5371(81)90165-1; Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732; GPT-4, 2023, Open AI; Grant Adam., 2017, ORIGINALS NONCONFORM; Gray K, 2019, AM PSYCHOL, V74, P539, DOI 10.1037/amp0000391; Hagendorff T., 2022, Machine Intuition: Uncovering Human-Like Intuitive Decision-Making in GPT-3; Huang L., 2020, Edge: Turning adversity into advantage; JACOWITZ KE, 1995, PERS SOC PSYCHOL B, V21, P1161, DOI 10.1177/01461672952111004; Jones E, 2022, Arxiv, DOI arXiv:2202.12299; Kim JY, 2022, INFORM TECHNOL PEOPL, V35, P861, DOI 10.1108/ITP-04-2019-0173; Kleinberg J, 2018, Q J ECON, V133, P237, DOI 10.1093/qje/qjx032; Kosinski M, 2023, Theory of mind may have spontaneously emerged in large language models; Logg JM, 2019, ORGAN BEHAV HUM DEC, V151, P90, DOI 10.1016/j.obhdp.2018.12.005; Lopez-Lira A, 2023, Arxiv, DOI arXiv:2304.07619; Meehl P. E., 1954, CLIN VERSUS STAT PRE; Mueller JS, 2012, PSYCHOL SCI, V23, P13, DOI 10.1177/0956797611421018; SIMON HA, 1971, AM PSYCHOL, V26, P145, DOI 10.1037/h0030806; Tu M., 2020, Conference of Marketing Research; TVERSKY A, 1983, PSYCHOL REV, V90, P293, DOI 10.1037/0033-295X.90.4.293; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124	29	1	1	10	23	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	AUG 23	2023	6								1206516	10.3389/frai.2023.1206516	http://dx.doi.org/10.3389/frai.2023.1206516			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	Q7II4	37680588	gold, Green Submitted, Green Published			2024-07-03	WOS:001059219200001
C	Chung, A; Tanaka-Ishii, K			ACM	Chung, Andy; Tanaka-Ishii, Kumiko			Modeling Momentum Spillover with Economic Links Discovered from Financial Documents	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		Economic links; momentum; inattention; graph neural networks; large language models	ATTENTION	Momentum spillover is a market anomaly well-acknowledged in finance literature. This paper proposes using novel economic links discovered from financial documents as a momentum spillover channel, followed by modeling with graph attention networks. These text-based economic links are constructed using contextual embeddings extracted with pre-trained language models from various sections of company annual reports and earnings call transcripts. We examine the effectiveness of our proposed methods based on point-in-time S&P500 constituents from 2010/01/01 to 2022/12/31 in the US stock market. We compare our proposed model against the mean aggregator of peer firms' momentum baseline and Monte Carlo experiments based on randomized nodes or edges. Our results show that our proposed graph neural network model significantly outperforms the peer firm's momentum aggregation baseline. Furthermore, economic links discovered in some sections of company annual reports and earnings call transcripts are useful for modeling momentum spillover. In particular, the economic link constructed from management discussion and analysis from earnings call transcripts outperforms the industry link, which represents the well-acknowledged industry momentum.	[Chung, Andy] Univ Tokyo, Grad Sch Engn, Dept Adv Interdisciplinary Studies, Tokyo, Japan; [Tanaka-Ishii, Kumiko] Waseda Univ, Sch Fundamental Sci & Engn, Dept Comp Sci & Engn, Tokyo, Japan	University of Tokyo; Waseda University	Chung, A (corresponding author), Univ Tokyo, Grad Sch Engn, Dept Adv Interdisciplinary Studies, Tokyo, Japan.	andy@g.ecc.u-tokyo.ac.jp; kumiko@waseda.jp		Chung, Andy/0009-0009-2446-7506				Ali U, 2020, J FINANC ECON, V136, P649, DOI 10.1016/j.jfineco.2019.10.007; Antón M, 2014, J FINANC, V69, P1099, DOI 10.1111/jofi.12149; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Brody S, 2022, Arxiv, DOI [arXiv:2105.14491, DOI 10.48550/ARXIV.2105.14491]; Cheng R, 2021, AAAI CONF ARTIF INTE, V35, P55; Cohen L, 2008, J FINANC, V63, P1977, DOI 10.1111/j.1540-6261.2008.01379.x; Cohen L, 2012, J FINANC ECON, V104, P383, DOI 10.1016/j.jfineco.2011.08.006; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du X, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3353; Gilmer J, 2017, 34 INT C MACHINE LEA, V70; Hirshleifer D, 2003, J ACCOUNT ECON, V36, P337, DOI 10.1016/j.jacceco.2003.10.002; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; JEGADEESH N, 1993, J FINANC, V48, P65, DOI 10.1111/j.1540-6261.1993.tb04702.x; Kingma D. P., 2017, ARXIV; Lee CMC, 2015, J FINANC ECON, V116, P410, DOI 10.1016/j.jfineco.2015.02.003; Maskey S, 2022, Arxiv, DOI arXiv:2202.00645; Matsunaga D, 2019, Arxiv, DOI arXiv:1909.10660; Menzly L, 2010, J FINANC, V65, P1555, DOI 10.1111/j.1540-6261.2010.01578.x; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; Misirli Efdal, 2021, Peer momentum; Moskowitz TJ, 1999, J FINANC, V54, P1249, DOI 10.1111/0022-1082.00146; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P7; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rosa Guilherme Moraes, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P295, DOI 10.1145/3462757.3466103; Song KT, 2020, Arxiv, DOI arXiv:2004.09297; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903	28	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							490	497		10.1145/3604237.3626862	http://dx.doi.org/10.1145/3604237.3626862			8	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		hybrid			2024-07-03	WOS:001124982700057
J	Wang, XF; Sanders, HM; Liu, YC; Seang, K; Tran, BX; Atanasov, AG; Qiu, Y; Tang, SL; Car, J; Wang, YX; Wong, TY; Tham, YC; Chung, KC				Wang, Xiaofei; Sanders, Hayley M.; Liu, Yuchen; Seang, Kennarey; Tran, Bach Xuan; Atanasov, Atanas G.; Qiu, Yue; Tang, Shenglan; Car, Josip; Wang, Ya Xing; Wong, Tien Yin; Tham, Yih-Chung; Chung, Kevin C.			ChatGPT: promise and challenges for deployment in low- and middle-income countries	LANCET REGIONAL HEALTH-WESTERN PACIFIC			English	Article						Large language model; ChatGPT; Public health; Global health; Low to middle income countries; Equity	ARTIFICIAL-INTELLIGENCE; RURAL-AREAS; LANGUAGE; ENGLISH; ERA	In low- and middle-income countries (LMICs), the fields of medicine and public health grapple with numerous challenges that continue to hinder patients' access to healthcare services. ChatGPT, a publicly accessible chatbot, has emerged as a potential tool in aiding public health efforts in LMICs. This viewpoint details the potential benefits of employing ChatGPT in LMICs to improve medicine and public health encompassing a broad spectrum of domains ranging from health literacy, screening, triaging, remote healthcare support, mental health support, multilingual capabilities, healthcare communication and documentation, medical training and education, and support for healthcare professionals. Additionally, we also share potential concerns and limitations associated with the use of ChatGPT and provide a balanced discussion on the opportunities and challenges of using ChatGPT in LMICs.	[Wang, Xiaofei; Liu, Yuchen] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Key Lab Biomech & Mechanobiol,Minist Educ, Beijing, Peoples R China; [Sanders, Hayley M.; Chung, Kevin C.] Univ Michigan, Med Sch, Dept Surg, Sect Plast Surg, Ann Arbor, MI USA; [Seang, Kennarey] Univ Hlth Sci, Grant Management Off, Phnom Penh, Cambodia; [Tran, Bach Xuan] Hanoi Med Univ, Inst Prevent Med & Publ Hlth, Dept Hlth Econ, Hanoi, Vietnam; [Tran, Bach Xuan] Inst Hlth Econ & Technol, Hanoi, Vietnam; [Atanasov, Atanas G.] Med Univ Vienna, Ludwig Boltzmann Inst Digital Hlth & Patient Safe, Spitalgasse 23, A-1090 Vienna, Austria; [Atanasov, Atanas G.] Polish Acad Sci, Inst Genet & Anim Biotechnol, PL-05552 Jastrzebiec, Magdalenka, Poland; [Qiu, Yue] Tsinghua Univ, Inst Hosp Management, Beijing, Peoples R China; [Tang, Shenglan] Duke Univ, Duke Global Hlth Inst, Durham, NC USA; [Car, Josip] Nanyang Technol Univ, Ctr Populat Hlth Sci, Lee Kong Chian Sch Med, Singapore, Singapore; [Car, Josip] Imperial Coll London, Sch Publ Hlth, Dept Primary Care & Publ Hlth, London, England; [Wang, Ya Xing] Capital Med Univ, Beijing Tongren Hosp, Beijing Tongren Eye Ctr, Beijing Ophthalmol & Visual Sci Key Lab,Beijing In, Beijing, Peoples R China; [Wong, Tien Yin; Tham, Yih-Chung] Singapore Natl Eye Ctr, Singapore Eye Res Inst, Singapore, Singapore; [Wong, Tien Yin] Tsinghua Univ, Tsinghua Med, Beijing, Peoples R China; [Wong, Tien Yin] Beijing Tsinghua Changgung Hosp, Sch Clin Med, Beijing, Peoples R China; [Tham, Yih-Chung] Natl Univ Singapore, Ctr Innovat & Precis Eye Hlth, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore, Singapore; [Tham, Yih-Chung] Duke NUS Med Sch, Ophthalmol & Visual Sci Acad Clin Program, Singapore, Singapore; [Tham, Yih-Chung] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore, Singapore; [Chung, Kevin C.] Univ Michigan Hlth Syst, Sect Plast Surg, Taubman Ctr 2130,1500 E Med Ctr Dr,SPC 5340, Ann Arbor, MI 48109 USA	Beihang University; University of Michigan System; University of Michigan; Hanoi Medical University; Medical University of Vienna; Polish Academy of Sciences; Institute of Genetics & Animal Biotechnology, Polish Academy of Sciences; Tsinghua University; Duke University; Nanyang Technological University; Imperial College London; Capital Medical University; National University of Singapore; Singapore National Eye Center; Tsinghua University; National University of Singapore; National University of Singapore; National University of Singapore; University of Michigan System; University of Michigan	Tham, YC (corresponding author), Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore, Singapore.; Chung, KC (corresponding author), Univ Michigan Hlth Syst, Sect Plast Surg, Taubman Ctr 2130,1500 E Med Ctr Dr,SPC 5340, Ann Arbor, MI 48109 USA.	thamyc@nus.edu.sg; kecchung@med.umich.edu	Car, Josip/H-6755-2015; Wong, Tien Yin/AAC-9724-2020; Tham, Yih Chung/IUP-0091-2023; wang, YA XING/K-9671-2016	Car, Josip/0000-0001-8969-371X; Wong, Tien Yin/0000-0002-8448-1264; 				Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Al Shamsi H, 2020, OMAN MED J, V35, P122, DOI 10.5001/omj.2020.40; Al-Shamsi Mustafa, 2017, J Adv Med Educ Prof, V5, P210; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alliance for Affordable Internet, 2020, Meaningful connectivity: a new target to raise the bar for internet access; [Anonymous], How your data is used to improve model performance; [Anonymous], 2023, Historical yearly trends in the usage statistics of content languages for websites; [Anonymous], 2021, BBC News; [Anonymous], 2023, vice30-Mar; [Anonymous], 2023, Bloomberg; [Anonymous], 2023, Wikipedia; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Be my eyes, About us; bemyeyes, Community stories; BERACOCHEA E, 1995, TROP DOCT, V25, P69, DOI 10.1177/004947559502500207; Bommineni VL, 2023, Performance of ChatGPT on the MCAT: the road to personalized and equitable premedical learning; Cao BL, 2020, CURR OPIN INFECT DIS, V33, P44, DOI 10.1097/QCO.0000000000000619; Cao Y, 2023, Arxiv, DOI arXiv:2303.17466; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chan SMH, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03481-w; Chen LJ, 2023, Arxiv, DOI [arXiv:2305.05176, 10.48550/arXiv.2305.05176]; Ciecierski-Holmes T, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00700-y; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; datahelpdesk, World bank country and lending groups-world bank data help desk; Demyttenaere K, 2004, JAMA-J AM MED ASSOC, V291, P2581, DOI 10.1001/jama.291.21.2581; Di Bitetti MS, 2017, AMBIO, V46, P121, DOI 10.1007/s13280-016-0820-7; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Garzon-Chavez D, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251295; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Guo J, 2018, HEALTH EQUITY, V2, P174, DOI 10.1089/heq.2018.0037; Haroz EE, 2016, SOC PSYCH PSYCH EPID, V51, P981, DOI 10.1007/s00127-016-1218-3; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hossain MM, 2021, Int J Artif Intell., V8, P58; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Hulman Adam, 2023, PLoS One, V18, pe0290773, DOI 10.1371/journal.pone.0290773; Iftikhar L, 2023, DocGPT: impact of ChatGPT-3 on health services as a virtual doctor; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Kim JH, 2022, medRxiv, DOI [10.1101/2022.12.16.22283512, 10.1101/2022.12.16.22283512, DOI 10.1101/2022.12.16.22283512V2]; Kimmarita L, Ministry to launch app, chatbot to help counter gender violence; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Li HR, 2023, Arxiv, DOI [arXiv:2304.05197, 10.48550/arXiv.2304.05197]; Love SM, 2018, J GLOB ONCOL, V4, DOI 10.1200/JGO.17.00222; Ly KH, 2017, INTERNET INTERV, V10, P39, DOI 10.1016/j.invent.2017.10.002; MAHER J, 1986, APPL LINGUIST, V7, P206, DOI 10.1093/applin/7.2.206; McCradden MD, 2023, NAT MED, V29, P765, DOI 10.1038/s41591-023-02224-8; Medenilla A., 2023, PLoS Digital Health, V2; Mgbako O, 2020, AIDS BEHAV, V24, P1990, DOI 10.1007/s10461-020-02926-x; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Oh KJ, 2017, IEEE INT CONF MOB DA, P371, DOI 10.1109/MDM.2017.64; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; openai, Usage policies; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Parry Sarah J, 2020, BJPsych Int, V17, P29, DOI 10.1192/bji.2019.24; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rao A., 2023, MEDRXIV; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Saluja S, 2020, BMJ GLOB HEALTH, V5, DOI 10.1136/bmjgh-2019-001535; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Schwalbe N, 2020, LANCET, V395, P1579, DOI 10.1016/S0140-6736(20)30226-9; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Thaver IH, 1998, SOC SCI MED, V46, P1441, DOI 10.1016/S0277-9536(97)10134-4; Ting DS, 2020, BRIT J OPHTHALMOL, V104, P299, DOI 10.1136/bjophthalmol-2019-315066; Tschandl P, 2020, NAT MED, V26, P1229, DOI 10.1038/s41591-020-0942-0; Tu RB, 2023, Arxiv, DOI [arXiv:2301.13819, 10.48550/arXiv.2301.13819]; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; van de Sande D, 2022, BMJ HEALTH CARE INFO, V29, DOI 10.1136/bmjhci-2021-100495; World Health Organization, 1998, IMPROVING HLTH CARE, P5; World Health Organization, 2021, Mental Health Atlas 2020; World Health Organization, 2021, COVID 19 SOCIAL DETE; Xiang Chloe, 2023, VICE; Yadav Deepika, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359272; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhu L, 2023, Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer?	86	22	22	33	77	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2666-6065		LANCET REG HEALTH-W	Lancet Reg. Health-W. Pac.	DEC	2023	41								100905	10.1016/j.lanwpc.2023.100905	http://dx.doi.org/10.1016/j.lanwpc.2023.100905		SEP 2023	14	Health Care Sciences & Services; Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	T8NK4	37731897	gold, Green Published			2024-07-03	WOS:001080494200001
J	Komp-Leukkunen, K				Komp-Leukkunen, Kathrin			How ChatGPT shapes the future labour market situation of software engineers: A Finnish Delphi study	FUTURES			English	Article						Artificial Intelligence; Large Language Models; Software architects; Scenarios; Possible futures; Probable futures	TECHNOLOGY; EMPLOYMENT; JOBS	ChatGPT is changing our working lives, conjuring visions of revolutionary shifts ahead. ChatGPT is a chatbot based on generative artificial intelligence, which can, e.g., write computer code. This article explores how it might shape the future labour market situation of software engineers. A Delphi study with 14 experts was conducted in Finland. The first round identified possible futures, and the second round assessed their probabilities. Five scenarios prevailed: the unlikely scenario that the status quo persists; the ambivalent scenario that ChatGPT can replace software engineers to a large extent; the likely scenario that computer departments in startups embrace ChatGPT; the likely scenario that ChatGPT use proliferates among software engineers to increase productivity; and the highly likely scenario that ChatGPT makes computer programming accessible to the masses. Findings contradict previous discussions that technological advancements might take over especially routine tasks. ChatGPT can also take over non-routine tasks. Moreover, findings underline that digitalisation does not only bring about a choice between upskilling and employability loss, but also a democratisation of knowledge and expertise. Software engineers and companies might use the findings as an impetus for upskilling, while universities might feel nudged to incorporate ChatGPT more strongly into their curricula.	[Komp-Leukkunen, Kathrin] LUT Univ, Dept Social Sci, POB 20, Lappeenranta 53851, Finland	Lappeenranta-Lahti University of Technology LUT	Komp-Leukkunen, K (corresponding author), LUT Univ, Dept Social Sci, POB 20, Lappeenranta 53851, Finland.	kathrin.komp-leukkunen@lut.fi						Ajlouni A. O., 2023, STUDENTSATTITUDES US, V17, P99, DOI [10.3991/ijim.v17i18.41753, DOI 10.3991/IJIM.V17I18.41753]; [Anonymous], 2019, OECD Skills Outlook 2019: Thriving in a Digital World, DOI DOI 10.1787/DF80BC12-EN; Boel A, 2021, J CLIN EPIDEMIOL, V129, P31, DOI 10.1016/j.jclinepi.2020.09.034; Brady SR, 2015, INT J QUAL METH, V14, DOI 10.1177/1609406915621381; Brooke L, 2009, AGEING SOC, V29, P237, DOI 10.1017/S0144686X0800768X; Brynjolfsson E., 2000, UNDERSTANDING DIGITA; Brynjolfsson E., 2023, Working Paper, DOI DOI 10.3386/W31161; Burke Q, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P503, DOI 10.1145/3159450.3159485; Chow T, 2022, SOC SCI-BASEL, V11, DOI 10.3390/socsci11030116; Cohen B, 2017, BUS HORIZONS, V60, P741, DOI 10.1016/j.bushor.2017.06.004; Corfield G., 2023, The TelegraphFebruary 16; Cwikla M, 2023, FUTURES, V153, DOI 10.1016/j.futures.2023.103235; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Dorschel R, 2022, NEW TECH WORK EMPLOY, V37, P288, DOI 10.1111/ntwe.12225; Douglas H., 2022, Principles of social research methodology, P415, DOI [10.1007/978-981-19-5441-2_29, DOI 10.1007/978-981-19-5441-2_29]; Eccles H, 2020, J OCCUP ENVIRON MED, V62, P171, DOI 10.1097/JOM.0000000000001797; Eurostat, 2023, Employed ICT specialists-total; Fernández-Macías E, 2017, SOCIO-ECON REV, V15, P563, DOI 10.1093/ser/mww016; Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019; Glaser B. G., 1978, THEORETICAL SENSITIV; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Gorgon E, 2019, J CLIN EPIDEMIOL, V108, P110, DOI 10.1016/j.jclinepi.2018.12.010; Gruetzemacher R, 2022, FUTURES, V135, DOI 10.1016/j.futures.2021.102884; Hasson F, 2011, TECHNOL FORECAST SOC, V78, P1695, DOI 10.1016/j.techfore.2011.04.005; Kashefi A., 2023, Journal of Machine Learning for Modeling and Computing, V4, P1, DOI DOI 10.1615/JMACHLEARNMODELCOMPUT.2023048492; Kim J, 2020, ASIAN-PAC ECON LIT, V34, P3, DOI 10.1111/apel.12299; Kim S, 2021, HUM RESOUR MANAGE-US, V60, P229, DOI 10.1002/hrm.22049; Komp-Leukkunen K., 2022, The Journal of Aging and Social Change, V12, P37, DOI 10.18848/2576-5310; Komp-Leukkunen K, 2023, GERONTOLOGIST, V63, P1413, DOI 10.1093/geront/gnac181; Komp-Leukkunen K, 2020, FUTURES, V124, DOI 10.1016/j.futures.2020.102651; Kurer T, 2019, RES POLITICS, V6, DOI 10.1177/2053168018822142; Lautenschläger A, 2015, J SMALL BUS ENTERP D, V22, P143, DOI 10.1108/JSBED-09-2011-0006; Makridakis S, 2017, FUTURES, V90, P46, DOI 10.1016/j.futures.2017.03.006; Marasco E., 2022, P CAN ENG ED ASS C C, DOI [10.24908/pceea.vi.15970, DOI 10.24908/PCEEA.VI.15970]; Marshall VW, 2011, J APPL GERONTOL, V30, P185, DOI 10.1177/0733464810367791; Mauno T, 2023, FOREST POLICY ECON, V157, DOI 10.1016/j.forpol.2023.103075; Mayer KU, 2009, ANNU REV SOCIOL, V35, P413, DOI 10.1146/annurev.soc.34.040507.134619; Mayring P, 2015, ADVNCS MTHMTCS EDUC, P365, DOI 10.1007/978-94-017-9181-6_13; Mead NR, 2009, J SYST SOFTWARE, V82, P571, DOI 10.1016/j.jss.2008.12.038; Meade A., 2023, The GuardianJuly 31; Merow C, 2023, NAT ECOL EVOL, V7, P960, DOI 10.1038/s41559-023-02063-3; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Mollman S., 2023, Fortune; Niederberger M, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.00457; Nizami N., 2017, Decent work: Concepts, theory and measurement; Nowack M, 2011, TECHNOL FORECAST SOC, V78, P1603, DOI 10.1016/j.techfore.2011.03.006; OpenAI, 2023, Introducing chatgpt; Ozpolat Z., 2023, European Journal of Technique, V13, P220, DOI [10.36222/ejt.1330631, DOI 10.36222/EJT.1330631]; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Rantanen V., 2023, Nordic Journal of Working Life Studies, DOI [10.18291/njwls.137865, DOI 10.18291/NJWLS.137865]; Rintamäki H, 2016, FUTURES, V83, P64, DOI 10.1016/j.futures.2016.03.004; Rivas P, 2023, AI-BASEL, V4, P375, DOI 10.3390/ai4020019; Rowe G, 2001, INT SER OPER RES MAN, V30, P125, DOI 10.1007/978-0-306-47630-3_7; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Shelton K., 2018, Handbook of research on innovation techniques, trends, and analysis for optimized research methods, P233, DOI [DOI 10.4018/978-1-5225-5164-5.CH015, 10.4018/978-1-5225-5164-5.ch015]; Simmons L., 2023, Zeit onlineApril 28; Sitra, 2022, Sitra's statement on the draft for Finland's digital compass; Smolander K., 2023, Ohjelmistot Suomessa 2023-2033 [Software in Finland]; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Taylor E, 2020, HERD-HEALTH ENV RES, V13, P11, DOI 10.1177/1937586719887709; Uden L., 2004, International Journal of Continuing Engineering Education and Life-Long Learning, V14, P101, DOI 10.1504/IJCEELL.2004.004578; Upadhya C., 2011, ELITE EVERYMAN CULTU, P167; Wang Y., 2008, Software engineering foundations: A software science perspective; Wiedner J, 2022, SOC FORCES, V101, P150, DOI 10.1093/sf/soab120; World Economic Forum, 2023, The Future of Jobs Report 2023; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yu J, 2023, REV BUS, V44, P53; Zarifhonarvar A., 2023, Journal of Electronic Business & Digital Economics, Advance Online Publication, DOI DOI 10.1108/JEBDE-10-2023-0021; Sossa JWZ, 2019, FORESIGHT, V21, P525, DOI 10.1108/FS-11-2018-0095	70	0	0	0	0	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0016-3287	1873-6378		FUTURES	Futures	JUN	2024	160								103382	10.1016/j.futures.2024.103382	http://dx.doi.org/10.1016/j.futures.2024.103382			11	Economics; Regional & Urban Planning	Social Science Citation Index (SSCI)	Business & Economics; Public Administration	QJ7F1		hybrid			2024-07-03	WOS:001220565000001
J	Lindemann, NF				Lindemann, Nora Freya			Chatbots, search engines, and the sealing of knowledges	AI & SOCIETY			English	Article; Early Access						Chatbots; Large language models; Search; Situated knowledge; Sealed surfaces; Sealing of knowledges		In 2023, online search engine provider Microsoft integrated a language model that provides direct answers to search queries into its search engine Bing. Shortly afterwards, Google also introduced a similar feature to its search engine with the launch of Google Gemini. This introduction of direct answers to search queries signals an important and significant change in online search. This article explores the implications of this new search paradigm. Drawing on Donna Haraway's theory of Situated Knowledges and Rainer Muhlhoff's concept of Sealed Surfaces, I introduce the term Sealed Knowledges to draw attention to the increasingly difficult access to the plurality of potential answers to search queries through the output of a singular, authoritative, and plausible text paragraph. I argue that the integration of language models for the provision of direct answers into search engines is based on a de-situated and disembodied understanding of knowledge and affects the subjectivities of its users. At the same time, the sealing of knowledges can lead to an increasing spread of misinformation and may make marginalized knowledge increasingly difficult to find. The paper concludes with an outlook on how to resist the increasing sealing of knowledges in online search.	[Lindemann, Nora Freya] Univ Osnabruck, Inst Cognit Sci, Osnabruck, Germany	University Osnabruck	Lindemann, NF (corresponding author), Univ Osnabruck, Inst Cognit Sci, Osnabruck, Germany.	norafreya.lindemann@uni-osnabrueck.de			Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL. No funding was received to assist with the preparation of this manuscript.	Ahmed S, 2008, Blackwell concise companions to literature and culture. A concise companion to feminist theory, P236; AlgorithmWatch and AI Forensics, 2023, ChatGPT and Co: are AI-driven search engines a threat to democratic elections?; Amershi B, 2020, AI SOC, V35, P417, DOI 10.1007/s00146-019-00885-z; Amoore Louise, 2020, Cloud ethics: algorithms and the attributes of ourselves and others; Anderson E., 2012, The Stanford Encyclopedia of Philosophy, VFall 2012; [Anonymous], 2010, Der Google Komplex: Uber Macht im Zeitalter des Internets; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Google, Gemini: supercharge your creativity and productivity; Gusbeth S, 2023, Handelsblatt; HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066; Haraway D.J., 2016, Staying with the Trouble; Harding Sandra, 1986, Feminist Epistemologies; hooks bell., 2020, APPL THEATRE READER, V2nd, P203; Huang Z, 2023, BloombergJanuary 30; Introna LD, 2000, INFORM SOC, V16, P169, DOI 10.1080/01972240050133634; Kammler C, 2014, Foucault Handbuch: Leben-Werk-Wirkung, DOI [10.1007/978-3-476-01378-1, DOI 10.1007/978-3-476-01378-1]; Kissinger H., 2021, The age of AI: And our human future, VFirst; Lindern J, 2023, Zeit Online; McLaren MA, 2002, SUNY series in contemporary continental philosophy; Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Milmo D, 2023, The Guardian; Muhlhoff R, 2018, Leviathan-Berliner Zeitschrift Fur Sozialwissenschaft, V46, P551, DOI [10.5771/0340-0425-2018-4-551, DOI 10.5771/0340-0425-2018-4-551]; Muhlhoff R, Ethics of AI in the digital media age: power, critique, responsibility; Nayak Pandu, 2019, Understanding searches better than ever before; Pichai S, 2023, Introducing gemini: Our largest and most capable ai model; Pichai S., 2023, Google; Potthast Martin, 2020, ACM SIGIR Forum, V54, DOI 10.1145/3451964.3451978; Reputation911, 2023, Do people click on the second page of Google?; Segev E, 2008, Webology, V5, P1; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816; Southern M., 2020, Over 25% of people click the first google search result; Stanley L., 1990, FEMINIST PRAXIS RES, P20, DOI DOI 10.1177/107780049700300303; Stockdale K, 2023, Twitter; Traweek S., 1988, Beamtimes and Lifetimes: The world of high energy physicists, VRevised edition; van Dijck J, 2010, INT J CULTURAL STUD, V13, P574, DOI 10.1177/1367877910376582; Vogelmann F, 2017, Foucault lesen, DOI [10.1007/978-3-658-15474-5, DOI 10.1007/978-3-658-15474-5]; Waldby C., 1995, Transitions: New Australian feminisms; Wikimedia Statistics, Total page views	39	0	0	5	5	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2024 APR 22	2024										10.1007/s00146-024-01944-w	http://dx.doi.org/10.1007/s00146-024-01944-w		APR 2024	14	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	OH7U9		hybrid			2024-07-03	WOS:001206455500002
J	Ghanem, YK; Rouhi, AD; Al-Houssan, A; Saleh, Z; Moccia, MC; Joshi, H; Dumon, KR; Hong, Y; Spitz, F; Joshi, AR; Kwiatt, M				Ghanem, Yazid K.; Rouhi, Armaun D.; Al-Houssan, Ammr; Saleh, Zena; Moccia, Matthew C.; Joshi, Hansa; Dumon, Kristoffel R.; Hong, Young; Spitz, Francis; Joshi, Amit R.; Kwiatt, Michael			Dr. Google to Dr. ChatGPT: assessing the content and quality of artificial intelligence-generated medical information on appendicitis	SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES			English	Article						Artificial intelligence; Large language models; ChatGPT; Appendicitis; Health literacy; Online medical information		IntroductionGenerative artificial intelligence (AI) chatbots have recently been posited as potential sources of online medical information for patients making medical decisions. Existing online patient-oriented medical information has repeatedly been shown to be of variable quality and difficult readability. Therefore, we sought to evaluate the content and quality of AI-generated medical information on acute appendicitis.MethodsA modified DISCERN assessment tool, comprising 16 distinct criteria each scored on a 5-point Likert scale (score range 16-80), was used to assess AI-generated content. Readability was determined using the Flesch Reading Ease (FRE) and Flesch-Kincaid Grade Level (FKGL) scores. Four popular chatbots, ChatGPT-3.5 and ChatGPT-4, Bard, and Claude-2, were prompted to generate medical information about appendicitis. Three investigators independently scored the generated texts blinded to the identity of the AI platforms.ResultsChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 had overall mean (SD) quality scores of 60.7 (1.2), 62.0 (1.0), 62.3 (1.2), and 51.3 (2.3), respectively, on a scale of 16-80. Inter-rater reliability was 0.81, 0.75, 0.81, and 0.72, respectively, indicating substantial agreement. Claude-2 demonstrated a significantly lower mean quality score compared to ChatGPT-4 (p = 0.001), ChatGPT-3.5 (p = 0.005), and Bard (p = 0.001). Bard was the only AI platform that listed verifiable sources, while Claude-2 provided fabricated sources. All chatbots except for Claude-2 advised readers to consult a physician if experiencing symptoms. Regarding readability, FKGL and FRE scores of ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 were 14.6 and 23.8, 11.9 and 33.9, 8.6 and 52.8, 11.0 and 36.6, respectively, indicating difficulty readability at a college reading skill level.ConclusionAI-generated medical information on appendicitis scored favorably upon quality assessment, but most either fabricated sources or did not provide any altogether. Additionally, overall readability far exceeded recommended levels for the public. Generative AI platforms demonstrate measured potential for patient education and engagement about appendicitis.	[Ghanem, Yazid K.; Saleh, Zena; Moccia, Matthew C.; Joshi, Hansa; Hong, Young; Spitz, Francis; Joshi, Amit R.; Kwiatt, Michael] Cooper Univ Hosp, Dept Surg, 3 Cooper Plaza Suite 411, Camden, NJ 08103 USA; [Rouhi, Armaun D.; Dumon, Kristoffel R.] Univ Penn, Perelman Sch Med, Dept Surg, Philadelphia, PA USA; [Al-Houssan, Ammr] Univ Connecticut, Dept Surg, Hartford, CT USA; [Ghanem, Yazid K.; Hong, Young; Spitz, Francis; Joshi, Amit R.; Kwiatt, Michael] Rowan Univ, Cooper Med Sch, Camden, NJ 08102 USA	Cooper University Hospital; University of Pennsylvania; University of Connecticut; Rowan University; Cooper Medical School of Rowan University	Ghanem, YK (corresponding author), Cooper Univ Hosp, Dept Surg, 3 Cooper Plaza Suite 411, Camden, NJ 08103 USA.; Ghanem, YK (corresponding author), Rowan Univ, Cooper Med Sch, Camden, NJ 08102 USA.	ghanem-yazidkhalilmo@cooperhealth.edu		Ghanem, Yazid Khalil Mousa/0000-0002-0113-9632; Joshi, Hansa/0000-0003-2656-9265; Moccia, Matthew/0009-0008-4607-3615; Rouhi, Armaun/0000-0002-7724-1457				Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40977; American College of Surgeons Division of Education, 2022, APPENDECTOMY; [Anonymous], 1994, Clear and simple: Developing effective print materials for low literate readers; Baumann E, 2020, BUNDESGESUNDHEITSBLA, V63, P1151, DOI 10.1007/s00103-020-03192-x; Charnock D, 1999, J EPIDEMIOL COMMUN H, V53, P105, DOI 10.1136/jech.53.2.105; Daraz L, 2018, AM J MED QUAL, V33, P487, DOI 10.1177/1062860617751639; Duarte F., 2024, Exploding Topics; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Link E., 2020, BUNDESGESUNDHEITSBLA, V63, P681, DOI [https://doi.org/10.1007/s00103-020-03144-5, DOI 10.1007/S00103-020-03144-5]; Massie PL, 2024, J SURG RES, V293, P727, DOI 10.1016/j.jss.2023.09.018; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Moons P, 2024, EUR J CARDIOVASC NUR, V23, P122, DOI 10.1093/eurjcn/zvad087; Moris D, 2021, JAMA-J AM MED ASSOC, V326, P2299, DOI 10.1001/jama.2021.20502; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Ron L., 2023, JAMA INTERN MED, V183, P596, DOI [10.1001/jamainternmed.2023.1835, DOI 10.1001/JAMAINTERNMED.2023.1835]; Rouhi AD, 2023, SURG-J R COLL SURG E, V21, pe195, DOI 10.1016/j.surge.2022.12.002; Rouhi AD, 2023, ARTIF ORGANS, V47, P1029, DOI 10.1111/aor.14479; Rouhi AD, 2023, OBES SURG, V33, P397, DOI 10.1007/s11695-022-06385-2; Rouhi AD, 2023, J SURG ONCOL, V127, P699, DOI 10.1002/jso.27143; Rouhi AD, 2023, J GASTROINTEST SURG, V27, P598, DOI 10.1007/s11605-022-05460-4; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Smink D, 2023, MANAGEMENT ACUTE APP; Trutner ZD, 2023, J SURG RES, V291, P720, DOI 10.1016/j.jss.2023.06.044; Weiss BD., 2003, Health Literacy: A Manual for Clinicians; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	32	4	4	17	17	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0930-2794	1432-2218		SURG ENDOSC	Surg. Endosc.	MAY	2024	38	5					2887	2893		10.1007/s00464-024-10739-5	http://dx.doi.org/10.1007/s00464-024-10739-5		MAR 2024	7	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	PT5W2	38443499	hybrid, Green Accepted			2024-07-03	WOS:001176403700002
J	Klymenko, R; de Kroon, E; Agostinho, LLF; Fuchs, EC; Woisetschläger, J; Hoeben, WFLM				Klymenko, Roman; de Kroon, Esther; Agostinho, Luewton L. F.; Fuchs, Elmar C.; Woisetschlaeger, Jakob; Hoeben, Wilfred F. L. M.			Characterization of a hyperbolic vortex plasma reactor for the removal of aqueous phase micropollutants	JOURNAL OF PHYSICS D-APPLIED PHYSICS			English	Article						micropollutants; hyperbolic vortex; plasma treatment; pharmaceuticals; PFAS	WASTE-WATER TREATMENT; ADVANCED OXIDATION PROCESSES; DISCHARGE PLASMA; PHARMACEUTICALS; SUBSTANCES; FATE; PERFLUOROALKYL; BEHAVIOR	The present study focuses on the characterization of a hyperbolic vortex plasma reactor through the comparison of various plasma-atmospheric regimes for the production efficiency of reactive nitrogen (RNS) and reactive oxygen (ROS) species. The research also explores effectiveness in the removal of micropollutants, including pharmaceuticals and per- and polyfluoroalkyl substances (PFAS). The technology includes several degradation mechanisms, such as advanced oxidation, ultraviolet photolysis, ozonation, electrolysis, and shockwave water purification, without the need for additional chemicals. Our results indicate that the plasma of bipolar or 'flashover' mode is notably more effective and efficient than both positive or negative polarity. Through the testing of various energy levels, it has been demonstrated that higher energy plasma yields lower efficiency but necessitates shorter treatment times compared to lower energy treatment. When plasma is produced under ambient atmosphere, water chemical properties change significantly in comparison to treatment under argon (Ar) or nitrogen (N2) due to the presence of both oxygen and N2 molecules. In a N2 atmosphere, the predominant formation is of RNS due to the chemical reactivity of N2 exited states, whereas under Ar atmosphere, predominantly ROS are generated. Notable advantages of this technology are its scalability and its low energy requirements. The scalability of the technology involves increasing the size of the reactor, the power and electrode count.	[Klymenko, Roman; de Kroon, Esther; Agostinho, Luewton L. F.; Fuchs, Elmar C.] European Ctr Excellence Sustainable Water Technol, Wetsus, Leeuwarden, Netherlands; [Klymenko, Roman; Hoeben, Wilfred F. L. M.] Eindhoven Univ Technol, Dept Elect Engn, Elect Energy Syst Grp, Eindhoven, Netherlands; [Agostinho, Luewton L. F.] NHL Stenden Univ Appl Sci, Water Technol Res Grp, Leeuwarden, Netherlands; [Fuchs, Elmar C.] Univ Twente, Twente, Netherlands; [Woisetschlaeger, Jakob] Graz Univ Technol, Inst Thermal Turbomachinery & Machine Dynam, Graz, Austria	Eindhoven University of Technology; NHL Stenden University of Applied Sciences; University of Twente; Graz University of Technology	Klymenko, R (corresponding author), European Ctr Excellence Sustainable Water Technol, Wetsus, Leeuwarden, Netherlands.; Klymenko, R (corresponding author), Eindhoven Univ Technol, Dept Elect Engn, Elect Energy Syst Grp, Eindhoven, Netherlands.	roman.klymenko@wetsus.nl		Fuchs, Elmar C./0000-0001-8632-2702; Hoeben, W. F. L. M./0000-0003-3390-8026; Klymenko, Roman/0009-0002-2351-8550	Marie Sklodowska-Curie; Applied Water Physics theme; Dutch Ministry of Economic Affairs and Ministry of Infrastructure and Environment, The Province of Friesland; Northern Netherlands Provinces [665874, 2023]; European Union's Horizon 2020 research and innovation program under the Marie Sklodowska-Curie Grant	Marie Sklodowska-Curie(Marie Curie Actions); Applied Water Physics theme; Dutch Ministry of Economic Affairs and Ministry of Infrastructure and Environment, The Province of Friesland; Northern Netherlands Provinces; European Union's Horizon 2020 research and innovation program under the Marie Sklodowska-Curie Grant(Marie Curie ActionsHorizon 2020)	This work was performed in the cooperation framework of Wetsus European Center of Excellence for Sustainable Water Technology (www.wetsus.eu) within the Applied Water Physics theme. Wetsus is cofounded by the Dutch Ministry of Economic Affairs and Ministry of Infrastructure and Environment, The Province of Friesland and the Northern Netherlands Provinces. This research has received funding from the European Union's Horizon 2020 research and innovation program under the Marie Sklodowska-Curie Grant Agreement No. 665874 and the Gilbert-Armstrong lab. During the preparation of this work, the authors used OpenAI (2023) ChatGPT (version 3.5) [Large language model] in order to structure text and DeepL SE (2023) DeepL API [Document translation application programming interface] for a stylistic text translation. After using these tools, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.	Agostinho L, 2022, WATER-SUI, V14, DOI 10.3390/w14050771; Ajo P, 2018, J ENVIRON CHEM ENG, V6, P1569, DOI 10.1016/j.jece.2018.02.007; Barjasteh A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083372; Bonato M, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17218020; Bruggeman P. J., 2021, J. Appl. Phys, V130, P200401, DOI [10.1063/5.0078076, DOI 10.1063/5.0078076]; Byeon YS, 2017, PLASMA CHEM PLASMA P, V37, P1405, DOI 10.1007/s11090-017-9823-9; Clara M, 2005, WATER RES, V39, P4797, DOI 10.1016/j.watres.2005.09.015; Dhore R, 2021, BIORESOURCE TECHNOL, V341, DOI 10.1016/j.biortech.2021.125808; Elton M D., 2017, Undergrad. J. Math. Model.: One + Two, V7, P1, DOI [10.5038/2326-3652.7.2.4876, DOI 10.5038/2326-3652.7.2.4876]; Foster JE, 2017, PHYS PLASMAS, V24, DOI 10.1063/1.4977921; Fridman A, 2008, PLASMA CHEMISTRY, P1, DOI 10.1017/CBO9780511546075; Groele JR, 2021, J APPL PHYS, V130, DOI 10.1063/5.0039264; Gros M, 2010, ENVIRON INT, V36, P15, DOI 10.1016/j.envint.2009.09.002; Gworek B, 2019, ACTA POL PHARM, V76, P397, DOI 10.32383/appdr/103368; Hoeben WFLM, 2019, PLASMA CHEM PLASMA P, V39, P597, DOI 10.1007/s11090-019-09976-7; Huang Y, 2020, WATER RES, V174, DOI 10.1016/j.watres.2020.115587; I. T. . R. Council and P. Team, 2022, PFAS Technical and Regulatory Guidance Document and Fact Sheets; Jiang B, 2014, CHEM ENG J, V236, P348, DOI 10.1016/j.cej.2013.09.090; Khasawneh OFS, 2021, PROCESS SAF ENVIRON, V150, P532, DOI 10.1016/j.psep.2021.04.045; Klymenko Roman, 2023, J Vis Exp, DOI 10.3791/64516; Kumar A, 2021, EUR PHYS J D, V75, DOI 10.1140/epjd/s10053-021-00283-5; Li F, 2020, CHEM ENG J, V380, DOI 10.1016/j.cej.2019.122506; Li WC, 2014, ENVIRON POLLUT, V187, P193, DOI 10.1016/j.envpol.2014.01.015; Machala Z, 2019, J PHYS D APPL PHYS, V52, DOI 10.1088/1361-6463/aae807; Magureanu M, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aacd9c; McCarthy C, 2017, CURR POLLUT REP, V3, P289, DOI 10.1007/s40726-017-0070-8; Miklos DB, 2018, WATER RES, V139, P118, DOI 10.1016/j.watres.2018.03.042; Mojiri A, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132580; Nau-Hix C, 2021, ACS EST WATER, V1, P680, DOI 10.1021/acsestwater.0c00170; Ngqwala NP, 2020, S AFR J SCI, V116, P42, DOI 10.17159/sajs.2020/5730; Nijdam S., 2012, An Introduction to Nonequilibrium Plasmas at Atmospheric Pressure; Olsavsky NJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196921; Rahman MF, 2014, WATER RES, V50, P318, DOI 10.1016/j.watres.2013.10.045; Reungoat J, 2012, WATER RES, V46, P863, DOI 10.1016/j.watres.2011.11.064; Richardson SD, 2017, ENVIRON TECHNOL INNO, V8, P40, DOI 10.1016/j.eti.2017.04.002; Sakudo A, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20205216; Sharma S, 2022, CHEM ENG J, V430, DOI 10.1016/j.cej.2021.132895; Shaw P, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29549-6; Singh RK, 2019, ENVIRON SCI TECHNOL, V53, P2731, DOI 10.1021/acs.est.8b07031; Snyder SA, 2003, ENVIRON ENG SCI, V20, P449, DOI 10.1089/109287503768335931; Vucic MR, 2021, PROCESS SAF ENVIRON, V149, P786, DOI 10.1016/j.psep.2021.03.039; Xu ZM, 2018, BIOELECTROCHEMISTRY, V121, P125, DOI 10.1016/j.bioelechem.2018.01.012; Yadav S, 2022, CHEM ENG RES DES, V182, P667, DOI 10.1016/j.cherd.2022.04.009; Zeghioud H, 2020, J WATER PROCESS ENG, V38, DOI 10.1016/j.jwpe.2020.101664; Ziylan-Yavas A, 2022, ENVIRON PROG SUSTAIN, V41, DOI 10.1002/ep.13821	45	0	0	11	11	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0022-3727	1361-6463		J PHYS D APPL PHYS	J. Phys. D-Appl. Phys.	MAY 24	2024	57	21							215204	10.1088/1361-6463/ad2b22	http://dx.doi.org/10.1088/1361-6463/ad2b22			15	Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Physics	JY4W0		hybrid			2024-07-03	WOS:001176716600001
J	Shrestha, N; Shen, ZK; Zaidat, B; Duey, AH; Tang, JE; Ahmed, W; Hoang, T; Mejia, MR; Rajjoub, R; Markowitz, JS; Kim, JS; Cho, SK				Shrestha, Nancy; Shen, Zekun; Zaidat, Bashar; Duey, Akiro H.; Tang, Justin E.; Ahmed, Wasil; Hoang, Timothy; Mejia, Mateo Restrepo; Rajjoub, Rami; Markowitz, Jonathan S.; Kim, Jun S.; Cho, Samuel K.			Performance of ChatGPT on NASS Clinical Guidelines for the Diagnosis and Treatment of Low Back Pain	SPINE			English	Article						clinical guidelines; low back pain; ChatGPT; artificial intelligence; large language models	GLOBAL BURDEN; DISABILITY; QUALITY; DISEASE	Study Design.Comparative analysis.Objective.To evaluate Chat Generative Pre-trained Transformer (ChatGPT's) ability to predict appropriate clinical recommendations based on the most recent clinical guidelines for the diagnosis and treatment of low back pain.Background.Low back pain is a very common and often debilitating condition that affects many people globally. ChatGPT is an artificial intelligence model that may be able to generate recommendations for low back pain.Materials and Methods.Using the North American Spine Society Evidence-Based Clinical Guidelines as the gold standard, 82 clinical questions relating to low back pain were entered into ChatGPT (GPT-3.5) independently. For each question, we recorded ChatGPT's answer, then used a point-answer system-the point being the guideline recommendation and the answer being ChatGPT's response-and asked ChatGPT if the point was mentioned in the answer to assess for accuracy. This response accuracy was repeated with one caveat-a prior prompt is given in ChatGPT to answer as an experienced orthopedic surgeon-for each question by guideline category. A two-sample proportion z test was used to assess any differences between the preprompt and postprompt scenarios with alpha=0.05.Results.ChatGPT's response was accurate 65% (72% postprompt, P=0.41) for guidelines with clinical recommendations, 46% (58% postprompt, P=0.11) for guidelines with insufficient or conflicting data, and 49% (16% postprompt, P=0.003*) for guidelines with no adequate study to address the clinical question. For guidelines with insufficient or conflicting data, 44% (25% postprompt, P=0.01*) of ChatGPT responses wrongly suggested that sufficient evidence existed.Conclusion.ChatGPT was able to produce a sufficient clinical guideline recommendation for low back pain, with overall improvements if initially prompted. However, it tended to wrongly suggest evidence and often failed to mention, especially postprompt, when there is not enough evidence to adequately give an accurate recommendation.	[Shrestha, Nancy] Rosalind Franklin Univ, Chicago Med Sch, N Chicago, IL USA; [Shen, Zekun; Zaidat, Bashar; Duey, Akiro H.; Tang, Justin E.; Ahmed, Wasil; Hoang, Timothy; Rajjoub, Rami] Icahn Sch Med Mt Sinai, New York, NY USA; [Mejia, Mateo Restrepo; Markowitz, Jonathan S.; Kim, Jun S.; Cho, Samuel K.] Mt Sinai Hlth Syst, Dept Neurosurg, New York, NY USA; [Cho, Samuel K.] Mt Sinai West, 787,11th Ave,7th Floor, New York, NY 10019 USA	Rosalind Franklin University of Medicine & Science; Chicago Medical School; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Mount Sinai West	Cho, SK (corresponding author), Mt Sinai West, 787,11th Ave,7th Floor, New York, NY 10019 USA.	nancy.shrestha@my.rfums.org; bruceshenzk@gmail.com; bashar.zaidat@icahn.mssm.edu; akiro.duey@icahn.mssm.edu; justin.tang@icahn.mssm.edu; wasil.ahmed@icahn.mssm.edu; timothy.hoang@icahn.mssm.edu; mateo.restrepomejia@icahn.mssm.edu; moutie.rajjoub@icahn.mssm.edu; Jonathan.Markowitz@mountsinai.org; Jun.Kim@mountsinai.org; Samuel.Cho@mountsinai.org						Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Balagué F, 2012, LANCET, V379, P482, DOI 10.1016/S0140-6736(11)60610-7; Butler L, 2003, SPINE, V28, P395, DOI 10.1097/00007632-200302150-00017; Delitto A, 2012, J ORTHOP SPORT PHYS, V42, pA1, DOI 10.2519/jospt.2012.42.4.A1; Duarte F., 2023, Exploding topics; Gremeaux V., 2007, Annales de Readaptation et de Medecine Physique, V50, P85, DOI 10.1016/j.annrmp.2006.09.003; Harwood KJ, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-08092-1; healthquality, VA/DoD Clinical Practice Guidelines; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Hoy D, 2014, ANN RHEUM DIS, V73, P968, DOI 10.1136/annrheumdis-2013-204428; Hu K., 2023, REUTERS, V12; Kreiner DS, 2020, SPINE J, V20, P998, DOI 10.1016/j.spinee.2020.04.006; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Murray CJL, 2018, LANCET, V392, P1995, DOI [10.1016/s0140-6736(18)32279-7, 10.1016/S0140-6736(18)32279-7, 10.1016/s0140-6736(18)32278-5]; Neogi T, 2013, OSTEOARTHR CARTILAGE, V21, P1145, DOI 10.1016/j.joca.2013.03.018; Ng JY, 2021, INTEGR MED RES, V10, DOI 10.1016/j.imr.2020.100692; openai, GPT-4; openai, INTRO CHATGPT; platform.openai, OpenAI platform; Qaseem Amir, 2017, Ann Intern Med, V166, P514, DOI 10.7326/M16-2367; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Walsh M., 2023, ChatGPT statistics (2023)-essential facts and figures; Yamaguchi Y, 2020, J MED INTERNET RES, V22, DOI 10.2196/18684	24	0	0	0	0	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0362-2436	1528-1159		SPINE	SPINE	MAY 1	2024	49	9					640	651		10.1097/BRS.0000000000004915	http://dx.doi.org/10.1097/BRS.0000000000004915			12	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	SJ8I2					2024-07-03	WOS:001234173500006
J	Andreadis, K; Newman, DR; Twan, C; Shunk, A; Mann, DM; Stevens, ER				Andreadis, Katerina; Newman, Devon R.; Twan, Chelsea; Shunk, Amelia; Mann, Devin M.; Stevens, Elizabeth R.			Mixed methods assessment of the influence of demographics on medical advice of ChatGPT	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						artificial intelligence; large language model; ChatGPT; symptom checker; digital health; bias	TOOL	Objectives: To evaluate demographic biases in diagnostic accuracy and health advice between generative artificial intelligence (AI) (ChatGPT GPT-4) and traditional symptom checkers like WebMD. Materials and Methods: Combination symptom and demographic vignettes were developed for 27 most common symptom complaints. Standardized prompts, written from a patient perspective, with varying demographic permutations of age, sex, and race/ethnicity were entered into ChatGPT (GPT-4) between July and August 2023. In total, 3 runs of 540 ChatGPT prompts were compared to the corresponding WebMD Symptom Checker output using a mixed-methods approach. In addition to diagnostic correctness, the associated text generated by ChatGPT was analyzed for readability (using Flesch-Kincaid Grade Level) and qualitative aspects like disclaimers and demographic tailoring. Results: ChatGPT matched WebMD in 91% of diagnoses, with a 24% top diagnosis match rate. Diagnostic accuracy was not significantly different across demographic groups, including age, race/ethnicity, and sex. ChatGPT's urgent care recommendations and demographic tailoring were presented significantly more to 75-year-olds versus 25-year-olds (P < .01) but were not statistically different among race/ethnicity and sex groups. The GPT text was suitable for college students, with no significant demographic variability. Discussion: The use of non-health-tailored generative AI, like ChatGPT, for simple symptom-checking functions provides comparable diagnostic accuracy to commercially available symptom checkers and does not demonstrate significant demographic bias in this setting. The text accompanying differential diagnoses, however, suggests demographic tailoring that could potentially introduce bias. Conclusion: These results highlight the need for continued rigorous evaluation of AI-driven medical platforms, focusing on demographic biases to ensure equitable care.	[Andreadis, Katerina; Newman, Devon R.; Twan, Chelsea; Shunk, Amelia; Mann, Devin M.; Stevens, Elizabeth R.] NYU Grossman Sch Med, Dept Populat Hlth, New York, NY 10016 USA; [Newman, Devon R.] Brown Univ, Providence, RI 02912 USA; [Mann, Devin M.] NYU Langone Hlth, Med Ctr Informat Technol, New York, NY 10016 USA; [Stevens, Elizabeth R.] NYU Langone Hlth, NYU Grossman Sch Med, Dept Populat Hlth, 227 E 30th St,6th Floor, New York, NY 10016 USA	Brown University; NYU Langone Medical Center; NYU Langone Medical Center	Stevens, ER (corresponding author), NYU Langone Hlth, NYU Grossman Sch Med, Dept Populat Hlth, 227 E 30th St,6th Floor, New York, NY 10016 USA.	elizabeth.stevens@nyulangone.org	Andreadis, Katerina/ITU-0700-2023	Andreadis, Katerina/0000-0001-8586-450X; Newman, Devon/0009-0004-8143-1319				Anastasio Albert Thomas, 2023, Foot Ankle Orthop, V8, p24730114231209919, DOI 10.1177/24730114231209919; [Anonymous], WebMD symptom checker; [Anonymous], OpenAI API Reference; [Anonymous], MayoClinic Symptom Checker; Arora VM, 2020, JAMA-J AM MED ASSOC, V324, P2367, DOI 10.1001/jama.2020.4263; Bach RL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234663; Baur C, 2014, HEALTH PROMOT PRACT, V15, P629, DOI 10.1177/1524839914538969; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Busker T, 2023, P 16 INT C THEOR PRA, P24, DOI [10.1145/3614321.3614325, DOI 10.1145/3614321.3614325]; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Dinu LP, 2006, THEOR COMPUT SCI, V359, P455, DOI 10.1016/j.tcs.2006.05.024; Fraser H, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/49995; Frith KH, 2023, NURS EDUC PERSPECT, V44, P198, DOI 10.1097/01.NEP.0000000000001129; Giannakopoulos K, 2023, J MED INTERNET RES, V25, DOI 10.2196/51580; Hanna J.J., 2023, medRxiv, DOI DOI 10.1101/2023.08.28.23294730; Heiss R, 2023, COMPUT HUM BEHAV, V148, DOI 10.1016/j.chb.2023.107908; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Horiuchi D, 2024, NEURORADIOLOGY, V66, P73, DOI 10.1007/s00234-023-03252-4; Hristidis V, 2023, J MED INTERNET RES, V25, DOI 10.2196/48966; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Lyons Riley J, 2023, Can J Ophthalmol, DOI 10.1016/j.jcjo.2023.07.016; Mann Sean, 2022, PLOS Digit Health, V1, pe0000132, DOI 10.1371/journal.pdig.0000132; Miller S, 2020, JMIR HUM FACTORS, V7, DOI 10.2196/19713; Mittermaier M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00858-z; Monteith S, 2024, BRIT J PSYCHIAT, V224, P33, DOI 10.1192/bjp.2023.136; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Nastasi AJ, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45223-y; Oca MC, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45911; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; OpenAi, ChatGPT; Paterick Timothy E, 2017, Proc (Bayl Univ Med Cent), V30, P112; Perchik JD, 2023, ACAD RADIOL, V30, P1472, DOI 10.1016/j.acra.2022.10.002; Pew Research, The search for online medical help; Pew Research Center, 2023, Survey of U.S. adults; Razdan S, 2023, INT J IMPOT RES, DOI 10.1038/s41443-023-00797-z; Riboli-Sasco E, 2023, J MED INTERNET RES, V25, DOI 10.2196/43803; Rooney MK, 2021, J PATIENT EXPERIENCE, V8, DOI 10.1177/2374373521998847; Salinas A, 2024, Arxiv, DOI [arXiv:2308.02053, 10.1145/3617694.3623257, DOI 10.1145/3617694.3623257]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Singh N., 2023, PLOS Digit Health, V2, pe0000367; Temel MH, 2024, WORLD NEUROSURG, V181, pE1138, DOI 10.1016/j.wneu.2023.11.062; Wagner MM., 2006, Handbook of Biosurveillance, P333, DOI [DOI 10.1016/B978012369378-5/50025-9, DOI 10.1016/B978-012369378-5/50025-9, 10.1016/B978-012369378-5/50025-9]; Wallace W, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00667-w; Wang BC, 2023, BEHAV INFORM TECHNOL, V42, P1324, DOI 10.1080/0144929X.2022.2072768; Watanabe K., 2023, Package 'quanteda.textstats'; Weiss DA., 2003, Health Literacy: A Manual for Clinicians; Wennberg JE., 2007, Preference-Sensitive Care: A Dartmouth Atlas Project Topic Brief; Wiedermann CJ, 2023, J PERS MED, V13, DOI 10.3390/jpm13091379; Wyatt JC, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h3727; Xie Q., medRxiv; Zack T, 2023, medRxiv, DOI [10.1101/2023.07.13.23292577, 10.1101/2023.07.13.23292577v2, DOI 10.1101/2023.07.13.23292577V2]	54	0	0	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 29	2024										10.1093/jamia/ocae086	http://dx.doi.org/10.1093/jamia/ocae086		APR 2024	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	OR6S0	38679900				2024-07-03	WOS:001209045400001
J	Kelloniemi, M; Koljonen, V				Kelloniemi, Minna; Koljonen, Virve			AI did not pass Finnish plastic surgery written board examination	JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY			English	Letter						AI; Medical education; Plastic surgery; Surgery; Large language model; Board examination			[Kelloniemi, Minna] Tampere Univ Hosp, Dept Plast Surg, Tampere, Finland; [Koljonen, Virve] Univ Helsinki, Dept Plast Surg, Helsinki, Finland; [Koljonen, Virve] Helsinki Univ Hosp, Helsinki, Finland; [Koljonen, Virve] Pk Hosp, POB 281, Helsinki 00029, Finland	Tampere University; Tampere University Hospital; University of Helsinki; University of Helsinki; Helsinki University Central Hospital	Koljonen, V (corresponding author), Pk Hosp, POB 281, Helsinki 00029, Finland.	virve.koljonen@hus.fi		Koljonen, Virve/0000-0003-0398-4829				Desaire H, 2023, arXiv; Medenilla A., 2023, PLoS Digital Health, V2; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038	5	1	1	5	28	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1748-6815	1878-0539		J PLAST RECONSTR AES	J. Plast. Reconstr. Aesthet. Surg.	DEC	2023	87						172	179		10.1016/j.bjps.2023.10.059	http://dx.doi.org/10.1016/j.bjps.2023.10.059		OCT 2023	8	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	X3CD0	37871487	hybrid			2024-07-03	WOS:001097256900001
J	Crawford, J; Cowling, M; Allen, KA				Crawford, Joseph; Cowling, Michael; Allen, Kelly -Ann			Leadership is needed for ethical ChatGPT: Character, assessment, and learning using artifiicial intelligence (AI)	JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE			English	Article						ChatGPT; OpenAI; artificial intelligence; large language model; student character; academic integrity	ARTIFICIAL-INTELLIGENCE; HIGHER-EDUCATION; PREVALENCE; STRESS; HEALTH; STRAIN	The OpenAI's ChatGPT-3, or Chat Generative Pre-Trained Transformer was released in November 2022 without significant warning, and has taken higher education by storm since. The artificial intelligence (AI) -powered chatbot has caused alarm for practitioners seeking to detect authenticity of student work. Whereas some educational doomsayers predict the end of education in its current form, we propose an alternate early view. We identify in this commentary a position where educators can leverage AI like ChatGPT to build supportive learning environments for students who have cultivated good character. Such students know how to use ChatGPT for good, and can engage effectively with the ChatGPT application. In building our ChatGPT argument, we acknowledge the existing literature on plagiarism and academic integrity, and consider leadership as a root support mechanism, character development as an antidote, and authentic assessment as an enabler. In doing so, we highlight that while ChatGPT - like papermills, and degree factories before it - can be used to cheat on university exams, it can also be used to support deeper learning and better learning outcomes for students. In doing so, we offer a commentary that offers opportunities for practitioners, and research potential for scholars.	[Crawford, Joseph] Univ Tasmania, Hobart, Tas, Australia; [Cowling, Michael] Cent Queensland Univ, Rockhampton, Qld, Australia; [Allen, Kelly -Ann] Monash Univ, Melbourne, Vic, Australia	University of Tasmania; Central Queensland University; Monash University	Crawford, J (corresponding author), Univ Tasmania, Hobart, Tas, Australia.	joseph.crawford@utas.edu.au; m.cowling@cqu.edu.au; kelly-ann.allen@monash.edu	Allen, Kelly-Ann/L-4989-2018; Crawford, Joseph/J-6397-2019; Cowling, Michael A./L-7059-2017	Allen, Kelly-Ann/0000-0002-6813-0034; Crawford, Joseph/0000-0002-2191-6216; Cowling, Michael A./0000-0003-1444-1563				Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938; Adams DR, 2016, J AM COLL HEALTH, V64, P362, DOI 10.1080/07448481.2016.1154559; Alghamdi S., 2019, Global Journal of Health Science, V11, P116, DOI 10.5539/gjhs.v11n9p116; Allen KA, 2021, J UNIV TEACH LEARN P, V18; Allen KA, 2020, J UNIV TEACH LEARN P, V17; American College Health Association, 2018, SPRING 2018 REF GROU; Amigud A, 2020, ASSESS EVAL HIGH EDU, V45, P98, DOI 10.1080/02602938.2019.1612851; [Anonymous], 2023, BENGULURU NEWS  0128; Archer-Kuhn B., 2020, Journal of Higher Education Outreach and Engagement, V24, P107; Beiter R, 2015, J AFFECT DISORDERS, V173, P90, DOI 10.1016/j.jad.2014.10.054; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bruffaerts R, 2018, J AFFECT DISORDERS, V225, P97, DOI 10.1016/j.jad.2017.07.044; Butler-Henderson K, 2020, COMPUT EDUC, V159, DOI 10.1016/j.compedu.2020.104024; Carnovalini F, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00014; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Connor M, 2021, J UNIV TEACH LEARN P, V18; Crawford J., 2023, Journal of University Teaching and Learning Practice, V20, P1, DOI DOI 10.53761/1.20.01.01; Csikszentmihalyi M., 2008, Flow; Darr W, 2008, J OCCUP HEALTH PSYCH, V13, P293, DOI 10.1037/a0012639; Dawson P, 2020, ASSESS EVAL HIGH EDU, V45, P473, DOI 10.1080/02602938.2019.1662884; Deng YW, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.869337; Dodd RH, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18030866; Eager B., 2023, CHATGPT ED; Ehrich J, 2016, STUD HIGH EDUC, V41, P231, DOI 10.1080/03075079.2014.927850; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Ferrucci D, 2013, ARTIF INTELL, V199, P93, DOI 10.1016/j.artint.2012.06.009; Geary E., 2023, CURR CONTENTS, V20, DOI [10.53761/1.20.01.13, DOI 10.53761/1.20.01.13]; Gravett K, 2020, TEACH HIGH EDUC, V25, P84, DOI 10.1080/13562517.2018.1541883; Gregory RW, 2021, ACAD MANAGE REV, V46, P534, DOI 10.5465/amr.2019.0178; Hamzaçebi C, 2009, EXPERT SYST APPL, V36, P3839, DOI 10.1016/j.eswa.2008.02.042; Hassabis D, 2017, NATURE, V544, P413, DOI 10.1038/544413a; Hu K., 2023, REUTERS, V12; Jereb E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202252; LaMontagne AD, 2014, BMC PSYCHIATRY, V14, DOI 10.1186/1471-244X-14-131; Lea MR, 1998, STUD HIGH EDUC, V23, P157, DOI 10.1080/03075079812331380364; Liebrenz M., 2023, The Lancet Digital Health, P1; Lyons Z, 2020, AUSTRALAS PSYCHIATRY, V28, P649, DOI 10.1177/1039856220947945; Ma YC, 2013, J ACAD ETHICS, V11, P169, DOI 10.1007/s10805-013-9186-7; Makridakis S, 2017, FUTURES, V90, P46, DOI 10.1016/j.futures.2017.03.006; Marginson S, 2016, HIGH EDUC, V72, P413, DOI 10.1007/s10734-016-0016-x; McCabe D, 2016, HANDBOOK OF ACADEMIC INTEGRITY, P187, DOI 10.1007/978-981-287-098-8_35; MCCARTHY J, 1987, COMMUN ACM, V30, P1030, DOI 10.1145/33447.33448; McCarthy J, 2006, AI MAG, V27, P12; Thi NK, 2022, ASIA-PAC EDUC RES, V31, P767, DOI 10.1007/s40299-021-00625-2; Newton P., 2018, Frontiers in Education, V3, P67, DOI DOI 10.3389/FEDUC.2018.00067; Panagopoulos J., 2022, AUSTR           1219; Pascoe MC, 2020, INT J ADOLESC YOUTH, V25, P104, DOI 10.1080/02673843.2019.1596823; Pavlik J.V., 2023, J MASS COMMUN ED; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Perrone L., 2003, EDUC TRAIN, V45, P69, DOI 10.1108/00400910310464044; Prowse R, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.650759; Ragheb M. A., 2022, International Journal of Higher Education Management, V8; Reddit, 2023, R CHATGPT POST; Reddy K.J., 2018, BIOMED PHARMACOL J, V11, DOI [DOI 10.13005/bpj/1404, 10.13005/bpj/1404]; RMIT University, 2023, RMIT NEWS       0208; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68; Sciences Po, 2023, SCIENCESPO NEWS 0127; Shaffique S., 2020, RADS J. Biol. Res. Appl. Sci, DOI [10.37962/jbas.v11i1.308, DOI 10.37962/JBAS.V11I1.308]; Shu LL, 2012, J PERS SOC PSYCHOL, V102, P1164, DOI 10.1037/a0028381; Shu LL, 2011, PERS SOC PSYCHOL B, V37, P330, DOI 10.1177/0146167211398138; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Surahman E, 2022, J COMPUT ASSIST LEAR, V38, P1535, DOI 10.1111/jcal.12708; Thomas L, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103754; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; University of Tasmania, 2023, STAT US ART INT; Vernon L., 2022, Understanding wellbeing challenges for university students during crisis disruption; von Keyserlingk L, 2022, J COMMUNITY PSYCHOL, V50, P285, DOI 10.1002/jcop.22561; Wen A., 2023, TEEN VOGUE      0213; Wright TA, 2015, J LEADERSH ORG STUD, V22, P253, DOI 10.1177/1548051815578950; Yau C., 2023, S CHINA MORNING POST; Zhai XS, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8812542	72	79	79	61	351	UNIV WOLLONGONG	WOLLONGONG	NORTHFIELDS AVE, WOLLONGONG, NSW 2522, AUSTRALIA	1449-9789			J UNIV TEACH LEARN P	J. Univ. Teach. Learn. Pract.		2023	20	3							02	10.53761/1.20.3.02	http://dx.doi.org/10.53761/1.20.3.02			21	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	9X9VD		gold, Green Submitted			2024-07-03	WOS:000950113500004
J	Bajcetic, M; Mircic, A; Rakocevic, J; Dokovic, D; Milutinovic, K; Zaletel, I				Bajcetic, Milos; Mircic, Aleksandar; Rakocevic, Jelena; Dokovic, Danilo; Milutinovic, Katarina; Zaletel, Ivan			Comparing the performance of artificial intelligence learning models to medical students in solving histology and embryology multiple choice questions	ANNALS OF ANATOMY-ANATOMISCHER ANZEIGER			English	Article						Medical education; Large language models (LLM); Histology; ChatGPT; Bloom's taxonomy		Introduction: The appearance of artificial intelligence language models (AI LMs) in the form of chatbots has gained a lot of popularity worldwide, potentially interfering with different aspects of education, including medical education as well. The present study aims to assess the accuracy and consistency of different AI LMs regarding the histology and embryology knowledge obtained during the 1st year of medical studies. Methods: Five different chatbots (ChatGPT, Bing AI, Bard AI, Perplexity AI, and ChatSonic) were given two sets of multiple-choice questions (MCQs). AI LMs test results were compared to the same test results obtained from 1st year medical students. Chatbots were instructed to use revised Bloom's taxonomy when classifying questions depending on hierarchical cognitive domains. Simultaneously, two histology teachers independently rated the questions applying the same criteria, followed by the comparison between chatbots' and teachers' question classification. The consistency of chatbots' answers was explored by giving the chatbots the same tests two months apart. Results: AI LMs successfully and correctly solved MCQs regarding histology and embryology material. All five chatbots showed better results than the 1st year medical students on both histology and embryology tests. Chatbots showed poor results when asked to classify the questions according to revised Bloom's cognitive taxonomy compared to teachers. There was an inverse correlation between the difficulty of questions and their correct classification by the chatbots. Retesting the chatbots after two months showed a lack of consistency concerning both MCQs answers and question classification according to revised Bloom's taxonomy learning stage. Conclusion: Despite the ability of certain chatbots to provide correct answers to the majority of diverse and heterogeneous questions, a lack of consistency in answers over time warrants their careful use as a medical education tool.	[Bajcetic, Milos; Mircic, Aleksandar; Rakocevic, Jelena; Dokovic, Danilo; Milutinovic, Katarina; Zaletel, Ivan] Univ Belgrade, Inst Histol & Embryol Aleksandar D Kost, Fac Med, Visegradska 2, Belgrade 11000, Serbia	University of Belgrade	Zaletel, I (corresponding author), Univ Belgrade, Inst Histol & Embryol Aleksandar D Kost, Fac Med, Visegradska 2, Belgrade 11000, Serbia.	ivan.zaletel@med.bg.ac.rs	Zaletel, Ivan/O-4681-2016	Zaletel, Ivan/0000-0002-4841-788X				Baglivo F, 2023, JMIR MED EDUC, V9, DOI 10.2196/51421; Bloom BS., 2001, TAXONOMY LEARNING TE, DOI DOI 10.7771/1541-5015.1355; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Day T, 2023, PROF GEOGR, V75, P1024, DOI 10.1080/00330124.2023.2190373; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gravel J., 2023, Mayo Clin Proc Digit Health, V1, P226, DOI [DOI 10.1016/J.MCPDIG.2023.05.004, 10.1016/j.mcpdig.2023.05.004]; Griesshammer A., 2023, bioRxiv, DOI DOI 10.1101/2023; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Meo SA, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11142046; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909; Totlis T, 2023, SURG RADIOL ANAT, V45, P1321, DOI 10.1007/s00276-023-03229-1; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Tsang R, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231178449	22	0	0	2	2	ELSEVIER GMBH	MUNICH	HACKERBRUCKE 6, 80335 MUNICH, GERMANY	0940-9602	1618-0402		ANN ANAT	Ann. Anat.-Anat. Anz.	JUN	2024	254								152261	10.1016/j.aanat.2024.152261	http://dx.doi.org/10.1016/j.aanat.2024.152261		MAR 2024	7	Anatomy & Morphology	Science Citation Index Expanded (SCI-EXPANDED)	Anatomy & Morphology	PQ0K1	38521363				2024-07-03	WOS:001215426000001
J	Agarwal, M; Goswami, A; Sharma, P				Agarwal, Mayank; Goswami, Ayan; Sharma, Priyanka			Evaluating ChatGPT-3.5 and Claude-2 in Answering and Explaining Conceptual Medical Physiology Multiple-Choice Questions	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						physiology; medical education; multiple choice questions; large language models; claude; chatgpt; artificial intelligence		Background Generative artificial intelligence (AI) systems such as ChatGPT-3.5 and Claude-2 may assist in explaining complex medical science topics. A few studies have shown that AI can solve complicated physiology problems that require critical thinking and analysis. However, further studies are required to validate the effectiveness of AI in answering conceptual multiple-choice questions (MCQs) in human physiology.Objective This study aimed to evaluate and compare the proficiency of ChatGPT-3.5 and Claude-2 in answering and explaining a curated set of MCQs in medical physiology.Methods In this cross-sectional study, a set of 55 MCQs from 10 competencies of medical physiology was purposefully constructed that required comprehension, problem-solving, and analytical skills to solve them. The MCQs and a structured prompt for response generation were presented to ChatGPT-3.5 and Claude-2. The explanations provided by both AI systems were documented in an Excel spreadsheet. All three authors subjected these explanations to a rating process using a scale of 0 to 3. A rating of 0 was assigned to an incorrect, 1 to a partially correct, 2 to a correct explanation with some aspects missing, and 3 to a perfectly correct explanation. Both AI models were evaluated for their ability to choose the correct answer (option) and provide clear and comprehensive explanations of the MCQs. The Mann-Whitney U test was used to compare AI responses. The Fleiss multi-rater kappa (kappa) was used to determine the score agreement among the three raters. The statistical significance level was decided at P <= 0.05.Results Claude-2 answered 40 MCQs correctly, which was significantly higher than the 26 correct responses from ChatGPT-3.5. The rating distribution for the explanations generated by Claude-2 was significantly higher than that of ChatGPT-3.5. The kappa values were 0.804 and 0.818 for Claude-2 and ChatGPT-3.5, respectively.Conclusion In terms of answering and elucidating conceptual MCQs in medical physiology, Claude-2 surpassed ChatGPT-3.5. However, accessing Claude-2 from India requires the use of a virtual private network, which may raise security concerns.	[Agarwal, Mayank] All India Inst Med Sci, Physiol, Raebareli, India; [Goswami, Ayan] Santiniketan Med Coll, Physiol, Bolpur, India; [Sharma, Priyanka] Sharda Univ, Sch Med Sci & Res, Physiol, Greater Noida, India	Sharda University	Sharma, P (corresponding author), Sharda Univ, Sch Med Sci & Res, Physiol, Greater Noida, India.	priyankaphysiology@gmail.com	Agarwal, Mayank/L-2940-2019	Agarwal, Mayank/0000-0002-1107-1889				Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40977; Alqahtani T, 2023, RES SOC ADMIN PHARM, V19, P1236, DOI 10.1016/j.sapharm.2023.05.016; Asghar A, 2022, SURG RADIOL ANAT, V44, P1309, DOI 10.1007/s00276-022-03020-8; Banerjee A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43314; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goyal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42527; Heston TF, 2023, Preprints, DOI [10.20944/preprints202307.0813.v1, 10.20944/preprints202307.0813.v1, DOI 10.20944/PREPRINTS202307.0813.V1]; Hussain J, 2023, SSRN Electron J, DOI [10.2139/ssrn.4478285, DOI 10.2139/SSRN.4478285]; Jones M, 2011, INT J EPIDEMIOL, V40, P1308, DOI 10.1093/ije/dyr109; Lin ZC, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.230658; Meo SA, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11142046; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; National Medical Commission, 2019, competency based assessment module for undergraduate medical education 2019; National Medical Commission, 2018, competency based undergraduate curriculum for the Indian Medical Graduate, VI; Seetharaman R, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01957-w; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Varma JR, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39701; Wu S, 2023, Arxiv, DOI arXiv:2308.04709; Zaidi NLB, 2018, ACAD MED, V93, P856, DOI 10.1097/ACM.0000000000002087	21	6	6	10	11	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	SEP 29	2023	15	9							e46222	10.7759/cureus.46222	http://dx.doi.org/10.7759/cureus.46222			18	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	W2YJ9	37908959	Green Published, gold			2024-07-03	WOS:001090333700001
J	Vemprala, SH; Bonatti, R; Bucker, A; Kapoor, A				Vemprala, Sai H.; Bonatti, Rogerio; Bucker, Arthur; Kapoor, Ashish			ChatGPT for Robotics: Design Principles and Model Abilities	IEEE ACCESS			English	Article						Large language models; Open systems; Artificial intelligence; robotics; language understanding; code generation; perception		This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics. Videos and blog: aka.ms/ChatGPT-Robotics PromptCraft, AirSim-ChatGPT code: https://github.com/microsoft/PromptCraft-Robotics	[Vemprala, Sai H.; Kapoor, Ashish] Scaled Fdn, Kirkland, WA 98033 USA; [Bonatti, Rogerio] Microsoft Corp, Redmond, WA 98072 USA; [Bucker, Arthur] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA	Microsoft; Carnegie Mellon University	Vemprala, SH (corresponding author), Scaled Fdn, Kirkland, WA 98033 USA.	mail@saihv.com						Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Arkin J, 2020, INT J ROBOT RES, V39, P1279, DOI 10.1177/0278364920917755; Bonatti R, 2022, Arxiv, DOI arXiv:2209.11133; Brohan A, 2023, Arxiv, DOI arXiv:2212.06817; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bucker A., 2022, arXiv; Bucker A, 2022, Arxiv, DOI arXiv:2208.02918; Chen LL, 2021, ADV NEUR IN, V34; Chen M., 2021, arXiv; Dettmers T., 2023, P ADV NEUR INF PROC, P1233; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; Fu J., 2019, arXiv; Giuliari F, 2021, INT C PATT RECOG, P10335, DOI 10.1109/ICPR48806.2021.9412190; Goyal P, 2021, Arxiv, DOI arXiv:2106.02972; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; Hong YC, 2021, Arxiv, DOI arXiv:2011.13922; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Huang WL, 2022, PR MACH LEARN RES; Janner M, 2021, ADV NEUR IN, V34; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jiang Y., 2022, ARXIV; Li J., 2023, P MACHINE LEARNING R, P19730; Liang JCY, 2022, Arxiv, DOI [arXiv:2209.07753, 10.48550/arXiv.2209.07753]; Liu H., 2023, P ADV NEUR INF PROC, P1; OpenAI, 2023, ABOUT US; OpenAL, 2023, Gpt-4 Technical Report; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Russell SJ., 2016, ARTIF INTELL; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Shafiullah N, 2022, Arxiv, DOI arXiv:2210.05663; Shah Shital, 2018, Field and service robotics, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-540]; Sharma P, 2022, Arxiv, DOI arXiv:2204.05186; Shridhar M., 2022, C ROBOT LEARNING, P894; Shridhar M, 2022, Arxiv, DOI arXiv:2209.05451; Singh I, 2022, Arxiv, DOI arXiv:2209.11302; Stepputtis S., 2020, Advances in Neural Information Processing Systems, V33, p13 139; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A., 2017, P ADV NEUR INF PROC, VVolume 30; Walter MR, 2021, Arxiv, DOI arXiv:2105.10396; Gadre SY, 2022, Arxiv, DOI arXiv:2203.10421; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598	44	21	21	16	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						55682	55696		10.1109/ACCESS.2024.3387941	http://dx.doi.org/10.1109/ACCESS.2024.3387941			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	ON7Q7		gold, Green Submitted			2024-07-03	WOS:001208023800001
J	Irvine, DJ; Halloran, LJS; Brunner, P				Irvine, Dylan J.; Halloran, Landon J. S.; Brunner, Philip			Opportunities and limitations of the ChatGPT Advanced Data Analysis plugin for hydrological analyses	HYDROLOGICAL PROCESSES			English	Editorial Material						baseflow separation; large language models; major ion chemistry; python; research ethics; research methods		Artificial intelligence (AI) tools, such as ChatGPT, have already changed the way that many industries operate. Much of the recent discussion surrounding AI tools has focused on their ability to generate text and the associated ethical concerns. Recent developments with the ChatGPT Code Interpreter, now called the Advanced Data Analysis plugin, demonstrate that AI's growing abilities in the generation, translation and adaptation of computer scripts also offer significant potential to change the way that data analyses are conducted. We demonstrate the new capabilities of ChatGPT, providing four worked examples of prompt-based generation of Python scripts to analyse hydrological datasets. Our examples include (1) converting R functions to Python to perform baseflow separation, (2) converting MATLAB functions to Python to 'web scrape' temperature data, (3) creating a correlation matrix of major ion groundwater data, and (4) presenting boxplots of river flow data. We discuss the significant opportunities, current limitations and concerns relating to the use of ChatGPT in hydrological data analyses.	[Irvine, Dylan J.] Charles Darwin Univ, Res Inst Environm & Livelihoods, Casuarina, Australia; [Irvine, Dylan J.] Charles Darwin Univ, Fac Sci & Technol, Casuarina, Australia; [Irvine, Dylan J.] Natl Ctr Groundwater Res & Training, Bedford Pk, Australia; [Halloran, Landon J. S.; Brunner, Philip] Univ Neuchatel, Ctr Hydrogeol & Geotherm, Neuchatel, Switzerland	Charles Darwin University; Charles Darwin University; National Centre for Groundwater Research & Training; Flinders University South Australia; University of Neuchatel	Irvine, DJ (corresponding author), Charles Darwin Univ, Res Inst Environm & Livelihoods, Casuarina, Australia.; Irvine, DJ (corresponding author), Charles Darwin Univ, Fac Sci & Technol, Casuarina, Australia.; Irvine, DJ (corresponding author), Natl Ctr Groundwater Res & Training, Bedford Pk, Australia.	dylan.irvine@cdu.edu.au		Halloran, Landon James Szasz/0000-0002-0205-5430; Brunner, Philip/0000-0001-6304-6274; Irvine, Dylan/0000-0002-3543-6221	Council of Australian University Librarians (CAUL)	Council of Australian University Librarians (CAUL)	The text of this article was written without the assistance of AI. The data analyses were facilitated using either ChatGPT-3.5, or ChatGPT-4 (i.e., the paid version). We would like to thank HPToday Editor Prof. James McNamara for helpful feedback and discussion. DJI would like to thank the many researchers for the discussions on the ethical use of AI tools. Open Access is facilitated through Charles Darwin University through the Council of Australian University Librarians (CAUL).	Bakker M, 2016, GROUNDWATER, V54, P733, DOI 10.1111/gwat.12413; Barros J. M., 2021, Get-historical-weather-data; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bureau of Meteorology, 2023, Water data online: Water information: Bureau of Meteorology; Bureau of Meteorology, 2023, Australian groundwater explorer: Water Information: Bureau of Meteorology; Collenteur R., 2023, Open source python packages in hydrology; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Foroumandi E, 2023, WATER RESOUR RES, V59, DOI 10.1029/2023WR036288; Halloran LJS, 2023, HYDROL PROCESS, V37, DOI 10.1002/hyp.14843; Hughes JD, 2024, GROUNDWATER, V62, P124, DOI 10.1111/gwat.13327; Irvine DJ, 2015, J HYDROL, V531, P728, DOI 10.1016/j.jhydrol.2015.10.054; Kashefi A, 2023, Arxiv, DOI arXiv:2303.12093; Kratzert F., 2022, J.Open Source Softw., V7, P4050, DOI [10.21105/joss.04050, DOI 10.21105/JOSS.04050]; Ladson AR, 2013, AUSTRALAS J WAT RESO, V17, P25, DOI 10.7158/W12-028.2013.17.1; Ladson T., 2023, BaseflowSeparation_LyneHollick; Lyne V., 1979, Stochastic timevariable rainfall-runoff modelling. In Proceedings of the Hydrology and Water Resources Symposium Perth (pp. 89-92); Malinka K, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P47, DOI 10.1145/3587102.3588827; NOAA, 2023, NOAA OneStop. National Oceanic and Atmospheric Administration; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Sundberg L, 2023, BUS HORIZONS, V66, P777, DOI 10.1016/j.bushor.2023.04.003; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wang L, 2024, ANN BIOMED ENG, V52, P754, DOI 10.1007/s10439-023-03324-9; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220	23	0	0	17	17	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0885-6087	1099-1085		HYDROL PROCESS	Hydrol. Process.	OCT	2023	37	10							e15015	10.1002/hyp.15015	http://dx.doi.org/10.1002/hyp.15015			5	Water Resources	Science Citation Index Expanded (SCI-EXPANDED)	Water Resources	FX9A0		hybrid			2024-07-03	WOS:001149256700004
C	Chen, ZM; Gaurav; Kruppa, H		Li, H; Cavallaro, G; Heras, DB; Lunga, D; Werner, M; Zufle, A		Chen, Zhaomin; Gaurav; Kruppa, Hannes			Category based Fast Retrieval for Point-of-Interest Search	PROCEEDINGS OF THE 2ND ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON SEARCHING AND MINING LARGE COLLECTIONS OF GEOSPATIAL DATA, GEOSEARCH 2023			English	Proceedings Paper	2nd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data (GeoSearch)	NOV 13, 2023	Hamburg, GERMANY	Assoc Comp Machinery, Apple, ESRI, Oracle		Point-of-Interest; Category-Aware POI Candidate Retrieval; Large Language Model; Active Learning		In the quest of achieving a seamless e-commerce and ride-hailing experience, the significance of effective Point-of-Interest (POI) search cannot be overstated. Yet, the relentless growth in number of POIs over the years, has given a rise to increased latency concerns within modern POI search engines. This, in turn, has resulted in an unsatisfactory search journey for users on the receiving end. In response to this challenge, we introduce a novel approach in the form of a category-based POI retrieval pipeline by mapping POI and query in the same space, effectively improving retrieval efficiency. Through several online A/B experiments, we showcase that our proposed pipeline outperforms by concurrently elevating NDGC@k and recall@k metrics while reducing the latency from 4.1-14.33% that affect POI searches.	[Chen, Zhaomin; Gaurav; Kruppa, Hannes] Grab Holdings Inc, Singapore, Singapore		Chen, ZM (corresponding author), Grab Holdings Inc, Singapore, Singapore.	zhaomin.chen@grabtaxi.com; Gaurav@grabtaxi.com; hannes.kruppa@grabtaxi.com						Chen Y., 2015, Master's Thesis; Deloitte, 2023, Milliseconds Make Millions-A study on how improvements in mobile site speed positively affect a brands bottom line; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; ElasticSearch, 2023, Family; Here, 2023, Here Filtering by Categories; Hu BT, 2014, ADV NEUR IN, V27; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lin XV, 2022, Arxiv, DOI arXiv:2112.10668; Microsoft, 2023, Microsoft Get POI Category; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Settles B., 2009, ACTIVE LEARNING LIT; Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI DOI 10.18653/V1/N16-1174; Zhao J, 2019, AAAI CONF ARTIF INTE, P1270; Zhou CT, 2015, Arxiv, DOI [arXiv:1511.08630, DOI 10.48550/ARXIV.1511.08630]	15	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0352-2				2023							25	28		10.1145/3615890.3628534	http://dx.doi.org/10.1145/3615890.3628534			4	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IQ		Bronze			2024-07-03	WOS:001161646800004
C	Nakagawa, H; Honiden, S		Schneider, K; Dalpiaz, F; Horkoff, J		Nakagawa, Hiroyuki; Honiden, Shinichi			MAPE-K Loop-based Goal Model Generation Using Generative AI	2023 IEEE 31ST INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS, REW	IEEE International Requirements Engineering Conference Workshops		English	Proceedings Paper	31st IEEE International Requirements Engineering Conference (RE)	SEP 04-05, 2023	Hannover, GERMANY	IEEE, IEEE Comp Soc		Goal models; requirements analysis; large language models; generative AI; MAPE-K loop mechanism		Goal modeling constitutes a systematic modeling of representation, specifically crafted to capture and depict stakeholders' intentions, desires, and objectives. Notwithstanding its importance, describing the entire scope of goals to be achieved remains a complex task. To address this challenge, we propose a semi-automatic goal model generation process. The feature of the process lies in its use of a generative AI based on the MAPE-K loop mechanism. We conducted two case studies that built goal models using this proposed process. The results demonstrate that our process, grounded on the MAPE-K loop mechanism, efficiently aids goal model construction.	[Nakagawa, Hiroyuki] Osaka Univ, 51-5 Yamadaoka, Suita, Osaka 5650871, Japan; [Honiden, Shinichi] Natl Inst Informat, 2-1-2 Hitotsubashi,Chiyoda Ku, Tokyo 1018430, Japan	Osaka University; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Nakagawa, H (corresponding author), Osaka Univ, 51-5 Yamadaoka, Suita, Osaka 5650871, Japan.	nakagawa@ist.osaka-u.ac.jp; honiden@nii.ac.jp						[Anonymous], 2006, ARCHITECTURAL BLUEPR, VFourth; [Anonymous], 2023, Anthropic: Claude; ao S.A., 2019, Information and Software Technology, V116; Barke S, 2022, Arxiv, DOI [arXiv:2206.15000, DOI 10.48550/ARXIV.2206.15000]; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Cámara J, 2023, SOFTW SYST MODEL, V22, P781, DOI 10.1007/s10270-023-01105-5; Cheng BHC, 2007, FOSE 2007: FUTURE OF SOFTWARE ENGINEERING, P285, DOI 10.1109/FOSE.2007.17; GitHub I., 2023, Copilot; Google, 2021, Lamda: our breakthrough conversation technology; Midjourney, 2023, Midjourney; Nakagawa H, 2013, S VIS LANG HUM CEN C, P155, DOI 10.1109/RE.2013.6636715; OpenAI, 2023, CHATGPT; Stanford Alpaca project, 2023, Stanford alpaca: An instruction-following LLaMA model; Vaithilingam P., 2022, CHI EA 22; van Lamsweerde A, 2000, IEEE T SOFTWARE ENG, V26, P978, DOI 10.1109/32.879820; van Lamsweerde A., 2009, Requirements engineering: from system goals to UML models to software specifications"	16	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2770-6826		979-8-3503-2691-8	Intern Req Engg Work			2023							247	251		10.1109/REW57809.2023.00050	http://dx.doi.org/10.1109/REW57809.2023.00050			5	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV9BJ					2024-07-03	WOS:001085223300045
J	Farhat, F				Farhat, Faiza			ChatGPT as a Complementary Mental Health Resource: A Boon or a Bane	ANNALS OF BIOMEDICAL ENGINEERING			English	Article						ChatGPT; Mental health; Artificial intelligence; Large language model; Depression; Anxiety		The launch of Open AI's chatbot, ChatGPT, has generated a lot of attention and discussion among professionals in several fields. Many concerns and challenges have been brought up by researchers from various fields, particularly in relation to the harm that using these tools for medical diagnosis and treatment recommendations can cause. In addition, it has been debated if ChatGPT is dependable, efficient, and helpful for clinicians and medical professionals. Therefore, in this study, we assess ChatGPT's effectiveness in providing mental health support, particularly for issues related to anxiety and depression, based on the chatbot's responses and cross-questioning. The findings indicate that there are significant inconsistencies and that ChatGPT's reliability is low in this specific domain. As a result, care must be used when using ChatGPT as a complementary mental health resource.	[Farhat, Faiza] Aligarh Muslim Univ, Dept Zool, Sect Parasitol, Aligarh 202002, UP, India	Aligarh Muslim University	Farhat, F (corresponding author), Aligarh Muslim Univ, Dept Zool, Sect Parasitol, Aligarh 202002, UP, India.	faizahaque16@gmail.com	FARHAT, FAIZA/KIK-8175-2024	FARHAT, FAIZA/0000-0002-1310-1586				Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Chisholm D, 2007, LANCET, V370, P1241, DOI 10.1016/S0140-6736(07)61242-2; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Wainberg ML, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0780-z	11	10	10	23	63	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	MAY	2024	52	5					1111	1114		10.1007/s10439-023-03326-7	http://dx.doi.org/10.1007/s10439-023-03326-7		JUL 2023	4	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	MX8I3	37477707	Green Submitted			2024-07-03	WOS:001035550600001
J	Clay, G; Ontiveros, C				Clay, Graham; Ontiveros, Caleb			Philosophers ought to develop, theorize about, and use philosophically relevant AI	METAPHILOSOPHY			English	Article						artificial intelligence; GPT; epistemic progress; large language models; philosophical progress		The transformative power of artificial intelligence (AI) is coming to philosophy-the only question is the degree to which philosophers will harness it. This paper argues that the application of AI tools to philosophy could have an impact on the field comparable to the advent of writing, and that it is likely that philosophical progress will significantly increase as a consequence of AI. The role of philosophers in this story is not merely to use AI but also to help develop it and theorize about it. In fact, the paper argues that philosophers have a prima facie obligation to spend significant effort in doing so, at least insofar as they should spend effort philosophizing.	[Clay, Graham] Univ Coll Dublin, Sch Philosophy, 510D Newman Bldg, Dublin D04 V1W8, Ireland	University College Dublin	Clay, G (corresponding author), Univ Coll Dublin, Sch Philosophy, 510D Newman Bldg, Dublin D04 V1W8, Ireland.	graham@grahamclay.com		Clay, Graham/0000-0001-5315-3746				Amodei D, 2018, OPENAI BLOG; Berner C., 2019, ARXIV; Bostrom Nick, 2016, SUPERINTELLIGENCE PA, DOI DOI 10.1080/01402390.2013.844127; Broad Charlie Dunbar., 1946, Philosophy, V21, P99; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buckner C, 2019, PHILOS COMPASS, V14, DOI 10.1111/phc3.12625; Chalmers DJ, 2015, PHILOSOPHY, V90, P3, DOI 10.1017/S0031819114000436; Chirimuuta M, 2021, SYNTHESE, V199, P767, DOI 10.1007/s11229-020-02713-0; Cowen Tyler., 2023, GMU WORKING PAPER EC; Creel KA, 2020, PHILOS SCI, V87, P568, DOI 10.1086/709729; Crisp R, 2020, J MORAL PHILOS, V17, P398, DOI 10.1163/17455243-20193133; dAvila Garcez A., 2020, arXiv; Frances B, 2017, METAPHILOSOPHY, V48, P47, DOI 10.1111/meta.12227; Garcez A. d., 2019, NEURAL SYMBOLIC COMP; Grace K, 2018, J ARTIF INTELL RES, V62, P729, DOI 10.1613/jair.1.11222; Greaves H., 2019, Global Priorities Institute, Working Paper Series; Guo B., 2023, How close is chatgpt to human experts? comparison corpus, evaluation, and detection; Hernandez D., 2020, MEASURING ALGORITHMI; Jackson F., 2017, Philosophy's Future: The Problem of Philosophical Progress, P51; Jones W. E., 2017, Philosophy's Future. The Problem of Philosophical Progress, P227; Kripke, 1980, NAMING NECESSITY; LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745; Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231; MacFarlane John., 2016, RELATIVE TRUTH ITS A; Mayo-Wilson C, 2011, PHILOS SCI, V78, P653, DOI 10.1086/661777; Moore GE., 1965, Electronics, V38, P8, DOI [DOI 10.1109/N-SSC.2006.4785860, DOI 10.1109/JPROC.1998.658762]; Moravec H., 1998, J EVOL TECHNOL, V1, P12; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ord T., 2020, The Precipice: Existential Risk and the Future of Humanity; Parfit Derek, 2011, On what matters; Reppert Justin., 2023, ITERATED DECOMPOSITI; Ric??n Jos? Luis., 2020, NINTIL; Ross LD, 2021, EPISTEME-J INDIV SOC, V18, P738, DOI 10.1017/epi.2020.2; Ross WD., 1930, The right and the good; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sinhababu N, 2018, PHILOS STUD, V175, P3131, DOI 10.1007/s11098-017-0998-y; Stoljar Daniel., 2017, Philosophical Progress; Williamson T., 2008, PHILOS PHILOS; Wilson Jessica., 2017, Philosophys Future: The Problem of Philosophical Progress, P91; Zhang Jingqing, 2019, PEGASUS: Pre -training with extracted gap -sentences for abstractive summarization	40	0	0	4	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0026-1068	1467-9973		METAPHILOSOPHY	Metaphilosophy	JUL	2023	54	4					463	479		10.1111/meta.12647	http://dx.doi.org/10.1111/meta.12647		JUL 2023	17	Philosophy	Arts &amp; Humanities Citation Index (A&amp;HCI)	Philosophy	N4TE0		Green Submitted, hybrid			2024-07-03	WOS:001027429000001
J	Tay, JQ				Tay, Jing Qin			ChatGPT and the future of plastic surgery research: evolutionary tool or revolutionary force in academic publishing?	EUROPEAN JOURNAL OF PLASTIC SURGERY			English	Article						Large language models; ChatGPT; Academic writing; Healthcare research; Ethical concerns			[Tay, Jing Qin] Salisbury Dist Hosp, Plast Burns & Reconstruct Surg Dept, Odstock Rd, Salisbury SP2 8BJ, England	Salisbury District Hospital	Tay, JQ (corresponding author), Salisbury Dist Hosp, Plast Burns & Reconstruct Surg Dept, Odstock Rd, Salisbury SP2 8BJ, England.	jingqin.tay1@nhs.net		Tay, Jing Qin/0000-0002-5870-2932				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Marshall IJ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P7, DOI 10.18653/v1/P17-4002; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; Mann SP, 2023, NAT MACH INTELL, V5, P472, DOI 10.1038/s42256-023-00653-1; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	9	3	3	3	24	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0930-343X	1435-0130		EUR J PLAST SURG	Eur. J. Plast. Surg.	AUG	2023	46	4					643	644		10.1007/s00238-023-02081-1	http://dx.doi.org/10.1007/s00238-023-02081-1		MAY 2023	2	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	M6SM0					2024-07-03	WOS:001000178500001
C	Thibault, M; Kivikangas, T; Roihankorpi, R; Pohjola, P; Aho, M			ACM	Thibault, Mattia; Kivikangas, Timo; Roihankorpi, Riku; Pohjola, Petri; Aho, Markus			Who am AI? - Mapping Generative AI Impact and Transformative Potential in Creative Ecosystems	PROCEEDINGS OF THE 26TH INTERNATIONAL ACADEMIC MINDTREK, MINDTREK 2023			English	Proceedings Paper	26th International Academic Mindtrek Conference Mindtrek)	OCT 03-06, 2023	Tampere, FINLAND	ACM In Cooperat, ACM SIGCHI		Artificial Intelligence; GPT; Large Language Models; Creative Industries; Cultural Production	MACHINE TRANSLATION; ARTIFICIAL-INTELLIGENCE	Generative AI's emergence reshapes creative ecosystems, presenting diverse prospects and trials. As these systems adjust to AI's inclusion, equilibrium is disrupted, influencing workers and society. A proactive cross-sectoral approach becomes crucial in navigating this transformation, harnessing AI's potential for sustainable growth. This poster proposes two dimensions relevant to map the possible impacts of AI on the creative sector: the impact of AI on the Industry from a perspective of labour, professionalisation, and management and the Actor Network status of AI in creative efforts. This marks an initial step in a cross-disciplinary endeavor to comprehend and guide the evolution of creative ecosystems, underlining the necessity for comprehensive data engagement and broad academic collaboration.	[Thibault, Mattia; Roihankorpi, Riku] Tampere Univ, Tampere, Finland; [Kivikangas, Timo; Pohjola, Petri; Aho, Markus] Tampere Univ Appl Sci, Tampere, Finland	Tampere University; Tampere University; Tampere University of Applied Sciences TAMK	Thibault, M (corresponding author), Tampere Univ, Tampere, Finland.	mattia.thibault@tuni.fi; timo.kivikangas@tuni.fi; riku.roihankorpi@tuni.fi; petri.pohjola@tuni.fi; markus.aho@tuni.fi		Thibault, Mattia/0000-0002-3593-0350				Alphonso Geoffrey, 2023, Generative AI: Education In The Age Of Innovation; Anastasiou D, 2011, J INF SCI, V37, P637, DOI 10.1177/0165551511418760; [Anonymous], 2023, LANCET, V402, P503, DOI [10.1016/S0140-6736(23)01668-9, 10.1016/s0140-6736(23)01668-9]; Bywood L, 2017, PERSPECT STUD TRANSL, V25, P492, DOI 10.1080/0907676X.2017.1291695; Cadwell P, 2016, TRANSL SPACES, V5, P222, DOI 10.1075/ts.5.2.04cad; Davenport Thomas H., 2023, How Generative AI Is Changing Creative Work; Eco U., 2000, Apocalypse Postponed; FIRAT Gokhan, 2021, The Journal of Internationalization and Localization, V8, P48; Francesconi E, 2022, ARTIF INTELL LAW, V30, P147, DOI 10.1007/s10506-022-09309-8; Gaspari F, 2015, PERSPECT STUD TRANSL, V23, P333, DOI 10.1080/0907676X.2014.979842; Goracke Marc, 2023, The Summer Of "Deep Drakes": How Generative AI Is Creating New Music And Copyright Issues; Hatzius J., 2023, POTENTIALLY LARGE EF; Hogan Mark, 2023, Musicians Are Already Using AI More Often Than We Think; Hollister Sean, 2023, Watch this Nvidia demo and imagine actually speaking to AI game characters; Hoppner Thomas, 2023, Authors and Performers Call for Safeguards Around Generative AI in the European AI Act; Koponen M, 2016, J SPEC TRANSL, P131; Lane M., 2021, The impact of Artificial Intelligence on the labour market: What do we know so far?, DOI [10.1787/7c895724-en, DOI 10.1787/7C895724-EN]; Laporte Nicola, 2023, How generative AI got cast in its first Hollywood movie; Latour B, 2008, INSIDE TECHNOL, P151; Latour Bruno., 2007, REASSEMBLING SOCIAL; Leach, 2022, ARCHITECTURE AGE ART; Muller M, 2022, COMPUT GRAPH FORUM, V41, P1, DOI 10.1111/cgf.14618; Nicolau Anna, 2023, Google and Universal Music negotiate deal over AI 'deepfakes'; OECD, 2023, OECD Employment Outlook 2023; Reid A, 2013, Introduction to machine translation and the post-editing paradigm shift; Roose Kevin, 2023, A.I. Poses 'Risk of Extinction,' Industry Leaders Warn; Sunkel Cameron, 2023, Survey Finds 73Artificial Intelligence Will Replace Them; Vieira LN, 2021, INFORM COMMUN SOC, V24, P1515, DOI 10.1080/1369118X.2020.1776370; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Wainwright Oliver, 2023, It's already way beyond what humans can do': will AI wipe out architects?; Webb M., 2019, The impact of artificial intelligence on the labor market, DOI DOI 10.2139/SSRN.3482150; Yu H, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1183162	32	0	0	16	16	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0874-9				2023							344	349		10.1145/3616961.3617804	http://dx.doi.org/10.1145/3616961.3617804			6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4FM					2024-07-03	WOS:001147480500037
J	Gerasimov, R; Burgasser, AJ; Caiazzo, I; Homeier, D; Richer, HB; Correnti, M; Heyl, J				Gerasimov, Roman; Burgasser, Adam J.; Caiazzo, Ilaria; Homeier, Derek; Richer, Harvey B.; Correnti, Matteo; Heyl, Jeremy			Exploring the Chemistry and Mass Function of the Globular Cluster 47 Tucanae with New Theoretical Color-Magnitude Diagrams	ASTROPHYSICAL JOURNAL			English	Article							METAL-POOR STARS; MULTIPLE STELLAR POPULATIONS; SODIUM-ABUNDANCE VARIATIONS; EARLY DISC ACCRETION; HST LARGE PROGRAM; SUB-GIANT BRANCH; MAIN-SEQUENCE; RED GIANTS; HORIZONTAL-BRANCH; CYANOGEN DISTRIBUTION	Despite their shared origin, members of globular clusters display star-to-star variations in composition. The observed pattern of element abundances is unique to these stellar environments and cannot be fully explained by any proposed mechanism. It remains unclear whether stars form with chemical heterogeneity or inherit it from interactions with other members. These scenarios may be differentiated by the dependence of chemical spread on stellar mass; however, obtaining a sufficiently large mass baseline requires abundance measurements on the lower main sequence, which is too faint for spectroscopy even in the nearest globular clusters. We developed a stellar modeling method to obtain precise chemical abundances for stars near the end of the main sequence from multiband photometry, and we applied it to the globular cluster 47 Tucanae. The computational efficiency is attained by matching chemical elements to the model components that are most sensitive to their abundance. We determined [O/Fe] for similar to 5000 members below the main-sequence knee at the level of accuracy, comparable to the spectroscopic measurements of evolved members in the literature. The inferred distribution disfavors stellar interactions as the origin of chemical spread; however, an accurate theory of accretion is required to draw a more definitive conclusion. We anticipate that future observations of 47 Tucanae with the James Webb Space Telescope will extend the mass baseline of our analysis into the substellar regime. Therefore, we present predicted color-magnitude diagrams and mass-magnitude relations for the brown dwarf members of 47 Tucanae.	[Gerasimov, Roman; Burgasser, Adam J.] Univ Calif San Diego, Ctr Astrophys & Space Sci, La Jolla, CA 92093 USA; [Gerasimov, Roman] Univ Notre Dame, Dept Phys & Astron, Nieuwland Sci Hall, Notre Dame, IN 46556 USA; [Caiazzo, Ilaria] CALTECH, Div Phys Math & Astron, Pasadena, CA 91125 USA; [Homeier, Derek] Aperio Software Ltd, Insight House,Riverside Business Pk,Stoney Common, Stansted CM24 8PL, Essex, England; [Richer, Harvey B.; Heyl, Jeremy] Univ British Columbia, Dept Phys & Astron, 6224 Agr Rd, Vancouver, BC V6T 1Z1, Canada; [Correnti, Matteo] INAF Osservatorio Astron Roma, Via Frascati 33, I-00078 Rome, Italy; [Correnti, Matteo] ASI Space Sci Data Ctr, Via Politecn, I-00133 Rome, Italy	University of California System; University of California San Diego; University of Notre Dame; California Institute of Technology; University of British Columbia; Istituto Nazionale Astrofisica (INAF); Agenzia Spaziale Italiana (ASI)	Gerasimov, R (corresponding author), Univ Calif San Diego, Ctr Astrophys & Space Sci, La Jolla, CA 92093 USA.; Gerasimov, R (corresponding author), Univ Notre Dame, Dept Phys & Astron, Nieuwland Sci Hall, Notre Dame, IN 46556 USA.		Caiazzo, Ilaria/G-7762-2018	Caiazzo, Ilaria/0000-0002-4770-5388; Burgasser, Adam J./0000-0002-6523-9536; Gerasimov, Roman/0000-0003-0398-639X	Hubble Space Telescope (HST) Program [GO-15096]; NASA [NAS5-26555]; Space Telescope Science Institute; Extreme Science and Engineering Discovery Environment (XSEDE); NSF [ACI-1548562]; Today	Hubble Space Telescope (HST) Program; NASA(National Aeronautics & Space Administration (NASA)); Space Telescope Science Institute(Space Telescope Science Institute); Extreme Science and Engineering Discovery Environment (XSEDE); NSF(National Science Foundation (NSF)); Today	We acknowledge the funding support from Hubble Space Telescope (HST) Program GO-15096, provided by NASA through a grant from the Space Telescope Science Institute, which is operated by the Association of Universities for Research in Astronomy, Incorporated, under NASA contract NAS5-26555. The computational demand of this study was met by the Extreme Science and Engineering Discovery Environment (XSEDE), supported by NSF grant ACI-1548562. Some of the software used in this study was produced with assistance from ChatGPT 3.5. ChatGPT is a large language model developed and maintained by OpenAI. This work was conducted at University of California, San Diego, which was built on the unceded territory of the Kumeyaay Nation. Today, the Kumeyaay people continue to maintain their political sovereignty and cultural traditions as vital members of the San Diego community. We acknowledge their tremendous contributions to our region and thank them for their stewardship.	Alabi AB, 2017, MON NOT R ASTRON SOC, V468, P3949, DOI 10.1093/mnras/stx678; Alabi AB, 2016, MON NOT R ASTRON SOC, V460, P3838, DOI 10.1093/mnras/stw1213; Allard F, 2001, ASTROPHYS J, V556, P357, DOI 10.1086/321547; Allard F, 2012, PHILOS T R SOC A, V370, P2765, DOI 10.1098/rsta.2011.0269; Allard F., 2014, Star, Brown Dwarf and Planet Simulator; Allard F., 2011, Astronomical Society of the Pacific Conference Series, P91; Anderson A. J., 1997, PhD thesis; Anderson J., 2002, ASP C SER 265 OMEGA, P87; Anderson J, 2010, ASTROPHYS J, V710, P1032, DOI 10.1088/0004-637X/710/2/1032; Andrievsky SM, 2008, ASTRON ASTROPHYS, V481, P481, DOI 10.1051/0004-6361:20078837; Angelou GC, 2011, ASTROPHYS J, V728, DOI 10.1088/0004-637X/728/2/79; Arkelyan NR, 2022, ASTRON REP+, V66, P191, DOI 10.1134/S1063772922030015; Baade W, 1944, ASTROPHYS J, V100, P137, DOI 10.1086/144650; Bailin J, 2019, ASTROPHYS J SUPPL S, V245, DOI 10.3847/1538-4365/ab4812; Baraffe I, 2015, ASTRON ASTROPHYS, V577, DOI 10.1051/0004-6361/201425481; Barber C. B., 2013, Qhull: Quickhull Algorithm for Computing the Convex Hull, Astrophysics Source Code Library; Barber RJ, 2006, MON NOT R ASTRON SOC, V368, P1087, DOI 10.1111/j.1365-2966.2006.10184.x; Bastian N, 2013, MON NOT R ASTRON SOC, V436, P2398, DOI 10.1093/mnras/stt1745; Bastian N, 2018, ANNU REV ASTRON ASTR, V56, P83, DOI 10.1146/annurev-astro-081817-051839; Bastian N, 2015, MON NOT R ASTRON SOC, V453, P357, DOI 10.1093/mnras/stv1661; BAUM WA, 1952, ASTRON J, V57, P222, DOI 10.1086/106758; Baumgardt H, 2017, MON NOT R ASTRON SOC, V472, P744, DOI 10.1093/mnras/stx2036; Bedin L. R., 2021, The Faintest and Coolest Stars in the Two Closest Globulars, JWST Proposal,Cycle; Bedin LR, 2004, ASTROPHYS J, V605, pL125, DOI 10.1086/420847; Bergemann M, 2011, MON NOT R ASTRON SOC, V413, P2184, DOI 10.1111/j.1365-2966.2011.18295.x; Bohm-Vitense E., 1958, Z ASTROPHYS, V46, P108; BONDI H, 1952, MON NOT R ASTRON SOC, V112, P195, DOI 10.1093/mnras/112.2.195; Briley MM, 1996, NATURE, V383, P604, DOI 10.1038/383604a0; Brown LR, 2005, J QUANT SPECTROSC RA, V96, P251, DOI 10.1016/j.jqsrt.2004.12.037; Brown S. T., 2021, Practice and Experience in Advanced Research Computing, P1, DOI DOI 10.1145/3437359.3465593; BRUGGER RM, 1969, AM STAT, V23, P32; Burgasser AJ, 2004, ASTROPHYS J SUPPL S, V155, P191, DOI 10.1086/424386; Burke CJ, 2004, ASTROPHYS J, V604, P272, DOI 10.1086/381242; BURROWS A, 1989, ASTROPHYS J, V345, P939, DOI 10.1086/167964; Caiazzo I., 2021, Brown Dwarfs, White Dwarfs and Planetary Disks in an Ancient Stellar System, JWST Proposal, Cycle 1; Caiazzo I., 2019, BAAS, V51, P521; Caiazzo I, 2017, Arxiv, DOI arXiv:1702.00091; Calamida A, 2015, ASTROPHYS J, V810, DOI 10.1088/0004-637X/810/1/8; Carbon D. F., 1984, Methods in radiative transfer, P395; Carpenter JM, 2006, ASTROPHYS J, V651, pL49, DOI 10.1086/509121; Carretta E, 2000, ASTROPHYS J, V533, P215, DOI 10.1086/308629; Carretta E, 2010, ASTRON ASTROPHYS, V516, DOI 10.1051/0004-6361/200913451; Castelli, 2003, IAU S, pA20, DOI DOI 10.1017/S0074180900133583; Castelli F., 2005, MEM SOC ASTRON ITAL, V8, P34; Chabrier G, 1997, ASTRON ASTROPHYS, V327, P1039; Chabrier G, 2000, ANNU REV ASTRON ASTR, V38, P337, DOI 10.1146/annurev.astro.38.1.337; Chen S, 2018, ASTROPHYS J, V867, DOI 10.3847/1538-4357/aae089; Choi J, 2016, ASTROPHYS J, V823, DOI 10.3847/0004-637X/823/2/102; COHEN JG, 1978, ASTROPHYS J, V223, P487, DOI 10.1086/156284; Cordero MJ, 2014, ASTROPHYS J, V780, DOI 10.1088/0004-637X/780/1/94; COTTRELL PL, 1981, ASTROPHYS J, V245, pL79, DOI 10.1086/183527; CROCKER DA, 1988, ASTROPHYS J, V332, P236, DOI 10.1086/166648; D'Ercole A, 2016, MON NOT R ASTRON SOC, V461, P4088, DOI 10.1093/mnras/stw1583; D'Ercole A, 2008, MON NOT R ASTRON SOC, V391, P825, DOI 10.1111/j.1365-2966.2008.13915.x; DACOSTA GS, 1982, ASTROPHYS J, V259, P193, DOI 10.1086/160159; de Lacaille N., 1755, Memoires de l'Academie Royale des Sciences, P194; De Silva GM, 2009, ASTRON ASTROPHYS, V500, pL25, DOI 10.1051/0004-6361/200912279; Decressin T, 2007, ASTRON ASTROPHYS, V475, P859, DOI 10.1051/0004-6361:20078425; Denissenkov PA, 2014, MON NOT R ASTRON SOC, V437, pL21, DOI 10.1093/mnrasl/slt133; DICKENS RJ, 1991, NATURE, V351, P212, DOI 10.1038/351212a0; DICKENS RJ, 1976, ASTROPHYS J, V207, P506, DOI 10.1086/154518; Dieball A, 2019, MON NOT R ASTRON SOC, V486, P2254, DOI 10.1093/mnras/stz996; Dieball A., 2016, Hunting for Brown Dwarfs in Globular Clusters: Second Epoch Deep IR observations of the Globular Clusters M4, HST Proposal,Cycle 24; Doppel JE, 2021, MON NOT R ASTRON SOC, V502, P1661, DOI 10.1093/mnras/staa3915; DORMAN B, 1989, ASTROPHYS J, V342, P1003, DOI 10.1086/167658; Dotter A., 2013, MmSAI, V84, P97; Dotter A, 2015, MON NOT R ASTRON SOC, V446, P1641, DOI 10.1093/mnras/stu2170; Fitzpatrick EL, 2007, ASTROPHYS J, V663, P320, DOI 10.1086/518158; Freeman K, 2002, ANNU REV ASTRON ASTR, V40, P487, DOI 10.1146/annurev.astro.40.060401.093840; FREEMAN KC, 1975, ASTROPHYS J, V201, pL71, DOI 10.1086/181945; FRIED J, 1973, PHYS MED BIOL, V18, P550, DOI 10.1088/0031-9155/18/4/306; GAMOW G, 1945, REV MOD PHYS, V17, P125, DOI 10.1103/RevModPhys.17.125; Gerasimov R., 2020, RNAAS, V4, P214, DOI [10.3847/2515-5172/abcf2c, DOI 10.3847/2515-5172/ABCF2C]; Gerasimov R., 2022, 21 CAMBRIDGE WORKSHO, P120, DOI [10.5281/zenodo.7535820, DOI 10.5281/ZENODO.7535820]; Gerasimov R, 2022, ASTROPHYS J, V930, DOI 10.3847/1538-4357/ac61e5; Gieles M, 2018, MON NOT R ASTRON SOC, V478, P2461, DOI 10.1093/mnras/sty1059; Gratton R, 2004, ANNU REV ASTRON ASTR, V42, P385, DOI 10.1146/annurev.astro.42.053102.133945; Gratton R., 2015, HiA, V16, P230, DOI [10.1017/S1743921314005547, DOI 10.1017/S1743921314005547]; Gratton R, 2019, ASTRON ASTROPHYS REV, V27, DOI 10.1007/s00159-019-0119-3; Gratton RG, 2000, ASTRON ASTROPHYS, V354, P169; GRATTON RG, 1982, ASTRON ASTROPHYS, V115, P336; Gratton RG, 2001, ASTRON ASTROPHYS, V369, P87, DOI 10.1051/0004-6361:20010144; Greenstein JL, 1939, ASTROPHYS J, V90, P387, DOI 10.1086/144115; Gustafsson B, 2008, ASTRON ASTROPHYS, V486, P951, DOI 10.1051/0004-6361:200809724; Hachenberg O., 1939, ZAp, V18, P49; Han SI, 2009, ASTROPHYS J LETT, V707, pL190, DOI 10.1088/0004-637X/707/2/L190; Harding G. A., 1962, OBSERVATORY, V82, P205; Harris WE, 1996, ASTRON J, V112, P1487, DOI 10.1086/118116; HARRIS WE, 1979, ANNU REV ASTRON ASTR, V17, P241, DOI 10.1146/annurev.aa.17.090179.001325; HARRIS WE, 1974, ASTROPHYS J, V192, pL161, DOI 10.1086/181616; HARRIS WE, 1991, ANNU REV ASTRON ASTR, V29, P543, DOI 10.1146/annurev.aa.29.090191.002551; Hauschildt PH, 1999, ASTROPHYS J, V512, P377, DOI 10.1086/306745; Hauschildt PH, 1997, ASTROPHYS J, V483, P390, DOI 10.1086/304233; Helling C, 2008, MON NOT R ASTRON SOC, V391, P1854, DOI 10.1111/j.1365-2966.2008.13991.x; HESSER JE, 1980, ASTROPHYS J, V238, pL149, DOI 10.1086/183276; Hilker M., 2020, Star Clusters: From the Milky Way to the Early Universe, V351, P451, DOI [DOI 10.1017/S1743921319006823, 10.1017/S1743921319006823]; Homeier D, 2003, IAU SYMP, P419; Hubble E, 1932, ASTROPHYS J, V76, P44, DOI 10.1086/143397; Johnson CI, 2010, ASTROPHYS J, V722, P1373, DOI 10.1088/0004-637X/722/2/1373; Johnson H. R., 1994, Molecules in the Stellar Environment, VVol. 428, P234; Joyce M, 2018, ASTROPHYS J, V856, DOI 10.3847/1538-4357/aab200; Kalirai JS, 2012, ASTRON J, V143, DOI 10.1088/0004-6256/143/1/11; KEENAN PC, 1953, ASTROPHYS J, V117, P241, DOI 10.1086/145687; KRAFT RP, 1994, PUBL ASTRON SOC PAC, V106, P553, DOI 10.1086/133416; Krauss LM, 2003, SCIENCE, V299, P65, DOI 10.1126/science.1075631; Kroupa P, 2001, MON NOT R ASTRON SOC, V322, P231, DOI 10.1046/j.1365-8711.2001.04022.x; Kurucz R. L., 1981, 391 SAO; Kurucz R. L., 1974, Blanketed Model Atmospheres for Early-type Stars; Kurucz R. L., 2005, Mem. Soc. Astron. Ital. Suppl, V8, P14; Kurucz R. L., 1970, SAO Special Report; Kurucz RL, 2014, GEOPLANET-EARTH PLAN, P39, DOI 10.1007/978-3-319-06956-2_4; Larkin MM, 2023, ASTRON J, V165, DOI 10.3847/1538-3881/ac9b43; Lee M. G., 2012, ASP C SER 458 GALACT, P291; Lee S.-W., 1977, Astronomy and Astrophysics Supplement Series, V27, P381; Lide D. R., 2007, CRC HDB CHEM PHYS; Lind K, 2015, ASTRON ASTROPHYS, V575, DOI 10.1051/0004-6361/201425554; Lind K, 2011, ASTRON ASTROPHYS, V528, DOI 10.1051/0004-6361/201016095; LUNINE JI, 1986, ASTROPHYS J, V310, P238, DOI 10.1086/164678; MacLean BT, 2015, MON NOT R ASTRON SOC, V446, P3556, DOI 10.1093/mnras/stu2348; Marino AF, 2016, MON NOT R ASTRON SOC, V459, P610, DOI 10.1093/mnras/stw611; Marino AF, 2012, ASTROPHYS J, V746, DOI 10.1088/0004-637X/746/1/14; Marino AF, 2011, ASTROPHYS J LETT, V730, DOI 10.1088/2041-8205/730/2/L16; Marino A. F., 2013, MmSAI, V84, P29; Marley MS, 2002, ASTROPHYS J, V568, P335, DOI 10.1086/338800; Martell SL, 2011, ASTRON ASTROPHYS, V534, DOI 10.1051/0004-6361/201117644; Martell SL, 2010, ASTRON ASTROPHYS, V519, DOI 10.1051/0004-6361/201014135; Martell SL, 2009, PUBL ASTRON SOC PAC, V121, P577, DOI 10.1086/599979; Mashonkina L, 2010, EAS PUBLICATIONS, V43, P189, DOI 10.1051/eas/1043014; Messenger BB, 2002, MON NOT R ASTRON SOC, V331, P684, DOI 10.1046/j.1365-8711.2002.05234.x; Messier C., 1781, Catalogue des Nebuleuses des amas d'Etoiles (Catalog of Nebulae and Star Clusters); Mészáros S, 2013, MON NOT R ASTRON SOC, V430, P3285, DOI 10.1093/mnras/stt130; Mészáros S, 2012, ASTRON J, V144, DOI 10.1088/0004-6256/144/4/120; Mihalas D., 1978, Stellar Atmospheres; Milone AP, 2023, Arxiv, DOI arXiv:2304.07770; Milone AP, 2019, MON NOT R ASTRON SOC, V484, P4046, DOI 10.1093/mnras/stz277; Milone AP, 2013, ASTROPHYS J, V767, DOI 10.1088/0004-637X/767/2/120; Milone AP, 2022, UNIVERSE-BASEL, V8, DOI 10.3390/universe8070359; Moehler S, 2001, PUBL ASTRON SOC PAC, V113, P1162, DOI 10.1086/323297; Nardiello D, 2023, MON NOT R ASTRON SOC, V521, pL39, DOI 10.1093/mnrasl/slad021; Nendwich J., 2004, CoAst, V144, P43; Newberg HJ, 2016, ASTROPHYS SPACE SC L, V420, P1, DOI 10.1007/978-3-319-19336-6; Nitschai MS, 2023, ASTROPHYS J, V958, DOI 10.3847/1538-4357/acf5db; NORRIS J, 1981, ASTROPHYS J, V248, P177, DOI 10.1086/159141; NORRIS J, 1975, ASTROPHYS J, V201, pL75, DOI 10.1086/181946; NORRIS J, 1981, ASTROPHYS J, V244, P205, DOI 10.1086/158698; NORRIS J, 1979, ASTROPHYS J, V230, pL179, DOI 10.1086/182988; Oort J. H., 1926, PhD thesis; Paxton B, 2019, ASTROPHYS J SUPPL S, V243, DOI 10.3847/1538-4365/ab2241; Paxton B, 2018, ASTROPHYS J SUPPL S, V234, DOI 10.3847/1538-4365/aaa5a8; Paxton B, 2015, ASTROPHYS J SUPPL S, V220, DOI 10.1088/0067-0049/220/1/15; Paxton B, 2013, ASTROPHYS J SUPPL S, V208, DOI 10.1088/0067-0049/208/1/4; Paxton B, 2011, ASTROPHYS J SUPPL S, V192, DOI 10.1088/0067-0049/192/1/3; Percival SM, 2002, ASTROPHYS J, V573, P174, DOI 10.1086/340593; PETERSON RC, 1980, ASTROPHYS J, V237, pL87, DOI 10.1086/157950; Phillips MW, 2020, ASTRON ASTROPHYS, V637, DOI 10.1051/0004-6361/201937381; Piotto G, 2007, ASTROPHYS J, V661, pL53, DOI 10.1086/518503; Piotto G, 2012, ASTROPHYS J, V760, DOI 10.1088/0004-637X/760/1/39; Plez B, 2011, J PHYS CONF SER, V328, DOI 10.1088/1742-6596/328/1/012005; POPPER DM, 1947, ASTROPHYS J, V105, P204, DOI 10.1086/144893; Qin SM, 2023, ASTROPHYS J SUPPL S, V265, DOI 10.3847/1538-4365/acadd6; Ramírez I, 2012, ASTROPHYS J, V757, DOI 10.1088/0004-637X/757/2/164; Recio-Blanco A, 2018, ASTRON ASTROPHYS, V620, DOI 10.1051/0004-6361/201833179; Rennó C, 2020, MON NOT R ASTRON SOC, V498, P5834, DOI 10.1093/mnras/staa2697; Ribas A, 2015, ASTRON ASTROPHYS, V576, DOI 10.1051/0004-6361/201424846; Rood R. T., 1985, Horizontal-Branch and UV-Bright Stars, P99; Salaris M, 2005, EVOLUTION OF STARS AND STELLAR POPULATIONS, P1, DOI 10.1002/0470033452; Salaris M, 2020, MON NOT R ASTRON SOC, V492, P3459, DOI 10.1093/mnras/staa089; Salaris M, 2015, ASTRON ASTROPHYS, V577, DOI 10.1051/0004-6361/201525812; Salaris M, 2014, ASTRON ASTROPHYS, V566, DOI 10.1051/0004-6361/201423722; Sampedro L, 2017, MON NOT R ASTRON SOC, V470, P3937, DOI 10.1093/mnras/stx1485; SANDAGE A, 1967, ASTROPHYS J, V150, P469, DOI 10.1086/149350; SAUMON D, 1995, ASTROPHYS J SUPPL S, V99, P713, DOI 10.1086/192204; Sbordone L., 2005, ATLAS COOKBOOK; SMITH GH, 1987, PUBL ASTRON SOC PAC, V99, P67, DOI 10.1086/131958; SMITH GH, 1982, ASTROPHYS J, V254, P594, DOI 10.1086/159770; SMITH GH, 1982, ASTROPHYS J, V254, P149, DOI 10.1086/159718; SMITH GH, 1983, ASTROPHYS J, V264, P215, DOI 10.1086/160588; SNEDEN C, 1992, ASTRON J, V104, P2121, DOI 10.1086/116388; Sollima A, 2017, MON NOT R ASTRON SOC, V471, P3668, DOI 10.1093/mnras/stx1856; Spada F, 2017, ASTROPHYS J, V838, DOI 10.3847/1538-4357/aa661d; Strader J, 2004, ASTRON J, V127, P3431, DOI 10.1086/420995; SWEIGART AV, 1979, ASTROPHYS J, V229, P624, DOI 10.1086/156996; ten Bruggencate P., 1927, Sternhaufen: Ihr Bau, Ihre Stellung zum Sternsystem und Ihre Bedeutung fur die Kosmogonie, P127; Thompson IB, 2020, MON NOT R ASTRON SOC, V492, P4254, DOI 10.1093/mnras/staa032; Thygesen AO, 2014, ASTRON ASTROPHYS, V572, DOI 10.1051/0004-6361/201424533; Tsuji T, 2003, ASTROPHYS J, V585, pL151, DOI 10.1086/374388; Valcin D, 2021, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2021/08/017; Valcin D, 2020, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2020/12/002; VandenBerg DA, 2000, ASTROPHYS J SUPPL S, V129, P315, DOI 10.1086/313404; VandenBerg DA, 2013, ASTROPHYS J, V775, DOI 10.1088/0004-637X/775/2/134; VANDENBERGH S, 1967, ASTRON J, V72, P70, DOI 10.1086/110203; WALLERSTEIN G, 1969, ASTROPHYS J, V158, P607, DOI 10.1086/150222; WALLERSTEIN G, 1964, ASTROPHYS J, V139, P1163, DOI 10.1086/147858; Wenger C, 1998, J QUANT SPECTROSC RA, V59, P471, DOI 10.1016/S0022-4073(97)00106-4; WING RF, 1973, ASTROPHYS J, V186, P979, DOI 10.1086/152561; Winter AJ, 2023, MON NOT R ASTRON SOC, V521, P1646, DOI 10.1093/mnras/stad312; Yong D, 2008, ASTROPHYS J, V689, P1020, DOI 10.1086/592229; Zhang HW, 2008, ASTRON ASTROPHYS, V481, P489, DOI 10.1051/0004-6361:20078910; Zhou T., 2022, RNAAS, V6, P212, DOI [10.3847/2515-5172/ac9ab6, DOI 10.3847/2515-5172/AC9AB6]; Ziliotto T, 2023, ASTROPHYS J, V953, DOI 10.3847/1538-4357/acde76; ZINN R, 1973, ASTRON ASTROPHYS, V25, P409	201	2	2	2	2	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0004-637X	1538-4357		ASTROPHYS J	Astrophys. J.	JAN 1	2024	961	1							139	10.3847/1538-4357/ad08bf	http://dx.doi.org/10.3847/1538-4357/ad08bf			19	Astronomy & Astrophysics	Science Citation Index Expanded (SCI-EXPANDED)	Astronomy & Astrophysics	GN9J4		gold, Green Submitted			2024-07-03	WOS:001153465000001
J	Zhang, P; Boulos, MNK				Zhang, Peng; Kamel Boulos, Maged N.			Generative AI in Medicine and Healthcare: Promises, Opportunities and Challenges	FUTURE INTERNET			English	Review						generative AI; large language models; ChatGPT; artificial intelligence; medicine; healthcare; human health		Generative AI (artificial intelligence) refers to algorithms and models, such as OpenAI's ChatGPT, that can be prompted to generate various types of content. In this narrative review, we present a selection of representative examples of generative AI applications in medicine and healthcare. We then briefly discuss some associated issues, such as trust, veracity, clinical safety and reliability, privacy, copyrights, ownership, and opportunities, e.g., AI-driven conversational user interfaces for friendlier human-computer interaction. We conclude that generative AI will play an increasingly important role in medicine and healthcare as it further evolves and gets better tailored to the unique settings and requirements of the medical domain and as the laws, policies and regulatory frameworks surrounding its use start taking shape.	[Zhang, Peng] Vanderbilt Univ, Dept Comp Sci, Nashville, TN 37240 USA; [Zhang, Peng] Vanderbilt Univ, Data Sci Inst, Nashville, TN 37240 USA; [Kamel Boulos, Maged N.] Univ Lisbon, Sch Med, P-1649028 Lisbon, Portugal	Vanderbilt University; Vanderbilt University; Universidade de Lisboa	Boulos, MNK (corresponding author), Univ Lisbon, Sch Med, P-1649028 Lisbon, Portugal.	mnkboulos@ieee.org	Kamel Boulos, Maged N./B-3728-2013	Kamel Boulos, Maged N./0000-0003-2400-6303				ABR, The American Board of Radiology; Adams LC, 2023, J MED INTERNET RES, V25, DOI 10.2196/43110; [Anonymous], 2023, EUROPEAN PARLIAMENT; [Anonymous], 2023, BBC News1 April; [Anonymous], 2023, BBC News28 April; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ben-Shabat N, 2022, INT J MED INFORM, V168, DOI 10.1016/j.ijmedinf.2022.104897; Bertolini D., 2020, arXiv; Board of Innovation, Glass AI; Board of Innovation, Ellen AI; Candemir S, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210014; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen L, 2020, J AM MED INFORM ASSN, V27, P56, DOI 10.1093/jamia/ocz141; Claburn T., 2023, REGISTER; corti, Corti AI-Powered Patient Triaging; cynerio, 2023, Cynerio Harnesses the Power of Generative AI to Revolutionize Healthcare Cybersecurity; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dilibal C., 2021 3rd International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA), V2021, P1, DOI DOI 10.1109/HORA52670.2021.9461370; Ellen A.I, Your Smart AI Companion with Voice; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gautam R, OSM-GPT: An Innovative Project Combining GPT-3 and the Overpass API to Facilitate Easy Feature Discovery on OpenStreetMap; glass.health, Glass Health Glass AI; Google, BARD; gridspace, Gridspace Explore Ways to Build a Better Customer Experience with Conversational AI; Hillier M, 2023, Why does ChatGPT generate fake references?; Hippocratic A.I, Benchmarks; Kahun, Evidence-Based AI Designed for Clinical Reasoning; Kilicoglu H, 2012, BIOINFORMATICS, V28, P3158, DOI 10.1093/bioinformatics/bts591; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Krishna K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4958; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lee P., 2023, REVOLUTION MED GPT 4; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Matsuzoe R., 2023, Nikkei Asia; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Meta, 2023, Meta and Microsoft Introduce the Next Generation of Llama; Microsoft Corporation, 2023, Summary of Changes to the Microsoft Services Agreement; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Muniz-Terrera G, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.613956; Naskar R., 2023, Neowin; ncbi.nlm.nih, PubMed Query Using the Term 'ChatGPT; Nolan M., 2023, Llama and ChatGPT Are Not Open-Source-Few Ostensibly Open-Source LLMs Live up to the Openness Claim; Nuance, Nuance Dragon Medical One; NVIDIA Corporation, NVIDIA HGX AI Supercomputer; O'Laughlin D, 2023, AI Foundations Part 1: Transformers, Pre-Training and Fine-Tuning, and Scaling; openai, API Reference-OpenAI API; OpenAI, 2023, New ways to manage your data in ChatGPT; openai, OpenAI Models; openai, OpenAIDALL-E2; openai, Chat Plugins-Introduction; openai, 2023, Chatgpt plugins; Ozcan S., 2023, The Conversation; paige, Paige FullFocus; Patel AA., 2021, Applied natural language processing in the enterprise; Petal/Paladin Max Inc, GPT-Trainer; Philips, 2023, Philips Joins Forces with AWS to bring Philips HealthSuite Imaging PACS to the Cloud and Advance AI-Enabled Tools in Support of Clinicians; Proser Z, Retrieval Augmented Generation (RAG): Reducing Hallucinations in GenAI Applications; Raciti P, 2023, ARCH PATHOL LAB MED, V147, P1178, DOI 10.5858/arpa.2022-0066-OA; Rahaman M., 2023, The AI Race Is on! Google's Bard and OpenAI's ChatGPT Head to Head: An Opinion Article; Rao R., 2023, Generative AI's Intellectual Property Problem Heats up AIs producing Art or Inventions Have to Navigate a Hostile Legal Landscape, and a Consensus Is Far Away; Regard, 2022, Torrance Memorial Medical Center Reduces Physician Burnout, Increases Annual Revenue by $2 Million with the Help of Regard Case Study; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Sabzalieva E., 2023, ChatGPT and artificial intelligence in higher education quick start guide; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; sayheart, SayHeart-Humanizing Health; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Sharma S., 2023, F.A.S.T.-Meta AI's Segment Anything for Medical Imaging; Sniegula A, 2020, LECT NOTES COMPUT SC, V12011, P375, DOI 10.1007/978-3-030-38919-2_31; Spataro J., 2023, Official Microsoft Blog; Srivastava J, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7218113; Strickland E., 2023, IEEE Spectrum; suki, Suki Suki Assistant; syntegra, Syntegra Data-Driven Innovation through Advanced AI; Tao R, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12070284; Thampapillai D., 2023, The Conversation7 July; UK Cabinet Office, 2023, Guidance to Civil Servants on Use of Generative AI; UK Medicines & Healthcare products Regulatory Agency, Software and Artificial Intelligence (AI) as a Medical Device (Guidance; Unlearn A.I, AI-Powered Digital Twins of Individual Patients; VanBuskirk A, 2023, A Brief History of the Generative Pre-Trained Transformer (GPT) Language Models; Vaswani A, 2017, ADV NEUR IN, V30; Velvart A., 2023, Linkedin; Venkatesh K., 2023, JMIR Medical Education; Venkatesh KP, 2024, ANNU REV PHARMACOL, V64, P159, DOI 10.1146/annurev-pharmtox-022123-022046; Wong B., 2023, How Generative AI is Changing the Game in Healthcare; Wu ST, 2013, ANN ALLERG ASTHMA IM, V111, P364, DOI 10.1016/j.anai.2013.07.022; Wu Yonghui, 2015, AMIA Annu Symp Proc, V2015, P1326; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yellig J., 2023, IoT World Today (Informa); youtube, 2023, Can AI Code Beat Saber? Watch ChatGPT Try (YouTube Video; Zhang DW, 2023, Arxiv, DOI [arXiv:2307.03941, 10.48550/arXiv.2307.03941]	93	17	18	74	116	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	SEP	2023	15	9							286	10.3390/fi15090286	http://dx.doi.org/10.3390/fi15090286			15	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	S9BG4		gold			2024-07-03	WOS:001074041500001
J	Adelstein, JM; Sinkler, MA; Li, LT; Mistovich, RJ				Adelstein, Jeremy M.; Sinkler, Margaret A.; Li, Lambert T.; Mistovich, R. Justin			ChatGPT Responses to Common Questions About Slipped Capital Femoral Epiphysis: A Reliable Resource for Parents?	JOURNAL OF PEDIATRIC ORTHOPAEDICS			English	Article						ChatGPT; artificial intelligence; SCFE; large language model; health literacy; machine learning; frequently asked questions	COMPLICATIONS; MANAGEMENT	Background:We sought to evaluate the ability of ChatGPT, an AI-powered online chatbot, to answer frequently asked questions (FAQs) regarding slipped capital femoral epiphysis (SCFE).Methods:Seven FAQs regarding SCFE were presented to ChatGPT. Initial responses were recorded and compared with evidence-based literature and reputable online resources. Responses were subjectively rated as "excellent response requiring no further clarification," "satisfactory response requiring minimal clarification," "satisfactory response requiring moderate clarification," or "unsatisfactory response requiring substantial clarification."Results:ChatGPT was frequently able to provide satisfactory responses that required only minimal clarification. One response received an excellent rating and required no further clarification, while only 1 response from ChatGPT was rated unsatisfactory and required substantial clarification.Conclusions:ChatGPT is able to frequently provide satisfactory responses to FAQs regarding SCFE while appropriately reiterating the importance of always consulting a medical professional.	[Adelstein, Jeremy M.; Sinkler, Margaret A.; Li, Lambert T.; Mistovich, R. Justin] Case Western Reserve Univ, Univ Hosp, Dept Orthopaed Surg, Cleveland, OH USA; [Mistovich, R. Justin] Case Western Reserve Univ, Sch Med, Rainbow Babies & Childrens Hosp, Div Pediat Orthopaed, Cleveland, OH USA; [Mistovich, R. Justin] Metrohlth Syst, Div Pediat Orthopaed, Cleveland, OH USA; [Adelstein, Jeremy M.] Case Western Reserve Univ, Univ Hosp Cleveland Med Ctr, Dept Orthopaed, 11100 Euclid Ave, Cleveland, OH 44106 USA	University System of Ohio; Case Western Reserve University; University Hospitals of Cleveland; University Hospitals of Cleveland; Rainbow Babies & Children's Hospital; University System of Ohio; Case Western Reserve University; Case Western Reserve University Hospital; MetroHealth System; University System of Ohio; Case Western Reserve University; University Hospitals of Cleveland	Adelstein, JM (corresponding author), Case Western Reserve Univ, Univ Hosp Cleveland Med Ctr, Dept Orthopaed, 11100 Euclid Ave, Cleveland, OH 44106 USA.	jeremy.adelstein2@UHhospitals.org; margaret.sinkler@uhhospitals.org; Lambert.Li@UHHospitals.org; justin@mistovich.net						Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bajwa Junaid, 2021, Future Healthc J, V8, pe188, DOI 10.7861/fhj.2021-0095; Campbell DJ, 2023, J CLIN SLEEP MED, V19, P1989, DOI 10.5664/jcsm.10728; Crepeau A, 2015, J PEDIATR ORTHOPED, V35, pE90, DOI 10.1097/BPO.0000000000000440; De Inocencio J, 2004, ARCH DIS CHILD, V89, P431, DOI 10.1136/adc.2003.028860; Fernandez FF, 2019, ORTHOPADE, V48, P677, DOI 10.1007/s00132-019-03729-2; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; Fuglkjær S, 2017, BMC MUSCULOSKEL DIS, V18, DOI 10.1186/s12891-017-1771-2; Georgiadis AG, 2014, PEDIATR CLIN N AM, V61, P1119, DOI 10.1016/j.pcl.2014.08.001; Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011; Hesper T, 2017, J CHILD ORTHOP, V11, P99, DOI 10.1302/1863-2548-11-160276; Kennedy JG, 2001, J PEDIATR ORTHOPED, V21, P189, DOI 10.1097/00004694-200103000-00011; Kim SJ, 2013, ACTA ORTHOP, V84, P271, DOI 10.3109/17453674.2013.795103; Loder Randall T, 2011, ISRN Orthop, V2011, P486512, DOI 10.5402/2011/486512; LODER RT, 1993, J BONE JOINT SURG AM, V75A, P1134, DOI 10.2106/00004623-199308000-00002; LODER RT, 1995, J PEDIATR ORTHOPED, V15, P349, DOI 10.1097/01241398-199505000-00018; Lubicky JP, 1996, J PEDIATR ORTHOP B, V5, P162, DOI 10.1097/01202412-199605030-00005; Macía-Villa CC, 2016, REUMATISMO, V68, P40, DOI 10.4081/reumatismo.2016.860; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Novais EN, 2012, CLIN ORTHOP RELAT R, V470, P3432, DOI 10.1007/s11999-012-2452-y; Peck DM, 2017, AM FAM PHYSICIAN, V95, P779; Pehora C, 2015, INTERACT J MED RES, V4, P49, DOI 10.2196/ijmr.3790; Perry DC, 2018, PEDIATRICS, V142, DOI 10.1542/peds.2018-1067; Roaten J, 2016, ORTHOP CLIN N AM, V47, P405, DOI 10.1016/j.ocl.2015.09.013; Schrader T, 2016, J BONE JOINT SURG AM, V98, P1030, DOI 10.2106/JBJS.15.01002; Speirs JN, 2019, JAAOS GLOB RES REV, V3, DOI 10.5435/JAAOSGlobal-D-19-00084; Swarup I, 2020, J PEDIATR ORTHOPED, V40, pE446, DOI 10.1097/BPO.0000000000001482; Thawrani DP, 2016, J PEDIATR ORTHOPED, V36, pE27, DOI 10.1097/BPO.0000000000000496; Umans H, 1998, SKELETAL RADIOL, V27, P139, DOI 10.1007/s002560050353; Upasani VV, 2020, J PEDIATR ORTHOPED, V40, P176, DOI 10.1097/BPO.0000000000001284; Uvodich M, 2019, J PEDIATR-US, V206, P184, DOI 10.1016/j.jpeds.2018.10.050; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Veramuthu V, 2022, CHILDREN-BASEL, V9, DOI 10.3390/children9091374; Zusman NL, 2024, J PEDIATR ORTHOPED, V44, pE30, DOI 10.1097/BPO.0000000000002539	34	0	0	0	0	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0271-6798	1539-2570		J PEDIATR ORTHOPED	J. Pediatr. Orthop.	JUL	2024	44	6					353	357		10.1097/BPO.0000000000002681	http://dx.doi.org/10.1097/BPO.0000000000002681			5	Orthopedics; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Pediatrics	TD8G3	38597253				2024-07-03	WOS:001239409500002
J	Rupp, MC; Gerdesmeyer, L; Rab, P; Siebenlist, S				Rupp, Marco-Christopher; Gerdesmeyer, Lennart; Rab, Peter; Siebenlist, Sebastian			Chatbots in (sports) orthopedics Opportunities and challenges in the digital age	ARTHROSKOPIE			German	Review; Early Access						Traumatology; Patient care; Artificial intelligence<middle dot>; NaturalLanguage Processing<middle dot>; Large Language Models	ARTIFICIAL-INTELLIGENCE	The German healthcare system, and particularly orthopedics, is confronted with substantial challenges due to increasing health economic constraints, and shortages in staff and resources. In this context, the upcoming digital transformation should strive to support orthopedic surgeons and trauma surgeons in delivering individualized and optimized patient care. Chatbots, technical dialogue systems that enable human interactions with computer-based programs via spoken or written language, are already increasingly being utilized in patient care, propelled by recent advancements in artificial intelligence (AI). This article discusses the potential and the challenges associated with the use of chatbots throughout the orthopedic treatment pathway of patients, particularly aiming to provide optimal preoperative, perioperative and rehabilitative care to enhance treatment outcomes. In addition to the technology, where a distinction is made between rule-based and AI-driven models, applications in sports orthopedics are analyzed from the initial contact to postoperative care using examples from the current literature. Challenges include liability, data protection, regulatory guidelines and implementation tasks. With the ongoing digitalization in the healthcare system chatbots could potentially be an instrumental tool in positively impacting aspects of the diagnostics, postoperative care, and patient education in orthopedics.	[Rupp, Marco-Christopher; Gerdesmeyer, Lennart; Rab, Peter; Siebenlist, Sebastian] Tech Univ Munich, Klinikum Rechts Isar, Sekt Sportorthopadie, D-81675 Munich, Germany	Technical University of Munich	Siebenlist, S (corresponding author), Tech Univ Munich, Klinikum Rechts Isar, Sekt Sportorthopadie, D-81675 Munich, Germany.	sebastian.siebenlist@tum.de						Abdullah YI, 2021, ASIA-PAC J OPHTHALMO, V10, P289, DOI 10.1097/APO.0000000000000397; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Bagley CHM, 2011, ANN ROY COLL SURG, V93, P401, DOI 10.1308/003588411X580179; Bian YY, 2020, J MED INTERNET RES, V22, DOI 10.2196/16896; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Dwyer Tim, 2023, Arthrosc Sports Med Rehabil, V5, pe495, DOI 10.1016/j.asmr.2023.01.020; Gisy J., 2023, Hautnah Dermatologie, V39, P80, DOI [10.1007/s15012-023-7876-4, DOI 10.1007/S15012-023-7876-4]; Khandelwal P., 2020, Zocdoc: Understanding and Exploring the Market Penetration in Texas, DOI [10.4135/9781529706451, DOI 10.4135/9781529706451]; Kim J-H, 2022, medRxiv; McLean SM, 2010, MANUAL THER, V15, P514, DOI 10.1016/j.math.2010.05.012; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Murray CJL, 2018, LANCET, V392, P1995, DOI [10.1016/s0140-6736(18)32279-7, 10.1016/S0140-6736(18)32279-7, 10.1016/s0140-6736(18)32278-5]; Primc N., 2020, Ethik im Gesundheitswesen, P1; Ramkumar PN, 2019, J ARTHROPLASTY, V34, P2253, DOI 10.1016/j.arth.2019.05.021; Schmitz-Rixen T, 2019, INNOV SURG SCI, V4, P51, DOI 10.1515/iss-2019-0002; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Smith M, 2020, INTERN MED J, V50, P1278, DOI 10.1111/imj.15017; Stanley AL, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231152177; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	21	0	0	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0933-7946	1434-3924		ARTHROSKOPIE	Arthroskopie	2024 APR 12	2024										10.1007/s00142-024-00668-9	http://dx.doi.org/10.1007/s00142-024-00668-9		APR 2024	9	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	NP8P6					2024-07-03	WOS:001201750400002
J	Klippel, TS; Fonteles, H; Torgo, D; Selau, F; Borges, E; Konrad, B; Trombini, H; Morais, J; Alves, MDM; Benvenutti, E; Baptista, DL; Grande, A				Klippel, T. S.; Fonteles, Henrique; Torgo, Daphne; Selau, Felipe; Borges, Eduarda; Konrad, Barbara; Trombini, Henrique; Morais, Jonder; Alves, Maria do Carmo M.; Benvenutti, E., V; Baptista, D. L.; Grande, And			Novel deposition method for gold and platinum nanoparticles on silicon substrates utilizing poly (ethylene glycol) 6000 for MEIS analysis	JOURNAL OF PHYSICS D-APPLIED PHYSICS			English	Article						gold nanoparticles; platinum nanoparticles; RBS; MEIS; TEM; SEM; PEG	DEPTH RESOLUTION; DRUG-DELIVERY; PARTICLES; SURFACES; GROWTH	The use of nanoparticles has significantly increased in many areas, such as biomedical research, being highly useful as nanoprobes for imaging and as nanocarriers for drug delivery applications. Nevertheless, this potential can only be achieved with the correct characterization of the nanoparticles, since their size and shape can directly affect their biological behavior. In this study, we propose a novel approach for a monolayer deposition of gold and platinum nanoparticles on Si substrates suitable for medium energy ion scattering (MEIS) analysis. The samples were prepared using poly(ethylene glycol) 6000 (PEG 6000) as a coating agent for the substrates, utilizing a spin coater-a versatile, cost-effective, and practical technique. The samples were first analyzed with the RBS technique to assess the adhesion and the overlapping of the nanoparticles in the substrates coated with PEG 6000 and then characterized through the MEIS technique. The analysis through MEIS allowed the determination of the shape, size, and coverage area of the nanoparticles. Scanning and transmission electron microscopy were also performed on the samples, with the results corroborating the findings of the MEIS experiment. Together, the data obtained with microscopy and the MEIS technique suggests the effectiveness of the method in the production of monolayer samples.	[Klippel, T. S.; Fonteles, Henrique; Selau, Felipe; Borges, Eduarda; Konrad, Barbara; Baptista, D. L.; Grande, And] Univ Fed Rio Grande Sul UFRGS, Inst Fis, Inst Fis, Ave Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil; [Torgo, Daphne] Univ Fed Rio Grande Do Sul UFRGS, Lab Sinalizacao & Plasticidade Celular, Inst Biociencias, Porto Alegre, Brazil; [Trombini, Henrique] Saude Porto Alegre, UFCSPA Univ Fed Ciencias, Rua Sarmento Leite 245, BR-90050170 Porto, RS, Brazil; [Morais, Jonder] Univ Fed Rio Grande Do Sul UFRGS, Lab Espect Eletron LEe, Inst Fis, Porto Alegre, Brazil; [Benvenutti, E., V] Univ Fed Rio Grande Do Sul UFRGS, Rio Grande, Brazil; [Alves, Maria do Carmo M.] Univ Fed Rio Grande Do Sul UFRGS, Dept Quim, Inst Quim, Porto Alegre, Brazil	Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio Grande do Sul; Universidade Federal do Rio Grande do Sul	Klippel, TS (corresponding author), Univ Fed Rio Grande Sul UFRGS, Inst Fis, Inst Fis, Ave Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil.	theylorklippel@hotmail.com	Benvenutti, Edilson/G-4285-2016; Ferreira Selau, Felipe/L-2645-2018; L. Baptista, Daniel/I-2605-2012	Benvenutti, Edilson/0000-0002-7889-3625; Ferreira Selau, Felipe/0000-0001-8172-9749; Trombini, Henrique/0000-0002-7254-4774; L. Baptista, Daniel/0000-0002-2658-6412	Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brazil (CAPES) [001]; Financiadora de Estudos e Projetos (FINEP); Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq); Instituto Nacional de Engenharia de Superficies (INES) PRONEX-FAPERGS; Research Support Foundation of the State of Rio Grande do Sul (FAPERGS) [16/2551-0000479-0];  [21/2551-0000722-2]	Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brazil (CAPES)(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); Financiadora de Estudos e Projetos (FINEP)(Financiadora de Inovacao e Pesquisa (Finep)); Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); Instituto Nacional de Engenharia de Superficies (INES) PRONEX-FAPERGS; Research Support Foundation of the State of Rio Grande do Sul (FAPERGS)(Fundacao de Amparo a Ciencia e Tecnologia do Estado do Rio Grande do Sul (FAPERGS)); 	This study was financed in part by the Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brazil (CAPES) - Finance Code 001, by Financiadora de Estudos e Projetos (FINEP), by the Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq), by the Instituto Nacional de Engenharia de Superficies (INES) PRONEX-FAPERGS 16/2551-0000479-0, and Research Support Foundation of the State of Rio Grande do Sul (FAPERGS, 21/2551-0000722-2).We would also like to thank Professor Henri Boudinovfor providing space in the microelectronics laboratory facilities for the samples to be prepared. During the preparation ofthis work, the authors used ChatGPT version 3.5 to improvereadability and language. After using this tool/service, theauthors reviewed and edited the content as needed and take(s)full responsibility for the content of the publication (OpenAI.(2024). ChatGPT (3.5) [Large language model].https://chat.openai.com).	Abuelmakarem HS, 2023, LASER MED SCI, V38, DOI 10.1007/s10103-022-03678-x; Andrae R., 2010, Dos and don'ts of reduced chi-squared; Arenas LT, 2008, J COLLOID INTERF SCI, V318, P96, DOI 10.1016/j.jcis.2007.09.073; Bano A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38234-2; Browning RJ, 2017, ACS NANO, V11, P8560, DOI 10.1021/acsnano.7b04092; Chu WK, 1978, BACKSCATTERING SPECT, DOI DOI 10.1016/B978-0-12-173850-1.50008-9; Ciftci N, 2023, NANOMEDICINE-UK, V18, P1719, DOI 10.2217/nnm-2023-0223; Comenge J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047562; Craig GE, 2012, INORG CHEM, V51, P3490, DOI 10.1021/ic202197g; D'souza AA, 2016, EXPERT OPIN DRUG DEL, V13, P1257, DOI 10.1080/17425247.2016.1182485; Das A, 2008, B MATER SCI, V31, P277, DOI 10.1007/s12034-008-0045-x; Ealias Anu Mary, 2017, IOP Conference Series: Materials Science and Engineering, V263, DOI 10.1088/1757-899X/263/3/032019; Franco-Ulloa S, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19164-3; González-López MA, 2020, CANCER NANOTECHNOL, V11, DOI 10.1186/s12645-020-00060-w; Gorji Mohammad Saleh, 2014, Advanced Materials Research, V1024, P124, DOI 10.4028/www.scientific.net/AMR.1024.124; Gorji MS, 2013, J COLLOID INTERF SCI, V408, P220, DOI 10.1016/j.jcis.2013.07.026; Gratton SEA, 2008, P NATL ACAD SCI USA, V105, P11613, DOI 10.1073/pnas.0801763105; Gurbich AF, 2016, NUCL INSTRUM METH B, V371, P27, DOI 10.1016/j.nimb.2015.09.035; Hall JB, 2007, NANOMEDICINE-UK, V2, P789, DOI 10.2217/17435889.2.6.789; Hepperle P, 2022, PART PART SYST CHAR, V39, DOI 10.1002/ppsc.202200136; Hong YK, 2002, APPL PHYS LETT, V80, P844, DOI 10.1063/1.1445811; Hoo CM, 2008, J NANOPART RES, V10, P89, DOI 10.1007/s11051-008-9435-7; Jacob L, 2024, ADV ENG MATER, V26, DOI 10.1002/adem.202301242; Jung KW, 2014, ANAL CHEM, V86, P1091, DOI 10.1021/ac402753j; Kosmala A, 2011, MATER CHEM PHYS, V129, P1075, DOI 10.1016/j.matchemphys.2011.05.064; Kumar A, 2017, WOODH PUB SER BIOMED, P43, DOI 10.1016/B978-0-08-100557-6.00003-1; Lansåker PC, 2014, AIP ADV, V4, DOI 10.1063/1.4897340; Leveneur J, 2012, J NANOPART RES, V14, DOI 10.1007/s11051-012-1149-1; Malik H., 2024, Med. Sci. Forum, V24, P6, DOI [10.3390/ECA2023-16387, DOI 10.3390/ECA2023-16387]; Marmitt G., 2013, theses and dissertations digital repository Master's Thesis; Marmitt G G., Powermeis-3 simulation code; Marmitt G.G., 2017, Tesis; Mayer M., 1998, SIMNRA user's guide; Megginson R, 2022, APPL SURF SCI, V575, DOI 10.1016/j.apsusc.2021.151656; Okazawa T, 2006, SURF SCI, V600, P1331, DOI 10.1016/j.susc.2006.01.028; Paes V Z C., PhD Thesis; Paes VZC, 2017, J PHYS CHEM C, V121, P19461, DOI 10.1021/acs.jpcc.7b05472; Parveen S, 2012, NANOMED-NANOTECHNOL, V8, P147, DOI 10.1016/j.nano.2011.05.016; Pinto L., 1996, PhD Thesis; Sanchez DF, 2011, SURF SCI, V605, P654, DOI 10.1016/j.susc.2010.12.011; Sanchez DF, 2013, SCI REP-UK, V3, DOI 10.1038/srep03414; Schneid AC, 2019, NANOTECHNOLOGY, V30, DOI 10.1088/1361-6528/aaf17e; Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089; Schulte WH, 2001, NUCL INSTRUM METH B, V183, P16, DOI 10.1016/S0168-583X(01)00313-5; Selau FF, 2020, PHYS REV A, V102, DOI 10.1103/PhysRevA.102.032812; Selau F F., PhD Thesis; SMEENK RG, 1982, NUCL INSTRUM METHODS, V195, P581, DOI 10.1016/0029-554X(82)90022-2; Sortica MA, 2012, APPL PHYS LETT, V101, DOI 10.1063/1.4734686; Sortica MA, 2009, J APPL PHYS, V106, DOI 10.1063/1.3266139; Thi TTH, 2020, POLYMERS-BASEL, V12, DOI 10.3390/polym12020298; Todescato F, 2016, MATERIALS, V9, DOI 10.3390/ma9080672; Trombini H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48117-0; TROMP RM, 1984, NUCL INSTRUM METH B, V4, P155, DOI 10.1016/0168-583X(84)90055-7; TURKEVICH J, 1951, DISCUSS FARADAY SOC, P55, DOI 10.1039/df9511100055; Van der Veen JF, 1985, SURF SCI REP, V5, P199, DOI 10.1016/0167-5729(85)90001-9; Woodruff D P., 1994, Modern Techniques of Surface Science; Zhao Y, 2008, PHYS FLUIDS, V20, DOI 10.1063/1.2896601; Zhou C, 2013, EXP BIOL MED, V238, P1199, DOI 10.1177/1535370213505825; Zhuang J, 2011, ACS SYM SER, V1079, P41	59	0	0	4	4	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0022-3727	1361-6463		J PHYS D APPL PHYS	J. Phys. D-Appl. Phys.	MAY 31	2024	57	22							225301	10.1088/1361-6463/ad2a14	http://dx.doi.org/10.1088/1361-6463/ad2a14			11	Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Physics	JY5Y2					2024-07-03	WOS:001176744900001
J	Cheong, RCT; Pang, KP; Unadkat, S; Mcneillis, V; Williamson, A; Joseph, J; Randhawa, P; Andrews, P; Paleri, V				Cheong, Ryan Chin Taw; Pang, Kenny Peter; Unadkat, Samit; Mcneillis, Venkata; Williamson, Andrew; Joseph, Jonathan; Randhawa, Premjit; Andrews, Peter; Paleri, Vinidh			Performance of artificial intelligence chatbots in sleep medicine certification board exams: ChatGPT versus Google Bard	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						Artificial intelligence; Large language models; ChatGPT; Google Bard; Sleep medicine; Certification examinations		Purpose To conduct a comparative performance evaluation of GPT-3.5, GPT-4 and Google Bard in self-assessment questions at the level of the American Sleep Medicine Certification Board Exam.Methods A total of 301 text-based single-best-answer multiple choice questions with four answer options each, across 10 categories, were included in the study and transcribed as inputs for GPT-3.5, GPT-4 and Google Bard. The first output responses generated were selected and matched for answer accuracy against the gold-standard answer provided by the American Academy of Sleep Medicine for each question. A global score of 80% and above is required by human sleep medicine specialists to pass each exam category.Results GPT-4 successfully achieved the pass mark of 80% or above in five of the 10 exam categories, including the Normal Sleep and Variants Self-Assessment Exam (2021), Circadian Rhythm Sleep-Wake Disorders Self-Assessment Exam (2021), Insomnia Self-Assessment Exam (2022), Parasomnias Self-Assessment Exam (2022) and the Sleep-Related Movements Self-Assessment Exam (2023). GPT-4 demonstrated superior performance in all exam categories and achieved a higher overall score of 68.1% when compared against both GPT-3.5 (46.8%) and Google Bard (45.5%), which was statistically significant (p value < 0.001). There was no significant difference in the overall score performance between GPT-3.5 and Google Bard.Conclusions Otolaryngologists and sleep medicine physicians have a crucial role through agile and robust research to ensure the next generation AI chatbots are built safely and responsibly.	[Cheong, Ryan Chin Taw; Williamson, Andrew; Paleri, Vinidh] Royal Marsden NHS Fdn Trust, Otolaryngol Head & Neck Surg Dept, Fulham Rd, London SW3 6JJ, England; [Pang, Kenny Peter] Asia Sleep Ctr, Singapore, Singapore; [Unadkat, Samit; Mcneillis, Venkata; Joseph, Jonathan; Randhawa, Premjit; Andrews, Peter] Univ Coll London Hosp NHS Fdn Trust, Royal Natl ENT & Eastman Dent Hosp, Otolaryngol Head & Neck Surg Dept, London, England	Royal Marsden NHS Foundation Trust; University of London; University College London; University College London Hospitals NHS Foundation Trust	Cheong, RCT (corresponding author), Royal Marsden NHS Fdn Trust, Otolaryngol Head & Neck Surg Dept, Fulham Rd, London SW3 6JJ, England.	ryan.cheong@nhs.net		Paleri, Vinidh/0000-0002-7933-4585; Williamson, Andrew/0000-0002-3861-4847; Cheong, Ryan ChinTaw/0000-0001-7846-8699	American Academy of Sleep Medicine	American Academy of Sleep Medicine	The authors would like to thank the American Academy of Sleep Medicine for the development and availability of the maintenance of certification self-assessment questions in sleep medicine for non-commercial research.	aasm, MAINT CERT SLEEP MED; Ali MR, 2023, J ROY SOC MED, DOI 10.1177/01410768231187734; [Anonymous], 2023, LANCET, V402, P503, DOI [10.1016/S0140-6736(23)01668-9, 10.1016/s0140-6736(23)01668-9]; [Anonymous], SLEEP MED EX REQ APP; [Anonymous], 2023, GOOGL AI UPD BARD NE; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Benjafield AV, 2019, LANCET RESP MED, V7, P687, DOI 10.1016/S2213-2600(19)30198-5; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Birkett L, 2023, BRIT J ANAESTH, V131, pe34, DOI 10.1016/j.bja.2023.04.025; blog, GOOGL I O 2023 MAK A; Bubeck S., 2023, arXiv; businessinsider, MUCH DOES CHATGPT CO; businesswire, GLOB MED ED MARK REP; esrs, ONL EX RUL SETT; futureoflife, PAUS GIANT AI EXP OP; futureoflife, AI PRINC FUT LIF I; Grandner MA, 2021, SCIENCE, V374, P568, DOI 10.1126/science.abj8188; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lloyd-Jones DM, 2022, CIRCULATION, V146, pE18, DOI 10.1161/CIR.0000000000001078; Marin JM, 2005, LANCET, V365, P1046, DOI 10.1016/S0140-6736(05)71141-7; Nori H., 2023, ARXIV; Oosthuizen RM, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.913168; OpenAI, 2022, Introducing ChatGPT, P1; Quan SF, 2012, J CLIN SLEEP MED, V8, P221, DOI 10.5664/jcsm.1790; Reeder K, 2022, CLIN IMAG, V81, P67, DOI 10.1016/j.clinimag.2021.09.018; Roche J, 2021, J CLIN SLEEP MED, V17, P2341, DOI 10.5664/jcsm.9614; safe, STAT AI RISK; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Stoller MK, EC EFFECTS INSOMNIA; Susnjak T., 2022, ChatGPT: The End of Online Exam Integrity, P1; worldsleepsociety, APPL EX; Yu PK, 2021, LARYNGOSCOPE, V131, pE2712, DOI 10.1002/lary.29725	35	5	5	10	10	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	APR	2024	281	4					2137	2143		10.1007/s00405-023-08381-3	http://dx.doi.org/10.1007/s00405-023-08381-3		DEC 2023	7	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	LQ7A3	38117307				2024-07-03	WOS:001127366100001
C	Abukhalaf, S; Hamdaqa, M; Khomh, F			IEEE	Abukhalaf, Seif; Hamdaqa, Mohammad; Khomh, Foutse			On Codex Prompt Engineering for OCL Generation: An Empirical Study	2023 IEEE/ACM 20TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES, MSR	IEEE International Working Conference on Mining Software Repositories		English	Proceedings Paper	IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)	MAY 15-16, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, GitHub, Huawei Canada		Codex; Prompt Engineering; Object Constraint Language (OCL); Code Generation; Large Language Models		The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to Meta-Object Facility (MOF) models. OCL can provide precision and conciseness to UML models. Nevertheless, the unfamiliar syntax of OCL has hindered its adoption by software practitioners. LLMs, such as GPT-3, have made significant progress in many NLP tasks, such as text generation and semantic parsing. Similarly, researchers have improved on the downstream tasks by fine-tuning LLMs for the target task. Codex, a GPT-3 descendant by OpenAI, has been fine-tuned on publicly available code from GitHub and has proven the ability to generate code in many programming languages, powering the AI-pair programmer Copilot. One way to take advantage of Codex is to engineer prompts for the target downstream task. In this paper, we investigate the reliability of the OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications from various educational resources. We manually crafted a prompt template with slots to populate with the UML information and the target task in the prefix format to complete the template with the generated OCL constraint. We used both zero- and few-shot learning methods in the experiments. The evaluation is reported by measuring the syntactic validity and the execution accuracy metrics of the generated OCL constraints. Moreover, to get insight into how close or natural the generated OCL constraints are compared to human-written ones, we measured the cosine similarity between the sentence embedding of the correctly generated and human-written OCL constraints. Our findings suggest that by enriching the prompts with the UML information of the models and enabling few-shot learning, the reliability of the generated OCL constraints increases. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex.	[Abukhalaf, Seif; Hamdaqa, Mohammad] Polytech Montreal, Dept Comp & Software Engn, Software & Emerging Technol Lab SAET, Montreal, PQ, Canada; [Khomh, Foutse] Polytech Montreal, Dept Comp & Software Engn, SoftWare Analyt & Technol Lab SWAT, Montreal, PQ, Canada	Universite de Montreal; Polytechnique Montreal; Universite de Montreal; Polytechnique Montreal	Abukhalaf, S (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Software & Emerging Technol Lab SAET, Montreal, PQ, Canada.	seif.abukhalaf@polymtl.ca; mhamdaqa@polymtl.ca; foutse.khomh@polymtl.ca		Abukhalaf, Seif/0009-0008-7347-9143	Fonds de Recherche du Quebec (FRQ); Canadian Institute for Advanced Research (CIFAR); National Science and Engineering Research Council of Canada (NSERC)	Fonds de Recherche du Quebec (FRQ)(Fonds de recherche du Quebec (FRQ)); Canadian Institute for Advanced Research (CIFAR)(Canadian Institute for Advanced Research (CIFAR)); National Science and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work is partially supported by the Fonds de Recherche du Quebec (FRQ), the Canadian Institute for Advanced Research (CIFAR), and the National Science and Engineering Research Council of Canada (NSERC).	[Anonymous], 2002, BUSINESS RULES BC4J; [Anonymous], PLANT LANG REF GUID; [Anonymous], 2017, UN MOD LANG VERS 2 5; [Anonymous], 2014, OBJ CONSTR LANG SPEC; Ashbacher C., 2003, J OBJECT TECHNOL, V2, P139; Bajwa I., 2012, THESIS; Bajwa I., 2010, OCL CONSTRAINTS GENE, V10; Bajwa IS, 2012, J KING SAUD UNIV-COM, V24, P117, DOI 10.1016/j.jksuci.2011.12.003; Cabot Jordi, 2012, Formal Methods for Model-Driven Engineering. 12th International School of Formal Methods for the Design of Computer, Communication and Software Systems (SFM 2012). Advanced Lectures, P58, DOI 10.1007/978-3-642-30982-3_3; Cabot J., 2022, COMBINING OCL NATURA, V11, P908; Cabot J., 2006, AMBIGUITY ISSUES OCL; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, ARXIV220402311; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; da Silva AR, 2015, COMPUT LANG SYST STR, V43, P139, DOI 10.1016/j.cl.2015.06.001; Gogolla M, 2007, SCI COMPUT PROGRAM, V69, P27, DOI 10.1016/j.scico.2007.01.013; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Pengfei, 2021, arXiv; Mengerink JGM, 2019, EMPIR SOFTW ENG, V24, P1574, DOI 10.1007/s10664-018-9641-6; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Noten J, 2017, IEEE WORK CONF MIN S, P531, DOI 10.1109/MSR.2017.52; Poesia G., 2022, ARXIV220111227; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Richters M., 2000, INT C UN MOD LANG; Salemi S., 2015, J KING SAUD U COMPUT, V28, P11; Wahler M., 2008, USING PATTERNS DEV C; Wang Wenhui, 2020, Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers; Wang Y., 2021, arXiv preprint arXiv:2109.00859; Yu C, 2022, PROC IEEE INT CONF S, P82, DOI 10.1109/ICSME55016.2022.00016	29	0	0	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2160-1852		979-8-3503-1184-6	IEEE WORK CONF MIN S			2023							148	157		10.1109/MSR59073.2023.00033	http://dx.doi.org/10.1109/MSR59073.2023.00033			10	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JN		Green Submitted			2024-07-03	WOS:001032697200019
J	Ash, E; Hansen, S				Ash, Elliott; Hansen, Stephen			Text Algorithms in Economics	ANNUAL REVIEW OF ECONOMICS			English	Article						text as data; topic models; word embeddings; large language models; transformer models	MODELS	This article provides an overview of the methods used for algorithmic text analysis in economics, with a focus on three key contributions. First, we introduce methods for representing documents as high-dimensional count vectors over vocabulary terms, for representing words as vectors, and for representing word sequences as embedding vectors. Second, we define four core empirical tasks that encompass most text-as-data research in economics and enumerate the various approaches that have been taken so far to accomplish these tasks. Finally, we flag limitations in the current literature, with a focus on the challenge of validating algorithmic output.	[Ash, Elliott] Swiss Fed Inst Technol, Ctr Law & Econ, Zurich, Switzerland; [Hansen, Stephen] UCL, Dept Econ, London, England; [Hansen, Stephen] Ctr Econ Policy Res, London, England	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of London; University College London; Centre for Economic Policy Research - UK	Hansen, S (corresponding author), UCL, Dept Econ, London, England.; Hansen, S (corresponding author), Ctr Econ Policy Res, London, England.	stephen.hansen@ucl.ac.uk						Adams-Prassl A, 2020, IZA Discuss. Pap. 13691; Adukia A, 2023, Q J ECON, V138, P2225, DOI 10.1093/qje/qjad028; Advani A, 2021, CEPR Discuss. Pap. 16115; Ahrens M, 2023, Natural language processing for monetary economics: a benchmark; Angelico C, 2022, J ECONOMETRICS, V228, P259, DOI 10.1016/j.jeconom.2021.12.008; Angrist JD, 2009, MOSTLY HARMLESS ECONOMETRICS: AN EMPIRICISTS COMPANION, P1; Apel M., 2014, REV EC, V65, P53; Arora S, 2016, 5 INT C LEARN REPR T; Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288; Ash E, 2020, 2 INT WORKSH MIN LEA; Ash E, 2021, CEPR Discuss. Pap. 16624; Ash E, 2020, Work. Pap.; Ash E, 2020, Work. Pap. 15; Ash E, 2020, Work. Pap. 4; Ash E, 2024, POLIT ANAL, V32, P115, DOI 10.1017/pan.2023.8; Atalay E, 2020, AM ECON J-APPL ECON, V12, P1, DOI 10.1257/app.20190070; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Baker SR, 2016, Q J ECON, V131, P1593, DOI 10.1093/qje/qjw024; Bana SH, 2022, Work2vec: using language models to understand wage premia; Bandiera O, 2020, J POLIT ECON, V128, P1325, DOI 10.1086/705331; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bertrand M, 2021, Q J ECON, V136, P2413, DOI 10.1093/qje/qjab023; Besley T, 2020, How big is the media multiplier? Evidence from dyadic news data; Biasi B, 2022, NBER Working Paper 29853; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Boukus Ellyn., 2006, INFORM CONTENT FOMC; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bybee L, 2021, 29344 NBER; Byrne D, 2023, CEPR Discuss. Pap. 17931; Cagé J, 2020, REV ECON STUD, V87, P2126, DOI 10.1093/restud/rdz061; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chang J., 2009, Advances in neural information processing systems, P22; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cieslak A, 2021, Policymakers' uncertainty; COASE RH, 1960, J LAW ECON, V3, P1, DOI 10.1086/466560; Davis S J., 2020, Firm-Level Risk Exposures and Stock Returns in the Wake of COVID-19 (No. w27867); DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deming D, 2018, J LABOR ECON, V36, pS337, DOI 10.1086/694106; Demszky D, 2019, Arxiv, DOI arXiv:1904.01596; Denny MJ, 2018, POLIT ANAL, V26, P168, DOI 10.1017/pan.2017.44; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Djourelova M, 2021, CESifoWork. Pap. 9090; Draca M, 2018, Warwick Econ. Res. Pap. Ser., V1218; Enke B, 2020, J POLIT ECON, V128, P3679, DOI 10.1086/708857; Farrell MH, 2021, ECONOMETRICA, V89, P181, DOI 10.3982/ECTA16901; Fetzer T, 2020, J EUR ECON ASSOC, V18, P3337, DOI 10.1093/jeea/jvz062; Friedman M., 1963, MONETARY HIST US 186; Gallagher R. J., 2017, Transactions of the Association for Computational Linguistics (TACL), V5, P529, DOI [10.1162/tacl_a_00078, DOI 10.1162/TACL_A_00078]; Gennaro G, 2022, ECON J, V132, P1037, DOI 10.1093/ej/ueab104; Gentzkow M, 2019, J ECON LIT, V57, P535, DOI 10.1257/jel.20181020; Gentzkow M, 2019, ECONOMETRICA, V87, P1307, DOI 10.3982/ECTA16566; Gentzkow M, 2010, ECONOMETRICA, V78, P35, DOI 10.3982/ECTA7195; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Goldberg Y., 2017, Neural Network Methods in Natural Language Processing, DOI 10.2200/S00762ED1V01Y201703HLT037; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Grimmer J., 2022, TEXT DATA NEW FRAMEW; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; Hanley KW, 2019, REV FINANC STUD, V32, P4543, DOI 10.1093/rfs/hhz023; Hansen S, 2021, NBER Working Paper 28959; Hansen S, 2023, NBER Working Paper 31007; Hansen S, 2018, Q J ECON, V133, P801, DOI 10.1093/qje/qjx045; Hansen S, 2016, J INT ECON, V99, pS114, DOI 10.1016/j.jinteco.2015.12.008; Hassan TA, 2019, Q J ECON, V134, P2135, DOI 10.1093/qje/qjz021; Hastie T., 2009, ELEMENTS STAT LEARNI; Hoberg G, 2016, J POLIT ECON, V124, P1423, DOI 10.1086/688176; Hoberg G, 2010, REV FINANC STUD, V23, P3773, DOI 10.1093/rfs/hhq053; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Iaria A, 2018, Q J ECON, V133, P927, DOI 10.1093/qje/qjx046; Jha M, 2022, Does finance bene fit society? A language embedding approach; Joulin A, 2016, Arxiv, DOI [arXiv:1607.01759, 10.48550/arXiv.1607.01759]; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Ke S, 2021, Robust machine learning algorithms for text analysis; Ke ZT, 2019, NBER Working Paper No. 26186; Kelly B, 2021, AM ECON REV INSIGHTS, V3, P303, DOI 10.1257/aeri.20190499; Kelly B, 2021, J BUS ECON STAT, V39, P859, DOI 10.1080/07350015.2021.1947843; Khodak M, 2018, Arxiv, DOI arXiv:1805.05388; Kleinberg J, 2019, ACM EC '19: PROCEEDINGS OF THE 2019 ACM CONFERENCE ON ECONOMICS AND COMPUTATION, P807, DOI 10.1145/3328526.3329621; Kogan L, 2019, NBERWork. Pap. 29552; Kozlowski AC, 2019, AM SOCIOL REV, V84, P905, DOI 10.1177/0003122419877135; Larsen VH, 2019, J ECONOMETRICS, V210, P203, DOI 10.1016/j.jeconom.2018.11.013; Lerner Josh, 2021, 28999 NBER; Levy O, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P302, DOI 10.3115/v1/p14-2050; Li K, 2021, REV FINANC STUD, V34, P3265, DOI 10.1093/rfs/hhaa079; Lippmann Q, 2022, J PUBLIC ECON, V207, DOI 10.1016/j.jpubeco.2022.104610; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Manning C.D., 2008, Introduction to information retrieval; Mcauliffe J., 2007, Adv. Neural Inf. Process. Syst., V20; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Monarch R., 2021, Human -in-the -Loop Machine Learning: Active Learning and Annotation for Human -Centered AI; Mueller H, 2018, AM POLIT SCI REV, V112, P358, DOI 10.1017/S0003055417000570; Ng AY, 2002, ADV NEUR IN, V14, P841; OpenAI, 2023, Gpt-4 technical report, 2023.; Ornaghi A, 2020, Work. Pap.; Osnabrügge M, 2023, POLIT ANAL, V31, P59, DOI 10.1017/pan.2021.37; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng, 2006, AAAI, P342; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Phuong M, 2022, Arxiv, DOI [arXiv:2207.09238, DOI 10.48550/ARXIV.220709238]; Pryzant Reid, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume, V1, P1615; Radford A., 2018, IMPROVING LANGUAGE U; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Roberts ME, 2014, AM J POLIT SCI, V58, P1064, DOI 10.1111/ajps.12103; Rodriguez PL, 2022, J POLIT, V84, P101, DOI 10.1086/715162; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Ruiz FJR, 2020, ANN APPL STAT, V14, P1, DOI 10.1214/19-AOAS1265; Rydning J, 2021, Worldwide Global DataSphere and Global StorageSphere Structured and Unstructured Data Forecast, 2021-2025; Sacher S, 2024, Arxiv, DOI arXiv:2107.08112; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sedova A, 2021, Arxiv, DOI arXiv:2104.11557; Shapiro AH, 2022, J ECONOMETRICS, V228, P221, DOI 10.1016/j.jeconom.2020.07.053; Shen ZJ, 2021, LECT NOTES COMPUT SC, V12821, P131, DOI 10.1007/978-3-030-86549-8_9; Soto PE, 2021, J FINANC SERV RES, V59, P1, DOI 10.1007/s10693-020-00338-5; Stammbach D., 2022, Heroes, Villains, and Victims, and GPT-3: Automated Extraction of Character Roles Without Training Data, DOI DOI 10.48550/ARXIV.2205.07557; Taddy M, 2015, ANN APPL STAT, V9, P1394, DOI 10.1214/15-AOAS831; Taddy M, 2013, J AM STAT ASSOC, V108, P755, DOI 10.1080/01621459.2012.734168; Thorsrud LA, 2020, J BUS ECON STAT, V38, P393, DOI 10.1080/07350015.2018.1506344; Tiedemann J., 2020, P 22 ANN C EUROPEAN, P479; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Truffa F, 2022, Working paper; Vafa K., 2020, P 58 ANN M ASS COMP, P5345, DOI [10.18653/v1/2020.acl-main.475, DOI 10.18653/V1/2020.ACL-MAIN.475]; Vaswani A, 2017, ADV NEUR IN, V30; Wallach H, 2009, Adv. Neural Inf. Process. Syst, V22; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Widmer P, 2020, Work. Pap. 14; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174	132	3	3	12	17	ANNUAL REVIEWS	PALO ALTO	4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0139 USA	1941-1383	1941-1391		ANNU REV ECON	Annu. Rev. Econ.		2023	15						659	688		10.1146/annurev-economics-082222-074352	http://dx.doi.org/10.1146/annurev-economics-082222-074352			30	Economics	Social Science Citation Index (SSCI)	Business & Economics	R7HF0		Green Published, hybrid			2024-07-03	WOS:001066019400025
J	Dunn, C; Hunter, J; Steffes, W; Whitney, Z; Foss, M; Mammino, J; Leavitt, A; Hawkins, SD; Dane, A; Yungmann, M; Nathoo, R				Dunn, Charles; Hunter, Jacob; Steffes, William; Whitney, Zackary; Foss, Michael; Mammino, Jere; Leavitt, Adam; Hawkins, Spencer D.; Dane, Alexander; Yungmann, Martin; Nathoo, Rajiv			Artificial intelligence-derived dermatology case reports are indistinguishable from those written by humans: A single-blinded observer study	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Letter						artificial intelligence; case reports; ChatGPT; large language models; machine learning; medical writing			[Dunn, Charles; Steffes, William; Whitney, Zackary; Foss, Michael; Mammino, Jere; Leavitt, Adam; Dane, Alexander; Yungmann, Martin; Nathoo, Rajiv] KCU GME ADCS Consortium, Dept Dermatol, Maitland, FL USA; [Hunter, Jacob] Kansas City Univ, Dept Scholarly Act, Kansas City, MO USA; [Hawkins, Spencer D.] Deparment Dermatol Adv Dermatol & Cosmet Surg, East Greenwich, RI USA; [Dunn, Charles] Kansas City Univ, KCU GME ADCS Consortium, Grad Med Educ Adv Dermatol & Cosmet Surg Consortiu, Dept Dermatol, 151 Southhall Lane,Suite 300, Maitland, FL 32751 USA		Dunn, C (corresponding author), Kansas City Univ, KCU GME ADCS Consortium, Grad Med Educ Adv Dermatol & Cosmet Surg Consortiu, Dept Dermatol, 151 Southhall Lane,Suite 300, Maitland, FL 32751 USA.	DrCDunn@ADCSClinics.com	Hunter, Jacob/JGM-0016-2023					ChatGPT, about us; Cyr PR, 2014, INT J MED EDUC, V5, P18, DOI 10.5116/ijme.52c6.d7ef; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gao C. A., 2022, bioRxiv; Pividori M, 2023, bioRxiv, DOI [10.1101/2023.01.21.525030, 10.1101/2023.01.21.525030, DOI 10.1101/2023.01.21.525030]	5	17	18	3	10	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	AUG	2023	89	2					388	390		10.1016/j.jaad.2023.04.005	http://dx.doi.org/10.1016/j.jaad.2023.04.005		JUL 2023	3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	O0LG2	37054810				2024-07-03	WOS:001040816200001
J	Luong, TC; Tran, OT				Luong, Tho Chi; Tran, Oanh Thi			Product information recognition in the retail domain as an MRC problem	BIZNES INFORMATIKA-BUSINESS INFORMATICS			English	Article						product information recognition; MRC framework; retail domain; large-language models; viBERT; vELECTRA		This paper presents the task of recognizing product information (PI) (i.e., product names, prices, materials, etc.) mentioned in customer statements. This is one of the key components in developing artificial intelligence products to enable businesses to listen to their customers, adapt to market dynamics, continuously improve their products and services, and improve customer engagement by enhancing effectiveness of a chatbot. To this end, natural language processing (NLP) tools are commonly used to formulate the task as a traditional sequence labeling problem. However, in this paper, we bring the power of machine reading comprehension (MRC) tasks to propose another, alternative approach. In this setting, determining product information types is the same as asking "Which PI types are referenced in the statement?" For example, extracting product names (which corresponds to the label PRO_NAME) is cast as retrieving answer spans to the question "Which instances of product names are mentioned here?" We perform extensive experiments on a Vietnamese public dataset. The experimental results show the robustness of the proposed alternative method. It boosts the performance of the recognition model over the two robust baselines, giving a significant improvement. We achieved 92.87% in the F1 score on recognizing product descriptions at Level 1. At Level 2, the model yielded 93.34% in the F1 score on recognizing each product information type.	[Luong, Tho Chi] Vietnam Natl Univ, Inst Francophone Int, E5 144 Xuan Thuy St, Hanoi, Vietnam; [Tran, Oanh Thi] Vietnam Natl Univ, Int Sch, G7 144 Xuan Thuy St, Hanoi, Vietnam	Vietnam National University Hanoi; Vietnam National University Hanoi	Tran, OT (corresponding author), Vietnam Natl Univ, Int Sch, G7 144 Xuan Thuy St, Hanoi, Vietnam.	tholc@vnu.edu.vn; oanhtt@gmail.com			International School, Vietnam National University Hanoi [CS.NNC/2021-07]	International School, Vietnam National University Hanoi	This paper was funded by the International School, Vietnam National University Hanoi under the project CS.NNC/2021-07.	Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; The VB, 2020, Arxiv, DOI [arXiv:2006.15994, DOI 10.48550/ARXIV.2006.15994]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Goncharova E., 2021, CEUR-WS., V2972, P51; Ji ZC, 2014, Arxiv, DOI [arXiv:1408.6988, 10.48550/arXiv.1408.6988, DOI 10.48550/ARXIV.1408.6988]; Kingma D. P., 2017, ARXIV; Levy O, 2017, Arxiv, DOI arXiv:1706.04115; Li XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1340; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; McCann B, 2018, Arxiv, DOI arXiv:1806.08730; Tran OT, 2020, INT CONF KNOWL SYS, P269, DOI [10.1109/kse50997.2020.9287650, 10.1109/KSE50997.2020.9287650]; Tran OT, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103322; Qiu MH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P498, DOI 10.18653/v1/P17-2079; Therasa M., 2022, 2022 6th International Conference on Computing Methodologies and Communication (ICCMC), P1006, DOI 10.1109/ICCMC53470.2022.9754070; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Yan Z, 2017, AAAI CONF ARTIF INTE, P4618; Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237	17	0	0	3	3	NATL RESEARCH UNIV, HIGHER SCH ECONOMICS	MOSCOW	MYASNITSKAYA, 20, MOSCOW, 101000, RUSSIA	1998-0663			BIZN INFORM	Bizn. Inform.		2024	18	1					79	88		10.17323/2587-814X.2024.1.79.88	http://dx.doi.org/10.17323/2587-814X.2024.1.79.88			10	Business	Emerging Sources Citation Index (ESCI)	Business & Economics	MT5C1		gold			2024-07-03	WOS:001195889600004
J	Wei, WI; Leung, CLK; Tang, A; McNeil, EB; Wong, SYS; Kwok, KO				Wei, Wan In; Leung, Cyrus Lap Kwan; Tang, Arthur; McNeil, Edward Braddon; Wong, Samuel Yeung Shan; Kwok, Kin On			Extracting symptoms from free-text responses using ChatGPT among COVID-19 cases in Hong Kong	CLINICAL MICROBIOLOGY AND INFECTION			English	Article						ChatGPT; Entity recognition; Large language model; Symptom extraction; Symptom narratives; Symptom science		Objectives: To investigate the feasibility and performance of Chat Generative Pretrained Transformer (ChatGPT) in converting symptom narratives into structured symptom labels. Methods: We extracted symptoms from 300 deidentified symptom narratives of COVID-19 patients by a computer-based matching algorithm (the standard), and prompt engineering in ChatGPT. Common symptoms were those with a prevalence >10% according to the standard, and similarly less common symptoms were those with a prevalence of 2-10%. The precision of ChatGPT was compared with the standard using sensitivity and specificity with 95% exact binomial CIs (95% binCIs). In ChatGPT, we prompted without examples (zero-shot prompting) and with examples (few-shot prompting). Results: In zero-shot prompting, GPT-4 achieved high specificity (0.947 [95% binCI: 0.894-0.978]-1.000 [95% binCI: 0.965-0.988, 1.000]) for all symptoms, high sensitivity for common symptoms (0.853 [95% binCI: 0.689-0.950]-1.000 [95% binCI: 0.951-1.00 0]), and moderate sensitivity for less common symptoms (0.200 [95% binCI: 0.043-0.481]-1.000 [95% binCI: 0.590-0.815, 1.000]). Few-shot prompting increased the sensitivity and specificity. GPT-4 outperformed GPT-3.5 in response accuracy and consistent labelling. Discussion: This work substantiates ChatGPT's role as a research tool in medical fields. Its performance in converting symptom narratives to structured symptom labels was encouraging, saving time and effort in compiling the task-specific training data. It potentially accelerates free-text data compilation and synthesis in future disease outbreaks and improves the accuracy of symptom checkers. Focused prompt training addressing ambiguous descriptions impacts medical research positively. Wan In Wei, Clin Microbiol Infect 2024;30:142.e1-142.e3 (c) 2023 European Society of Clinical Microbiology and Infectious Diseases. Published by Elsevier Ltd. All rights reserved.	[Wei, Wan In; Leung, Cyrus Lap Kwan; McNeil, Edward Braddon; Wong, Samuel Yeung Shan; Kwok, Kin On] Chinese Univ Hong Kong, JC Sch Publ Hlth & Primary Care, Hong Kong, Peoples R China; [Tang, Arthur] RMIT Univ, Sch Sci Engn & Technol, Dept Informat Technol, Ho Chi Minh City, Vietnam; [Kwok, Kin On] Chinese Univ Hong Kong, Stanley Ho Ctr Emerging Infect Dis, Hong Kong, Peoples R China; [Kwok, Kin On] Chinese Univ Hong Kong, Hong Kong Inst Asia Pacific Studies, Hong Kong, Peoples R China; [Kwok, Kin On] Imperial Coll London, Sch Publ Hlth, Dept Infect Dis Epidemiol, London, England	Chinese University of Hong Kong; Royal Melbourne Institute of Technology (RMIT); Chinese University of Hong Kong; Chinese University of Hong Kong; Imperial College London	Kwok, KO (corresponding author), Chinese Univ Hong Kong, JC Sch Publ Hlth & Primary Care, Hong Kong, Peoples R China.	k.kwok@imperial.ac.uk	Tang, Arthur/C-8784-2009	Tang, Arthur/0000-0002-6655-6883	Health and Medical Research Fund [20210232, CID-CUHK-A, COVID1903008, 14112818, 17160302]; General Research Fund [24104920, 200861/Z/16/Z]; Welcome Trust Fund [INF-CUHK-1]; Group Research Scheme of The Chinese University of Hong Kong;  [18170312]	Health and Medical Research Fund; General Research Fund; Welcome Trust Fund(Wellcome Trust); Group Research Scheme of The Chinese University of Hong Kong; 	We would like to acknowledge support from the Health and Medical Research Fund (reference numbers: INF-CUHK-1, 17160302, 18170312, 20210232, CID-CUHK-A, COVID1903008) , General Research Fund (reference numbers: 14112818, 24104920) , Welcome Trust Fund (reference number: 200861/Z/16/Z) and Group Research Scheme of The Chinese University of Hong Kong. This work formed part of the doctoral thesis requirements for Wan In WEI.	Ceney A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254088; chp, HKSARG Department of health Declaration system for individuals tested positive for COVID-19 using Rapid Antigen test; Dorsey SG, 2019, NURS RES, V68, P86, DOI 10.1097/NNR.0000000000000339; Edelman EJ, 2011, AIDS BEHAV, V15, P853, DOI 10.1007/s10461-010-9706-z; Ellen Fragaszy, 2022, Wellcome Open Research; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173; Kwok KO, 2023, medRxiv, DOI [10.1101/2023.05.25.23289996, 10.1101/2023.05.25.23289996, DOI 10.1101/2023.05.25.23289996]; Kwok KO, 2023, J TRAVEL MED, V30, DOI 10.1093/jtm/taad058; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Malden DE, 2022, JMIR PUBLIC HLTH SUR, V8, DOI 10.2196/41529; Mehnen L, 2023, medRxiv, DOI [10.1101/2023.04.20.23288859, 10.1101/2023.04.20.23288859, DOI 10.1101/2023.04.20.23288859]; Menni C, 2022, LANCET, V399, P1618, DOI 10.1016/S0140-6736(22)00327-0; openai, GPT-4; openai, INTR CHATGPT; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Pickler RH, 2020, NURS RES, V69, P89, DOI 10.1097/NNR.0000000000000416; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Semigran HL, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h3480; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Vihta Karina Doris, 2022, Clin Infect Dis, DOI 10.1093/cid/ciac613; Whitaker M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-34244-2	22	4	4	11	13	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1198-743X	1469-0691		CLIN MICROBIOL INFEC	Clin. Microbiol. Infect.	JAN	2024	30	1					142e1	142e3		10.1016/j.cmi.2023.11.002	http://dx.doi.org/10.1016/j.cmi.2023.11.002		DEC 2023	3	Infectious Diseases; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Infectious Diseases; Microbiology	IG2I1	37949111				2024-07-03	WOS:001165106600001
J	Bernstorff, M; Vistisen, ST; Enevoldsen, KC				Bernstorff, Martin; Vistisen, Simon Tilma; Enevoldsen, Kenneth C.			Natural language processing for electronic health records in anaesthesiology: an introduction to clinicians with recommendations and pitfalls	JOURNAL OF CLINICAL MONITORING AND COMPUTING			English	Editorial Material						Natural language processing; Large language model; Machine learning; Prediction model; Surgical duration			[Bernstorff, Martin; Enevoldsen, Kenneth C.] Aarhus Univ Hosp Psychiat, Dept Affect Disorders, Aarhus, Denmark; [Bernstorff, Martin; Vistisen, Simon Tilma; Enevoldsen, Kenneth C.] Aarhus Univ, Dept Clin Med, Aarhus, Denmark; [Bernstorff, Martin; Enevoldsen, Kenneth C.] Aarhus Univ, Ctr Humanities Comp, Jens Chr Skous Vej 4, DK-8200 Aarhus N, Denmark; [Vistisen, Simon Tilma] Aarhus Univ Hosp, Dept Anaesthesiol & Intens Care, Palle Juul Jensens Blvd 99, DK-8200 Aarhus N, Denmark; [Enevoldsen, Kenneth C.] Aarhus Univ, Quantitat Genom Grp, Aarhus, Denmark	Aarhus University; Aarhus University; Aarhus University; Aarhus University	Vistisen, ST (corresponding author), Aarhus Univ, Dept Clin Med, Aarhus, Denmark.; Vistisen, ST (corresponding author), Aarhus Univ Hosp, Dept Anaesthesiol & Intens Care, Palle Juul Jensens Blvd 99, DK-8200 Aarhus N, Denmark.	manber@rm.dk; vistisen@clin.au.dk; kenneth.enevoldsen@cas.au.dk		Vistisen, Simon Tilma/0000-0002-1297-1459; Enevoldsen, Kenneth C./0000-0001-8733-0966; Bernstorff, Martin/0000-0002-0234-5390				Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Danielsen AA, 2019, ACTA PSYCHIAT SCAND, V140, P147, DOI 10.1111/acps.13061; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Huang K., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.1904.05342; Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Schmidt RM, 2019, ARXIV, P23, DOI [10.48550/arXiv.1912.05911, DOI 10.48550/ARXIV.1912.05911]; Sculley D, 2015, ADV NEUR IN, V28; Vaswani A, 2017, ADV NEUR IN, V30; Vistisen ST, 2022, EUR J ANAESTH, V39, P729, DOI 10.1097/EJA.0000000000001696; Zhong W, 2023, RADIOLOGY REPORTS	11	0	0	8	8	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1387-1307	1573-2614		J CLIN MONIT COMPUT	J. Clin. Monitor. Comp.	APR	2024	38	2					241	245		10.1007/s10877-024-01128-3	http://dx.doi.org/10.1007/s10877-024-01128-3		FEB 2024	5	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	MX8J8	38310589	Green Published, hybrid			2024-07-03	WOS:001156905700001
C	Tanaka, H; Nakamura, S; Martin, JC; Pelachaud, C			ACM	Tanaka, Hiroki; Nakamura, Satoshi; Martin, Jean-Claude; Pelachaud, Catherine			4thWorkshop on Social Afective Multimodal Interaction for Health (SAMIH)	PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023			English	Proceedings Paper	25th International Conference on Multimodal Interaction (ICMI)	OCT 09-13, 2023	Sorbonne Univ, Paris, FRANCE	Assoc Comp Machinery, ACM SIGCHI, Openstreams Ai, Living & Learning Lab Neurodevelopment, CCC Comp Community Consortium Catalyst, AFIHM, Persyval Lab, Grenoble Informat Lab, Univ Grenoble Alpes, Sorbonne Ctr Artificial Intelligence	Sorbonne Univ	cognitive behavioral therapy; motivational interview; social skills training; social signal processing; afective computing; virtual agents; large language models		This workshop discusses how interactive, multimodal technology, such as virtual agents, can measure and train social-afective interactions. Sensing technology nowenables analyzing users' behaviors and physiological signals. Various signal processing and machine learning methods can be used for prediction tasks. Such social signal processing and tools can be applied to measure and reduce social stress in everyday situations, including public speaking at schools and workplaces.	[Tanaka, Hiroki; Nakamura, Satoshi] Nara Inst Sci & Technol, Ikoma, Japan; [Martin, Jean-Claude] Univ Paris Saclay, CNRS, LISN, Gif Sur Yvette, France; [Pelachaud, Catherine] Sorbonne Univ, CNRS, ISIR, Paris, France	Nara Institute of Science & Technology; Centre National de la Recherche Scientifique (CNRS); Universite Paris Saclay; Universite Paris Cite; Centre National de la Recherche Scientifique (CNRS); Sorbonne Universite	Tanaka, H (corresponding author), Nara Inst Sci & Technol, Ikoma, Japan.	hiroki-tan@is.naist.jp; s-nakamura@is.naist.jp; martin@limsi.fr; catherine.pelachaud@upmc.fr			JST CREST Grant, Japan [JPMJCR19M5-1];  [ANR-19-JSTS-0001]	JST CREST Grant, Japan; 	We would like to thank ANR-CREST-TAPAS Japan - France project. This workshop was funded by the JST CREST Grant Number JPMJCR19M5-1, Japan and ANR-19-JSTS-0001, France (TAPAS).	[Anonymous], 2015, P 20 INT C INTELLIGE, DOI DOI 10.1145/2678025.2701386; Burke SL, 2018, J AUTISM DEV DISORD, V48, P905, DOI 10.1007/s10803-017-3374-z; Daniels J, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0035-3; Grynszpa O, 2019, RES AUTISM SPECT DIS, V67, DOI 10.1016/j.rasd.2019.101441; Hemamou L, 2019, INT CONF AFFECT, DOI 10.1109/acii.2019.8925439; Hemamou L, 2019, AAAI CONF ARTIF INTE, P573; Poggi I, 2005, TEXT SPEECH LANG TEC, V27, P3, DOI 10.1007/1-4020-3051-7_1; Shidara K, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.762424; Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151; Tanaka Hiroki, 2022, 3 WORKSHOP SOCIAL AF, P805; Tanaka Hiroki, 2021, 2 WORKSHOP SOCIAL AF, P853; Tanaka Hiroki, 2020, P 2020 INT C MULTIMO, P893, DOI [10.1145/3382507.3420059, DOI 10.1145/3382507.3420059]	12	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0055-2				2023							816	817		10.1145/3577190.3616878	http://dx.doi.org/10.1145/3577190.3616878			2	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GP					2024-07-03	WOS:001147764700102
J	Chen, YF; Zhang, SQ; Tang, N; George, DM; Huang, TL; Tang, JP				Chen, Yifan; Zhang, Shengqun; Tang, Ning; George, Daniel M.; Huang, Tianlong; Tang, Jinping			Using Google web search to analyze and evaluate the application of ChatGPT in femoroacetabular impingement syndrome	FRONTIERS IN PUBLIC HEALTH			English	Article						ChatGPT; machine learning; femoroacetabular impingement syndrome (FAI); large language model; Google	ARTIFICIAL-INTELLIGENCE; INFORMATION; INTERNET; TRENDS	Background Chat Generative Pre-trained Transformer (ChatGPT) is a new machine learning tool that allows patients to access health information online, specifically compared to Google, the most commonly used search engine in the United States. Patients can use ChatGPT to better understand medical issues. This study compared the two search engines based on: (i) frequently asked questions (FAQs) about Femoroacetabular Impingement Syndrome (FAI), (ii) the corresponding answers to these FAQs, and (iii) the most FAQs yielding a numerical response.Purpose To assess the suitability of ChatGPT as an online health information resource for patients by replicating their internet searches.Study design Cross-sectional study.Methods The same keywords were used to search the 10 most common questions about FAI on both Google and ChatGPT. The responses from both search engines were recorded and analyzed.Results Of the 20 questions, 8 (40%) were similar. Among the 10 questions searched on Google, 7 were provided by a medical practice. For numerical questions, there was a notable difference in answers between Google and ChatGPT for 3 out of the top 5 most common questions (60%). Expert evaluation indicated that 67.5% of experts were satisfied or highly satisfied with the accuracy of ChatGPT's descriptions of both conservative and surgical treatment options for FAI. Additionally, 62.5% of experts were satisfied or highly satisfied with the safety of the information provided. Regarding the etiology of FAI, including cam and pincer impingements, 52.5% of experts expressed satisfaction or high satisfaction with ChatGPT's explanations. Overall, 62.5% of experts affirmed that ChatGPT could serve effectively as a reliable medical resource for initial information retrieval.Conclusion This study confirms that ChatGPT, despite being a new tool, shows significant potential as a supplementary resource for health information on FAI. Expert evaluations commend its capacity to provide accurate and comprehensive responses, valued by medical professionals for relevance and safety. Nonetheless, continuous improvements in its medical content's depth and precision are recommended for ongoing reliability. While ChatGPT offers a promising alternative to traditional search engines, meticulous validation is imperative before it can be fully embraced as a trusted medical resource.	[Chen, Yifan; Zhang, Shengqun; Huang, Tianlong] Cent South Univ, Orthopaed Dept, Xiangya Hosp 2, Changsha, Peoples R China; [Tang, Ning] Cent South Univ, Orthopaed Dept, Xiangya Hosp 3, Changsha, Peoples R China; [George, Daniel M.] Royal Adelaide Hosp, Adelaide, SA, Australia; [Tang, Jinping] Third Peoples Hosp Chenzhou, Dept Orthopaed, Chenzhou, Hunan, Peoples R China	Central South University; Central South University; Royal Adelaide Hospital	Huang, TL (corresponding author), Cent South Univ, Orthopaed Dept, Xiangya Hosp 2, Changsha, Peoples R China.; Tang, JP (corresponding author), Third Peoples Hosp Chenzhou, Dept Orthopaed, Chenzhou, Hunan, Peoples R China.	tianlong.huang@csu.edu.cn; 737555088@qq.com			Hunan Provincial Natural Science Foundation of China [2021JJ30932]	Hunan Provincial Natural Science Foundation of China(Natural Science Foundation of Hunan Province)	The author(s) declare that financial support was received for the research, authorship, and/or publication of this article. This work was supported by the Hunan Provincial Natural Science Foundation of China for the year 2021 (Grant No. 2021JJ30932).	[Anonymous], 2016, Statista Research Department Number of search engine users in the United States from 2014 to 2020 (in millions); Antony J, 2016, INT C PATT RECOG, P1195, DOI 10.1109/ICPR.2016.7899799; Bidmon S, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4127; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Cabitza F, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00075; Cassidy JT, 2016, J BONE JOINT SURG AM, V98, P325, DOI 10.2106/JBJS.N.01189; Chen PJ, 2019, COMPUT MED IMAG GRAP, V75, P84, DOI 10.1016/j.compmedimag.2019.06.002; Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714; Cline RJW, 2001, HEALTH EDUC RES, V16, P671, DOI 10.1093/her/16.6.671; Daraz L, 2019, J GEN INTERN MED, V34, P1884, DOI 10.1007/s11606-019-05109-0; Dehghani M, 2017, BEHAV RES METHODS, V49, P538, DOI 10.3758/s13428-016-0722-4; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Ellis DJ, 2015, GLOB SPINE J, V5, P436, DOI 10.1055/s-0035-1551650; Fraval A, 2015, BMC MUSCULOSKEL DIS, V16, DOI 10.1186/s12891-015-0466-9; Fraval A, 2012, AUSTRALAS MED J, V5, P633, DOI 10.4066/AMJ.2012.1530; Gilat R, 2023, ARTHROSCOPY, V39, P1119, DOI 10.1016/j.arthro.2023.01.014; Groot OQ, 2022, J ORTHOP RES, V40, P475, DOI 10.1002/jor.25036; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haeberle HS, 2019, J ARTHROPLASTY, V34, P2201, DOI 10.1016/j.arth.2019.05.055; Hale RF, 2021, AM J SPORT MED, V49, P35, DOI 10.1177/0363546520970914; Hariri N, 2013, ONLINE INFORM REV, V37, P287, DOI 10.1108/OIR-12-2011-0210; Helm JM, 2020, CURR REV MUSCULOSKE, V13, P69, DOI 10.1007/s12178-020-09600-8; Kanthawala S, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5369; Karnuta JM, 2021, J ARTHROPLASTY, V36, pS290, DOI 10.1016/j.arth.2020.11.015; Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015; Lalehzarian SP, 2021, WORLD J ORTHOP, V12, P685, DOI 10.5312/wjo.v12.i9.685; López-Jornet P, 2009, ORAL ONCOL, V45, pE95, DOI 10.1016/j.oraloncology.2009.03.017; Mont MA, 2019, J ARTHROPLASTY, V34, P2199, DOI 10.1016/j.arth.2019.08.017; Nayak P., 2019, The keyword, P295; Neuprez A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167911; Polesie S, 2023, ACTA DERM-VENEREOL, V103, DOI 10.2340/actadv.v103.9593; Roblot V, 2019, DIAGN INTERV IMAG, V100, P243, DOI 10.1016/j.diii.2019.02.007; Rothwell J.D., 2013, MIXED CO COMMUNICATI; Siebenrock KA, 2011, CLIN ORTHOP RELAT R, V469, P3229, DOI 10.1007/s11999-011-1945-4; Starman JS, 2010, J BONE JOINT SURG AM, V92A, P1612, DOI 10.2106/JBJS.I.00821; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sun YL, 2019, J MED INTERNET RES, V21, DOI 10.2196/12522; Susnjak T., 2022, ChatGPT: The end of online exam integrity?, P19; Tang N, 2021, ORTHOP SURG, V13, P1922, DOI 10.1111/os.13037; Tripathi S, 2019, LECT NOTES COMPUT SC, V11608, P54, DOI 10.1007/978-3-030-23281-8_5; Wang VM, 2020, J AM ACAD ORTHOP SUR, V28, pE415, DOI 10.5435/JAAOS-D-19-00688; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Yi PH, 2020, KNEE, V27, P535, DOI 10.1016/j.knee.2019.11.020; Zhang Y, 2015, J ASSOC INF SCI TECH, V66, P2071, DOI 10.1002/asi.23311	45	0	0	1	1	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-2565		FRONT PUBLIC HEALTH	Front. Public Health	MAY 31	2024	12								1412063	10.3389/fpubh.2024.1412063	http://dx.doi.org/10.3389/fpubh.2024.1412063			10	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	UC4A2	38883198	gold			2024-07-03	WOS:001245837200001
J	Yavuz, YE; Kahraman, F				Yavuz, Yunus Emre; Kahraman, Fatih			Evaluation of the prediagnosis and management of ChatGPT-4.0 in clinical cases in cardiology	FUTURE CARDIOLOGY			English	Article; Early Access						artificial intelligence; cardiology; ChatGPT; clinical decision support systems; large language models	ARTIFICIAL-INTELLIGENCE	<bold>Aim:</bold> Evaluation of the performance of ChatGPT-4.0 in providing prediagnosis and treatment plans for cardiac clinical cases by expert cardiologists. <bold>Methods:</bold> 20 cardiology clinical cases developed by experienced cardiologists were divided into two groups according to preparation methods. Cases were reviewed and analyzed by the ChatGPT-4.0 program, and analyses of ChatGPT were then sent to cardiologists. Eighteen expert cardiologists evaluated the quality of ChatGPT-4.0 responses using Likert and Global quality scales. <bold>Results:</bold> Physicians rated case difficulty (median 2.00), revealing high ChatGPT-4.0 agreement to differential diagnoses (median 5.00). Management plans received a median score of 4, indicating good quality. Regardless of the difficulty of the cases, ChatGPT-4.0 showed similar performance in differential diagnosis (p: 0.256) and treatment plans (p: 0.951). <bold>Conclusion:</bold> ChatGPT-4.0 excels at delivering accurate management and demonstrates its potential as a valuable clinical decision support tool in cardiology.	[Yavuz, Yunus Emre] Siirt Training & Res Hosp, Dept Cardiol, TR-56100 Siirt, Turkiye; [Kahraman, Fatih] Kutahya Evliya Celebi Training & Res Hosp, Dept Cardiol, TR-43000 Kutahya, Turkiye	Kutahya Evliya Celebi Training & Research Hospital	Yavuz, YE (corresponding author), Siirt Training & Res Hosp, Dept Cardiol, TR-56100 Siirt, Turkiye.	yemre91@icloud.com	yavuz, yunus emre/KTI-6762-2024	Kahraman, Fatih/0000-0003-3860-2755				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; [Anonymous], 2023, Openai; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; El Sherbini A, 2024, PROG CARDIOVASC DIS, V84, P76, DOI 10.1016/j.pcad.2024.03.002; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Jansz J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41879; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Ledzinski L, 2023, J CARDIOVASC DEV DIS, V10, DOI 10.3390/jcdd10050202; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Lin F, 2024, MED-CAMBRIDGE, V5, DOI 10.1016/j.medj.2024.02.006; Lin G., 2023, AI in cardiology and cardiac surgery, P144; Martínez-Sellés M, 2023, J CARDIOVASC DEV DIS, V10, DOI 10.3390/jcdd10040175; Miller Robert J H, 2024, Semin Nucl Med, DOI 10.1053/j.semnuclmed.2024.02.005; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Vidal-Perez R, 2023, WORLD J CARDIOL, V15, P116, DOI 10.4330/wjc.v15.i4.116; Ye Y., 2023, MedcommFuture Medicine, DOI [10.1002/mef2.51, DOI 10.1002/MEF2.51]	24	0	0	0	0	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1479-6678	1744-8298		FUTUR CARDIOL	Futur. Cardiol.	2024 MAY 16	2024										10.1080/14796678.2024.2348898	http://dx.doi.org/10.1080/14796678.2024.2348898		MAY 2024	11	Cardiac & Cardiovascular Systems	Emerging Sources Citation Index (ESCI)	Cardiovascular System & Cardiology	RG9A8					2024-07-03	WOS:001226619600001
J	Sandnes, FE				Sandnes, Frode Eika			Can we identify prominent scholars using ChatGPT?	SCIENTOMETRICS			English	Article						Evaluating; Research impact; Research visibility; ChatGPT; Large language models; Scientometrics; Bibliometrics		It may be tempting to learn about scholars using ChatGPT. To validate ChatGPT for this task a small experiment was conducted based on the 50 most cited researchers at the author's university. The results show that ChatGPT (GPT-3.5) only recognized an adhoc subset of the scholars with no obvious connection to the respective authors' citation attributes or internet footprint. Moreover, details about the recognized scholars were often erroneous.	[Sandnes, Frode Eika] Oslo Metropolitan Univ, Dept Comp Sci, N-0130 Oslo, Norway	Oslo Metropolitan University (OsloMet)	Sandnes, FE (corresponding author), Oslo Metropolitan Univ, Dept Comp Sci, N-0130 Oslo, Norway.	frodes@oslomet.no		Sandnes, Frode Eika/0000-0001-7781-748X				Aczel B., 2023, Transparency guidance for chatgpt usage in scientific writing; Carniel Theophile, 2023, Biomimetic and Biohybrid Systems: 12th International Conference, Living Machines 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14158), P257, DOI 10.1007/978-3-031-39504-8_18; de Winter J., 2023, TRANSFORMING SCIENTO; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eika E, 2022, SCIENTOMETRICS, V127, P6363, DOI 10.1007/s11192-022-04521-4; Farhat F., 2023, ANAL SCHOLARLY FOOTP; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Khosravi H., 2023, ARXIV; Kirtania D. K., 2023, CHATGPT TOOL BIBLIOM; Lotfigolian M, 2023, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023, P95, DOI 10.1145/3594806.3594828; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Orduña-Malea E, 2023, SCIENTOMETRICS, V128, P5351, DOI 10.1007/s11192-023-04804-4; Pereira V., 2023, ARXIV; Petiska E., 2023, ARXIV; Sandnes FE, 2021, SCIENTOMETRICS, V126, P6105, DOI 10.1007/s11192-021-04004-y; Sandnes FE, 2020, SCIENTOMETRICS, V124, P1685, DOI 10.1007/s11192-020-03521-6; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; TANG L., 2023, arXiv; Tomlinson B., 2023, ARXIV	21	1	1	36	45	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0138-9130	1588-2861		SCIENTOMETRICS	Scientometrics	JAN	2024	129	1					713	718		10.1007/s11192-023-04882-4	http://dx.doi.org/10.1007/s11192-023-04882-4		NOV 2023	6	Computer Science, Interdisciplinary Applications; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	ES5M9					2024-07-03	WOS:001107757700001
J	Arrivé, L; Minssen, L; Ali, A				Arrive, Lionel; Minssen, Lise; Ali, Amal			ChatGPT risk of fabrication in literature searches.	BRITISH JOURNAL OF ANAESTHESIA			English	Letter						artificial intelligence; bibliography; ChatGPT; citations; generative pretrained transformer; large language models			[Arrive, Lionel] St Antoine Hosp, AP HP, Dept Radiol, Paris, France; Sorbonne Univ, Paris, France	Assistance Publique Hopitaux Paris (APHP); Sorbonne Universite; Hopital Universitaire Saint-Antoine - APHP; Sorbonne Universite	Arrivé, L (corresponding author), St Antoine Hosp, AP HP, Dept Radiol, Paris, France.	lionel.arrive@aphp.fr		Arrive, Lionel/0000-0002-0267-109X				Aldridge MJ, 2023, BRIT J ANAESTH, V131, pe36, DOI 10.1016/j.bja.2023.04.033; Birkett L, 2023, BRIT J ANAESTH, V131, pe34, DOI 10.1016/j.bja.2023.04.025; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; Grigio TR, 2023, BRIT J ANAESTH, V131, pE29, DOI 10.1016/j.bja.2023.04.009; Pozdnyakov A, 2023, DIAGN INTERV IMAG, V104, P265, DOI 10.1016/j.diii.2023.01.007; Shay D, 2023, BRIT J ANAESTH, V131, DOI 10.1016/j.bja.2023.04.017; Wang XX, 2018, ACS NANO, V12, P8588, DOI 10.1021/acsnano.8b04244	7	0	0	11	25	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	NOV	2023	131	5					E172	E173		10.1016/j.bja.2023.07.024	http://dx.doi.org/10.1016/j.bja.2023.07.024		OCT 2023	2	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	X3CO0	37625909				2024-07-03	WOS:001097268000001
C	Denny, P; Kumar, V; Giacaman, N			ACM	Denny, Paul; Kumar, Viraj; Giacaman, Nasser			Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language	PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023			English	Proceedings Paper	54th Annual ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS)	MAR 15-18, 2023	Toronto, CANADA	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		OpenAI; GitHub Copilot; foundation models; large language models; CS1; artificial intelligence; introductory programming		GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.	[Denny, Paul; Giacaman, Nasser] Univ Auckland, Auckland, New Zealand; [Kumar, Viraj] Indian Inst Sci, Bengaluru, India	University of Auckland; Indian Institute of Science (IISC) - Bangalore	Denny, P (corresponding author), Univ Auckland, Auckland, New Zealand.	paul@cs.auckland.ac.nz; viraj@iisc.ac.in; n.giacaman@auckland.ac.nz		Denny, Paul/0000-0002-5150-9806				Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Barke S, 2022, Arxiv, DOI [arXiv:2206.15000, DOI 10.48550/ARXIV.2206.15000]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Cunningham K., Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. CHI'21. Yokohama, p2021. isbn, DOI 10.1145/3411764.3445571; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Ernst NA, 2022, IEEE SOFTWARE, V39, P106, DOI 10.1109/MS.2021.3133805; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gulwani Sumit, 2010, P 12 INT ACM SIGPLAN, P13, DOI [10.1145/1836089.1836091, DOI 10.1145/1836089.1836091]; Heyman Geert, 2021, Onward! 2021: Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, P39, DOI 10.1145/3486607.3486749; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870; Kumar Deepak, 2018, ACM Inroads, V9, P22, DOI [10.1145/3233246, DOI 10.1145/3233246]; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Ramesh A., 2022, arXiv; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Shin J, 2021, J INF PROCESS SYST, V17, P537; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tang L, 2022, LECT NOTES COMPUT SC, V13356, P612, DOI 10.1007/978-3-031-11647-6_127; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665	26	45	45	10	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9431-4				2023							1136	1142		10.1145/3545945.3569823	http://dx.doi.org/10.1145/3545945.3569823			7	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW2KI		Green Submitted, Green Accepted			2024-07-03	WOS:001117817800164
J	Chen, LQ; Zhang, Y; Han, J; Sun, LY; Childs, P; Wang, BH				Chen, Liuqing; Zhang, Yuan; Han, Ji; Sun, Lingyun; Childs, Peter; Wang, Boheng			A foundation model enhanced approach for generative design in combinational creativity	JOURNAL OF ENGINEERING DESIGN			English	Article; Early Access						Combinational creativity; generative design; large language models; text-to-image models		In creativity theory, combining two unrelated concepts into a novel idea is a common means of enhancing creativity. Designers can integrate the Additive concept into the Base concept to inspire and facilitate creative tasks. However, conceiving high-quality combinational ideas poses a challenge that combinational creativity itself demands the consideration of conceptual reasoning and synthesis. We propose an AI foundation model enhanced approach for supporting combinational creativity. This approach derives combinational embodiments, and assists humans in verbalising and externalising combinational ideas. Our experimental study demonstrates that the generated combinational ideas by the approach obtained highest scores compared to those ideas generated without an AI foundation model or combinational strategy. We built a combinational creativity tool called CombinatorX based on this approach to generate ideas. In a study with the comparison of an existing combinational creativity tool and Internet search, we validated that our approach improves the effectiveness of combinational idea generation, enables a reduction in labour force, and facilitates the refinement of combinational ideation.	[Chen, Liuqing; Zhang, Yuan; Sun, Lingyun] Zhejiang Univ, Dept Comp Sci & Technol, Hangzhou, Peoples R China; [Han, Ji] Univ Exeter, Dept Innovat Technol & Entrepreneurship, Exeter, England; [Childs, Peter; Wang, Boheng] Imperial Coll London, Dyson Sch Design Engn, London, England	Zhejiang University; University of Exeter; Imperial College London	Wang, BH (corresponding author), Imperial Coll London, Dyson Sch Design Engn, London, England.	b.wang21@imperial.ac.uk	Chen, Liuqing/HPE-0376-2023	Chen, Liuqing/0000-0002-9049-0394; Childs, Peter/0000-0002-2465-8822	National Key R&D Program of China [2022YFB3303304]; National Natural Science Foundation of China [62207023]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research is supported by National Key R&D Program of China (2022YFB3303304) and National Natural Science Foundation of China (62207023).	Bang Y, 2023, P 13 INT JOINT C NAT, P675, DOI [DOI 10.18653/V1/2023.IJCNLP--MAIN.45, DOI 10.18653/V1/2023.IJCNLP-MAIN.45]; Bar-Cohen Y, 2006, BIOINSPIR BIOMIM, V1, pP1, DOI 10.1088/1748-3182/1/1/P01; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bian N, 2024, Arxiv, DOI arXiv:2303.16421; Boden Margaret A., 2004, The creative mind: Myths and mechanisms, DOI DOI 10.4324/9780203508527; Bonnardel N., 2004, Creativity and Innovation Management, V13, P176, DOI [DOI 10.1111/j.0963-1690.2004.00307.x, DOI 10.1111/J.0963-1690.2004.00307.X]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen LQ, 2019, J VIS COMMUN IMAGE R, V61, P10, DOI 10.1016/j.jvcir.2019.02.009; Childs P, 2022, J INTELL-BASEL, V10, DOI 10.3390/jintelligence10040073; Chowdhery A, 2023, J MACH LEARN RES, V24; Craft A., 2001, CREATIVITY ED; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diao SZ, 2024, Arxiv, DOI arXiv:2302.12246; Eppe M, 2018, ARTIF INTELL, V256, P105, DOI 10.1016/j.artint.2017.11.005; Eugeni Q., 2020, Love Chair; Göring S, 2023, IEEE ACCESS, V11, P38999, DOI 10.1109/ACCESS.2023.3267968; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Guan J, 2024, Arxiv, DOI arXiv:2310.14564; Han J., 2020, P DES SOC DESIGN C, V1, P177, DOI [10.1017/dsd.2020.36, DOI 10.1017/DSD.2020.36]; Han J, 2018, DES SCI, V4, DOI 10.1017/dsj.2018.7; Helman D. H., 2013, Analogical Reasoning: Perspectives of Artificial Intelligence, Cognitive Science, and Philosophy; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Huang DL, 2019, BOUND VALUE PROBL, DOI 10.1186/s13661-019-1169-1; Issa L., 2019, Computational Creativity: The Design of a Creative Computer Program, V198, DOI [10.1109/IACS.2019.8809107, DOI 10.1109/IACS.2019.8809107]; Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099; Jansson D.G., 1991, DESIGN STUDIES, V12, P3, DOI [10.1016/0142-694X(91)90003-F, DOI 10.1016/0142-694X(91)90003-F]; Kaufman J.C., 2010, CAMBRIDGE HDB CREATI, DOI DOI 10.1017/CBO9780511763205.029; Keith L., 2016, Baby Bottle Drying Rack organicKidz Baby Bottle Tree; Ken Okuyama Design Co. Ltd., 2016, Teaware ORIGAMI; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Koizumi S., 2021, Kanpai Bell Pair; Koralus Philipp., 2023, arXiv; Koronis G, 2023, J CREATIVE BEHAV, V57, P711, DOI 10.1002/jocb.611; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lloyd-Cox J, 2021, PSYCHOL AESTHET CREA, V15, P575, DOI 10.1037/aca0000371; Marcus G, 2020, Arxiv, DOI [arXiv:2002.06177, DOI 10.48550/ARXIV.2002.06177]; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; OpenAI, 2023, OpenAI Terms of Use; Pavlichenko N, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2067, DOI 10.1145/3539618.3592000; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Shah J. J., 2003, Design Studies, V24, P111, DOI 10.1016/S0142-694X(02)00034-0; Shneiderman B, 2007, COMMUN ACM, V50, P20, DOI 10.1145/1323688.1323689; Suresh S., 2023, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. EMNLP 2023, P722, DOI [https://doi.org/10.18653/v1/2023.emnlp-main.47, DOI 10.18653/V1/2023.EMNLP-MAIN.47]; Tan LN, 2024, DES J, DOI 10.1080/14606925.2024.2353479; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; Veale Tony., 2019, Computational Creativity: The Philosophy and Engineering of Autonomously Creative Systems, P71, DOI [https://doi.org/10.1007/978-3-319-43610-44, DOI 10.1007/978-3-319-43610-44]; Wallace Benedikte, 2021, Artificial Intelligence in Music, Sound, Art and Design. 10th International Conference, EvoMUSART 2021. Held as Part of EvoStar 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12693), P344, DOI 10.1007/978-3-030-72914-1_23; Wang BH, 2023, AI EDAM, V37, DOI 10.1017/S0890060423000069; Wang ST, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580948; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Wei-Chieh L., 2023, SADDLE Chair/Lounge Chair; Weisz JD, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P402, DOI 10.1145/3397481.3450656; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wu XP, 2024, DES J, V27, P270, DOI 10.1080/14606925.2024.2303236; Yang J., 2023, PREPRINT; Yu-Hsu Lee, 2023, Human Interface and the Management of Information: Thematic Area, HIMI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Proceedings. Lecture Notes in Computer Science (14015), P502, DOI 10.1007/978-3-031-35132-7_38; Zhang M, 2021, FUND RES-CHINA, V1, P831, DOI 10.1016/j.fmre.2021.11.011; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zuo HY, 2022, J INTELL-BASEL, V10, DOI 10.3390/jintelligence10040103	66	0	0	2	2	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0954-4828	1466-1837		J ENG DESIGN	J. Eng. Des.	2024 MAY 28	2024										10.1080/09544828.2024.2356707	http://dx.doi.org/10.1080/09544828.2024.2356707		MAY 2024	27	Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	SI5I2		hybrid			2024-07-03	WOS:001233834200001
J	De Freitas, J; Uguralp, AK; Oguz-Uguralp, Z; Puntoni, S				De Freitas, Julian; Uguralp, Ahmet Kaan; Oguz-Uguralp, Zeliha; Puntoni, Stefano			Chatbots and mental health: Insights into the safety of generative AI	JOURNAL OF CONSUMER PSYCHOLOGY			English	Article; Early Access						artificial intelligence; chatbots; ethics; generative AI; large language models; mental health	PEOPLE; DISCRIMINATION; DEPRESSION; ALGORITHM; RESPONSES; IMPACT; HELP	Chatbots are now able to engage in sophisticated conversations with consumers. Due to the "black box" nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and "companion AI": Applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: Actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a nonnegligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies.	[De Freitas, Julian] Harvard Sch Business, Mkt, Soldiers Field Morgan Hall 161, Boston, MA 02163 USA; [Uguralp, Ahmet Kaan] Bilkent Univ, Comp Sci, Ankara, Turkiye; [Oguz-Uguralp, Zeliha] Bilkent Univ, Psychol, Ankara, Turkiye; [Puntoni, Stefano] Univ Penn, Wharton Sch, Mkt, Philadelphia, PA USA	Harvard University; Ihsan Dogramaci Bilkent University; Ihsan Dogramaci Bilkent University; University of Pennsylvania	De Freitas, J (corresponding author), Harvard Sch Business, Mkt, Soldiers Field Morgan Hall 161, Boston, MA 02163 USA.	jdefreitas@hbs.edu	De Freitas, Julian/JXN-4053-2024	Puntoni, Stefano/0000-0002-3259-2325				Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anonymous, 2022, Detecting Offensive Language in an Open Chatbot Platform; Barney LJ, 2006, AUST NZ J PSYCHIAT, V40, P51, DOI 10.1111/j.1440-1614.2006.01741.x; Baumeister H, 2012, J AFFECT DISORDERS, V139, P240, DOI 10.1016/j.jad.2011.05.025; Bendig E, 2019, VERHALTENSTHERAPIE, V29, P266, DOI 10.1159/000499492; Boucher EM, 2021, EXPERT REV MED DEVIC, V18, P37, DOI 10.1080/17434440.2021.2013200; Commission Personal Data Protection, 2019, Fostering Responsible Development and Adoption of Ai (2019); Corker E, 2013, BRIT J PSYCHIAT, V202, pS58, DOI 10.1192/bjp.bp.112.112912; Dang JN, 2023, COMPUT HUM BEHAV, V141, DOI 10.1016/j.chb.2022.107637; Dawson D., 2019, Artificial Intelligence: Australias Ethics Framework; De Freitas J., 2022, Replika Ai: Monetizing a Chatbot; Deng L., 2018, Deep learning in natural language processing; Dietvorst BJ, 2015, J EXP PSYCHOL GEN, V144, P114, DOI 10.1037/xge0000033; Epstein Z, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101515; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gould CE, 2019, PSYCHOL SERV, V16, P196, DOI 10.1037/ser0000289; Hayes A.F., 2021, PROCESS: A versatile computational tool for observed variable mediation, moderation; High-Level Expert Group on Artificial Intelligence, 2019, Ethics Guidelines for Trustworthy AI; Hughes ME, 2004, RES AGING, V26, P655, DOI 10.1177/0164027504268574; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Kakuma R, 2011, LANCET, V378, P1654, DOI 10.1016/S0140-6736(11)61093-3; Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083; Lambrecht A, 2019, MANAGE SCI, V65, P2966, DOI 10.1287/mnsc.2018.3093; Leviathan Yaniv, 2018, Google duplex: An ai system for accomplishing real-world tasks over the phone; Longoni C, 2019, J CONSUM RES, V46, P629, DOI 10.1093/jcr/ucz013; Luo XM, 2019, MARKET SCI, V38, P937, DOI 10.1287/mksc.2019.1192; Malle BF, 2016, ACMIEEE INT CONF HUM, P125, DOI 10.1109/HRI.2016.7451743; Markov T, 2022, Arxiv, DOI arXiv:2208.03274; Montoya AK, 2017, PSYCHOL METHODS, V22, P6, DOI 10.1037/met0000086; Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153; Nass C, 1999, J APPL SOC PSYCHOL, V29, P1093, DOI 10.1111/j.1559-1816.1999.tb00142.x; Pichai S., 2018, The Keyword, V7, P1; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Rickwood DJ, 2007, MED J AUSTRALIA, V187, pS35, DOI 10.5694/j.1326-5377.2007.tb01334.x; Schepman A, 2020, COMPUT HUM BEHAV REP, V1, DOI 10.1016/j.chbr.2020.100014; Sweeney Colm, 2021, ACM Transactions on Computing and Healthcare, V2, DOI 10.1145/3453175; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Vassinen R., 2018, Journal of Brand Strategy, V7, P13; Walker L., 2023, Belgian Man Dies by Suicide Following Exchanges with Chatbot; Wellman A., 2023, Woman Asks Ai If She Should Divorce Her Husband-Walks out of Marriage after Advice	42	5	5	226	226	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1057-7408	1532-7663		J CONSUM PSYCHOL	J. Consum. Psychol.	2023 DEC 19	2023										10.1002/jcpy.1393	http://dx.doi.org/10.1002/jcpy.1393		DEC 2023	11	Business; Psychology, Applied	Social Science Citation Index (SSCI)	Business & Economics; Psychology	CT8Q1					2024-07-03	WOS:001127585600001
J	de Vicente-Yagüe-Jara, MI; López-Martínez, O; Navarro-Navarro, V; Cuéllar-Santiago, F				de Vicente-Yague-Jara, Maria-Isabel; Lopez-Martinez, Olivia; Navarro-Navarro, Veronica; Cuellar-Santiago, Francisco			Writing, creativity, and artificial intelligence. ChatGPT in the university context	COMUNICAR			Spanish	Article						Artificial intelligence; writing; language teaching; verbal creativity; ChatGPT; Large Language Models		The main objective of the research is to study the creative potential of Artificial Intelligence (AI) for writing skills in an educational context. The research aims to provide evidence on the use of AI and contribute to its integration in the classroom as a support for the teaching-learning process. Two types of research designs were established: a descriptive and comparative non-experimental quantitative research, and a quasi-experimental pretest-posttest study. The sample consisted of 20 AI systems and 193 university students who were given Games 2 and 3 of the Spanish PIC-A test ("Creative Imagination Test for Adults"). The students repeated the games, assisted by ChatGPT, to compare the possible improvement of their productions. The findings reveal statistically significant differences between the AIs and the students in the indicators of fluency, flexibility, and narrative originality in Game 2. Furthermore, significant differences are found between students' pre-test and post-test scores in fluency, flexibility, and narrative originality in Game 2 and in fluency in Game 3. Finally, the assistance provided by AI in writing tasks and verbal creativity is highlighted, and this should be considered in language teaching; in any case, AI cannot replace human intelligence and creativity.	[de Vicente-Yague-Jara, Maria-Isabel] Univ Murcia, Dept Didact Lengua & Literatura, Murcia, Spain; [Lopez-Martinez, Olivia] Univ Murcia, Dept Psicol Evolut & Educ, Murcia, Spain; [Navarro-Navarro, Veronica] Univ Salamanca, Dept Hist Arte Bellas Artes, Salamanca, Spain; [Cuellar-Santiago, Francisco] Univ Miguel Hernandez Elche, Dept Arte, Elche, Spain	University of Murcia; University of Murcia; University of Salamanca; Universidad Miguel Hernandez de Elche	de Vicente-Yagüe-Jara, MI (corresponding author), Univ Murcia, Dept Didact Lengua & Literatura, Murcia, Spain.	isabelvyague@um.es; olivia@um.es; veronicanavarro@usal.es; fcuellar@umh.es	de Vicente-Yagüe Jara, María Isabel/JBR-7944-2023; Cuéllar Santiago, Francisco/GZM-5669-2022	de Vicente-Yagüe Jara, María Isabel/0000-0002-2496-2971; Cuellar Santiago, Francisco/0000-0003-0523-6509; Navarro Navarro, Veronica/0000-0003-3439-9278; Lopez Martinez, Olivia/0000-0002-9819-8005				Aleksic D, 2016, EUR J WORK ORGAN PSY, V25, P363, DOI 10.1080/1359432X.2015.1077809; [Anonymous], 2021, OECD Digital Education Outlook 2021: Pushing the Frontiers with Artificial Intelligence, Blockchain and Robots, DOI DOI 10.1787/589B283F-EN; Argondizzo C., 2012, Creativity and innovation in language education, DOI [10.3726/978-3-0351-0431-8, DOI 10.3726/978-3-0351-0431-8]; Artola T., 2012, PIC A PRUEBA IMAGINA; Boden M.A., 2018, Artificial Intelligence: A Very Short Introduction, DOI 10.1093/actrade/9780199602919.001.0001; Boden Margaret A., 2004, The creative mind: Myths and mechanisms, DOI DOI 10.4324/9780203508527; Bonami B, 2020, COMUNICAR, V28, P43, DOI 10.3916/C65-2020-04; Breton, 2021, Una Europa adaptada a la era digital: la comision propone nuevas normas y medidas para favorecer la excelencia y la confianza en la inteligencia artificial; Csikszentmihalyi M., 1998, Paidas; Edelvives, 2023, Edelvives se convierte en la primera editorial en integrar ChatGPT en su plataforma educativa; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Fyfe P, 2023, AI SOC, V38, P1395, DOI 10.1007/s00146-022-01397-z; Gade R., 2023, Become a published author using ChatGPT; Goleman D., 2016, Ediciones B; Guilford JP, 1950, AM PSYCHOL, V5, P444, DOI 10.1037/h0063487; Gutiérrez-Fandiño A, 2022, PROCES LENG NAT, P39, DOI 10.26342/2022-68-3; Holmes W., 2019, Artificial intelligence in education. Promises and implications for teaching and learning, DOI [10.1007/978-3-319-60013-0_107-1, DOI 10.1007/978-3-319-60013-0_107-1]; Hora S, 2022, J APPL PSYCHOL, V107, P1926, DOI 10.1037/apl0000999; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; INTEF, 2022, IA y educacion: Orientaciones para los responsables de la elaboracion de politicas; Lee A., 2023, NVIDIA; Miller AI, 2019, ARTIST IN THE MACHINE: THE WORLD OF AI-POWERED CREATIVITY, DOI 10.1080/09540121.2019.1668533; Montero L., 2023, Somos un cerebro flotando en una cubeta; Munari B., 2018, Fantasia: Invencion, creatividad e imaginacion en las comunicaciones visuales (Clasicos); O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OCDE, 2019, PISA 2021 Creative thinking framework; OpenAI, 2023, Classifier; Peiron F., 2023, La Vanguardia; Real Academia Espanola -RAE, Proyecto Lengua Espanola e Inteligencia Artificial (LEIA); Renbarger M., 2023, Business Insider; Rodrigo-Martin I., 2022, Visual Culture Review, V9, P1, DOI [10.37467/revvisual.v9.3533, DOI 10.37467/REVVISUAL.V9.3533]; Sadin E., 2018, La inteligencia artificial o el desafio del siglo; Sanchez A., 2023, La Opinion; Selwyn N., 2022, Educar con sentido transformador en la universidad, P137, DOI [10.31235/osf.io/vx4zr, DOI 10.31235/OSF.IO/VX4ZR]; Donolo DS, 2007, AN PSICOL-SPAIN, V23, P147; Sternberg R.J., 1999, Handbook of Creativity, DOI [10.1017/cbo9780511807916.003, DOI 10.1017/CBO9780511807916.003]; Sun ZM, 2021, COMPUT INTELL-US, V37, P1166, DOI 10.1111/coin.12351; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; UNESCO, 2022, K-12 AI curricula: A mapping of government-endorsed AI curricula; Unesco, 2022, Recomendacion sobre la etica de la inteligencia artificial; UNESCO, 2021, International Forum on AI and the Futures of Education, developing competencies for the AI Era; UNESCO, 2019, INT C ART INT ED PLA; UNESCO, Teaching AI for K-12; Universidad de Murcia, 2022, Codigo de Buenas Practicas en Investigacion de la Universidad de Murcia; Vaswani A, 2017, ADV NEUR IN, V30; Vazquez D., 2023, Business Insider; Ward M., 2020, NARRATIVES HIST IMAG, P144, DOI DOI 10.1093/OSO/9780198846666.001.0001; Zhu Yanhua, 2020, 2020 International Conference on Artificial Intelligence and Education (ICAIE), P40, DOI 10.1109/ICAIE50891.2020.00017	49	2	2	150	186	Oxbridge Publishing House	Sollihul	4 White House Way, Sollihul, ENGLAND	1134-3478	1988-3293		COMUNICAR	Comunicar	OCT	2023	31	77					47	57		10.3916/C77-2023-04	http://dx.doi.org/10.3916/C77-2023-04			11	Communication; Education & Educational Research	Social Science Citation Index (SSCI)	Communication; Education & Educational Research	W6RD1		Green Submitted, gold			2024-07-03	WOS:001092871200004
J	Khosravi, T; Al Sudani, ZM; Oladnabi, M				Khosravi, Teymoor; Al Sudani, Zainab M.; Oladnabi, Morteza			To what extent does ChatGPT understand genetics?	INNOVATIONS IN EDUCATION AND TEACHING INTERNATIONAL			English	Article; Early Access						ChatGPT; generative pre-trained transformer; genetics; artificial intelligence; large language model	OPPORTUNITIES; EDUCATION; GPT	OpenAI's ChatGPT, is a conversational chatbot that uses Generative Pre-trained Transformer or GPT language model to mimic human-like responses. Here we evaluated its performance in providing responses to genetics questions across five different tasks including solid genetic basics, identifying inheritance pattern based on described pedigrees, interpreting genetic mutation notations, solving genetic population problems, and taking a medical genetics Ph.D. entrance exam. Our results showed that ChatGPT was able to generate correct answers to approximately 70% of questions (n = 145). Its performance on descriptive and memorisation tasks showed more accuracy compared to analytical and critical thinking ones. Failure to capture human writing nuances in questions, and applying genetic basics to solve problems, alongside providing false information were the most notable drawbacks. However, overall results were promising suggesting that ChatGPT could be a well-prepared assistant for genetic educators and healthcare providers.	[Khosravi, Teymoor; Al Sudani, Zainab M.] Golestan Univ Med Sci, Student Res Comm, Gorgan, Iran; [Oladnabi, Morteza] Golestan Univ Med Sci, Gorgan Congenital Malformat Res Ctr, Gorgan, Iran; [Oladnabi, Morteza] Golestan Univ Med Sci, Ischem Disorders Res Ctr, Gorgan, Iran; [Oladnabi, Morteza] Golestan Univ Med Sci, Sch Adv Technol Med, Dept Med Genet, Gorgan 4916978342, Iran	Golestan University of Medical Sciences; Golestan University of Medical Sciences; Golestan University of Medical Sciences; Golestan University of Medical Sciences	Oladnabi, M (corresponding author), Golestan Univ Med Sci, Sch Adv Technol Med, Dept Med Genet, Gorgan 4916978342, Iran.	oladnabidozin@yahoo.com	oladnabi, Morteza/H-9169-2016	oladnabi, Morteza/0000-0001-7037-5084	Golestan University of Medical Sciences and Health Services [113350]	Golestan University of Medical Sciences and Health Services	This work was supported by the Golestan University of Medical Sciences and Health Services [113350].	Bird S., 2009, NATURAL LANGUAGE PRO; Bommineni VL, 2023, medRxiv, DOI [10.1101/2023.03.05.23286533, 10.1101/2023.03.05.23286533, DOI 10.1101/2023.03.05.23286533]; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Cahan P, 2023, STEM CELL REP, V18, P1, DOI 10.1016/j.stemcr.2022.12.009; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Day T, 2023, PROF GEOGR, V75, P1024, DOI 10.1080/00330124.2023.2190373; De Angelis Luigi, 2023, SSRN Electronic Journal, DOI [10.2139/ssrn.4352931, DOI 10.2139/SSRN.4352931]; Dignum V, 2019, ARTIF INTELL-FOUND, P1, DOI 10.1007/978-3-030-30371-6; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Fattahi Z, 2019, HUM MUTAT, V40, P1968, DOI 10.1002/humu.23880; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fuchs K, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1166682; Glikson E, 2020, ACAD MANAG ANN, V14, P627, DOI 10.5465/annals.2018.0057; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kublik S., 2022, GPT 3 BUILDING INNOV; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mukhamediev RI, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10152552; Nadimpalli M., 2017, International Journal of Innovative Research in Science, Engineering and Technology, V6; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sharma G, 2023, ChemRxiv; Tegmark M., 2018, LIFE 3 0 BEING HUMAN, DOI [https://doi.org/10.1201/9781351251389-5, DOI 10.1201/9781351251389-5]; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang JA, 2023, Arxiv, DOI arXiv:2302.14229; Wang YX, 2010, COGN SYST RES, V11, P81, DOI 10.1016/j.cogsys.2008.08.003; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712	30	0	0	21	46	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1470-3297	1470-3300		INNOV EDUC TEACH INT	Innov. Educ. Teach. Int.	2023 SEP 16	2023										10.1080/14703297.2023.2258842	http://dx.doi.org/10.1080/14703297.2023.2258842		SEP 2023	10	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	R6NT9					2024-07-03	WOS:001065511400001
J	Aldridge, MJ; Penders, R				Aldridge, Matthew J.; Penders, Robert			Artificial intelligence and anaesthesia examinations: exploring ChatGPT as a prelude to the future	BRITISH JOURNAL OF ANAESTHESIA			English	Letter						anaesthesia training; artificial intelligence; ChatGPT; examination; GPT-4; large language model			[Aldridge, Matthew J.; Penders, Robert] North Bristol NHS Trust, Bristol, England	North Bristol NHS Trust	Aldridge, MJ (corresponding author), North Bristol NHS Trust, Bristol, England.	matt.aldridge@nhs.net		Aldridge, Matthew/0009-0008-7274-3854				Bengio Y, 2023, Pause giant AI experiments: an open letter; consilium, US; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gupta B, 2023, INDIAN J ANAESTH, V67, P146, DOI 10.4103/ija.ija_974_22; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Kulkarni S, 2020, ACAD RADIOL, V27, P62, DOI 10.1016/j.acra.2019.10.001; Medenilla A., 2023, PLoS Digital Health, V2; Royal College of Anaesthetists, 2019, Primary SBA example questions; Royal College of Anaesthetists, 2019, The Candidate Newsletter; Yoon HK, 2022, KOREAN J ANESTHESIOL, V75, P202, DOI 10.4097/kja.22157	10	8	8	2	2	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	AUG	2023	131	2					e36	e37		10.1016/j.bja.2023.04.033	http://dx.doi.org/10.1016/j.bja.2023.04.033		JUL 2023	2	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	FT3T7	37244834				2024-07-03	WOS:001148075700001
C	Morales-Garzón, A; Sánchez-Pérez, GM; Sierra, JC; Martin-Bautista, MJ		Larsen, HL; Martin-Bautista, MJ; Ruiz, MD; Andreasen, T; Bordogna, G; DeTre, G		Morales-Garzon, Andrea; Sanchez-Perez, Gracia M.; Sierra, Juan Carlos; Martin-Bautista, Maria J.			The Promise of Query Answering Systems in Sexuality Studies: Current State, Challenges and Limitations	FLEXIBLE QUERY ANSWERING SYSTEMS, FQAS 2023	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	15th International Conference on Flexible Query Answering Systems (FQAS)	SEP 05-07, 2023	European Soc Fuzzy Log & Technol, Mallorca, SPAIN	Univ Granada, Univ Illes Balears, Univ Cultura, Consejeria Fondos Europeos, Govern Illes Balears, Ajuntament Palma, Fundacio Univ Empresa Illes Balears	European Soc Fuzzy Log & Technol	Query Answering; Natural Language Processing; Sexuality; Large Language Models; Sexual Health	HEALTH; TRAUMA	Sexuality is a field of study that attempts to comprehend human behaviour, improve sexual health and understand culture and gender, among others. Recent advances and developments in artificial intelligence, specifically in query answering and natural language processing, can help to study the social relationship between population and sexuality. They are powerful tools to cope with crucial problems in the field, such as subjectivity, social desirability and social opinion biases. In this work, we review the state-of-the-art of AI-based methods in sexuality-related studies. Focusing on the psychological perspective, we analyse the role of query answering in this area of research. We discuss the necessary foundations, challenges, and limitations a query answering system must cover in this specialised and complex field.	[Morales-Garzon, Andrea; Martin-Bautista, Maria J.] Univ Granada, Dept Comp Sci & Artificial Intelligence, Granada, Spain; [Sanchez-Perez, Gracia M.; Sierra, Juan Carlos] Univ Granada, Mind Brain & Behav Res Ctr, Granada, Spain	University of Granada; University of Granada	Morales-Garzón, A (corresponding author), Univ Granada, Dept Comp Sci & Artificial Intelligence, Granada, Spain.	amoralesg@decsai.ugr.es; graciasp@ugr.es; jcsierra@ugr.es; mbautis@decsai.ugr.es	Sierra, Juan Carlos/G-3044-2010	Sierra, Juan Carlos/0000-0002-5593-9803; Martin-Bautista, Maria J./0000-0002-6973-477X; Morales-Garzon, Andrea/0000-0002-3458-0694; Sanchez, Gracia Maria/0000-0003-2578-0560	MCIN/AEI [PID2021123960OB-I00, TED2021-129402B-C21]; ERDF A way of making Europe; European Union NextGenerationEU/PRTR; Consejeria de Transformacion Econ'omica, Industria, Conocimiento y Universidades de la Junta de Andalucia [PREDOC 00289, PREDOC 00298]	MCIN/AEI; ERDF A way of making Europe; European Union NextGenerationEU/PRTR(European Union (EU)); Consejeria de Transformacion Econ'omica, Industria, Conocimiento y Universidades de la Junta de Andalucia	This research was partially funded by the Grant PID2021123960OB-I00 funded by MCIN/AEI/10.13039/501100011033 and by ERDF A way of making Europe. It was also funded by the Grant TED2021-129402B-C21 funded by MCIN/AEI/10.13039/501100011033 and, by the European Union NextGenerationEU/PRTR. It was also funded by "Consejeria de Transformacion Econ ' omica, Industria, Conocimiento y Universidades de la Junta de Andalucia" through a predoctoral fellowship program (Grant Refs. PREDOC 00289 and PREDOC 00298).	Al-Asadi MA., 2022, Combating Fake News with Computational Intelligence Techniques, P39, DOI [10.1007/978-3-030-90087-8_2, DOI 10.1007/978-3-030-90087-8_2]; Alkomah F, 2022, INFORMATION, V13, DOI 10.3390/info13060273; [Anonymous], 2006, Sexual health; Arcila-Calderón C, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5100063; Belcher RE, 2023, J SEX MED, V20, P287, DOI 10.1093/jsxmed/qdac045; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Sierra JC, 2009, PSYCHOL REP, V105, P69, DOI 10.2466/PR0.105.1.69-79; Castano M.E.F., 2008, Revista de psicopatologia y psicologia clinica, V13, P21; Castiglioni I, 2021, PHYS MEDICA, V83, P9, DOI 10.1016/j.ejmp.2021.02.006; Cervilla O, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060805; Chernyavska T, 2022, BRAIN-BROAD RES ARTI, V13, P292, DOI 10.18662/brain/13.1/285; Curchoe CL, 2019, J ASSIST REPROD GEN, V36, P591, DOI 10.1007/s10815-019-01408-x; Das R, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3586075; Dimitriadis I, 2022, REPROD BIOMED ONLINE, V44, P435, DOI 10.1016/j.rbmo.2021.11.003; Divita G, 2017, STUD HEALTH TECHNOL, V245, P351, DOI 10.3233/978-1-61499-830-3-351; Drukker L, 2020, ULTRASOUND OBST GYN, V56, P498, DOI 10.1002/uog.22122; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; Muñoz-García LE, 2023, ARCH SEX BEHAV, V52, P1479, DOI 10.1007/s10508-022-02493-3; Frank L, 2017, ARTIF INTELL LAW, V25, P305, DOI 10.1007/s10506-017-9212-y; Gundlapalli AV, 2019, MED CARE, V57, pS149, DOI 10.1097/MLR.0000000000001031; Gundlapalli AV, 2017, STUD HEALTH TECHNOL, V238, P128, DOI 10.3233/978-1-61499-781-8-128; Han JW, 1996, IEEE T KNOWL DATA EN, V8, P373, DOI 10.1109/69.506706; Hyde J.S., 2006, Understanding Human Sexuality, V9th; Istaiteh Othman, 2020, 2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P95, DOI 10.1109/IDSTA50958.2020.9264052; Jones Audrey L, 2019, AMIA Annu Symp Proc, V2019, P514; Katins J., 2019, LWDA, P343; Khanam SA, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0184-7; Liu Luchen, 2020, AMIA Annu Symp Proc, V2020, P763; Liu YS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-13642-y; Magnini B., 2005, Tutorial of the Conference on Recent Advances in Natural Language Processing-RANLP; Mariani MM, 2022, PSYCHOL MARKET, V39, P755, DOI 10.1002/mar.21619; Martinez-Barco P., 2007, Sistemas de pregunta-respuesta; McCradden MD, 2020, LANCET DIGIT HEALTH, V2, pE221, DOI 10.1016/S2589-7500(20)30065-0; McGahuey CA, 2000, J SEX MARITAL THER, V26, P25, DOI 10.1080/009262300278623; Munoz-Garcia Laura Elvira, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20031820; Nadarzynski T, 2020, BMJ SEX REPROD HEAL, V46, P210, DOI 10.1136/bmjsrh-2018-200271; Parihar Anil Singh, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P1302, DOI 10.1109/ICOEI51242.2021.9452882; Patra BG, 2021, J AM MED INFORM ASSN, V28, P2716, DOI 10.1093/jamia/ocab170; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Robertson C, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.836733; Safdar NM, 2020, EUR J RADIOL, V122, DOI 10.1016/j.ejrad.2019.108768; Sanchez Fuentes M., 2019, Validation of the Spanish version of the Arizona sexual experience scale (ASEX) using self-reported and psychophysiological measures; Santos E, 2012, HUM REPROD, V27, P2641, DOI 10.1093/humrep/des219; Schmidt A., 2017, P 5 INT WORKSHOP NAT, P1; Shahid W, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3177359; Sinclair D, 2023, INF COMMUN TECHNOL L, V32, P328, DOI 10.1080/13600834.2022.2154050; Socatiyanurak V, 2021, IEEE ACCESS, V9, P131440, DOI 10.1109/ACCESS.2021.3113172; Sprecher S., 1993, Sexuality, V6; Sufi FK, 2022, SOFTW IMPACTS, V13, DOI 10.1016/j.simpa.2022.100319; Thorne J, 2021, PROC VLDB ENDOW, V14, P1033, DOI 10.14778/3447689.3447706; Vowels LM, 2022, J SOC PERS RELAT, V39, P1191, DOI 10.1177/02654075211047004; Wang RJ, 2019, REPRODUCTION, V158, pR139, DOI 10.1530/REP-18-0523; Wilcke X., 2017, DATA SCI, V1, P39, DOI DOI 10.3233/DS-170007; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; World Health Organization, 2020, Sexual and Reproductive Health and Research (SRH); Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhou B., 2022, IEEE Rev. Biomed. Eng.	57	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-42934-7; 978-3-031-42935-4	LECT NOTES ARTIF INT			2023	14113						39	49		10.1007/978-3-031-42935-4_4	http://dx.doi.org/10.1007/978-3-031-42935-4_4			11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WY					2024-07-03	WOS:001156345100004
J	Yun, H; Yi, E; Song, S				Yun, Hongoak; Yi, Eunkyung; Song, Sanghoun			Exploring AI-Generated English Relative Clauses in Comparison to Human Production	JOURNAL OF COGNITIVE SCIENCE			English	Article						large language models; asymmetry of relative clauses; semantic sensitivity; AI-generated corpus; ChatGPT	FREQUENCY; EXPECTATIONS; CHATGPT; MEMORY; VERBS	Human behavioral studies have consistently indicated a preference for subject-extracted relative clauses (SRCs) over object-extracted relative clauses (ORCs) in sentence production and comprehension. Some studies have further shown that this preference can be influenced by the semantic properties of head nouns, particularly animacy. In this study, we use AI language models, specifically GPT-2 and ChatGPT 3.5, to simulate human sentence generation. Our primary goal is to evaluate the extent to which these language models replicate human behaviors in sentence production and identify any divergences. We tasked the models with completing sentence fragments structured as 'the,' followed by a head noun and 'that' (The reporter that ...). We varied the semantic property of head nouns such that they are all animate (the secretary that ... ) in Study 1 and are either animate or inanimate (the musician/book that ... ) in Study 2. Our findings reveal that in Study 1, both GPT models exhibited a robust SRC bias, replicating human-like behavior in relative clause production. However, in Study 2, we observed divergent behavior between the models when head nouns were inanimate, while consistency was maintained when head nouns were animate. Specifically, ChatGTP 3.5 generated more ORCs than SRCs in the presence of inanimate head nouns. These results, particularly those from ChatGPT 3.5, closely mirror human relative clause production patterns. Our study highlights the potential of language generative language models as efficient and versatile corpus simulators. Furthermore, our findings contribute to the evolving field of AI linguistics, shedding light on the capacity of AI generative systems to emulate human-like linguistic patterns in sentence production.	[Yun, Hongoak] Jeju Natl Univ, Jeju Si, South Korea; [Yi, Eunkyung] Ewha Womans Univ, Seoul, South Korea; [Song, Sanghoun] Korea Univ, Seoul, South Korea	Jeju National University; Ewha Womans University; Korea University	Yi, E (corresponding author), Ewha Womans Univ, Seoul, South Korea.; Song, S (corresponding author), Korea Univ, Seoul, South Korea.	eyi@ewha.ac.kr; sanghoun@korea.ac.kr			Jeju National University	Jeju National University	Funding This research was supported by the 2023 scientific promotion program funded by Jeju National University.	Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1; Arisoy E, 2012, P NAACL HLT 2012 WOR, P20; Bernardy Jean-Philippe, 2017, Linguistic Issues in Language Technology, V15, P1; Bever T. G, 1970, Cognition and development of language; BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Chomsky N., 2023, NEW YORK TIMES; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Emile, 2017, P 21 C COMP NAT LANG, P3; Ettinger Allyson, 2016, P 1 WORKSH EV VECT S, P134; Filippova K., 2015, P 2015 C EMP METH NA, P360, DOI DOI 10.18653/V1/D15-1042; FORD M, 1983, J VERB LEARN VERB BE, V22, P203, DOI 10.1016/S0022-5371(83)90156-1; FOX BA, 1990, LANGUAGE, V66, P297, DOI 10.2307/414888; Frank S., 2019, P 41 ANN M COGNITIVE, P337; Futrell R, 2018, Arxiv, DOI arXiv:1809.01329; Futrell Richard, 2019, P SOC COMP LING SCIL, P50, DOI 10.7275/jb34-9986; Gennari SP, 2008, J MEM LANG, V58, P161, DOI 10.1016/j.jml.2007.07.004; Gibson E, 2013, P NATL ACAD SCI USA, V110, P8051, DOI 10.1073/pnas.1216438110; Gordon PC, 2001, J EXP PSYCHOL LEARN, V27, P1411, DOI 10.1037/0278-7393.27.6.1411; Grodner D, 2005, COGNITIVE SCI, V29, P261, DOI 10.1207/s15516709cog0000_7; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Heider PM, 2014, J MEM LANG, V75, P58, DOI 10.1016/j.jml.2014.05.001; Howard N, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00016; Kako E, 2006, LANG COGNITIVE PROC, V21, P562, DOI 10.1080/01690960500101967; Kim CE, 2016, J CHILD LANG, V43, P1038, DOI 10.1017/S0305000915000422; KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Linzen Tal, 2016, Transactions of the Association for Computational Linguistics, V1990, P521, DOI [10.1162/tacl_a_00115, DOI 10.1162/TACL_A_00115]; MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226; MacDonald MC, 2002, PSYCHOL REV, V109, P35, DOI 10.1037//0033-295X.109.1.35; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; MITCHELL DC, 1995, J PSYCHOLINGUIST RES, V24, P469, DOI 10.1007/BF02143162; OpenAI, 2023, CHATGPT; Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reali F, 2007, J MEM LANG, V57, P1, DOI 10.1016/j.jml.2006.08.014; Roland D, 2007, J MEM LANG, V57, P348, DOI 10.1016/j.jml.2007.03.002; Roland D, 2021, J MEM LANG, V119, DOI 10.1016/j.jml.2021.104244; Roland D, 2012, J MEM LANG, V66, P479, DOI 10.1016/j.jml.2011.12.004; Schneider ETR, 2021, COMP MED SY, P474, DOI 10.1109/CBMS52027.2021.00056; Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schwenk J, 2012, NEURON, V74, P621, DOI 10.1016/j.neuron.2012.03.034; Shin U, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.937656; Shrivastava Adarsh, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1345, DOI 10.1109/ICICCS51141.2021.9432283; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Traxler MJ, 2002, J MEM LANG, V47, P69, DOI 10.1006/jmla.2001.2836; van Schijndel Marten, 2018, P 40 ANN C COGNITIVE, P2600; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Warstadt A, 2020, Arxiv, DOI arXiv:2007.06761; Wilcox E., 2018, P 2018 EMNLP WORKSHO, P211; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Yi E., 2022, Korean Journal of English Language and Linguistics, V22, P1101; Yun H., 2019, Language Research, V55, P253	58	0	0	5	5	SEOUL NATL UNIV, INST COGNITIVE SCIENCE	SEOUL	SEOUL NATL UNIV, SEOUL, 151-742, SOUTH KOREA	1598-2327			J COGN SCI	J. Cogn. Sci.		2023	24	4					465	496						32	Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	FQ1Y6					2024-07-03	WOS:001147235500003
J	Shen, SA; Perez-Heydrich, CA; Xie, DX; Nellis, JC				Shen, Sarek A.; Perez-Heydrich, Carlos A.; Xie, Deborah X.; Nellis, Jason C.			ChatGPT vs. web search for patient questions: what does ChatGPT do better?	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						Large language model; ChatGPT; Patient education; Patient questions; Accuracy; Readability; Accessibility	EDUCATION MATERIALS	Purpose Chat generative pretrained transformer (ChatGPT) has the potential to significantly impact how patients acquire medical information online. Here, we characterize the readability and appropriateness of ChatGPT responses to a range of patient questions compared to results from traditional web searches. Methods Patient questions related to the published Clinical Practice Guidelines by the American Academy of Otolaryngology-Head and Neck Surgery were sourced from existing online posts. Questions were categorized using a modified Rothwell classification system into (1) fact, (2) policy, and (3) diagnosis and recommendations. These were queried using ChatGPT and traditional web search. All results were evaluated on readability (Flesch Reading Ease and Flesch-Kinkaid Grade Level) and understandability (Patient Education Materials Assessment Tool). Accuracy was assessed by two blinded clinical evaluators using a three-point ordinal scale. Results 54 questions were organized into fact (37.0%), policy (37.0%), and diagnosis (25.8%). The average readability for ChatGPT responses was lower than traditional web search (FRE: 42.3 +/- 13.1 vs. 55.6 +/- 10.5, p < 0.001), while the PEMAT understandability was equivalent (93.8% vs. 93.5%, p = 0.17). ChatGPT scored higher than web search for questions the 'Diagnosis' category (p < 0.01); there was no difference in questions categorized as 'Fact' (p = 0.15) or 'Policy' (p = 0.22). Additional prompting improved ChatGPT response readability (FRE 55.6 +/- 13.6, p < 0.01). Conclusions ChatGPT outperforms web search in answering patient questions related to symptom-based diagnoses and is equivalent in providing medical facts and established policy. Appropriate prompting can further improve readability while maintaining accuracy. Further patient education is needed to relay the benefits and limitations of this technology as a source of medial information.	[Shen, Sarek A.; Xie, Deborah X.; Nellis, Jason C.] Johns Hopkins Sch Med, Dept Otolaryngol Head & Neck Surg, 601 North Caroline St, Baltimore, MD 21287 USA; [Perez-Heydrich, Carlos A.] Johns Hopkins Sch Med, Baltimore, MD USA	Johns Hopkins University; Johns Hopkins Medicine; Johns Hopkins University; Johns Hopkins Medicine	Shen, SA (corresponding author), Johns Hopkins Sch Med, Dept Otolaryngol Head & Neck Surg, 601 North Caroline St, Baltimore, MD 21287 USA.	sarek.shen@gmail.com		Shen, Sarek/0000-0001-6627-6139	National Institute on Deafness and Other Communication Disorders	National Institute on Deafness and Other Communication Disorders(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	No Statement Available	Amante DJ, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4126; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ayoub NF, 2024, OTOLARYNG HEAD NECK, V170, P1484, DOI 10.1002/ohn.465; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Bergmo TS, 2023, JMIR FORM RES, V7, DOI 10.2196/40466; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chakraborty C, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1237704; Chen LW, 2021, OTOLARYNG HEAD NECK, V165, P50, DOI 10.1177/0194599820969154; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; Gabriel J, 2023, INT UROL NEPHROL, V55, P2717, DOI 10.1007/s11255-023-03729-4; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hannabass K, 2023, MIL MED, V188, P780, DOI 10.1093/milmed/usab484; Johnson D, 2023, RES SQ, V28; Kasabwala K, 2012, OTOLARYNG HEAD NECK, V147, P466, DOI 10.1177/0194599812442783; Kim JH, 2022, OTOLARYNG HEAD NECK, V166, P862, DOI 10.1177/01945998211033254; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Misra P, 2012, J NEURO-ONCOL, V109, P573, DOI 10.1007/s11060-012-0930-4; O'Mathuna Donal P, 2018, AMA J Ethics, V20, pE1059, DOI 10.1001/amajethics.2018.1059; Patel MJ, 2022, FACIAL PLAST SURG AE, V24, P276, DOI 10.1089/fpsam.2021.0001; Pham KT, 2022, PSYCHIAT QUART, V93, P249, DOI 10.1007/s11126-022-09973-8; Rich AS, 2019, NAT MACH INTELL, V1, P174, DOI 10.1038/s42256-019-0038-z; Rothwell JD., 2021, MIXED CO 11E COMMUNI; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shneyderman M, 2021, OTO OPEN, V5, DOI 10.1177/2473974X211032644; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Weis B., 2003, Health literacy: a manual for clinicians; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yang S, 2023, HEALTH COMMUN, V38, P1293, DOI 10.1080/10410236.2021.2004698	31	4	4	23	23	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	JUN	2024	281	6					3219	3225		10.1007/s00405-024-08524-0	http://dx.doi.org/10.1007/s00405-024-08524-0		FEB 2024	7	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	TG9T2	38416195				2024-07-03	WOS:001173169500001
J	Iwasaki, M				Iwasaki, Masaki			Digital Cloning of the Dead: Exploring the Optimal Default Rule	ASIAN JOURNAL OF LAW AND ECONOMICS			English	Article						digital clone; digital resurrection; deep learning; large language model; default rule		We conducted a survey experiment in the U.S. to analyze how the consent or dissent of a deceased individual influences the social acceptability of digital resurrection. The results showed a substantial relative treatment effect of consent versus dissent, with a 2-point difference in acceptability on a 5-point scale. When the deceased had consented, 58 % of respondents viewed digital resurrection as socially acceptable, whereas this number was only 3 % when the deceased had dissented. These findings suggest that relevant legal regulations should respect the decision of the deceased. Our study then explored the optimal default rule using observational research: 59 % of respondents were against the idea of their own digital resurrection. An opt-in rule seems socially desirable, where the default is the prohibition of digital resurrection, and exceptions allow it only with consent from the deceased.	[Iwasaki, Masaki] Seoul Natl Univ, Sch Law, Seoul, South Korea	Seoul National University (SNU)	Iwasaki, M (corresponding author), Seoul Natl Univ, Sch Law, Seoul, South Korea.	miwasaki@sjd.law.harvard.edu		Iwasaki, Masaki/0000-0003-3569-2425	Seoul National University	Seoul National University	The author is grateful to Haksoo Ko, Keun-Gwan Lee, Yijia Lu, Sangchul Park, and the participants of the 2023 SNU-KYU Joint Symposium for their comments, and to Qi Wang for her research assistance.	AYRES I, 1989, YALE LAW J, V99, P87, DOI 10.2307/796722; Bar-Gill O, 2021, U CHICAGO LAW REV, V88, P531; Bedingfield W., 2023, WIRED           0707; Boothe A, 2022, INT J LAW INFORM TEC, V30, P398, DOI 10.1093/ijlit/eaad005; Bullock JG, 2009, J POLIT, V71, P1109, DOI 10.1017/S0022381609090914; Chandler J, 2019, BEHAV RES METHODS, V51, P2022, DOI 10.3758/s13428-019-01273-7; Clifford S, 2021, AM POLIT SCI REV, V115, P1048, DOI 10.1017/S0003055421000241; Harbinja E, 2023, COMPUT LAW SECUR REV, V48, DOI 10.1016/j.clsr.2023.105791; Jee C., 2022, MIT TECHNOLOGY  1018; Johnson EJ, 2003, SCIENCE, V302, P1338, DOI 10.1126/science.1091721; Lees D, 2021, CONVERGENCE-US, V27, P954, DOI 10.1177/13548565211030452; Morse T, 2022, NEW MEDIA SOC, V24, P1343, DOI 10.1177/1461444820974955; Mummolo J, 2019, AM POLIT SCI REV, V113, P517, DOI 10.1017/S0003055418000837; Roberts R. J., 2023, FED COMMUN LAW J, V75, P273; Sunstein CR, 2002, NEW YORK U LAW REV, V77, P106; Truby J, 2021, INF COMMUN TECHNOL L, V30, P140, DOI 10.1080/13600834.2020.1850174; Zahn M., 2023, ABC NEWS        0721	17	0	0	7	7	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6086	2154-4611		ASIAN J LAW ECON	Asian J. Law Econ.	MAR 11	2024	15	1					1	29		10.1515/ajle-2023-0125	http://dx.doi.org/10.1515/ajle-2023-0125		DEC 2023	29	Law	Emerging Sources Citation Index (ESCI)	Government & Law	KR8E3		hybrid			2024-07-03	WOS:001131721500001
J	Kiyak, YS; Kononowicz, AA				Kiyak, Yavuz Selim; Kononowicz, Andrzej A.			Case-based MCQ generator: A custom ChatGPT based on published prompts in the literature for automatic item generation	MEDICAL TEACHER			English	Article; Early Access						ChatGPT; multiple-choice questions; automatic item generation; large language models; artificial intelligence		What is the Educational Challenge?A fundamental challenge in medical education is creating high-quality, clinically relevant multiple-choice questions (MCQs). ChatGPT-based automatic item generation (AIG) methods need well-designed prompts. However, the use of these prompts is hindered by the time-consuming process of copying and pasting, a lack of know-how among medical teachers, and the generalist nature of standard ChatGPT, which often lacks the medical context.What are the Proposed Solutions?The Case-based MCQ Generator, a custom GPT, addresses these challenges. It has been trained by using GPT Builder, which is a platform designed by OpenAI for customizing ChatGPT to meet specific needs, in order to allow users to generate case-based MCQs. By using this free tool for those who have ChatGPT Plus subscription, health professions educators can easily select a prompt, input a learning objective or item-specific test point, and generate clinically relevant questions.What are the Potential Benefits to a Wider Global Audience?It enhances the efficiency of MCQ generation and ensures the generation of contextually relevant questions, surpassing the capabilities of standard ChatGPT. It streamlines the MCQ creation process by integrating prompts published in medical education literature, eliminating the need for manual prompt input.What are the Next Steps?Future development aims at sustainability and addressing ethical and accessibility issues. It requires regular updates, integration of new prompts from emerging health professions education literature, and a supportive digital ecosystem around the tool. Accessibility, especially for educators in low-resource countries, is vital, demanding alternative access models to overcome financial barriers.	[Kiyak, Yavuz Selim] Gazi Univ, Fac Med, Dept Med Educ & Informat, Ankara, Turkiye; [Kiyak, Yavuz Selim; Kononowicz, Andrzej A.] Jagiellonian Univ Med Coll, Dept Bioinformat & Telemed, Krakow, Poland; [Kiyak, Yavuz Selim] Gazi Univ Hastanesi, E Blok 9 Kat, TR-06500 Ankara, Turkiye	Gazi University; Jagiellonian University; Collegium Medicum Jagiellonian University; Gazi University	Kiyak, YS (corresponding author), Gazi Univ Hastanesi, E Blok 9 Kat, TR-06500 Ankara, Turkiye.	yskiyak@gazi.edu.tr	KIYAK, Yavuz Selim/AAE-5111-2022; Kononowicz, Andrzej A./ABG-8696-2020	KIYAK, Yavuz Selim/0000-0002-5026-3234; Kononowicz, Andrzej A./0000-0003-2956-2093	TBIdot;TAK	TBIdot;TAK	No Statement Available	Gierl M. J., 2021, ADV METHODS AUTOMATI; Indran IR, 2023, MED TEACH, DOI 10.1080/0142159X.2023.2294703; Kiyak YS, 2023, Rev. esp. educ. med., V4, P98, DOI [10.6018/edumed.587451, DOI 10.6018/EDUMED.587451]; Masters K, 2024, MED TEACH, V46, P752, DOI 10.1080/0142159X.2024.2305365; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Zuckerman M, 2023, MED TEACH, V45, P1224, DOI 10.1080/0142159X.2023.2249239	6	4	4	29	29	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0142-159X	1466-187X		MED TEACH	Med. Teach.	2024 FEB 6	2024										10.1080/0142159X.2024.2314723	http://dx.doi.org/10.1080/0142159X.2024.2314723		FEB 2024	3	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	HN8H3	38340312				2024-07-03	WOS:001160269300001
J	Baum, K; Bryson, J; Dignum, F; Dignum, V; Grobelnik, M; Hoos, H; Irgens, M; Lukowicz, P; Muller, C; Rossi, F; Shawe-Taylor, J; Theodorou, A; Vinuesa, R				Baum, Kevin; Bryson, Joanna; Dignum, Frank; Dignum, Virginia; Grobelnik, Marko; Hoos, Holger; Irgens, Morten; Lukowicz, Paul; Muller, Catelijne; Rossi, Francesca; Shawe-Taylor, John; Theodorou, Andreas; Vinuesa, Ricardo			From fear to action: AI governance and opportunities for all	FRONTIERS IN COMPUTER SCIENCE			English	Editorial Material						Artificial Intelligence; governance; responsible AI; Trustworthy AI; large language models; generative AI			[Baum, Kevin] Deutsch Forschungszentrum Julich Kunstl Intelligen, Kaiserslautern, Germany; [Bryson, Joanna] Hertie Sch, Berlin, Germany; [Dignum, Frank; Dignum, Virginia] Umea Univ, Umea, Sweden; [Grobelnik, Marko] OECD, Paris, France; [Hoos, Holger] Rhein Westfal TH Aachen, Aachen, Germany; [Irgens, Morten] Oslo Metropolitan Univ, CLAIRE AIorg, Oslo, Norway; [Lukowicz, Paul] Deutsch Forschungszentrum Julich Kunstl Intelligen, Kaiserslautern, Germany; [Muller, Catelijne] ALLAI, Amsterdam, Netherlands; [Rossi, Francesca] IBM Corp, Yorktown Hts, NY USA; [Shawe-Taylor, John] Int Res Inst AI, IRCAI, Ljubljana, Slovenia; [Theodorou, Andreas] VerAI, Umea, Sweden; [Vinuesa, Ricardo] KTH Royal Inst Technol, Stockholm, Sweden	Hertie School; Umea University; Organisation for Economic Co-operation & Development (OECD); RWTH Aachen University; Oslo Metropolitan University (OsloMet); International Business Machines (IBM); Royal Institute of Technology	Dignum, V (corresponding author), Umea Univ, Umea, Sweden.	virginia@cs.umu.se	Vinuesa, Ricardo/ABG-6234-2020; Theodorou, Andreas/AAD-2346-2020	Vinuesa, Ricardo/0000-0001-6570-5499; Theodorou, Andreas/0000-0001-9499-1535; Shawe-Taylor, John/0000-0002-2030-0073; Baum, Kevin/0000-0002-6893-573X	European AI networks of Excellence HumaneAI-net and VISION	European AI networks of Excellence HumaneAI-net and VISION	The European AI networks of Excellence HumaneAI-net and VISION have contributed to this work.	Commission E, 2019, Ethics Guidelines for Trustworthy Al, DOI DOI 10.2759/346720; Dignum V., 2020, AI Matters, V5, P18, DOI DOI 10.1145/3375637.3375644; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; Future of Life Institute, 2023, Pause giant AI experiments: An open letter; Jelinek, 2021, ETHICS, V1, P141, DOI [DOI 10.1007/S43681-020-00019-Y, 10.1007/s43681-020-00019-y]; Mokander J., 2023, ARXIV, DOI [10.2139/ssrn.4361607, DOI 10.2139/SSRN.4361607]; OECD, 2019, Recommendation of the council on OECD legal instruments public service leadership and capability; OpenAI, 2023, GPT-4 Technical Report; Rossi Francesca, 2023, WORKING TOGETHER OUR; UNESCO, 2022, Tech. Rep. SHS/BIO/PI/2021/1; Vinuesa R, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-14108-y; White House, 2022, Blueprint for an AI Bill of Rights.; Winfield AFT, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.665729; Winter PM, 2021, Arxiv, DOI arXiv:2103.16910	14	5	5	13	39	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-9898		FRONT COMP SCI-SWITZ	Front. Comput. Sci.-Switz	MAY 18	2023	5								1210421	10.3389/fcomp.2023.1210421	http://dx.doi.org/10.3389/fcomp.2023.1210421			4	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	I1YF9		Green Published, gold			2024-07-03	WOS:001000803300001
J	Li, X; Han, GX; Fang, B; He, JH				Li, Xian; Han, Guangxin; Fang, Bei; He, Juhou			Advancing the In-Class Dialogic Quality: Developing an Artificial Intelligence-Supported Framework for Classroom Dialogue Analysis	ASIA-PACIFIC EDUCATION RESEARCHER			English	Article; Early Access						Automatic dialogue analysis; Artificial intelligence; Classroom dialogue; Dialogic teaching; Large language model	TALK; TEACHERS; ONLINE; CLASSIFICATION; COMPONENTS; PROGRAM; SCHEME	The development of artificial intelligence (AI) significantly improves the effectiveness of classroom dialogue systems, but their integration into the learning environment remains challenging. To address this gap, this research presents a framework for automatic intelligent dialogue analysis, intending to promote high-quality classroom dialogue and facilitate teaching and learning. The proposed framework includes two main components: a dialogue-oriented interactive classroom and an artificial intelligence-powered analysis system. We present a synthesis of essential principles that ought to be adhered to in the dialogue-oriented interactive classroom, as viewed through the lens of three key domains: the environment, the community and the teaching-learning. The AI system will analyse the dialogues generated from the interactive classroom. The utilization of feedback obtained from the AI system assists educators who adjust their pedagogical strategies, consequently improving the quality of classroom dialogues. Elevated-quality dialogues will reciprocally boost the performance of the AI system, engendering a sustainable improvement for the entire framework. Moreover, we also propose "Guide of AI", a union of classroom participants and experts, which serves as the bridge between the classroom and technology to guide the operation of AI system. For the validation of the framework, we conduct an empirical study that mainly investigates the effectiveness of processed essential principles and AI systems. We select 6 pre-service teachers who are randomly divided into three groups. Three groups have different levels of involvement in AI system and each teacher gives three lessons. We record and analyse all teaching dialogue records and also use questionnaires to obtain teachers' attitudes. The results show that timely feedback from AI system can promote the improvement of dialogue quality, which demonstrates the effectiveness of AI dialogue analysis system. In addition, the proposed essential principles also show a constructive impact.	[Li, Xian; Han, Guangxin; Fang, Bei; He, Juhou] Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China; [Fang, Bei] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Shaanxi, Peoples R China	Shaanxi Normal University; Shaanxi Normal University	He, JH (corresponding author), Shaanxi Normal Univ, Key Lab Modern Teaching Technol, Minist Educ, Xian 710062, Shaanxi, Peoples R China.	xianl@snnu.edu.cn; hgx@snnu.edu.cn; beifang@snnu.edu.cn; juhouh@snnu.edu.cn			National Natural Science Foundation of China [62177032, 62107027]; National Natural Science Foundation of China [2020P006]; Shaanxi Social Science Foundation [GK202205020]; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shaanxi Social Science Foundation; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This research was supported by the National Natural Science Foundation of China (62177032, 62107027), the Shaanxi Social Science Foundation (2020P006) and the Fundamental Research Funds for the Central Universities(GK202205020).	Alam A., 2021, 2021 INT C COMP INT, P1, DOI 10.1109/ICCICA52458.2021.9697272; Alexander R. J., 2008, DIALOGIC TEACHING RE; [Anonymous], 2007, Dialogue and the development of children's thinking: A sociocultural approach; Barron B, 2000, J LEARN SCI, V9, P403, DOI 10.1207/S15327809JLS0904_2; Basöz T, 2014, PROCD SOC BEHV, V116, P531, DOI 10.1016/j.sbspro.2014.01.253; Blanchard N, 2015, LECT NOTES ARTIF INT, V9112, P23, DOI 10.1007/978-3-319-19773-9_3; Böheim R, 2021, LEARN CULT SOC INTER, V28, DOI 10.1016/j.lcsi.2020.100450; Bouhnik D, 2014, J INF TECHNOL EDUC-R, V13, P217; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cacciamani S, 2018, ETR&D-EDUC TECH RES, V66, P1529, DOI 10.1007/s11423-018-9621-y; Calcagni E, 2018, LEARN CULT SOC INTER, V18, P1, DOI 10.1016/j.lcsi.2018.03.001; Cazden C.B., 1988, Classroom discourse: The language of teaching and learning; Chalkidis I, 2019, Arxiv, DOI arXiv:1906.02192; Chen X., 2020, Computers and Education: Artificial Intelligence, V1, P100002, DOI DOI 10.1016/J.CAEAI.2020.100002; Cobb P, 2011, MATH EDUC LIB, V48, P179, DOI 10.1007/978-90-481-9729-3_11; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Cui RG, 2021, LANG EDUC-UK, V35, P187, DOI 10.1080/09500782.2020.1837859; Dai SL, 2019, INT J EMERG TECHNOL, V14, P38, DOI 10.3991/ijet.v14i03.10104; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Edwards D., 2013, COMMON KNOWLEDGE DEV; Flanders N., 1970, ANAL TEACHER BEHAV; Gagné N, 2013, LANG TEACH RES, V17, P188, DOI 10.1177/1362168812460818; Gröschner A, 2015, PROF DEV EDUC, V41, P729, DOI 10.1080/19415257.2014.939692; Gu X., 2004, China Educational Technology, V7, P18; Hao TY, 2020, J EDUC COMPUT RES, V58, P1311, DOI 10.1177/0735633120940956; Hennessy S, 2018, PROF DEV EDUC, V44, P145, DOI 10.1080/19415257.2016.1258653; Higham RJE, 2014, LANG EDUC-UK, V28, P86, DOI 10.1080/09500782.2013.771655; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Hirtle J.S., 1996, ENGL J, V85, P91; Howe C, 2019, J LEARN SCI, V28, P462, DOI 10.1080/10508406.2019.1573730; Huang Y., 2021, Curriculum, Teaching Material and Method, V41, P105; Hufferd-Ackles K, 2004, J RES MATH EDUC, V35, P81, DOI 10.2307/30034933; Jaramillo J.A., 1996, EDUCATION, V117, P133; Kang S, 2013, PATTERN RECOGN LETT, V34, P1119, DOI 10.1016/j.patrec.2013.03.008; Kim MY, 2019, LEARN CULT SOC INTER, V21, P70, DOI 10.1016/j.lcsi.2019.02.003; Langley P, 2019, AAAI CONF ARTIF INTE, P9670; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lefstein A., 2013, Better than best practice: Developing teaching and learning through dialogue; Looi CK, 2010, COMPUT EDUC, V54, P14, DOI 10.1016/j.compedu.2009.07.003; Lossman H, 2010, ASIA PAC EDUC REV, V11, P121, DOI 10.1007/s12564-009-9063-7; Major L, 2018, EDUC INF TECHNOL, V23, P1995, DOI 10.1007/s10639-018-9701-y; Mercer N., 2000, WORDS MINDS WE USE L; Mercer N., 1996, Learning and Instruction, V6, P359, DOI [DOI 10.1016/S0959-4752(96)00021-7, 10.1016/s0959-4752(96)00021-7]; Mercer N, 2008, HUM DEV, V51, P90, DOI 10.1159/000113158; Mercer N, 2010, BRIT J EDUC PSYCHOL, V80, P1, DOI 10.1348/000709909X479853; Michaels S, 2008, STUD PHILOS EDUC, V27, P283, DOI 10.1007/s11217-007-9071-1; Nystrand M, 2003, DISCOURSE PROCESS, V35, P135, DOI 10.1207/S15326950DP3502_3; Pianta R. C., 2008, CLASSROOM ASSESSMENT; Radford A., 2018, IMPROVING LANGUAGE U; Saini MK, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3365757; Sánchez V, 2013, INSTR SCI, V41, P247, DOI 10.1007/s11251-012-9226-5; Sapci AH, 2020, JMIR MED EDUC, V6, DOI 10.2196/19285; Scherer R, 2018, COMPUT HUM BEHAV, V80, P67, DOI 10.1016/j.chb.2017.11.003; Song Y, 2021, J EDUC COMPUT RES, V59, P496, DOI 10.1177/0735633120968554; Stigler J.W., 1999, The TIMSS videotape classroom study: Methods and findings from an exploratory research project on eighth-grade mathematics instruction in Germany, Japan, and the United States; Suresh A., 2022, P 17 WORKSH INN US N, P71; Van Ginkel S, 2020, J COMPUT ASSIST LEAR, V36, P412, DOI 10.1111/jcal.12424; Vrikki M, 2019, INT J RES METHOD EDU, V42, P185, DOI 10.1080/1743727X.2018.1467890; Vygotsky L, 2012, THOUGHT AND LANGUAGE, P1; Walsh S, 2013, EDINB TEXTB APPL LIN, P1; Wang ZW, 2014, COMPUT EDUC, V78, P115, DOI 10.1016/j.compedu.2014.05.010; Wegerif R, 2011, THINK SKILLS CREAT, V6, P179, DOI 10.1016/j.tsc.2011.08.002; Wolf M.K., 2005, Accountable talk in reading comprehension instruction; Yang XM, 2018, INTERNET HIGH EDUC, V36, P13, DOI 10.1016/j.iheduc.2017.08.003; Yu SS, 2019, IEEE ACCESS, V7, P176600, DOI 10.1109/ACCESS.2019.2953990; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhao K, 2014, INT J COMP-SUPP COLL, V9, P63, DOI 10.1007/s11412-013-9188-x	67	0	0	2	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0119-5646	2243-7908		ASIA-PAC EDUC RES	Asia-Pac. Educ. Res.	2024 JUN 7	2024										10.1007/s40299-024-00872-z	http://dx.doi.org/10.1007/s40299-024-00872-z		JUN 2024	15	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	TO4Z9		hybrid			2024-07-03	WOS:001242204000001
J	Birkun, A				Birkun, Alexei			Performance of an artificial intelligence-based chatbot when acting as EMS dispatcher in a cardiac arrest scenario	INTERNAL AND EMERGENCY MEDICINE			English	Letter						Artificial intelligence; Cardiopulmonary resuscitation; Chatbot; GPT-4; Large language model; T-CPR	CARDIOPULMONARY-RESUSCITATION; SYSTEMS		[Birkun, Alexei] VI Vernadsky Crimean Fed Univ, Med Acad, Dept Gen Surg Anaesthesiol Resuscitat & Emergency, Simferopol, Russia	VI Vernadsky Crimean Federal University	Birkun, A (corresponding author), VI Vernadsky Crimean Fed Univ, Med Acad, Dept Gen Surg Anaesthesiol Resuscitat & Emergency, Simferopol, Russia.	birkunalexei@gmail.com	Birkun, Alexei/R-3613-2017	Birkun, Alexei/0000-0002-2789-9760				Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Berg KM, 2020, CIRCULATION, V142, pS580, DOI 10.1161/CIR.0000000000000899; Birkun AA, 2023, PREHOSP DISASTER MED, V38, P345, DOI 10.1017/S1049023X23000511; Burger B, 2023, EUR J INNOV MANAG, V26, P233, DOI 10.1108/EJIM-02-2023-0156; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Kurz MC, 2020, CIRCULATION, V141, pE686, DOI 10.1161/CIR.0000000000000744; Mould-Millman NK, 2017, PREHOSPITAL DISASTER, V32, P273, DOI 10.1017/S1049023X17000061; Picard C, 2020, BMJ INNOV, V6, P26, DOI 10.1136/bmjinnov-2018-000326	9	0	0	5	17	SPRINGER-VERLAG ITALIA SRL	MILAN	VIA DECEMBRIO, 28, MILAN, 20137, ITALY	1828-0447	1970-9366		INTERN EMERG MED	Intern. Emerg. Med.	NOV	2023	18	8					2449	2452		10.1007/s11739-023-03399-1	http://dx.doi.org/10.1007/s11739-023-03399-1		AUG 2023	4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	HC1N4	37603142				2024-07-03	WOS:001052526200001
J	Jungherr, A; Schroeder, R				Jungherr, Andreas; Schroeder, Ralph			Artificial intelligence and the public arena	COMMUNICATION THEORY			English	Article						public sphere; public arena; artificial intelligence (AI); large language models (LLMs); ChatGPT	MEDIA	The public arena relies on artificial intelligence (AI) to ever greater degrees. Media structures hosting the public arena-such as Facebook, TikTok, Twitter, and YouTube-increasingly rely on AI-enabled applications to shape information environments, autonomously generate content, and communicate with people. These applications affect the public arena's functions: make society visible to itself and provide spaces for the formation of publics and counterpublics. We offer a framework that allows for the conceptualization and empirical examination of AI's structural impact on the public arena. Based on this perspective, we argue that the growing uses of AI will lead to a strengthening of intermediary structures that can exercise a greater degree of control over the public arena. In addition, the data-driven nature of most AI-applications threatens to push challenges to the political status quo out of sight and obstruct the assessability of AI-enabled interventions.	[Jungherr, Andreas] Univ Bamberg, Inst Polit Sci, Bamberg, Germany; [Schroeder, Ralph] Univ Oxford, Oxford Internet Inst, Oxford, England	Otto Friedrich University Bamberg; University of Oxford	Jungherr, A (corresponding author), Univ Bamberg, Inst Polit Sci, Bamberg, Germany.	andreas.jungherr@uni-bamberg.de		Jungherr, Andreas/0000-0003-2598-2453				Ahmed N, 2023, SCIENCE, V379, P884, DOI 10.1126/science.ade2420; Ananny M, 2018, NEW MEDIA SOC, V20, P973, DOI 10.1177/1461444816676645; Arendt H., 1968, Between past and future: Eight exercises in political thought; Asenbaum H, 2022, POLIT STUD REV, V20, P680, DOI 10.1177/14789299211052890; Bandy Jack, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449152; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BENNETT WL, 1990, J COMMUN, V40, P103, DOI 10.1111/j.1460-2466.1990.tb02265.x; Bourdieu Pierre., 1990, OTHER WORDS, P123; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Castells M., 2009, COMMUNICATION POWER; Christian B., 2020, The Alignment Problem: Machine Learning and Human Values; Christin Angele, 2020, Metrics at Work: Journalism and the Contested Meaning of Algorithms; Cormen TH., 2022, INTRO ALGORITHMS; Diakopoulos N., 2019, Automating the news, DOI DOI 10.4159/9780674239302; Douek E, 2021, COLUMBIA LAW REV, V121, P759; Esposito Elena., 2022, Artificial Communication: How Algorithms Produce Social Intelligence; Ferree MM, 2002, THEOR SOC, V31, P289, DOI 10.1023/A:1016284431021; Fraser Nancy, 1990, Habermas and the Public Sphere, V25-26, P56, DOI DOI 10.2307/466240; Gerhards J., 1991, Offentlichkeit, Kultur, Massenkommunikation S, P31; Goldstein JA., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.04246; Gorwa R, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951719897945; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Guzman AL, 2020, NEW MEDIA SOC, V22, P70, DOI 10.1177/1461444819858691; Habermas J., 1990, Strukturwandel der O ffentlichkeit: Untersuchungen zu einer Kategorie der burgerlichen Gesellschaft; Habermas Jrgen., 2022, Ein neuer Strukturwandel der ffentlichkeit und die deliberative Politik; Habermas J, 2006, COMMUN THEOR, V16, P411, DOI 10.1111/j.1468-2885.2006.00280.x; Habermas Jurgen, 1992, Faktizitat und Geltung: Beitrage zur Diskurstheorie des Rechts und des demokratischen Rechtsstaats; Hand D.J., 2016, Measurement; a Very Short Introduction; Illing S, 2020, Vox; Jannach D., 2022, AI and Ethics, V2, P103; Jungherr A, 2020, RETOOLING POLITICS, P1, DOI 10.1017/9781108297820; Jungherr A., 2021, Digital transformations of the public arena, DOI [10.1017/9781009064484, DOI 10.1017/9781009064484]; Jungherr A., 2023, ARTIFICIAL INTELLIGE; Jungherr A, 2021, SOC MEDIA SOC, V7, DOI 10.1177/2056305121988928; Jungherr A, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119875439; Jungherr A, 2019, INT J PRESS/POLIT, V24, P404, DOI 10.1177/1940161219841543; Kelleher JD, 2019, MIT PRESS ESSENT, P1; Kovach Bill, 2021, ELEMENTS JOURNALISM; Larson Erik., 2021, The Myth of Artificial Intelligence: Why Computers Cant Think the Way We Do; Lazer D, 2014, SCIENCE, V343, P1203, DOI 10.1126/science.1248506; Lichtenberg J., 1990, DEMOCRACY MASS MEDIA, P269; Luhmann N., 2017, REALIT T MASSENMEDIE, DOI [10.1007/978-3-658-17738-6, DOI 10.1007/978-3-658-17738-6]; MacKenzie D., 2022, LONDON REV BOOKS, V44; Mitchell M., 2019, ARTIFICIAL INTELLIGE; Mitchell S, 2021, ANNU REV STAT APPL, V8, P141, DOI 10.1146/annurev-statistics-042720-125902; Muller Jan-Werner., 2021, Democracy Rules; Napoli PM, 2014, COMMUN THEOR, V24, P340, DOI 10.1111/comt.12039; Narayanan A, 2023, INDIAN J HIST SCI, V58, P87, DOI 10.1007/s43539-023-00083-3; Natale Simone, 2021, Deceitful media: Artificial intelligence and social life after the Turing test; Nielsen R. K., 2022, POWER PLATFORMS SHAP, DOI [10.1093/oso/9780190908850.001.0001, DOI 10.1093/OSO/9780190908850.001.0001]; O'Neill O., 2022, PHILOSOPHER LOOKS DI, DOI [10.1017/9781108981583, DOI 10.1017/9781108981583]; Peters Bernhard., 2007, Der Sinn von Offentlichkeit, P55; Raji Inioluwa Deborah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P959, DOI 10.1145/3531146.3533158; Ramesh A., 2022, HIERARCHICAL TEXT CO, DOI DOI 10.48550/ARXIV.2204.06125; Rauchfleisch A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241045; Rauchfleisch A, 2016, SOC MEDIA SOC, V2, DOI 10.1177/2056305116646393; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Schafer M.S., 2020, PUBLIZISTIK, V65, P307, DOI [10.1007/s11616-020-00592-6, DOI 10.1007/S11616-020-00592-6]; Schultz J., 1998, REVIVING 4 ESTATE DE, DOI [10.1017/CBO9780511597138, DOI 10.1017/CBO9780511597138]; Simon FM, 2022, DIGIT JOURNAL, DOI 10.1080/21670811.2022.2063150; Smith BC, 2019, PROMISE OF ARTIFICIAL INTELLIGENCE: RECKONING AND JUDGMENT, P1; Szegedy Christian, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1312.6199; Taylor Ch., 1995, Philosophical Arguments, P257; Trielli D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300683; Vaswani A, 2017, ADV NEUR IN, V30; Vela D, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15245-z; Warner M, 2002, PUBLIC CULTURE, V14, P49, DOI 10.1215/08992363-14-1-49; Warner Michael., 1990, The Letters of the Republic: Publication and the Public Sphere in Eighteenth-Century America; WHO, 2010, WORLD MALARIA REPORT 2010, P1; Wolfram Stephen, 2023, Stephen Wolfram Writings February 14	74	4	4	42	113	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1050-3293	1468-2885		COMMUN THEOR	Commun. Theory	JUL 28	2023	33	2-3			SI		164	173		10.1093/ct/qtad006	http://dx.doi.org/10.1093/ct/qtad006		JUN 2023	10	Communication	Social Science Citation Index (SSCI)	Communication	N0CP2		hybrid			2024-07-03	WOS:001008157600001
J	Jackson, S; Beekhuizen, B; Zhao, Z; Mcewen, R				Jackson, Samantha; Beekhuizen, Barend; Zhao, Zhao; Mcewen, Rhonda			GPT-4-Trinis: assessing GPT-4's communicative competence in the English-speaking majority world	AI & SOCIETY			English	Article; Early Access						Trinidadian English Creole; Bias; Large language models; Language variation; Inclusive AI; Human-machine communication		Biases and misunderstanding stemming from pre-training in Generative Pre-Trained Transformers are more likely for users of underrepresented English varieties, since the training dataset favors dominant Englishes (e.g., American English). We investigate (potential) bias in GPT-4 when it interacts with Trinidadian English Creole (TEC), a non-hegemonic English variety that partially overlaps with standardized English (SE) but still contains distinctive characteristics. (1) Comparable responses: we asked GPT-4 18 questions in TEC and SE and compared the content and detail of the responses. (2) Accurate translation: we assessed how accurate and authentic 29 TEC and 34 SE translations were. (3) Language knowledge and attitudes: we asked what language the prompts were written in and categorized the responses and examined any language attitudes that were exhibited. Content and detail in prompts were comparable. The model was proficient at translating TEC pronouns and many grammatical categories. It was weaker at processing spelling and vocabulary items. In addition, it produced several inauthentic features. Only 39% of TEC-generated sentences were fully grammatical. While GPT-4 was perfect at identifying SE, it was 21% accurate at identifying TEC, which it sometimes classified as English with "errors" and "corrected". GPT-4's scope of use is limited for non-hegemonic English users. It is problematic that some of its analyses perpetuate bias against underrepresented Englishes. Increased research on lesser-documented Englishes is necessary and we anticipate that this problem affects dialects of other languages. We intend to partner with Trinidadian stakeholders to train GPT-4 in the future.	[Jackson, Samantha; Beekhuizen, Barend] Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON, Canada; [Zhao, Zhao] McMaster Univ, Dept Comp & Software, Hamilton, ON, Canada; [Mcewen, Rhonda] Univ Toronto, Victoria Univ, Toronto, ON, Canada	University of Toronto; University Toronto Mississauga; McMaster University; University of Victoria; University of Toronto	Jackson, S (corresponding author), Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON, Canada.	samantha.jackson@utoronto.ca			Social Sciences and Humanities Research Council	Social Sciences and Humanities Research Council(Social Sciences and Humanities Research Council of Canada (SSHRC))	We would like to thank Yi-Ting Deng, Wenqing Qian, and Yi Cheng Zhao for their work as research assistants, and Julia Watson for help with the literature review.	[Anonymous], 2012, CONNECTING EMIGRANTS, DOI DOI 10.1787/9789264177949-EN; [Anonymous], 1953, USE VERNACULAR LANGU; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blodgett SL, 2020, Arxiv, DOI arXiv:2005.14050; Chen M, 2023, AI SOC, DOI 10.1007/s00146-023-01681-6; Coeckelbergh M, 2023, AI SOC, DOI 10.1007/s00146-023-01710-4; Davani AM, 2023, T ASSOC COMPUT LING, V11, P300, DOI 10.1162/tacl_a_00550; Deas N, 2023, Arxiv, DOI [arXiv:2305.14291, 10.48550/arXiv.2305.14291, DOI 10.48550/ARXIV.2305.14291]; DeGraff M., 2005, Rev Francaise De Linguistique Appl, DOI [10.3917/rfla.101.24, DOI 10.3917/RFLA.101.24]; Deuber D., 2009, World Englishes - problems, properties and prospects: Selected papers from the 13th IAWE conference, P83, DOI DOI 10.1075/VEAW.G40.08DEU; Deuber D., 2014, English in the Caribbean: Variation, style and standards in Jamaica and Trinidad, DOI DOI 10.1017/CBO9781139226400; Deuber D, 2013, LANG CULT CURRIC, V26, P109, DOI 10.1080/07908318.2013.794816; Färber M, 2023, SCIENTOMETRICS, V128, P2703, DOI 10.1007/s11192-023-04636-2; Fan LZ, 2023, Arxiv, DOI [arXiv:2304.02020, DOI 10.48550/ARXIV.2304.02020]; Friedman B, 1996, ACM T INFORM SYST, V14, P330, DOI 10.1145/230538.230561; Garg N., 2018, Proc Natl Acad Sci, DOI [10.1073/pnas.172034711, DOI 10.1073/PNAS.172034711]; Hao K., 2022, TECHNOLOGY REV; Jackson S, 2023, FIRST LANG, V43, P283, DOI 10.1177/01427237221147614; James W., 2004, A handbook of varieties of English 1: morphology and syntax, P454; Janowicz K, 2023, Arxiv, DOI [arXiv:2304.06508, 10.48550/arXiv.2304.06508, DOI 10.48550/ARXIV.2304.06508]; Johnstone B, 2018, AM SPEECH, V93, P497, DOI 10.1215/00031283-7271294; Jones S, 2023, SAGE handbook of Human-Machine Communication, DOI [10.4135/9781529782783, DOI 10.4135/9781529782783]; Krenn B, 2017, AI SOC, V32, P65, DOI 10.1007/s00146-014-0569-0; Lalla B., 2006, Exploring the boundaries of Caribbean Creole languages, P173; Lawrence HM, 2020, YOUR COMPUTER IS ON FIRE, P179; Lee A, 2023, Arxiv, DOI [arXiv:2306.13840, 10.48550/arXiv.2306.13840, DOI 10.48550/ARXIV.2306.13840]; Lent H, 2021, Arxiv, DOI [arXiv:2109.06074, 10.48550/arXiv.2109.06074, DOI 10.48550/ARXIV.2109.06074]; Lippi-Green Rosina., 2012, English with an accent: Language, ideology, and discrimination in the United States, DOI DOI 10.4324/9780203348802; Miller K, 2022, The movement to decolonize AI: centering dignity over dependency; Mufwene S., 2001, The ecology of language evolution (Cambridge approaches to language contact), DOI DOI 10.1017/CBO9780511612862; Mufwene S., 2001, International encyclopedia of the social behavioral sciences, P11440, DOI [10.1016/B0-08-043076-7/02939-9, DOI 10.1016/B0-08-043076-7/02939-9]; Muhleisen S, 2001, Philol Netz; Murawaki Y, 2016, P 2016 C N AM CHAPT; Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356; Parde N, 2023, SAGE handbook of Human-Machine Communication, DOI [10.4135/9781529782783, DOI 10.4135/9781529782783]; Santy S, 2023, P 61 ANN M ASS COMP, V1, DOI [10.18653/v1/2023.acl-long.505, DOI 10.18653/V1/2023.ACL-LONG.505]; Siegel J, 2010, J MULTILING MULTICUL, V31, P383, DOI 10.1080/01434632.2010.497217; Solomon D., 1993, SPEECH TRINIDAD; Stinson Catherine., 2022, AI and Ethics, V2, P763, DOI DOI 10.1007/S43681-022-00136-W; Tajeddin Z, 2020, ASIAN-PAC J SEC FOR, V5, DOI 10.1186/s40862-020-00089-9; Tatman Rachael, 2017, P 1 ACL WORKSHOP ETH, DOI [10.18653/v1/w17, DOI 10.18653/V1/W17-1606, 10.18653/v1/w17-1606]; Thakur V, 2023, Arxiv, DOI arXiv:2307.09162; Tommasi T, 2015, Arxiv, DOI [arXiv:1505.01257, 10.48550/arXiv.1505.01257, DOI 10.48550/ARXIV.1505.01257]; Watson J, 2023, P 61 ANN M ASS COMP, V1, DOI [10.18653/v1/2023.acl-long.375, DOI 10.18653/V1/2023.ACL-LONG.375]; Winer L., 1993, Trinidad and Tobago, DOI [10.1075/veaw.t6, DOI 10.1075/VEAW.T6]; Winer L., 2009, Dictionary of the English/Creole of Trinidad Tobago, DOI [10.1515/9780773576070, DOI 10.1515/9780773576070]; Winer Lise., 1990, LANG PROBL LANG PLAN, V14, P237, DOI DOI 10.1075/LPLP.14.3.04WIN; Youssef V., 2004, A handbook of varieties of English: Volume 1: Phonology, P508; Youssef V., 2010, Educ Societes Plurilingues, DOI [10.1075/jpcl.11.1.02you, DOI 10.1075/JPCL.11.1.02YOU]; Youssef V., 2004, ENGL TODAY, V20, P42, DOI DOI 10.1017/S0266078404004080; Yu Y, 2023, Arxiv, DOI [arXiv:2306.15895, DOI 10.48550/ARXIV.2306.15895]; Zhao Z, 2022, ACMIEEE INT CONF HUM, P24, DOI 10.1109/HRI53351.2022.9889672; Zhou JY, 2023, Arxiv, DOI arXiv:2308.15399	53	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2024 MAY 2	2024										10.1007/s00146-024-01945-9	http://dx.doi.org/10.1007/s00146-024-01945-9		MAY 2024	17	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	PV6O1					2024-07-03	WOS:001216899100001
J	Sufi, F				Sufi, Fahim			Addressing Data Scarcity in the Medical Domain: A GPT-Based Approach for Synthetic Data Generation and Feature Extraction	INFORMATION			English	Article						GPT; large language models; prompt engineering; synthetic data generation; medical date labeling; feature extraction	CHATGPT	This research confronts the persistent challenge of data scarcity in medical machine learning by introducing a pioneering methodology that harnesses the capabilities of Generative Pre-trained Transformers (GPT). In response to the limitations posed by a dearth of labeled medical data, our approach involves the synthetic generation of comprehensive patient discharge messages, setting a new standard in the field with GPT autonomously generating 20 fields. Through a meticulous review of the existing literature, we systematically explore GPT's aptitude for synthetic data generation and feature extraction, providing a robust foundation for subsequent phases of the research. The empirical demonstration showcases the transformative potential of our proposed solution, presenting over 70 patient discharge messages with synthetically generated fields, including severity and chances of hospital re-admission with justification. Moreover, the data had been deployed in a mobile solution where regression algorithms autonomously identified the correlated factors for ascertaining the severity of patients' conditions. This study not only establishes a novel and comprehensive methodology but also contributes significantly to medical machine learning, presenting the most extensive patient discharge summaries reported in the literature. The results underscore the efficacy of GPT in overcoming data scarcity challenges and pave the way for future research to refine and expand the application of GPT in diverse medical contexts.	[Sufi, Fahim] Monash Univ, Sch Publ Hlth & Prevent Med, Melbourne, Vic 3004, Australia	Monash University	Sufi, F (corresponding author), Monash Univ, Sch Publ Hlth & Prevent Med, Melbourne, Vic 3004, Australia.	research@fahimsufi.com	Sufi, Fahim/AFL-8167-2022	Sufi, Fahim/0000-0002-9683-0839				Acharya A, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1204, DOI 10.1145/3604915.3610647; Alahmar Ayman, 2018, 2018 4th International Conference on Big Data Innovations and Applications (Innovate-Data). Proceedings, P38, DOI 10.1109/Innovate-Data.2018.00013; Alberts IL, 2023, EUR J NUCL MED MOL I, V50, P1549, DOI 10.1007/s00259-023-06172-w; Amin-Nejad A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4699; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Aouedi O, 2023, IEEE J BIOMED HEALTH, V27, P790, DOI 10.1109/JBHI.2022.3185673; Balaji S, 2023, Arxiv, DOI arXiv:2310.03030; Bayer M, 2023, INT J MACH LEARN CYB, V14, P135, DOI 10.1007/s13042-022-01553-3; Ben Veyseh AP, 2021, LECT NOTES ARTIF INT, V12977, P644, DOI 10.1007/978-3-030-86523-8_39; Bird JJ, 2021, IEEE ROBOT AUTOM LET, V6, P3498, DOI 10.1109/LRA.2021.3056355; Borisov V, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3229161; Borisov V, 2023, Arxiv, DOI [arXiv:2210.06280, 10.48550/arXiv.2210.06280]; Cai XM, 2023, medRxiv, DOI [10.1101/2023.09.06.23295072, 10.1101/2023.09.06.23295072, DOI 10.1101/2023.09.06.23295072]; Casula C, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3359; Chang Y., 2023, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), P265, DOI [10.1007/978-3-031-41682-817, DOI 10.1007/978-3-031-41682-817]; Chatterjee S, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00700-1; Chen Huanlei, 2023, Neural Information Processing: 29th International Conference, ICONIP 2022, Virtual Event, Proceedings. Communications in Computer and Information Science (1794), P272, DOI 10.1007/978-981-99-1648-1_23; Chung JJY, 2023, Arxiv, DOI arXiv:2306.04140; Cohen S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101887; D'sa Ashwin Geet, 2021, Text, Speech, and Dialogue: 24th International Conference, TSD 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12848), P135, DOI 10.1007/978-3-030-83527-9_12; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; de Kok T.., 2023, Generative LLMs and Textual Analysis in Accounting: (Chat)GPT as Research Assistant?; Elbadawi M, 2024, INT J PHARMACEUT, V652, DOI 10.1016/j.ijpharm.2023.123741; Espejel J.L., 2023, Nat. Lang. Process. J, V5, P100032, DOI DOI 10.1016/J.NLP.2023.100032; Gilbert A, 2021, IEEE T MED IMAGING, V40, P2783, DOI 10.1109/TMI.2021.3051806; Grässler I, 2022, IEEE INT SYST ENG SY, DOI 10.1109/ISSE54508.2022.10005452; Hämäläinen P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580688; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hong X.-S., 2022, P 16 NTCIR C EV INF; Hu YJ, 2023, INT J GEOGR INF SCI, V37, P2289, DOI 10.1080/13658816.2023.2266495; Jansen B J., 2023, Natural Language Processing Journal, P100020, DOI DOI 10.1016/J.NLP.2023.100020; Khatri S, 2022, 2022 HUMAN-CENTERED COGNITIVE SYSTEMS, HCCS, P71, DOI 10.1109/HCCS55241.2022.10090376; Lee MHY, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11112451; Lengerich BJ, 2023, Arxiv, DOI arXiv:2308.01157; Lim S, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1129082; Lu Q., 2021, P 2021 IEEE INT C BI, P2817, DOI [10.1109/BIBM52615.2021.9669861, DOI 10.1109/BIBM52615.2021.9669861]; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Mahuli SA, 2023, BRIT DENT J, V235, P90, DOI 10.1038/s41415-023-6132-y; Maimaiti M, 2022, INT J INTELL SYST, V37, P30, DOI 10.1002/int.22616; Tapia-Téllez JM, 2020, LECT NOTES ARTIF INT, V12469, P247, DOI 10.1007/978-3-030-60887-3_22; Meyer S, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544529; Modzelewski A., 2023, P 17 INT WORKSH SEM; Nakamoto R, 2023, COMPUTERS, V12, DOI 10.3390/computers12110217; Narayan A, 2022, PROC VLDB ENDOW, V16, P738, DOI 10.14778/3574245.3574258; Nouri N., 2022, P 2022 C N AM CHAPT; Pellicer LFAO, 2023, APPL SOFT COMPUT, V132, DOI 10.1016/j.asoc.2022.109803; Pouran A., 2022, P 3 WORKSH DEEP LEAR; Queiroz Abonizio Hugo, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P551, DOI 10.1007/978-3-030-61377-8_38; Quteineh H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7400; Rebboud Y., 2023, P 2023 IEEE 5 INT C; Reddy Sandeep, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101304; Romero-Sandoval M., 2023, P 2023 IEEE 5 INT C, P1, DOI [10.1109/BIP60195.2023.10379347, DOI 10.1109/BIP60195.2023.10379347]; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sawai R, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10243082; Sharma A., 2022, P 2022 IEEE BOMB SEC; Singh C, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-43713-1; Sufi Fahim K., 2022, IEEE Transactions on Technology and Society, V3, P290, DOI 10.1109/TTS.2022.3192757; Sufi F.K., 2022, Decis. Anal. J, V5, P100130, DOI [10.1016/j.dajour.2022.100130, DOI 10.1016/J.DAJOUR.2022.100130]; Sufi F, 2023, INFORMATION, V14, DOI 10.3390/info14090485; Sufi F, 2023, ALGORITHMS, V16, DOI 10.3390/a16020108; Sufi FK, 2023, ARAB J SCI ENG, V48, P2455, DOI 10.1007/s13369-022-07250-1; Sufi FK, 2022, SOFTW IMPACTS, V13, DOI 10.1016/j.simpa.2022.100319; Sufi FK, 2022, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2022.3157142; Sufi FK, 2022, SOFTW IMPACTS, V11, DOI 10.1016/j.simpa.2022.100218; Sufi FK, 2021, IEEE ACCESS, V9, P152449, DOI 10.1109/ACCESS.2021.3127571; Suhaeni C, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13179766; Thamsen B, 2021, IEEE T MED IMAGING, V40, P1438, DOI 10.1109/TMI.2021.3057496; Van Nooten J., 2023, P 13 WORKSH COMP APP; Vogel L, 2022, LECT NOTES ARTIF INT, V13502, P476, DOI 10.1007/978-3-031-16270-1_39; Waisberg E., 2023, J. Med. Artif. Intell, V6, DOI [10.21037/jmai-23-36, DOI 10.21037/JMAI-23-36]; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]; Zhou SH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311251	73	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	MAY	2024	15	5							264	10.3390/info15050264	http://dx.doi.org/10.3390/info15050264			31	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	SE6G8		gold			2024-07-03	WOS:001232815400001
J	Mozhdehi, MH; Moghadam, AE				Mozhdehi, Mahsa Hadikhah; Moghadam, AmirMasoud Eftekhari			Textual emotion detection utilizing a transfer learning approach	JOURNAL OF SUPERCOMPUTING			English	Article						Natural language processing; Emotion classification; Text mining; Emotion detection; Transfer learning; Large language models	RECOGNITION; BERT	Many attempts have been made to overcome the challenges of automating textual emotion detection using different traditional deep learning models such as LSTM, GRU, and BiLSTM. But the problem with these models is that they need large datasets, massive computing resources, and a lot of time to train. Also, they are prone to forgetting and cannot perform well when applied to small datasets. In this paper, we aim to demonstrate the capability of transfer learning techniques to capture the better contextual meaning of the text and as a result better detection of the emotion represented in the text, even without a large amount of data and training time. To do this, we conduct an experiment utilizing a pre-trained model called EmotionalBERT, which is based on bidirectional encoder representations from transformers (BERT), and we compare its performance to RNN-based models on two benchmark datasets, with a focus on the amount of training data and how it affects the models' performance.	[Mozhdehi, Mahsa Hadikhah; Moghadam, AmirMasoud Eftekhari] Islamic Azad Univ, Fac Comp & Informat Technol, Qazvin, Iran	Islamic Azad University	Moghadam, AE (corresponding author), Islamic Azad Univ, Fac Comp & Informat Technol, Qazvin, Iran.	mahsa.mozhdehi@gmail.com; eftekhari.moghadam@gmail.com						Acheampong FA, 2021, ARTIF INTELL REV, V54, P5789, DOI 10.1007/s10462-021-09958-2; Adoma AF, 2020, I COMP CONF WAVELET, P117, DOI 10.1109/ICCWAMTIP51612.2020.9317379; Asghar MZ, 2019, PERFORM EVALUATION, DOI [10.20944/preprints201908.0019.v1, DOI 10.20944/PREPRINTS201908.0019.V1]; Avots E, 2019, MACH VISION APPL, V30, P975, DOI 10.1007/s00138-018-0960-9; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169; Chatterjee A, 2019, COMPUT HUM BEHAV, V93, P309, DOI 10.1016/j.chb.2018.12.029; Cho Bv, 2014, ARXIV14061078, P1724, DOI 10.3115/v1/d14-1179; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du K-L, 2019, NEURAL NETWORKS STAT, P351, DOI [10.1007/978-1-4471-5571-3_2, DOI 10.1007/978-1-4471-5571-3_2]; Fung P., 2018, INT C LANG RES EV; Garcia K, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107057; Hasan M, 2021, IEEE INT CONF BIG DA, P5143, DOI 10.1109/BigData52589.2021.9671803; Hasan M, 2019, INT J DATA SCI ANAL, V7, P35, DOI 10.1007/s41060-018-0096-z; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094; Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008; Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Kratzwald B, 2018, DECIS SUPPORT SYST, V115, P24, DOI 10.1016/j.dss.2018.09.002; Mehendale N, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2234-1; Poria S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P527; Prottasha NJ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114157; Radford A., 2018, IMPROVING LANGUAGE U; Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2; SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158; Wakamiya S, 2015, LECT NOTES COMPUT SC, V9080, P37, DOI 10.1007/978-3-319-18251-3_3; Wang WB, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P587, DOI 10.1109/SocialCom-PASSAT.2012.119; Xu GX, 2020, FUTURE GENER COMP SY, V102, P347, DOI 10.1016/j.future.2019.07.007; Yang Z., 2019, NEURAL INFORM PROCES	33	1	1	9	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-8542	1573-0484		J SUPERCOMPUT	J. Supercomput.	AUG	2023	79	12					13075	13089		10.1007/s11227-023-05168-5	http://dx.doi.org/10.1007/s11227-023-05168-5		MAR 2023	15	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J3MB8	37359334	Bronze, Green Published			2024-07-03	WOS:000957533900006
C	Ma, M; Waldon, B; Nyarko, J			ACM	Ma, Megan; Waldon, Brandon; Nyarko, Julian			Conceptual Questions in Developing Expert-Annotated Data	PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023			English	Proceedings Paper	19th International Conference on Artificial Intelligence and Law (ICAIL)	JUN 19-23, 2023	Univ Minho Law Sch, Braga, PORTUGAL	Int Assoc Artificial Intelligence & Law, Univ Minho Informat Dept Engn Sch, JUSGOV Res Ctr Justice & Governance, Centro Algoritmi, Intelligent Syst Associated Lab, Thomson Reuters, Centro Juridico Minho, Antas da Cunha ECIJA Soc Advogados, Visionware, Simplexico, Assoc Advancement Artificial Intelligence, ACM SIGAI	Univ Minho Law Sch	data annotation paradigms; large language models; contract review; domain expertise; legal NLP		In this paper, we argue that nuanced expert annotation often requires a significant rethinking of the traditional paradigms of data annotation. In a small pilot study, we find that even the most highly trained experts demonstrate significant heterogeneity in their evaluation of the document-level coherence of bespoke contracts. The outcomes of our study provide preliminary considerations of how paradigms of document annotation should fully utilize expert annotations in bespoke contexts.	[Ma, Megan] Stanford Law Sch, Stanford Ctr Legal Informat, Palo Alto, CA 94305 USA; [Waldon, Brandon] Stanford Univ, Palo Alto, CA 94304 USA; [Nyarko, Julian] Stanford Law Sch, Palo Alto, CA USA	Stanford University; Stanford University; Stanford University	Ma, M (corresponding author), Stanford Law Sch, Stanford Ctr Legal Informat, Palo Alto, CA 94305 USA.	meganma@law.stanford.edu; bwaldon@stanford.edu; jnyarko@law.stanford.edu		Nyarko, Julian/0000-0002-7121-5696	Stanford Institute for Human-Centered Artificial Intelligence (HAI)	Stanford Institute for Human-Centered Artificial Intelligence (HAI)	This research is made possible thanks to our affiliate partnerships at the Stanford Center for Legal Informatics (CodeX) and to the funding support from the Stanford Institute for Human-Centered Artificial Intelligence (HAI).	Chalkidis I, 2022, Arxiv, DOI arXiv:2110.00976; Hendrycks D., 2021, arXiv; Koreeda Yuta, 2021, arXiv; Le K.H., 2022, arXiv; Leivaditi S, 2020, Arxiv, DOI arXiv:2010.10386; Pearlman Jessica C., 2021, 2021 ABA PRIVATE TARGET MERGERS ACQUISITIONS DEAL POINTS STUDY; Röttger P, 2022, Arxiv, DOI arXiv:2112.07475; Wang SH, 2023, Arxiv, DOI arXiv:2301.00876; Williams Spencer, 2020, Del. J. Corp. L, V45, P219	9	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0197-9				2023							427	431		10.1145/3594536.3595139	http://dx.doi.org/10.1145/3594536.3595139			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Government & Law	BW3KK					2024-07-03	WOS:001139079400049
J	Jia, JY; Wang, TR; Zhang, YY; Wang, GD				Jia, Jiyou; Wang, Tianrui; Zhang, Yuyue; Wang, Guangdi			The comparison of general tips for mathematical problem solving generated by generative AI with those generated by human teachers	ASIA PACIFIC JOURNAL OF EDUCATION			English	Article						General tips; intelligent tutoring system; mathematical education; large language models; prompt engineering; turing test	INTELLIGENT TUTORING SYSTEMS	In designing an intelligent tutoring system, a core area of the application of AI in education, tips from the system or virtual tutors are crucial in helping students solve difficult questions in disciplines like mathematics. Traditionally, the manual design of general tips by teachers is time-consuming and error-prone. Generative AI, like ChatGPT, presents a new channel for designing general tips. This study utilized prompt engineering and Chain of Thought to summarize general tips for given mathematical problems (one geometry problem and one algebra problem) and their solutions. A Turing test was conducted to compare ChatGPT-generated general tips with human-designed ones. Results from 121 human evaluators, each assessing 6 ChatGPT-generated and 6 human-designed general tips for each of two mathematical problems, showed that the average score for ChatGPT-generated tips is less than that of human-designed tips at a statistically significant level (p < 0.05), and Zero-Shot CoT achieved the best score. However, no evaluator could distinguish the tip types exactly. The average precision, recall and F-value of all ChatGPT-generated tips are less than 40%. AI-generated general tips can serve as a valuable reference for teachers to enhance efficiency and students' mathematical learning.	[Jia, Jiyou; Zhang, Yuyue] Peking Univ, Dept Educ Technol, Grad Sch Educ, Beijing, Peoples R China; [Wang, Tianrui] Univ Chinese Acad Sci, Sch Humanities, Beijing, Peoples R China; [Wang, Guangdi] Beijing Int Studies Univ, Chinese Inst, Beijing, Peoples R China; [Jia, Jiyou] Peking Univ, Grad Sch Educ, Dept Educ Technol, Yiheyuanlu 5, Beijing 100871, Peoples R China	Peking University; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Beijing International Studies University; Peking University	Jia, JY (corresponding author), Peking Univ, Grad Sch Educ, Dept Educ Technol, Yiheyuanlu 5, Beijing 100871, Peoples R China.	jjy@pku.edu.cn		Wang, Guangdi/0009-0006-1737-8239	National Social Science Fund of China [BCA220208]; National Education Research Funding Project "Students' Intelligent Assessment and Tutoring Research Based on Big-data Mining"; National Social Science Foundation, China	National Social Science Fund of China; National Education Research Funding Project "Students' Intelligent Assessment and Tutoring Research Based on Big-data Mining"; National Social Science Foundation, China	This research is supported by the National Education Research Funding Project "Students' Intelligent Assessment and Tutoring Research Based on Big-data Mining" (Number: BCA220208) granted by National Social Science Foundation, China. The authors extend heartfelt appreciation to all the teachers and students who have participated in this research, as well as gratitude to the reviewers and editors for their invaluable insights and suggestions.	[Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Dao XQ, 2023, Arxiv, DOI arXiv:2306.06331; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Garcia X, 2023, Arxiv, DOI [arXiv:2302.01398, 10.48550/arXiv.2302.01398]; Han L., 2010, Teaching Administration, V2010, P59; Hao H., 2006, Theory and Practice of Education, V26, P40; Jia J., 2023, E-Education Research, V44, P74; Jia J., 2015, Encyclopedia of educational technology, P411; Jia J., 2023, China Educational Technology, P112, DOI [https://doi.org/10.3969/j.issn.1006-9860.2023.03.016, DOI 10.3969/J.ISSN.1006-9860.2023.03.016]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Kulik JA, 2016, REV EDUC RES, V86, P42, DOI 10.3102/0034654315581420; Lee CI, 2017, EURASIA J MATH SCI T, V13, P893, DOI 10.12973/eurasia.2017.00649a; Li HA, 2024, Arxiv, DOI arXiv:2306.09212; Liu V., 2022, P 2022 CHI C HUMAN F, P1; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Nov O., 2023, arXiv preprint arXiv:230110035; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Russo J., 2020, MATH TEACHER ED DEV, V22, P48; Sanh V, 2022, arXiv; Song YS, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3582688; Tang Ruya, 2023, Blended Learning : Lessons Learned and Ways Forward: 16th International Conference on Blended Learning, ICBL 2023, Proceedings. Lecture Notes in Computer Science (13978), P273, DOI 10.1007/978-3-031-35731-2_24; VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369; Wardat Y., 2023, Eurasia Journal of Mathematics, Science and Technology Education, V19, DOI DOI 10.29333/EJMSTE/13272; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Winata Genta Indra, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.07684; Yang CHH, 2023, Arxiv, DOI arXiv:2309.15649; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zheng CY, 2023, Arxiv, DOI [arXiv:2304.09797, 10.48550/arXiv.2304.09797]; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]	33	0	0	39	39	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0218-8791	1742-6855		ASIA PAC J EDUC	Asia Pac. J. Educ.	JAN 2	2024	44	1			SI		8	28		10.1080/02188791.2023.2286920	http://dx.doi.org/10.1080/02188791.2023.2286920			21	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	JG4I1					2024-07-03	WOS:001171996000006
C	Cambaz, D; Zhang, XL			Assoc Computing Machinery	Cambaz, Doga; Zhang, Xiaoling			Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		Systematic review; Artificial intelligence in education; Programming education; Code generation models; Large language models		The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.	[Cambaz, Doga; Zhang, Xiaoling] Delft Univ Technol, Delft, Netherlands	Delft University of Technology	Cambaz, D (corresponding author), Delft Univ Technol, Delft, Netherlands.	dogacambaz@gmail.com; X.Zhang-14@tudelft.nl		Zhang, Xiaoling/0000-0003-0951-0771				Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Brennan Robert W., 2023, Exploring the Implications of OpenAI Codex on Education for Industry, V4, P254, DOI [10.1007/978-3-031-24291-5_20, DOI 10.1007/978-3-031-24291-5_20]; Brusilovsky Peter, 2023, CS2023; Bull C, 2023, Arxiv, DOI arXiv:2303.13936; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Dobslaw F, 2023, Arxiv, DOI arXiv:2305.02198; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Geng CQ, 2023, Arxiv, DOI arXiv:2305.02230; Gramoli Vincent, 2016, P AUSTRALASIAN COMPU, DOI DOI 10.1145/2843043.2843070; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kazemitabaar M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580919; Kitchenham B, 2007, Technical Report EBSE-2007-01; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil Stephen, 2023, P 54 ACM TECHNICAL S, V2, P1176, DOI DOI 10.1145/3545947.3569630; Prather J, 2023, Arxiv, DOI arXiv:2304.02491; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Qureshi B, 2023, Arxiv, DOI arXiv:2304.11214; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI [arXiv:2303.08033, DOI 10.48550/ARXIV.2303.08033]; Sherman M., 2013, J. Comput. Sci. Coll., V28, P69, DOI 10.5555/2460156.24601713,4,7; Wilcox C., 2015, Proc. 2015 SIGCSE, P90, DOI DOI 10.1145/2676723.2677226; Yan LX, 2023, Arxiv, DOI arXiv:2303.13379; Zhang J., 2022, arXiv	25	1	1	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							172	178		10.1145/3626252.3630958	http://dx.doi.org/10.1145/3626252.3630958			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		Green Submitted			2024-07-03	WOS:001181240800027
J	Cheong, RCT; Unadkat, S; Mcneillis, V; Williamson, A; Joseph, J; Randhawa, P; Andrews, P; Paleri, V				Cheong, Ryan Chin Taw; Unadkat, Samit; Mcneillis, Venkata; Williamson, Andrew; Joseph, Jonathan; Randhawa, Premjit; Andrews, Peter; Paleri, Vinidh			Artificial intelligence chatbots as sources of patient education material for obstructive sleep apnoea: ChatGPT versus Google Bard	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						Artificial intelligence; Large language models; ChatGPT; Google Bard; Obstructive sleep apnoea; Patient education material		Purpose To perform the first head-to-head comparative evaluation of patient education material for obstructive sleep apnoea generated by two artificial intelligence chatbots, ChatGPT and its primary rival Google Bard.Methods Fifty frequently asked questions on obstructive sleep apnoea in English were extracted from the patient information webpages of four major sleep organizations and categorized as input prompts. ChatGPT and Google Bard responses were selected and independently rated using the Patient Education Materials Assessment Tool-Printable (PEMAT-P) Auto-Scoring Form by two otolaryngologists, with a Fellowship of the Royal College of Surgeons (FRCS) and a special interest in sleep medicine and surgery. Responses were subjectively screened for any incorrect or dangerous information as a secondary outcome. The Flesch-Kincaid Calculator was used to evaluate the readability of responses for both ChatGPT and Google Bard.Results A total of 46 questions were curated and categorized into three domains: condition (n = 14), investigation (n = 9) and treatment (n = 23). Understandability scores for ChatGPT versus Google Bard on the various domains were as follows: condition 90.86% vs.76.32% (p < 0.001); investigation 89.94% vs. 71.67% (p < 0.001); treatment 90.78% vs.73.74% (p < 0.001). Actionability scores for ChatGPT versus Google Bard on the various domains were as follows: condition 77.14% vs. 51.43% (p < 0.001); investigation 72.22% vs. 54.44% (p = 0.05); treatment 73.04% vs. 54.78% (p = 0.002). The mean Flesch-Kincaid Grade Level for ChatGPT was 9.0 and Google Bard was 5.9. No incorrect or dangerous information was identified in any of the generated responses from both ChatGPT and Google Bard.Conclusion Evaluation of ChatGPT and Google Bard patient education material for OSA indicates the former to offer superior information across several domains.	[Cheong, Ryan Chin Taw; Williamson, Andrew; Paleri, Vinidh] Royal Marsden NHS Fdn Trust, Otolaryngol Head & Neck Surg Dept, Fulham Rd, London SW3 6JJ, England; [Unadkat, Samit; Mcneillis, Venkata; Joseph, Jonathan; Randhawa, Premjit; Andrews, Peter] Univ Coll London Hosp NHS Fdn Trust, Royal Natl ENT & Eastman Dent Hosp, Otolaryngol Head & Neck Surg Dept, London, England	Royal Marsden NHS Foundation Trust; University College London Hospitals NHS Foundation Trust; University of London; University College London	Cheong, RCT (corresponding author), Royal Marsden NHS Fdn Trust, Otolaryngol Head & Neck Surg Dept, Fulham Rd, London SW3 6JJ, England.	ryan.cheong@nhs.net		Williamson, Andrew/0000-0002-3861-4847; Paleri, Vinidh/0000-0002-7933-4585; Cheong, Ryan ChinTaw/0000-0001-7846-8699				aasm, PAT FRIENDL GUID AM; ahrq, INTRO AGENCY HEALTHC; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], NHS LONG TERM PLAN; [Anonymous], 2023, GOOGL AI UPD BARD NE; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Benjafield AV, 2019, LANCET RESP MED, V7, P687, DOI 10.1016/S2213-2600(19)30198-5; entuk, SNORING SLEEP APNOEA; epic, EP MICR BRING GPT 4; goodcalculators, FLESCH KINC CALC; gov, MILL ROLL OUT ART IN; gov, FUNDING BOOST ARTIFI; impressiondigital, BING VS GOOGL SEARCH; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lyons MM, 2020, RESPIROLOGY, V25, P690, DOI 10.1111/resp.13838; Marin JM, 2005, LANCET, V365, P1046, DOI 10.1016/S0140-6736(05)71141-7; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; microsoft, REINV SEARCH NEW AI; ncsc, CHATGPT LLMS WHATS R; Obstructive Sleep Apnea (OSA), US; Oliffe M, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-024582; OpenAI, 2022, Introducing ChatGPT, P1; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Shoemaker SJ, 2013, PATIENT ED MAT ASSES, P11; statista, INTERNET SOCIAL MEDI; surgicalsleep, PATIENTS INT SURG SL; Watson NF, 2016, J CLIN SLEEP MED, V12, P1075, DOI 10.5664/jcsm.6034	28	10	10	5	10	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	FEB	2024	281	2					985	993		10.1007/s00405-023-08319-9	http://dx.doi.org/10.1007/s00405-023-08319-9		NOV 2023	9	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	FD4N0	37917165				2024-07-03	WOS:001098005800002
J	Wu, RC; Li, DX; Feng, DC				Wu, Rui-Cheng; Li, Deng-Xiong; Feng, De-Chao			Re: Michael Eppler, Conner Ganjavi, Lorenzo Storino Ramacciotti, et al. Awareness and Use of ChatGPT and Large Language Models: A Prospective Cross-sectional Global Survey in Urology. Eur Urol. 2024;85:146-53.	EUROPEAN UROLOGY			English	Letter									[Wu, Rui-Cheng; Li, Deng-Xiong; Feng, De-Chao] Sichuan Univ, West China Hosp, Inst Urol, Dept Urol, Chengdu 610041, Sichuan, Peoples R China	Sichuan University	Feng, DC (corresponding author), Sichuan Univ, West China Hosp, Inst Urol, Dept Urol, Chengdu 610041, Sichuan, Peoples R China.	fdcfenix@stu.scu.edu.cn						Caglar U, 2024, J PEDIATR UROL, V20, DOI 10.1016/j.jpurol.2023.08.003; Eppler M, 2024, EUR UROL, V85, P146, DOI 10.1016/j.eururo.2023.10.014; He Q, 2023, Brain-X, V1, pe51, DOI [10.1002/brx2.51, DOI 10.1002/BRX2.51]; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922	4	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0302-2838	1873-7560		EUR UROL	Eur. Urol.	MAR	2024	85	3					e87	e88		10.1016/j.eururo.2023.11.029	http://dx.doi.org/10.1016/j.eururo.2023.11.029		MAR 2024	2	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	NR3Z1	38151444				2024-07-03	WOS:001202153800001
J	Zalzal, HG; Cheng, JH; Shah, RK				Zalzal, Habib G.; Cheng, Jenhao; Shah, Rahul K.			Evaluating the Current Ability of ChatGPT to Assist in Professional Otolaryngology Education	OTO OPEN			English	Article						artificial intelligence; ChatGPT; continuing medical education; large language model; machine learning; maintenance of certification; OpenAI		Objective. To quantify ChatGPT's concordance with expert Otolaryngologists when posed with high-level questions that require blending rote memorization and critical thinking.Study Design. Cross-sectional survey.Setting. OpenAI's ChatGPT-3.5 Platform.Methods. Two board-certified otolaryngologists (HZ, RS) input 2 sets of 30 text-based questions (open-ended and single-answer multiple-choice) into the ChatGPT-3.5 model. Responses were rated on a scale (correct, partially correct, incorrect) by each Otolaryngologist working simultaneously with the AI model. Interrater agreement percentage was based on binomial distribution for calculating the 95% confidence intervals and performing significance tests. Statistical significance was defined as P < .05 for 2-sided tests.Results. In testing open-ended questions, the ChatGPT model had 56.7% of initially answering questions with complete accuracy, and 86.7% chance of answer with some accuracy (corrected agreement = 80.1%; P < .001). For repeat questions, ChatGPT improved to 73.3% with complete accuracy and 96.7% with some accuracy (corrected agreement = 88.8%; P < .001). For multiple-choice questions, the ChatGPT model performed substantially worse (43.3% correct).Conclusion. ChatGPT currently does not provide reliably accurate responses to sophisticated questions in Otolaryngology. Professional societies must be aware of the potential of this tool and prevent unscrupulous use during test-taking situations and consider guidelines for clinical scenarios. Expert clinical oversight is still necessary for myriad use cases (eg, hallucination).	[Zalzal, Habib G.; Shah, Rahul K.] Childrens Natl Hosp, Div Otolaryngol Head & Neck Surg, Washington, DC USA; [Cheng, Jenhao] Childrens Natl Hosp, Qual, Safety, Analyt, Washington, DC USA; [Zalzal, Habib G.] Childrens Natl Med Ctr, Div Otolaryngol, 111 Michigan Ave NW,Suite 3W-800, Washington, DC 20010 USA	Children's National Health System; Children's National Health System; Children's National Health System	Zalzal, HG (corresponding author), Childrens Natl Med Ctr, Div Otolaryngol, 111 Michigan Ave NW,Suite 3W-800, Washington, DC 20010 USA.	hzalzal@cnmc.org	Cheng, Jacob/JDC-9120-2023	Cheng, Jenhao/0000-0001-8359-2475				Altman DG., 1991, Practical Statistics for Medical Research (Chapman Hall/CRC Texts in Statistical Science), V1st ed; [Anonymous], 2019, Daily ENT Question Bank; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Gwet K. L., 2014, Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters, V4th; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Medenilla A., 2023, PLoS Digital Health, V2; OpenAI, 2023, "ChatGPT," OpenAI; Park I, 2023, AM J OTOLARYNG, V44, DOI 10.1016/j.amjoto.2023.103873	12	8	8	5	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2473-974X		OTO OPEN	OTO Open	OCT	2023	7	4							e94	10.1002/oto2.94	http://dx.doi.org/10.1002/oto2.94			8	Otorhinolaryngology	Emerging Sources Citation Index (ESCI)	Otorhinolaryngology	Z0UE0	38020045	gold			2024-07-03	WOS:001109310800001
J	Pillutla, K; Liu, L; Thickstun, J; Welleck, S; Swayamdipta, S; Zellers, R; Oh, S; Choi, Y; Harchaoui, Z				Pillutla, Krishna; Liu, Lang; Thickstun, John; Welleck, Sean; Swayamdipta, Swabha; Zellers, Rowan; Oh, Sewoong; Choi, Yejin; Harchaoui, Zaid			MAUVE Scores for Generative Models: Theory and Practice	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Generative models; evaluation; divergence frontiers; neural text generation; large language models; f-divergences; statistical estimation	DIVERGENCE ESTIMATION; MISSING MASS; INEQUALITIES	Generative artificial intelligence has made significant strides, producing text indistinguishable from human prose and remarkably photorealistic images. Automatically measuring how close the generated data distribution is to the target distribution is central to diagnosing existing models and developing better ones. We present MAUVE, a family of comparison measures between pairs of distributions such as those encountered in the generative modeling of text or images. These scores are statistical summaries of divergence frontiers capturing two types of errors in generative modeling. We explore three approaches to statistically estimate these scores: vector quantization, non-parametric estimation, and classifier-based estimation. We provide statistical bounds for the vector quantization approach. Empirically, we find that the proposed scores paired with a range of f-divergences and statistical estimation methods can quantify the gaps between the distributions of human written text and those of modern neural language models by correlating with human judgments and identifying known properties of the generated texts. We demonstrate in the vision domain that MAUVE can identify known properties of generated images on par with or better than existing metrics. In conclusion, we present practical recommendations for using MAUVE effectively with language and image modalities.	[Pillutla, Krishna; Welleck, Sean; Oh, Sewoong] Google Res, Mountain View, CA 94043 USA; [Liu, Lang; Harchaoui, Zaid] Univ Washington, Dept Stat, Seattle, WA USA; [Thickstun, John] Stanford Univ, Dept Comp Sci, Stanford, CA USA; [Welleck, Sean; Choi, Yejin] Allen Inst Artificial Intelligence, Seattle, WA USA; [Swayamdipta, Swabha] Univ Southern Calif, Viterbi Sch Engn, Los Angeles, CA USA; [Zellers, Rowan] OpenAI, San Francisco, CA USA; [Oh, Sewoong; Choi, Yejin] Univ Washington, Paul G Allen Sch Comp Sci Engn, Seattle, WA USA	Google Incorporated; University of Washington; University of Washington Seattle; Stanford University; University of Southern California; OpenAI; University of Washington; University of Washington Seattle	Pillutla, K (corresponding author), Google Res, Mountain View, CA 94043 USA.	PILLUTLA@CS.WASHINGTON.EDU; LIU16@UW.EDU; JTHICKSTUN@STANFORD.EDU; WELLECKS@CS.WASHINGTON.EDU; SWABHAS@USC.EDU; ROWANZ@CS.WASHINGTON.EDU; SEWOONG@CS.WASHINGTON.EDU; YEJIN@CS.WASHINGTON.EDU; ZAID@UW.EDU	Pillutla, Krishna/JBJ-3023-2023		NSF [DMS-2023166, DMS-2134012, CCF-2019844]; DARPA MCS program through NIWC Pacific [N66001-19-2-4031]; CIFAR "Learning in Machines & Brains" program, a Qualcomm Innovation Fellowship	NSF(National Science Foundation (NSF)); DARPA MCS program through NIWC Pacific; CIFAR "Learning in Machines & Brains" program, a Qualcomm Innovation Fellowship	Part of this work was done while Zaid Harchaoui was visiting the Simons Institute for the Theory of Computing, and while Krishna Pillutla, Lang Liu, John Thickstun, and Rowan Zellers were at the University of Washington. This work was supported by NSF DMS-2134012, NSF CCF-2019844, NSF DMS-2023166, the DARPA MCS program through NIWC Pacific (N66001-19-2-4031) , the CIFAR "Learning in Machines & Brains" program, a Qualcomm Innovation Fellowship, and faculty research awards.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Alamgir Morteza, 2014, COLT; Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; [Anonymous], 2022, BLOOM: A 176bparameter open-access multilingual language model; [Anonymous], 2004, KERNEL METHODS PATTE; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Basu S., 2021, P ICLR; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Berend D, 2012, STAT PROBABIL LETT, V82, P1102, DOI 10.1016/j.spl.2012.02.014; Biau G, 2021, J MACH LEARN RES, V22, P1; Braess D, 2004, J APPROX THEORY, V128, P187, DOI 10.1016/j.jat.2004.04.010; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bu YH, 2018, IEEE T INFORM THEORY, V64, P2648, DOI 10.1109/TIT.2018.2805844; Caccia Massimo, 2020, P ICLR; Cai HX, 2006, IEEE T INFORM THEORY, V52, P3456, DOI 10.1109/TIT.2006.878182; Cai TT, 2011, J R STAT SOC B, V73, P629, DOI 10.1111/j.1467-9868.2011.00778.x; Celikyilmaz A., 2020, PREPRINT; Chan DV, 2022, Arxiv, DOI arXiv:2209.07518; Cheema F., 2023, P INT C ART INT STAT, P6571; Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128; Clark E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2748; Clark Elizabeth, 2021, P ACL; Clemencon N., 2009, INT C MACH LEARN, P185; Clemençon S, 2010, CONSTR APPROX, V32, P619, DOI 10.1007/s00365-010-9084-9; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Cortes Corinna, 2005, P NEURIPS, V17; Cuturi M., 2013, SINKHORN DISTANCES L; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Devroye L., 1996, PROBABILISTIC THEORY; Djolonga J, 2020, PR MACH LEARN RES, V108, P2550; Eikema Bryan, 2020, P COLING; Falahatgar M, 2017, ADV NEUR IN, V30; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Finlayson Matthew, 2023, Closing the curious case of neural text degeneration; Flach P. A, 2012, Machine learning: the art and science of algorithms that make sense of data, DOI [10.1017/CBO9780511973000, DOI 10.1017/CBO9780511973000]; Gehman S, 2020, M ASS FOR COMPUTATIO; Gehrmann S, 2023, J ARTIF INTELL RES, V77, P103; Gokaslan A., 2019, Openwebtext corpus; GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344; Goodfellow I., 2014, P 28 C NEURAL INFORM, P2672, DOI DOI 10.1145/3422622; Google, 2023, Bard: A Conversational AI Tool by Google; Guan J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9157; Guntuboyina A, 2014, IEEE T INFORM THEORY, V60, P104, DOI 10.1109/TIT.2013.2288674; GYORFI L, 1978, ANN I STAT MATH, V30, P105, DOI 10.1007/BF02480206; Hamalainen Perttu, 2020, arXiv; Hashimoto TB, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1689; Hegde A, 2004, IEEE IJCNN, P105, DOI 10.1109/IJCNN.2004.1379879; Hensel M, 2017, ADV NEUR IN, V30; Hewitt John, 2022, PROC EMNLP FINDINGS; Holtzman A., 2019, INT C LEARNING REPRE; Hu JY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P697; Hunter DR, 2004, ANN STAT, V32, P384; Ingster Y., 2003, NONPARAMETRIC GOODNE; Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1808; Jiang Albert Q., 2023, PREPRINT; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kandasamy K, 2015, ADV NEUR IN, V28; Karpinska M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1265; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T., 2020, ADV NEURAL INFORM PR, V33, p12 104, DOI 10.48550/arXiv.2006.06676; Karras T, 2021, ADV NEUR IN, V34; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kilgour K, 2019, INTERSPEECH, P2350, DOI 10.21437/Interspeech.2019-2219; Kim Pum Jun, 2023, PROC NEURIPS; Kour George, 2022, P EMNLP; KRICHEVSKY RE, 1981, IEEE T INFORM THEORY, V27, P199, DOI 10.1109/TIT.1981.1056331; Kurakin Alexey, 2023, PREPRINT; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Kynkaanniemi Tuomas, 2019, P NEURIPS; Lan Tian, 2022, PREPRINT; Li XL, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P12286; Liang P., 2023, Holistic evaluation of language models; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu Lang, 2021, P NEURIPS; LIU Y., 2019, PREPRINT; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Lopez-Paz D., 2017, INT C LEARNING REPRE; Manning C. D., 2001, Foundations of statistical natural language processing; Marden J. I., 1995, Monographs on Statistics and Applied Probability, V64; Martins PH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4252; Massarelli L, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P223; Mattern Justus, 2022, P EMNLP; McAllester D, 2004, J MACH LEARN RES, V4, P895, DOI 10.1162/1532443041424292; Meinicke P, 2002, ADV NEUR IN, V14, P825; Meister C, 2023, T ASSOC COMPUT LING, V11, P102, DOI 10.1162/tacl_a_00536; Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016; Miettinen, 2012, NONLINEAR MULTIOBJEC; Moon KR, 2014, IEEE INT SYMP INFO, P356, DOI 10.1109/ISIT.2014.6874854; Nguyen XL, 2010, IEEE T INFORM THEORY, V56, P5847, DOI 10.1109/TIT.2010.2068870; Nielsen F., 2013, MATRIX INFORM GEOMET; Noshad M, 2017, IEEE INT SYMP INFO, P903, DOI 10.1109/ISIT.2017.8006659; Novikova Jekaterina, 2017, P EMNLP; OpenAI, 2023, GPT-4 Technical Report; Opitz J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1504; Oquab M., 2023, DINOv2: learning robust visual features without supervision; Orlitsky Alon, 2015, NEURIPS; Papineni K., 2002, P ACL, P311; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pepe MS, 2000, J AM STAT ASSOC, V95, P308, DOI 10.2307/2669554; Pillutla Krishna, 2021, P NEURIPS; Pimentel Tiago, 2023, P ICLR; Poczos Barnabas, 2011, P 27 C UNC ART INT U, P599; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramesh A., 2022, PREPRINT; Rashkin H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4274; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rousu J, 2005, J MACH LEARN RES, V6, P1323; Rubenstein Paul, 2019, PROC ANN C NEURAL IN, P4072; Sablayrolles Alexandre, 2019, P ICLR; Saharia C., 2022, P NEURIPS; Sai AB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485766; Sajjadi MSM, 2018, ADV NEUR IN, V31; Salimans T, 2016, ADV NEUR IN, V29; Sauer Axel, 2022, SIGGRAPH22 Conference Proceeding: Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, DOI 10.1145/3528233.3530738; Schreuder N., 2021, P MACHINE LEARNING R, P1051; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Semeniuta Stanislau, 2018, PREPRINT; Sharoff S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2453; Shimanaka Hiroki, 2018, P 3 C MACHINE TRANSL, P751, DOI DOI 10.18653/V1/W18-6456; Shimorina A, 2022, PROCEEDINGS OF THE 2ND WORKSHOP ON HUMAN EVALUATION OF NLP SYSTEMS (HUMEVAL 2022), P54; Silva J, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-7, P2021, DOI 10.1109/ISIT.2007.4557518; Silva J, 2010, J STAT PLAN INFER, V140, P3180, DOI 10.1016/j.jspi.2010.04.011; Song Yang, 2021, P ICLR; Sreekumar S, 2022, J MACH LEARN RES, V23; Stein George, 2023, P NEURIPS 2023; Su Y., 2022, PREPRINT; Su Yixuan, 2022, P NEURIPS; Sugiyama M, 2012, DENSITY RATIO ESTIMATION IN MACHINE LEARNING, P1, DOI 10.1017/CBO9781139035613; Sun Yu, 2021, PREPRINT; Sutherland Danica J, 2018, INT C LEARN REPR; Tao CY, 2018, AAAI CONF ARTIF INTE, P722; Touvron H., 2023, PREPRINT; Unterthiner Thomas, 2018, PREPRINT; Van Hulle MM, 1999, NEURAL NETWORKS, V12, P803, DOI 10.1016/S0893-6080(99)00041-6; Vaswani A, 2017, ADV NEUR IN, V30; Verdú S, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080720; Verine Alexandre, 2023, P NEURIPS; Villani C., 2003, Graduate Studies in Mathematics, DOI DOI 10.1090/GSM/058; Wang Q, 2005, IEEE T INFORM THEORY, V51, P3064, DOI 10.1109/TIT.2005.853314; Wang Yu-Xiong, 2017, PROC NEURIPS; Welleck S., 2020, 8 INT C LEARN REPR I, P1; Welleck S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5553; Yang Zonghan, 2023, P ICLR; Yanjun Han, 2020, IEEE Journal on Selected Areas in Information Theory, V1, P814, DOI 10.1109/JSAIT.2020.3041036; Yu Lili, 2023, PREPRINT; Yue X, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1321; Zellers Rowan, 2019, P NEURIPS; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang T., 2020, INT C LEARNING REPRE; Zhang ZY, 2014, NEURAL COMPUT, V26, P2570, DOI 10.1162/NECO_a_00646; Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563	152	0	0	2	2	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.		2023	24								356					92	Automation & Control Systems; Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science	DD9V8					2024-07-03	WOS:001130219900001
J	Qin, HT; Ji, GP; Khan, S; Fan, DP; Khan, FS; Van Gool, L				Qin, Haotong; Ji, Ge-Peng; Khan, Salman; Fan, Deng-Ping; Khan, Fahad Shahbaz; Van Gool, Luc			How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges	MACHINE INTELLIGENCE RESEARCH			English	News Item						Google Bard; multi-modal understanding; visual comprehension; large language models; conversational AI; chatbot		Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs to be bridged in future developments. We expect that this empirical study will prove valuable in advancing future models, leading to enhanced capabilities in comprehending and interpreting fine-grained visual data. Our project is released on https://github.com/htqin/GoogleBard-VisUnderstand.	[Qin, Haotong; Fan, Deng-Ping; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab CVL, CH-8001 Zurich, Switzerland; [Ji, Ge-Peng] Australian Natl Univ, Coll Engn Comp & Cybernet, Canberra, ACT 8105, Australia; [Khan, Salman; Khan, Fahad Shahbaz] Mohamed bin Zayed Univ Artificial Intelligence, Abu Dhabi 999041, U Arab Emirates	Swiss Federal Institutes of Technology Domain; ETH Zurich; Australian National University; Mohamed Bin Zayed University of Artificial Intelligence	Fan, DP (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab CVL, CH-8001 Zurich, Switzerland.	qinhaotong@gmail.com; gepengai.ji@gmail.com; salman.khan@mbzuai.ac.ae; dengpfan@gmail.com; fahad.khan@mbzuai.ac.ae; vangool@vision.ee.ethz.ch	Qin, Haotong/AGP-1834-2022; Fan, DengPing/AAT-6679-2020; Khan, Salman Hameed/M-4834-2016	Qin, Haotong/0000-0001-7391-7539; Fan, DengPing/0000-0002-5245-7518; Khan, Salman Hameed/0000-0002-9502-1749; Van Gool, Luc/0000-0002-3445-5711				A S., 2019, VQA MODELS CAN READ, P8309; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, Visual Intelligence, V1; [Anonymous], 2022, Sensors, V22; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Fan DP, 2022, IEEE T PATTERN ANAL, V44, P6024, DOI 10.1109/TPAMI.2021.3085766; Hendrycks D., 2019, BENCHMARKING NEURAL; Ji GP, 2022, MACH INTELL RES, V19, P531, DOI 10.1007/s11633-022-1371-y; LLaVA, 2023, LLaVA-Bench; Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782; Maji S, 2013, Arxiv, DOI arXiv:1306.5151; Microsoft, 2023, Bing chat enterprise announced, multimodal visual search rolling out to bing chat; Sun GL, 2023, PROC CVPR IEEE, P13791, DOI 10.1109/CVPR52729.2023.01325; T Y L., 2014, MICROSOFT COCO COMMO, P740; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; X C Cao., 2019, SINGLE IMAGE DERAINI, P3833	16	1	1	5	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2731-538X	2731-5398		MACH INTELL RES	Mach. Intell. Res.	OCT	2023	20	5					605	613		10.1007/s11633-023-1469-x	http://dx.doi.org/10.1007/s11633-023-1469-x			9	Automation & Control Systems; Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Automation & Control Systems; Computer Science	FZ3Y3					2024-07-03	WOS:001149649700001
J	Wang, ZY; Shi, YC; Wang, YT; Yao, YC; Yan, K; Wang, YH; Ji, L; Xu, XH; Yu, C				Wang, Zeyu; Shi, Yuanchun; Wang, Yuntao; Yao, Yuchen; Yan, Kun; Wang, Yuhan; Ji, Lei; Xu, Xuhai; Yu, Chun			G-VOILA: Gaze-Facilitated Information Querying in Daily Scenarios	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						information retrieval; gaze tracking; smart glasses; large language models; information query	RETRIEVAL	Modern information querying systems are progressively incorporating multimodal inputs like vision and audio. However, the integration of gaze - a modality deeply linked to user intent and increasingly accessible via gaze-tracking wearables remains underexplored. This paper introduces a novel gaze-facilitated information querying paradigm, named G-VOILA, which synergizes users' gaze, visual field, and voice-based natural language queries to facilitate a more intuitive querying process. In a user-enactment study involving 21 participants in 3 daily scenarios (p = 21, scene = 3), we revealed the ambiguity in users' query language and a gaze-voice coordination pattern in users' natural query behaviors with G-VOILA. Based on the quantitative and qualitative findings, we developed a design framework for the G-VOILA paradigm, which effectively integrates the gaze data with the in-situ querying context. Then we implemented a G-VOILA proof-of-concept using cutting-edge deep learning techniques. A follow-up user study (p = 16, scene = 2) demonstrates its effectiveness by achieving both higher objective score and subjective score, compared to a baseline without gaze data. We further conducted interviews and provided insights for future gaze-facilitated information querying systems.	[Wang, Zeyu; Shi, Yuanchun; Wang, Yuntao] Tsinghua Univ, Dept Comp Sci & Technol, Key Lab Pervas Comp, Minist Educ, Beijing, Peoples R China; [Shi, Yuanchun] Qinghai Univ, Intelligent Comp & Applicat Lab Qinghai Prov, Xining, Qinghai, Peoples R China; [Yao, Yuchen; Yu, Chun] Tsinghua Univ, Beijing, Peoples R China; [Yan, Kun; Ji, Lei] Microsoft Res Asia, Beijing, Peoples R China; [Yan, Kun] Beihang Univ, SKLSDE Lab, Beijing, Peoples R China; [Wang, Yuhan] Beijing Univ Posts & Telecommun, Beijing, Peoples R China; [Xu, Xuhai] MIT, Cambridge, MA USA	Tsinghua University; Qinghai University; Tsinghua University; Microsoft Research Asia; Microsoft; Beihang University; Beijing University of Posts & Telecommunications; Massachusetts Institute of Technology (MIT)	Shi, YC; Wang, YT (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Key Lab Pervas Comp, Minist Educ, Beijing, Peoples R China.; Shi, YC (corresponding author), Qinghai Univ, Intelligent Comp & Applicat Lab Qinghai Prov, Xining, Qinghai, Peoples R China.	wang-zy23@mails.tsinghua.edu.cn; shiyc@tsinghua.edu.cn; yuntaowang@tsinghua.edu.cn; yaoyc19@mails.tsinghua.edu.cn; kunyan@buaa.edu.cn; yigetianluoturanjiu@gmail.com; leiji@microsoft.com; orson.xuhai.xu@gmail.com; chunyu@tsinghua.edu.cn		Yu, Chun/0000-0003-2591-7993; Xu, Xuhai/0000-0001-5930-3899	Natural Science Foundation of China (NSFC) [62132010]; Young Elite Scientists Sponsorship Program by CAST [2021QNRC001]; Tsinghua University Initiative Scientific Research Program; Beijing Key Lab of Networked Multimedia; Institute for Artificial Intelligence; Tsinghua University; Undergraduate/Graduate Education Innovation Grants; Beijing National Research Center for Information Science and Technology (BNRist)	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Young Elite Scientists Sponsorship Program by CAST; Tsinghua University Initiative Scientific Research Program; Beijing Key Lab of Networked Multimedia; Institute for Artificial Intelligence; Tsinghua University; Undergraduate/Graduate Education Innovation Grants; Beijing National Research Center for Information Science and Technology (BNRist)	This work is supported by the Natural Science Foundation of China (NSFC) under Grant No. 62132010, Young Elite Scientists Sponsorship Program by CAST under Grant No.2021QNRC001, Tsinghua University Initiative Scientific Research Program, Beijing Key Lab of Networked Multimedia, Institute for Artificial Intelligence, Tsinghua University, Undergraduate/Graduate Education Innovation Grants, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist).	Admoni Henny, 2016, 2016 AAAI FALL S SER; Ajanki A., 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), P95, DOI 10.1109/MLSP.2010.5589228; Ajanki A, 2009, USER MODEL USER-ADAP, V19, P307, DOI 10.1007/s11257-009-9066-4; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Alibaba, 2023, Tongyi Qianwen; Allan James., 2012, SIGIR FORUM, V46, P2; Andrist S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2571, DOI 10.1145/3025453.3026033; Awadalla Anas, 2023, Zenodo; Baeza-Yates R., 1999, Modern information retrieval, V463; Baidu, 2023, ERNIE Bot: Enhanced Representation through Knowledge Integration; bing, Microsoft Bing; Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503; Büschel W, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P171, DOI 10.1145/3176349.3176384; Bulling A, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P41; Buschel Wolfgang, 2018, 2018 CHI C HUM FACT, P1; Chen J, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P743, DOI 10.1145/3442381.3450127; Chen KQ, 2023, Arxiv, DOI arXiv:2306.15195; Chen Liangyu, 2023, ICLR 2023 WORKSH MAT; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cho J, 2021, PR MACH LEARN RES, V139; D'Angelo S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2492, DOI 10.1145/2858036.2858499; Dick Ellysse, 2021, The promise of immersive learning: Augmented and virtual reality's potential in education; Ding Jiexin, 2023, 2023 CHI C HUM FACT, DOI [10.1145/3544549, DOI 10.1145/3544549]; Doshi A, 2009, IEEE INT VEH SYM, P887, DOI 10.1109/IVS.2009.5164397; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Ellenberg Mats Ole, 2023, 2023 CHI C HUM FACT, DOI 10.1145/; Gao P, 2023, Arxiv, DOI arXiv:2304.15010; Gao Ziqi, 2023, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V7, P1; Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07; Huang CM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01049; Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710; Jin WJ, 2023, Arxiv, DOI arXiv:2305.14676; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Land MF, 2006, PROG RETIN EYE RES, V25, P296, DOI 10.1016/j.preteyeres.2006.01.002; Li B, 2023, Arxiv, DOI arXiv:2305.03726; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li Mingyang, 2021, Intelligent Equipment, Robots, and Vehicles, DOI [10.1007/978-981-16-7213-28, DOI 10.1007/978-981-16-7213-28]; Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu Xiaoyi, 2023, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V7, P1; Lou JX, 2022, NEUROCOMPUTING, V494, P455, DOI 10.1016/j.neucom.2022.04.080; Louradour Jerome, 2023, Whisper-Timestamped; Minderer M, 2022, Arxiv, DOI arXiv:2205.06230; Newn J, 2019, LECT NOTES COMPUT SC, V11747, P255, DOI 10.1007/978-3-030-29384-0_17; OpenAI, 2023, Introducing chatgpt; OpenAI, 2023, GPT-4 Technical Report; Peng ZL, 2023, Arxiv, DOI [arXiv:2306.14824, 10.48550/arXiv.2306.14824]; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perkhofer L, 2019, L N INF SYST ORGAN, V29, P73, DOI 10.1007/978-3-030-01087-4_9; Pfeuffer K, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P373, DOI 10.1145/2807442.2807460; Piening R, 2021, LECT NOTES COMPUT SC, V12932, P544, DOI 10.1007/978-3-030-85623-6_32; Plopski A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491207; Pont-Tuset Jordi, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P647, DOI 10.1007/978-3-030-58558-7_38; Rhodes BJ, 2000, IBM SYST J, V39, P685, DOI 10.1147/sj.393.0685; Sattar H, 2020, NEUROCOMPUTING, V387, P369, DOI 10.1016/j.neucom.2020.01.028; SenseTime, 2023, Sense Nova; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Su YK, 2024, IEEE T MULTIMEDIA, V26, P313, DOI 10.1109/TMM.2023.3264883; Surís D, 2023, Arxiv, DOI [arXiv:2303.08128, DOI 10.48550/ARXIV.2303.08128(2023).2303.08128]; Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tonsen M, 2020, Arxiv, DOI [arXiv:2009.00508, 10.48550/arXiv.2009.00508]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang P, 2022, 39 INT C MACHINE LEA; Wang YL, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581402; Wang YT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517698; Wei YS, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581042; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Xu XH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581500; Xu XH, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3381011; Yan K, 2023, Arxiv, DOI arXiv:2401.09454; Yan K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2014; Yan Yukang, 2023, IEEE Transactions on Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., V8; Yang FL, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1613, DOI 10.1145/3488560.3502194; Yang ZY, 2023, Arxiv, DOI [arXiv:2303.11381, 10.48550/arXiv.2303.11381]; Yao Y, 2022, Arxiv, DOI arXiv:2205.11169; Zeng Belinda, 2022, Go beyond the search box: Introducing multisearch; Zhao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P455, DOI 10.1007/978-3-030-58610-2_27; Zhong YW, 2022, PROC CVPR IEEE, P16772, DOI 10.1109/CVPR52688.2022.01629; Zhou Q, 2023, Arxiv, DOI arXiv:2308.02299; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592; Zou Xueyan, 2022, arXiv	83	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAY	2024	8	2							78	10.1145/3659623	http://dx.doi.org/10.1145/3659623			33	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	RR2F4		hybrid, Green Submitted			2024-07-03	WOS:001229316000037
J	Kolar, V; Chmelová, E; Bílková, M; Borovec, J; Carreira, BM; Cerny, M; Ditrich, T; Horká, P; Hrivniak, L; Hruby, F; Jan, JR; Landeira-Dabarca, A; Lepsová-Skácelová, O; Musilová, Z; Otáhalová, S; Poláková, M; Polásková, V; Sacherová, V; Spacek, J; Sroka, P; Vebrová, L; Boukal, DS; Tropek, R				Kolar, Vojtech; Chmelova, Eliska; Bilkova, Martina; Borovec, Jakub; Carreira, Bruno M.; Cerny, Martin; Ditrich, Tomas; Horka, Petra; Hrivniak, Lubos; Hruby, Frantisek; Jan, Jiri; Landeira-Dabarca, Andrea; Lepsova-Skacelova, Olga; Musilova, Zuzana; Otahalova, Sarka; Polakova, Martina; Polaskova, Vendula; Sacherova, Veronika; Spacek, Jan; Sroka, Pavel; Vebrova, Lucie; Boukal, David S.; Tropek, Robert			Muddying the unexplored post-industrial waters: Biodiversity and conservation potential of freshwater habitats in fly ash sedimentation lagoons	SCIENCE OF THE TOTAL ENVIRONMENT			English	Article						Aquatic communities; Biodiversity conservation; Energetic industry; Environmental pollution; Restoration ecology; Post-industrial sites	COAL COMBUSTION RESIDUES; SPONTANEOUS SUCCESSION; AQUATIC DISPOSAL; TRACE-ELEMENTS; HEAVY-METALS; RESTORATION; TOXICITY; BIOACCUMULATION; STREAM; DRAGONFLIES	Deposits of fly ash and other coal combustion wastes are common remnants of the energy industry. Despite their environmental risks from heavy metals and trace elements, they have been revealed as refuges for threatened terrestrial biodiversity. Surprisingly, freshwater biodiversity of fly ash sedimentation lagoons remains unknown despite such lack of knowledge strongly limits the efficient restoration of fly ash deposits. We bring the first comprehensive survey of freshwater biodiversity, including nekton, benthos, zooplankton, phytoplankton, and macrophytes, in fly ash lagoons across industrial regions of the Czech Republic. To assess their conservation potential, we compared their biodiversity with abandoned post-mining ponds, the known strongholds of en-dangered aquatic species in the region with a shortage of natural ponds. Of 28 recorded threatened species, 15 occurred in the studied fly ash lagoons, some of which were less abundant or even absent in the post-mining ponds. These are often species of nutrient-poor, fishless waters with rich vegetation, although some are speci-alised extremophiles. Species richness and conservation value of most groups in the fly ash lagoons did not significantly differ from the post-mining ponds, except for species richness of benthos, zooplankton, and mac-rophytes, which were slightly lower in the fly ash lagoons. Although the concentrations of some heavy metals (mainly Se, V, and As) were significantly higher in the fly ash lagoons, they did not significantly affect species richness or conservation value of the local communities. The differences in species composition therefore does not seem to be caused by water chemistry. Altogether, we have shown that fly ash lagoons are refuges for threatened aquatic species, and we thus suggest maintaining water bodies during site restoration after the cessation of fly ash deposition. Based on our analyses of environmental variables, we discuss suitable restoration practices that efficiently combine biodiversity protection and environmental risk reduction.	[Kolar, Vojtech; Chmelova, Eliska; Borovec, Jakub; Carreira, Bruno M.; Hrivniak, Lubos; Jan, Jiri; Landeira-Dabarca, Andrea; Otahalova, Sarka; Sroka, Pavel; Boukal, David S.; Tropek, Robert] Czech Acad Sci, Biol Ctr, Branisovska 1160-31, Ceske Budejovice 37005, Czech Republic; [Kolar, Vojtech; Borovec, Jakub; Carreira, Bruno M.; Hruby, Frantisek; Jan, Jiri; Landeira-Dabarca, Andrea; Lepsova-Skacelova, Olga; Polakova, Martina; Vebrova, Lucie; Boukal, David S.] Univ South Bohemia, Fac Sci, Dept Ecosyst Biol & Bot, Branisovska 1760, Ceske Budejovice 37005, Czech Republic; [Chmelova, Eliska; Cerny, Martin; Sacherova, Veronika; Tropek, Robert] Charles Univ Prague, Fac Sci, Dept Ecol, Vinicna 7, Prague 12844, Czech Republic; [Bilkova, Martina; Carreira, Bruno M.; Polakova, Martina; Polaskova, Vendula] Masaryk Univ, Fac Sci, Dept Bot & Zool, Kotlarska 2, Brno 61137, Czech Republic; [Carreira, Bruno M.] Univ Lisbon, Fac Sci, cE3c Ctr Ecol Evolut & Environm Changes, Fac Sci, Edificio C2, P-1749016 Lisbon, Portugal; [Carreira, Bruno M.] Univ Lisbon, Fac Sci, Global Change & Sustainabil Inst, Edificio C2, P-1749016 Lisbon, Portugal; [Ditrich, Tomas] Univ South Bohemia, Fac Educ, Dept Biol, Jeronymova 10, Ceske Budejovice 37112, Czech Republic; [Horka, Petra] Charles Univ Prague, Inst Environm Studies, Fac Sci, Benatska 2, Prague 12801, Czech Republic; [Musilova, Zuzana] Charles Univ Prague, Fac Sci, Dept Zool, Vinicna 7, Prague 12844, Czech Republic; [Spacek, Jan] Povodi Labe State Enterprise, Vita Nejedleho 951-8, Hradec Kralove 50003, Czech Republic	Czech Academy of Sciences; Biology Centre of the Czech Academy of Sciences; University of South Bohemia Ceske Budejovice; Charles University Prague; Masaryk University Brno; Universidade de Lisboa; Universidade de Lisboa; University of South Bohemia Ceske Budejovice; Charles University Prague; Charles University Prague	Tropek, R (corresponding author), Charles Univ Prague, Fac Sci, Dept Ecol, Vinicna 7, Prague 12844, Czech Republic.	robert.tropek@gmail.com	Ditrich, Tomáš/B-2747-2013; Tropek, Robert/G-6564-2014; Borovec, Jakub/AAP-3377-2021; Horka, Petra/D-6591-2015; Černý, Martin/ABA-2513-2021; Musilova, Zuzana/S-2899-2017; Boukal, David/H-4762-2014; Carreira, Bruno/L-8332-2013; Jan, Jiri/F-2172-2017	Ditrich, Tomáš/0000-0002-3179-7716; Tropek, Robert/0000-0001-7499-6259; Borovec, Jakub/0000-0002-1259-8703; Horka, Petra/0000-0002-5407-7594; Černý, Martin/0000-0002-0619-4737; Boukal, David/0000-0001-8181-7458; Landeira-Dabarca, Andrea/0000-0001-8878-8223; Carreira, Bruno/0000-0002-5910-4619; Jan, Jiri/0000-0002-2264-0418	Czech Science Foundation [18-15927S]; FCT [CEECIND/02435/2018]; Czech Academy of Sciences (Strategy AV 21: Land Conservation and Restoration)	Czech Science Foundation(Grant Agency of the Czech Republic); FCT(Fundacao para a Ciencia e a Tecnologia (FCT)); Czech Academy of Sciences (Strategy AV 21: Land Conservation and Restoration)	We are grateful to Pavel Potocky for his help in the field; to Lucie Plestilova and Michaela Tumova for sorting a large part of the invertebrate material to the focal taxonomic groups; to Martin Waldhauser for the identification of Zygoptera; to Lenka Prochazkova for the identifi-cation of dinoflagellates; to Josef Juran & nbsp;for the identification of euglenophytes; and to Petra Pitelkova for the identification of desmids; and to the owners and administrators of the studied localities for their kind approval to access them. The manuscript has been proofread using two large language models (Paperpal and InstaText). Fish collection for this study was permitted by the Czech Fishing Association, as officially authorized by the Ministry of Agriculture of the Czech Republic. Permission to handle the animals was issued by the Ministry of Agriculture of the Czech Republic (CZ03061) to ZM. Our research was funded by the Czech Science Foundation (18-15927S), B.M.C. was supported by a contract awarded by FCT (CEECIND/02435/2018), and VK was supported by the Czech Academy of Sciences (Strategy AV 21: Land Conservation and Restoration).	Ali H, 2019, J CHEM-NY, V2019, DOI 10.1155/2019/6730305; Badry A, 2019, SCI TOTAL ENVIRON, V676, P746, DOI 10.1016/j.scitotenv.2019.04.217; Besser J.M, 2007, Toxicity of Metals in Water and Sediment to Aquatic Biota, P14; Bobrek R, 2020, EUR J ENVIRON SCI, V10, P107, DOI 10.14712/23361964.2020.12; Bogusch P, 2016, BIODIVERS CONSERV, V25, P827, DOI 10.1007/s10531-016-1070-5; Borm PJA, 1997, ANN OCCUP HYG, V41, P659, DOI 10.1093/annhyg/41.6.659; Brooks ME, 2017, R J, V9, P378, DOI 10.32614/RJ-2017-066; Buckland-Nicks A, 2014, ENVIRON TOXICOL CHEM, V33, P2047, DOI 10.1002/etc.2653; Carreira B.M., 2023, SCI TOTAL ENVIRON; Cempel M, 2006, POL J ENVIRON STUD, V15, P375; Chmelová E, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131810385; Chytry M, 2019, ECOL INDIC, V106, DOI 10.1016/j.ecolind.2019.105446; CLEMENTS WH, 1994, J N AM BENTHOL SOC, V13, P30, DOI 10.2307/1467263; Courtney LA, 2002, FRESHWATER BIOL, V47, P1766, DOI 10.1046/j.1365-2427.2002.00896.x; Ditrich T, 2017, AQUAT INSECT, V38, P171, DOI 10.1080/01650424.2017.1359305; Doig LE, 2015, INTEGR ENVIRON ASSES, V11, P490, DOI 10.1002/ieam.1616; Dolny A, 2012, BIOL CONSERV, V145, P109, DOI 10.1016/j.biocon.2011.10.020; Eeva T, 2004, ENVIRON POLLUT, V132, P533, DOI 10.1016/j.envpol.2004.05.004; Farkac J., 2005, AGENTURA OCHRANY PRI, P1; Gillet S, 2003, APPL SOIL ECOL, V22, P127, DOI 10.1016/S0929-1393(02)00134-8; Gollakota ARK, 2019, SCI TOTAL ENVIRON, V672, P951, DOI 10.1016/j.scitotenv.2019.03.337; Han DM, 2021, SCI TOTAL ENVIRON, V798, DOI 10.1016/j.scitotenv.2021.149116; Harabis F, 2013, ECOL ENG, V55, P51, DOI 10.1016/j.ecoleng.2013.02.007; Hartig Florian, 2022, CRAN; Haynes RJ, 2009, J ENVIRON MANAGE, V90, P43, DOI 10.1016/j.jenvman.2008.07.003; Heikens A, 2001, ENVIRON POLLUT, V113, P385, DOI 10.1016/S0269-7491(00)00179-2; Hejda R, 2017, Invertebrates. Priroda, V36, P1; Horvat T, 2007, SCI TOTAL ENVIRON, V384, P229, DOI 10.1016/j.scitotenv.2007.06.007; Izquierdo M, 2012, INT J COAL GEOL, V94, P54, DOI 10.1016/j.coal.2011.10.006; Jankowski J, 2006, FUEL, V85, P243, DOI 10.1016/j.fuel.2005.05.028; Klecka J, 2011, ECOL INDIC, V11, P500, DOI 10.1016/j.ecolind.2010.07.005; Kolar V, 2021, ECOL ENG, V173, DOI 10.1016/j.ecoleng.2021.106440; Kolar V, 2021, J APPL ECOL, V58, P1921, DOI 10.1111/1365-2664.13956; Kolar V, 2020, INSECT CONSERV DIVER, V13, P480, DOI 10.1111/icad.12433; Kolár V, 2017, ECOL ENG, V99, P310, DOI 10.1016/j.ecoleng.2016.11.042; Kopácek J, 2001, COMMUN SOIL SCI PLAN, V32, P1431, DOI 10.1081/CSS-100104203; Kopp J., 2012, RYBNIKY CESKE REPUBL; Liess M, 2017, ENVIRON POLLUT, V227, P505, DOI 10.1016/j.envpol.2017.05.017; Poláková M, 2022, RESTOR ECOL, V30, DOI 10.1111/rec.13679; Prach K, 2008, RESTOR ECOL, V16, P363, DOI 10.1111/j.1526-100X.2008.00412.x; R Core Team, 2023, R: A Language and Environment for Statistical Computing; RAUSCH H, 1993, SCI TOTAL ENVIRON, V130, P317, DOI 10.1016/0048-9697(93)90086-L; Rehounková K, 2016, ENVIRON SCI POLLUT R, V23, P13745, DOI 10.1007/s11356-016-6585-5; Reid AJ, 2019, BIOL REV, V94, P849, DOI 10.1111/brv.12480; Rodwell J.S., 2013, REP DG ENV EUR COMM, P78; Rowe CL, 2014, SCI TOTAL ENVIRON, V485, P490, DOI 10.1016/j.scitotenv.2014.03.119; Rowe CL, 2002, ENVIRON MONIT ASSESS, V80, P207, DOI 10.1023/A:1021127120575; Sherrard RM, 2015, INTEGR ENVIRON ASSES, V11, P5, DOI 10.1002/ieam.1587; Silva LFO, 2011, ENVIRON MONIT ASSESS, V174, P187, DOI 10.1007/s10661-010-1449-9; Sroka P, 2022, BIODIVERS DATA J, V10, DOI 10.3897/BDJ.10.e90950; Stendera S, 2012, HYDROBIOLOGIA, V696, P1, DOI 10.1007/s10750-012-1183-0; Sushil S, 2006, FUEL, V85, P2676, DOI 10.1016/j.fuel.2006.04.031; ter Braak C.J., 2012, CANOCO reference manual and CanoDraw for Windows user's guide: Software for Canonical community ordination (version 4.5); Tichanek F, 2015, J INSECT CONSERV, V19, P975, DOI 10.1007/s10841-015-9814-1; Tropek R., 2015, ECOLOGICAL RESTORATI, P158; Tropek R, 2017, POL J ECOL, V65, P385, DOI 10.3161/15052249PJE2017.65.3.006; Tropek R, 2016, ENVIRON SCI POLLUT R, V23, P13653, DOI 10.1007/s11356-015-4382-1; Tropek R, 2013, BIOL CONSERV, V162, P60, DOI 10.1016/j.biocon.2013.03.027; Tropek R, 2010, J APPL ECOL, V47, P139, DOI 10.1111/j.1365-2664.2009.01746.x; Van Straalen N.M., 1994, PROC SECT EXP APPL E; Vojar J, 2016, ECOL ENG, V90, P278, DOI 10.1016/j.ecoleng.2016.01.028; Worms I, 2006, BIOCHIMIE, V88, P1721, DOI 10.1016/j.biochi.2006.09.008; Zvereva E, 2003, COMP BIOCHEM PHYS C, V135, P383, DOI 10.1016/S1532-0456(03)00115-7	63	1	1	8	19	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0048-9697	1879-1026		SCI TOTAL ENVIRON	Sci. Total Environ.	NOV 20	2023	900								165803	10.1016/j.scitotenv.2023.165803	http://dx.doi.org/10.1016/j.scitotenv.2023.165803		JUL 2023	10	Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology	P6SU9	37499824				2024-07-03	WOS:001051962900001
J	Doo, FX; Parekh, VS; Kanhere, A; Savani, D; Tejani, AS; Sapkota, A; Yi, PH				Doo, Florence X.; Parekh, Vishwa S.; Kanhere, Adway; Savani, Dharmam; Tejani, Ali S.; Sapkota, Amir; Yi, Paul H.			Evaluation of Climate-Aware Metrics Tools for Radiology Informatics and Artificial Intelligence: Toward a Potential Radiology Ecolabel	JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY			English	Article						Climate change; sustainability; artificial intelligence; large language models; life cycle assessment tools; ecolabel		Radiology is a major contributor to health care's impact on climate change, in part due to its reliance on energy -intensive equipment as well as its growing technological reliance. Delivering modern patient care requires a robust informatics team to move images from the imaging equipment to the workstations and the health care system. Radiology informatics is the field that manages medical imaging IT. This involves the acquisition, storage, retrieval, and use of imaging information in health care to improve access and quality, which includes PACS, cloud services, and artificial intelligence. However, the electricity consumption of computing and the life cycle of various computer components expands the carbon footprint of health care. The authors provide a general framework to understand the environmental impact of clinical radiology informatics, which includes using the international Greenhouse Gas Protocol to draft a definition of scopes of emissions pertinent to radiology informatics, as well as exploring existing tools to measure and account for these emissions. A novel standard ecolabel for radiology informatics tools, such as the Energy Star label for consumer devices or Leadership in Energy and Environmental Design certification for buildings, should be developed to promote awareness and guide radiologists and radiology informatics leaders in making environmentally conscious decisions for their clinical practice. At this critical climate juncture, the radiology community has a unique and pressing obligation to consider our shared environmental responsibility in innovating clinical technology for patient care.	[Doo, Florence X.; Parekh, Vishwa S.; Kanhere, Adway; Savani, Dharmam; Yi, Paul H.] Univ Maryland, Univ Maryland Med Intelligent Imaging UM2ii Ctr, Dept Radiol & Nucl Med, Baltimore, MD USA; [Tejani, Ali S.] Univ Texas Southwestern Med Ctr, Dallas, TX USA; [Tejani, Ali S.] Sect AI Subcomm, Dallas, TX USA; [Sapkota, Amir] Univ Maryland, Sch Publ Hlth, Dept Epidemiol & Biostat, College Pk, MD USA; [Yi, Paul H.] Soc Imaging Informat Med, Program Planning Comm, Dallas, TX USA; [Doo, Florence X.] Dept Radiol, 22 S Greene St, Baltimore, MD 21201 USA	University System of Maryland; University of Maryland Baltimore; University of Texas System; University of Texas Southwestern Medical Center Dallas; University System of Maryland; University of Maryland College Park	Doo, FX (corresponding author), Dept Radiol, 22 S Greene St, Baltimore, MD 21201 USA.	fdoo@som.umaryland.edu	; Doo, Florence Xini/Q-6640-2018	Sapkota, Amir/0000-0001-5978-2543; Doo, Florence Xini/0000-0001-6519-5222				[Anonymous], 2022, GHG Inventory Development Process and Guidance; [Anonymous], 2010, US GREEN BUILDING CO; [Anonymous], 2022, Carbon-Aware SDK; Bashir Noman, 2023, P 2 WORKSHOP SUSTAIN; Buchanan W, 2023, White paper: carbon-aware computing; cloudcarbonfootprint, Cloud Carbon Footprint-an open source tool to measure and analyze cloud carbon emissions; Corio AP, 5 years of 100% renewable energy, and targeting 100% CFE; Dhar P, 2020, NAT MACH INTELL, V2, P423, DOI 10.1038/s42256-020-0219-9; Dodge Jesse, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1877, DOI 10.1145/3531146.3533234; Doo FX, 2024, J Am Coll Radiol; Energy star, About us; Anthony LFW, 2020, Arxiv, DOI arXiv:2007.03051; Freitag C, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100340; ftc, How to use the EnergyGuide label to shop for home appliances; github, Introduction-Scaphandre documentation; github, CodeCarbon documentation; Green Software Foundation, Awesome green software; Green Software Foundation, Software carbon intensity standard; Greenpeace International, Clicking clean; Gupta U, 2022, CONF PROC INT SYMP C, P784, DOI 10.1145/3470496.3527408; Hilty L.M., 2017, Opportunities and Risks of Digitalization for Climate Protection in Switzerland; huggingface, Meta Llama-2 7B $ Hugging Face; Jay M, 2023, 2023 IEEE/ACM 23RD INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING, CCGRID, P106, DOI 10.1109/CCGRID57682.2023.00020; Joint Research Centre (European Commission), 2019, Brief on the use of life cycle assessment (LCA) to evaluate environmental impacts of the bioeconomy; Kim YG, 2023, Arxiv, DOI arXiv:2304.00404; Koomey J, 2021, JOULE, V5, P1625, DOI 10.1016/j.joule.2021.05.007; Lacoste A, 2019, Arxiv, DOI [arXiv:1910.09700, 10.48550/arXiv.1910.09700]; Lannelongue L, Green Algorithms 4 HPC; Li PF, 2023, Arxiv, DOI arXiv:2304.03271; Lövehagen N, 2023, RENEW SUST ENERG REV, V183, DOI 10.1016/j.rser.2023.113422; Luccioni A. S., 2022, arXiv, DOI 10.48550/ARXIV.2211.02001; Narasimhan A., White paper: a new approach for scope 3 emissions transparency; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714; PowerAPI, 2019, About Us; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Romanello M, 2021, LANCET, V398, P1619, DOI 10.1016/S0140-6736(21)01787-6; Schaubroeck T, 2023, Front Sustain, V4; Schaubroeck T, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13137386; Schoen J, 2021, J AM COLL RADIOL, V18, P1041, DOI 10.1016/j.jacr.2021.02.009; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Singh H, 2022, NEW ENGL J MED, V387, P2469, DOI 10.1056/NEJMsb2210022; Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693; Tarara A, Green Metrics Tool docs; Teehan P, 2013, ENVIRON SCI TECHNOL, V47, P3997, DOI 10.1021/es303012r; US Environmental Protection Agency, Framework for the assessment of environmental performance standards and ecolabels for federal purchasing; US Environmental Protection Agency, EPA 430-R-21-003; World Resources Institute, Corporate value chain (scope 3) standard: GHG Protocol; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zoie RC, 2017, 2017 5 INT S ELECT E	50	1	1	1	1	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	1546-1440	1558-349X		J AM COLL RADIOL	J. Am. Coll. Radiol.	FEB	2024	21	2					239	247		10.1016/j.jacr.2023.11.019	http://dx.doi.org/10.1016/j.jacr.2023.11.019		FEB 2024	9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	IZ7A5	38043630				2024-07-03	WOS:001170220500001
J	Li, H; Moon, JT; Iyer, D; Balthazar, P; Krupinski, EA; Bercu, ZL; Newsome, JM; Banerjee, I; Gichoya, JW; Trivedi, HM				Li (Hanssen), Hanzhou; Moon, John T.; Iyer, Deepak; Balthazar, Patricia; Krupinski, Elizabeth A.; Bercu, Zachary L.; Newsome, Janice M.; Banerjee, Imon; Gichoya, Judy W.; Trivedi, Hari M.			Decoding radiology reports: Potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports	CLINICAL IMAGING			English	Article						Large language model; Patient-centered reports; Natural language processing; 21st century cures act	EXPERIENCE	Purpose: To evaluate the complexity of diagnostic radiology reports across major imaging modalities and the ability of ChatGPT (Early March 2023 Version, OpenAI, California, USA) to simplify these reports to the 8th grade reading level of the average U.S. adult.Methods: We randomly sampled 100 radiographs (XR), 100 ultrasound (US), 100 CT, and 100 MRI radiology reports from our institution's database dated between 2022 and 2023 (N = 400). These were processed by ChatGPT using the prompt "Explain this radiology report to a patient in layman's terms in second person: ". Mean report length, Flesch reading ease score (FRES), and Flesch-Kincaid reading level (FKRL) were calculated for each report and ChatGPT output. T-tests were used to determine significance.Results: Mean report length was 164 & PLUSMN; 117 words, FRES was 38.0 & PLUSMN; 11.8, and FKRL was 10.4 & PLUSMN; 1.9. FKRL was significantly higher for CT and MRI than for US and XR. Only 60/400 (15%) had a FKRL <8.5. The mean simplified ChatGPT output length was 103 & PLUSMN; 36 words, FRES was 83.5 & PLUSMN; 5.6, and FKRL was 5.8 & PLUSMN; 1.1. This reflects a mean decrease of 61 words (p < 0.01), increase in FRES of 45.5 (p < 0.01), and decrease in FKRL of 4.6 (p < 0.01). All simplified outputs had FKRL <8.5.Discussion: Our study demonstrates the effective use of ChatGPT when tasked with simplifying radiology reports to below the 8th grade reading level. We report significant improvements in FRES, FKRL, and word count, the last of which requires modality-specific context.	[Li (Hanssen), Hanzhou; Moon, John T.; Iyer, Deepak; Balthazar, Patricia; Krupinski, Elizabeth A.; Bercu, Zachary L.; Newsome, Janice M.; Gichoya, Judy W.; Trivedi, Hari M.] Emory Univ, Dept Radiol & Imaging Sci, Sch Med, 1364 Clifton Rd, Atlanta, GA 30322 USA; [Banerjee, Imon] Mayo Clin, Dept Radiol, Phoenix, AZ USA	Emory University; Mayo Clinic; Mayo Clinic Phoenix	Li, H (corresponding author), Emory Univ, Dept Radiol & Imaging Sci, Sch Med, 1364 Clifton Rd, Atlanta, GA 30322 USA.	Hli277@emory.edu	Gichoya, Judy W/E-1657-2011	Trivedi, Hari/0000-0001-6648-8334				American College of Radiology, 2021, ACR B; [Anonymous], 2021, Businesswire; Ariyaratne S, 2023, SKELETAL RADIOL, V14; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Cook TS, 2017, ACAD RADIOL, V24, P1169, DOI 10.1016/j.acra.2017.03.005; Devlin J., 2018, BERT PRE TRAINING DE; Eltorai AEM, 2014, ARCH TRAUMA RES, V3, DOI 10.5812/atr.18161; Flesch R, 2022, WRITE PLAIN ENGLISH; Friedman CHG, 1995, Natural Language Engineering, V1, P83; Goff DJ, 2018, J DIGIT IMAGING, V31, P185, DOI 10.1007/s10278-017-0030-2; Gunn AJ, 2017, AM J ROENTGENOL, V208, P1262, DOI 10.2214/AJR.16.17584; Hassanpour S, 2016, ARTIF INTELL MED, V66, P29, DOI 10.1016/j.artmed.2015.09.007; Ji Z., 2022, ARXIV; Johnson A, 2023, GITHUB 0523; Kadom N, 2021, J AM COLL RADIOL, V18, P128, DOI 10.1016/j.jacr.2020.09.049; Kadom N, 2017, AM J ROENTGENOL, V209, P982, DOI 10.2214/AJR.17.18179; Kemp J, 2022, J AM COLL RADIOL, V19, P377, DOI 10.1016/j.jacr.2021.10.008; Kemp J, 2020, AM J ROENTGENOL, V215, P673, DOI 10.2214/AJR.19.22713; Kemp J, 2020, AM J ROENTGENOL, V214, P1311, DOI 10.2214/AJR.19.22264; Kuhlman M, 2012, ACAD RADIOL, V19, P646, DOI 10.1016/j.acra.2012.02.020; Martin-Carreras T, 2019, CLIN IMAG, V54, P116, DOI 10.1016/j.clinimag.2018.12.006; Mehan WA, 2022, CURR PROBL DIAGN RAD, V51, P712, DOI 10.1067/j.cpradiol.2022.01.012; Mehan WA, 2021, J AM COLL RADIOL, V18, P1012, DOI 10.1016/j.jacr.2021.01.016; Norgeot B, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0258-y; Roose K, 2022, The New York TimesDecember 5,; von Eckstaedt HV, 2020, J THORAC IMAG, V35, P85, DOI 10.1097/RTI.0000000000000469; Zhang Y., 2018, EMNLP 2018, P204	27	20	20	7	13	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0899-7071	1873-4499		CLIN IMAG	Clin. Imaging	SEP	2023	101						137	141		10.1016/j.clinimag.2023.06.008	http://dx.doi.org/10.1016/j.clinimag.2023.06.008		JUN 2023	5	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	M0HI4	37336169				2024-07-03	WOS:001026997400001
J	de Jager, S				de Jager, Sonia			Semantic Noise and Conceptual Stagnation in Natural Language Processing	ANGELAKI-JOURNAL OF THE THEORETICAL HUMANITIES			English	Article						semantic noise; natural language processing; Winograd schemas; disambiguation; artificial intelligence; large language models		Semantic noise, the effect ensuing from the denotative and thus functional variability exhibited by different terms in different contexts, is a common concern in natural language processing (NLP). While unarguably problematic in specific applications (e.g., certain translation tasks), the main argument of this paper is that failing to observe this linguistic matter of fact as a generative effect rather than as an obstacle, leads to actual obstacles in instances where language model outputs are presented as neutral. Given that a common and long-standing challenge in NLP is the interpretation of ambiguous - i.e., semantically noisy - cases, this article focuses on an exemplar ambiguity-resolution task in NLP: the problem of anaphora in Winograd schemas. The main question considered is: to what extent is the standard approach to disambiguation in NLP subject to a stagnant "image of language"? And, can a transdisciplinary, dynamic approach combining linguistics and philosophy elucidate new perspectives on these possible conceptual shortcomings? In order to answer these questions we explore the term and concept of noise, particularly in its presentation as semantic noise. Owing to its definitional plurality, and sometimes even desirable unspecificity, the term noise is thus used as proof of concept for semantic generativity being an inherent characteristic in linguistic representation, and its concept is used to interrogate assumptions admitted in the resolution of Winograd schemas. The argument is speculative and theoretical in method, and the result is an analysis which provides an account of the fundamentally dialogical and necessarily open-ended effects of semantic noise in natural language.	[de Jager, Sonia] Erasmus Sch Philosophy, Room J5-55,Burgemeester Oudlaan 50, NL-3062 PA Rotterdam, Netherlands		de Jager, S (corresponding author), Erasmus Sch Philosophy, Room J5-55,Burgemeester Oudlaan 50, NL-3062 PA Rotterdam, Netherlands.	dejager@esphil.eur.nl						[Anonymous], 1949, The Mathematical Theory of Information; Bacchus F, 1999, ARTIF INTELL, V111, P171, DOI 10.1016/S0004-3702(99)00031-4; Bansal H, 2022, Arxiv, DOI [arXiv:2210.15230, 10.48550/ARXIV.2210.15230]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Borges Jorge Luis, 1960, RIGOR CIENCIA; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; Crawford K., 2016, The New York Times; Curiel E, 2019, NAT ASTRON, V3, P27, DOI 10.1038/s41550-018-0602-1; DAVIDSON D, 1978, CRIT INQUIRY, V5, P31, DOI 10.1086/447971; DAVIDSON D, 1967, SYNTHESE, V17, P304, DOI 10.1007/BF00485035; Davis Ernest, 2011, CS NYU WS COLLECTION; de Jager S, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01643-9; Derrida J., 1974, NEW LITERARY HIST, V6, P5, DOI [10.2307/468341, DOI 10.2307/468341]; Dreyfus H. L., 1992, What computers still can't do.; Elazar Y., 2021, arXiv; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Friston K, 2022, Arxiv, DOI arXiv:2201.06387; Gastaldi J.L., 2021, Philosophy Technology, V34, P149, DOI DOI 10.1007/S13347-020-00393-9; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Wolff JG, 2018, Arxiv, DOI arXiv:1810.04554; Grice P., 1989, STUDIES WAYS WORDS; HARAWAY D, 1985, SOCIALIST REV, P65; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hofstadter Douglas R., 2013, Surfaces and essences: Analogy as the fuel and fire of thinking; Jones Karen Sparck, 2004, Technical Report; Kahneman D., 2022, Noise: A flaw in human judgment; Kocijan V, 2023, Arxiv, DOI arXiv:2201.02387; Lakoff George, 1980, METAPHORS WE LIVE BY; Levesque Hector J., 2011, Technical Report SS-11-06; Luo XW, 2022, IEEE WIREL COMMUN, V29, P210, DOI 10.1109/MWC.101.2100269; Malaspina Cecile, 2018, An Epistemology of Noise; Marcuse Herbert., 2007, ONE DIMENSIONAL MAN; McCarthy John., 1978, MODEL THEORY KNOWLED; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Miller T, 2017, Arxiv, DOI [arXiv:1712.00547, 10.48550/arXiv.1712.00547]; Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513; Morgenstern L, 2016, AI MAG, V37, P50, DOI 10.1609/aimag.v37i1.2639; Nietzsche F., 1988, TRUTH LIE EXTRAMORAL; Prado Casanova Miguel, 2021, THESIS U W ENGLAND B; Rahman V., 2012, P 2012 JOINT C EMPIR, P777; Rieder B, 2020, Engines of order: A mechanology of algorithmic techniques; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Sharma A, 2019, THEOR PRACT LOG PROG, V19, P1021, DOI 10.1017/S1471068419000334; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Weaver Warren., 1949, TRANSLATION; WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3; Xie H, 2020, GLOBECOM 2020 2020 I	48	0	0	1	1	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0969-725X	1469-2899		ANGELAKI	Angelaki-J Theor. Humanit.	MAY 4	2023	28	3			SI		111	132		10.1080/0969725X.2023.2216555	http://dx.doi.org/10.1080/0969725X.2023.2216555			22	Humanities, Multidisciplinary	Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics	K5GU3		hybrid			2024-07-03	WOS:001016730000011
J	Nakaura, T; Yoshida, N; Kobayashi, N; Shiraishi, K; Nagayama, Y; Uetani, H; Kidoh, M; Hokamura, M; Funama, Y; Hirai, T				Nakaura, Takeshi; Yoshida, Naofumi; Kobayashi, Naoki; Shiraishi, Kaori; Nagayama, Yasunori; Uetani, Hiroyuki; Kidoh, Masafumi; Hokamura, Masamichi; Funama, Yoshinori; Hirai, Toshinori			Preliminary assessment of automated radiology report generation with generative pre-trained transformers: comparing results to radiologist-generated reports	JAPANESE JOURNAL OF RADIOLOGY			English	Article						Radiology report; Computed tomography; Deep learning; Large language model; Generative pre-trained transformer		Purpose In this preliminary study, we aimed to evaluate the potential of the generative pre-trained transformer (GPT) series for generating radiology reports from concise imaging findings and compare its performance with radiologist-generated reports.Methods This retrospective study involved 28 patients who underwent computed tomography (CT) scans and had a diagnosed disease with typical imaging findings. Radiology reports were generated using GPT-2, GPT-3.5, and GPT-4 based on the patient's age, gender, disease site, and imaging findings. We calculated the top-1, top-5 accuracy, and mean average precision (MAP) of differential diagnoses for GPT-2, GPT-3.5, GPT-4, and radiologists. Two board-certified radiologists evaluated the grammar and readability, image findings, impression, differential diagnosis, and overall quality of all reports using a 4-point scale.Results Top-1 and Top-5 accuracies for the different diagnoses were highest for radiologists, followed by GPT-4, GPT-3.5, and GPT-2, in that order (Top-1: 1.00, 0.54, 0.54, and 0.21, respectively; Top-5: 1.00, 0.96, 0.89, and 0.54, respectively). There were no significant differences in qualitative scores about grammar and readability, image findings, and overall quality between radiologists and GPT-3.5 or GPT-4 (p > 0.05). However, qualitative scores of the GPT series in impression and differential diagnosis scores were significantly lower than those of radiologists (p < 0.05).Conclusions Our preliminary study suggests that GPT-3.5 and GPT-4 have the possibility to generate radiology reports with high readability and reasonable image findings from very short keywords; however, concerns persist regarding the accuracy of impressions and differential diagnoses, thereby requiring verification by radiologists.	[Nakaura, Takeshi; Yoshida, Naofumi; Kobayashi, Naoki; Shiraishi, Kaori; Nagayama, Yasunori; Uetani, Hiroyuki; Kidoh, Masafumi; Hokamura, Masamichi; Hirai, Toshinori] Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, 1-1-1 Honjo,Chuo Ku, Kumamoto, Kumamoto 8608556, Japan; [Funama, Yoshinori] Kumamoto Univ, Fac Life Sci, Dept Med Phys, Honjo 1-1-1, Kumamoto 8608556, Japan	Kumamoto University; Kumamoto University	Nakaura, T (corresponding author), Kumamoto Univ, Grad Sch Med Sci, Dept Diagnost Radiol, 1-1-1 Honjo,Chuo Ku, Kumamoto, Kumamoto 8608556, Japan.	kff00712@nifty.com; yoshida.nfm25@gmail.com; kobayashi.qm@gmail.com; kaorinpa27@gmail.com; nag_poo777@yahoo.co.jp; hiromaelen5@gmail.com; masafkidoh@yahoo.co.jp; deepimpacted@gmail.com; funama@kumamoto-u.ac.jp; t-hirai@kumamoto-u.ac.jp	Nagayama, Yasunori/GZG-5667-2022	Nagayama, Yasunori/0000-0003-3280-7346; Nakaura, Takeshi/0000-0002-9010-0341				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Barat M, 2021, JPN J RADIOL, V39, P514, DOI 10.1007/s11604-021-01098-5; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chassagnon G, 2023, JPN J RADIOL, V41, P235, DOI 10.1007/s11604-022-01359-x; Hartung MP, 2020, RADIOGRAPHICS, V40, P1658, DOI 10.1148/rg.2020200020; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kitahara H, 2022, JPN J RADIOL, V40, P38, DOI 10.1007/s11604-021-01184-8; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu TY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6723; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; paperswithcode, Papers with Code-language models are unsupervised multitask learners; Parikh JR, 2020, J AM COLL RADIOL, V17, P78, DOI 10.1016/j.jacr.2019.07.008; Radford A., 2018, IMPROVING LANGUAGE U; Sirshar M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262209; Sullivan J.r. J., 2022, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P521; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Van Veen D, 2023, Arxiv, DOI arXiv:2305.01146; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Yan S, 2022, JPN J RADIOL, V40, P847, DOI 10.1007/s11604-022-01268-z; Yasaka K, 2022, JPN J RADIOL, V40, P476, DOI 10.1007/s11604-021-01225-2	20	6	6	12	15	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1867-1071	1867-108X		JPN J RADIOL	Jpn. J. Radiol.	FEB	2024	42	2					190	200		10.1007/s11604-023-01487-y	http://dx.doi.org/10.1007/s11604-023-01487-y		SEP 2023	11	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	FT3L0	37713022	Green Published, hybrid			2024-07-03	WOS:001067533400001
J	Elias, P; Jain, SS; Poterucha, T; Randazzo, M; Jimenez, FL; Khera, R; Perez, M; Ouyang, DV; Pirruccello, J; Salerno, M; Einstein, AJ; Avram, R; Tison, GH; Nadkarni, G; Natarajan, V; Pierson, E; Beecy, A; Kumaraiah, D; Haggerty, C; Silva, JNA; Maddox, TM				Elias, Pierre; Jain, Sneha S.; Poterucha, Timothy; Randazzo, Michael; Jimenez, Francisco Lopez; Khera, Rohan; Perez, Marco; Ouyang, David; Pirruccello, James; Salerno, Michael; Einstein, Andrew J.; Avram, Robert; Tison, Geoffrey H.; Nadkarni, Girish; Natarajan, Vivek; Pierson, Emma; Beecy, Ashley; Kumaraiah, Deepa; Haggerty, Chris; Silva, Jennifer N. Avari; Maddox, Thomas M.			Artificial Intelligence for Cardiovascular Care-Part 1: Advances	JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY			English	Article						artificial intelligence; cardiac imaging; deep learning; digital health; innovation; large language models; machine learning	MAGNETIC-RESONANCE; ATRIAL-FIBRILLATION; LEARNING ALGORITHM; EJECTION FRACTION; HEART-FAILURE; ELECTROCARDIOGRAM; DIAGNOSIS; STENOSIS; CLASSIFICATION; IDENTIFICATION	Recent artificial intelligence (AI) advancements in cardiovascular care offer potential enhancements in diagnosis, treatment, and outcomes. Innovations to date focus on automating measurements, enhancing image quality, and detecting diseases using novel methods. Applications span wearables, electrocardiograms, echocardiography, angiography, genetics, and more. AI models detect diseases from electrocardiograms at accuracy not previously achieved by technology or human experts, including reduced ejection fraction, valvular heart disease, and other cardiomyopathies. However, AI 's unique characteristics necessitate rigorous validation by addressing training methods, real-world efficacy, equity concerns, and long-term reliability. Despite an exponentially growing number of studies in cardiovascular AI, trials showing improvement in outcomes remain lacking. A number are currently underway. Embracing this rapidly evolving technology while setting a high evaluation benchmark will be crucial for cardiology to leverage AI to enhance patient care and the provider experience. (c) 2024 by the American College of Cardiology Foundation.	[Elias, Pierre; Poterucha, Timothy; Einstein, Andrew J.; Kumaraiah, Deepa] Columbia Univ, Irving Med Ctr, Seymour Paul & Gloria Milstein Div Cardiol, New York, NY USA; [Elias, Pierre; Pirruccello, James; Haggerty, Chris] Columbia Univ, Irving Med Ctr, Dept Biomed Informat, New York, NY USA; [Jain, Sneha S.; Perez, Marco; Salerno, Michael] Stanford Univ, Sch Med, Div Cardiol, Palo Alto, CA USA; [Randazzo, Michael] Univ Chicago, Med Ctr, Div Cardiol, Chicago, IL USA; [Jimenez, Francisco Lopez] Mayo Clin, Coll Med, Dept Cardiol, Rochester, MN USA; [Khera, Rohan] Yale Sch Med, Div Cardiol, New Haven, CT USA; [Ouyang, David] Cedars Sinai Med Ctr, Div Cardiol, Los Angeles, CA USA; [Pirruccello, James; Tison, Geoffrey H.] Univ Calif San Francisco, Div Cardiol, San Francisco, CA USA; [Avram, Robert] Montreal Heart Inst, Div Cardiol, Montreal, PQ, Canada; [Nadkarni, Girish] Icahn Sch Med Mt Sinai, New York, NY USA; [Natarajan, Vivek] Google Hlth, Mountain View, CA USA; [Pierson, Emma] Cornell Tech, Dept Comp Sci, New York, NY USA; [Beecy, Ashley; Kumaraiah, Deepa; Haggerty, Chris] New York Presbyterian Hlth Syst, New York, NY USA; [Beecy, Ashley] Weill Cornell Med Coll, Div Cardiol, New York, NY USA; [Silva, Jennifer N. Avari; Maddox, Thomas M.] Washington Univ, Sch Med, Div Cardiol, St Louis, MO USA	NewYork-Presbyterian Hospital; Columbia University; Columbia University; NewYork-Presbyterian Hospital; Stanford University; University of Chicago; University of Chicago Medical Center; Mayo Clinic; Yale University; Cedars Sinai Medical Center; University of California System; University of California San Francisco; Universite de Montreal; Icahn School of Medicine at Mount Sinai; Cornell University; Weill Cornell Medicine; Washington University (WUSTL)	Maddox, TM (corresponding author), Washington Univ, Sch Med, BJC HealthCare, Mailstop 90-29-933,4590 Nash Way, St Louis, MO 63110 USA.	thomas.maddox@bjc.org	Jain, Sneha Shah/KHU-3667-2024	Jain, Sneha Shah/0000-0002-0592-1453	Eidos Therapeutics; Pfizer; Janssen; Edwards Lifesciences; New York Academy of Medicine; Google; Amyloidosis Foundation; American Heart Association [933452, 23SCISA1077 494]; Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine; Abbott; Boston Scientific; Boehringer Ingelheim [NHLBI UG3HL165065]; Novartis; National Institutes of Health (NHLBI) [UG3HL165065]	Eidos Therapeutics; Pfizer(Pfizer); Janssen(Johnson & JohnsonJohnson & Johnson USAJanssen Biotech Inc); Edwards Lifesciences; New York Academy of Medicine; Google(Google Incorporated); Amyloidosis Foundation; American Heart Association(American Heart Association); Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine; Abbott(Abbott Laboratories); Boston Scientific(Boston Scientific); Boehringer Ingelheim(Boehringer Ingelheim); Novartis(Novartis); National Institutes of Health (NHLBI)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI))	Dr Elias has research support provided to his institution from Eidos Therapeutics, Pfizer, Janssen, Edwards Lifesciences, New York Academy of Medicine, and Google. Dr Jain has consulting relationships with Bristol Myers Squibb, ARTIS Ventures, and Broadview Ventures. Dr Poterucha owns stock in Abbott Laboratories and Baxter International; and research support is provided to his institution from the Amyloidosis Foundation, American Heart Association (Award #933452 and #23SCISA1077 494) , Eidos Therapeutics, Pfizer, Janssen, Edwards Lifesciences, and the Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine. Dr Avram is a co-inventor in the patent 63/208,406 (Method and System for Automated Analysis of Coronary Angiograms) ; and has received speaker fees from Abbott, Boston Scientific, Boehringer Ingelheim, and Novartis. Dr Avari Silva is the co-founder and consultant to and holds equity in SentiAR; the technology has been licensed by Washington University to SentiAR. Dr Maddox has received grant funding from the National Institutes of Health (NHLBI UG3HL165065: The Rhythm Evaluation for Anticoagulation with Continuous Monitoring of Atrial Fibrillation Trial [REACT-AF] ) ; has received honoraria and/or expense reimbursement in the past 3 years from the University of Chicago, George Washington University, Baylor College of Medicine, the New York Cardiological Society, and Medscape (Dec 2022) ; has received compensation and travel expense reimbursement for American College of Cardiology leadership roles and meetings; is currently employed as a cardiologist and Vice President, Digital Products and Innovation at BJC HealthCare/Washington University School of Medicine, and in this capacity, he is advising Myia Labs, for which his employer is receiving equity compensation in the company, he is receiving no individual compensation from the company, and he is a compensated director for a New Mexico-based foundation, the J.F Maddox Foundation. All other authors have reported that they have no relationships relevant to the contents of this paper to disclose.	accessdata.fda, 510(k) Premarket Notification: K232699; Adedinsewo D, 2020, CIRC-ARRHYTHMIA ELEC, V13, DOI 10.1161/CIRCEP.120.008437; Akerman Ashley P, 2023, JACC Adv, V2, P100452, DOI 10.1016/j.jacadv.2023.100452; Attia ZI, 2022, NAT MED, V28, P2497, DOI 10.1038/s41591-022-02053-1; Attia ZI, 2019, CIRC-ARRHYTHMIA ELEC, V12, DOI 10.1161/CIRCEP.119.007284; Attia ZI, 2019, LANCET, V394, P861, DOI 10.1016/S0140-6736(19)31721-0; Attia ZI, 2019, J CARDIOVASC ELECTR, V30, P668, DOI 10.1111/jce.13889; Attia ZI, 2019, NAT MED, V25, P70, DOI 10.1038/s41591-018-0240-2; Attia ZI, 2016, J AM HEART ASSOC, V5, DOI 10.1161/JAHA.115.002746; Aufiero S, 2022, BMC MED, V20, DOI 10.1186/s12916-022-02350-z; Avram R, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00880-1; Avram R, 2023, JAMA CARDIOL, V8, P586, DOI 10.1001/jamacardio.2023.0968; Bachtiger P, 2022, LANCET DIGIT HEALTH, V4, pE117, DOI 10.1016/S2589-7500(21)00256-9; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Banerjee A, 2023, LANCET DIGIT HEALTH, V5, pE370, DOI 10.1016/S2589-7500(23)00065-1; Bauer MJ, 2023, RADIOL-CARDIOTHORAC, V5, DOI 10.1148/ryct.220107; Bos JM, 2021, JAMA CARDIOL, V6, P532, DOI 10.1001/jamacardio.2020.7422; Chao CJ, 2024, JACC-CARDIOVASC IMAG, V17, P349, DOI 10.1016/j.jcmg.2023.09.011; Choi AD, 2021, J CARDIOVASC COMPUT, V15, P470, DOI 10.1016/j.jcct.2021.05.004; Christensen M, 2023, Arxiv, DOI [arXiv:2308.15670, 10.48550/arXiv.2308.15670, DOI 10.48550/ARXIV.2308.15670]; Cohen-Shelly M, 2021, EUR HEART J, V42, P2885, DOI 10.1093/eurheartj/ehab153; Delbarre MA, 2023, JACC-CARDIOVASC IMAG, V16, P1085, DOI 10.1016/j.jcmg.2023.01.014; Dey D, 2019, J AM COLL CARDIOL, V73, P1317, DOI 10.1016/j.jacc.2018.12.054; Du HY, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106599; Du TM, 2021, EUROINTERVENTION, V17, P32, DOI 10.4244/EIJ-D-20-00570; Duffy G, 2021, Arxiv, DOI [arXiv:2106.12511, 10.48550/arXiv.2106.12511, DOI 10.48550/ARXIV.2106.12511]; Dunham AS, 2023, GENOME BIOL, V24, DOI 10.1186/s13059-023-02948-3; Elgart M, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03812-z; Elias P, 2022, J AM COLL CARDIOL, V80, P613, DOI 10.1016/j.jacc.2022.05.029; Eng D, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00460-1; Farsalinos KE, 2015, J AM SOC ECHOCARDIOG, V28, P1171, DOI 10.1016/j.echo.2015.06.011; Feher A, 2023, J NUCL CARDIOL, V30, P590, DOI 10.1007/s12350-022-03099-x; Ferreira VM, 2012, J CARDIOVASC MAGN R, V14, DOI 10.1186/1532-429X-14-42; Friedrich MG, 2009, J AM COLL CARDIOL, V53, P1475, DOI 10.1016/j.jacc.2009.02.007; Gadaleta M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00966-w; Galloway CD, 2019, JAMA CARDIOL, V4, P428, DOI 10.1001/jamacardio.2019.0640; Ghanzouri I, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17180-5; Giffard-Roisin S, 2017, IEEE T BIO-MED ENG, V64, P2206, DOI 10.1109/TBME.2016.2629849; Giudicessi JR, 2021, CIRCULATION, V143, P1274, DOI 10.1161/CIRCULATIONAHA.120.050231; Goto S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22877-8; Grogan M, 2021, MAYO CLIN PROC, V96, P2768, DOI 10.1016/j.mayocp.2021.04.023; Guo YT, 2019, J AM COLL CARDIOL, V74, P2365, DOI 10.1016/j.jacc.2019.08.019; Hagio T, 2022, EUR J NUCL MED MOL I, V49, P3140, DOI 10.1007/s00259-022-05735-7; Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3; Hansen BJ, 2018, JACC-CLIN ELECTROPHY, V4, P1501, DOI 10.1016/j.jacep.2018.08.024; He BY, 2023, NATURE, V616, P520, DOI 10.1038/s41586-023-05947-3; healio, FDA grants de novo approval for Al algorithm for detection of hypertrophic cardiomyopathy; Holste G, 2022, medRxiv, DOI [10.1101/2022.08.30.22279413, 10.1101/2022.08.30.22279413, DOI 10.1101/2022.08.30.22279413]; Hong Huihong, 2022, JACC Asia, V2, P460, DOI 10.1016/j.jacasi.2022.03.004; Howell SJ, 2021, JACC-CLIN ELECTROPHY, V7, P1505, DOI 10.1016/j.jacep.2021.06.009; Hu LH, 2020, EUR HEART J-CARD IMG, V21, P549, DOI 10.1093/ehjci/jez177; Hu LH, 2021, EUR HEART J-CARD IMG, V22, P705, DOI 10.1093/ehjci/jeaa134; Jun TJ, 2019, MED BIOL ENG COMPUT, V57, P863, DOI 10.1007/s11517-018-1925-x; Kashou AH, 2021, MAYO CLIN PROC, V96, P2576, DOI 10.1016/j.mayocp.2021.02.029; Khunte A, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00869-w; Khurshid S, 2022, CIRCULATION, V145, P122, DOI 10.1161/CIRCULATIONAHA.121.057480; Khurshid S, 2021, CIRC-CARDIOVASC IMAG, V14, P485, DOI 10.1161/CIRCIMAGING.120.012281; Klempfner RV, 2023, J AM COLL CARDIOL, V81, P1401; Ko WY, 2020, J AM COLL CARDIOL, V75, P722, DOI 10.1016/j.jacc.2019.12.030; Krishna H, 2023, J AM SOC ECHOCARDIOG, V36, P769, DOI 10.1016/j.echo.2023.03.008; Krummen DE, 2017, EUROPACE, V19, P769, DOI 10.1093/europace/euw377; Kwon JM, 2021, ANN NONINVAS ELECTRO, V26, DOI 10.1111/anec.12839; Kwon JM, 2020, LANCET DIGIT HEALTH, V2, pE358, DOI 10.1016/S2589-7500(20)30108-4; Kwon JM, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.119.014717; Kwon JM, 2020, J ELECTROCARDIOL, V59, P151, DOI 10.1016/j.jelectrocard.2020.02.008; Kwon JM, 2020, EUROPACE, V22, P412, DOI 10.1093/europace/euz324; Kwon JM, 2019, KOREAN CIRC J, V49, P629, DOI 10.4070/kcj.2018.0446; Lau ES, 2023, J AM COLL CARDIOL, V82, P1936, DOI 10.1016/j.jacc.2023.09.800; Leiner T, 2019, J CARDIOVASC MAGN R, V21, DOI 10.1186/s12968-019-0575-y; Liao S, 2022, JACC-CLIN ELECTROPHY, V8, P1010, DOI 10.1016/j.jacep.2022.05.003; Lin A, 2022, LANCET DIGIT HEALTH, V4, DOI 10.1016/S2589-7500(22)00022-X; Liu CM, 2022, CAN J CARDIOL, V38, P152, DOI 10.1016/j.cjca.2021.08.014; Liu M, 2023, CLIN RADIOL, V78, pE600, DOI 10.1016/j.crad.2023.04.013; Liu Z, 2023, arXiv, DOI [DOI 10.48550/ARXIV.2306, 10.48550/ARXIV.2306]; Lubitz SA, 2022, CIRCULATION, V146, P1415, DOI 10.1161/CIRCULATIONAHA.122.060291; Ma H, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101634; Moon JH, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105819; Narang A, 2021, JAMA CARDIOL, V6, P624, DOI 10.1001/jamacardio.2021.0185; Neleman T, 2021, J CARDIOVASC TRANSL, V14, P992, DOI 10.1007/s12265-021-10103-1; Ng K, 2016, CIRC-CARDIOVASC QUAL, V9, P649, DOI 10.1161/CIRCOUTCOMES.116.002797; Nicora G, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06547-3; Nkomo VT, 2006, LANCET, V368, P1005, DOI 10.1016/S0140-6736(06)69208-8; Noseworthy PA, 2022, LANCET, V400, P1206, DOI 10.1016/S0140-6736(22)01637-3; Noseworthy PA, 2020, CIRC-ARRHYTHMIA ELEC, V13, DOI 10.1161/CIRCEP.119.007988; Oikonomou EK, 2018, LANCET, V392, P929, DOI 10.1016/S0140-6736(18)31114-0; Ouyang DV, 2020, NATURE, V580, P252, DOI 10.1038/s41586-020-2145-8; Pang K, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101900; Papandrianos NI, 2023, NUCL MED COMMUN, V44, P1, DOI 10.1097/MNM.0000000000001634; Park S, 2022, JACC-CARDIOVASC INTE, V15, P2020, DOI 10.1016/j.jcin.2022.08.040; Peng AW, 2023, J AM COLL CARDIOL, V82, P1192, DOI 10.1016/j.jacc.2023.06.040; Perez MV, 2019, NEW ENGL J MED, V381, P1909, DOI 10.1056/NEJMoa1901183; Poon K, 2005, J ELECTROCARDIOL, V38, P235, DOI 10.1016/j.jelectrocard.2005.01.008; Quer G, 2021, J AM COLL CARDIOL, V77, P300, DOI 10.1016/j.jacc.2020.11.030; Raghunath S, 2021, CIRCULATION, V143, P1287, DOI 10.1161/CIRCULATIONAHA.120.047829; Raghunath S, 2020, NAT MED, V26, P886, DOI 10.1038/s41591-020-0870-z; Raman SV, 2010, J AM COLL CARDIOL, V55, P2480, DOI 10.1016/j.jacc.2010.01.047; Ribeiro AH, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15432-4; Rohmetra H, 2023, COMPUTING, V105, P783, DOI 10.1007/s00607-021-00937-7; Salih AM, 2023, J MAGN RESON IMAGING, V58, P1797, DOI 10.1002/jmri.28675; Sandhu AT, 2023, CIRCULATION, V147, P703, DOI 10.1161/CIRCULATIONAHA.122.062746; Sangha V, 2023, CIRCULATION, V148, P765, DOI 10.1161/CIRCULATIONAHA.122.062646; Sangha V, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29153-3; Schläpfer J, 2017, J AM COLL CARDIOL, V70, P1183, DOI 10.1016/j.jacc.2017.07.723; Selvaraju V, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114097; Shah AP, 2007, J ELECTROCARDIOL, V40, P385, DOI 10.1016/j.jelectrocard.2007.03.008; Silva JNA, 2020, JACC-CLIN ELECTROPHY, V6, P1023, DOI 10.1016/j.jacep.2020.04.036; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Smith SW, 2019, J ELECTROCARDIOL, V52, P88, DOI 10.1016/j.jelectrocard.2018.11.013; Soto JT, 2022, EUR HEART J-DIGIT HL, V3, P380, DOI 10.1093/ehjdh/ztac033; Southworth MK, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2020.3007031; Tang SY, 2022, CIRC-ARRHYTHMIA ELEC, V15, DOI 10.1161/CIRCEP.122.010850; Tatsugami F, 2023, ACAD RADIOL, V30, P2497, DOI 10.1016/j.acra.2022.12.044; Thavendiranathan P, 2012, CIRC-CARDIOVASC IMAG, V5, P102, DOI 10.1161/CIRCIMAGING.111.967836; Thawkar O, 2023, Arxiv, DOI [arXiv:2306.07971, 10.48550/arXiv.2306.07971, DOI 10.48550/ARXIV.2306.07971]; Tilz RR, 2021, EUROPACE, V23, P722, DOI 10.1093/europace/euaa378; Tison GH, 2019, CIRC-CARDIOVASC QUAL, V12, DOI 10.1161/CIRCOUTCOMES.118.005289; Tison GH, 2018, INT J MED INFORM, V120, P1, DOI 10.1016/j.ijmedinf.2018.09.016; Tokodi M, bioRxiv, DOI [10.1101/2022.03.16.22272374, DOI 10.1101/2022.03.16.22272374]; Tromp J, 2022, LANCET DIGIT HEALTH, V4, P46, DOI 10.1016/S2589-7500(21)00235-1; Tu SX, 2021, CATHETER CARDIO INTE, V97, P1040, DOI 10.1002/ccd.29592; Ulloa-Cerna AE, 2022, CIRCULATION, V146, P36, DOI 10.1161/CIRCULATIONAHA.121.057869; van de Leur RR, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.119.015138; van der Velde N, 2021, EUR RADIOL, V31, P3846, DOI 10.1007/s00330-020-07461-w; van Velzen SGM, 2020, RADIOLOGY, V295, P66, DOI 10.1148/radiol.2020191621; Wang AR, 2021, COMMUN BIOL, V4, DOI 10.1038/s42003-021-01824-9; Wehbe RM, 2023, JAMA CARDIOL, V8, P1089, DOI 10.1001/jamacardio.2023.3142; Yan BP, 2020, JAMA CARDIOL, V5, P105, DOI 10.1001/jamacardio.2019.4004; Yao XX, 2021, NAT MED, V27, P815, DOI 10.1038/s41591-021-01335-4; Yuan NE, 2021, JACC-CARDIOVASC IMAG, V14, P2360, DOI 10.1016/j.jcmg.2021.06.018; Zhang J, 2018, CIRCULATION, V138, P1623, DOI 10.1161/CIRCULATIONAHA.118.034338; Zhang Q, 2021, CIRCULATION, V144, P589, DOI 10.1161/CIRCULATIONAHA.121.054432; Zhao C, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104667; Zhu HL, 2020, LANCET DIGIT HEALTH, V2, pE348, DOI 10.1016/S2589-7500(20)30107-2	133	0	0	0	0	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0735-1097	1558-3597		J AM COLL CARDIOL	J. Am. Coll. Cardiol.	JUN 18	2024	83	24					2472	2486		10.1016/j.jacc.2024.03.400	http://dx.doi.org/10.1016/j.jacc.2024.03.400			15	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	WC9O6	38593946				2024-07-03	WOS:001252790500001
J	Uranbey, O; Özbey, F; Kaygisiz, O; Ayranci, F				Uranbey, Oemer; Ozbey, Furkan; Kaygisiz, Omer; Ayranci, Ferhat			Assessing ChatGPT's Diagnostic Accuracy and Therapeutic Strategies in Oral Pathologies: A Cross-Sectional Study	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						oral surgery; large language model; oral pathologies; chatgpt; artificial intelligence in healthcare		Background: The rapid adoption of artificial intelligence (AI) models in the medical field is due to their ability to collaborate with clinicians in the diagnosis and management of a wide range of conditions. This research assesses the diagnostic accuracy and therapeutic strategies of Chat Generative Pre -trained Transformer (ChatGPT) in comparison to dental professionals across 12 clinical cases. Methodology: ChatGPT 3.5 was queried for diagnoses and management plans for 12 retrospective cases. Physicians were tasked with rating the complexity of clinical scenarios and their agreement with the ChatGPT responses using a five -point Likert scale. Comparisons were made between the complexity of the cases and the accuracy of the diagnoses and treatment plans. Results: ChatGPT exhibited high accuracy in providing differential diagnoses and acceptable treatment plans. In a survey involving 30 attending physicians, scenarios were rated with an overall median difficulty level of 3, showing acceptable agreement with ChatGPT's differential diagnosis accuracy (overall median 4). Our study revealed lower diagnosis scores correlating with decreased treatment management scores, as demonstrated by univariate ordinal regression analysis. Conclusions: ChatGPT's rapid processing aids healthcare by offering an objective, evidence -based approach, reducing human error and workload. However, potential biases may affect outcomes and challenge lessexperienced practitioners. AI in healthcare, including ChatGPT, is still evolving, and further research is needed to understand its full potential in analyzing clinical information, establishing diagnoses, and suggesting treatments.	[Uranbey, Oemer; Ayranci, Ferhat] Ordu Univ, Oral & Maxillofacial Surg, Ordu, Turkiye; [Ozbey, Furkan] Ordu Univ, Oral & Maxillofacial Radiol, Ordu, Turkiye; [Kaygisiz, Omer] Gaziantep Univ, Oral & Maxillofacial Surg, Gaziantep, Turkiye	Ordu University; Ordu University; Gaziantep University	Uranbey, O (corresponding author), Ordu Univ, Oral & Maxillofacial Surg, Ordu, Turkiye.	eomeruranbey@gmail.com						Alkhaqani A. L., 2023, Al-Rafidain Journal of Medical Sciences, V4, P50; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cruz JA, 2006, CANCER INFORM, V2, P59; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Huang HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00239-y; Jensen H, 2018, CANCER EPIDEMIOL, V55, P142, DOI 10.1016/j.canep.2018.06.007; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jurisica I, 2022, Artificial Intelligence/Machine Learning in Nuclear Medicine and Hybrid Imaging, P171, DOI [10.1007/978-3-031-00119-2_13, DOI 10.1007/978-3-031-00119-2_13]; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lievin V, 2023, arXiv; Mago J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42133; Qasem Fawaz, 2023, Library Hi Tech News, P30, DOI 10.1108/LHTN-03-2023-0043; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Salas A, 2023, HUM VACC IMMUNOTHER, V19, DOI 10.1080/21645515.2023.2235200; Shah N, 2015, J MAXILLOFAC ORAL SU, V14, P51, DOI 10.1007/s12663-013-0592-6; Shen JY, 2019, JMIR MED INF, V7, DOI 10.2196/10010; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Tekinay ON, 2023, ANN BIOMED ENG, V51, P1371, DOI 10.1007/s10439-023-03209-x; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Varshney N, 2023, Arxiv, DOI arXiv:2307.03987	30	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	APR 19	2024	16	4							e58607	10.7759/cureus.58607	http://dx.doi.org/10.7759/cureus.58607			17	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	QW1Y7	38770501	gold			2024-07-03	WOS:001223827200032
J	Pagano, S; Holzapfel, S; Kappenschneider, T; Meyer, M; Maderbacher, G; Grifka, J; Holzapfel, DE				Pagano, Stefano; Holzapfel, Sabrina; Kappenschneider, Tobias; Meyer, Matthias; Maderbacher, Guenther; Grifka, Joachim; Holzapfel, Dominik Emanuel			Arthrosis diagnosis and treatment recommendations in clinical practice: an exploratory investigation with the generative AI model GPT-4	JOURNAL OF ORTHOPAEDICS AND TRAUMATOLOGY			English	Article						Artificial intelligence; ChatGPT-4; Large language model; Orthopaedics; Total joint replacement; Arthrosis	RELIABILITY	Background The spread of artificial intelligence (AI) has led to transformative advancements in diverse sectors, including healthcare. Specifically, generative writing systems have shown potential in various applications, but their effectiveness in clinical settings has been barely investigated. In this context, we evaluated the proficiency of ChatGPT-4 in diagnosing gonarthrosis and coxarthrosis and recommending appropriate treatments compared with orthopaedic specialists.Methods A retrospective review was conducted using anonymized medical records of 100 patients previously diagnosed with either knee or hip arthrosis. ChatGPT-4 was employed to analyse these historical records, formulating both a diagnosis and potential treatment suggestions. Subsequently, a comparative analysis was conducted to assess the concordance between the AI's conclusions and the original clinical decisions made by the physicians.Results In diagnostic evaluations, ChatGPT-4 consistently aligned with the conclusions previously drawn by physicians. In terms of treatment recommendations, there was an 83% agreement between the AI and orthopaedic specialists. The therapeutic concordance was verified by the calculation of a Cohen's Kappa coefficient of 0.580 (p < 0.001). This indicates a moderate-to-good level of agreement. In recommendations pertaining to surgical treatment, the AI demonstrated a sensitivity and specificity of 78% and 80%, respectively. Multivariable logistic regression demonstrated that the variables reduced quality of life (OR 49.97, p < 0.001) and start-up pain (OR 12.54, p = 0.028) have an influence on ChatGPT-4's recommendation for a surgery.Conclusion This study emphasises ChatGPT-4's notable potential in diagnosing conditions such as gonarthrosis and coxarthrosis and in aligning its treatment recommendations with those of orthopaedic specialists. However, it is crucial to acknowledge that AI tools such as ChatGPT-4 are not meant to replace the nuanced expertise and clinical judgment of seasoned orthopaedic surgeons, particularly in complex decision-making scenarios regarding treatment indications. Due to the exploratory nature of the study, further research with larger patient populations and more complex diagnoses is necessary to validate the findings and explore the broader potential of AI in healthcare.	[Pagano, Stefano; Kappenschneider, Tobias; Meyer, Matthias; Maderbacher, Guenther; Grifka, Joachim; Holzapfel, Dominik Emanuel] Univ Regensburg, Dept Orthopaed Surg, Asklepios Klinikum, Bad Abbach, Germany; [Holzapfel, Sabrina] Univ Regensburg, Univ Childrens Hosp Regensburg, Hosp St Hedwig Order St John, Dept Neonatol, Regensburg, Germany	University of Regensburg; University of Regensburg	Pagano, S (corresponding author), Univ Regensburg, Dept Orthopaed Surg, Asklepios Klinikum, Bad Abbach, Germany.	stefano.pagano@ukr.de	Maderbacher, Günther/S-5946-2019	Pagano, Stefano/0009-0006-6721-7564	Universitt Regensburg (3161)	Universitt Regensburg (3161)	Not applicable.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Cheng KM, 2023, INT J SURG, V109, P2859, DOI 10.1097/JS9.0000000000000521; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Cross M, 2014, ANN RHEUM DIS, V73, P1323, DOI 10.1136/annrheumdis-2013-204763; Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Harskamp RE, 2023, medRxiv, DOI [10.1101/2023.03.25.23285475, https://doi.org/10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475, 10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475V1]; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li Z, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231184048; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Nastasi AJ, 2023, medRxiv, DOI [10.1101/2023.02.25.23286451, 10.1101/2023.02.25.23286451, DOI 10.1101/2023.02.25.23286451]; Padash S, 2023, J ARTHROPLASTY, V38, P1938, DOI 10.1016/j.arth.2023.08.043; Rajjoub R, 2024, GLOB SPINE J, V14, P998, DOI 10.1177/21925682231195783; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Secinaro S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01488-9; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Yin JM, 2021, J MED INTERNET RES, V23, DOI 10.2196/25759	24	3	3	12	21	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1590-9921	1590-9999		J ORTHOP TRAUMATOL	J. Orthop. Traumatol.	NOV 28	2023	24	1							61	10.1186/s10195-023-00740-4	http://dx.doi.org/10.1186/s10195-023-00740-4			11	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	Z2NI5	38015298	gold			2024-07-03	WOS:001110492100001
J	Cesur, T; Günes, YC				Cesur, Turay; Gunes, Yasin Celal			Optimizing Diagnostic Performance of ChatGPT: The Impact of Prompt Engineering on Thoracic Radiology Cases	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						prompt engineering; radiology; large language models; gpt-4; chat generative pre-trained transformer (chatgpt)		Background Recent studies have highlighted the diagnostic performance of ChatGPT 3.5 and GPT-4 in a text -based format, demonstrating their radiological knowledge across different areas. Our objective is to investigate the impact of prompt engineering on the diagnostic performance of ChatGPT 3.5 and GPT-4 in diagnosing thoracic radiology cases, highlighting how the complexity of prompts influences model performance. Methodology We conducted a retrospective cross-sectional study using 124 publicly available Case of the Month examples from the Thoracic Society of Radiology website. We initially input the cases into the ChatGPT versions without prompting. Then, we employed five different prompts, ranging from basic task -oriented to complex role-specific formulations to measure the diagnostic accuracy of ChatGPT versions. The differential diagnosis lists generated by the models were compared against the radiological diagnoses listed on the Thoracic Society of Radiology website, with a scoring system in place to comprehensively assess the accuracy. Diagnostic accuracy and differential diagnosis scores were analyzed using the McNemar, Chisquare, Kruskal-Wallis, and Mann -Whitney U tests. Results Without any prompts, ChatGPT 3.5's accuracy was 25% (31/124), which increased to 56.5% (70/124) with the most complex prompt ( P < 0.001). GPT-4 showed a high baseline accuracy at 53.2% (66/124) without prompting. This accuracy increased to 59.7% (74/124) with complex prompts ( P = 0.09). Notably, there was no statistical difference in peak performance between ChatGPT 3.5 (70/124) and GPT-4 (74/124) ( P = 0.55). Conclusions This study emphasizes the critical influence of prompt engineering on enhancing the diagnostic performance of ChatGPT versions, especially ChatGPT 3.5.	[Cesur, Turay] Ankara Mamak State Hosp, Radiol, Ankara, Turkiye; [Gunes, Yasin Celal] Kirikkale Yuksek Ihtisas Hosp, Radiol, Ankara, Turkiye	Kirikkale University; Kirikkale Yuksek Ihtisas Hospital	Cesur, T (corresponding author), Ankara Mamak State Hosp, Radiol, Ankara, Turkiye.	turaycesur93@gmail.com						Almeida LC, 2024, RADIOL-ARTIF INTELL, V6, DOI 10.1148/ryai.230103; [Anonymous], 2024, A Comparative Study: Diagnostic Performance of ChatGPT 3.5, Google Bard, Microsoft Bing, and Radiologists in Thoracic Radiology Cases, DOI [10.1101/2024.01.18.24301495, DOI 10.1101/2024.01.18.24301495]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]; Gunes Yasin Celal, 2024, Acad Radiol, DOI 10.1016/j.acra.2024.02.043; Gunes YC, 2024, JPN J RADIOL, V42, P673, DOI 10.1007/s11604-024-01548-w; Günes YC, 2024, CARDIOVASC INTER RAD, DOI 10.1007/s00270-024-03674-4; Gupta B, 2023, COGENT BUS MANAG, V10, DOI 10.1080/23311975.2023.2275851; Horiuchi D, 2023, bioRxiv, V20, P2024, DOI [10.1101/2023.08.28.23294607, DOI 10.1101/2023.08.28.23294607]; Kaba Esat, 2024, Acad Radiol, V31, P2641, DOI 10.1016/j.acra.2024.03.005; Li D, 2024, RADIOLOGY, V310, DOI 10.1148/radiol.232411; Li David, 2023, Radiology, V308, pe232082, DOI 10.1148/radiol.232082; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarangi PK, 2024, INDIAN J RADIOL IMAG, V34, P269, DOI 10.1055/s-0043-1777289; Sarangi PK, 2024, INDIAN J RADIOL IMAG, V34, P276, DOI 10.1055/s-0043-1777746; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040	24	0	0	6	6	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 9	2024	16	5							e60009	10.7759/cureus.60009	http://dx.doi.org/10.7759/cureus.60009			12	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	SR9K5	38854352	gold			2024-07-03	WOS:001236292800029
J	Yan, B; Mai, F; Wu, CJ; Chen, R; Li, XL				Yan, Bei; Mai, Feng; Wu, Chaojiang; Chen, Rui; Li, Xiaolin			A Computational Framework for Understanding Firm Communication During Disasters	INFORMATION SYSTEMS RESEARCH			English	Article; Early Access						disaster communication; social media; engagement; competing values framework; natural language processing large language models	SOCIAL MEDIA; COMPETING VALUES; EMPIRICAL-ANALYSIS; DATA BREACH; BIG DATA; MANAGEMENT; PRODUCT; ORGANIZATIONS; ORIENTATION; ENGAGEMENT	Large firms are leaders in disaster response and communication. We study how firms communicate on social media during various disasters and the relationship between their communication and public engagement using a computationally intensive theory construction framework. The framework incorporates a novel natural language processing (NLP) approach, Semantic Projection with Active Retrieval (SPAR), as a key component of the method lexicon. Drawing on the two dimensions (internal versus external and stable versus flexible) of the Competing Values Framework (CVF) as our theoretical lexicon, we examine Facebook posts of Russell 3000 firms on multiple disasters between 2009 and 2022. We find that social media messages that are internal- and stable-oriented, or emphasize operational continuity, are more likely to elicit engagement from the public during biological disasters. By contrast, messages that are external- and flexible-oriented, or stress the innovations to adapt to the disaster, induce more engagement in weather-related disasters. The study offers theoretical implications and methodological support for the research and design of social media messages in disasters and other contexts.	[Yan, Bei; Mai, Feng] Stevens Inst Technol, Hoboken, NJ 07030 USA; [Wu, Chaojiang] Kent State Univ, Kent, OH 44242 USA; [Chen, Rui] Iowa State Univ, Ames, IA 50011 USA; [Li, Xiaolin] Towson Univ, Towson, MD 21252 USA	Stevens Institute of Technology; University System of Ohio; Kent State University; Kent State University Kent; Kent State University Salem; Iowa State University; University System of Maryland; Towson University	Chen, R (corresponding author), Iowa State Univ, Ames, IA 50011 USA.	byan7@stevens.edu; fmai@stevens.edu; cwu13@kent.edu; ruichen@iastate.edu; xli@towson.edu	Chen, Rui/A-7206-2017	Chen, Rui/0000-0002-8280-9414; Mai, Feng/0000-0001-6897-8935	National Science Foundation [2020203]	National Science Foundation(National Science Foundation (NSF))	Funding: This work was supported by the National Science Foundation (Grant 2020203) .	Abbasi A, 2018, MIS QUART, V42, P427, DOI 10.25300/MISQ/2018/13239; Agarwal R, 2014, INFORM SYST RES, V25, P443, DOI 10.1287/isre.2014.0546; [Anonymous], 2021, WMO Atlas of Mortality and Economic Lossess from Weather, Climate and Water Extremes (1970-2019); Arora SD, 2021, J MACROMARKETING, V41, P675, DOI 10.1177/02761467211020109; Athey S, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208110120; Bachura E, 2022, MIS QUART, V46, P881, DOI 10.25300/MISQ/2022/15596; Bai X, 2020, INFORM SYST RES, V31, P1132, DOI 10.1287/isre.2020.0935; Ballesteros L, 2017, ACAD MANAGE J, V60, P1682, DOI 10.5465/amj.2015.0765; Bartov E, 2018, ACCOUNT REV, V93, P25, DOI 10.2308/accr-51865; Belasen A., 2008, THEORY PRACTICE CORP; Belasen A, 2010, ATL J COMMUN, V18, P280, DOI 10.1080/15456870.2010.521475; Below R., 2009, DISASTER CATEGORY CL; Berente N, 2019, INFORM SYST RES, V30, P50, DOI 10.1287/isre.2018.0774; Bethel Jeffrey W, 2013, Disaster Health, V1, P110, DOI 10.4161/dish.27085; Bhattacharya CB, 2003, J MARKETING, V67, P76, DOI 10.1509/jmkg.67.2.76.18609; Bolukbasi T, 2016, ADV NEUR IN, V29; Borah A, 2020, J MARKETING, V84, P69, DOI 10.1177/0022242919899383; BROWN AD, 1994, J MANAGE STUD, V31, P807, DOI 10.1111/j.1467-6486.1994.tb00640.x; Buenger V, 1996, ORGAN SCI, V7, P557, DOI 10.1287/orsc.7.5.557; Cameron K., 2009, An introduction to the Competing Values Framework; Cameron KS, 2006, NEW HORIZ INNO MANAG, P1; Chandra A, 2016, Perspective; Chen YRR, 2019, AM BEHAV SCI, V63, P1603, DOI 10.1177/0002764219835258; Chu SC, 2020, J BUS RES, V110, P260, DOI 10.1016/j.jbusres.2020.01.036; Chung S, 2020, INFORM SYST RES, V31, P258, DOI 10.1287/isre.2019.0884; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Donthu N, 2020, J BUS RES, V117, P284, DOI 10.1016/j.jbusres.2020.06.008; Dou YF, 2013, INFORM SYST RES, V24, P164, DOI 10.1287/isre.1120.0463; Ebrahimi M, 2022, MIS QUART, V46, P1209, DOI 10.25300/MISQ/2022/16618; Fernandes M, 2021, Tips to optimize social media strategy during COVID-19; FOMBRUN C, 1990, ACAD MANAGE J, V33, P233, DOI 10.5465/256324; Gabbatt A., 2013, The GuardianFebruary 20; Gao Y, 2021, INFORM SYST RES, DOI 10.1287/isre.2021.1092; Ghose A, 2009, MIS QUART, V33, P263; Gillan SL, 2021, J CORP FINANC, V66, DOI 10.1016/j.jcorpfin.2021.101889; Grand G, 2022, NAT HUM BEHAV, V6, P975, DOI 10.1038/s41562-022-01316-8; Grover V, 2020, J ASSOC INF SYST, V21, P268, DOI 10.17705/1jais.00601; Guan PQ, 2015, DECIS ANAL, V12, P173, DOI 10.1287/deca.2015.0319; Gunarathne P, 2017, J MANAGE INFORM SYST, V34, P314, DOI 10.1080/07421222.2017.1334465; Guo W, 2021, J MANAGE STUD, V58, P1421, DOI 10.1111/joms.12705; Gwebu KL, 2018, J MANAGE INFORM SYST, V35, P683, DOI 10.1080/07421222.2018.1451962; Hartnell CA, 2011, J APPL PSYCHOL, V96, P677, DOI 10.1037/a0021987; Hassan TA, 2023, REV FINANC STUD, V36, P4919, DOI 10.1093/rfs/hhad044; He S, 2018, INFORM SYST RES, V29, P362, DOI 10.1287/isre.2017.0707; Hoberg G, 2016, J POLIT ECON, V124, P1423, DOI 10.1086/688176; Hong YL, 2021, INFORM SYST RES, V32, P786, DOI 10.1287/isre.2021.1003; Houston JB, 2015, DISASTERS, V39, P1, DOI 10.1111/disa.12092; Howison J, 2011, J ASSOC INF SYST, V12, P767; Huang YL, 2021, J ASSOC INF SYST, V22, P544, DOI 10.17705/1jais.00671; Izumi T., 2015, DISAS MANAGE; Johnson SL, 2019, INFORM ORGAN-UK, V29, P41, DOI 10.1016/j.infoandorg.2019.01.001; Kim HY, 2009, J CONSUM RES, V35, P877, DOI 10.1086/593700; Kryvasheyeu Y, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1500779; Kumar N, 2022, INFORM SYST RES, V33, P1403, DOI 10.1287/isre.2022.1107; Kusumasondjaja S, 2018, ASIA PAC J MARKET LO, V30, P1135, DOI 10.1108/APJML-10-2017-0267; Lam NSN, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047935; LANGFIELD-SMITH K, 1992, J MANAGE STUD, V29, P349, DOI 10.1111/j.1467-6486.1992.tb00669.x; Lee D, 2018, MANAGE SCI, V64, P5105, DOI 10.1287/mnsc.2017.2902; Leidner DE, 2006, MIS QUART, V30, P357; Leong CML, 2015, J ASSOC INF SYST, V16, P174, DOI 10.17705/1jais.00390; Li K, 2021, REV FINANC STUD, V34, P3265, DOI 10.1093/rfs/hhaa079; Liu WL, 2020, PUBLIC RELAT REV, V46, DOI 10.1016/j.pubrev.2020.101949; Luo XM, 2013, INFORM SYST RES, V24, P146, DOI 10.1287/isre.1120.0462; Mallipeddi RR, 2021, INFORM SYST RES, V32, P212, DOI 10.1287/isre.2020.0961; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Miller AR, 2013, INFORM SYST RES, V24, P52, DOI 10.1287/isre.1120.0466; Miranda S, 2022, MIS QUART, V46, pIII; Miranda SM, 2022, MIS QUART, V46, P1421, DOI 10.25300/MISQ/2022/15736; Mirbabaie M, 2020, J INF TECHNOL-UK, V35, P195, DOI 10.1177/0268396220929258; Mu JF, 2022, INFORM SYST RES, V33, P18, DOI 10.1287/isre.2021.1051; Nguyen Dong, 2020, PROC 28 INTERNAT C C, P870; Nian TT, 2022, INFORM SYST RES, V33, P540, DOI 10.1287/isre.2021.1067; Oh O, 2013, MIS QUART, V37, P407, DOI 10.25300/MISQ/2013/37.2.05; OpenAI, 2022, New and improved embedding model; Palttala P, 2012, J CONTING CRISIS MAN, V20, P2, DOI 10.1111/j.1468-5973.2011.00656.x; Park E, 2018, J MARKETING, V82, P93, DOI 10.1509/jm.16.0271; Peng J, 2022, J MANAGE INFORM SYST, V39, P706, DOI 10.1080/07421222.2022.2096547; Qiu LF, 2015, J MANAGE INFORM SYST, V32, P78, DOI 10.1080/07421222.2015.1138368; Quinn R.E., 2011, Diagnosing and changing organizational culture: based on the competing values framework; Quinn R.E., 1991, The Journal of Business Communication, V28, P213, DOI [DOI 10.1177/0021943691028003, DOI 10.1177/002194369102800303, 10.1177/002194369102800303]; QUINN RE, 1983, MANAGE SCI, V29, P363, DOI 10.1287/mnsc.29.3.363; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Robinson SL, 2019, ACAD MANAG DISCOV, V5, P1, DOI 10.5465/amd.2019.0059; ROGERS PS, 1993, HUM RESOURCE MANAGE, V32, P121, DOI 10.1002/hrm.3930320107; Roshan M, 2016, COMPUT HUM BEHAV, V63, P350, DOI 10.1016/j.chb.2016.05.016; Saar-Tsechansky M, 2007, INFORM SYST RES, V18, P4, DOI 10.1287/isre.1070.0111; Sanh V, 2020, 5 WORKSHOP ENERGY EF; Saxton GD, 2019, J BUS ETHICS, V155, P359, DOI 10.1007/s10551-017-3464-z; Segal Edward., 2021, Forbes; Settles B, 2012, Active Learning, Synthesis Lectures on Artificial Intelligence and Machine Learning, P3; Shi D, 2020, Internat. J. Strategic Comm., V14, P348, DOI DOI 10.1080/1553118X.2020.1835920; Sun SJ, 2021, J MANAGE INFORM SYST, V38, P579, DOI 10.1080/07421222.2021.1958548; Syed R, 2023, J ASSOC INF SYST, V24, P249, DOI 10.17705/1jais.00776; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Wang L, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2020.103371; Wooldridge JM, 2010, ECONOMETRIC ANALYSIS OF CROSS SECTION AND PANEL DATA, 2ND EDITION, P3; Yan L, 2019, PROD OPER MANAG, V28, P2514, DOI 10.1111/poms.13064; Yang K, 2023, INFORM SYST RES, V34, P194, DOI 10.1287/isre.2022.1111; Yang MC, 2019, INFORM SYST RES, V30, P839, DOI 10.1287/isre.2019.0834; Yang Y, 2023, INFORM SYST RES, V34, P137, DOI 10.1287/isre.2022.1124; Yousaf A, 2021, J PROD BRAND MANAG, V30, P44, DOI 10.1108/JPBM-08-2019-2546; Zhang R, 2010, J BUS ETHICS, V91, P51, DOI 10.1007/s10551-009-0067-3	103	1	1	15	15	INFORMS	CATONSVILLE	5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA	1047-7047	1526-5536		INFORM SYST RES	Inf. Syst. Res.	2023 NOV 7	2023										10.1287/isre.2022.0128	http://dx.doi.org/10.1287/isre.2022.0128		NOV 2023	20	Information Science & Library Science; Management	Social Science Citation Index (SSCI)	Information Science & Library Science; Business & Economics	KJ3U8					2024-07-03	WOS:001179561200001
J	Ortiz-Zambrano, JA; Espin-Riofrio, C; Montejo-Ráez, A				Ortiz-Zambrano, Jenny A.; Espin-Riofrio, Cesar; Montejo-Raez, Arturo			Combining Transformer Embeddings with Linguistic Features for Complex Word Identification	ELECTRONICS			English	Article						lexical complexity prediction; linguistic features; features fusion; pre-trained large language models		Identifying which words present in a text may be difficult to understand by common readers is a well-known subtask in text complexity analysis. The advent of deep language models has also established the new state-of-the-art in this task by means of end-to-end semi-supervised (pre-trained) and downstream training of, mainly, transformer-based neural networks. Nevertheless, the usefulness of traditional linguistic features in combination with neural encodings is worth exploring, as the computational cost needed for training and running such networks is becoming more and more relevant with energy-saving constraints. This study explores lexical complexity prediction (LCP) by combining pre-trained and adjusted transformer networks with different types of traditional linguistic features. We apply these features over classical machine learning classifiers. Our best results are obtained by applying Support Vector Machines on an English corpus in an LCP task solved as a regression problem. The results show that linguistic features can be useful in LCP tasks and may improve the performance of deep learning systems.	[Ortiz-Zambrano, Jenny A.; Espin-Riofrio, Cesar] Univ Guayaquil, Fac Ciencias Matemat & Fis, Guayaquil 090514, Ecuador; [Montejo-Raez, Arturo] Univ Jaen, Dept Informat, Jaen 23071, Spain	Universidad de Jaen	Ortiz-Zambrano, JA (corresponding author), Univ Guayaquil, Fac Ciencias Matemat & Fis, Guayaquil 090514, Ecuador.; Montejo-Ráez, A (corresponding author), Univ Jaen, Dept Informat, Jaen 23071, Spain.	jenny.ortizz@ug.edu.ec	Espin Riofrio, Cesar/IUN-7905-2023; Montejo-Raez, Arturo/D-3387-2009	Espin Riofrio, Cesar/0000-0001-8864-756X; Montejo-Raez, Arturo/0000-0002-8643-2714	Andalusian Regional Government of Spain [1380939]	Andalusian Regional Government of Spain	This work is partially funded by the WeLee Project grant 1380939 (FEDER Andalucia 2014-2020) from the Andalusian Regional Government of Spain.	[Anonymous], 2016, P 10 INT WORKSHOP SE; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Breiman L, 2001, MACH LEARN, V45, P5, DOI DOI 10.1023/A:1010933404324; Canete J., 2020, P PML4DC ICLR 2020; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Crammer K, 2006, J MACH LEARN RES, V7, P551; Dale E, 1948, EDUC RES BULL, V27, P37; Desai A.T., 2021, P 15 INT WORKSH SEM, P548, DOI 10.18653/v1/2021.semeval-1.67; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; El Mamoun N., 2020, P 15 INT WORKSHOP SE, P585, DOI [10.18653/v1/2021.semeval-1.73, DOI 10.18653/V1/2021.SEMEVAL-1.73]; Gooding Sian, 2018, P 13 WORKSHOP INNOVA, P184; Liebeskind C, 2021, P 15 INT WORKSHOP SE, P138; MCLAUGHLIN GH, 1969, J READING, V12, P639; Mosquera A., 2021, P 15 INT WORKSH SEM, P554, DOI 10.18653/v1/2021.semeval-1.68; Nandy A., 2021, P 15 INT WORKSHOP SE, P678; Ortiz-Zambrano J. A, 2021, P 15 INT WORKSHOP SE, P126; Paetzold G., 2021, P 15 INT WORKSH SEM, P617; Paetzold G., 2016, P 10 INT WORKSH SEM, P969, DOI DOI 10.18653/V1/S16-1149; RAYNER K, 1986, MEM COGNITION, V14, P191, DOI 10.3758/BF03197692; Rico-Sulayes A., 2020, P IBERIAN LANGUAGES; Shardlow M., 2013, 51 ANN M ASS COMP LI, P103; Shardlow M, 2022, LANG RESOUR EVAL, V56, P1153, DOI 10.1007/s10579-022-09588-2; Shardlow Matthew, 2020, P 1 WORKSHOP TOOLS R; Shariq M, 2021, PEER PEER NETW APPL, V14, P3737, DOI 10.1007/s12083-021-01192-5; Singh S, 2021, IEEE ACCESS, V9, P68675, DOI 10.1109/ACCESS.2021.3077350; Song B, 2021, P 15 INT WORKSHOP SE, P1130, DOI 10.18653/v1/2021.semeval-1.158; Taya Y., 2021, P 15 INT WORKSH SEM, P17, DOI 10.18653/v1/2021.semeval-1.2; Uluslu AY, 2022, Arxiv, DOI arXiv:2201.05878; Vaswani A, 2017, ADV NEUR IN, V30; Vettigli G, 2021, P 15 INT WORKSHOP SE, P560; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yaseen Tuqa Bani, 2021, P 15 INT WORKSHOP SE, P661, DOI 10.18653/v1/2021.semeval-1.85; Zaharia G.E., 2021, P 15 INT WORKSHOP SE, P609, DOI [10.18653/v1/2021.semeval-1.77, DOI 10.18653/V1/2021.SEMEVAL-1.77]; Zhuang L., 2021, P 20 CHINESE NATL C, P1218	35	1	1	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JAN	2023	12	1							120	10.3390/electronics12010120	http://dx.doi.org/10.3390/electronics12010120			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	7Q6EA		gold			2024-07-03	WOS:000909481200001
J	dos Santos, A; Pereira, J; Nogueira, R; Masiero, B; Tavallaey, SS; Zea, E				dos Santos, Arthur; Pereira, Jayr; Nogueira, Rodrigo; Masiero, Bruno; Tavallaey, Shiva Sander; Zea, Elias			An experiment on an automated literature survey of data-driven speech enhancement methods	ACTA ACUSTICA			English	Letter						Speech enhancement methods; Data-driven acoustics; Literature survey; Natural language processing; Large language models	INDUCED HEARING-LOSS; SOURCE LOCALIZATION; ART	The increasing number of scientific publications in acoustics, in general, presents difficulties in conducting traditional literature surveys. This work explores the use of a generative pre-trained transformer (GPT) model to automate a literature survey of 117 articles on data-driven speech enhancement methods. The main objective is to evaluate the capabilities and limitations of the model in providing accurate responses to specific queries about the papers selected from a reference human-based survey. While we see great potential to automate literature surveys in acoustics, improvements are needed to address technical questions more clearly and accurately.	[dos Santos, Arthur; Masiero, Bruno] Univ Estadual Campinas, Sch Elect & Comp Engn, Commun Acoust Lab, BR-13083970 Campinas, SP, Brazil; [Pereira, Jayr; Nogueira, Rodrigo] NeuralMind, BR-13083898 Campinas, SP, Brazil; [Tavallaey, Shiva Sander] ABB Corp Res, SE-72226 Vasteras, Sweden; [Tavallaey, Shiva Sander; Zea, Elias] KTH Royal Inst Technol, Dept Engn Mech, Marcus Wallenberg Lab Sound & Vibrat Res, SE-10044 Stockholm, Sweden	Universidade Estadual de Campinas; ABB; Royal Institute of Technology	dos Santos, A (corresponding author), Univ Estadual Campinas, Sch Elect & Comp Engn, Commun Acoust Lab, BR-13083970 Campinas, SP, Brazil.	a264372@dac.unicamp.br	Masiero, Bruno/D-6364-2014; Zea, Elias/I-6208-2019	Masiero, Bruno/0000-0002-2246-4450; Zea, Elias/0000-0001-5723-9571; Pereira, Jayr/0000-0001-5478-438X	Sao Paulo Research Foundation (FAPESP) [2017/08120-6, 2019/22795-1, 2022/16168-7]	Sao Paulo Research Foundation (FAPESP)(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	This study was partially sponsored by the Sao Paulo Research Foundation (FAPESP) under grants #2017/08120-6, #2019/22795-1, and #2022/16168-7. We also thank Prof. Roberto Lotufo and Prof. Renato Lopes for their valuable discussions and suggestions.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Argentieri S, 2015, COMPUT SPEECH LANG, V34, P87, DOI 10.1016/j.csl.2015.03.003; Bianco MJ, 2019, J ACOUST SOC AM, V146, P3590, DOI 10.1121/1.5133944; Cobos M., 2017, A survey of sound source localization methods in wireless acoustic sensor networks; Döllinger M, 2023, ACTA ACUST, V7, DOI 10.1051/aacus/2023014; dos Santos A., 2022, P 24 INT C ACOUSTICS, P173; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Evers C, 2020, IEEE-ACM T AUDIO SPE, V28, P1620, DOI 10.1109/TASLP.2020.2990485; Frank S.D., 2012, Remember everything you read: The Evelyn Wood 7 day speed reading and learning program; Gannot S, 2017, IEEE-ACM T AUDIO SPE, V25, P692, DOI 10.1109/TASLP.2016.2647702; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Grumiaux PA, 2022, J ACOUST SOC AM, V152, P107, DOI 10.1121/10.0011809; Kaltenbacher M, 2023, ACTA ACUST, V7, DOI 10.1051/aacus/2023003; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Malowski KS, 2022, J ACOUST SOC AM, V151, P1769, DOI 10.1121/10.0009675; McLachlan G, 2021, ACTA ACUST, V5, DOI 10.1051/aacus/2021039; Neitzel RL, 2019, J ACOUST SOC AM, V146, P3911, DOI 10.1121/1.5132287; Pain E., 2016, SCIENCE, DOI [10.1126/science.caredit.a1600047, DOI 10.1126/SCIENCE.CAREDIT.A1600047]; Park M, 2023, NATURE, V613, P138, DOI 10.1038/s41586-022-05543-x; Radford A., 2018, IMPROVING LANGUAGE U; Radziwon KE, 2019, J ACOUST SOC AM, V146, P3733, DOI 10.1121/1.5132292; Rafaely B, 2022, ACTA ACUST, V6, DOI 10.1051/aacus/2022040; Song HC, 2022, J ACOUST SOC AM, V151, P2336, DOI 10.1121/10.0009828; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Syed Shahbaz., 2020, P 28 INT C COMP LING, P5384, DOI 10.18653/v1/2020.coling-main.470; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7	28	0	0	3	3	EDP SCIENCES S A	LES ULIS CEDEX A	17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE		2681-4617		ACTA ACUST	Acta Acust.	JAN 9	2024	8								2	10.1051/aacus/2023067	http://dx.doi.org/10.1051/aacus/2023067			8	Acoustics	Science Citation Index Expanded (SCI-EXPANDED)	Acoustics	EK4D8		Green Published, gold, Green Submitted			2024-07-03	WOS:001138798100002
C	Zhai, Y; Jiang, CQ; Wang, LY; Jia, XY; Zhang, S; Chen, ZZ; Liu, X; Zhu, YB			IEEE	Zhai, Yujia; Jiang, Chengquan; Wang, Leyuan; Jia, Xiaoying; Zhang, Shang; Chen, Zizhong; Liu, Xin; Zhu, Yibo			ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs	2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM, IPDPS	International Parallel and Distributed Processing Symposium IPDPS		English	Proceedings Paper	37th IEEE International Parallel and Distributed Processing Symposium (IPDPS)	MAY 15-19, 2023	St Petersburg, FL	IEEE, IEEE Comp Soc, TCPP		Transformer; BERT; Multi-head Attention; Large Language Models; Natural Language Processing; NVIDIA; GPU; CUTLASS		Transformers have become keystone models in natural language processing over the past decade. They have achieved great popularity in deep learning applications, but the increasing sizes of the parameter spaces required by transformer models generate a commensurate need to accelerate performance. Natural language processing problems are also routinely faced with variable-length sequences, as word counts commonly vary among sentences. Existing deep learning frameworks pad variable-length sequences to a maximal length, which adds significant memory and computational overhead. In this paper, we present ByteTransformer, a high-performance transformer boosted for variable-length inputs. We propose a padding-free algorithm that liberates the entire transformer from redundant computations on zero padded tokens. In addition to algorithmic-level optimization, we provide architecture-aware optimizations for transformer functional modules, especially the performancecritical algorithm Multi-Head Attention (MHA). Experimental results on an NVIDIA A100 GPU with variable-length sequence inputs validate that our fused MHA outperforms PyTorch by 6.13x. The end-to-end performance of ByteTransformer for a forward BERT transformer surpasses state-of-the-art transformer frameworks, such as PyTorch JIT, TensorFlow XLA, Tencent TurboTransformer, Microsoft DeepSpeed-Inference and NVIDIA FasterTransformer, by 87%, 131%, 138%, 74% and 55%, respectively. We also demonstrate the general applicability of our optimization methods to other BERT-like models, including ALBERT, DistilBERT, and DeBERTa.	[Zhai, Yujia; Chen, Zizhong] Univ Calif Riverside, Riverside, CA USA; [Jiang, Chengquan; Wang, Leyuan; Jia, Xiaoying; Liu, Xin] ByteDance Ltd, Beijing, Peoples R China; [Zhang, Shang] NVIDIA Corp, Santa Clara, CA USA	University of California System; University of California Riverside; Nvidia Corporation	Liu, X (corresponding author), ByteDance Ltd, Beijing, Peoples R China.	liuxin.ai@bytedance.com	liu, huan/JKI-3764-2023; Wang, Minghao/JMD-0670-2023; liu, huan/JEO-4705-2023; Li, jiaqi/JOZ-6395-2023; yang, yue/KCK-7870-2024; zhang, yueqi/JXM-4287-2024; Yu, Yue/JWP-9103-2024; CHEN, MINGWEI/KHT-6744-2024; LIU, HUI/JPX-8014-2023; Wang, Hao/ABB-8923-2020; zhang, zheng/KBQ-7815-2024; luo, yuan/JLS-6416-2023; wang, wenxin/JOZ-3291-2023; Liu, Yilin/JWP-9153-2024; Zhao, Chunxia/KBB-4190-2024; WANG, Bin/JGM-2639-2023; wang, hao/JKH-5890-2023; WANG, HUI/JFA-9683-2023; Chen, Xin/JDN-2017-2023; wang, yixuan/JGM-3893-2023; wang, hang/JND-8481-2023	Wang, Hao/0000-0001-9109-6017; Liu, Yilin/0000-0002-7581-3933; 				Abadi M., 2016, P OSDI 16 12 USENIX; Aminabadi RY, 2022, Arxiv, DOI [arXiv:2207.00032, DOI 10.48550/ARXIV.2207.00032]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen QW, 2019, 1ST INTERNATIONAL WORKSHOP ON DEEP LEARNING PRACTICE FOR HIGH-DIMENSIONAL SPARSE DATA WITH KDD (DLP-KDD 2019), DOI 10.1145/3326937.3341261; Chen SY, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476138; Cho KYHY, 2014, Arxiv, DOI [arXiv:1409.1259, DOI 10.48550/ARXIV.1409.1259, 10.48550/arXiv.1409.1259]; Dao T, 2022, Arxiv, DOI [arXiv:2205.14135, DOI 10.48550/ARXIV.2205.14135]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Edunov S, 2018, Arxiv, DOI arXiv:1808.09381; google, About us; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, 10.48550/arXiv.1606.08415]; Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; NVIDIA, about Us; OpenAI, ABOUT US; Ouyang K., 2020, IEEE T PARALL DISTR; Paszke A, 2019, ADV NEUR IN, V32; PyTorch, About us; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Vaswani A, 2017, ADV NEUR IN, V30; Wang XH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P113; Yang ZL, 2019, ADV NEUR IN, V32; Yujia Zhai, 2021, ICS '21: Proceedings of the ACM International Conference on Supercomputing, P127, DOI 10.1145/3447818.3460364; Zeng JL, 2022, Arxiv, DOI arXiv:2208.08124; Zhai YJ, 2022, INT PARALL DISTRIB P, P705, DOI 10.1109/IPDPS53621.2022.00074	31	4	4	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-2075		979-8-3503-3766-2	INT PARALL DISTRIB P			2023							344	355		10.1109/IPDPS54959.2023.00042	http://dx.doi.org/10.1109/IPDPS54959.2023.00042			12	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4MJ		Green Submitted			2024-07-03	WOS:001035517300033
C	Rodrigues, J; Gomes, L; Silva, J; Branco, A; Santos, R; Cardoso, HL; Osório, T		Vale, Z; Moniz, N; Cascalho, J; Silva, C; Sebastiao, R		Rodrigues, Joao; Gomes, Luis; Silva, Joao; Branco, Antonio; Santos, Rodrigo; Cardoso, Henrique Lopes; Osorio, Tomas			Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*	PROGRESS IN ARTIFICIAL INTELLIGENCE, EPIA 2023, PT I	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	22nd EPIA Conference on Artificial Intelligence (EPIA)	SEP 05-08, 2023	Azores, PORTUGAL	EPIA, Associacao Portuguesa Inteligencia Artificial, Springer, Elsevier, Artificial Intelligence Journal, Fundacao Ciencia & Tecnologia, Governo Acores, Assembleia Legislativa Regiao Autonoma Acores, Camara Municipal Horta, NOS, INESCTEC, GRIA, LIACC, OKEANOS UAC, Univ Acores, Res Grp Intelligent Engn & Comp Adv Innovat & Dev, CISUC, Inst Engn Electronica Telematica Aveiro, Intelligent Syst Associate Lab, Dev Scope		Portuguese; Large language model; Foundation model; Encoder; Albertina; DeBERTa; BERT; Transformer; Deep learning		To advance the neural encoding of Portuguese (PT), and a fortiori the technological preparation of this language for the digital age, we developed a Transformer-based foundation model that sets a new state of the art in this respect for two of its variants, namely European Portuguese from Portugal (PT-PT) and American Portuguese from Brazil (PT-BR). To develop this encoder, which we named Albertina PT-*, a strong model was used as a starting point, DeBERTa, and its pre-training was done over data sets of Portuguese, namely over a data set we gathered for PT-PT and over the brWaC corpus for PT-BR. The performance of Albertina and competing models was assessed by evaluating them on prominent downstream language processing tasks adapted for Portuguese. Both Albertina versions are distributed free of charge and under a most permissive license possible and can be run on consumer-grade hardware, thus seeking to contribute to the advancement of research and innovation in language technology for Portuguese.	[Rodrigues, Joao; Gomes, Luis; Silva, Joao; Branco, Antonio; Santos, Rodrigo] Univ Lisbon, Fac Sci FCUL, Dept Informat, NLX Nat Language & Speech Grp, P-1749016 Lisbon, Portugal; [Cardoso, Henrique Lopes; Osorio, Tomas] Univ Porto FEUP, Fac Engn, Lab Inteligencia Artificial & Ciencia Comp LIACC, Rua Dr Roberto Frias, P-4200465 Porto, Portugal	Universidade de Lisboa; Universidade do Porto	Rodrigues, J (corresponding author), Univ Lisbon, Fac Sci FCUL, Dept Informat, NLX Nat Language & Speech Grp, P-1749016 Lisbon, Portugal.	jarodrigues@fc.ul.pt; luis.gomes@fc.ul.pt; jsilva@fc.ul.pt; antonio.branco@fc.ul.pt; rsdsantos@fc.ul.pt; hlc@fe.up.pt; tomas.s.osorio@gmail.com	Gomes, Luís/G-1192-2011		PORTULAN CLARIN-Research Infrastructure for the Science and Technology of Language - Lisboa 2020; Alentejo 2020; FCT [PINFRA/22117/2016]; ACCELERAT.AI-Multilingual Intelligent Contact Centers - IAPMEI [C625734525-00462629]; ALBERTINA-Foundation Encoder Model for Portuguese and AI - FCT [CPCA-IAC/AV/478394/2022]; LIACC-Artificial Intelligence and Computer Science Laboratory [FCT/UID/CEC/0027/2020]	PORTULAN CLARIN-Research Infrastructure for the Science and Technology of Language - Lisboa 2020; Alentejo 2020; FCT(Fundacao para a Ciencia e a Tecnologia (FCT)); ACCELERAT.AI-Multilingual Intelligent Contact Centers - IAPMEI; ALBERTINA-Foundation Encoder Model for Portuguese and AI - FCT; LIACC-Artificial Intelligence and Computer Science Laboratory	This research was partially supported by: PORTULAN CLARIN-Research Infrastructure for the Science and Technology of Language, funded by Lisboa 2020, Alentejo 2020 and FCT (PINFRA/22117/2016); ACCELERAT.AI-Multilingual Intelligent Contact Centers, funded by IAPMEI (C625734525-00462629); ALBERTINA-Foundation Encoder Model for Portuguese and AI, funded by FCT (CPCA-IAC/AV/478394/2022); and LIACC-Artificial Intelligence and Computer Science Laboratory (FCT/UID/CEC/0027/2020).	Abadji J, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4344; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; de Vries W, 2019, Arxiv, DOI arXiv:1912.09582; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gomes J.R.S., 2020, PLUE: Portuguese language understanding evaluation; Gugger S., 2022, Accelerate: Training and inference at scale made simple, efficient and adaptable; Gutiérrez-Fandiño A, 2022, PROCES LENG NAT, P39, DOI 10.26342/2022-68-3; Hajlaoui N, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3164; He P, 2020, ICLR; huggingface, Hugging Face; Koehn P., 2005, P MT SUMM, V5, P79; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Laurencon Hugo, 2022, 36 C NEUR INF PROC S; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Martin L., 2020, P 58 ANN M ASS COMPU, P7203, DOI [DOI 10.18653/V1/2020.ACL-MAIN.645, 10.18653/v1/2020.acl-main.645,Online]; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Miquelina N, 2022, LECT NOTES COMPUT SC, V13756, P280, DOI 10.1007/978-3-031-21753-1_28; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P7; Real L, 2020, LECT NOTES ARTIF INT, V12037, P406, DOI 10.1007/978-3-030-41505-1_39; Schneider Elisa Terumi Rubel, 2020, P ARD CLIN NATURAL L, P65; Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; Sutskever I, 2014, ADV NEUR IN, V27; Vaswani A, 2017, ADV NEUR IN, V30; Wagner JA, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P4339; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38	32	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-49007-1; 978-3-031-49008-8	LECT NOTES ARTIF INT			2023	14115						441	453		10.1007/978-3-031-49008-8_35	http://dx.doi.org/10.1007/978-3-031-49008-8_35			13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5HB		Green Submitted			2024-07-03	WOS:001160573500035
J	Alier, M; García-Peñalvo, FJ; Camba, JD				Alier, Marc; Garcia-Penalvo, Francisco Jose; Camba, Jorge D.			Generative Artificial Intelligence in Education: From Deceptive to Disruptive	INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE			English	Article						Artificial Intelligence; Ethical Implications; Ethical Principles; Generative Artificial Intelligence; Large Language Model		Generative Artificial Intelligence (GenAI) has emerged as a promising technology that can create original content, such as text, images, and sound. The use of GenAI in educational settings is becoming increasingly popular and offers a range of opportunities and challenges. This special issue explores the management and integration of GenAI in educational settings, including the ethical considerations, best practices, and opportunities. The potential of GenAI in education is vast. By using algorithms and data, GenAI can create original content that can be used to augment traditional teaching methods, creating a more interactive and personalized learning experience. In addition, GenAI can be utilized as an assessment tool and for providing feedback to students using generated content. For instance, it can be used to create custom quizzes, generate essay prompts, or even grade essays. The use of GenAI as an assessment tool can reduce the workload of teachers and help students receive prompt feedback on their work. Incorporating GenAI in educational settings also poses challenges related to academic integrity. With availability of GenAI models, students can use them to study or complete their homework assignments, which can raise concerns about the authenticity and authorship of the delivered work. Therefore, it is important to ensure that academic standards are maintained, and the originality of the student's work is preserved. This issue highlights the need for implementing ethical practices in the use of GenAI models and ensuring that the technology is used to support and not replace the student's learning experience.	[Alier, Marc] Univ Politecn Cataluna, Barcelona, Spain; [Garcia-Penalvo, Francisco Jose] Univ Salamanca, Res Inst Educ Sci, Salamanca, Spain; [Camba, Jorge D.] Purdue Univ, Purdue, IN 47907 USA	Universitat Politecnica de Catalunya; University of Salamanca; Purdue University System; Purdue University	Camba, JD (corresponding author), Purdue Univ, Purdue, IN 47907 USA.	marc.alier@upc.edu; fgarcia@usal.es; jdorribo@purdue.edu	GARCÍA-PEÑALVO, Francisco José/D-5445-2013	GARCÍA-PEÑALVO, Francisco José/0000-0001-9987-5584	Ministry of Science and Innovation [PID2020-118345RB-I00]; Departament de Recerca i Universitats de la Generalitat de Catalunya [2021 SGR 01412]	Ministry of Science and Innovation(Spanish Government); Departament de Recerca i Universitats de la Generalitat de Catalunya(Generalitat de Catalunya)	The Ministry of Science and Innovation partially funded this monograph through the AvisSA project grant number (PID2020-118345RB-I00) . The Departament de Recerca i Universitats de la Generalitat de Catalunya partially funded this monograph through the 2021 SGR 01412 research groups award.	Abdou M., 2021, P 25 C COMPUTATIONAL, P109, DOI [10.18653/v1/2021.conll-1.9, DOI 10.18653/V1/2021.CONLL-1.9]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alier M., 2023, P TEEM 2023 11 INT C; Alier M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13169206; Alier-Forment M., 2023, EP-31 Las Alucinaciones de ChatGPT con Faraon Llorens; Altman S., 2023, OpenAI; Amo-Filva Daniel, 2023, Proceedings TEEM 2022: Tenth International Conference on Technological Ecosystems for Enhancing Multiculturality. Lecture Notes in Educational Technology, P1199, DOI 10.1007/978-981-99-0942-1_126; Anand A., 2018, Annals: Computer Science Series, V16, P185; Andreas J, 2022, FINDINGS ASS COMPUTA, P5769; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bahrini A, 2023, Arxiv, DOI arXiv:2304.09103; Bartolomé A, 2018, INT J EDUC TECHNOL H, V15, DOI 10.1186/s41239-018-0095-0; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Castañeda L, 2018, INT J EDUC TECHNOL H, V15, DOI 10.1186/s41239-018-0109-y; Cifuentes SC, 2016, IEEE INT CONF ADV LE, P431, DOI 10.1109/ICALT.2016.23; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Diamandis P. H., 2012, Exponential Technology Series; Diamandis P. H., 2020, The Future is Faster Than You Think: How Converging Technologies are Transforming Business, Industries, and Our Lives; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Elliott V., 2023, WiredDecember 28; Fernandez Enguita M., 2024, Cuadernos de Pedagogia; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Fourrier C., 2023, Hugging Face; García FJ, 2005, COMPUT EDUC, V44, P301, DOI 10.1016/j.compedu.2004.02.004; García-Holgado A, 2020, INT J INTERACT MULTI, V6, P136, DOI 10.9781/ijimai.2020.05.005; García-Peñalvo FJ, 2024, RIED-REV IBEROAM EDU, V27, DOI 10.5944/ried.27.1.37716; García-Penalvo FJ, 2023, INT J INTERACT MULTI, V8, DOI 10.9781/ijimai.2023.07.006; García-Peñalvo FJ, 2023, EDUC KNOWL SOC, V24, DOI 10.14201/eks.31279; García-Peñalvo FJ, 2022, EDUC KNOWL SOC, V23, DOI 10.14201/eks.28600; Garcia-Perialvo F. J., 2024, Cuadernos de Pedagogia; Gasevic D., 2023, Comput. Educ. Artif. Intell, V4, DOI [DOI 10.1016/J.CAEAI.2023.100130, 10.1016/j.caeai.2023.100130]; Harris T., 2023, AI and The Future of Life; Henrickson L, 2023, AI SOC, DOI 10.1007/s00146-023-01752-8; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu YP, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3487890; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; García-Peñalvo FJ, 2015, EDUC KNOWL SOC, V16, P119, DOI 10.14201/eks2015161119144; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Li Belinda Z, 2021, arXiv; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Llorens-Largo F., 2023, Universidad; Llorens-Largo F., 2023, Aula Magna 2.0; Lopez C., 2005, RED. Revista de Educacion a Distancia, VIV; Mahajan V., 2023, 100+ Incredible ChatGPT Statistics & Facts in 2024; Maia JDZ, 2023, WORLD-BASEL, V4, P288, DOI 10.3390/world4020019; Nazir Anam, 2023, Meta Radiol, V1, DOI 10.1016/j.metrad.2023.100022; Nye Maxwell, 2021, arXiv; OpenAI, 2023, OpenAI; OpenAI, 2023, Gpt-4v(ision) system card; Papert S., 1987, EDUC RESEARCHER, V16, P22, DOI 10.3102/0013189X016001022; Patel D., 2023, GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE. Demystifying GPT-4: The engineering tradeoffs that led OpenAI to their architecture; Peral-García D, 2024, COMPUT SCI REV, V51, DOI 10.1016/j.cosrev.2024.100619; Pichai S., 2024, AI; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Sabzalieva E., 2023, ED/HE/IESALC/ IP/2023/12; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Schaller RR, 1997, IEEE SPECTRUM, V34, P52, DOI 10.1109/6.591665; Selwyn N, 2016, LEARN MEDIA TECHNOL, V41, P437, DOI 10.1080/17439884.2015.1012523; Sevilla J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891914; Sharples M, 2009, TECHNOLOGY-ENHANCED LEARNING: PRINCIPLES AND PRODUCTS, P233, DOI 10.1007/978-1-4020-9827-7_14; Shin D, 2023, J INF SCI, V49, P18, DOI 10.1177/0165551520985495; Srinivasan B., 2022, NETWORK STATE START; Srivastava Aarohi, 2022, arXiv; Stephenson N., 1992, SNOWCRASH; Stephenson Neal., 1995, The Diamond Age, or, A Young Lady's Illustrated Primer; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Topinka R., The GuardianFebruary 13th; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; UNESCO, 2022, Recommendation on the ethics of artificial intelligence; Urdan T. A., 2000, Corporate e -learning: Exploring a new frontier; Vaswani A, 2017, ADV NEUR IN, V30; Villagrá-Arnedo CJ, 2020, INT J INTERACT MULTI, V6, P112, DOI 10.9781/ijimai.2020.05.006; Wang T., 2021, Computers and Education: Artificial Intelligence, V2, P100031, DOI DOI 10.1016/J.CAEAI.2021.100031; Wang T, 2023, Arxiv, DOI arXiv:2309.09435; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Willinson S., 2023, Simon Willinson's Blog; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Yin SK, 2023, Arxiv, DOI arXiv:2306.13549; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhou J., 2023, arXiv	94	1	1	50	50	UNIV INT RIOJA-UNIR	LOGRONO	RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN	1989-1660			INT J INTERACT MULTI	Int. J. Interact. Multimed. Artif. Intell.	MAR	2024	8	5								10.9781/ijimai.2024.02.011	http://dx.doi.org/10.9781/ijimai.2024.02.011			83	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KO8Q8		gold			2024-07-03	WOS:001181004000002
J	Wong, RSY; Ming, LC; Ali, RAR				Wong, Rebecca Shin-Yee; Ming, Long Chiau; Ali, Raja Affendi Raja			The Intersection of ChatGPT, Clinical Medicine, and Medical Education	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; clinical research; large language model; artificial intelligence; ethical considerations; AI; OpenAI		As we progress deeper into the digital age, the robust development and application of advanced artificial intelligence (AI) technology, specifically generative language models like ChatGPT (OpenAI), have potential implications in all sectors including medicine. This viewpoint article aims to present the authors' perspective on the integration of AI models such as ChatGPT in clinical medicine and medical education. The unprecedented capacity of ChatGPT to generate human-like responses, refined through Reinforcement Learning with Human Feedback, could significantly reshape the pedagogical methodologies within medical education. Through a comprehensive review and the authors' personal experiences, this viewpoint article elucidates the pros, cons, and ethical considerations of using ChatGPT within clinical medicine and notably, its implications for medical education. This exploration is crucial in a transformative era where AI could potentially augment human capability in the process of knowledge creation and dissemination, potentially revolutionizing medical education and clinical practice. The importance of maintaining academic integrity and professional standards is highlighted. The relevance of establishing clear guidelines for the responsible and ethical use of AI technologies in clinical medicine and medical education is also emphasized.	[Wong, Rebecca Shin-Yee] Sunway Univ, Sch Med & Life Sci, Dept Med Educ, Selangor, Malaysia; [Wong, Rebecca Shin-Yee] SEGi Univ, Fac Med Nursing & Hlth Sci, Petaling Jaya, Malaysia; [Ming, Long Chiau; Ali, Raja Affendi Raja] Sunway Univ, Sch Med & Life Sci, Selangor, Malaysia; [Ali, Raja Affendi Raja] Univ Kebangsaan Malaysia, Fac Med, GUT Res Grp, Kuala Lumpur, Malaysia; [Ming, Long Chiau] Sunway Univ, Sch Med & Life Sci, 5 Jalan Univ Bandar Sunway, Selangor 47500, Malaysia	Sunway University; SEGi University; Sunway University; Universiti Kebangsaan Malaysia; Sunway University	Ming, LC (corresponding author), Sunway Univ, Sch Med & Life Sci, 5 Jalan Univ Bandar Sunway, Selangor 47500, Malaysia.	longchiauming@gmail.com	Ming, Long Chiau/J-5210-2015; Wong, Rebecca Shin Yee/HGD-2690-2022	Ming, Long Chiau/0000-0002-6971-1383; Wong, Rebecca Shin Yee/0000-0002-7738-9398				AI Chatbots Vs Search Engines, 2023, Analytics Insight; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amiri P, 2022, J AM MED INFORM ASSN, V29, P1000, DOI 10.1093/jamia/ocac014; Asensio-Cuesta S, 2021, JMIR MED INF, V9, DOI 10.2196/17503; Bhatia P, 2023, J ANAESTH CLIN PHARM, V39, P1, DOI 10.4103/joacp.joacp_84_23; Bhattamisra SK, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010010; Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158; ChatGPT, Optimizing Language Models for Dialogue; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; Echeazarra L, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01730-x; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Fenech ME, 2020, FRONT CARDIOVASC MED, V7, DOI 10.3389/fcvm.2020.00054; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giunti G, 2021, Stud Health Technol Inform, V284, P259, DOI 10.3233/SHTI210719; Görtz M, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231173304; Hegde A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35850; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Jungmann Stefanie Maria, 2019, JMIR Form Res, V3, pe13863, DOI 10.2196/13863; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kim YJ, 2021, J AM MED INFORM ASSN, V29, P149, DOI 10.1093/jamia/ocab240; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Mehnen L, 2023, medRxiv, DOI [10.1101/2023.04.20.23288859, 10.1101/2023.04.20.23288859, DOI 10.1101/2023.04.20.23288859]; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Meszaros J, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.927721; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Niemiec E, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221089079; Poon AIF, 2021, J GASTROEN HEPATOL, V36, P581, DOI 10.1111/jgh.15384; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Rebelo N, 2022, JMIR FORM RES, V6, DOI 10.2196/39443; Roslan NE, 2023, J Med Internet Res, DOI [10.2196/49239, DOI 10.2196/49239]; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Uludogan G, 2022, BIOINFORMATICS, V38, pii155, DOI 10.1093/bioinformatics/btac482; Ursin F, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.695217; Vaswani A, 2017, ADV NEUR IN, V30; Vokinger KN, 2021, NAT MACH INTELL, V3, P738, DOI 10.1038/s42256-021-00386-z; Wilczewski H, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1125926; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2177160	43	4	4	28	32	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e47274	10.2196/47274	http://dx.doi.org/10.2196/47274			8	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Z9BQ7	37988149	Green Published, gold			2024-07-03	WOS:001114957900001
J	Mahajan, AP; Shabet, CL; Smith, J; Rudy, SF; Kupfer, RA; Bohm, LA				Mahajan, Arushi P.; Shabet, Christina L.; Smith, Joshua; Rudy, Shannon F.; Kupfer, Robbi A.; Bohm, Lauren A.			Assessment of Artificial Intelligence Performance on the Otolaryngology Residency In-Service Exam	OTO OPEN			English	Article						artificial intelligence; BoardVitals; ChatGPT; in-service exams; large language models; otolaryngology residency training		ObjectivesThis study seeks to determine the potential use and reliability of a large language learning model for answering questions in a sub-specialized area of medicine, specifically practice exam questions in otolaryngology-head and neck surgery and assess its current efficacy for surgical trainees and learners.Study Design and SettingAll available questions from a public, paid-access question bank were manually input through ChatGPT.MethodsOutputs from ChatGPT were compared against the benchmark of the answers and explanations from the question bank. Questions were assessed in 2 domains: accuracy and comprehensiveness of explanations.ResultsOverall, our study demonstrates a ChatGPT correct answer rate of 53% and a correct explanation rate of 54%. We find that with increasing difficulty of questions there is a decreasing rate of answer and explanation accuracy.ConclusionCurrently, artificial intelligence-driven learning platforms are not robust enough to be reliable medical education resources to assist learners in sub-specialty specific patient decision making scenarios.	[Mahajan, Arushi P.; Shabet, Christina L.] Univ Michigan, Med Sch, Ann Arbor, MI USA; [Smith, Joshua; Rudy, Shannon F.; Kupfer, Robbi A.; Bohm, Lauren A.] Univ Michigan, Sch Med, Dept Otolaryngol Head & Neck Surg, Ann Arbor, MI USA; [Mahajan, Arushi P.] Univ Michigan, Med Sch, 1500 East Med Ctr Dr, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan; University of Michigan System; University of Michigan; University of Michigan System; University of Michigan	Mahajan, AP (corresponding author), Univ Michigan, Med Sch, 1500 East Med Ctr Dr, Ann Arbor, MI 48109 USA.	arushim@med.umich.edu						Arzte BJ., 2020, Chirurg, V91, P265, DOI [10.1007/s00104-020-01120-y, DOI 10.1007/S00104-020-01120-Y]; Augustin Marc, 2014, Yale Journal of Biology and Medicine, V87, P207; Barbour AB, 2019, J MED EDUC CURRIC DE, V6, DOI 10.1177/2382120519889348; boardvitals, about us; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Gupta R, 2023, AESTHET SURG J, DOI 10.1093/asj/sjad128; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Jones Andrew T, 2014, J Surg Educ, V71, pe144, DOI 10.1016/j.jsurg.2014.04.004; Medenilla A., 2023, PLoS Digital Health, V2; openfoam, ABOUT US; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Weidlich V, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.2475; Weiss D. C., 2023, ABA Journal; Wynter L, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1462-9	15	2	2	6	6	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2473-974X		OTO OPEN	OTO Open	OCT	2023	7	4							e98	10.1002/oto2.98	http://dx.doi.org/10.1002/oto2.98			5	Otorhinolaryngology	Emerging Sources Citation Index (ESCI)	Otorhinolaryngology	Z2NU3	38034065	gold			2024-07-03	WOS:001110503900001
J	Esplugas, M				Esplugas, Mireia			The use of artificial intelligence (AI) to enhance academic communication, education and research: a balanced approach	JOURNAL OF HAND SURGERY-EUROPEAN VOLUME			English	Article						Artificial intelligence (AI); AI-related tools; Large language model (LLM) academics; research; risks		Much has been written about the concerns surrounding artificial intelligence (AI). This article looks positively at how AI can enhance communication and academic skills, including teaching and research. The article explains what AI, Generative Pre-trained Transformer (GPT), and chat-GPT are and highlights a few AI-based tools that are currently in use to improve communication and academic skills. It also mentions potential AI problems, such as a lack of personalization, societal biases, and privacy concerns. The future lies in the training of hand surgeons to master the skill of precise communication and academia using AI tools.	[Esplugas, Mireia] Kaplan Hand Inst Barcelona, Avinguda Reina Elisenda 17, Barcelona 08034, Spain; [Esplugas, Mireia] Clin Activamutua Tarragona, C Pin i Soler 12-14, Tarragona 43002, Spain		Esplugas, M (corresponding author), Clin Activamutua Tarragona, C Pin i Soler 12-14, Tarragona 43002, Spain.	mireiaesplugas@institut-kaplan.com						Leopold SS, 2023, J ORTHOP RES, V41, P1137, DOI 10.1002/jor.25566; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7	2	5	5	63	170	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1753-1934	2043-6289		J HAND SURG-EUR VOL	J. Hand Surg.-Eur. Vol.	SEP	2023	48	8					819	822		10.1177/17531934231185746	http://dx.doi.org/10.1177/17531934231185746		JUL 2023	4	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	CL8M0	37417005				2024-07-03	WOS:001023812200001
C	Huang, F; Kwak, H; An, JS			ACM	Huang, Fan; Kwak, Haewoon; An, Jisun			Is ChatGPT beter than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech	COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023			English	Proceedings Paper	32nd World Wide Web Conference (WWW)	APR 30-MAY 04, 2023	Austin, TX	Assoc Comp Machinery, Amazon Science, Baidu, Megagon Labs, Zhipu AI, Google, Booking Com, eBay, Bloomberg Engn, Netflix, ACM SIGWEB, Univ Texas Austin, Sch Informat, Data World, Inst Fdn Machine Learning		Hate Speech; Toxicity Detection; Natural Language Explanation; ChatGPT; Large Language Models; Human Annotation		Recent studies have alarmed that many online hate speeches are implicit. With its subtle nature, the explainability of the detection of such hateful speech has been a challenging problem. In this work, we examine whether ChatGPT can be used for providing natural language explanations (NLEs) for implicit hateful speech detection. We design our prompt to elicit concise ChatGPT-generated NLEs and conduct user studies to evaluate their qualities by comparison with human-written NLEs. We discuss the potential and limitations of ChatGPT in the context of implicit hateful speech research.	[Huang, Fan; Kwak, Haewoon; An, Jisun] Indiana Univ, Bloomington, IN 47405 USA	Indiana University System; Indiana University Bloomington	Huang, F (corresponding author), Indiana Univ, Bloomington, IN 47405 USA.	huangfan@acm.org; haewoon@acm.org; jisun.an@acm.org		Kwak, Haewoon/0000-0003-1418-0834; An, Jisun/0000-0002-4353-8009				An Jisun, 2021, EMNLP FINDINGS; Basile Valerio, 2019, 13 INT WORKSH SEM EV; Belz Anja, 2009, P EUR WORKSH NAT LAN; Camburu OM, 2018, ADV NEUR IN, V31; Dusek Ondrej, 2020, Computer Speech & Language, V2020; ElSherief M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P345; Engadget, 2023, ChatGPT reportedly reached 100 million users in January; Gibert O. d., 2018, P 2 WORKSH AB LANG O, P11, DOI [10.18653/v1/W18-5102, DOI 10.18653/V1/W18-5102]; Gilson A., 2022, medRxiv, P2022; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hine G., 2017, ICWSM, V11, P92, DOI 10.1609/icwsm.v11i1.14893; Huang Fan, 2023, COMP P ACM WEB C; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kwak H, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3739, DOI 10.1145/2702123.2702529; Salminen J., 2018, ICWSM; Sap Maarten, 2020, ACL; Schulman J, 2022, Introducing chatgpt; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sridhar R, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P811; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]	20	14	14	11	12	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9416-1				2023							294	297		10.1145/3543873.3587368	http://dx.doi.org/10.1145/3543873.3587368			4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SF		Green Submitted			2024-07-03	WOS:001124276300070
C	Pei, KX; She, DD; Wang, M; Geng, S; Xuan, Z; David, Y; Yang, JF; Jana, S; Ray, B		Roychoudhury, A; Cadar, C; Kim, M		Pei, Kexin; She, Dongdong; Wang, Michael; Geng, Scott; Xuan, Zhou; David, Yaniv; Yang, Junfeng; Jana, Suman; Ray, Baishakhi			NEUDEP: Neural Binary Memory Dependence Analysis	PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022			English	Proceedings Paper	30th ACM Joint European Software Engineering Conference / Symposium on the Foundations of Software Engineering (ESEC/FSE)	NOV 14-18, 2022	Singapore, SINGAPORE	Assoc Comp Machinery, ACM SIGSOFT, Natl Univ Singapore, Sea Ltd, Amazon Web Serv, Dragon Testing, Microsoft Res, Ant Grp, Google, Meta, Naver, Huawei, Zilliqa, KAIST		Memory Dependence Analysis; Reverse Engineering; Large Language Models; Machine Learning for Program Analysis		Determining whether multiple instructions can access the same memory location is a critical task in binary analysis. It is challenging as statically computing precise alias information is undecidable in theory. The problem aggravates at the binary level due to the presence of compiler optimizations and the absence of symbols and types. Existing approaches either produce significant spurious dependencies due to conservative analysis or scale poorly to complex binaries. We present a new machine-learning-based approach to predict memory dependencies by exploiting the model's learned knowledge about how binary programs execute. Our approach features (i) a self-supervised procedure that pretrains a neural net to reason over binary code and its dynamic value flows through memory addresses, followed by (ii) supervised finetuning to infer the memory dependencies statically. To facilitate efficient learning, we develop dedicated neural architectures to encode the heterogeneous inputs (i.e., code, data values, and memory addresses from traces) with specific modules and fuse them with a composition learning strategy. We implement our approach in NEUDEP and evaluate it on 41 popular software projects compiled by 2 compilers, 4 optimizations, and 4 obfuscation passes. We demonstrate that NEUDEP is more precise (1.5x) and faster (3.5x) than the current state-of-the-art. Extensive probing studies on security-critical reverse engineering tasks suggest that NEUDEP understands memory access patterns, learns function signatures, and is able to match indirect calls. All these tasks either assist or benefit from inferring memory dependencies. Notably, NEUDEP also outperforms the current state-of-the-art on these tasks.	[Pei, Kexin; She, Dongdong; Geng, Scott; David, Yaniv; Yang, Junfeng; Jana, Suman; Ray, Baishakhi] Columbia Univ, New York, NY 10025 USA; [Wang, Michael] MIT, Cambridge, MA USA; [Xuan, Zhou] Purdue Univ, W Lafayette, IN 47907 USA	Columbia University; Massachusetts Institute of Technology (MIT); Purdue University System; Purdue University	Pei, KX (corresponding author), Columbia Univ, New York, NY 10025 USA.	kpei@cs.columbia.edu; dongdong@cs.columbia.edu; mi27950@mit.edu; scott.geng@columbia.edu; xuan1@purdue.edu; yaniv.david@columbia.edu; junfeng@cs.columbia.edu; suman@cs.columbia.edu; rayb@cs.columbia.edu			NSF [CCF-1845893, CCF-2107405, CNS-1564055, IIS-2221943]; ONR [N00014-17-1-2788]; NSF Career Award; Accenture Faculty Research Award; Google Gift; IBM Faculty Award	NSF(National Science Foundation (NSF)); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); NSF Career Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); Accenture Faculty Research Award; Google Gift(Google Incorporated); IBM Faculty Award(International Business Machines (IBM))	We thank the anonymous reviewers for their constructive and valuable feedback. We thank the author of BDA, Zhuo Zhang, for providing valuable insight and suggestion, and running experiments of BDA. This work is sponsored in part by NSF grants CCF-1845893, CCF-2107405, CNS-1564055, and IIS-2221943; ONR grant N00014-17-1-2788; an NSF Career Award; an Accenture Faculty Research Award; a Google Gift; an IBM Faculty Award. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors, and do not necessarily reflect those of the US Government, NSF, ONR, Accenture, Google, or IBM.	Al Ishtiaq A, 2021, Arxiv, DOI arXiv:2104.08017; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Allamanis M, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P281, DOI 10.1145/2635868.2635883; Arras PA, 2022, INT J SOFTW TOOLS TE, V24, P205, DOI 10.1007/s10009-021-00644-w; Balakrishnan G, 2004, LECT NOTES COMPUT SC, V2985, P5; Balakrishnan G, 2010, ACM T PROGR LANG SYS, V32, DOI 10.1145/1749608.1749612; Bardin Sebastien, 2021, MLPA 2020 MACH LEARN; Bengio Y., 2009, ICML, P41, DOI DOI 10.1145/1553374.1553380; Benoit T, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2021), P131, DOI 10.1109/SANER50967.2021.00021; Bhoopchand A., 2016, Learning python code suggestion with a sparse pointer network; Brumley David, 2006, Technical Report. Technical Report CMU-CS-06-180; Brunetto M, 2021, J SYST SOFTWARE, V176, DOI 10.1016/j.jss.2021.110933; Bui NDQ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P511, DOI 10.1145/3404835.3462840; Bui NDQ, 2021, PROC INT CONF SOFTW, P1186, DOI 10.1109/ICSE43902.2021.00109; Chua ZL, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P99; Cifuentes C, 1997, INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE, PROCEEDINGS, P188; Ciniselli M, 2021, IEEE WORK CONF MIN S, P108, DOI 10.1109/MSR52588.2021.00024; Cova M, 2006, ANN COMPUT SECURITY, P269, DOI 10.1109/ACSAC.2006.50; Cui WD, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P17; David R, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P653, DOI 10.1109/SANER.2016.43; David Y, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428293; Debray S., 1998, Conference Record of POPL '98: 25th ACM SIGPLAN-SIGACT. Symposium on Principles of Programming Languages, P12, DOI 10.1145/268946.268948; Degiovanni R., 2022, arXiv; Devanbu P, 2020, Arxiv, DOI arXiv:2009.08525; Devlin J., 2018, BERT PRE TRAINING DE; Dinella E, 2021, Arxiv, DOI arXiv:2105.07569; Ding SHH, 2019, P IEEE S SECUR PRIV, P472, DOI 10.1109/SP.2019.00003; Egele M, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P303; Erlingsson U, 2006, Usenix Association 7th Usenix Symposium on Operating Systems Design and Implementation, P75; Godefroid P, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P539, DOI 10.11455/2568225.2568273; Grimmer Matthias, 2014, P 2014 INT C PRINC P; Gu WC, 2021, NEURAL NETWORKS, V141, P385, DOI 10.1016/j.neunet.2021.04.019; Gui Y., 2022, arXiv; Guo BL, 2005, INT SYM CODE GENER, P291; Guo WB, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1787; He L, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P2497; Hellendoorn VJ, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P152, DOI 10.1145/3236024.3236051; Hernandez G, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2245, DOI 10.1145/3133956.3134050; Hindle A, 2016, COMMUN ACM, V59, P122, DOI 10.1145/2902362; Huang Y, 2020, IEEE T RELIAB, V69, P88, DOI 10.1109/TR.2019.2931725; Huq F, 2022, INFORM SOFTWARE TECH, V143, DOI 10.1016/j.infsof.2021.106765; Izadi M., 2022, arXiv; Jain R, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3498538; Jin Xin, 2022, 2022 ACM SIGSAC C CO; Kim G, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P151, DOI 10.1145/3533767.3534383; Kim SH, 2021, 28TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2021), DOI 10.14722/ndss.2021.24386; Kim Y, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3345628; Lee JongHyup., 2011, Tie: Principled reverse engineering of types in binary programs; Lee Y., 2017, KSII 9 INT C INT ICO; Li XZX, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P3236, DOI 10.1145/3460120.3484587; Louis A, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING RESULTS (ICSE-NIER 2020), P21, DOI 10.1145/3377816.3381736; Mir AM, 2022, Arxiv, DOI arXiv:2101.04470; Ma W, 2022, Arxiv, DOI arXiv:2112.01218; Manning Christopher D., 2020, P NATL ACAD SCI; Mehrotra Nikita, 2021, IEEE Trans. Softw. Eng.; Mondal S, 2021, PROC IEEE INT CONF S, P309, DOI 10.1109/ICSME52107.2021.00034; Mu DL, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P924, DOI 10.1109/ASE.2019.00090; National Security Agency, 2019, Ghidra Disassembler; Nguyen M.-D., 2020, P 23 INT S RES ATT I, P47; Nye Maxwell, 2021, arXiv; Pa˘sa˘reanu C.S., 2012, INT S LEV APPL FORM, P505; Pandi Eirene V, 2021, ADV PROGRAMMING LANG; Patra J, 2022, PROC INT CONF SOFTW, P1469, DOI 10.1145/3510003.3510144; Pei KX, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P690, DOI 10.1145/3468264.3468607; Pei KX, 2021, 28TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2021), DOI 10.14722/ndss.2021.23112; Pei Kexin, 2021, 2021 IEEE S SECURITY; Peng F, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P829; Pina L, 2016, IEEE INT CONF SOFTW, P278, DOI 10.1109/ICST.2016.27; Pradel M, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P209, DOI 10.1145/3368089.3409715; Pradel M, 2022, COMMUN ACM, V65, P86, DOI 10.1145/3460348; Reps T, 2008, LECT NOTES COMPUT SC, V4959, P16; Roziere B., 2021, arXiv; Sellik Hendrig, 2021, 2021 IEEE ACM 18 INT; Sharma Tushar, 2021, arXiv, DOI 10.48550/ARXIV.2110.09610; Shi ES, 2022, PROC INT CONF SOFTW, P1597, DOI 10.1145/3510003.3510060; Srivastava R.K., 2015, Highway networks; Sui YL, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION (CC 2016), P265, DOI 10.1145/2892208.2892235; Sun ZY, 2019, AAAI CONF ARTIF INTE, P7055; Svyatkovskiy A, 2021, Arxiv, DOI arXiv:2109.00084; The Qiling Team, 2020, Qiling-A True Instrumentable Binary Emulation Framework; van der Veen V, 2016, P IEEE S SECUR PRIV, P934, DOI 10.1109/SP.2016.60; Vaswani A, 2017, ADV NEUR IN, V30; Visual Studio, 2006, x86 Assembly Guide; Wang C, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P97, DOI 10.1145/3338906.3338963; Wang F, 2017, 2017 IEEE CYBERSECURITY DEVELOPMENT (SECDEV), P8, DOI 10.1109/SecDev.2017.14; Wang G., 2019, IEEE Transactions on Software Engineering; Wang HJ, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P561; Wang JB, 2021, PROC INT CONF SOFTW, P810, DOI 10.1109/ICSE43902.2021.00079; Wang K, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P121, DOI 10.1145/3385412.3385999; Williams-King D, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P133, DOI 10.1145/3373376.3378470; Xu J, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P17; Xu ZG, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P607, DOI 10.1145/2950290.2950343; Yin H, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P116; Zhang N., 2017, Hikari-an improvement over Obfuscator; Zhang WW, 2021, Arxiv, DOI arXiv:2111.10793; Zhang Z, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360563; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	97	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9413-0				2022							747	759		10.1145/3540250.3549147	http://dx.doi.org/10.1145/3540250.3549147			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LL		Green Submitted			2024-07-03	WOS:001118262900065
J	Okada, Y; Mertens, M; Liu, N; Lam, SSW; Ong, MEH				Okada, Yohei; Mertens, Mayli; Liu, Nan; Lam, Sean Shao Wei; Ong, Marcus Eng Hock			AI and machine learning in resuscitation: Ongoing research, new concepts, and key challenges	RESUSCITATION PLUS			English	Article						Prediction model; Natural language processing; Heterogeneity; Self-fulfilling prophecy; Feedback loop; Large language model; Emergency medicine	HOSPITAL CARDIAC-ARREST; EMERGENCY-DEPARTMENT; CRITICAL-CARE; PREDICTION; VALIDATION; OUTCOMES; SUBPHENOTYPES; EVENTS; IMPACT; ASIA	Aim: Artificial intelligence (AI) and machine learning (ML) are important areas of computer science that have recently attracted attention for their application to medicine. However, as techniques continue to advance and become more complex, it is increasingly challenging for clinicians to stay abreast of the latest research. This overview aims to translate research concepts and potential concerns to healthcare professionals interested in applying AI and ML to resuscitation research but who are not experts in the field.Main text: We present various research including prediction models using structured and unstructured data, exploring treatment heterogeneity, reinforcement learning, language processing, and large-scale language models. These studies potentially offer valuable insights for optimizing treatment strategies and clinical workflows. However, implementing AI and ML in clinical settings presents its own set of challenges. The availability of high quality and reliable data is crucial for developing accurate ML models. A rigorous validation process and the integration of ML into clinical practice is essential for practical implementation. We furthermore highlight the potential risks associated with self-fulfilling prophecies and feedback loops, emphasizing the importance of transparency, interpretability, and trustworthiness in AI and ML models. These issues need to be addressed in order to establish reliable and trustworthy AI and ML models.Conclusion: In this article, we overview concepts and examples of AI and ML research in the resuscitation field. Moving forward, appropriate understanding of ML and collaboration with relevant experts will be essential for researchers and clinicians to overcome the challenges and harness the full potential of AI and ML in resuscitation.	[Okada, Yohei; Liu, Nan; Lam, Sean Shao Wei; Ong, Marcus Eng Hock] Natl Univ Singapore, Duke NUS Med Sch, Singapore, Singapore; [Okada, Yohei] Kyoto Univ, Grad Sch Med, Prevent Serv, Kyoto, Japan; [Mertens, Mayli] Antwerp Univ, Antwerp Ctr Responsible AI, Antwerp, Belgium; [Mertens, Mayli] Antwerp Univ, Dept Philosophy, Ctr Ethics, Antwerp, Belgium; [Ong, Marcus Eng Hock] Singapore Gen Hosp, Dept Emergency Med, Singapore, Singapore; [Okada, Yohei] Natl Univ Singapore, Duke NUS Med Sch, Hlth Serv & Syst Res, Singapore, Singapore	National University of Singapore; Kyoto University; University of Antwerp; University of Antwerp; Singapore General Hospital; National University of Singapore	Okada, Y (corresponding author), Natl Univ Singapore, Duke NUS Med Sch, Hlth Serv & Syst Res, Singapore, Singapore.	yohei_ok@duke-nus.edu.sg; mayli.mertens@uantwerpen.be; liu.nan@duke-nus.edu.sg; gmslasws@nus.edu.sg; marcus.ong@duke-nus.edu.sg	Liu, Nan/L-9529-2013; Okada, Yohei/ABI-3017-2020; Liu, Nan/HCS-2632-2022	Okada, Yohei/0000-0002-2266-476X; Liu, Nan/0000-0003-3610-4883	JSPS KAKENHI of Japan [JP22K21143]; Zoll foundation; Japan Society for the Promotion of Science; FUKUDA Foundation for medical technology; International medical research foundation; European Union [101107292]	JSPS KAKENHI of Japan(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Zoll foundation; Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); FUKUDA Foundation for medical technology(Fukuda Foundation for Medical Technology); International medical research foundation; European Union(European Union (EU))	This study was supported by a scientific research grant from the JSPS KAKENHI of Japan (JP22K21143) and the Zoll foundation. YO has received an overseas scholarship from the Japan Society for the Promotion of Science, the FUKUDA Foundation for medical technology, and the International medical research foundation. MM is funded by the European Union, through the HORIZON-MSCA2022-PF-01-01 Marie Curie Postdoctoral Fellowship, Project 101107292 'PredicGenX'.	Aellen FM, 2023, BRAIN, V146, P778, DOI 10.1093/brain/awac340; Athey S., 2019, Observational Studies, V5, P37, DOI [10.1353/obs.2019.0001, DOI 10.1353/OBS.2019.0001]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Azuaje F, 2019, NPJ PRECIS ONCOL, V3, DOI 10.1038/s41698-019-0078-1; Bartkowiak B, 2019, ANN SURG, V269, P1059, DOI 10.1097/SLA.0000000000002665; Bihorac A, 2019, ANN SURG, V269, P652, DOI 10.1097/SLA.0000000000002706; Blomberg SN, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2020.32320; Brown JR, 2022, J AM HEART ASSOC, V11, DOI 10.1161/JAHA.121.024198; Byrsell F, 2021, RESUSCITATION, V162, P218, DOI 10.1016/j.resuscitation.2021.02.041; Callaway CW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.8215; Chan SL, 2023, ANN EMERG MED, V82, P22, DOI 10.1016/j.annemergmed.2023.02.001; Chin KC, 2022, J MED INTERNET RES, V24, DOI 10.2196/30210; De-Arteaga M, 2023, RESUSCITATION, V183, DOI 10.1016/j.resuscitation.2022.10.014; Detsky ME, 2017, JAMA-J AM MED ASSOC, V317, P2187, DOI 10.1001/jama.2017.4078; Di Nucci E, 2022, ROWMAN LITTLEFIELD H; Elmer J, 2022, RESUSCITATION, V172, P17, DOI 10.1016/j.resuscitation.2022.01.004; Fernandes MB, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119171; Floridi L, 2019, NAT MACH INTELL, V1, P261, DOI 10.1038/s42256-019-0055-y; Frisch A, 2014, RESUSCITATION, V85, P1111, DOI 10.1016/j.resuscitation.2014.05.002; Fujiwara G, 2024, NEUROCRIT CARE, V40, P292, DOI 10.1007/s12028-023-01712-6; Fukaguchi K, 2022, JMIR FORM RES, V6, DOI 10.2196/37301; Goldstein BA, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.23547; Gong XJ, 2021, CPT-PHARMACOMET SYST, V10, P1433, DOI 10.1002/psp4.12715; Goto T, 2020, ACUTE MED SURG, V7, DOI 10.1002/ams2.554; Goto T, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2018.6937; Hajeb-M S, 2021, J AM HEART ASSOC, V10, DOI 10.1161/JAHA.120.019065; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Ivanov O, 2021, J EMERG NURS, V47, DOI 10.1016/j.jen.2020.11.001265; Jacobs I, 2004, CIRCULATION, V110, P3385, DOI 10.1161/01.CIR.0000147236.85306.15; Jawadekar N, 2023, AM J EPIDEMIOL, V192, P1155, DOI 10.1093/aje/kwad043; Jonas S, 2019, HUM BRAIN MAPP, V40, P4606, DOI 10.1002/hbm.24724; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Kawai Y, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-32899-5; Kenet AL, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109740; King OC, 2023, ETHICAL THEORY MORAL, V26, P127, DOI 10.1007/s10677-022-10359-9; Kline A, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00712-8; Kolk MZH, 2023, EBIOMEDICINE, V89, DOI 10.1016/j.ebiom.2023.104462; Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5; Koo Geraldine P Y, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20064979; Koo GPY, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19148476; Kudo D, 2021, CRIT CARE, V25, DOI 10.1186/s13054-021-03541-5; Kühl N, 2022, ELECTRON MARK, V32, P2235, DOI 10.1007/s12525-022-00598-0; Kwon JM, 2020, SCAND J TRAUMA RESUS, V28, DOI 10.1186/s13049-020-00791-0; Lauschke VM, 2020, NPJ GENOM MED, V5, DOI 10.1038/s41525-020-0119-2; Liu N, 2022, ECLINICALMEDICINE, V48, DOI 10.1016/j.eclinm.2022.101422; Liu SQ, 2020, J MED INTERNET RES, V22, DOI 10.2196/18477; Loftus TJ, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.842306; Mansour A, 2022, NEUROCRIT CARE, V36, P974, DOI 10.1007/s12028-021-01405-y; Medenilla A., 2023, PLoS Digital Health, V2; Mertens M, 2022, J MED ETHICS, V48, P922, DOI 10.1136/medethics-2020-106636; Mowafi H, 2019, BMJ GLOB HEALTH, V4, DOI 10.1136/bmjgh-2019-001442; Nanayakkara S, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002709; Navarro CLA, 2021, BMJ-BRIT MED J, V375, DOI 10.1136/bmj.n2281; Nichol G, 2008, JAMA-J AM MED ASSOC, V300, P1423, DOI 10.1001/jama.300.12.1423; Nishikimi M, 2021, CRIT CARE MED, V49, pE741, DOI 10.1097/CCM.0000000000005025; Nishioka N, 2021, RESUSCITATION, V168, P142, DOI 10.1016/j.resuscitation.2021.09.027; Nolan JP, 2021, INTENS CARE MED, V47, P369, DOI 10.1007/s00134-021-06368-4; Okada Y, 2022, ACUTE MED SURG, V9, DOI 10.1002/ams2.760; Okada Y, 2022, AM J EMERG MED, V51, P348, DOI 10.1016/j.ajem.2021.11.022; Okada Y, 2022, CIRC J, V86, P668, DOI 10.1253/circj.CJ-21-0675; Okada Y, 2021, J INTENSIVE CARE, V9, DOI 10.1186/s40560-021-00525-z; Ong MEH, 2015, RESUSCITATION, V96, P100, DOI 10.1016/j.resuscitation.2015.07.026; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Peine A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00388-6; Perkins GD, 2015, CIRCULATION, V132, P1286, DOI 10.1161/CIR.0000000000000144; Pham SDT, 2022, NEUROCRIT CARE, V37, P248, DOI 10.1007/s12028-022-01449-8; Pimentel MAF, 2021, AM J RESP CRIT CARE, V204, P44, DOI 10.1164/rccm.202007-2700OC; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Ramspek CL, 2021, CLIN KIDNEY J, V14, P49, DOI 10.1093/ckj/sfaa188; Reddy K, 2020, LANCET RESP MED, V8, P631, DOI 10.1016/S2213-2600(20)30124-7; Riascos A, 2017, DOCUMENTO CEDE; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Scholz ML, 2022, SCAND J TRAUMA RESUS, V30, DOI 10.1186/s13049-022-01020-6; Seitz KP, 2023, AM J RESP CRIT CARE, V207, P1602, DOI 10.1164/rccm.202209-1799OC; Sem M, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109755; Seymour CW, 2019, JAMA-J AM MED ASSOC, V321, P2003, DOI 10.1001/jama.2019.5791; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sinha P, 2021, CRIT CARE MED, V49, pE63, DOI 10.1097/CCM.0000000000004710; Sterling NW, 2019, INT J MED INFORM, V129, P184, DOI 10.1016/j.ijmedinf.2019.06.008; Sundermann ML, 2015, AM J EMERG MED, V33, P95, DOI 10.1016/j.ajem.2014.10.037; Suresh H, 2021, PROCEEDINGS OF 2021 ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2021, DOI 10.1145/3465416.3483305; Syrowatka A, 2022, LANCET DIGIT HEALTH, V4, pE137, DOI 10.1016/S2589-7500(21)00229-6; Tagami T, 2020, ACUTE MED SURG, V7, DOI 10.1002/ams2.430; Van Calster B, 2023, BMC MED, V21, DOI 10.1186/s12916-023-02779-w; Volovici V, 2022, NAT MED, V28, P1996, DOI 10.1038/s41591-022-01961-6; Wager S, 2018, J AM STAT ASSOC, V113, P1228, DOI 10.1080/01621459.2017.1319839; Wildi K, 2021, J INTENSIVE CARE, V9, DOI 10.1186/s40560-021-00528-w; Wilson JG, 2020, CRIT CARE, V24, DOI 10.1186/s13054-020-2778-x; Winslow CJ, 2022, CRIT CARE MED, V50, P1339, DOI 10.1097/CCM.0000000000005492; Yang C, 2022, J AM MED INFORM ASSN, V29, P983, DOI 10.1093/jamia/ocac002; Yun WJ, 2023, COMPUT BIOL MED, V156, DOI 10.1016/j.compbiomed.2023.106739; Zheng WL, 2022, IEEE T BIO-MED ENG, V69, P1813, DOI 10.1109/TBME.2021.3139007; Zheng Wei-Long, 2021, Resuscitation, V169, P86, DOI 10.1016/j.resuscitation.2021.10.034; Zicari RV, 2021, FRONT HUM DYNAM, V3, DOI 10.3389/fhumd.2021.673104	94	9	9	2	8	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-5204			RESUSC PLUS	Resusc. Plus	SEP	2023	15								100435	10.1016/j.resplu.2023.100435	http://dx.doi.org/10.1016/j.resplu.2023.100435		JUL 2023	10	Critical Care Medicine; Emergency Medicine	Emerging Sources Citation Index (ESCI)	General & Internal Medicine; Emergency Medicine	P6SE4	37547540	Green Published, gold			2024-07-03	WOS:001051946400001
C	Soundararajan, S; Jeyaraj, MN; Delany, SJ			IEEE	Soundararajan, Shweta; Jeyaraj, Manuela Nayantara; Delany, Sarah Jane			Using ChatGPT to generate Gendered Language	2023 31ST IRISH CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COGNITIVE SCIENCE, AICS			English	Proceedings Paper	31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)	DEC 07-08, 2023	Letterkenny, IRELAND			natural language processing; machine learning; large language models; ChatGPT; gendered language; prompt engineering; zero-shot prompting	FEMININE TRAITS; STEREOTYPES; PERCEPTION; ATTITUDES; MASCULINE; IMPLICIT; ENGLISH	Gendered language is the use of words that denote an individual's gender. This can be explicit where the gender is evident in the actual word used, e.g. mother, she, man, but it can also be implicit where social roles or behaviours can signal an individual's gender - for example, expectations that women display communal traits (e.g., affectionate, caring, gentle) and men display agentic traits (e.g., assertive, competitive, decisive). The use of gendered language in NLP systems can perpetuate gender stereotypes and bias. This paper proposes an approach to generating gendered language datasets using ChatGPT which will provide data for data-driven approaches for gender stereotype detection and gender bias mitigation. The approach focuses on generating implicit gendered language that captures and reflects stereotypical characteristics or traits of a particular gender. This is done by engineering prompts to ChatGPT that use gender-coded words from gender-coded lexicons. The evaluation of the datasets generated shows good instances of English-language gendered sentences that can be identified as those that are consistent with gender stereotypes and those that are contradictory. The generated data also shows strong gender bias.	[Soundararajan, Shweta; Jeyaraj, Manuela Nayantara; Delany, Sarah Jane] Technol Univ Dublin, Sch Comp Sci, Dublin, Ireland		Soundararajan, S (corresponding author), Technol Univ Dublin, Sch Comp Sci, Dublin, Ireland.	shweta.x.soundararajan@mytudublin.ie; manuela.n.jeyaraj@mytudublin.ie; sarahjane.delany@tudublin.ie	Soundararajan, Shweta/IXW-7071-2023	Soundararajan, Shweta/0009-0005-2171-5501	Technological University Dublin through the TU Dublin Scholarship - Presidents Award	Technological University Dublin through the TU Dublin Scholarship - Presidents Award	This work was funded by Technological University Dublin through the TU Dublin Scholarship - Presidents Award.	Ackerman L, 2019, GLOSSA-UK, V4, DOI 10.5334/gjgl.721; Arvidsson S., 2009, A gender based adjectival study of women's and men's magazines; Bartl M, 2022, PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022), P47; Bartz JA, 2004, PERS SOC PSYCHOL B, V30, P1389, DOI 10.1177/0146167204264245; BEM SL, 1974, J CONSULT CLIN PSYCH, V42, P155, DOI 10.1037/h0036215; Bigler R.S., 2015, Policy Insights from the Behavioral and Brain Sciences, V2, P187, DOI DOI 10.1177/2372732215600452; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bolukbasi T, 2016, ADV NEUR IN, V29; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brutt-Griffler J, 2018, ENGL TODAY, V34, P12, DOI 10.1017/S0266078417000372; Bucholtz Mary., 2004, A Companion to Linguistic Anthropology, P369, DOI DOI 10.1002/9780470996522.CH16; Cao YT, 2020, Arxiv, DOI arXiv:1910.13913; Chen Q., 2023, bioRxiv, P2023; Chiril P, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2833; Cryan J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376488; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; De-Arteaga M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P120, DOI 10.1145/3287560.3287572; Dean ML, 2017, SEX ROLES, V76, P643, DOI 10.1007/s11199-016-0713-z; DEAUX K, 1984, J PERS SOC PSYCHOL, V46, P991, DOI 10.1037/0022-3514.46.5.991; Donnelly K, 2017, SEX ROLES, V76, P556, DOI 10.1007/s11199-016-0625-y; Eckert Penelope., 1992, Locating Power: Proceedings of the Second Berkeley Women and Language Conference, P89; Ellemers N, 2018, ANNU REV PSYCHOL, V69, P275, DOI 10.1146/annurev-psych-122216-011719; Fast Ethan, 2016, 10 INT AAAI C WEB SO; Gabriel U, 2008, BEHAV RES METHODS, V40, P206, DOI 10.3758/BRM.40.1.206; Gaucher D, 2011, J PERS SOC PSYCHOL, V101, P109, DOI 10.1037/a0022530; Ghosh S, 2023, Arxiv, DOI arXiv:2305.10510; Hamidi F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173582; Hellinger M., 2015, Gender across languages, P1; HOFFMAN C, 1990, J PERS SOC PSYCHOL, V58, P197, DOI 10.1037/0022-3514.58.2.197; HOFFMAN C, 1990, J PERS SOC PSYCHOL, V58, P765, DOI 10.1037/0022-3514.58.5.765; Hymes D., 2009, Explorations in the; Lakoff R., 1973, Language in Society, V2, P45, DOI [DOI 10.1017/S0047404500000051, 10.1017/S0047404500000051]; Leaper C., 2004, Monographs of the Society for Research in Child Development; Litosseliti L., 2002, GENDER IDENTITY DISC; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Maass A., 1999, Advances in Experimental Social Psychology, V31, P79, DOI [DOI 10.1016/S0065-2601(08)60272-5, 10.1016/S0065-2601(08)60272-5]; Madaan N., 2018, PMLR, P92; Madera JM, 2009, J APPL PSYCHOL, V94, P1591, DOI 10.1037/a0016539; Matfield K., 2014, Gender decoder for jobs ads; Michail A, 2023, Arxiv, DOI arXiv:2303.01194; Morelius A., 2018, The use of adjectives in contemporary fashion magazines: A gender based study; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nangia N, 2020, Arxiv, DOI arXiv:2010.00133; Prost F., 2019, arXiv; Pujari R., 2022, arXiv; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Rickford John R., 1994, Sociolinguistic perspectives on register, P276; ROSENKRANTZ P, 1968, J CONSULT CLIN PSYCH, V32, P287, DOI 10.1037/h0025909; RUBIN DL, 1991, SEX ROLES, V24, P391, DOI 10.1007/BF00289330; Rudman LA, 2000, PERS SOC PSYCHOL B, V26, P1315, DOI 10.1177/0146167200263001; Shahriar S, 2023, Arxiv, DOI [arXiv:2302.13817, 10.47852/bonviewAIA3202939, DOI 10.47852/BONVIEWAIA3202939]; Shiliang Tang, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134734; Sidner C.L., 1981, Computational Linguistics, V7, P217; Singh S., 2023, Is chatgpt biased? a review; Spence J. T., 1974, Developmental Psychology; Strohmaier, 2015, P ICWSM, DOI DOI 10.1609/ICWSM.V9I1.14628; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Thomson R, 2001, PSYCHOL SCI, V12, P171, DOI 10.1111/1467-9280.00329; Tokarz RE, 2021, J LIBR ADM, V61, P301, DOI 10.1080/01930826.2021.1883368; Twenge JM, 1997, SEX ROLES, V36, P305, DOI 10.1007/BF02766650; Ubani S, 2023, Arxiv, DOI [arXiv:2304.14334, 10.48550/arXiv.2304.14334]; Wang S., 2023, arXiv; Williams Jr J. A., 1987, Sociology Department, P8; Zhao JY, 2018, Arxiv, DOI [arXiv:1809.01496, DOI 10.48550/ARXIV.1809.01496]; Zhao JY, 2018, Arxiv, DOI arXiv:1804.06876; Zhao JY, 2019, Arxiv, DOI arXiv:1904.03310; Zhao JY, 2017, Arxiv, DOI arXiv:1707.09457; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	68	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-6021-9				2023										10.1109/AICS60730.2023.10470830	http://dx.doi.org/10.1109/AICS60730.2023.10470830			8	Behavioral Sciences; Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Behavioral Sciences; Computer Science	BW7SN					2024-07-03	WOS:001195949100034
J	Breazu, P; Katson, N				Breazu, Petre; Katson, Napoleon			ChatGPT-4 as a journalist: Whose perspectives is it reproducing?	DISCOURSE & SOCIETY			English	Article; Early Access						AI and Journalism; AI biases; Artificial sociality; ChatGPT-4; critical discourse analysis; generative AI; hate speech; Large Language Models (LLMs)		The rapid emergence of generative AI models in the media sector demands a critical examination of the narratives these models produce, particularly in relation to sensitive topics, such as politics, racism, immigration, public health, gender and violence, among others. The ease with which generative AI can produce narratives on sensitive topics raises concerns about potential harms, such as amplifying biases or spreading misinformation. Our study juxtaposes the content generated by a state-of-the-art generative AI, specifically ChatGPT-4, with actual articles from leading UK media outlets on the topic of immigration. Our specific case study focusses on the representation of Eastern European Roma migrants in the context of the 2016 UK Referendum on EU membership. Through a comparative critical discourse analysis, we uncover patterns of representation, inherent biases and potential discrepancies in representation between AI-generated narratives and mainstream media discourse with different political views. Preliminary findings suggest that ChatGPT-4 exhibits a remarkable degree of objectivity in its reporting and demonstrates heightened racial awareness in the content it produces. Moreover, it appears to consistently prioritise factual accuracy over sensationalism. All these features set it apart from right-wing media articles in our sample. This is further evidenced by the fact that, in most instances, ChatGPT-4 refrains from generating text or does so only after considerable adjustments when prompted with headlines that the model deems inflammatory. While these features can be attributed to the model's diverse training data and model architecture, the findings invite further examination to determine the full scope of ChatGPT-4's capabilities and its potential shortcomings in representing the full spectrum of social and political perspectives prevalent in society.	[Breazu, Petre] Univ Cambridge, Dept Theoret & Appl Linguist, Cambridge, England; [Katson, Napoleon] Univ Cambridge, Dept Theoret & Appl Linguist, Expt Pragmat, Cambridge, England; [Breazu, Petre] Univ Cambridge, 9 West Rd, Cambridge CB2 1TN, England	University of Cambridge; University of Cambridge; University of Cambridge	Breazu, P (corresponding author), Univ Cambridge, 9 West Rd, Cambridge CB2 1TN, England.	pb842@cam.ac.uk						[РЕЗАЕВ Андрей Владимирович Andrey V. REZAEV], 2018, [Мониторинг общественного мнения: экономические и социальные перемены, The monitoring of public opinion: economic & social changes, Monitoring obshchestvennogo mneniya: ekonomicheskie i sotsial'nye peremeny], P91, DOI 10.14515/monitoring.2018.5.10; Arguedas AR., 2023, Automating Democracy: Generative AI, Journalism, and the Future of Democracy; Arnorsson A, 2018, EUR J POLIT ECON, V55, P301, DOI 10.1016/j.ejpoleco.2018.02.001; Beckett C., 2023, Polis Blog; Biswas S., 2023, Journal of Alsalam University, V6, P39; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Breazu P., 2020, Representing the Roma in Romanian Media: A Multimodal Critical Discourse Analysis; Breazu P, 2023, DISCOURSE CONTEXT ME, V55, DOI 10.1016/j.dcm.2023.100718; Breazu P, 2023, SOC SEMIOT, DOI 10.1080/10350330.2023.2165907; Budzianowski P., 2019, arXiv preprint arXiv, V1907, P05774; Burger B, 2023, EUR J INNOV MANAG, V26, P233, DOI 10.1108/EJIM-02-2023-0156; Cao Y., 2023, arXiv preprint arXiv, V2303, P04226; Cuartielles R, 2023, PROF INFORM, V32, DOI 10.3145/epi.2023.sep.15; Fairclough N, 2013, CRIT POLICY STUD, V7, P177, DOI 10.1080/19460171.2013.798239; Fernandez Peter, 2023, Library Hi Tech News, P11, DOI 10.1108/LHTN-02-2023-0017; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Flowerdew J., 2018, ROUTLEDGE HDB CRITIC, DOI [10.4324/9781315739342, DOI 10.4324/9781315739342]; Foucault M., 1972, ARCHAEOLOGY KNOWLEDG; Fui-Hoon Nah F, 2023, J. Inf. Technol. Case Appl. Res, V25, P277, DOI [DOI 10.1080/15228053.2023.2233814, 10.1080/15228053.2023.2233814]; Gondwe G., 2023, Exploring the multifaceted nature of generative AI in journalism studies: A typology of scholarly definitions; Gozalo-Brizuela R., 2023, arXiv; Gross N, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12080435; Guo ZS, 2023, Arxiv, DOI arXiv:2310.19736; Hadi MU, 2023, PREPRINT; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Heaven W., 2023, MIT Technology Review, V10; Hoes E., 2023, PsyArXiv; Hofstede G. J., 2021, Review of Artificial Societies and Social Simulation; Leiser M.R., 2022, Artificial Intelligence and the Media Reconsidering Rights and Responsibilities, P8, DOI [10.4337/9781839109973.00007, DOI 10.4337/9781839109973.00007]; Marconi F., 2020, Newsmakers: Artificial intelligence and the future of journalism; Nishal S, 2024, Arxiv, DOI arXiv:2402.18835; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Richardson J.E., 2007, An approach from critical discourse analysis, DOI 10.1007/978-0-230-20968-8_3; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rzepnikowska A, 2019, J ETHN MIGR STUD, V45, P61, DOI 10.1080/1369183X.2018.1451308; Saetra HS, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102372; van Dijk T.A., 2015, RACISM PRESS; van Leeuwen T., 2008, Discourse and Practice: New Tools for Critical Discourse Analysis; Van Leeuwen T., 2013, Texts and practices, P41; Vaswani A, 2017, ADV NEUR IN, V30; Wang S., 2021, arXiv; Yang J., 2023, ACM Transactions on Knowledge Discovery from Data, V18, P1; Zagorulko D., 2023, ChatGPT in newsrooms: Adherence of AI-generated content to journalism standards and prospects for its implementation in digital media, V34, P73; Zarifhonarvar A., 2023, Economics of ChatGPT: A labor market view on the occupational impact of artificial intelligence; Zhang CN, 2023, Arxiv, DOI arXiv:2303.11717; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	48	0	0	16	16	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0957-9265	1460-3624		DISCOURSE SOC	niscl. Soc.	2024 MAY 21	2024										10.1177/09579265241251479	http://dx.doi.org/10.1177/09579265241251479		MAY 2024	21	Communication; Psychology, Multidisciplinary; Sociology	Social Science Citation Index (SSCI)	Communication; Psychology; Sociology	RM6L7		hybrid			2024-07-03	WOS:001228118600001
J	Gangwal, A; Ansari, A; Ahmad, I; Azad, A; Kumarasamy, V; Subramaniyan, V; Wong, LS				Gangwal, Amit; Ansari, Azim; Ahmad, Iqrar; Azad, Abul Kalam; Kumarasamy, Vinoth; Subramaniyan, Vetriselvan; Wong, Ling Shing			Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities	FRONTIERS IN PHARMACOLOGY			English	Review						ChatGPT; de novo drug design; deep generative models; AlphaFold; variational autoencoders; generative adversarial network; large language models; chemical language models	DE-NOVO GENERATION; NEURAL-NETWORKS; LANGUAGE MODELS; INTERACTION PREDICTION; MOLECULAR GENERATION; CHEMICAL LANGUAGE; LEARNING APPROACH; DESIGN; INFORMATION; REPRESENTATION	There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.	[Gangwal, Amit] Shri Vile Parle Kelavani Mandals Inst Pharm, Dept Nat Prod Chem, Dhule, Maharashtra, India; [Ansari, Azim] Comp Aided Drug Design Ctr Shri Vile Parle Kelavan, Dhule, Maharashtra, India; [Ahmad, Iqrar] Prof Ravindra Nikam Coll Pharm, Dept Pharmaceut Chem, Dhule, India; [Azad, Abul Kalam] Univ Coll MAIWP Int, Fac Pharm, Batu Caves, Malaysia; [Kumarasamy, Vinoth] Univ Kebangsaan Malaysia, Fac Med, Dept Parasitol & Med Entomol, Cheras, Malaysia; [Subramaniyan, Vetriselvan] Monash Univ Malaysia, Jeffrey Cheah Sch Med & Hlth Sci, Pharmacol Unit, Subang Jaya, Selangor, Malaysia; [Subramaniyan, Vetriselvan] Lovely Profess Univ, Sch Bioengn & Biosci, Phagwara, Punjab, India; [Wong, Ling Shing] INTI Int Univ, Fac Hlth & Life Sci, Nilai, Malaysia	Universiti Kebangsaan Malaysia; Monash University; Monash University Malaysia; Lovely Professional University; INTI International University	Gangwal, A (corresponding author), Shri Vile Parle Kelavani Mandals Inst Pharm, Dept Nat Prod Chem, Dhule, Maharashtra, India.; Azad, A (corresponding author), Univ Coll MAIWP Int, Fac Pharm, Batu Caves, Malaysia.; Kumarasamy, V (corresponding author), Univ Kebangsaan Malaysia, Fac Med, Dept Parasitol & Med Entomol, Cheras, Malaysia.; Subramaniyan, V (corresponding author), Monash Univ Malaysia, Jeffrey Cheah Sch Med & Hlth Sci, Pharmacol Unit, Subang Jaya, Selangor, Malaysia.; Subramaniyan, V (corresponding author), Lovely Profess Univ, Sch Bioengn & Biosci, Phagwara, Punjab, India.	gangwal.amit@gmail.com; vinoth@ukm.edu.my; azad2011iium@gmail.com; subramaniyan.vetriselvan@monash.edu	Azad, Abul/AAN-6501-2020; Bhardwaj, Arvind Kumar/JVP-0040-2024	Azad, Abul/0000-0003-4874-1169; Bhardwaj, Arvind Kumar/0009-0005-9682-6855; Gangwal, Amit/0000-0003-3228-5437				Abdel-Aty H, 2022, J CHEM INF MODEL, V62, P4852, DOI 10.1021/acs.jcim.2c00715; Adcreviews, 2023, The-worlds-first-ai-designed-drug-has-stopped-research-and-development; Aliper A, 2016, MOL PHARMACEUT, V13, P2524, DOI 10.1021/acs.molpharmaceut.6b00248; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, Businesswire; Arús-Pous J, 2019, J CHEMINFORMATICS, V11, DOI 10.1186/s13321-019-0393-0; Bagal V, 2022, J CHEM INF MODEL, V62, P2064, DOI 10.1021/acs.jcim.1c00600; Bai QF, 2022, WIRES COMPUT MOL SCI, V12, DOI 10.1002/wcms.1581; Bai QF, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa161; Baillif B, 2023, CURR OPIN STRUC BIOL, V80, DOI 10.1016/j.sbi.2023.102566; Bb I, 2023, Insilico medicine recives FDA IND approval to initiate clinical trials with USP1 program; Bender A, 2020, DRUG DISCOV TODAY, V26, P511, DOI 10.1016/j.drudis.2020.12.009; Benevolenet, 2023, BEN-2293-a topical best-in-class PanTrk inhibitor in development to relieve inflammation and rapidly resolve itch in patients with atopic dermatitis (AD): phase IIa data currently under evaluation; Benevolent, 2023, Neuroscience institute; BenevolentAI, 2023, Inconclusive efficacy of BenevolentAI's AD drug leaves the company guessing; Besnard J, 2022, CANCER RES, V82; Bess A, 2022, DRUG DISCOV TODAY, V27, P1099, DOI 10.1016/j.drudis.2021.10.022; Bian YM, 2019, MOL PHARMACEUT, V16, P4451, DOI 10.1021/acs.molpharmaceut.9b00500; Bickerton GR, 2012, NAT CHEM, V4, P90, DOI [10.1038/NCHEM.1243, 10.1038/nchem.1243]; Bjerrum E. J., 2017, arXiv; Blaschke T, 2020, J CHEM INF MODEL, V60, P5918, DOI 10.1021/acs.jcim.0c00915; Blaschke T, 2018, MOL INFORM, V37, DOI 10.1002/minf.201700123; Bohacek RS, 1996, MED RES REV, V16, P3, DOI 10.1002/(SICI)1098-1128(199601)16:1<3::AID-MED1>3.0.CO;2-6; Bondy J. A., 1976, Graph theory with applications; Bradshaw J, 2019, ADV NEUR IN, V32; Bralley P, 1996, BIOSCIENCE, V46, P146, DOI 10.2307/1312817; Brown N, 2019, J CHEM INF MODEL, V59, P1096, DOI 10.1021/acs.jcim.8b00839; Burki T, 2020, LANCET DIGIT HEALTH, V2, pE226, DOI 10.1016/S2589-7500(20)30088-1; Businesswire, 2023, Exscientia-exscientia. Exscientia announces first-in-human study for bristol myers squibb in-licensed PKC theta inhibitor E; Businesswire, 2022, Verge-genomics-initiates; Chakraborty C, 2023, MOL THER-NUCL ACIDS, V33, P866, DOI 10.1016/j.omtn.2023.08.009; Chao XR, 2018, EUR J OPER RES, V265, P239, DOI 10.1016/j.ejor.2017.07.030; Chen JX, 2016, COMPUT SCI ENG, V18, P4, DOI 10.1109/MCSE.2016.74; Chen W, 2023, MOL THER-NUCL ACIDS, V31, P691, DOI 10.1016/j.omtn.2023.02.019; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Cho KYHY, 2014, Arxiv, DOI [arXiv:1409.1259, DOI 10.48550/ARXIV.1409.1259, 10.48550/arXiv.1409.1259]; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Clinicaltrialsarena, 2023, Benevolentai-atopic-dermatitis-ad; Coeckelbergh M, 2020, SCI ENG ETHICS, V26, P2051, DOI 10.1007/s11948-019-00146-8; Collins GS, 2019, LANCET, V393, P1577, DOI 10.1016/S0140-6736(19)30037-6; Company Bap, 2022, The world's first Ai-designed drug has stopped research and development; David L, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00460-5; De Cao N, 2018, Arxiv, DOI [arXiv:1805.11973, 10.48550/arXiv.1805.11973]; Dehghan A, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120754; DeLano WL., 2002, CCP4 Newsl Protein Crystallogr, V40, P82; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DiMasi JA, 2016, J HEALTH ECON, V47, P20, DOI 10.1016/j.jhealeco.2016.01.012; Doersch C, 2021, Arxiv, DOI arXiv:1606.05908; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Drugdiscoveryonline, 2022, Canmolecular modeling-overcome-the-limitations-of-drug-discoveryai; Elton DC, 2019, MOL SYST DES ENG, V4, P828, DOI 10.1039/c9me00039a; Eurekalert, 2023, Insilico advances anti-tumor drug to Phase I, marking first clinical milestone in Fosun Pharma collaboration.; Exscientia S. S., 2023, Announces sixth molecule created through generative AI platform to enter clinical stage; Fellows M, 2019, ADV NEUR IN, V32; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Gao WH, 2020, J CHEM INF MODEL, V60, P5714, DOI 10.1021/acs.jcim.0c00174; Gao Wenhao., 2022, Advances in neural information processing systems, V35, P21342, DOI DOI 10.48550/ARXIV.2206.12411; Gogineni T., 2020, Advances in Neural Information Processing Systems, V33, P20142; Goldman B, 2022, J MED CHEM, V65, P7073, DOI 10.1021/acs.jmedchem.2c00334; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Graff DE, 2021, CHEM SCI, V12, P7866, DOI 10.1039/d0sc06805e; Grisoni F, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg3338; Grisoni F, 2020, J CHEM INF MODEL, V60, P1175, DOI 10.1021/acs.jcim.9b00943; Guimaraes GL, 2018, Arxiv, DOI [arXiv:1705.10843, 10.48550/arXiv.1705.10843, DOI 10.48550/ARXIV.1705.10843]; Gupta Anvita, 2018, Mol Inform, V37, DOI 10.1002/minf.201880141; Hanwell MD, 2012, J CHEMINFORMATICS, V4, DOI 10.1186/1758-2946-4-17; Harel S, 2018, MOL PHARMACEUT, V15, P4406, DOI 10.1021/acs.molpharmaceut.8b00474; Hassan-Harrirou H, 2020, J CHEM INF MODEL, V60, P2791, DOI 10.1021/acs.jcim.0c00075; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hester T, 2017, Arxiv, DOI arXiv:1704.03732; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094; Holcomb SD, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON BIG DATA AND EDUCATION (ICBDE 2018), P67, DOI 10.1145/3206157.3206174; Horgan D, 2018, Arxiv, DOI arXiv:1803.00933; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang KX, 2020, BIOINFORMATICS, V36, P5545, DOI 10.1093/bioinformatics/btaa1005; Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5; Bjerrum EJ, 2017, Arxiv, DOI arXiv:1703.07076; Jastrzebski S, 2018, Arxiv, DOI [arXiv:1602.06289, 10.48550/ARXIV.1602.06289]; Jayatunga MKP, 2022, NAT REV DRUG DISCOV, V21, P174, DOI 10.1038/d41573-022-00025-1; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang DJ, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-020-00479-8; Jin BW, 2024, Arxiv, DOI [arXiv:2312.02783, 10.48550/arXiv.2312.02783]; Jin W., 2023, PMLR, P4839, DOI [10.48550/arXiv.2002.03230, DOI 10.48550/ARXIV.2002.03230]; Jin W., 2023, PMLR, P4849, DOI [10.48550/arXiv.2002.03244, DOI 10.48550/ARXIV.2002.03244]; Jorgensen PB, 2018, MOL INFORM, V37, DOI 10.1002/minf.201700133; Kadurin A, 2017, MOL PHARMACEUT, V14, P3098, DOI 10.1021/acs.molpharmaceut.7b00346; Kadurin A, 2017, ONCOTARGET, V8, P10883, DOI 10.18632/oncotarget.14073; Kang S, 2019, J CHEM INF MODEL, V59, P43, DOI 10.1021/acs.jcim.8b00263; Karpov P, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00423-w; Kirkpatrick P., 2022, Biopharma Deal, V2022, pd4374702200104, DOI [10.1038/d43747-022-00104-7, DOI 10.1038/D43747-022-00104-7]; Korshunova M., 2021, ChemRxiv, DOI [10.26434/chemrxiv.14045072.v1, DOI 10.26434/CHEMRXIV.14045072.V1]; Kotsias PC, 2020, NAT MACH INTELL, V2, P254, DOI 10.1038/s42256-020-0174-5; Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kusner MJ, 2017, Arxiv, DOI [arXiv:1703.01925, 10.48550/arXiv.1703.01925, DOI 10.48550/ARXIV.1703.01925]; Kwapien K, 2022, ACS OMEGA, V7, P26573, DOI 10.1021/acsomega.2c02738; Kwon Y, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21228424; Kwon Y, 2019, J CHEMINFORMATICS, V11, DOI 10.1186/s13321-019-0396-x; Lavecchia A, 2019, DRUG DISCOV TODAY, V24, P2017, DOI 10.1016/j.drudis.2019.07.006; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee I, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007129; Lennox M, 2021, IEEE ENG MED BIO, P4348, DOI 10.1109/EMBC46164.2021.9629695; Levy D., 2023, Molecular fragment-based diffusion model for drug discovery; Li FX, 2018, IEEE POWER ENERGY M, V16, P76, DOI 10.1109/MPE.2017.2779554; Li GH, 2020, Arxiv, DOI arXiv:2006.07739; Li X, 2018, MOL PHARMACEUT, V15, P4336, DOI 10.1021/acs.molpharmaceut.8b00110; Li XY, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00446-3; Li Y., 2023, bioRxiv, P2023; Li YB, 2020, J CHEM INF MODEL, V60, P77, DOI 10.1021/acs.jcim.9b00727; Li YB, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0287-6; Lim J, 2020, CHEM SCI, V11, P1153, DOI 10.1039/c9sc04503a; Lin E, 2020, MOLECULES, V25, DOI 10.3390/molecules25143250; Liu K, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20143389; Liu Q, 2018, PHYTOKEYS, P31, DOI 10.3897/phytokeys.94.21337; Liu XH, 2021, METHODS MOL BIOL, V2190, P139, DOI 10.1007/978-1-0716-0826-5_6; Liu ZC, 2021, DRUG DISCOV TODAY, V26, P2593, DOI 10.1016/j.drudis.2021.06.009; Lyu J, 2019, NATURE, V566, P224, DOI 10.1038/s41586-019-0917-9; Macrae CF, 2020, J APPL CRYSTALLOGR, V53, P226, DOI 10.1107/S1600576719014092; Madhawa K, 2019, Arxiv, DOI arXiv:1905.11600; Mamoshina P, 2016, MOL PHARMACEUT, V13, P1445, DOI 10.1021/acs.molpharmaceut.5b00982; Mao JS, 2023, J CHEM INF MODEL, V64, P2733, DOI 10.1021/acs.jcim.3c00536; Martinelli DD, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105403; Méndez-Lucio O, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13807-w; Merk D, 2018, COMMUN CHEM, V1, DOI 10.1038/s42004-018-0068-1; Merk D, 2018, MOL INFORM, V37, DOI 10.1002/minf.201700153; Mita G., 2023, PMLR, P7769, DOI [10.48550/arXiv.2010.09360, DOI 10.48550/ARXIV.2010.09360]; MITNEW, 2023, Speeding up drug discovery with diffusion generative models; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Momma K, 2011, J APPL CRYSTALLOGR, V44, P1272, DOI 10.1107/S0021889811038970; Monteiro NRC, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105772; Moret M, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-022-35692-6; Moret M, 2021, ANGEW CHEM INT EDIT, V60, P19477, DOI 10.1002/anie.202104405; Mouchlis VD, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22041676; Mullard A, 2017, NATURE, V549, P445, DOI 10.1038/549445a; Nagra N. S., 2023, Biopharma Deal, DOI [10.1038/d43747-023-00020-4, DOI 10.1038/D43747-023-00020-4]; O'Boyle NM, 2012, J CHEMINFORMATICS, V4, DOI 10.1186/1758-2946-4-22; OBoyle N., 2018, ChemRxiv, DOI [DOI 10.26434/CHEMRXIV.7097960.V1, DOI 10.26434/CHEMRXIV.7097960, 10.26434/CHEMRXIV.7097960.V1]; Olivecrona M, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0235-x; OLUROTIMI O, 1994, IEEE T NEURAL NETWOR, V5, P185, DOI 10.1109/72.279184; Özçelik R, 2023, CHEMBIOCHEM, DOI 10.1002/cbic.202200776; ™zturk H, 2019, Arxiv, DOI [arXiv:1902.04166, 10.48550/arXiv.1902.04166, DOI 10.48550/ARXIV.1902.04166]; Öztürk H, 2020, DRUG DISCOV TODAY, V25, P689, DOI 10.1016/j.drudis.2020.01.020; Pal MK, 2018, IEEE INT C INTELL TR, P3287, DOI 10.1109/ITSC.2018.8569484; Palhamkhani F, 2023, J BIOMOL STRUCT DYN, DOI 10.1080/07391102.2023.2291829; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Paul SM, 2010, NAT REV DRUG DISCOV, V9, P203, DOI 10.1038/nrd3078; Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644; Polykovskiy D, 2018, MOL PHARMACEUT, V15, P4398, DOI 10.1021/acs.molpharmaceut.8b00839; Popova M, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aap7885; Preuer K, 2018, J CHEM INF MODEL, V58, P1736, DOI 10.1021/acs.jcim.8b00234; Pu LM, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1006718; Putin E, 2018, J CHEM INF MODEL, V58, P1194, DOI 10.1021/acs.jcim.7b00690; Rafiei F, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad438; Reang J., 2023, Informatics: tools and databases in drug discovery. CADD and informatics in drug discovery, P53; Ren F, 2023, CHEM SCI, V14, P1443, DOI 10.1039/d2sc05709c; Renz Philipp, 2019, Drug Discov Today Technol, V32-33, P55, DOI 10.1016/j.ddtec.2020.09.003; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Richardson P, 2020, LANCET, V395, pE30, DOI 10.1016/S0140-6736(20)30304-4; Rifaioglu AS, 2020, CHEM SCI, V11, P2531, DOI 10.1039/c9sc03414e; Russin J, 2019, Arxiv, DOI arXiv:1904.09708; Salakhutdinov R, 2015, ANNU REV STAT APPL, V2, P361, DOI 10.1146/annurev-statistics-010814-020120; Samanta B, 2020, J MACH LEARN RES, V21; Sanchez-Lengeling B., 2017, ChemRxiv, DOI [DOI 10.26434/CHEMRXIV.5309668.V3, 10.26434/CHEMRXIV.5309668.V3]; Sattarov B, 2019, J CHEM INF MODEL, V59, P1182, DOI 10.1021/acs.jcim.8b00751; Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232; Segler MHS, 2018, ACS CENTRAL SCI, V4, P120, DOI 10.1021/acscentsci.7b00512; Service R. F., 2020, 'The game has changed.'AI triumphs at protein folding; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Shi Y, 2021, J LIQ CHROMATOGR R T, V44, P519, DOI 10.1080/10826076.2021.1968896; Shimizu H, 2022, ISCIENCE, V25, DOI 10.1016/j.isci.2022.105314; Shin B., 2019, MACHINE LEARNING HEA, P230, DOI DOI 10.48550/ARXIV.1908.06760; Simm G., 2023, PMLR, P8959, DOI [10.48550/arXiv.2002.07717, DOI 10.48550/ARXIV.2002.07717]; Simonovsky M, 2023, Graphvae: towards generation of small graphs using variational autoencoders, P412; Singh S, 2017, NATURE, V550, P336, DOI 10.1038/550336a; Skalic M, 2019, MOL PHARMACEUT, V16, P4282, DOI 10.1021/acs.molpharmaceut.9b00634; Skalic M, 2019, J CHEM INF MODEL, V59, P1205, DOI 10.1021/acs.jcim.8b00706; Skinnider MA, 2021, NAT MACH INTELL, V3, P759, DOI 10.1038/s42256-021-00368-1; Sriram A, 2017, Arxiv, DOI arXiv:1708.06426; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021; Su JL, 2018, Arxiv, DOI arXiv:1807.05936; Sun MY, 2020, BRIEF BIOINFORM, V21, P919, DOI 10.1093/bib/bbz042; Sunseri J, 2020, J CHEM INF MODEL, V60, P1079, DOI 10.1021/acs.jcim.9b01145; Suresh N, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269461; Sussman JL, 1998, ACTA CRYSTALLOGR D, V54, P1078, DOI 10.1107/S0907444998009378; Taly A, 2019, INTERFACE FOCUS, V9, DOI [10.1098/rsfs.2018.0065, 10.6084/m9.figshare.c.4410101]; Tang BW, 2022, BIOMOLECULES, V12, DOI 10.3390/biom12060746; Tang BW, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-0414-z; Thierer AdamD., 2017, ARTIF INTELL; Townshend RJL, 2022, Arxiv, DOI [arXiv:2012.04035, 10.48550/arXiv.2012.04035]; Tripathi S., 2022, Artif Intell Life Sci, V2, P100045, DOI [10.1016/j.ailsci.2022.100045, DOI 10.1016/J.AILSCI.2022.100045]; van Deursen R, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00425-8; van Otterlo M, 2012, ADAPT LEARN OPTIM, V12, P3; van Tilborg D, 2022, J CHEM INF MODEL, V62, P5938, DOI 10.1021/acs.jcim.2c01073; Vaswani A, 2017, ADV NEUR IN, V30; Vázquez-Canteli JR, 2019, APPL ENERG, V235, P1072, DOI 10.1016/j.apenergy.2018.11.002; Volkov M, 2022, J MED CHEM, V65, P7946, DOI 10.1021/acs.jmedchem.2c00487; von Ungern-Sternberg A., 2017, Research handbook on the law of artificial intelligence; Wang RX, 2005, J MED CHEM, V48, P4111, DOI 10.1021/jm048957q; WEININGER D, 1989, J CHEM INF COMP SCI, V29, P97, DOI 10.1021/ci00062a008; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Weng LL, 2019, Arxiv, DOI arXiv:1904.08994; WISWESSER WJ, 1985, J CHEM INF COMP SCI, V25, P258, DOI 10.1021/ci00047a023; Wu JS, 2022, COMPUT BIOL CHEM, V98, DOI 10.1016/j.compbiolchem.2022.107664; Xia Xiaolin, 2019, Drug Discov Today Technol, V32-33, P45, DOI 10.1016/j.ddtec.2020.11.004; Xiao SY, 2023, SPAT STAT-NETH, V57, DOI 10.1016/j.spasta.2023.100766; Xiong JC, 2021, DRUG DISCOV TODAY, V26, P1382, DOI 10.1016/j.drudis.2021.02.011; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yu LT, 2017, Arxiv, DOI [arXiv:1609.05473, DOI 10.48550/ARXIV.1609.05473, 10.48550/ARXIV.1609.05473]; Yu Y, 2023, ACS MED CHEM LETT, V14, P297, DOI 10.1021/acsmedchemlett.2c00515; Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199; Yuan W, 2017, J CHEM INF MODEL, V57, P875, DOI 10.1021/acs.jcim.6b00754; Zang CX, 2020, Arxiv, DOI arXiv:2006.10137; Zhang Y., 2023, Gastroenterology Endosc, V1, P139, DOI [10.3390/cancers16010139, DOI 10.3390/CANCERS16010139]; Zhavoronkov A, 2019, NAT BIOTECHNOL, V37, P1038, DOI 10.1038/s41587-019-0224-x; Zhou ZP, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47148-x; Zhu H, 2018, IEEE NETWORK, V32, P50, DOI 10.1109/MNET.2018.1800109; 2018, INT C MACHINE LEARNI, P2323, DOI DOI 10.1039/9781788016841-00228	223	0	1	46	46	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		1663-9812		FRONT PHARMACOL	Front. Pharmacol.	FEB 7	2024	15								1331062	10.3389/fphar.2024.1331062	http://dx.doi.org/10.3389/fphar.2024.1331062			26	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	IE8G1	38384298	Green Published, gold			2024-07-03	WOS:001164736100001
J	Acharya, S; Das, B; Sudarshan, TSB				Acharya, Sathwik; Das, Bhaskarjyoti; Sudarshan, T. S. B.			Capturing the Concept Projection in Metaphorical Memes for Downstream Learning Tasks	IEEE ACCESS			English	Article						Memes; metaphor; concept projection; cognitive computing; multimodal machine learning; knowledge graph; large language models	LANGUAGE	Metaphorical memes, where a source concept is projected into a target concept, are an essential construct in figurative language. In this article, we present a novel approach for downstream learning tasks on metaphorical multimodal memes. Our proposed framework replaces traditional methods using metaphor annotations with a metaphor-capturing mechanism. Besides using the significant zero-shot learning capability of state-of-the-art pretrained encoders, this work introduces an alternative external knowledge enhancement strategy based on ChatGPT (chatbot generative pretrained transformer), demonstrating its effectiveness in bridging the intermodal semantic gap. We propose a new concept projection process consisting of three distinct components to capture the intramodal knowledge and intermodal concept gap in the forms of text modality embedding, visual modality embedding, and concept projection embedding. This approach leverages the attention mechanism of the Graph Attention Network for fusing the common aspects of external knowledge related to the knowledge in the text and image modality to implement the concept projection process. Our experimental results demonstrate the superiority of our proposed approach compared to existing methods.	[Acharya, Sathwik; Sudarshan, T. S. B.] PES Univ, Dept Comp Sci & Engn, Bengaluru 560085, Karnataka, India; [Das, Bhaskarjyoti] PES Univ, Dept Comp Sci & Engn AI & ML, Bengaluru 560085, Karnataka, India	PES University; PES University	Das, B (corresponding author), PES Univ, Dept Comp Sci & Engn AI & ML, Bengaluru 560085, Karnataka, India.	Bhaskarjyoti01@gmail.com		Das, Bhaskarjyoti/0000-0003-1225-9354; TSB, Sudarshan/0000-0001-9032-7389				Abulaish M, 2020, ACM T WEB, V14, DOI 10.1145/3375547; Afridi Tariq Habib, 2021, Innovations in Smart Cities Applications. Proceedings of the 5th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (LNNS 183), P1451, DOI 10.1007/978-3-030-66840-2_109; Akula AR, 2023, PROC CVPR IEEE, P23201, DOI 10.1109/CVPR52729.2023.02222; [Anonymous], 2017, STAT-US, V1050; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Chauhan DS, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P281; Chen JY, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1295, DOI 10.1145/3394486.3403182; Chen YX, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2897, DOI 10.1145/3485447.3511968; Cheng ZJ, 2022, IEEE ACM T COMPUT BI, V19, P2208, DOI 10.1109/TCBB.2021.3077905; Crisp P, 2007, METAPHOR SYMBOL, V22, P1; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Dai WL, 2021, Arxiv, DOI arXiv:2104.11560; Das A, 2020, Arxiv, DOI arXiv:2012.14891; Das B., 2023, Online Social Netw. Media, V34; Diaz GO, 2020, AAAI CONF ARTIF INTE, V34, P13550; Dimitrov D., 2021, arXiv; Dresner E, 2010, COMMUN THEOR, V20, P249, DOI 10.1111/j.1468-2885.2010.01362.x; Elkhatib Y., 2021, PROC MISINFO WORKSHO; Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, DOI 10.48550/ARXIV.1903.02428]; Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025; Geng BZ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1229, DOI 10.1145/3404835.3462902; Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Hameleers M, 2020, POLIT COMMUN, V37, P281, DOI 10.1080/10584609.2019.1674979; Hamilton WL, 2017, ADV NEUR IN, V30; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; Hebert L, 2022, 2022 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT, P9, DOI 10.1109/WI-IAT55865.2022.00012; Hee MS, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3651, DOI 10.1145/3485447.3512260; Huang L., 2020, COLING, P799; Jaiswal U. P., 2021, IEEE 8THUTTAR PRADES, P1; Jiang N, 2023, IEEE T KNOWL DATA EN, V35, P5865, DOI 10.1109/TKDE.2022.3174044; Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454; Kapadia P, 2023, COMPLEX NETWORKS 13, P83; Kennedy B, 2020, Arxiv, DOI arXiv:2005.02439; Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552; Kiela D., 2021, P ADV NEUR INF PROC, P2611; Kiela D, 2021, Arxiv, DOI arXiv:2005.04790; Kille B., 2021, PROC MEDIAEVAL, P1; Kiran A., 2022, Computational Intelligence and Data Analytics, P341; Kirk HR, 2021, Arxiv, DOI arXiv:2107.04313; Kong AB, 2023, Arxiv, DOI arXiv:2305.04490; Kougia V, 2023, Arxiv, DOI arXiv:2305.18391; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kruk J., 2019, arXiv; Kulkarni M, 2022, Arxiv, DOI arXiv:2112.08547; Kumari R, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115412; Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697; Lakoff G., 2008, Metaphors we live by; Lanyu Shang, 2021, 2021 IEEE 17th International Conference on eScience (eScience), P186, DOI 10.1109/eScience51609.2021.00029; Li DX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3, P31; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li Y., 2021, arXiv; Li YY, 2020, J MARKETING RES, V57, P1, DOI 10.1177/0022243719881113; Li ZB, 2021, INT CONF ASIAN LANG, P346, DOI 10.1109/IALP54817.2021.9675255; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin Z., 2022, P 29 INT C COMP LING, P7124; Liu C., 2022, PROC C EMPIRICAL MET, P7069; Lou CW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1844, DOI 10.1145/3404835.3463061; Lu J., 2019, arXiv, DOI [DOI 10.48550/ARXIV.1908.02265, 10.48550/arXiv.1908.02265]; Lymperaiou M, 2023, Arxiv, DOI arXiv:2211.12328; Martínez-Cruz R, 2023, Arxiv, DOI arXiv:2304.14177; Matsumoto Hayato, 2021, 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), P19, DOI 10.1109/GCCE53005.2021.9621803; Mialon G, 2021, Arxiv, DOI arXiv:2006.12065; Min ER, 2022, Arxiv, DOI arXiv:2202.08455; Muennighoff N, 2020, Arxiv, DOI [arXiv:2012.07788, 10.48550/arXiv.2012.07788]; Namitha Seelam, 2023, 2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS), P1115, DOI 10.1109/ICICCS56967.2023.10142318; Narayanan A, 2017, Arxiv, DOI arXiv:1707.05005; Nikzad-Khasmakhi N., arXiv; Parcalabescu Letitia., 2021, arXiv; Patwa S., 2022, DE FACTIFY WORKSHOP; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Philip G, 2011, STUD CORPUS LINGUIST, V43, P1; Plepi J, 2021, Arxiv, DOI arXiv:2110.04001; Pranesh A., 2020, 4THLIFELONG MACH LEA; Qian SS, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P153, DOI 10.1145/3404835.3462871; Radford A, 2021, PR MACH LEARN RES, V139; Rai S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3373265; Rajesh S., 2023, PROC MULTIMEDIA EVAL; Richards I. A, 1965, The Philosophy of Rethoric; Sachan T, 2021, PR I-A I C AD S N A, P399, DOI 10.1145/3487351.3490965; Shang LY, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102664; Sharma C, 2020, Arxiv, DOI arXiv:2008.03781; Sharma Himanshu, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P325, DOI 10.1109/PARC49193.2020.236619; Sharma S, 2023, Arxiv, DOI arXiv:2301.11219; Sharma S, 2022, Arxiv, DOI arXiv:2205.04274; Shi YC, 2023, Arxiv, DOI arXiv:2305.03513; Singhal S., 2021, PROC ACM MULTIMEDIA, P1; Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437; Song DD, 2021, KNOWL-BASED SYST, V230, DOI 10.1016/j.knosys.2021.107408; Song MY, 2023, Arxiv, DOI arXiv:2303.13001; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Sudhakaran P., 2016, Asian Journal of Information Technology, V15, P1890; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Suryawanshi S., 2020, P 2 WORKSHOP TROLLIN, P32; Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]; Tan YM, 2023, Arxiv, DOI arXiv:2303.07992; Tauch C, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1560, DOI 10.1145/2968219.2968549; Tong XY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4673; Ubani S, 2023, Arxiv, DOI [arXiv:2304.14334, 10.48550/arXiv.2304.14334]; Wang JF, 2022, Arxiv, DOI arXiv:2205.14100; Wang S., 2021, arXiv; Wightman R., 2019, Pytorch image models; WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xing ZZ, 2023, ENERGY, V285, DOI 10.1016/j.energy.2023.128771; Xu B, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2887, DOI 10.1145/3477495.3532019; Xu Linhong, 2008, Journal of the China Society for Scientific and Technical Information, V27, P180; Xu P, 2023, IEEE T PATTERN ANAL, V45, P12113, DOI 10.1109/TPAMI.2023.3275156; Xue JX, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102610; Yan Y, 2023, IEEE T COGN DEV SYST, V15, P625, DOI 10.1109/TCDS.2022.3174209; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yosef R, 2023, Arxiv, DOI arXiv:2303.15445; Yue R., 2023, Inf.Fusion, V100; Zhang DY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3214; Zhang J., 2020, C EMPIRICAL METHODS, P1; Zhang WB, 2020, Arxiv, DOI arXiv:2012.04977; Zhao B, 2023, Arxiv, DOI arXiv:2305.06159; Zhong XY, 2020, Arxiv, DOI arXiv:2012.01002; Zhou X., 2021, P 59 ANN M ASS COMP, P7158; Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27; Zhou YJ, 2023, NEUROCOMPUTING, V544, DOI 10.1016/j.neucom.2023.126262	121	0	0	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						1250	1265		10.1109/ACCESS.2023.3347988	http://dx.doi.org/10.1109/ACCESS.2023.3347988			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	EF1O6		gold			2024-07-03	WOS:001137417300001
J	Mediboina, A; Badam, RK; Chodavarapu, S				Mediboina, Anjali; Badam, Rajani Kumari; Chodavarapu, Sailaja			Assessing the Accuracy of Information on Medication Abortion: A Comparative Analysis of ChatGPT and Google Bard AI	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						large language models; ethics; artificial intelligence; chatbots; patient information; medication abortion; google bardai; chatgpt	MIFEPRISTONE	Background and objective ChatGPT and Google Bard AI are widely used conversational chatbots, even in healthcare. While they have several strengths, they can generate seemingly correct but erroneous responses, warranting caution in medical contexts. In an era where access to abortion care is diminishing, patients may increasingly rely on online resources and AI-driven language models for information on medication abortions. In light of this, this study aimed to compare the accuracy and comprehensiveness of responses generated by ChatGPT 3.5 and Google Bard AI to medical queries about medication abortions. Methods Fourteen open-ended questions about medication abortion were formulated based on the Frequently Asked Questions (FAQs) from the National Abortion Federation (NAF) and the Reproductive Health Access Project (RHAP) websites. These questions were answered using ChatGPT version 3.5 and Google Bard AI on October 7, 2023. The accuracy of the responses was analyzed by cross-referencing the generated answers against the information provided by NAF and RHAP. Any discrepancies were further verified against the guidelines from the American Congress of Obstetricians and Gynecologists (ACOG). A rating scale used by Johnson et al. was employed for assessment, utilizing a 6-point Likert scale [ranging from 1 (completely incorrect) to 6 (correct)] to evaluate accuracy and a 3-point scale [ranging from 1 (incomplete) to 3 (comprehensive)] to assess completeness. Questions that did not yield answers were assigned a score of 0 and omitted from the correlation analysis. Data analysis and visualization were done using R Software version 4.3.1. Statistical significance was determined by employing Spearman's R and Mann-Whitney U tests. Results All questions were entered sequentially into both chatbots by the same author. On the initial attempt, ChatGPT successfully generated relevant responses for all questions, while Google Bard AI failed to provide answers for five questions. Repeating the same question in Google Bard AI yielded an answer for one; two were answered with different phrasing; and two remained unanswered despite rephrasing. ChatGPT showed a median accuracy score of 5 (mean: 5.26, SD: 0.73) and a median completeness score of 3 (mean: 2.57, SD: 0.51). It showed the highest accuracy score in six responses and the highest completeness score in eight responses. In contrast, Google Bard AI had a median accuracy score of 5 (mean: 4.5, SD: 2.03) and a median completeness score of 2 (mean: 2.14, SD: 1.03). It achieved the highest accuracy score in five responses and the highest completeness score in six responses. Spearman's correlation coefficient revealed no correlation between accuracy and completeness for ChatGPT (rs =-0.46771, p = 0.09171). However, Google Bard AI showed a marginally significant correlation (rs = 0.5738, p = 0.05108). Mann-Whitney U test indicated no statistically significant differences between ChatGPT and Google Bard AI concerning accuracy (U = 82, p>0.05) or completeness (U = 78, p>0.05). Conclusion While both chatbots showed similar levels of accuracy, minor errors were noted, pertaining to finer aspects that demand specialized knowledge of abortion care. This could explain the lack of a significant correlation between accuracy and completeness. Ultimately, AI-driven language models have the potential to provide information on medication abortions, but there is a need for continual refinement and oversight.	[Mediboina, Anjali] Alluri Sita Ramaraju Acad Med Sci, Community Med, Eluru, India; [Badam, Rajani Kumari] Sri Venkateswara Med Coll, Obstet & Gynaecol, Tirupati, India; [Chodavarapu, Sailaja] Govt Med Coll, Obstet & Gynaecol, Rajamahendravaram, India		Mediboina, A (corresponding author), Alluri Sita Ramaraju Acad Med Sci, Community Med, Eluru, India.	anjalimediboina@gmail.com		Mediboina, Anjali/0000-0002-4280-0693				Ahmed I., 2023, PREPRINT, DOI [10.36227/TECHRXIV.23536290.V2, DOI 10.36227/TECHRXIV.23536290.V2]; Ali R, 2023, NEUROSURGERY, V93, P1353, DOI 10.1227/neu.0000000000002632; [Anonymous], 2018, Meeting the sustainable development goals, P210; Cameron ST, 2012, CONTRACEPTION, V86, P67, DOI 10.1016/j.contraception.2011.11.010; Chen AM, 2004, AM J EPIDEMIOL, V160, P110, DOI 10.1093/aje/kwh182; Cheong RCT, 2024, EUR ARCH OTO-RHINO-L, V281, P985, DOI 10.1007/s00405-023-08319-9; Cohen AL, 2007, OBSTET GYNECOL, V110, P1027, DOI 10.1097/01.AOG.0000287291.19230.ba; Creinin MD, 2020, CONTRACEPTION, V102, P225, DOI 10.1016/j.contraception.2020.08.004; Deoghare S, 2024, INDIAN DERMATOL ONL, V15, P137, DOI 10.4103/idoj.idoj_77_23; Honkanen H, 2004, BJOG-INT J OBSTET GY, V111, P715, DOI 10.1111/j.1471-0528.2004.00153.x; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kerasidou Angeliki, 2021, J Oral Biol Craniofac Res, V11, P612, DOI 10.1016/j.jobcr.2021.09.004; Kulier R, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD002855.pub4; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Meera S, 2022, Artificial Intelligent Techniques for Wireless Communication and Networking, V7, P139, DOI [10.1002/9781119821809.ch10, DOI 10.1002/9781119821809.CH10]; Nasarian E, 2024, Arxiv, DOI arXiv:2311.11055; Oliver-Williams C, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001481; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Yang J, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4359424; Yokoe R, 2019, BMJ GLOB HEALTH, V4, DOI 10.1136/bmjgh-2019-001491	23	0	0	3	3	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JAN 2	2024	16	1							e51544	10.7759/cureus.51544	http://dx.doi.org/10.7759/cureus.51544			8	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	II4R3	38318564	gold			2024-07-03	WOS:001165689300005
J	Benbya, H; Strich, F; Tamm, T				Benbya, Hind; Strich, Franz; Tamm, Toomas			Navigating Generative Artificial Intelligence Promises and Perils for Knowledge and Creative Work	JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS			English	Article						Generative Artificial Intelligence; Creativity; Knowledge workers; knowledge management; Large Language Models; Research Agenda; Image Generation Models	SUPPORT-SYSTEMS; AI SYSTEMS; QUALITY	Generative artificial intelligence (GenAI) is rapidly becoming a viable tool to enhance productivity and act as a catalyst for innovation across various sectors. Its ability to perform tasks that have traditionally required human judgment and creativity is transforming knowledge and creative work. Yet it also raises concerns and implications that could reshape the very landscape of knowledge and creative work. In this editorial, we undertake an in-depth examination of both the opportunities and challenges presented by GenAI for future IS research.	[Benbya, Hind; Strich, Franz; Tamm, Toomas] Deakin Univ, Ctr Artificial Intelligence & Future Business, Geelong, Vic, Australia	Deakin University	Benbya, H (corresponding author), Deakin Univ, Ctr Artificial Intelligence & Future Business, Geelong, Vic, Australia.	h.benbya@deakin.edu.au; f.strich@deakin.edu.au; toomas.tamm@deakin.edu.au		Strich, Franz/0000-0002-0170-9025				Ali S., 2021, arXiv; Avital M, 2009, INFORM SYST J, V19, P345, DOI 10.1111/j.1365-2575.2007.00291.x; Avrahami O, 2021, Arxiv, DOI [arXiv:2112.01516, 10.48550/ARXIV.2112.01516, DOI 10.48550/ARXIV.2112.01516]; Benbya H, 2008, CHANDOS KNOWL MANAGE, P1; Benbya H, 2021, J ASSOC INF SYST, V22, P281, DOI 10.17705/1jais.00662; Benbya H, 2020, MIS Q EXEC, V19, pIX; Boden MA, 1998, ARTIF INTELL, V103, P347, DOI 10.1016/S0004-3702(98)00055-1; Bown O., 2012, COMPUTERS CREATIVITY, P361, DOI https://doi.org/10.1007/978-3-642-31727-9_14; Brea E, 2023, TECHNOVATION, V122, DOI 10.1016/j.technovation.2022.102643; Brynjolfsson E., 2023, NBER Working Paper No. 31161; Chemla-Romeu-Santos A, 2022, Arxiv, DOI arXiv:2211.08856; Chiarella SG, 2022, COMPUT HUM BEHAV, V137, DOI 10.1016/j.chb.2022.107406; Davenport T., 2005, THINKING LIVING; Davis JU, 2021, C&C'21: PROCEEDINGS OF THE 13TH CONFERENCE ON CREATIVITY AND COGNITION, DOI 10.1145/3450741.3465260; Dean DL, 2006, J ASSOC INF SYST, V7, P646, DOI 10.17705/1jais.00106; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; DiPaola S, 2018, PROCEDIA COMPUT SCI, V145, P158, DOI 10.1016/j.procs.2018.11.024; ELAM JJ, 1987, INFORM MANAGE, V13, P215, DOI 10.1016/0378-7206(87)90045-0; Elgammal A, 2019, AM SCI, V107, P18; Epstein Z, 2022, Arxiv, DOI arXiv:2206.00533; Eshraghian JK, 2020, NAT MACH INTELL, V2, P157, DOI 10.1038/s42256-020-0161-x; Forrest R., 2023, ComputerWeekly; Fügener A, 2021, MIS QUART, V45, P1527, DOI 10.25300/MISQ/2021/16553; Giermindl LM, 2022, EUR J INFORM SYST, V31, P410, DOI 10.1080/0960085X.2021.1927213; Grierson Jamie, 2023, the Guardian; Gurman M., 2023, BLOOMBERG; Haase J, 2023, Arxiv, DOI [arXiv:2303.12003, DOI 10.48550/ARXIV.2303.12003]; Hacker P, 2023, Arxiv, DOI [arXiv:2302.02337, DOI 10.48550/ARXIV.2302.02337, 10.48550/arXiv.2302.02337, DOI 10.48550/AR-XIV.2302.02337]; Haefner N, 2021, TECHNOL FORECAST SOC, V162, DOI 10.1016/j.techfore.2020.120392; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hong JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3326337; Jan Smits TB., 2022, Law and Artificial Intelligence Information Technology and Law Series, P323, DOI DOI 10.1007/978-94-6265-523-2; Jarrahi MH., 2023, MIT Sloan Management Review, V64, P1; Jarrahi MH, 2023, BUS HORIZONS, V66, P87, DOI 10.1016/j.bushor.2022.03.002; Jia N, 2024, ACAD MANAGE J, V67, P5, DOI 10.5465/amj.2022.0426; Kahn S., 2023, TED; Koster R, 2022, NAT HUM BEHAV, V6, P1398, DOI 10.1038/s41562-022-01383-x; Lamb C, 2017, J MATH ARTS, V11, P159, DOI 10.1080/17513472.2017.1373561; Lee JS, 2023, NAT COMPUT SCI, V3, P382, DOI 10.1038/s43588-023-00440-3; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lukpat A., 2023, The Wall Street Journal; Massetti B, 1996, MIS QUART, V20, P83, DOI 10.2307/249543; Mayer AS, 2020, MIS Q EXEC, V19, P239, DOI 10.17705/2msqe.00036; Mello G., 2023, Bloomberg; Mikalef P, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103434; Miller AI, 2020, AM SCI, V108, P244; Mohr J., 2023, Knowledge management, I'd like to introduce my new friend, generative AI; Morrow E, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.971044; Ni B, 2023, CHEM-US, V9, P1828, DOI 10.1016/j.chempr.2023.03.020; Oppenlaender Jonas, 2022, Academic Mindtrek 2022: 25th International Academic Mindtrek conference, P192, DOI 10.1145/3569219.3569352; Oppenlaender J, 2023, Arxiv, DOI arXiv:2303.13530; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Oppermann L, 2019, HALFWAY TO THE FUTURE SYMPOSIUM (HTTF 2019), DOI 10.1145/3363384.3363481; Oracle, 2020, As uncertainty remains, anxiety and stress reach a tipping point at work (AI@Work Study); Pedota M, 2022, CREAT INNOV MANAG, V31, P109, DOI 10.1111/caim.12468; Pilcicki R., 2022, P PAC AS C INF SYST; Raisch S, 2021, ACAD MANAGE REV, V46, P192, DOI 10.5465/amr.2018.0072; Renaud K., 2023, MIT Sloan Management Review, V64, P1; Roose Kevin, 2022, NEW YORK TIMES; Seeber I, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103174; Shneiderman B., 2020, AIS Transactions on Human-Computer Interaction, V12, P109, DOI DOI 10.17705/1THCI.00131; Siau K, 2020, J DATABASE MANAGE, V31, P74, DOI 10.4018/JDM.2020040105; Siemon D, 2022, COMMUN ASSOC INF SYS, V50, P241, DOI 10.17705/1CAIS.05009; Strich F, 2021, J ASSOC INF SYST, V22, P304, DOI 10.17705/1jais.00663; Sun LY, 2019, FRONT INFORM TECH EL, V20, P1644, DOI 10.1631/FITEE.1900386; Tarafdar M, 2023, INFORM SYST J, V33, P232, DOI 10.1111/isj.12389; Taylor J., 2023, GUARDIAN; Vasist PN, 2022, COMMUN ASSOC INF SYS, V51, P590, DOI 10.17705/1CAIS.05126; Vrontis D, 2022, INT J HUM RESOUR MAN, V33, P1237, DOI 10.1080/09585192.2020.1871398; Wierenga B, 1998, MIS QUART, V22, P81, DOI 10.2307/249679; Zhou L., 2021, AIS Trans Hum-Comput Interact, V13, P243, DOI [DOI 10.17705/1THCI.00149, 10.17705/1thci.00149]; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	72	0	0	71	71	ASSOC INFORMATION SYSTEMS	ATLANTA	GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA	1536-9323	1558-3457		J ASSOC INF SYST	J. Assoc. Inf. Syst.		2024	25	1			SI					10.17705/1jais.00861	http://dx.doi.org/10.17705/1jais.00861			15	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	LB5N1		Bronze			2024-07-03	WOS:001184331000006
J	Tate, S; Fouladvand, S; Chen, JH; Chen, CYA				Tate, Steven; Fouladvand, Sajjad; Chen, Jonathan H.; Chen, Chwen-Yuen Angie			The ChatGPT therapist will see you now: Navigating generative artificial intelligence's potential in addiction medicine research and patient care	ADDICTION			English	Editorial Material						artificial intelligence; automation; electronic health record data; evidence-based clinical practice; large language models; workflow optimization			[Tate, Steven] Stanford Univ, Dept Psychiat & Behav Sci, Sch Med, Palo Alto, CA USA; [Fouladvand, Sajjad; Chen, Jonathan H.; Chen, Chwen-Yuen Angie] Stanford Univ, Dept Med, Sch Med, Palo Alto, CA USA; [Tate, Steven] Stanford Univ, Sch Med, Dept Psychiat & Behav Sci, 401 Quarry Rd, Palo Alto, CA 94304 USA	Stanford University; Stanford University; Stanford University	Tate, S (corresponding author), Stanford Univ, Sch Med, Dept Psychiat & Behav Sci, 401 Quarry Rd, Palo Alto, CA 94304 USA.	tates@stanford.edu		Tate, Steven/0000-0001-9544-594X; Chen, Chwen-Yuen Angie/0000-0002-7207-598X	The project described was supported by Grant Number UG1 DA015815 from the National Institute on Drug Abuse (NIDA). Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institute on Dr [UG1 DA015815]; National Institute on Drug Abuse (NIDA)	The project described was supported by Grant Number UG1 DA015815 from the National Institute on Drug Abuse (NIDA). Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institute on Dr; National Institute on Drug Abuse (NIDA)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA))	The project described was supported by Grant Number UG1 DA015815 from the National Institute on Drug Abuse (NIDA). Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institute on Drug Abuse (NIDA) or NIH. We thank Anna Lembke for her comments on an early draft of this work.	Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Chen JH, 2017, NEW ENGL J MED, V376, P2507, DOI 10.1056/NEJMp1702071; Elicit, 2023, AI RES ASS; Fouladvand S., 2022, AMIA ANN S P, V2021, P476; Fouladvand S, 2023, IEEE J BIOMED HEALTH, V27, P3589, DOI 10.1109/JBHI.2023.3265920; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lopez Ivan., AMIA ANN S P; Microsoft, 2023, Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service; Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746; OpenAI, 2023, GPT 4 TECHNICAL REPO; Prochaska JJ, 2021, DRUG ALCOHOL DEPEN, V227, DOI 10.1016/j.drugalcdep.2021.108986; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Tyson A., 2023, 60 AM WOULD BE UNC P; Zhang X., 2023, arXiv	15	2	2	9	24	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0965-2140	1360-0443		ADDICTION	Addiction	DEC	2023	118	12					2249	2251		10.1111/add.16341	http://dx.doi.org/10.1111/add.16341		SEP 2023	3	Substance Abuse; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Substance Abuse; Psychiatry	X1RL0	37735091	Bronze			2024-07-03	WOS:001069351600001
J	Pticek, M; Dobsa, J				Pticek, Martina; Dobsa, Jasminka			Methods of Annotating and Identifying Metaphors in the Field of Natural Language Processing	FUTURE INTERNET			English	Review						metaphor; metaphor annotation; metaphor identification; neural networks; word embeddings; large language models		Metaphors are an integral and important part of human communication and greatly impact the way our thinking is formed and how we understand the world. The theory of the conceptual metaphor has shifted the focus of research from words to thinking, and also influenced research of the linguistic metaphor, which deals with the issue of how metaphors are expressed in language or speech. With the development of natural language processing over the past few decades, new methods and approaches to metaphor identification have been developed. The aim of the paper is to map the methods of annotating and identifying metaphors in the field of natural language processing and to give a systematic overview of how relevant linguistic theories and natural language processing intersect. The paper provides an outline of cognitive linguistic metaphor theory and an overview of relevant methods of annotating linguistic and conceptual metaphors as well as publicly available datasets. Identification methods are presented chronologically, from early approaches and hand-coded knowledge to statistical methods of machine learning and contemporary methods of using neural networks and contextual word embeddings.	[Pticek, Martina; Dobsa, Jasminka] Univ Zagreb, Fac Org & Informat, Varazhdin 42000, Croatia	University of Zagreb	Pticek, M (corresponding author), Univ Zagreb, Fac Org & Informat, Varazhdin 42000, Croatia.	marpticek@student.foi.hr; jasminka.dobsa@foi.hr		Dobsa, Jasminka/0000-0002-1684-1010				[Anonymous], 2007, P WORKSH COMP APPR F; [Anonymous], 2009, P 12 C EUR CHAPT ACL; [Anonymous], 2010, OXFORD HDB COGNITIVE; [Anonymous], 1963, AFIPS Conference Proceedings; Antloga S., 2020, Metaphor corpus KOMET 1.0; (Ben) Leong Chee Wee, 2018, P WORKSH FIG LANG PR, P56, DOI DOI 10.18653/V1/W18-0907; Bevilacqua M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2854; Birke J, 2006, 11 C EUROPEAN CHAPTE, P329; Bogetic K, 2019, CONV EVI LANG COMMUN, V22, P203, DOI 10.1075/celcr.22.10bog; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Bulat Luana, 2017, Short Papers, P523; Cameron L., 2003, METAPHOR ED DISCOURS; Chen XY, 2020, FIGURATIVE LANGUAGE PROCESSING, P235; Choi M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1763; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Crisp P, 2007, METAPHOR SYMBOL, V22, P1; Croft William., 2004, COGN LINGUIST; Dankers V, 2020, FIGURATIVE LANGUAGE PROCESSING, P227; Despot Strkalj K., 2014, METAFORE KOJE ISTRAZ, P63; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dinh Do, 2016, P 4 WORKSH MET NLP, P28, DOI [10.18653/v1/W16-1104, DOI 10.18653/V1/W16-1104]; Fass D., 1991, Computational Linguistics, V17, P49; Fauconnier G., 2003, WAY WE THINK CONCEPT; Feldman J, 2004, BRAIN LANG, V89, P385, DOI 10.1016/S0093-934X(03)00355-9; Fellbaum C, 1998, LANG SPEECH & COMMUN, P1; Gao G, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P607; Ge MS, 2022, AAAI CONF ARTIF INTE, P10681; Gong HY, 2020, FIGURATIVE LANGUAGE PROCESSING, P146; Grady J., 1997, Foundations of meaning: primary metaphor and primary scenes; Gutiérrez ED, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P183; Heintz Ilana, 2013, P 1 WORKSH MET NLP A, P58; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Johnson C.R., 1999, P CULT PSYCHOL TYP I; Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Karov Y, 1998, COMPUT LINGUIST, V24, P41; KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200; Krennmayr T., 2017, Handbook of Linguistic Annotation, P1053; Lakoff G., 1994, Master Metaphor List; Lakoff G., 2000, Where mathematics comes from: How the embodied mind brings mathematics into being; Lakoff George, 1980, METAPHORS WE LIVE BY; Lample G, 2019, Arxiv, DOI arXiv:1901.07291; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Leong CW, 2020, FIGURATIVE LANGUAGE PROCESSING, P18; Li Linlin., 2009, Proceedings of the 2009 Con- ference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, V1, P315, DOI 10.3115/1699510.1699552; Li YC, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1558; Lin ZX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3888; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mao R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3888; Mason ZJ, 2004, COMPUT LINGUIST, V30, P23, DOI 10.1162/089120104773633376; Maudslay R.H., 2022, P 29 INT C COMPUTATI, P65; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mohammad S., 2016, P 5 JOINT C LEX COMP, P23, DOI [10.18653/v1/S16-2003, DOI 10.18653/V1/S16-2003]; Mohler Michael, 2013, P 1 WORKSH MET NLP, P27; Mykowiecka Agnieszka, 2018, Proceedings of the Workshop on Figurative Language Processing, P124, DOI [DOI 10.18653/V1/W18-0916, 10.18653/v1/W18-0916]; Nacey S., 2019, Metaphor identification in multiple languages: MIPVU around the world; Neuman Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062343; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Rei Marek, 2017, P 2017 C EMP METH NA, P1537, DOI 10.18653/v1/D17-1162; Resnik P.S., 1993, IRCS9342 U PENNSYLVA; Shutova E., 2017, Handbook of linguistic annotation, P1073; Shutova E, 2015, COMPUT LINGUIST, V41, P579, DOI 10.1162/COLI_a_00233; Shutova E, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION; Shutova Ekaterina, 2016, P 2016 C N AM CHAPTE, P160, DOI 10.18653/V1/N16-1020; Shutova Ekaterina., 2010, P 23 INT C COMP LING, P1002; Song W, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4240; Steen G, 2010, A Method for Linguistic Metaphor Identification: from MIP to MIPVU, DOI 10.1075/celcr.14; Su CD, 2020, FIGURATIVE LANGUAGE PROCESSING, P30; Sullivan K, 2017, CAMB HB LANG LINGUIS, P385; Swarnkar K, 2018, Proceedings of the Workshop on Figurative Language Processing, P115, DOI DOI 10.18653/V1/W18-0914; Tsvetkov Y, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P248; Tsvetkov Yulia, 2013, P 1 WORKSH MET NLP A, P45; Turney Peter, 2011, P 2011 C EMPIRICAL M, P680; Vaswani A, 2017, ADV NEUR IN, V30; Wallington A.M., 2003, METAPHOR ANNOTATION; WILKS Y, 1978, ARTIF INTELL, V11, P197, DOI 10.1016/0004-3702(78)90001-2; WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8; Wilks Y., 2013, Proceedings of the First Workshop on Metaphor in NLP, P36; Wu C, 2018, P WORKSH FIG LANG PR, P110; Zhang S, 2022, P 29 INT C COMP LING, P4149	83	1	1	10	17	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	JUN	2023	15	6							201	10.3390/fi15060201	http://dx.doi.org/10.3390/fi15060201			28	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	K2UW3		gold			2024-07-03	WOS:001015051600001
J	Fear, K; Gleber, C				Fear, Kathleen; Gleber, Conrad			Shaping the Future of Older Adult Care: ChatGPT, Advanced AI, and the Transformation of Clinical Practice	JMIR AGING			English	Editorial Material						generative AI; artificial intelligence; large language models; ChatGPT; Generative Pre-trained Transformer		As the older adult population in the United States grows, new approaches to managing and streamlining clinical work are needed to accommodate their increased demand for health care. Deep learning and generative artificial intelligence (AI) have the potential to transform how care is delivered and how clinicians practice in geriatrics. In this editorial, we explore the opportunities and limitations of these technologies.	[Fear, Kathleen; Gleber, Conrad] Univ Rochester, Med Ctr, UR Hlth Lab, 30 Corporate Woods, Suite 180, Rochester, NY 14623 USA; [Gleber, Conrad] Univ Rochester, Med Ctr, Dept Med, Rochester, NY USA	University of Rochester; University of Rochester	Fear, K (corresponding author), Univ Rochester, Med Ctr, UR Hlth Lab, 30 Corporate Woods, Suite 180, Rochester, NY 14623 USA.	kathleen_fear@urmc.rochester.edu		Gleber, Conrad/0009-0005-8241-944X				Alessa A, 2023, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023, P667, DOI 10.1145/3594806.3596572; [Anonymous], 2023, Gpt-4 Technical Report; [Anonymous], 2023, Global Strategy on Human Resources for Health: workforce 2030: reporting at Seventy-fifth World Health Assembly; Asch DA, 2023, NEJM Catal Innov Care Deliv, V4; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bhattacharyya R., 2023, Journal of SAARC Psychiatric Federation, V1, P6; ChatGPT, about us; Diaz N., 2023, Becker's Health ITJun 2; Heinz MV, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231170499; Ismail AMA, 2023, ANN BIOMED ENG, V51, P2634, DOI 10.1007/s10439-023-03279-x; Mitra S., PREPRINT; Nandini Prasad KS, 2023, 2023 4 INT C EM TECH, P1, DOI [10.1109/incet57972.2023.10170114, DOI 10.1109/INCET57972.2023.10170114]; Nova K., 2023, J Adv Anal Healthc Manag, V7, P115; Qi X, 2023, NeurologyLiveJul 2; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Sinsky Christine A, 2021, Mayo Clin Proc Innov Qual Outcomes, V5, P1165, DOI 10.1016/j.mayocpiqo.2021.08.007; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Turner BEW, 2023, Modern HealthcareApr 17; Vespa J., 2020, DEMOGRAPHIC TURNING; Wang CY, 2023, medRxiv, DOI [10.1101/2023.06.27.23291884, 10.1101/2023.06.27.23291884, DOI 10.1101/2023.06.27.23291884]	21	2	2	23	33	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-7605		JMIR AGING	JMIR Aging		2023	6								e51776	10.2196/51776	http://dx.doi.org/10.2196/51776			3	Geriatrics & Gerontology; Gerontology; Medical Informatics	Emerging Sources Citation Index (ESCI)	Geriatrics & Gerontology; Medical Informatics	S4HE3	37703085	gold, Green Published			2024-07-03	WOS:001070786300001
J	Mármol-Romero, AM; García-Vega, M; García-Cumbreras, MA; Montejo-Ráez, A				Marmol-Romero, Alba Maria; Garcia-Vega, Manuel; Garcia-Cumbreras, Miguel angel; Montejo-Raez, Arturo			An Empathic GPT-Based Chatbot to Talk About Mental Disorders With Spanish Teenagers	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION			English	Article; Early Access						Dialogue systems; large language model; mental disorders; natural language generation; GPT-3; self-disclosure	COMMUNICATION	This article presents a chatbot-based system to engage young Spanish people in the awareness of certain mental disorders through a self-disclosure technique. The study was carried out in a population of teenagers aged between 12 and 18 years. The dialogue engine mixes closed and open conversations, so certain controlled messages are sent to focus the chat on a specific disorder, which will change over time. Once a set of trial questions is answered, the system can initiate the conversation on the disorder under the focus according to the user's sensibility to that disorder, in an attempt to establish a more empathetic communication. Then, an open conversation based on the GPT-3 language model is initiated, allowing the user to express themselves with more freedom. The results show that these systems are of interest to young people and could help them become aware of certain mental disorders.	[Marmol-Romero, Alba Maria; Garcia-Vega, Manuel; Garcia-Cumbreras, Miguel angel; Montejo-Raez, Arturo] Univ Jaen, CEATIC, Lagunillas S-N, Jaen, Spain	Universidad de Jaen	Mármol-Romero, AM (corresponding author), Univ Jaen, CEATIC, Lagunillas S-N, Jaen, Spain.	amarmol@ujaen.es	Montejo-Raez, Arturo/D-3387-2009	Montejo-Raez, Arturo/0000-0002-8643-2714; Marmol Romero, Alba Maria/0000-0001-7952-4541	Andalusian Regional Government	Andalusian Regional Government	No Statement Available	Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Ahmed A, 2023, HEALTH INFORM J, V29, DOI 10.1177/14604582221146719; Altman I., 1973, SOCIAL PENETRATION D; [Anonymous], 2023, Youth Risk Behavior Survey Data Summary Trends Report: 2011-2021; Balaskas A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248152; Brown T. B., 2020, P 34 INT C NEUR INF, V159; Carpenter A., 2016, INT ENCY INTERPERSON, P1, DOI DOI 10.1002/9781118540190.WBEIC160; Chen LL, 2021, ADV NEUR IN, V34; Chow JCL, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11172417; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Coghlan S, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231183542; COLBY KM, 1981, BEHAV BRAIN SCI, V4, P515, DOI 10.1017/S0140525X00000030; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Garrido-Muñoz I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073184; HALL JA, 1995, APPL PREV PSYCHOL, V4, P21, DOI 10.1016/S0962-1849(05)80049-6; Hawes MT, 2022, PSYCHOL MED, V52, P3222, DOI 10.1017/S0033291720005358; Hill CT., 1987, SELF DISCLOSURE, P81, DOI DOI 10.1007/978-1-4899-3523-6_5; Hollon S.D., 2013, BERGIN GARFIELDS HDB, V6th, P393; Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058; Huang SH, 2023, Arxiv, DOI arXiv:2302.14045; Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106; Jain Y., 2020, 2020 4 INT C EL COMM, P786, DOI [https://doi.org/10.1109/ICECA49313.2020.9297447, DOI 10.1109/ICECA49313.2020.9297447]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Luo MF, 2020, CURR OPIN PSYCHOL, V31, P110, DOI 10.1016/j.copsyc.2019.08.019; Mehrabian A., 1974, An approach to environmental psychology; Open AI, 2023, GPT-4 technical report; PILKINGTON CJ, 1993, J MARRIAGE FAM, V55, P1056, DOI 10.2307/352796; Schick T., 2023, arXiv; Shuster K, 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.07567; Siddique S., 2021, Encyclopedia, V1, P220, DOI DOI 10.3390/ENCYCLOPEDIA1010021; Skjuve M., 2022, International Journal of Human-Computer Studies, V168, P102903, DOI DOI 10.1016/J.IJHCS.2022.102903; Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601; Sniadach J, 2021, LIFE-BASEL, V11, DOI 10.3390/life11111188; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Vallecillo-Rodriguez M. E., 2023, sinai-uja/textflow; Vaswani A, 2017, ADV NEUR IN, V30; Weiste E, 2014, PSYCHOTHER RES, V24, P687, DOI 10.1080/10503307.2013.879619; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; World Health Organization, 2022, World mental health report. Transforming mental health for All; Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836; Yu Q., 2019, 2019 CHI C HUM FACT, P1; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	45	0	0	4	4	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	1044-7318	1532-7590		INT J HUM-COMPUT INT	Int. J. Hum.-Comput. Interact.	2024 MAY 8	2024										10.1080/10447318.2024.2344355	http://dx.doi.org/10.1080/10447318.2024.2344355		MAY 2024	17	Computer Science, Cybernetics; Ergonomics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PT8R9					2024-07-03	WOS:001216432900001
J	Rundle, CW; Szeto, MD; Presley, CL; Shahwan, KT; Md, DRC				Rundle, Chandler W.; Szeto, Mindy D.; Presley, Colby L.; Shahwan, Kathryn T.; Md, David R. Carr			Analysis of ChatGPT generated differential diagnoses in response to physical exam findings for benign and malignant cutaneous neoplasms	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Letter						artificial intelligence; ChatGPT; cuta- neous oncology; large language models; ma- chine learning; neoplastic dermatology			[Rundle, Chandler W.] Duke Univ Hosp, Dept Dermatol, Durham, NC USA; [Szeto, Mindy D.] Univ Colorado, Dept Dermatol, Anschutz Med Campus, Aurora, CO USA; [Presley, Colby L.] Lehigh Valley Hlth, Div Dermatol, Allentown, PA USA; [Shahwan, Kathryn T.; Md, David R. Carr] Ohio State Univ, Med Ctr, Dept Dermatol, Columbus, OH USA; [Shahwan, Kathryn T.] Univ North Dakota, Dept Internal Med, Med Sch, Grand Forks, ND USA; [Shahwan, Kathryn T.] Altru Hlth Syst, Dept Dermatol, Grand Forks, ND USA; [Shahwan, Kathryn T.] 540 Officenter Pl,Ste 240, Gahanna, OH 43230 USA	Duke University; University of Colorado System; University of Colorado Anschutz Medical Campus; Lehigh Valley Health Network; University System of Ohio; Ohio State University; University of North Dakota Grand Forks	Shahwan, KT (corresponding author), 540 Officenter Pl,Ste 240, Gahanna, OH 43230 USA.	kathryn.shahwan@osumc.edu		Carr, David/0000-0002-9372-4627				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bolognia Jean., 2018, Dermatology; Hirani R, 2023, J AM ACAD DERMATOL, V89, pE127, DOI 10.1016/j.jaad.2023.04.045; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Young JN, 2023, J AM ACAD DERMATOL, V89, P602, DOI 10.1016/j.jaad.2023.05.024	5	0	0	3	3	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	MAR	2024	90	3					615	616		10.1016/j.jaad.2023.10.040	http://dx.doi.org/10.1016/j.jaad.2023.10.040		FEB 2024	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	JF0G6	37898341	hybrid			2024-07-03	WOS:001171626100001
J	Inam, M; Sheikh, S; Minhas, AMK; Vaughan, EM; Krittanawong, C; Samad, Z; Lavie, CJ; Khoja, A; D'Cruze, M; Slipczuk, L; Alarakhiya, F; Naseem, A; Haider, AH; Virani, SS				Inam, Maha; Sheikh, Sana; Minhas, Abdul Mannan Khan; Vaughan, Elizabeth M.; Krittanawong, Chayakrit; Samad, Zainab; Lavie, Carl J.; Khoja, Adeel; D'Cruze, Melaine; Slipczuk, Leandro; Alarakhiya, Farhana; Naseem, Azra; Haider, Adil H.; Virani, Salim S.			A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing	CURRENT PROBLEMS IN CARDIOLOGY			English	Review						Artificial Intelligence; Editorial Policies; ChatGPT; Large Language Models; Machine Learing; Scientific Writing; Cardiology; Scimago	CHATGPT; HELP	Background Generative Artificial Intelligence (AI) tools have experienced rapid development over the last decade and are gaining increasing popularity as assistive models in academic writing. However, the ability of AI to generate reliable and accurate research articles is a topic of debate. Major scientific journals have issued policies regarding the contribution of AI tools in scientific writing. Methods We conducted a review of the author and peer reviewer guidelines of the top 25 Cardiology and Cardiovascular Medicine journals as per the 2023 SCImago rankings. Data were obtained though reviewing journal websites and directly emailing the editorial office. Descriptive data regarding journal characteristics were coded on SPSS. Subgroup analyses of the journal guidelines were conducted based on the publishing company policies. Results Our analysis revealed that all scientific journals in our study permitted the documented use of AI in scientific writing with certain limitations as per ICMJE recommendations. We found that AI tools cannot be included in the authorship or be used for image generation, and that all authors are required to assume full responsibility of their submitted and published work. The use of generative AI tools in the peer review process is strictly prohibited. Conclusion Guidelines regarding the use of generative AI in scientific writing are standardized, detailed, and unanimously followed by all journals in our study according to the recommendations set forth by international forums. It is imperative to ensure that these policies are carefully followed and updated to maintain scientific integrity.	[Inam, Maha] Aga Khan Univ, Off Vice Provost Res, Karachi, Pakistan; [Sheikh, Sana; Khoja, Adeel] Aga Khan Univ, Dept Med, Karachi, Pakistan; [Minhas, Abdul Mannan Khan; Vaughan, Elizabeth M.] Baylor Coll Med, Dept Med, Sect Cardiovasc Res, Houston, TX USA; [Vaughan, Elizabeth M.] Dept Internal Med, UTMB, Galveston, TX USA; [Krittanawong, Chayakrit] New York Univ Langone Hlth, Leon H Charney Div Cardiol, New York, NY USA; [Samad, Zainab] Aga Khan Univ Hosp, Dept Med, Sect Cardiol, Karachi, Pakistan; [Lavie, Carl J.] Univ Queensland, John Ochsner Heart & Vasc Inst, Ochsner Clin Sch, Dept Cardiovasc Dis,Sch Med, New Orleans, LA USA; [Khoja, Adeel] Univ Adelaide, Fac Hlth & Med Sci, Adelaide Med Sch, Adelaide, SA, Australia; [D'Cruze, Melaine; Naseem, Azra] Aga Khan Univ Hosp, Inst Educ Dev, Karachi, Pakistan; [Slipczuk, Leandro] Montefiore Med Ctr, Cardiol Div, Bronx, NY USA; [Slipczuk, Leandro] Albert Einstein Coll Med, Bronx, NY USA; [Alarakhiya, Farhana] Aga Khan Univ, Nairobi, Kenya; [Haider, Adil H.] Aga Khan Univ Hosp, Med Coll, Deans Off, Karachi, Pakistan; [Virani, Salim S.] Texas Heart Inst, Houston, TX USA; [Virani, Salim S.] Aga Khan Univ, Sect Cardiol, Dept Med, Stadium Rd,POB 3500, Karachi 78400, Pakistan	Aga Khan University; Aga Khan University; Baylor College of Medicine; University of Texas System; University of Texas Medical Branch Galveston; New York University; Aga Khan University; University of Queensland; Ochsner Health System; University of Adelaide; Aga Khan University; Montefiore Medical Center; Albert Einstein College of Medicine; Yeshiva University; Montefiore Medical Center; Albert Einstein College of Medicine; Aga Khan University; Aga Khan University; Texas Heart Institute; Aga Khan University	Virani, SS (corresponding author), Aga Khan Univ, Sect Cardiol, Dept Med, Stadium Rd,POB 3500, Karachi 78400, Pakistan.	salim.virani@aku.edu	Khoja, Adeel/ABA-8794-2020	Khoja, Adeel/0000-0003-1513-408X				Amano T, 2023, PLOS BIOL, V21, DOI 10.1371/journal.pbio.3002184; [Anonymous], ICMJE | Recommendations | Defining the Role of Authors and Contributors; [Anonymous], 2023, Using AI in Peer Review Is a Breach of Confidentiality-NIH Extramural Nexus; [Anonymous], 2023, J Rank Cardiol Cardiovasc Med; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Bhargava DC, 2023, Med Leg J.; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT, about us; Ciaccio EJ, 2023, Inform Med Unlocked, V41; COPE: Committee on Publication Ethics, 2023, Artif Intell Authorship; COPE: Committee on Publication Ethics, Ethical guidelines for peer reviewers; Del Giglio A, 2023, REV ASSOC MED BRAS, V69, DOI 10.1590/1806-9282.20230560; Doyal AS, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43292; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Falagas ME, 2008, FASEB J, V22, P2623, DOI 10.1096/fj.08-107938; Garcia MB, 2024, ANN BIOMED ENG, V52, P139, DOI 10.1007/s10439-023-03299-7; Golan R, 2023, NAT REV UROL, V20, P327, DOI 10.1038/s41585-023-00746-x; Huang JS, 2023, AM J CANCER RES, V13, P1148; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kurian N, 2023, BRIT DENT J, V234, P73, DOI 10.1038/s41415-023-5461-1; Lee Ping Yein, 2023, Malays Fam Physician, V18, P58, DOI 10.51866/cm0006; Leung TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/51584; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Miikkulainen Risto, 2021, SN Comput Sci, V2, P163, DOI 10.1007/s42979-021-00540-9; Park JY, 2023, J KOR ASSOC ORAL MAX, V49, P105, DOI 10.5125/jkaoms.2023.49.3.105; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; science, Science funding agencies say no to using AI for peer review; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Shoja MM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40883; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Suchikova Y, 2023, NATURE, V614, P413, DOI 10.1038/d41586-023-00381-x; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Zielinski C, 2023, Pan-Am J Ophthalmol, V5, P8, DOI 10.4103/2666-4909.372647	37	3	3	20	20	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0146-2806	1535-6280		CURR PROB CARDIOLOGY	Curr. Probl. Cardiol.	MAR	2024	49	3							102387	10.1016/j.cpcardiol.2024.102387	http://dx.doi.org/10.1016/j.cpcardiol.2024.102387		JAN 2024	7	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	HE7H9	38185435				2024-07-03	WOS:001157878100001
J	De Cooman, J				De Cooman, Jerome			When Art Becomes a Lemon: The Economics of Machine-Enabled Artworks and the Need for a Rule of Origin	LAW TECHNOLOGY AND HUMANS			English	Article						Machine-enabled artworks; rules of origin; lemons problem; authorship; large language model; GPT-3		In 2021, an artificial intelligence system wrote a law article. The results were far from perfect but begged the question of whether a human author will still be able to compete against artificial intelligence. Leaving aside the Luddites scenario, this paper starts with the premise that human-made art might be more valued than machine-enabled art. However, to be properly valued, machine-enabled and human-made art must be distinguishable-they are not. Indistinguishability creates an asymmetry in information. This leads to a 'lemons problem'-that is, a market erosion of good-quality products (in this scenario, human-made products). Against that background, this paper proposes a solution in light of international law and rules of origin. This paper argues that the lemons problem induces the need for a rule of origin labelling work as either human-made or machine-enabled. Determining human or machine authorship may be dauntingly complex when the artwork owes its existence to both humans and machines. One solution may be to review how the country of origin is identified whenever products are not created in a single location and then to apply, mutatis mutandis, to rules of authorship origin the solutions once identified in the context of geographical origins, that is, the so-called 'substantial transformation test'. In the context of machine-enabled artwork, this test is whether a human edited the machine output and, if so, whether those edits constituted a substantial transformation of the work of art.	[De Cooman, Jerome] Univ Liege, Liege, Belgium	University of Liege	De Cooman, J (corresponding author), Univ Liege, Liege, Belgium.	Jerome.decooman@uliege.be						Abid A, 2021, Arxiv, DOI arXiv:2101.05783; Abrantes-Metz R M., 2012, Harvard Business Law Review Online, V3, P10; Adorno TheodorW., 1945, Kenyon Review, V7, P208; AKERLOF GA, 1970, Q J ECON, V84, P488, DOI 10.2307/1879431; Alarie B, 2021, LAW TECHNOL HUMANS, V3, P5, DOI 10.5204/lthj.2089; Alighieri Dante, 1294, VITA NOVA; [Anonymous], 2007, THOMSON MULTIMEDIA S; [Anonymous], 1997, GESELLSCHAFT UBERSEE; [Anonymous], 2009, BUNDESFINANZDIREKTIO; [Anonymous], 2005, NBER WORKING PAPER S; [Anonymous], 2021, COM2021206; [Anonymous], 1979, YOSHIDA NEDERLAND BV; [Anonymous], 2013, Regulation (EU) No 952/2013 of the European Parliament and of the Council of 9 Oct. 2013 laying down the Union Customs Code; [Anonymous], 2021, RENESOLA UK LTD V CO; [Anonymous], 1989, BROTHERS INT GMBH V; [Anonymous], 2013, IOANNIS CHRISTODOULO; [Anonymous], 2010, HOESCH METALS ALLOYS; [Anonymous], 2015, COMMISSION DELEGATED; Asimov Isaac, 1982, GALAXY SCI FICTION, P315; Augier P, 2005, ECON POLICY, P567; Austen Jane, 2020, SANDITON; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barnabe Fanny, 2021, JAPANS CONT MEDIA CU, P251, DOI [10.11588/crossasia.971.c12887, DOI 10.11588/CROSSASIA.971.C12887]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bensinger G., 2023, ReutersFebruary 21; Boden M.A., 2018, Artificial Intelligence: A Very Short Introduction, DOI 10.1093/actrade/9780199602919.001.0001; Boden Margaret A., 2004, CREATIVE MINDS MYTHS; Bonadio Enrico, 2020, Intell Prop Q, V20, P112; Bridy Annemarie., 2016, Colum JL Arts, V39, P395; Brooks T, 2023, Arxiv, DOI arXiv:2211.09800; Brown Nina I., 2019, RESPONSE REQUEST COM; Brown Nina I, 2019, SCI TECHNOLOGY LAW R, V20, P1, DOI DOI 10.7916/STLR.V20I1.4766; Cadot O, 2008, WORLD BANK RES OBSER, V23, P77, DOI 10.1093/wbro/lkm010; Cai Kenrick, 2021, FORBES 0104; Celebi M., 2016, Unsupervised Learning Algorithms, DOI [10.1007/978-3-319-24211-8, DOI 10.1007/978-3-319-24211-8]; Chan A., 2022, AI and Ethics, V3, P53, DOI DOI 10.1007/S43681-022-00148-6; Cheong M, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P106, DOI 10.1145/3442188.3445874; Chiu Ke-Li, 2021, arXiv; Cohn G., 2018, NEW YORK TIMES; Cruz Sherley E., 2019, TENN. L. REV., V86, P347; Cyphert A. B., 2021, UC Davis L. Rev, V55, P401; da Costa Kleyton, 2023, HOLISTIC AI; Daws R., 2020, NEWS; De Beauvoir S, 1974, 2 SEX; Domingos P., 2015, The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Elliott A, 2021, ROUT INT HANDB, P3; Estevadeordal Antoni, 2009, MULTILATERALIZING RE, P262; Falvey R, 2002, INT ECON REV, V43, P393, DOI 10.1111/1468-2354.t01-1-00020; Falvey R, 1998, WELTWIRTSCH ARCH, V134, P209, DOI 10.1007/BF02708093; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frankish K., 2014, The Cambridge Handbook of Artificial Intelligence; Franklin S, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P15; GALFAND CE, 1989, U PENN J INT BUS LAW, V11, P469; Gillotte Jessica L., 2020, U.C. Davis Law Review, V53, P2684; Ginsburg Jane C., 2019, BERKELEY TECHNOLOGY, V34, P343, DOI [10.15779/Z38SF2MC24, DOI 10.15779/Z38SF2MC24]; Gordon Seth, PICTUREHOUSE; GPT- 3, 2020, Guardian; Grinbaum A, 2022, Arxiv, DOI [arXiv:2209.03118, DOI 10.48550/ARXIV.2209.03118, 10.48550/arXiv.2209.03118]; Gu CX, 2022, Arxiv, DOI arXiv:2210.07543; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hacker P, 2023, Arxiv, DOI [arXiv:2302.02337, DOI 10.48550/ARXIV.2302.02337, 10.48550/arXiv.2302.02337, DOI 10.48550/AR-XIV.2302.02337]; Han S., 2021, The Routledge Social Science Handbook of AI, P295; Hemmingsen M, 2021, SPORT ETHICS PHILOS, V15, P435, DOI 10.1080/17511321.2020.1796773; Hilliard A., 2022, Holistic AIDecember 12; Hobbes Thomas., 1909, Hobbes's Leviathan Reprinted from the Edition of 1651 with an Essay by the Late W.G. Pogson Smith; Inama S, 2009, RULES OF ORIGIN IN INTERNATIONAL TRADE, P1, DOI 10.1017/CBO9780511551949; Italian Renaissance Learning Resources and National Gallery of Art, MAK ART; Johnson D, 2017, MIND MACH, V27, P575, DOI 10.1007/s11023-017-9417-6; Johnson RL, 2022, arXiv, DOI 10.48550/ARXIV.2203.07785; Kaplan F., 2004, INT J HUMAN ROBOT IJ, V1, P465, DOI DOI 10.1142/S0219843604000289; KHAN RJ, 2020, J BIOMOL STRUCT 0418, DOI DOI https://doi.org/10.1080/07391102.2020.1753577; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Klingemann Mario, MEMORIES PASSERSBY 1; Kocurek C.A., 2015, COIN OPERATED AMERIC; LaGrandeur K., 2020, ETHICS, DOI DOI 10.1007/S43681-020-00010-7; Lehr David, 2017, UC Davis Law Review, V51, P653; Levy David, 2005, ROBOT UNLIMITED LIFE; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Mayson SG, 2019, YALE LAW J, V128, P2218; McGufe K, 2020, arXiv; Medler B., 2009, CULTURE, V3, P177, DOI DOI 10.7557/23.6004; Menotti Gabriel., 2014, The Italian Journal of Game Studies, V3, P81; Mikalef P, 2022, EUR J INFORM SYST, V31, P257, DOI 10.1080/0960085X.2022.2026621; MILLER AR, 1993, HARVARD LAW REV, V106, P978; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Nassim D., 2021, ETHICS SCI ENV POLIT, V21, P17; Nugent Ciara, 2018, TIME 0820; Obvious, BAR BEL; Obvious, PORTR E BEL; Obvious, COMPT BEL; OpenAI, 2022, Aligning Language Models to Follow Instructions; OpenAI, SHAR PUBL POL; Osha Jonathan P., 2019, STUDY QUESTION COPYR; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Petit Nicolas, 2018, ARTIFICIAL INTELLIGE; Pila J, 2021, ROUTL HANDBK, P63; Poe Edgar Allan, 1845, GRAHAMS MAGAZINE, P1; Poppe E.S. Taylor, 2019, Oklahoma Law Review, V72, P185; Ragot Martin, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3334480.3382892; Ramalho A., 2017, J Internet Law, V21, P12, DOI [10.2139/ssrn.2987757, DOI 10.2139/SSRN.2987757]; Reiss Sheryl E., 2013, A Companion to Renaissance and Baroque Art, P23; Rubinstein IS, 2013, INT DATA PRIV LAW, V3, P74, DOI 10.1093/idpl/ips036; Schwartz DG, 2017, GAMING LAW REV, V21, P542, DOI 10.1089/glr2.2017.2185; Scully-Blaker R, 2014, Game Studies, V14; Somepalli G, 2022, Arxiv, DOI arXiv:2212.03860; Sotheby's, 2018, MEM PASS 1; Sotheby's, 2019, BAR BEL; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thornhill John, 2020, FINANCIAL TIMES 1112; Tomalin M, 2021, ETHICS INF TECHNOL, V23, P419, DOI 10.1007/s10676-021-09583-1; Tomczak J.M., 2022, Deep Generative Modeling; Toole Betty A. Ada, 1988, ADA ENCHANTRESS NUMB; Tresset P, 2013, COMPUT GRAPH-UK, V37, P348, DOI 10.1016/j.cag.2013.01.012; Turner J., 2019, Robot Rules: Regulating Artificial Intelligence; Twin Galaxies, WHAT IS TWIN GAL; United States Copyright Office, 2023, ZAR DAWN REG VAU0014; van Gogh Vincent, 1887, STILL LIFE LEMONS PL; Vanherpe Jozefien, 2021, ARTIF INTELL, P207; Walsh T., 2017, Android Dreams: The Past, Present and Future of Artificial Intelligence; Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282; Wilks Y, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P213; Zerilli John, 2020, LAW ARTIFICIAL INTEL, P7; Zuidervaart L., 2015, Stanford Encyclopedia of Philosophy	125	0	0	1	3	QUEENSLAND UNIV TECHNOLOGY	BRISBANE	GPO  BOX 2434, BRISBANE, QLD 4001, AUSTRALIA		2652-4074		LAW TECHNOL HUMANS	Law Technol. Humans		2023	5	1					24	39		10.5204/lthj.2787	http://dx.doi.org/10.5204/lthj.2787			16	Law; Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Government & Law; Social Sciences - Other Topics	I1CZ1		gold			2024-07-03	WOS:001000234800003
J	Feldstein, S				Feldstein, Steven			The Consequences of Generative AI for Democracy, Governance and War	SURVIVAL			English	Article						Artificial intelligence (AI); chatbots; ChatGPT; cyber attacks; large language model (LLM); military planning; propaganda; surveillance		The potential impact of generative AI across politics, governance and war is enormous, and is the subject of considerable speculation informed by few hard facts. Yet it is possible to identify some major challenges. They include threats to democracies by privately controlled models that gain tremendous power to shape discourse and affect democratic deliberation; enhanced surveillance and propaganda dissemination by authoritarian regimes; new capacities for criminal and terrorist actors to carry out cyber attacks and related disruptions; and transformed war planning and military operations reflecting the accelerated dehumanisation of lethal force. While new innovations historically require time to take root, generative AI is likely to be adopted swiftly. Stakeholders must formulate pragmatic approaches to manage oncoming risks.	[Feldstein, Steven] Carnegie Endowment Int Peace, Governance Program, Washington, DC 20036 USA		Feldstein, S (corresponding author), Carnegie Endowment Int Peace, Governance Program, Washington, DC 20036 USA.				I would like to thank Tom Carothers, Matt O'Shaughnessy and Gavin Wilde for their valuable comments and feedback, and Brian (Chun Hey) Kot for his research assistance.	I would like to thank Tom Carothers, Matt O'Shaughnessy and Gavin Wilde for their valuable comments and feedback, and Brian (Chun Hey) Kot for his research assistance.	I would like to thank Tom Carothers, Matt O'Shaughnessy and Gavin Wilde for their valuable comments and feedback, and Brian (Chun Hey) Kot for his research assistance.	Alba Davey, 2022, Bloomberg8 December; Andersen Ross, 2023, AtlanticJune; [Anonymous], 2023, Governance of Superintelligence; [Anonymous], 2023, The EconomistApril 22; [Anonymous], 2023, The Economist25 May; [Anonymous], 2023, Batch25 January; [Anonymous], 2023, youtube; Antal John, 2022, 7 Seconds to Die: A Military Analysis of the Second Nagorno-Karabakh War and the Future of Warfighting; Atherton K, 2021, Loitering munitions preview the autonomous future of warfare; Bajohr Hannes, 2023, Whoever Controls Language Models Controls Politics; Barrington Lisa, 2023, Reuters25 May; Bateman Jon, 2021, Measuring the Effects of Influence Operations: Key Findings and Gaps from Empirical Research; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benson Thor, 2023, Wired27 April; Birhane A., 2022, WIRED; Bob Yonah Jeremy, 2023, Jerusalem Post28 June; Bommasani, 2022, OPPORTUNITIES RISKS; Bove Tristan, 2023, Fortune6 May; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Browne Ryan, 2023, CNBC4 April; Burgess Matt, 2023, Wired13 April; Carvin S, 2022, INT AFF, V98, P1695, DOI 10.1093/ia/iiac189; Chatterjee Mohar, 2023, Politico14 August; Cronin A. K., 2019, Power to the people: How open technological innovation is arming tomorrow's terrorists; DAVID PA, 1990, AM ECON REV, V80, P355; Deibert Ronald J., 2022, Foreign Affairs12 December; Devlin Kayleen, 2023, BBC News24 March; Esterle Lukas, 2022, Deep Learning for Robot Perception and Cognition, P435; Europol, 2023, Tech Watch Flash Report from the Europol Innovation Lab; Federspiel F, 2023, BMJ GLOB HEALTH, V8, DOI 10.1136/bmjgh-2022-010435; Feldstein S., 2023, WHY DOES GLOBAL SPYW; Feldstein S., 2021, RISE DIGITAL REPRESS; Feldstein S, 2023, DEMOCRATIZATION, DOI 10.1080/13510347.2023.2196068; Feldstein S, 2019, J DEMOCR, V30, P40, DOI 10.1353/jod.2019.0003; Feldstein Steven, 2022, The Global Struggle Over AI Surveillance; Feldstein Steven, 2019, The Global Expansion of AI Surveillance; Fiesler Casey, 2023, Conversation18 April; FitzGerald B, 2017, B ATOM SCI, V73, P102, DOI 10.1080/00963402.2017.1288445; Gaulkin Thomas, 2023, Bulletin of the Atomic Scientists; Goldfarb A, 2021, INT SECURITY, V46, P7, DOI 10.1162/isec_a_00425; Goldman Emily., 2003, The Diffusion of Military Technology and Ideas; Goldstein J. A., 2023, Generative language models and automated influence operations: Emerging threats and potential mitigations; Goldstein Josh A., 2023, Foreign Affairs27 April; Hirsh Michael, 2023, Foreign Policy11 April; Hoffman Samantha., 2017, Programming China: the Communist Party's Automatic Approach to Managing State Security; Hoffmann Jordan, 2022, Google DeepMind12 April; Holland Michel A, 2021, Known Unknowns: Data Issues and Military Autonomous Systems; Horowitz MC, 2010, DIFFUSION OF MILITARY POWER: CAUSES AND CONSEQUENCES FOR INTERNATIONAL POLITICS, P1; Hu K., 2023, Reuters; Ignatius David, 2022, The Washington Post19 de diciembre de; Jensen Benjamin, 2023, War on the Rocks; Jensen BM, 2020, INT STUD REV, V22, P526, DOI 10.1093/isr/viz025; Kahn Lauren, 2023, Foreign Affairs6 June; Karp Alexander, 2023, Palantir7 April; KATZENBACH EL, 1958, PUBLIC POLICY, V8, P120; Kendall-Taylor A, 2020, FOREIGN AFF, V99, P103; Kreps S., 2023, How generative AI impacts democratic engagement; Krugman Paul, 2023, New York Times31 March; Lee Channing, 2023, Georgetown Security Studies Review; Lima C., 2023, WASH POST; Lohn Andrew J., 2022, Will AI Make Cyber Swords or Shields?; Magnuson Stew, 2023, National Defense; Marcus Gary, 2023, US SENATE COMMITTEE; Martindale J., 2023, Digital Trends; Metz C., 2023, New York Times; Nield D., 2023, Wired; Nylen Leah, 2023, Bloomberg1 June; OHanlon Michael E., 1999, The Plane Truth: Fewer F -22s Mean a Stronger National Defense; Perrigo Billy, 2023, Time20 June; Peterson Dahlia, 2021, How China Harnesses Data Fusion to Make Sense of Surveillance Data.; Roose Kevin, 2023, New York Times28 March; Sanders Nathan E., 2023, New York Times15 January; Satariano A., 2023, N.Y. TIMES June 14; Scharre Paul, 2023, War on the Rocks; Scharre Paul, 2023, Foreign PolicyJune 19; Schaul Kevin, 2023, Washington Post24 May; Select Committee on Artificial Intelligence of the National Science and Technology Council, 2023, National Artificial Intelligence Research and Development Strategic Plan 2023 Update; Shear Michael D., 2023, N.Y. TIMESJuly 21; Sorkin Andrew Ross, 2023, New York Times; Stanley -Becker Isaac, 2023, Washington Post25 April; Stupp Catherine, 2019, The Wall Street Journal30 August; Sullivan Mark, 2023, Fast Company13 April; Tan Rebecca, 2023, Washington Post19 June; Tappin B, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2216261120; Tobin Meaghan, 2023, Washington Post14 July; Toner H., 2023, What Are Generative AI, Large Language Models, and Foundation Models?; Toner Helen, 2023, Foreign Affairs; Toner Helen, 2023, DigiChina; Triolo P, 2023, The China Project; Tucker JA., 2018, SSRN March, DOI [DOI 10.2139/SSRN.3144139, 10.2139/ssrn.3144139]; US Department of Defense, 2023, DOD Announces Establishment of Generative AI Task Force; US Department of Defense, 2023, DoD Announces Update to DoD Directive 3000.09; US Department of State, 2023, Political Declaration of Responsible Military Use of Artificial Intelligence and Autonomy; Ward Alexander, 2023, Politico11 May; Weiser B., 2023, The New York Times; White House, 2023, G7 Hiroshima Leaders' Communique; Wiggers Kyle, 2023, TechCrunch24 February; Wong Matteo, 2023, Atlantic2 June; Wright Nicholas, 2018, Foreign AffairsJuly 10; Xiang Chloe, 2023, Vice4 April; Yang Sophia, 2023, Taiwan News11 February; Zhou Cissy, 2023, Nikkei Asia22 February; Zumbrun Josh, 2023, Wall Street Journal4 August	103	2	2	33	50	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0039-6338	1468-2699		SURVIVAL	Survival	SEP 3	2023	65	5					117	142		10.1080/00396338.2023.2261260	http://dx.doi.org/10.1080/00396338.2023.2261260			26	International Relations; Political Science	Social Science Citation Index (SSCI)	International Relations; Government & Law	T7IK2					2024-07-03	WOS:001079678700008
J	Shay, D; Kumar, B; Bellamy, D; Palepu, A; Dershwitz, M; Walz, JM; Schaefer, MS; Beam, A				Shay, Denys; Kumar, Bhawesh; Bellamy, David; Palepu, Anil; Dershwitz, Mark; Walz, Jens M.; Schaefer, Maximilian S.; Beam, Andrew			Assessment of ChatGPT success with specialty medical knowledge using anaesthesiology board examination practice questions	BRITISH JOURNAL OF ANAESTHESIA			English	Letter						artificial intelligence; board examination; ChatGPT; large language models; medical knowledge; multiple choice questions; specialty qualifications			[Shay, Denys; Bellamy, David; Beam, Andrew] Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA 02115 USA; [Shay, Denys; Schaefer, Maximilian S.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Dept Anesthesia, Crit Care & Pain Med, Boston, MA USA; [Shay, Denys; Schaefer, Maximilian S.] Harvard Med Sch, Ctr Anesthesia Res Excellence, Beth Israel Deaconess Med Ctr, Boston, MA USA; [Kumar, Bhawesh; Bellamy, David] Harvard TH Chan Sch Publ Hlth, Dept Biostat, Boston, MA USA; [Palepu, Anil] MIT, Hlth Sci & Technol, Cambridge, MA USA; [Dershwitz, Mark; Walz, Jens M.] Univ Massachusetts, Chan Med Sch, Dept Anesthesiol & Perioperat Med, Worcester, MA USA; [Schaefer, Maximilian S.] Dusseldorf Univ Hosp, Dept Anesthesiol, Dusseldorf, Germany	Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Harvard Medical School; Beth Israel Deaconess Medical Center; Harvard University; Harvard Medical School; Beth Israel Deaconess Medical Center; Harvard University; Harvard T.H. Chan School of Public Health; Massachusetts Institute of Technology (MIT); University of Massachusetts System; University of Massachusetts Worcester; Heinrich Heine University Dusseldorf; Heinrich Heine University Dusseldorf Hospital	Beam, A (corresponding author), Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA 02115 USA.	andrew_beam@hms.harvard.edu		Kumar, Bhawesh/0009-0007-3550-1170; Beam, Andrew/0000-0002-6657-2787; Bellamy, David/0000-0002-6878-0803				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Dershwitz M, 2013, Anesthesiology examination and board review, V7th; Finlayson SG, 2023, JAMA PEDIATR, V177, P448, DOI 10.1001/jamapediatrics.2023.0034; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Levine DM, 2023, PREPRINT; Medenilla A., 2023, PLoS Digital Health, V2; OpenAi, ChatGPT; Schulman John, 2022, Chatgpt: Optimizing language models for dialogue; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138	9	15	15	8	10	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	AUG	2023	131	2								10.1016/j.bja.2023.04.017	http://dx.doi.org/10.1016/j.bja.2023.04.017		JUL 2023	4	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	FT6Q4	37210278				2024-07-03	WOS:001148150700001
J	Jedrzejczak, WW; Skarzynski, PH; Raj-Koziak, D; Sanfins, MD; Hatzopoulos, S; Kochanek, K				Jedrzejczak, W. Wiktor; Skarzynski, Piotr H.; Raj-Koziak, Danuta; Sanfins, Milaine Dominici; Hatzopoulos, Stavros; Kochanek, Krzysztof			ChatGPT for Tinnitus Information and Support: Response Accuracy and Retest after Three and Six Months	BRAIN SCIENCES			English	Article						chatbot; large language model; natural language processing; artificial intelligence; self-diagnosis; hearing; audiology; longitudinal; otorhinolaryngology	QUESTIONS; ANSWERS	Testing of ChatGPT has recently been performed over a diverse range of topics. However, most of these assessments have been based on broad domains of knowledge. Here, we test ChatGPT's knowledge of tinnitus, an important but specialized aspect of audiology and otolaryngology. Testing involved evaluating ChatGPT's answers to a defined set of 10 questions on tinnitus. Furthermore, given the technology is advancing quickly, we re-evaluated the responses to the same 10 questions 3 and 6 months later. The accuracy of the responses was rated by 6 experts (the authors) using a Likert scale ranging from 1 to 5. Most of ChatGPT's responses were rated as satisfactory or better. However, we did detect a few instances where the responses were not accurate and might be considered somewhat misleading. Over the first 3 months, the ratings generally improved, but there was no more significant improvement at 6 months. In our judgment, ChatGPT provided unexpectedly good responses, given that the questions were quite specific. Although no potentially harmful errors were identified, some mistakes could be seen as somewhat misleading. ChatGPT shows great potential if further developed by experts in specific areas, but for now, it is not yet ready for serious application.	[Jedrzejczak, W. Wiktor; Kochanek, Krzysztof] Inst Physiol & Pathol Hearing, World Hearing Ctr, Dept Expt Audiol, PL-05830 Kajetany, Poland; [Skarzynski, Piotr H.; Sanfins, Milaine Dominici] Inst Physiol & Pathol Hearing, World Hearing Ctr, Dept Teleaudiol & Screening, PL-05830 Kajetany, Poland; [Skarzynski, Piotr H.] Inst Sensory Organs, PL-05830 Kajetany, Poland; [Skarzynski, Piotr H.] Med Univ Warsaw, Fac Med, Heart Failure & Cardiac Rehabil Dept, PL-03242 Warsaw, Poland; [Raj-Koziak, Danuta] Inst Physiol & Pathol Hearing, World Hearing Ctr, Tinnitus Dept, PL-05830 Kajetany, Poland; [Sanfins, Milaine Dominici] Univ Fed Sao Paulo, Speech Hearing Language Dept, Audiol Discipline, BR-04023062 Sao Paulo, Brazil; [Hatzopoulos, Stavros] Univ Ferrara, Dept Neurosci & Rehabil, ENT & Audiol Unit, I-44121 Ferrara, Italy	Institute of Physiology & Hearing Pathology; Institute of Physiology & Hearing Pathology; Medical University of Warsaw; Institute of Physiology & Hearing Pathology; Universidade Federal de Sao Paulo (UNIFESP); University of Ferrara	Jedrzejczak, WW (corresponding author), Inst Physiol & Pathol Hearing, World Hearing Ctr, Dept Expt Audiol, PL-05830 Kajetany, Poland.	w.wiktor.j@gmail.com; p.skarzynski@csim.pl; d.koziak@ifps.org.pl; msanfins@uol.com.br; sdh1@unife.it; k.kochanek@ifps.org.pl	Jedrzejczak, W. Wiktor/L-2529-2015; Skarzynski, Piotr H./A-9642-2012; Dominici Sanfins, Milaine/K-2262-2012	Jedrzejczak, W. Wiktor/0000-0001-8404-0672; Skarzynski, Piotr H./0000-0002-4978-1915; Kochanek, Krzysztof/0000-0003-2860-5784; Dominici Sanfins, Milaine/0000-0002-3647-3999				BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Bloomberg, About us; Buhr CR, 2023, JMIR MED EDUC, V9, DOI 10.2196/49183; Davis AC, 2019, B WORLD HEALTH ORGAN, V97, P646, DOI 10.2471/BLT.19.224683; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Emile SH, 2023, SURGERY, V174, P1273, DOI 10.1016/j.surg.2023.06.005; Freire Y, 2024, J PROSTHET DENT, V131, DOI 10.1016/j.prosdent.2024.01.018; Gobira M, 2023, REV ASSOC MED BRAS, V69; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Halily S, 2021, OTOL NEUROTOL, V42, pE1432, DOI 10.1097/MAO.0000000000003311; Henry JA, 2014, J AM ACAD AUDIOL, V25, P5, DOI 10.3766/jaaa.25.1.2; HILLER W, 1992, J PSYCHOSOM RES, V36, P337, DOI 10.1016/0022-3999(92)90070-I; HILLER W, 1994, BRIT J CLIN PSYCHOL, V33, P231, DOI 10.1111/j.2044-8260.1994.tb01117.x; Huang Y, 2024, Arxiv, DOI arXiv:2310.05046; Jackson R, 2019, OTOL NEUROTOL, V40, P154, DOI 10.1097/MAO.0000000000002116; Jarach CM, 2022, JAMA NEUROL, V79, P888, DOI 10.1001/jamaneurol.2022.2189; Jedrzejczak WW, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042123; Kajsa-Mia H., 2003, Audiol. Med, V1, P101, DOI [10.1080/16513860301714, DOI 10.1080/16513860301714]; Kim Hee-Young, 2023, Cureus, V15, pe36830, DOI 10.7759/cureus.36830; Kochanek K, 2023, PREPRINT, DOI [10.1101/2023.11.22.23298893, DOI 10.1101/2023.11.22.23298893]; Kutyba J, 2022, INT J AUDIOL, V61, P686, DOI 10.1080/14992027.2021.1964040; Langguth B, 2013, LANCET NEUROL, V12, P920, DOI 10.1016/S1474-4422(13)70160-1; Lee SH, 2015, ACTA OTO-LARYNGOL, V135, P140, DOI 10.3109/00016489.2014.952334; Lewandowski M, 2023, CLIN EXP DERMATOL, V49, P686, DOI 10.1093/ced/llad255; Luykx JJ, 2023, WORLD PSYCHIATRY, V22, P479, DOI 10.1002/wps.21145; Manchaiah V, 2022, AM J AUDIOL, V31, P993, DOI 10.1044/2021_AJA-21-00158; Marcrum SC, 2022, NUTRIENTS, V14, DOI 10.3390/nu14245356; McMahon HV, 2024, FRONT DIGIT HEALTH, V6, DOI 10.3389/fdgth.2024.1287186; Meikle MB, 2012, EAR HEARING, V33, P153, DOI 10.1097/AUD.0b013e31822f67c0; Milloy V, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00237; Newman CW, 1996, ARCH OTOLARYNGOL, V122, P143; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; PENNER MJ, 1988, ARCH OTOLARYNGOL, V114, P150; Plevris V, 2023, AI-BASEL, V4, P949, DOI 10.3390/ai4040048; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Sanfins MD, 2023, INT ARCH OTORHINOLAR, V27, P400, DOI 10.1055/s-0042-1742351; Stohler NA, 2019, CLIN EPIDEMIOL, V11, P855, DOI 10.2147/CLEP.S213136; Swanepoel De Wet, 2023, Hear J, V76, P26, DOI DOI 10.1097/01.HJ.0000927336.03567.3; Trevis KJ, 2018, CLIN PSYCHOL REV, V60, P62, DOI 10.1016/j.cpr.2017.12.006; Trust T., 2023, Contemp Issues Technol Teach Educ, V23, P1; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Vandewyngaert C, 2023, HAEMOPHILIA, V29, P1646, DOI 10.1111/hae.14858; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yanagita Y, 2023, JMIR FORM RES, V7, DOI 10.2196/48023; ZUREK PM, 1981, J ACOUST SOC AM, V69, P514, DOI 10.1121/1.385481	46	1	1	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3425		BRAIN SCI	Brain Sci.	MAY	2024	14	5							465	10.3390/brainsci14050465	http://dx.doi.org/10.3390/brainsci14050465			11	Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	SC2S3	38790444	gold			2024-07-03	WOS:001232200500001
J	Richey, RG Jr; Chowdhury, S; Davis-Sramek, B; Giannakis, M; Dwivedi, YK				Richey Jr, Robert Glenn; Chowdhury, Soumyadeb; Davis-Sramek, Beth; Giannakis, Mihalis; Dwivedi, Yogesh K.			Artificial intelligence in logistics and supply chain management: A primer and roadmap for research	JOURNAL OF BUSINESS LOGISTICS			English	Editorial Material						ChatGPT; generative AI; generative artificial intelligence; large language models; LLMs; logistics management; supply chain management		The dawn of generative artificial intelligence (AI) has the potential to transform logistics and supply chain management radically. However, this promising innovation is met with a scholarly discourse grappling with an interplay between the promising capabilities and potential drawbacks. This conversation frequently includes dystopian forecasts of mass unemployment and detrimental repercussions concerning academic research integrity. Despite the current hype, existing research exploring the intersection between AI and the logistics and supply chain management (L&SCM) sector remains limited. Therefore, this editorial seeks to fill this void, synthesizing the potential applications of AI within the L&SCM domain alongside an analysis of the implementation challenges. In doing so, we propose a robust research framework as a primer and roadmap for future research. This will give researchers and organizations comprehensive insights and strategies to navigate the complex yet promising landscape of AI integration within the L&SCM domain.	[Richey Jr, Robert Glenn; Davis-Sramek, Beth] Auburn Univ, Auburn, AL 36849 USA; [Chowdhury, Soumyadeb] TBS Business Sch, Toulouse, France; [Giannakis, Mihalis] Audencia Business Sch, Nantes, France; [Dwivedi, Yogesh K.] Swansea Univ, Swansea, Wales	Auburn University System; Auburn University; Audencia; Swansea University	Richey, RG Jr (corresponding author), Auburn Univ, Auburn, AL 36849 USA.	richey@auburn.edu	Dwivedi, Yogesh Kumar/A-5362-2008	Dwivedi, Yogesh Kumar/0000-0002-5547-9990				Ashok M, 2022, INT J INFORM MANAGE, V62, DOI 10.1016/j.ijinfomgt.2021.102433; Balthrop A, 2023, J BUS LOGIST, V44, P641, DOI 10.1111/jbl.12353; Boston Consulting Group, 2023, GEN AI; Brau RI, 2024, J BUS LOGIST, V45, DOI 10.1111/jbl.12355; Budhwar P, 2023, HUM RESOUR MANAG J, V33, P606, DOI 10.1111/1748-8583.12524; Chowdhury S, 2022, J BUS RES, V144, P31, DOI 10.1016/j.jbusres.2022.01.069; Clayton J., 2023, BBC NEWS        0517; Data Scientist, 2023, INT SEARCH WILL CHAN; Davenport T., 2023, FORBES          0320; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002; Gligor DM, 2022, J BUS LOGIST, V43, P140, DOI 10.1111/jbl.12287; Grennan J., 2020, ARTIF INTELL, P20; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Hahn T, 2021, STRATEG ORGAN, V19, P456, DOI 10.1177/1476127020979228; Hasija A, 2022, J BUS LOGIST, V43, P388, DOI 10.1111/jbl.12301; Heater B., 2023, TECHCRUNCH      0817; Hendriksen C, 2023, J SUPPLY CHAIN MANAG, V59, P65, DOI 10.1111/jscm.12304; Hofer C, 2023, J BUS LOGIST, V44, P719, DOI 10.1111/jbl.12357; IBM, 2023, GEN AI SUPPL CHAIN; Johnson M, 2022, INT J INFORM MANAGE, V64, DOI 10.1016/j.ijinfomgt.2022.102479; Klumpp M, 2022, J BUS LOGIST, V43, P297, DOI 10.1111/jbl.12314; Kochhar R., 2023, Which U.S. Workers are More Exposed to AI on Their Jobs?; Konietzko J, 2023, SUSTAIN PROD CONSUMP, V38, P372, DOI 10.1016/j.spc.2023.04.014; Kumar A., 2023, Journal of Business Strategy, V45, P161, DOI [10.1108/JBS-04-2023-0067, DOI 10.1108/JBS-04-2023-0067]; Loske D, 2022, J BUS LOGIST, V43, P302, DOI 10.1111/jbl.12300; Makarius EE, 2020, J BUS RES, V120, P262, DOI 10.1016/j.jbusres.2020.07.045; Masorgo N, 2023, J BUS LOGIST, V44, P666, DOI 10.1111/jbl.12356; Mentzer JT, 2001, J MARKETING, V65, P82, DOI 10.1509/jmkg.65.4.82.18390; Meta A. I., 2023, INTRO LLAMA FDN 6500; Microsoft Dynamics 365, 2023, INTR NEXT GEN AI MIC; Morgan TR, 2023, INT J LOGIST MANAG, DOI 10.1108/IJLM-02-2021-0115; Norrman A, 2023, J BUS LOGIST, V44, P693, DOI 10.1111/jbl.12351; OECD Employment Outlook, 2023, ART JOBS URG NEED AC; Pan SL, 2023, INT J INFORM MANAGE, V72, DOI 10.1016/j.ijinfomgt.2023.102668; Peng CM, 2022, INT J INFORM MANAGE, V66, DOI 10.1016/j.ijinfomgt.2022.102533; Pessot E, 2023, J BUS LOGIST, V44, P609, DOI 10.1111/jbl.12360; Pritchard AM, 2023, J BUS LOGIST, V44, P741, DOI 10.1111/jbl.12359; Rese A, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102699; Richey RG, 2022, J BUS LOGIST, V43, P416, DOI 10.1111/jbl.12324; Richey RG, 2022, J BUS LOGIST, V43, P164, DOI 10.1111/jbl.12308; Richey RG, 2022, J BUS LOGIST, V43, P4, DOI 10.1111/jbl.12297; Richey RG, 2022, J BUS LOGIST, V43, P62, DOI 10.1111/jbl.12290; The White House, 2022, ISS BRIEF IMP ART IN; Thorbecke C., 2023, CNN BUSINESS    0209; Treiblmaier H, 2023, J BUS LOGIST, V44, P550, DOI 10.1111/jbl.12345; Treiblmaier H, 2023, INT J INFORM MANAGE, V68, DOI 10.1016/j.ijinfomgt.2022.102514; Vallance C., 2023, BBC NEWS        0328; von Krogh G, 2023, ACAD MANAGE J, V66, P367, DOI 10.5465/amj.2023.4002; Wamba SF, 2023, INT J PROD ECON, V265, DOI 10.1016/j.ijpe.2023.109015; Yurt O, 2023, J BUS LOGIST, V44, P583, DOI 10.1111/jbl.12354; Zagorin E., 2023, FORBES INNOVATI 0629	54	24	24	123	174	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0735-3766	2158-1592		J BUS LOGIST	J. Bus. Logist.	OCT	2023	44	4					532	549		10.1111/jbl.12364	http://dx.doi.org/10.1111/jbl.12364		SEP 2023	18	Management	Social Science Citation Index (SSCI)	Business & Economics	U1FB7		Green Submitted, Bronze			2024-07-03	WOS:001077820900001
J	Jordan, EN; Zade, RSH; Pillay, S; van Lent, P; Abeel, T; Kayser, O				Jordan, Erin Noel; Zade, Ramin Shirali Hossein; Pillay, Stephanie; van Lent, Paul; Abeel, Thomas; Kayser, Oliver			Integrated omics of <i>Saccharomyces cerevisiae</i> CENPK2-1C reveals pleiotropic drug resistance and lipidomic adaptations to cannabidiol	NPJ SYSTEMS BIOLOGY AND APPLICATIONS			English	Article							CDP-DIACYLGLYCEROL SYNTHASE; MITOCHONDRIAL PROTEIN; ABC PROTEINS; YEAST; ACID; GENE; PHYTOCANNABINOIDS; STRESS; BIOSYNTHESIS; TRANSPORTERS	Yeast metabolism can be engineered to produce xenobiotic compounds, such as cannabinoids, the principal isoprenoids of the plant Cannabis sativa, through heterologous metabolic pathways. However, yeast cell factories continue to have low cannabinoid production. This study employed an integrated omics approach to investigate the physiological effects of cannabidiol on S. cerevisiae CENPK2-1C yeast cultures. We treated the experimental group with 0.5 mM CBD and monitored CENPK2-1C cultures. We observed a latent-stationary phase post-diauxic shift in the experimental group and harvested samples in the inflection point of this growth phase for transcriptomic and metabolomic analysis. We compared the transcriptomes of the CBD-treated yeast and the positive control, identifying eight significantly overexpressed genes with a log fold change of at least 1.5 and a significant adjusted p-value. Three notable genes were PDR5 (an ABC-steroid and cation transporter), CIS1, and YGR035C. These genes are all regulated by pleiotropic drug resistance linked promoters. Knockout and rescue of PDR5 showed that it is a causal factor in the post-diauxic shift phenotype. Metabolomic analysis revealed 48 significant spectra associated with CBD-fed cell pellets, 20 of which were identifiable as non-CBD compounds, including fatty acids, glycerophospholipids, and phosphate-salvage indicators. Our results suggest that mitochondrial regulation and lipidomic remodeling play a role in yeast's response to CBD, which are employed in tandem with pleiotropic drug resistance (PDR). We conclude that bioengineers should account for off-target product C-flux, energy use from ABC-transport, and post-stationary phase cell growth when developing cannabinoid-biosynthetic yeast strains.	[Jordan, Erin Noel; Kayser, Oliver] TU Dortmund Univ, Tech Biochem, Emil-Figge-Str 66, D-44227 Dortmund, Germany; [Zade, Ramin Shirali Hossein; Pillay, Stephanie; van Lent, Paul; Abeel, Thomas] Delft Univ Technol Mourik, Delft Bioinformat Lab, Broekmanweg 6, NL-2628 XE Delft, Netherlands; [Zade, Ramin Shirali Hossein] Leiden Univ, Med Ctr, Dept Biomed Data Sci, Leiden, Netherlands; [Zade, Ramin Shirali Hossein] Leiden Univ, Med Ctr, Leiden Ctr Computat Oncol, Leiden, Netherlands; [Abeel, Thomas] Broad Inst MIT & Harvard, Infect Dis & Microbiome Program, 415 Main St, Cambridge, MA 02142 USA	Dortmund University of Technology; Leiden University - Excl LUMC; Leiden University; Leiden University Medical Center (LUMC); Leiden University; Leiden University Medical Center (LUMC); Leiden University - Excl LUMC; Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute	Jordan, EN; Kayser, O (corresponding author), TU Dortmund Univ, Tech Biochem, Emil-Figge-Str 66, D-44227 Dortmund, Germany.	erin.jordan@tu-dortmund.de; oliver.kayser@tu-dortmund.de	; Kayser, Oliver/B-1431-2016	Abeel, Thomas/0000-0002-7205-7431; Kayser, Oliver/0000-0001-6131-2495	German Federal Ministry of Education and Research in the program VIPplus for the project Canna Cell [03VP06370]; National Research Foundation of South Africa [120192]	German Federal Ministry of Education and Research in the program VIPplus for the project Canna Cell; National Research Foundation of South Africa(National Research Foundation - South Africa)	We acknowledge the financial support from the German Federal Ministry of Education and Research in the program VIPplus for the project Canna Cell (03VP06370). The funder played no role in study design, data collection, analysis and interpretation of data, or the writing of this manuscript. The work was carried out with permission of the Federal German Opium Agency. This work is based on the research supported by wholly/in part by the National Research Foundation of South Africa (Grant Numbers: 120192). We thank Prof. Dr. Joern Kalinowski and his research team at CeBiTec at Bielefeld Universitaet for sequencing our samples with their Illumina MiSeq. We thank Prof. Dr. Eckhard Boles, University of Frankfurt, for consulting with us early on regarding the yeast growth curves. We thank Christina Schmidt for her assistance with experimental workflows and protocols. We acknowledge the use of large language models in the drafting of this manuscript in accordance with the policies of the journal. LLM-use was limited to syntax and grammar of the written manuscript. All data, images, methods, results, and conclusions held within this manuscript are original from the authors unless otherwise cited.	Al Kadi M, 2020, FUNCT INTEGR GENOMIC, V20, P523, DOI 10.1007/s10142-020-00732-1; Athanasiou A, 2007, BIOCHEM BIOPH RES CO, V364, P131, DOI 10.1016/j.bbrc.2007.09.107; Athenstaedt K, 1997, J BACTERIOL, V179, P7611, DOI 10.1128/jb.179.24.7611-7616.1997; BALZI E, 1994, J BIOL CHEM, V269, P2206; Bauer BE, 1999, BBA-BIOMEMBRANES, V1461, P217, DOI 10.1016/S0005-2736(99)00160-1; Berman P, 2023, NAT PLANTS, V9, P817, DOI 10.1038/s41477-023-01402-3; Black PN, 2007, BBA-MOL CELL BIOL L, V1771, P286, DOI 10.1016/j.bbalip.2006.05.003; Bolger AM, 2014, BIOINFORMATICS, V30, P2114, DOI 10.1093/bioinformatics/btu170; Bonawitz ND, 2008, CURR GENET, V54, P83, DOI 10.1007/s00294-008-0203-0; Byrne KP, 2005, GENOME RES, V15, P1456, DOI 10.1101/gr.3672305; Carvalho A, 2017, FEMS YEAST RES, V17, DOI 10.1093/femsyr/fox037; Chen M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2302779120; Coelho PSR, 2002, GENE DEV, V16, P2755, DOI 10.1101/gad.1035002; Decottignies A, 1998, J BIOL CHEM, V273, P12612, DOI 10.1074/jbc.273.20.12612; Ernst R, 2005, METHOD ENZYMOL, V400, P460, DOI 10.1016/S0076-6879(05)00026-1; Ferraz L, 2021, FRONT MICROBIOL, V12, DOI 10.3389/fmicb.2021.715891; Ferreira C, 2019, FEMS YEAST RES, V19, DOI 10.1093/femsyr/foz042; Gibson DG, 2009, NAT METHODS, V6, P343, DOI [10.1038/NMETH.1318, 10.1038/nmeth.1318]; Gietz RD, 2007, NAT PROTOC, V2, P31, DOI 10.1038/nprot.2007.13; Golin J, 2007, BIOCHEM BIOPH RES CO, V356, P1, DOI 10.1016/j.bbrc.2007.02.011; Gülck T, 2020, TRENDS PLANT SCI, V25, P985, DOI 10.1016/j.tplants.2020.05.005; Hanus LO, 2016, NAT PROD REP, V33, P1357, DOI 10.1039/c6np00074f; Harkany T, 2017, CELL METAB, V25, P8, DOI 10.1016/j.cmet.2016.12.020; Harris A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25574-8; Hussain T, 2019, PHYTOCHEM REV, V18, P953, DOI 10.1007/s11101-019-09638-8; Jiao X, 2022, WORLD J MICROB BIOT, V38, DOI 10.1007/s11274-022-03241-4; Kang SL, 2021, FRONT CELL NEUROSCI, V15, DOI 10.3389/fncel.2021.654340; KATZMANN DJ, 1994, MOL CELL BIOL, V14, P4653, DOI 10.1128/MCB.14.7.4653; Kihara A, 2004, MOL BIOL CELL, V15, P4949, DOI 10.1091/mbc.E04-06-0458; Kolaczkowska A, 1999, DRUG RESIST UPDATE, V2, P403, DOI 10.1054/drup.1999.0113; Kolmogorov M, 2019, NAT BIOTECHNOL, V37, P540, DOI 10.1038/s41587-019-0072-8; Li H, 2009, BIOINFORMATICS, V25, P1094, DOI [10.1093/bioinformatics/btp100, 10.1093/bioinformatics/btp324]; Liu JD, 2013, J APPL MICROBIOL, V114, P482, DOI 10.1111/jam.12046; Love MI, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0550-8; Luo XZ, 2019, NATURE, V567, P123, DOI 10.1038/s41586-019-0978-9; Ma H, 2021, J CANNABIS RES, V3, DOI 10.1186/s42238-021-00077-x; Marçais G, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005944; Miyahara K, 1996, FEBS LETT, V399, P317, DOI 10.1016/S0014-5793(96)01353-1; Naranjo S, 2015, PLOS GENET, V11, DOI 10.1371/journal.pgen.1005751; Nguyen GN, 2022, J NAT PROD, V85, P1555, DOI 10.1021/acs.jnatprod.2c00155; Oh CS, 1997, J BIOL CHEM, V272, P17376, DOI 10.1074/jbc.272.28.17376; Pollastro F, 2017, FITOTERAPIA, V123, P13, DOI 10.1016/j.fitote.2017.09.010; Rajesh M, 2007, AM J PHYSIOL-HEART C, V293, pH610, DOI 10.1152/ajpheart.00236.2007; Reglinski K, 2020, FRONT CELL DEV BIOL, V8, DOI 10.3389/fcell.2020.574363; Rimmerman N, 2013, CELL DEATH DIS, V4, DOI 10.1038/cddis.2013.471; Ro DK, 2008, BMC BIOTECHNOL, V8, DOI 10.1186/1472-6750-8-83; Romero-Suarez D, 2022, CURR OPIN GREEN SUST, V33, DOI 10.1016/j.cogsc.2021.100567; Shen HF, 1996, J BIOL CHEM, V271, P789, DOI 10.1074/jbc.271.2.789; Simao FA, 2015, BIOINFORMATICS, V31, P3210, DOI 10.1093/bioinformatics/btv351; Smith SJ, 1996, MOL CELL BIOL, V16, P5427; Stepanov A, 2008, MOL PHARMACOL, V74, P423, DOI 10.1124/mol.107.044651; Sun J, 2015, J IND MICROBIOL BIOT, V42, P423, DOI 10.1007/s10295-014-1539-8; Suttithumsatid W, 2022, CURR RES FOOD SCI, V5, P1091, DOI 10.1016/j.crfs.2022.07.002; Tamura Y, 2013, CELL METAB, V17, P709, DOI 10.1016/j.cmet.2013.03.018; Thomas F, 2020, APPL MICROBIOL BIOT, V104, P9551, DOI 10.1007/s00253-020-10798-3; Verwaal R, 2010, YEAST, V27, P983, DOI 10.1002/yea.1807; Voelker DR, 1997, BBA-LIPID LIPID MET, V1348, P236, DOI 10.1016/S0005-2760(97)00101-X; Walker BJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112963; Wolfger H, 2001, RES MICROBIOL, V152, P375, DOI 10.1016/S0923-2508(01)01209-8; Yamashita S, 1997, BBA-LIPID LIPID MET, V1348, P228, DOI 10.1016/S0005-2760(97)00102-1; Zhang YF, 2023, METAB ENG, V80, P232, DOI 10.1016/j.ymben.2023.10.004; Zheng ZF, 2001, J BIOL CHEM, V276, P41710, DOI 10.1074/jbc.M104749200; Zirpel B, 2018, J BIOTECHNOL, V272, P40, DOI 10.1016/j.jbiotec.2018.03.008	63	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2056-7189		NPJ SYST BIOL APPL	npj Syst. Biol. Appl.	MAY 31	2024	10	1							63	10.1038/s41540-024-00382-0	http://dx.doi.org/10.1038/s41540-024-00382-0			13	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	ST0G8	38821949	gold			2024-07-03	WOS:001236575500001
J	Kasapovic, A; Ali, T; Babasiz, M; Bojko, J; Gathen, M; Kaczmarczyk, R; Roos, J				Kasapovic, Adnan; Ali, Thaer; Babasiz, Mari; Bojko, Jessica; Gathen, Martin; Kaczmarczyk, Robert; Roos, Jonas			Does the Information Quality of ChatGPT Meet the Requirements of Orthopedics and Trauma Surgery?	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						large language model; medical information quality; patient education; chatgpt; artificial intelligence in medicine	ARTIFICIAL-INTELLIGENCE	Background: The integration of artificial intelligence (AI) in medicine, particularly through AI -based language models like ChatGPT, offers a promising avenue for enhancing patient education and healthcare delivery. This study aims to evaluate the quality of medical information provided by Chat Generative Pretrained Transformer (ChatGPT) regarding common orthopedic and trauma surgical procedures, assess its limitations, and explore its potential as a supplementary source for patient education. Methods: Using the GPT-3.5-Turbo version of ChatGPT, simulated patient information was generated for 20 orthopedic and trauma surgical procedures. The study utilized standardized information forms as a reference for evaluating ChatGPT's responses. The accuracy and quality of the provided information were assessed using a modified DISCERN instrument, and a global medical assessment was conducted to categorize the information's usefulness and reliability. Results: ChatGPT mentioned an average of 47% of relevant keywords across procedures, with a variance in the mention rate between 30.5% and 68.6%. The average modified DISCERN (mDISCERN) score was 2.4 out of 5, indicating a moderate to low quality of information. None of the ChatGPT-generated fact sheets were rated as "very useful," with 45% deemed "somewhat useful," 35% "not useful," and 20% classified as "dangerous." A positive correlation was found between higher mDISCERN scores and better physician ratings, suggesting that information quality directly impacts perceived utility. Conclusion: While AI -based language models like ChatGPT hold significant promise for medical education and patient care, the current quality of information provided in the field of orthopedics and trauma surgery is suboptimal. Further development and refinement of AI sources and algorithms are necessary to improve the accuracy and reliability of medical information. This study underscores the need for ongoing research and development in AI applications in healthcare, emphasizing the critical role of accurate, high -quality information in patient education and informed consent processes.	[Kasapovic, Adnan; Ali, Thaer; Babasiz, Mari; Bojko, Jessica; Gathen, Martin; Roos, Jonas] Univ Hosp Bonn, Dept Orthoped & Trauma Surg, Bonn, Germany; [Kaczmarczyk, Robert] Tech Univ Munich, Sch Med, Dept Dermatol & Allergy, Munich, Germany	University of Bonn; Technical University of Munich	Roos, J (corresponding author), Univ Hosp Bonn, Dept Orthoped & Trauma Surg, Bonn, Germany.	jonas.roos@ukbonn.de						Abidi Syed Sibte Raza, 2019, Healthc Manage Forum, V32, P178, DOI 10.1177/0840470419846134; [Anonymous], Introducing chatgpt; [Anonymous], Kunstliche Intelligenz-wir bringen Ihnen die Technologie naher; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bartschat A, 2019, KLIN MONATSBL AUGENH, V236, P1399, DOI 10.1055/a-1008-9400; Charnock D, 1999, J EPIDEMIOL COMMUN H, V53, P105, DOI 10.1136/jech.53.2.105; Chatterjee S, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00700-1; Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714; Dandekar T, 2021, Bioinformatik, DOI [10.1007/978-3-662-62399-2_14:215-29. 10.1007/978-3- 662-62399-2_14, DOI 10.1007/978-3-662-62399-2_14:215-29.10.1007/978-3-662-62399-2_14]; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Dwyer Tim, 2023, Arthrosc Sports Med Rehabil, V5, pe495, DOI 10.1016/j.asmr.2023.01.020; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giorgino R, 2023, FRONT SURG, V10, DOI 10.3389/fsurg.2023.1284015; Glaser A, 2021, DIABETOLOGE, V17, P777, DOI 10.1007/s11428-021-00827-8; Hahn P, 2019, HANDCHIR MIKROCHIR P, V51, P62, DOI 10.1055/a-0826-4789; Hernigou P, 2023, INT ORTHOP, V47, P1887, DOI 10.1007/s00264-023-05887-7; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Kivrak A, 2023, J ORTHOP SURG RES, V18, DOI 10.1186/s13018-023-03648-1; Li Q, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000018500; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Mehta N, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103311; Mentzel HJ, 2021, MONATSSCHR KINDERH, V169, P694, DOI 10.1007/s00112-021-01230-9; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Piotrowski Alexander, 2021, J Urol Urogynakologie, V28, P124, DOI 10.1007/s41972-021-00148-4; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Singh SP, 2024, Digit J Clin Med., V6, DOI [10.55691/2582-3868.1177, DOI 10.55691/2582-3868.1177]; Ulusoy I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46662; Zhang SC, 2020, BONE JOINT J, V102B, P1574, DOI 10.1302/0301-620X.102B11.BJJ-2020-0712.R2	31	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 15	2024	16	5							e60318	10.7759/cureus.60318	http://dx.doi.org/10.7759/cureus.60318			10	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	SP9E8	38882956	gold			2024-07-03	WOS:001235764300017
J	Devunuri, S; Qiam, S; Lehe, LJ				Devunuri, Saipraneeth; Qiam, Shirin; Lehe, Lewis J.			ChatGPT for GTFS: benchmarking LLMs on GTFS semantics... and retrieval	PUBLIC TRANSPORT			English	Article; Early Access						GTFS; ChatGPT; Large language models; Generative AI; GPT-3.5 Turbo; GPT-4		The General Transit Feed Specification (GTFS) standard for publishing transit data is ubiquitous. With the advent of LLMs being used widely, this research explores the possibility of extracting transit information from GTFS through natural language instructions. To evaluate the capabilities and limitations of LLMs, we introduce two benchmarks, namely "GTFS Semantics" and "GTFS Retrieval" that test how well LLMs can "understand" GTFS standards and retrieve relevant transit information. We benchmark OpenAI's GPT-3.5 Turbo and GPT-4 LLMs, which are backends for the ChatGPT interface. In particular, we use zero-shot, one-shot, chain of thought, and program synthesis techniques with prompt engineering. For our multiple questions, GPT-3.5 Turbo answers 59.7% correctly and GPT-4 answers 73.3% correctly, but they do worse when one of the multiple choice options is replaced by "None of these". Furthermore, we evaluate how well the LLMs can extract information from a filtered GTFS feed containing four bus routes from the Chicago Transit Authority. Program synthesis techniques outperformed zero-shot approaches, achieving up to 93% (90%) accuracy for simple queries and 61% (41%) for complex ones using GPT-4 (GPT-3.5 Turbo).	[Devunuri, Saipraneeth; Qiam, Shirin; Lehe, Lewis J.] Univ Illinois Urbana & Champaign, Dept Civil & Environm Engn, Urbana, IL 61820 USA	University of Illinois System; University of Illinois Urbana-Champaign	Devunuri, S (corresponding author), Univ Illinois Urbana & Champaign, Dept Civil & Environm Engn, Urbana, IL 61820 USA.	sd37@illinois.edu; sqiam2@illinois.edu; lehe@illinois.edu	Devunuri, Saipraneeth/JXN-9997-2024	Devunuri, Saipraneeth/0000-0002-5911-4681; Lehe, Lewis/0000-0001-8029-1706				Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bai F, 2024, Arxiv, DOI [arXiv:2305.14336, 10.48550/arXiv.2305.14336, DOI 10.48550/ARXIV.2305.14336]; Chen M., 2021, arXiv; Conveyal, 2024, Conveyal R5 routing engine: rapid realistic routing on real-world and reimagined networks; Devunuri S., 2024, J Open Source Softw, V9, P6306, DOI [10.21105/joss.06306, DOI 10.21105/JOSS.06306]; Devunuri S, 2024, J PUBLIC TRANSPORT, V26, DOI 10.1016/j.jpubtr.2024.100083; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Katz DM, 2024, PHILOS T R SOC A, V382, DOI 10.1098/rsta.2023.0254; Khatry A, 2023, Arxiv, DOI [arXiv:2305.01598, 10.48550/arXiv.2305.01598, DOI 10.48550/ARXIV.2305.01598]; Kim J., 2023, Findings, DOI DOI 10.32866/001C.72634; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; McHugh B., 2013, Beyond Transparency: Open Data and the Future of Civic Innovation, P125; McKinney W., 2010, P 9 PYTH SCI C, V445, P51, DOI [DOI 10.25080/MAJORA-92BF1922-00A, 10.25080/MAJORA-92BF1922-00A]; Mumtarin M, 2023, arXiv, DOI [DOI 10.48550/ARXIV.2308.13563, 10.48550/arXiv.2308.13563]; Pereira RHM, 2023, J GEOGR SYST, V25, P453, DOI 10.1007/s10109-022-00400-x; Pereira RH., 2021, Transport Findings, DOI DOI 10.32866/001C.21262; Ray PP, 2023, OBES SURG, V33, P2588, DOI 10.1007/s11695-023-06664-6; Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4; Sobania D, 2023, IEEE T EVOLUT COMPUT, V27, P82, DOI 10.1109/TEVC.2022.3162324; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Taori R, 2024, Tatsu's shared repositories; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Voss S, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15129625; Voulgaris CT., 2023, Findings, DOI DOI 10.32866/001C.57722; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Whalen D, 2024, Remix/partridge. Remix; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng O, 2023, Arxiv, DOI arXiv:2303.05382; Zhuang Y., 2023, arXiv	34	0	0	1	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1866-749X	1613-7159		PUBLIC TRANSPORT	Public Transport	2024 APR 10	2024										10.1007/s12469-024-00354-x	http://dx.doi.org/10.1007/s12469-024-00354-x		APR 2024	25	Transportation Science & Technology	Emerging Sources Citation Index (ESCI)	Transportation	NK6C1					2024-07-03	WOS:001200376600001
C	Goel, T; Shaer, O; Gu, Q; Delcourt, C; Cooper, A			ACM	Goel, Toshali; Shaer, Orit; Gu, Quan; Delcourt, Catherine; Cooper, Angel			Preparing Future Designers for Human-AI Collaboration in Persona Creation	PROCEEDINGS OF THE 2ND ANNUAL MEETING OF THE SYMPOSIUM ON HUMAN-COMPUTER INTERACTION FOR WORK, CHIWORK 2023			English	Proceedings Paper	2nd Symposium on Human-Computer Interaction for Work (CHIWORK)	JUN 13-16, 2023	Oldenburg, GERMANY			natural-language generation; human-AI collaboration; large language models; personas; education; novice designers		This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.	[Goel, Toshali; Gu, Quan; Cooper, Angel] Wellesley Coll, Wellesley, MA 02181 USA; [Shaer, Orit; Delcourt, Catherine] Wellesley Coll, Comp Sci Dept, Wellesley, MA 02181 USA	Wellesley College; Wellesley College	Goel, T (corresponding author), Wellesley Coll, Wellesley, MA 02181 USA.	tg2@wellesley.edu; oshaer@wellesley.edu; qg100@wellesley.edu; cdelcour@wellesley.edu; acooper5@wellesley.edu		Goel, Toshali/0000-0002-9438-9795; Cooper, Angelora/0000-0003-0758-7740; Gu, Quan/0000-0002-1098-9065; Shaer, Orit/0000-0002-0515-2957				Abras C., 2004, Berkshire Encyclopedia of Human-Computer Interaction, P763, DOI DOI 10.3233/WOR-2010-1109; Ahn MJ, 2022, GOV INFORM Q, V39, DOI 10.1016/j.giq.2021.101664; ANDERSON NS, 1988, AM J PSYCHOL, V101, P148, DOI 10.2307/1422802; Braun V., 2012, Research designs: Quantitative, qualitative, neuropsychological and biological, V2, P57, DOI DOI 10.1037/13620-004(RESEARCH; Dakuo Wang, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359313; Dove G, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P278, DOI 10.1145/3025453.3025739; Flavián C, 2022, J SERV MANAGE, V33, P293, DOI 10.1108/JOSM-10-2020-0378; Forrester, 2023, Generative AI, like Chatgpt, won't destroy creativity-it'll save it.; Green S, 2015, COMMUN ACM, V58, P47, DOI 10.1145/2767151; Haag M, 2019, INT J TECHNOL DES ED, V29, P565, DOI 10.1007/s10798-018-9452-5; Hämäläinen P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580688; Inkpen K, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299002; Jones M Cameron, 2008, Teaching design with personas.; Jung SG, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P321, DOI 10.1145/3176349.3176893; Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453; Marsden N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300565; Marsden Nicola, 2017, P 29 AUSTR C COMP HU, P452; Matthews Tara, 2012, P 2012 ACM ANN C HUM, P1219, DOI [DOI 10.1145/2207676.2208573, 10. 1145/2207676. 2208573.]; Mingming Fan, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512943; Nielsen L., 2002, Proceedings of DIS 2002: Serious reflection on designing interactive systems, P99; Nieters J.E., 2007, P ACM HCI 2007 C HUM, P1817, DOI [10.1145/1240866.1240905, DOI 10.1145/1240866.1240905]; Pruitt John, 2003, P 2003 C DES US EXP, P1, DOI 10.1145/997078.997089; Salminen J, 2020, INT J HUM-COMPUT ST, V141, DOI 10.1016/j.ijhcs.2020.102437; Shneiderman B, 2020, INT J HUM-COMPUT INT, V36, P495, DOI 10.1080/10447318.2020.1741118; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wang DK, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3381069; Woo DJ, 2022, Arxiv, DOI arXiv:2207.01484	27	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0807-7				2023									4	10.1145/3596671.3598574	http://dx.doi.org/10.1145/3596671.3598574			14	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Industrial Relations & Labor	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Business & Economics	BW4GN					2024-07-03	WOS:001147740200004
C	Edenberg, E; Wood, A			ACM	Edenberg, Elizabeth; Wood, Alexandra			Disambiguating Algorithmic Bias: From Neutrality to Justice	PROCEEDINGS OF THE 2023 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2023			English	Proceedings Paper	AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES)	AUG 08-10, 2023	Montreal, CANADA	Assoc Comp Machinery, AAAI, ACM SIGAI, US Natil Sci Fdn		algorithms; bias; discrimination; fairness; justice; generative AI; large language models; vision-language models; law; philosophy	ARTIFICIAL-INTELLIGENCE; FAILS	As algorithms have become ubiquitous in consequential domains, societal concerns about the potential for discriminatory outcomes have prompted urgent calls to address algorithmic bias. In response, a rich literature across computer science, law, and ethics is rapidly proliferating to advance approaches to designing fair algorithms. Yet computer scientists, legal scholars, and ethicists are often not speaking the same language when using the term 'bias.' Debates concerning whether society can or should tackle the problem of algorithmic bias are hampered by conflations of various understandings of bias, ranging from neutral deviations from a standard to morally problematic instances of injustice due to prejudice, discrimination, and disparate treatment. This terminological confusion impedes efforts to address clear cases of discrimination. In this paper, we examine the promises and challenges of different approaches to disambiguating bias and designing for justice. While both approaches aid in understanding and addressing clear algorithmic harms, we argue that they also risk being leveraged in ways that ultimately deflect accountability from those building and deploying these systems. Applying this analysis to recent examples of generative AI, our argument highlights unseen dangers in current methods of evaluating algorithmic bias and points to ways to redirect approaches to addressing bias in generative AI at its early stages in ways that can more robustly meet the demands of justice.	[Edenberg, Elizabeth] CUNY, Baruch Coll, Dept Philosophy, New York, NY 10021 USA; [Wood, Alexandra] Harvard Univ, Berkman Klein Ctr Internet & Soc, Cambridge, MA 02138 USA	City University of New York (CUNY) System; Baruch College (CUNY); Harvard University	Edenberg, E (corresponding author), CUNY, Baruch Coll, Dept Philosophy, New York, NY 10021 USA.	elizabeth.edenberg@baruch.cuny.edu; awood@cyber.harvard.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alexander M., 2010, THE NEW JIM CROW; American Civil Liberties Union, 2019, Historic Decision on Digital Bias, EEOC Finds Employers Violated Federal Law When They Excluded Women and Older Workers from Facebook Job Ads. Press Release; Amodio DM, 2006, J PERS SOC PSYCHOL, V91, P652, DOI 10.1037/0022-3514.91.4.652; Angwin J., 2016, Facebook lets advertisers exclude users by race; [Anonymous], 1967, Section 623( e) of Age Discrimination in Employment Act of 1967; [Anonymous], 1974, The Equal Credit Opportunity Act, 15USC1691; [Anonymous], 1971, Griggs v. Duke Power Co.; [Anonymous], 2007, The media and the Rwanda genocide; [Anonymous], 1968, Section 3604( c) of the Fair Housing Act; [Anonymous], 2012, Speech and harm: Controversies over free speech; [Anonymous], 2015, The black box society, DOI DOI 10.4159/HARVARD.9780674736061; [Anonymous], 1995, Adarand Constructors, Inc. v. Pena; [Anonymous], 1986, Public Order Act 1986 (c 64); [Anonymous], 2009, RICCI DESTEFANO; [Anonymous], 2015, Criminal Code of Germany.  130; [Anonymous], 2019, ALGORITHMIC ACCOUNTA; [Anonymous], 1968, Fair Housing Act; [Anonymous], 1976, Washington v. Davis; [Anonymous], 1964, Section 2000e -3(b) of Title VII of the Civil Rights Act of 1964. 42 U.S.C.  2000e -3(b); [Anonymous], 1964, Title VII of the Civil Rights Act of 1964; [Anonymous], 2020, Data Accountability and Transparency Act of 2020. S.____, 116th Cong. (Discussion Draft).; Baker RS, 2022, INT J ARTIF INTELL E, V32, P1052, DOI 10.1007/s40593-021-00285-9; Barocas Solon, 2017, NOW; Barocas Solon, 2017, The problem with bias: from allocative to representational harms in machine learning, V2; Barocas Solon, 2019, FAIRNESS MACHINE LEA; Bartl M, 2020, Arxiv, DOI arXiv:2010.14534; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benkler Y., 2018, Network propaganda: Manipulation, disinformation, and radicalization in American politics, DOI DOI 10.1093/OSO/9780190923624.001.0001; Bianchi F, 2023, Arxiv, DOI arXiv:2211.03759; Binns Reuben, 2018, P 1 C FAIRN ACC TRAN; Birhane A, 2022, arXiv, DOI [arXiv:2110.01963, DOI 10.48550/ARXIV.2110.01963]; Birhane A, 2022, Arxiv, DOI arXiv:2106.15590; Blodgett S. L., 2020, in NLP; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bommasani R., 2022, arXiv, DOI 10.48550/arXiv.2211.13972; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Burgess DJ, 2008, J HEALTH CARE POOR U, V19, P894, DOI 10.1353/hpu.0.0063; Burrell J, 2021, ANNU REV SOCIOL, V47, P213, DOI 10.1146/annurev-soc-090820-020800; Caliskan-Islam A, 2016, arXiv; Chander A, 2017, MICH LAW REV, V115, P1023; Chouldechova A, 2017, BIG DATA-US, V5, P153, DOI 10.1089/big.2016.0047; Citron DK, 2014, WASH LAW REV, V89, P1; Clark Nicole, 2022, Polygon20 December; Corbett-Davies S, 2017, Arxiv, DOI [arXiv:1701.08230, 10.1145/3097983.309809]; CostanzaChock S, 2020, INFORM POL, P1; Crawford Kate, 2017, TROUBLE BIAS KEYNOTE; Danks D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4691; Datta A, 2017, Arxiv, DOI arXiv:1707.08120; Davis JL, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211044808; Raji ID, 2020, Arxiv, DOI [arXiv:2001.00973, 10.48550/arXiv.2001.00973, DOI 10.48550/ARXIV.2001.00973]; Dev S, 2021, Arxiv, DOI arXiv:2108.12084; Dev Sunipa, 2022, Findings of the Association for Computational Linguistics: AACL-IJCNLP, P246; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; DIgnazio C, 2020, STRONG IDEAS SERIES, P1; Dwork C, 2011, Arxiv, DOI arXiv:1104.3913; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; European Commission, 2021, Proposal for a Regulation of The European Parliament and of The Council Laying Down Harmonised Rules On Artificial Intelligence (Artifi- cial Intelligence Act) and amending certain Union legislative acts COM/2021/206 final; Fazelpour S, 2021, PHILOS COMPASS, V16, DOI 10.1111/phc3.12760; Fricker M, 2008, THEORIA-SPAIN, V23, P69; Friedler SA, 2021, COMMUN ACM, V64, P136, DOI 10.1145/3433949; Friedman B, 1996, ACM T INFORM SYST, V14, P330, DOI 10.1145/230538.230561; Gadiraju Vinitha, 2023, Disabilitycentered perspectives on large language models; Glymour B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P269; Goff PA, 2008, J PERS SOC PSYCHOL, V94, P292, DOI 10.1037/0022-3514.94.2.292; Goldfarb-Tarrant S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1926; Government of Canada, 2021, Directive on Automated decision-making; Green B., 2018, P MACH LEARN DEB WOR, P1; Green B, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P594, DOI 10.1145/3351095.3372869; Green B, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P19, DOI 10.1145/3351095.3372840; Green Ben, 2018, Putting the J(ustice) in FAT; Green Ben, 2022, Philosophy & Technology, V35, P90, DOI DOI 10.1007/S13347-022-00584-6; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Guo Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1012; Gupta A, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P492, DOI 10.1145/3593013.3594015; Haines Anna, 2022, Forbes19 December; Hardt M, 2016, ADV NEUR IN, V29; Heikkila Melissa, 2022, MIT Technology Review20 September; Heikkila Melissa, 2023, MIT Technology Review24 February; Heikkila Melissa, 2022, MIT Technology Review12 December; Hellman D, 2020, VA LAW REV, V106, P811; Hendrix Justin, 2022, Researchers Find Stable Diffusion Amplifies Stereotypes; Hoffmann AL, 2019, INFORM COMMUN SOC, V22, P900, DOI 10.1080/1369118X.2019.1573912; Hong Shen, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479577; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Jacobs AZ, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P375, DOI 10.1145/3442188.3445901; Jillson E., 2021, FEDERAL TRADE COMMIS; Johnson K, 2019, FORDHAM LAW REV, V88, P499; Kalluri P, 2020, NATURE, V583, P169, DOI 10.1038/d41586-020-02003-2; Kamps Haje Jan, 2022, TechCrunch6 December; Katzman J., 2021, FAIR COMP VIS WORKSH; Kim PT, 2020, VA LAW REV, V106, P867; Kim Pauline T., 2018, St. Louis U. L.J., V63, P93; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Kirk H, 2021, Arxiv, DOI arXiv:2102.04130; Klee Miles, 2022, Rolling Stone12 December; Kleinberg J, 2016, Arxiv, DOI [arXiv:1609.05807, DOI 10.48550/ARXIV.1609.05807, 10.48550/arXiv.1609.05807]; Kleinberg J, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2018340118; Kleinberg J, 2018, J LEGAL ANAL, V10, P113, DOI 10.1093/jla/laz001; Kuppler M, 2022, FRONT SOCIOL, V7, DOI 10.3389/fsoc.2022.883999; Le Bui Matthew, 2020, The Oxford Handbook of Ethics of AI; Liang PP, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.13219; Mehrabi Ninareh, 2019, A survey on bias and fairness in machine learning; Mercado Mia, 2022, The Cut12 December; Miller Alex P., 2018, HARV. BUS. REV; Mitchell S, 2021, ANNU REV STAT APPL, V8, P141, DOI 10.1146/annurev-statistics-042720-125902; Morris Loveday, 2021, Washington Post25 October; Mulligan Deirdre K., 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359221; Munoz C., 2016, Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights; Nanayakkara P, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P795, DOI 10.1145/3461702.3462608; Narayanan Arvind, 2022, 2022 JAMES BALDWIN L; Narayanan Arvind., 2018, TUT C FAIRN ACC TRAN; Nissim K, 2021, 2021 THIRD IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS (TPS-ISA 2021), P235, DOI 10.1109/TPSISA52974.2021.00026; Nissim K, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2017.0358; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; Ochigame R., 2020, Phenomenal World; Ochigame Rodrigo, 2018, INT C MACH LEARN; Ofqual, 2020, AW GCSE AS LEV ADV E; ONeil Cathy, 2016, WEAPONS MATH DESTRUC; OpenAI, 2023, OpenAI Blog; Powles Julia, 2018, MEDIUM; Prisma Labs, 2023, Lensa's Magic Avatars Explained; Rawls John., 1971, A theory of justice, DOI [10.2307/j.ctvjf9z6v, DOI 10.2307/J.CTVJF9Z6V, DOI 10.4159/9780674042605]; Rawls John., 2005, POLITICAL LIBERALISM; Savoldi B, 2021, Arxiv, DOI arXiv:2104.06001; Schwartz R., 2022, STANDARD IDENTIFYING, P1270, DOI DOI 10.6028/NIST.SP.1270; Selbst AD, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P59, DOI 10.1145/3287560.3287598; Singh J, 2021, AI and Ethics, V1, P529, DOI DOI 10.1007/S43681-021-00067-Y; SLUSHER MP, 1987, J PERS SOC PSYCHOL, V52, P653, DOI 10.1037/0022-3514.52.4.653; Smith Andrew, 2020, Federal Trade Commission Business Blog8 April; Snow Olivia, 2022, Wired7 December; Sottile Zoe, 2022, CNN Style11 December; Steed R, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P701, DOI 10.1145/3442188.3445932; Suk JCH, 2006, U ILLINOIS LAW REV, P405; Suresh Harini, 2021, P ACM EQUITY ACCESS, DOI [10.1145/3465416.3483305, DOI 10.1145/3465416.3483305]; Sweeney L., 2013, Communications of ACM, V11, P10, DOI [DOI 10.1145/2447976.2447990, 10.1145/2460276.2460278]; TUKEY JW, 1962, ANN MATH STAT, V33, P1, DOI 10.1214/aoms/1177704711; Tutt A, 2017, ADMIN LAW REV, V69, P83, DOI 10.2139/ssrn.2747994; U.S. Department of Housing and Urban Development, 2019, FHEONo.01-18-0323-8; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Weinberger D., 2019, Harvard Business Review; White House Office of Science and Technology Policy, 2022, Blueprint for an AI bill of rights: making automated systems work for the American people; WINNER L, 1980, DAEDALUS, V109, P121; Wolfe R, 2023, Arxiv, DOI arXiv:2212.11261; Wolfe Robert, 2022, P 2022 ACM C FAIRN A; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Zhao Dora, 2021, arXiv	147	1	1	12	12	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0231-0				2023							691	704		10.1145/3600211.3604695	http://dx.doi.org/10.1145/3600211.3604695			14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Ethics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BW2KK		Green Published			2024-07-03	WOS:001117838100053
C	Sadeghi, M; Egger, B; Agahi, R; Richer, R; Capito, K; Rupp, LH; Schindler-Gmelch, L; Berking, M; Eskofier, BM			IEEE	Sadeghi, Misha; Egger, Bernhard; Agahi, Reza; Richer, Robert; Capito, Klara; Rupp, Lydia Helene; Schindler-Gmelch, Lena; Berking, Matthias; Eskofier, Bjoern M.			Exploring the Capabilities of a Language Model-Only Approach for Depression Detection in Text Data	2023 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, BHI	IEEE EMBS International Conference on Biomedical and Health Informatics		English	Proceedings Paper	IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	OCT 15-18, 2023	Pittsburgh, PA	IEEE, IEEE Engn Med & Biol Soc, IEEE Future Direct, Natil Inst Hlth, Google, NSF, UPMC Hillman Canc Ctr		Depression detection; mental health; large language models; text analysis; DAIC dataset; GPT-based models; DepRoBERTa		Depression is a prevalent and debilitating mental health condition that requires accurate and efficient detection for timely and effective treatment. In this study, we utilized the E-DAIC (Extended Distress Analysis Interview Corpus-Wizard-of-Oz) dataset, an extended version of the DAIC-WOZ dataset, which consists of semi-clinical interviews conducted by an animated virtual interviewer called Ellie, controlled by a human interviewer in another room. With 275 participants, the E-DAIC dataset represents a valuable resource for investigating depression detection methods. Our aim is to predict PHQ-8 scores through text analysis. Leveraging state-of-the-art speech processing, LLM-based text summarization, and a specialized depression detection module, we demonstrate the transformative potential of language data analysis in enhancing depression screening. By overcoming the limitations of manual feature extraction methods, our automated techniques provide a more efficient and effective means of evaluating depression. In our evaluation, we achieve robust accuracy on the development set of the E-DAIC dataset, with a Mean Absolute Error (MAE) of 3.65 in estimating PHQ-8 scores from recorded interviews. This remarkable performance highlights the efficacy of our approach in automatically predicting depression severity. Our research contributes to the growing evidence supporting the use of LLMs in mental health assessment, showcasing the role of innovative technologies in advancing patient care for depression.	[Sadeghi, Misha; Richer, Robert; Eskofier, Bjoern M.] Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Artificial Intelligence Biomed Engn, Machine Learning & Data Analyt Lab, D-91052 Erlangen, Germany; [Egger, Bernhard] Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Comp Sci, Chair Visual Comp, D-91058 Erlangen, Germany; [Agahi, Reza] Syenah GMBH, D-65760 Eschborn, Germany; [Capito, Klara; Rupp, Lydia Helene; Schindler-Gmelch, Lena; Berking, Matthias] Friedrich Alexander Univ Erlangen Nurnberg FAU, Chair Clin Psychol & Psychotherapy, D-91052 Erlangen, Germany	University of Erlangen Nuremberg; University of Erlangen Nuremberg; University of Erlangen Nuremberg	Sadeghi, M (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Artificial Intelligence Biomed Engn, Machine Learning & Data Analyt Lab, D-91052 Erlangen, Germany.	misha.sadeghi@fau.de			Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [SFB 1483, 442419336]	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG))	This work was supported by the Deutsche Forschungsge-meinschaft (DFG, German Research Foundation) -SFB 1483 -Project-ID 442419336, EmpkinS.	Alhanai T, 2018, INTERSPEECH, P1716, DOI 10.21437/Interspeech.2018-2522; [Anonymous], deproberta-large-depression; Carey M, 2014, AUST NZ J PSYCHIAT, V48, P571, DOI 10.1177/0004867413520047; Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260; D. American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders: DSM-5, V5; DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061; Ekman P., 1978, ENVIRON PSYCH NONVER, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Gong Y., 2017, Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge, P69, DOI [DOI 10.1145/3133944.3133945, 10.1145/3133944.3133945]; Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123; Kroenke K, 2009, J AFFECT DISORDERS, V114, P163, DOI 10.1016/j.jad.2008.06.026; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Nasir M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P43, DOI 10.1145/2988257.2988261; Niu M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4235, DOI 10.1109/ICASSP39728.2021.9413486; Niu MY, 2019, INTERSPEECH, P4559, DOI 10.21437/Interspeech.2019-1617; OpenAI, Openai gpt-3.5 model documentation; Oureshi SA, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534330; Poswiata R, 2022, PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022), P276; Prabhu S, 2022, PATTERN ANAL APPL, V25, P537, DOI 10.1007/s10044-021-01020-9; Qureshi SA, 2019, Arxiv, DOI arXiv:1904.07656; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Ray A., 2019, P 9 INT AUD VIS EM, P81, DOI [10.48550/arXiv.1909.01417, DOI 10.1145/3347320.3357697]; Ringeval F., 2019, P 9 INT AUDIOVISUAL, P3, DOI [DOI 10.1145/3347320.3357688, 10.1145/3347320.3357688]; Rohanian M, 2019, INTERSPEECH, P1443, DOI 10.21437/Interspeech.2019-2283; Scherer S, 2014, IMAGE VISION COMPUT, V32, P648, DOI 10.1016/j.imavis.2014.06.001; Shen Y, 2022, INT CONF ACOUST SPEE, P6247, DOI 10.1109/ICASSP43922.2022.9746569; Song SY, 2022, IEEE T AFFECT COMPUT, V13, P829, DOI 10.1109/TAFFC.2020.2970712; Stepanov EA, 2018, 2018 IEEE 20TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM); Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258; Williamson JR, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P11, DOI 10.1145/2988257.2988263; Yang L., 2017, P 7 ANN WORKSH AUD V, P45, DOI DOI 10.1145/3133944.3133950; Yang L., 2017, P 7 ANN WORKSH AUD V, P53, DOI DOI 10.1145/3133944.3133948; Yin S., 2019, P 9 INT AUD VIS EM C, P65	32	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2641-3590		979-8-3503-1050-4	Biomedical Health In			2023										10.1109/BHI58575.2023.10313367	http://dx.doi.org/10.1109/BHI58575.2023.10313367			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering; Medical Informatics	BW1KL					2024-07-03	WOS:001107519300005
C	Farfade, S; Vernekar, S; Chaoji, VE; Mukherj, RD			Assoc computing machinery	Farfade, Sachin; Vernekar, Sachin; Chaoji, Vine Et; Mukherj, Raj Deep			Scaling Use-case Based Shopping using LLMs	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		e-commerce; use-case extraction; instruction tuning; large language models; generalizability; task adaptation; Claude		Products on e-commerce websites are usually organized based on seller-provided product attributes. Customers looking for a product typically have certain needs or product use-cases in mind, for e.g., a headphone for gym classes, or a printer for a small business. However, they often struggle to map these use-cases to product attributes and subsequently fail to find the product they need. In this talk, we present a use-case based shopping (UBS) ML system that facilitates use-case based customer experiences (CXs). The UBS system recommends dominant product use-cases to customers along with most relevant products for those use-cases. Use-cases and their definitions vary across product categories and marketplaces (MPs). This makes training supervised models for thousands of e-commerce categories and multiple MPs infeasible by collecting large amount training data needed to train these models. In this talk, we present our work on scaling the UBS model by instruction tuning an LLM for our task.	[Farfade, Sachin; Vernekar, Sachin; Chaoji, Vine Et] Amazon, Hyderabad, India; [Mukherj, Raj Deep] IIT Kharagpur, Kharagpur, W Bengal, India	Amazon.com; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur	Farfade, S (corresponding author), Amazon, Hyderabad, India.	sfarfade@amazon.com; svernek@amazon.com; vchaoji@amazon.com; rajdeep1989.iitkgp@gmail.com		Mukherjee, Rajdeep/0000-0002-2267-1695				Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Longpre S, 2023, Arxiv, DOI arXiv:2301.13688; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Raffel C, 2020, J MACH LEARN RES, V21; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	6	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1165	1166		10.1145/3616855.3635748	http://dx.doi.org/10.1145/3616855.3635748			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100150
J	Blazevic, M; Sina, LB; Secco, CA; Siegel, M; Nazemi, K				Blazevic, Midhad; Sina, Lennart B.; Secco, Cristian A.; Siegel, Melanie; Nazemi, Kawa			Real-Time Ideation Analyzer and Information Recommender	ELECTRONICS			English	Article						real-time recommendation systems; large language models; natural language processing; transdisciplinary ideation; ideation support	TRANSDISCIPLINARY RESEARCH	The benefits of ideation for both industry and academia alike have been outlined by countless studies, leading to research into various approaches attempting to add new ideation methods or examine how the quality of the ideas and solutions created can be measured. Although AI-based approaches are being researched, there is no attempt to provide the ideation participants with information that inspire new ideas and solutions in real time. Our proposal presents a novel and intuitive approach that supports users in real time by providing them with relevant information as they conduct ideation. By analyzing their ideas within the respective ideation sessions, our approach recommends items of interest with high contextual similarity to the proposed ideas, allowing users to skim through, for example, publications and inspire new ideas quickly. The recommendations also evolve in real time. As more ideas are written during the ideation session, the recommendations become more precise. This real-time approach is instantiated with various ideation methods as a proof of concept, and various models are evaluated and compared to identify the best model for working with ideas.	[Blazevic, Midhad; Sina, Lennart B.; Secco, Cristian A.; Siegel, Melanie; Nazemi, Kawa] Darmstadt Univ Appl Sci, Human Comp Interact & Visual Analyt, D-64295 Darmstadt, Germany	Hochschule Darmstadt	Blazevic, M (corresponding author), Darmstadt Univ Appl Sci, Human Comp Interact & Visual Analyt, D-64295 Darmstadt, Germany.	midhad.blazevic@h-da.de	Blazevic, Midhad/HNI-4811-2023	Blazevic, Midhad/0000-0002-6313-8125				[Anonymous], 2017, Research methods in human-computer interaction, DOI DOI 10.1016/B978-0-12-805390-4.00014-5; Badura V, 2010, P ANN HICSS, P535; Bernstein JH, 2015, J RES PRACT, V11; Bilgram Volker, 2023, IEEE Engineering Management Review, P18, DOI 10.1109/EMR.2023.3272799; Blazevic M, 2023, IEEE INT CONF INF VI, P259, DOI 10.1109/IV60283.2023.00052; Blazevic M, 2022, IEEE INT CONF INF VI, P293, DOI 10.1109/IV56949.2022.00057; Blazevic M, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12071699; Boeckle M, 2015, INT C COMP SUPP COOP, P159, DOI 10.1109/CSCWD.2015.7230951; Breytenbach J, 2020, 2020 THE 6TH IEEE INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2020), P343, DOI 10.1109/ICIM49319.2020.245373; Calderón FH, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P597, DOI 10.1145/3341161.3343689; Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14; Cohan A, 2020, Arxiv, DOI arXiv:2004.07180; de Jong SPL, 2016, RES POLICY, V45, P1397, DOI 10.1016/j.respol.2016.04.008; Deo SR, 2017, 2017 INTERNATIONAL CONFERENCE ON TRANSFORMING ENGINEERING EDUCATION (ICTEE); Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dogra V, 2024, IEEE ACCESS, V12, P26183, DOI 10.1109/ACCESS.2024.3360306; Eldesoky AI, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P145, DOI 10.1109/ICCES.2009.5383292; Furue N., 2022, P 2022 PORTL INT C M, P1, DOI [10.23919/PICMET53225.2022.9882607, DOI 10.23919/PICMET53225.2022.9882607]; Gaziulusoy AI, 2016, J CLEAN PROD, V123, P55, DOI 10.1016/j.jclepro.2015.08.049; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Hauge J.B., 2008, P 2008 IEEE INT TECH, P1; Hesmer A., 2007, P 2007 IEEE INT TECH, P1; Hesmer A., 2009, P 2009 IEEE INT TECH, P1, DOI [10.1109/ITMC.2009.7461375, DOI 10.1109/ITMC.2009.7461375]; Hoffmann S, 2017, RES POLICY, V46, P678, DOI 10.1016/j.respol.2017.01.004; Honnibal M., 2020, spaCy: Industrial-strength Natural Language Processing in Python; Iyer LR, 2010, IEEE IJCNN; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Jesse M, 2022, USER MODEL USER-ADAP, DOI 10.1007/s11257-022-09351-w; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Joosten Jan, 2024, IEEE Engineering Management Review, V52, P153, DOI 10.1109/EMR.2024.3353338; Kerr C.I.V., 2009, P PICMET 09 2009 POR, P2475, DOI [10.1109/PICMET.2009.5261838, DOI 10.1109/PICMET.2009.5261838]; Klein JT, 2008, AM J PREV MED, V35, pS116, DOI 10.1016/j.amepre.2008.05.010; Knoll S.W., 2011, P 2011 44 HAW INT C, P1, DOI [10.1109/HICSS.2011.416, DOI 10.1109/HICSS.2011.416]; Knoll SW, 2010, P ANN HICSS, P239; Kozitsin I.V., 2020, P 2020 13 INT C MAN, P1, DOI [10.1109/MLSD49919.2020.9247720, DOI 10.1109/MLSD49919.2020.9247720]; Lawrence R.J., 2010, Transdiscipl. J. Eng. Sci, V1, P125, DOI DOI 10.22545/2010/0003; LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110; Li B., 2023, P INT C HIGH PERF CO, DOI [10.1145/3581784.3607034, DOI 10.1145/3581784.3607034]; Maalej M., 2017, Cooperative Design, Visualization, and Engineering, P77; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Pohan H.I., 2022, P 2022 1 INT C INF S, P376, DOI [10.1109/ICISIT54091.2022.9873070, DOI 10.1109/ICISIT54091.2022.9873070]; Publications Office, 2022, CORDIS-EU Research Projects under HORIZON EUROPE (2021-2027), DOI [10.2906/112117098108/20, DOI 10.2906/112117098108/20]; React, About us; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Reinig B.A., 2006, System Sciences, V1, P20, DOI DOI 10.1109/HICSS.2006.270; Rigolot C, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-00598-5; SHAW T, 1993, IEEE T SYST MAN CYB, V23, P737, DOI 10.1109/21.256546; Sina LB, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12092019; Su HJ, 2023, Arxiv, DOI arXiv:2212.09741; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vivacqua A, 2008, INT C COMP SUPP COOP, P951; Wang Jinglei, 2022, 2022 2nd International Conference on Big Data Engineering and Education (BDEE), P53, DOI 10.1109/BDEE55929.2022.00016; WikiCFP, CALL PAP C WORKSH J; Yang Z, 2023, INNOV AGING, V7, P40, DOI 10.26599/IJCS.2022.9100030; Ziegler C.-N., 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754; Zimmerling E, 2016, P ANN HICSS, P837, DOI 10.1109/HICSS.2016.108	60	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	MAY	2024	13	9							1761	10.3390/electronics13091761	http://dx.doi.org/10.3390/electronics13091761			25	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	QH0G5		gold			2024-07-03	WOS:001219863900001
J	Thelwall, M				Thelwall, Mike			Can ChatGPT evaluate research quality?	JOURNAL OF DATA AND INFORMATION SCIENCE			English	Article						ChatGPT; Large Language Models; LLM; Research Excellence Framework; REF 2021; Research quality; Research assessment		Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research evaluations on journal articles to automate this time-consuming task. Design/methodology/approach: Test the extent to which ChatGPT-4 can assess the quality of journal articles using a case study of the published scoring guidelines of the UK Research Excellence Framework (REF) 2021 to create a research evaluation ChatGPT. This was applied to 51 of my own articles and compared against my own quality judgements. Findings: ChatGPT-4 can produce plausible document summaries and quality evaluation rationales that match the REF criteria. Its overall scores have weak correlations with my self-evaluation scores of the same documents (averaging r=0.281 over 15 iterations, with 8 being statistically significantly different from 0). In contrast, the average scores from the 15 iterations produced a statistically significant positive correlation of 0.509. Thus, averaging scores from multiple ChatGPT-4 rounds seems more effective than individual scores. The positive correlation may be due to ChatGPT being able to extract the author's significance, rigour, and originality claims from inside each paper. If my weakest articles are removed, then the correlation with average scores (r=0.200) falls below statistical significance, suggesting that ChatGPT struggles to make fine-grained evaluations. Research limitations: The data is self-evaluations of a convenience sample of articles from one academic in one field. Practical implications: Overall, ChatGPT does not yet seem to be accurate enough to be trusted for any formal or informal research quality evaluation tasks. Research evaluators, including journal editors, should therefore take steps to control its use. Originality/value: This is the first published attempt at post-publication expert review accuracy testing for ChatGPT.	[Thelwall, Mike] Univ Sheffield, Informat Sch, Sheffield S10 2TN, England	University of Sheffield	Thelwall, M (corresponding author), Univ Sheffield, Informat Sch, Sheffield S10 2TN, England.	m.thelwall@wlv.ac.uk	Thelwall, Mike/JDV-4700-2023	Thelwall, Mike/0000-0001-6065-205X				Baker M, 2016, NATURE, V540, P151, DOI 10.1038/540151a; Bornmann L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014331; Buriak JM, 2023, ACS ENERGY LETT, V9, P191, DOI 10.1021/acsenergylett.3c02586; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Feng YH, 2023, P INT COMP SOFTW APP, P876, DOI 10.1109/COMPSAC57700.2023.00117; Flanagin A, 2023, JAMA-J AM MED ASSOC, V330, P702, DOI 10.1001/jama.2023.12500; Garcia MB, 2024, ANN BIOMED ENG, V52, P139, DOI 10.1007/s10439-023-03299-7; Gov.uk, 2023, GUIDANCE EXCEPTIONS; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Huang JS, 2023, AM J CANCER RES, V13, P1148; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Langfeldt L, 2020, MINERVA, V58, DOI 10.1007/s11024-019-09385-2; Liang W., 2023, ARXIV; Memon AR, 2020, J KOREAN MED SCI, V35, DOI 10.3346/jkms.2020.35.e217; Mollaki, 2024, RES ETHICS; Nazir Anam, 2023, Meta Radiol, V1, DOI 10.1016/j.metrad.2023.100022; OpenAI, 2023, ArXiv; Perkins M., 2024, F1000RESEARCH, V12, P1398; REF, 2019, PANEL CRITERIA WORKI; REF, 2019, GUIDANCE SUBMISSIONS; Sivertsen G, 2017, PALGR COMMUN, V3, DOI 10.1057/palcomms.2017.78; Thelwall M, 2023, QUANT SCI STUD, V4, P547, DOI 10.1162/qss_a_00258; Thelwall M, 2023, J DOC, V79, P1514, DOI 10.1108/JD-01-2023-0012; Wei X., 2023, ARXIV; Wilsdon J., 2015, METRIC TIDE REPORT I, DOI [10.13140/RG.2.1.4929.1363, DOI 10.13140/RG.2.1.4929.1363]; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Zhao XQ, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103028	28	0	0	5	5	SCIENDO	WARSAW	BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND	2096-157X	2543-683X		J DATA INFO SCI	J. Data Info. Sci.	APR 1	2024	9	2					1	21		10.2478/jdis-2024-0013	http://dx.doi.org/10.2478/jdis-2024-0013		APR 2024	21	Information Science & Library Science	Emerging Sources Citation Index (ESCI)	Information Science & Library Science	SA7B9					2024-07-03	WOS:001210978100001
J	Li, JY; Song, SL; Li, YX; Zhang, HX; Hu, GN				Li, Jingyang; Song, Shengli; Li, Yixin; Zhang, Hanxiao; Hu, Guangneng			ChatMDG: A discourse parsing graph fusion based approach for multi-party dialogue generation	INFORMATION FUSION			English	Article						Multi-party dialogue; Dialogue generation; Discourse parsing; Semantic-enriched graph; Large language models	NETWORK	Comprehending multi -party dialogue generation poses a challenge due to intricate speaker interactions, where multiple participants engage in a dynamic exchange of questions and responses, assuming diverse roles such as speaker, receiver, and observer, with these roles evolving across conversational turns. Most existing research on multi -party dialogue generation only considers semantic information contained in each sentence and does not take into account the dialogue flow information implicit in multi -role interaction, leading to difficulties in accurately understanding the dialogue state in multi -party dialogue. To fill these gaps, we introduce an information fusion based approach for M ulti -party D ialogue G eneration named ChatMDG , which integrates role interaction into a semantic-enriched graph with context -based embeddings to cooperatively capture both global and local information in multi -party dialogue. Specifically, we proposes a graph-based network to represent the complex role-interaction dialogue structure for discourse parsing and then designs the dialogue flow encoding method to fuse role-interaction information with semantic states effectively. Furthermore, ChatMDG presents interaction strategies to correspondingly generate reactive and proactive utterances based on the fused embeddings, which lead to more dialogue coherence and user engagement. Experimental results show that ChatMDG significantly improves the accuracy of the multi -party response generation task, especially in complex scenarios with multiple interactions.	[Li, Jingyang; Song, Shengli; Li, Yixin; Zhang, Hanxiao; Hu, Guangneng] Xidian Univ, Sch Comp Sci & Technol, Xian 710126, Shaanxi, Peoples R China	Xidian University	Song, SL (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710126, Shaanxi, Peoples R China.	liyixin@stu.xidian.edu.cn; shlsong@xidian.edu.cn; liyixin@stu.xidian.edu.cn; zhanghx@stu.xidian.edu.cn; huguangneng@xidian.edu.cn			National Natural Science Foundation of China [62306220]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by National Natural Science Foundation of China (No. 62306220) .	Addlesee A, 2024, 2024 ACM IEEE INT C, P123; Addlesee Angus, 2024, P 18 C EUR CHAPT ASS, P62; Addlesee Angus, 2024, 2024 ACM IEEE INT C, P1273; Chen JA, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1380; Chen Nuo, 2024, Compress to impress: Unleashing the potential of compressive memory in real-world long-term conversations; Chen Q, 2023, FINDINGS ASS COMPUTA; Chernyavskiy Alexander, 2024, P 5 WORKSH COMP APPR, P149; Chi Ta-Chung, 2022, P 23 ANN M SPEC INT, P325; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Hu WP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5010; Jia Q, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1911; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kong YW, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7433, DOI 10.1109/ICASSP39728.2021.9413753; Li Jinpeng, 2023, 2023 C EMP METH NAT; Li Junnan, 2020, P 28 INT C COMP LING, DOI DOI 10.18653/V1/2020.COLING-MAIN.238; Liu C., 2019, P 23 C COMPUTATIONAL, P718; Liu J, 2024, ACM T ASIAN LOW-RESO, V23, DOI 10.1145/3644074; Liu Zhengyuan, 2021, P 2 WORKSH COMP APPR, P122; Mahajan Khyati, 2022, P 15 INT C NAT LANG, P278; Mao R, 2024, INFORM FUSION, V101, DOI 10.1016/j.inffus.2023.101988; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Nguyen-Mau T, 2024, INFORM FUSION, V104, DOI 10.1016/j.inffus.2023.102202; Ouchi Hiroki, 2016, P 2016 C EMP METH NA, P2133; Qiu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1889; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Serban IV, 2016, AAAI CONF ARTIF INTE, P3776; Shang LF, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1577; Shen Weizhou, 2023, ICASSP 2023, P1; Shi ZX, 2019, AAAI CONF ARTIF INTE, P7007; Shi Zhouxing, 2019, P 33 AAAI C ART INT; Song Q, 2022, INT CONF ACOUST SPEE, P6587, DOI 10.1109/ICASSP43922.2022.9746498; Su JS, 2017, AAAI CONF ARTIF INTE, P3302; Uthus DC, 2013, ARTIF INTELL, V199, P106, DOI 10.1016/j.artint.2013.02.004; Uthus David C., 2013, AAAI SPRING S AN MIC; Velickovic G., 2018, 6 INT C LEARNING REP; Wang Ante, 2021, P 30 INT JOINT C ART, P3943; Wang WS, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6581; Wei Jimmy, 2023, Multi-party chat: Conversational agents in group settings with humans and models; Wen JT, 2023, INFORM FUSION, V91, P123, DOI 10.1016/j.inffus.2022.10.009; Xing C, 2018, AAAI CONF ARTIF INTE, P5610; Xing Chen, 2018, P 32 AAAI C ART INT; Yang D., 2020, Proceedings of Machine Learning Research, P593; Zhang R, 2018, AAAI CONF ARTIF INTE, P5690; Zhang WN, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3522763; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zheng W, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P709, DOI 10.1145/3357384.3357889; Zhu LY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P298	47	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	OCT	2024	110								102469	10.1016/j.inffus.2024.102469	http://dx.doi.org/10.1016/j.inffus.2024.102469			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TU2O5					2024-07-03	WOS:001243708700001
J	Chen, AI; Ferris, LK; Nambudiri, VE; Piette, EW				Chen, Annie I.; Ferris, Laura K.; Nambudiri, Vinod E.; Piette, Evan W.			ChatRx: ChatGPT's potential to educate patients on medication adverse effects	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Editorial Material						artificial intelligence; ChatGPT; clinical research; dermatology; drug side effects; general dermatology; innovation; large language models; medical education; patients; technology; medical dermatology			[Chen, Annie I.; Ferris, Laura K.] Univ Pittsburgh, Sch Med, Dept Dermatol, Pittsburgh, PA USA; [Nambudiri, Vinod E.; Piette, Evan W.] Brigham & Womens Hosp, Dept Dermatol, Boston, MA USA; [Nambudiri, Vinod E.; Piette, Evan W.] Harvard Med Sch, Boston, MA USA; [Piette, Evan W.] 221 Longwood Ave, Suite 149, Boston, MA 02115 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School	Piette, EW (corresponding author), 221 Longwood Ave, Suite 149, Boston, MA 02115 USA.	epiette@bwh.harvard.edu						Chen R, 2023, J AM ACAD DERMATOL, V89, P872, DOI 10.1016/j.jaad.2023.05.088; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jeha GM, 2023, J INVEST DERMATOL, V143, P2105, DOI 10.1016/j.jid.2023.05.018; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044	4	0	0	12	12	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	MAR	2024	90	3					669	670		10.1016/j.jaad.2023.11.008	http://dx.doi.org/10.1016/j.jaad.2023.11.008		FEB 2024	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	JC6U0	37952568				2024-07-03	WOS:001171004100001
J	Polakova, P; Klimova, B				Polakova, Petra; Klimova, Blanka			Implementation of AI-driven technology into education - a pilot study on the use of chatbots in foreign language learning	COGENT EDUCATION			English	Article						Second language acquisition; artificial intelligence; conversational systems; technology in language learning; experiment; chatbot; large language models		Thanks to the continuous development of artificial intelligence (AI), more and more tools are available to help students to practice their language skills. Nowadays, there are various ways of using AI-driven technology in the process of language learning, one example is the use of chatbots. This pilot study aims to investigate the impact of the conversational chatbot on learning a foreign language and to understand learners' perceptions of using a chatbot as a complementary language tool. Altogether 58 university students learning English as an applied foreign language with B2 and C1 levels of English proficiency participated in the experiment during the period of one month. The qualitative results show a significant improvement in the student's language skills thanks to the use of smart AI. Furthermore, the questionnaire survey reveals positive perceptions of this additional learning tool. Therefore, the findings indicate that working with this AI-driven technology can contribute to improving language skills and its perceived usefulness in the process of second language acquisition at the university level.	[Polakova, Petra; Klimova, Blanka] Univ Hradec Kralove, Fac Informat & Management, Dept Appl Linguist, Hradec Kralove, Czech Republic	University of Hradec Kralove	Polakova, P (corresponding author), Univ Hradec Kralove, Fac Informat & Management, Dept Appl Linguist, Hradec Kralove, Czech Republic.	petra.polakova.3@uhk.cz			SPEV	SPEV	This study was supported by the SPEV project 2024, run at the Faculty of Informatics and Management of the University of Hradec Kralove, Czech Republic. The authors thank Ond & rcaron;ej Doubek and Jan Zabransk & yacute; for their help with data processing.	Akgun Selin, 2022, AI Ethics, V2, P431, DOI 10.1007/s43681-021-00096-7; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bean S., 2018, Generations divide on the role of Artificial Intelligence in the workplace; Belda-Medina J, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00432-3; Belda-Medina J, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178427; Bryant C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P793, DOI 10.18653/v1/P17-1074; Dokukina Irina, 2020, Procedia Computer Science, P542, DOI 10.1016/j.procs.2020.02.212; Essel H. B., 2024, Computers and Education: Artificial Intelligence, V6, DOI DOI 10.1016/J.CAEAI.2023.100198; Essel HB, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00362-6; Fitria T. N., 2021, ELT Echo: The Journal of English Language Teaching in Foreign Language Context, V6, P213; Golic Z., 2019, Zbornik Radova Ekonomskog Fakulteta u Istonom Sarajevu, V19, P67, DOI DOI 10.7251/ZREFIS1919067G; Haristiani Nuria, 2019, Journal of Physics: Conference Series, V1387, DOI 10.1088/1742-6596/1387/1/012020; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100115; Jeon J, 2023, COMPUT ASSIST LANG L, V36, P1338, DOI 10.1080/09588221.2021.1987272; Kalyan K. S., 2024, Natural Language Processing Journal, V6, DOI [DOI 10.1016/J.NLP.2023.100048, 10.1016/j.nlp.2023.100048]; Kamelabad M. A., 2022, Early Language Development in the Digital Age; Kim J, 2022, EDUC INF TECHNOL, V27, P6069, DOI 10.1007/s10639-021-10831-6; Klimova B, 2024, FRONT PSYCHOL, V15, DOI 10.3389/fpsyg.2024.1269319; Klimova B, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11010042; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Lee YF, 2022, ETR&D-EDUC TECH RES, V70, P1843, DOI 10.1007/s11423-022-10142-8; Mageira K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073239; Mahmoud R. H., 2022, Implementing AI-based conversational chatbots in EFL speaking classes: an evolutionary perspective; Montenegro-Rueda M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080153; Nghi T. T., 2019, International Journal of Scientific Technology Research, V8, P12; Petrovi J., 2021, Studies in Computational Intelligence, V973, P313; Rothe S, 2022, Arxiv, DOI arXiv:2106.03830; Schmidt T., 2022, Anglistik, V33, P165, DOI [10.33675/ANGL/2022/1/14, DOI 10.33675/ANGL/2022/1/14]; Yin Q., 2020, International Online Journal of Education and Teaching (IOJET), V7, P390; Yu H, 2024, HELIYON, V10, DOI 10.1016/j.heliyon.2024.e24289; Zhang RF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2202704; Ziatdinov R, 2024, SOCIETIES, V14, DOI 10.3390/soc14020019	33	0	0	11	11	TAYLOR & FRANCIS AS	OSLO	KARL JOHANS GATE 5, NO-0154 OSLO, NORWAY	2331-186X			COGENT EDUC	Cogent Educ.	DEC 31	2024	11	1							2355385	10.1080/2331186X.2024.2355385	http://dx.doi.org/10.1080/2331186X.2024.2355385			15	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	SY8S4		gold			2024-07-03	WOS:001238108600001
J	Jedrzejczak, WW; Kochanek, K				Jedrzejczak, W. Wiktor; Kochanek, Krzysztof			Comparison of the Audiological Knowledge of Three Chatbots: ChatGPT, Bing Chat, and Bard	AUDIOLOGY AND NEUROTOLOGY			English	Article; Early Access						Chatbot; Large language model; Natural language processing; Artificial intelligence; Chat Generative Pre-trained Transformer; Bing; Bard	ACCURACY	Introduction: The purpose of this study was to evaluate three chatbots - OpenAI ChatGPT, Microsoft Bing Chat (currently Copilot), and Google Bard (currently Gemini) - in terms of their responses to a defined set of audiological questions. Methods: Each chatbot was presented with the same 10 questions. The authors rated the responses on a Likert scale ranging from 1 to 5. Additional features, such as the number of inaccuracies or errors and the provision of references, were also examined. Results: Most responses given by all three chatbots were rated as satisfactory or better. However, all chatbots generated at least a few errors or inaccuracies. ChatGPT achieved the highest overall score, while Bard was the worst. Bard was also the only chatbot unable to provide a response to one of the questions. ChatGPT was the only chatbot that did not provide information about its sources. Conclusions: Chatbots are an intriguing tool that can be used to access basic information in a specialized area like audiology. Nevertheless, one needs to be careful, as correct information is not infrequently mixed in with errors that are hard to pick up unless the user is well versed in the field.	[Jedrzejczak, W. Wiktor; Kochanek, Krzysztof] Inst Physiol & Pathol Hearing, Warsaw, Poland; [Jedrzejczak, W. Wiktor; Kochanek, Krzysztof] World Hearing Ctr, Kajetany, Poland	Institute of Physiology & Hearing Pathology; Institute of Physiology & Hearing Pathology	Jedrzejczak, WW (corresponding author), Inst Physiol & Pathol Hearing, Warsaw, Poland.; Jedrzejczak, WW (corresponding author), World Hearing Ctr, Kajetany, Poland.	w.wiktor.j@gmail.com	Jedrzejczak, W. Wiktor/L-2529-2015	Jedrzejczak, W. Wiktor/0000-0001-8404-0672				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Al-Ashwal FY, 2023, DRUG HEALTHC PATIENT, V15, P137, DOI 10.2147/DHPS.S425858; AlAfnan MA., 2023, Journal of Artificial Intelligence and Technology, V3, P85, DOI DOI 10.37965/JAIT.2023.0267; Buchberger B., 2023, RISC Report Series, P23; cabanac Guillaume, comment on PubPeer; Coskun BN, 2024, RHEUMATOL INT, V44, P509, DOI 10.1007/s00296-023-05473-5; Dao XQ., 2023, arXiv preprint arXiv:2307.08272; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Geerling W., 2023, SSRN Electronic Journal; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Jedrzejczak WW, 2024, BRAIN SCI, V14, DOI 10.3390/brainsci14050465; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Luykx JJ, 2023, WORLD PSYCHIATRY, V22, P479, DOI 10.1002/wps.21145; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; Retraction watch, ABOUT US; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Swanepoel DW., 2023, Hear J, V76, p26,30,32; Topsakal O., 2023, Evaluating patient and otolaryngologist dialogues generated by ChatGPT, are they adequate?; Trust T., 2023, Contemp Issues Technol Teach Educ, V23, P1; Vaswani A, 2017, ADV NEUR IN, V30	25	0	0	0	0	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	1420-3030	1421-9700		AUDIOL NEUROTOL	Audiol. Neurotol.	2024 MAY 6	2024										10.1159/000538983	http://dx.doi.org/10.1159/000538983		MAY 2024	7	Audiology & Speech-Language Pathology; Neurosciences; Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Audiology & Speech-Language Pathology; Neurosciences & Neurology; Otorhinolaryngology	WB9J2	38710158	Green Submitted			2024-07-03	WOS:001252522500001
J	Ferrari, F; van Dijck, J; van den Bosch, A				Ferrari, Fabian; van Dijck, Jose; van den Bosch, Antal			Observe, inspect, modify: Three conditions for generative AI governance	NEW MEDIA & SOCIETY			English	Article; Early Access						AI governance; AI regulation; generative AI; generative models; inspectability; large language models; modifiability; observability; regulatory objects		In a world increasingly shaped by generative AI systems like ChatGPT, the absence of benchmarks to examine the efficacy of oversight mechanisms is a problem for research and policy. What are the structural conditions for governing generative AI systems? To answer this question, it is crucial to situate generative AI systems as regulatory objects: material items that can be governed. On this conceptual basis, we introduce three high-level conditions to structure research and policy agendas on generative AI governance: industrial observability, public inspectability, and technical modifiability. Empirically, we explicate those conditions with a focus on the EU's AI Act, grounding the analysis of oversight mechanisms for generative AI systems in their granular material properties as observable, inspectable, and modifiable objects. Those three conditions represent an action plan to help us perceive generative AI systems as negotiable objects, rather than seeing them as mysterious forces that pose existential risks for humanity.	[Ferrari, Fabian; van Dijck, Jose; van den Bosch, Antal] Univ Utrecht, Utrecht, Netherlands; [Ferrari, Fabian] Univ Utrecht, Fac Humanities, Achter de Dom 20, NL-3512 JP Utrecht, Netherlands	Utrecht University; Utrecht University	Ferrari, F (corresponding author), Univ Utrecht, Fac Humanities, Achter de Dom 20, NL-3512 JP Utrecht, Netherlands.	f.l.ferrari@uu.nl		Ferrari, Fabian/0000-0003-0637-0232; van den Bosch, Antal/0000-0003-2493-656X	Spinoza program of the Dutch Research Council (NWO)	Spinoza program of the Dutch Research Council (NWO)	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The authors were supported by the Spinoza program of the Dutch Research Council (NWO).	Bertuzzi L., 2023, Euractiv; Birhane A, 2022, arXiv, DOI [arXiv:2110.01963, DOI 10.48550/ARXIV.2110.01963]; Blumenthal R., 2023, Senator Josh Hawley; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brevini B, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951720935146; Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512; Busuioc M., 2023, European Law Open, V2, P79; Edwards B., 2022, Arstechnica; European Parliament, 2023, MEPs ready to negotiate first ever rules for safe and transparent AI; Ferrari F., 2023, ENV PLANNING F, V2, P459, DOI [10.1177/26349825231193226, DOI 10.1177/26349825231193226]; Ferrari F, 2023, NAT MACH INTELL, V5, P818, DOI 10.1038/s42256-023-00695-5; Fisher E, 2014, REV EUR COMP INT ENV, V23, P163, DOI 10.1111/reel.12081; Gillespie T., 2018, Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media; Gonen H, 2019, Arxiv, DOI arXiv:1903.03862; Gorwa R, 2020, SSRC ANXIET DEMOCR, P286; Helberger N, 2023, INTERNET POLICY REV, V12, P28, DOI 10.14763/2023.1.1682; Jasanoff S., 2004, STATES KNOWLEDGE COP; Lambert L., 2022, Illustrating Reinforcement Learning from Human Feedback (RLHF); Law John., 2002, AIRCRAFT STORIES DEC; Lezaun J, 2006, SOC STUD SCI, V36, P499, DOI 10.1177/0306312706059461; Liesenfeld A., 2023, P 5 INT C CONV US IN, P1; Liesenfeld A, 2023, Arxiv, DOI arXiv:2307.05532; Luitse D, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211047734; Milmo D., 2023, GUARDIAN        0202; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]; Orgad H, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2602; Perrigo B, 2023, Time; Rieder B., 2020, Internet Policy Review, V9, P1, DOI DOI 10.14763/2020.4.1535; Satariano A., 2023, The New York Times; Seaver N, 2017, BIG DATA SOC, V4, DOI 10.1177/2053951717738104; Seyfert R, 2022, INFORM COMMUN SOC, V25, P1542, DOI 10.1080/1369118X.2021.1874035; Sheehan Matt, 2023, FOREIGN POLICY; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Solaiman I, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P111, DOI 10.1145/3593013.3593981; UNESCO, 2023, Guidance for Generative AI in Education and Research; Van Dijck J, 2021, NEW MEDIA SOC, V23, P2801, DOI 10.1177/1461444820940293; Vaswani A, 2017, ADV NEUR IN, V30; Veale M, 2023, ANNU REV LAW SOC SCI, V19, P255, DOI 10.1146/annurev-lawsocsci-020223-040749; Widder David G, 2023, Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI'; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	41	0	0	138	154	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1461-4448	1461-7315		NEW MEDIA SOC	New Media Soc.	2023 NOV 29	2023										10.1177/14614448231214811	http://dx.doi.org/10.1177/14614448231214811		NOV 2023	19	Communication	Social Science Citation Index (SSCI)	Communication	Z3KI4		hybrid			2024-07-03	WOS:001111091300001
J	Yamamoto, Y				Yamamoto, Yusuke			Suggestive answers strategy in human-chatbot interaction: a route to engaged critical decision making	FRONTIERS IN PSYCHOLOGY			English	Article						human-AI interaction; large language model; behavior change; critical information-seeking; chatbot		In this study, we proposed a novel chatbot interaction strategy based on the suggestive ending of answers. This strategy is inspired by the cliffhanger ending narrative technique, which ends a story without specifying conclusions to spark readers' curiosity as to what will happen next and is often used in television series. Common chatbots provide relevant and comprehensive answers to users' questions. In contrast, chatbots with our proposed strategy end their answers with hints potentially interest-triggering users. The suggestive ending strategy aims to stimulate users' inquisition for critical decision-making, relating to a psychological phenomenon where humans are often urged to finish the uncompleted tasks they have initiated. We demonstrated the implication of our strategy by conducting an online user study involving 300 participants, where they used chatbots to perform three decision-making tasks. We adopted a between-subjects factorial experimental design and compared between the following UIs: (1) plain chatbot-it provides a generated answer when participants issue a question; (2) expositive chatbot-it provides a generated answer for a question, adding short summaries of a positive and negative person's opinion for the answer; (3) suggestive chatbot-it provides a generated answer for a question, which ends with a suggestion of a positive and negative person for the answer. We found that users of the suggestive chatbot were inclined to ask more questions to the bot, engage in prolonged decision-making and information-seeking actions, and formulate their opinions from various perspectives. These findings vary with the users' experience with plain and expositive chatbots.	[Yamamoto, Yusuke] Nagoya City Univ, Sch Data Sci, Nagoya, Japan	Nagoya City University	Yamamoto, Y (corresponding author), Nagoya City Univ, Sch Data Sci, Nagoya, Japan.	yusuke_yamamoto@acm.org			Ministry of Education, Culture, Sports, Science and Technology10.13039/501100001700	Ministry of Education, Culture, Sports, Science and Technology10.13039/501100001700	No Statement Available	Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Arnold KC, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P128, DOI 10.1145/3377325.3377523; Arnold KC, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P603, DOI 10.1145/2984511.2984584; Azzopardi L, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P27, DOI 10.1145/3406522.3446023; Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.2307/1165312; Brodsky JE, 2021, COGN RES, V6, DOI 10.1186/s41235-021-00291-4; Bucinca Zana, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449287; Câmara A, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P209, DOI 10.1145/3406522.3446012; Caraban A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300733; Carr Nicholas., 2014, The Glass Cage: How Our Computers Are Changing Us; Danry V, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580672; Ennis R.H., 1987, Teaching Thinking Skills, P9, DOI DOI 10.1177/0270467688008001113; Fisher A, 2019, J MACH LEARN RES, V20; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Harvey M, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P133, DOI 10.1145/2766462.2767731; Hertwig R, 2017, PERSPECT PSYCHOL SCI, V12, P973, DOI 10.1177/1745691617702496; Hettiachchi D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3494522; Hoyt GM, 2009, INT REV ECON EDUC, V8, P158, DOI 10.1016/S1477-3880(15)30073-6; Ihoriya H., 2022, Proceedings of the 2022 International Conference on Human-Computer Interaction, HCII '22, P17, DOI [10.1007/978-3-031-06509-5_2, DOI 10.1007/978-3-031-06509-5_2]; Jakesch M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581196; Kahneman D., 2011, THINKING FAST SLOW; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim B., 2016, ADV NEURAL INFORM PR, V29, P2280, DOI DOI 10.5555/3157096.3157352; KING A, 1992, EDUC PSYCHOL, V27, P111, DOI 10.1207/s15326985ep2701_8; Kittur A, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P453; Komarov S., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P207, DOI [10.1145/2470654.2470684, DOI 10.1145/2470654.2470684]; Lakkaraju H, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P79, DOI 10.1145/3375627.3375833; Lee HJ, 2015, HIGH EDUC RES DEV, V34, P131, DOI 10.1080/07294360.2014.892477; Lewins A., 2014, Using Software in Qualitative Research, P1; Liao Q. V., 2014, Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW '14, P184, DOI [10.1145/2531602.2531711, DOI 10.1145/2531602.2531711]; Liao QV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1439, DOI 10.1145/2702123.2702570; Liu MXY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501968; Lundberg SM, 2017, ADV NEUR IN, V30; Lutz J, 2016, SOC PSYCHOL-GERMANY, V47, P38, DOI 10.1027/1864-9335/a000256; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Meola M, 2004, PORTAL-LIBR ACAD, V4, P331, DOI 10.1353/pla.2004.0055; Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Musgrove AT, 2018, COLL UNDERGRAD LIBR, V25, P243, DOI 10.1080/10691316.2018.1480444; Najork M, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1, DOI 10.1145/3539618.3591871; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Noyes J., 2007, Decision making in complex systems, P73, DOI [10.1201/9781315576138-7, DOI 10.1201/9781315576138-7]; Odijk D, 2015, INT C INFORM KNOWLED, P1551, DOI [DOI 10.1145/2806416.2806488, 10.1145/2806416.2806488. URL]; Okuse Y., 2023, Proceedings of the 25th HCI International Conference, HCII '23, P568, DOI [10.1007/978-3-031-35132-7_43, DOI 10.1007/978-3-031-35132-7_43]; Oppenheimer DM, 2009, J EXP SOC PSYCHOL, V45, P867, DOI 10.1016/j.jesp.2009.03.009; Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006; Petridis S, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580907; PETTY RE, 1984, ADV CONSUM RES, V11, P668; Rinott R., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P440, DOI 10.18653/v1/d15-1050; Ross Joel, 2010, CHI 10 EXTENDED ABST, P2863, DOI [10.1145/1753846.1753873, DOI 10.1145/1753846.1753873]; Roy N, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P229, DOI 10.1145/3406522.3446025; Saito F., 2020, Proceedings of the 21st International Conference on Web Information Systems Engineering, WISE '20, P424, DOI [10.1007/978-3-030-34223-4_27, DOI 10.1007/978-3-030-34223-4_27]; Sharma N, 2024, Arxiv, DOI arXiv:2402.05880; Shimizu Y., 2022, Proceedings of the 2022 ACM Conference on Information Technology for Social Good, GoodIT '22, P24, DOI [10.1145/3524458.3547231, DOI 10.1145/3524458.3547231]; Sun J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P212, DOI 10.1145/3490099.3511119; Suzuki M., 2022, Proceedings of the 2022 ACM Conference on Information Technology for Social Good, GoodIT '22, P1, DOI [10.1145/3524458.3547222, DOI 10.1145/3524458.3547222]; Suzuki M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.771948; Tay Y., 2022, Advances in Neural Information Processing Systems, V35, P21831; Wambsganss T., 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445781, DOI 10.1145/3411764.3445781]; Wambsganss T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376732; Wang TL, 2023, Arxiv, DOI arXiv:2308.04592; Wang Y, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P763; Wei Jason, 2021, arXiv preprint arXiv:2109.01652; White R, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P3; Wilson MJ, 2013, J AM SOC INF SCI TEC, V64, P291, DOI 10.1002/asi.22758; Wineburg S, 2019, TEACH COLL REC, V121; Wirz DS, 2023, PSYCHOL POP MEDIA, V12, P186, DOI 10.1037/ppm0000392; Xu RY, 2023, Arxiv, DOI arXiv:2307.01135; Yamamoto Y., 2020, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020, JCDL '20, P37, DOI DOI 10.1145/3383583.3398519; Yamamoto Y, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P12, DOI 10.1145/3176349.3176377; Zimmerman S, 2019, PROCEEDINGS OF THE 2019 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL (CHIIR'19), P283, DOI 10.1145/3295750.3298952; Zylowski T., 2023, Proceedings of the 6th International Conference on Natural Language and Speech Processing, ICNLSP '23, P168	71	0	0	15	15	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-1078			FRONT PSYCHOL	Front. Psychol.	MAR 28	2024	15								1382234	10.3389/fpsyg.2024.1382234	http://dx.doi.org/10.3389/fpsyg.2024.1382234			16	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	NH9O9	38605834	Green Published, gold			2024-07-03	WOS:001199680600001
J	Giray, L; Jacob, J; Gumalin, DL				Giray, Louie; Jacob, Jomarie; Gumalin, Daxjhed Louis			Strengths, Weaknesses, Opportunities, and Threats of Using ChatGPT in Scientific Research	INTERNATIONAL JOURNAL OF TECHNOLOGY IN EDUCATION			English	Article						AI ethics; Artificial Intelligence; ChatGPT; Large language model; Prompt engineering; Scientific research; SWOT Analysis		The versatility of ChatGPT extends across diverse domains, including scientific research. This study delves into the transformative prospects of integrating ChatGPT into scientific research, achieved through a SWOT analysis. The analysis explores the model's strengths, which encompass a vast knowledge base, language proficiency, information retrieval, and the capacity for continuous learning. Conversely, it exposes its weaknesses, including a lack of contextual understanding, potential overreliance on training data, limitations in verifying information, and constrained critical thinking abilities. Amidst these factors, opportunities arise, such as facilitating literature reviews, fostering collaborative brainstorming, enabling seamless language translation and interpretation, and amplifying knowledge dissemination. Nonetheless, a spectrum of threats looms, encompassing concerns related to plagiarism, ethical quandaries, the propagation of misinformation, and even the potential erosion of higher-order cognitive thinking. These multifaceted aspects necessitate comprehensive consideration. Recommendations for researchers embarking on ChatGPT integration include a balanced approach that harmonizes AI and human ingenuity, thereby upholding research integrity. The potential of ChatGPT to reshape scientific inquiry can only be realized through conscientious use and ongoing oversight.	[Giray, Louie] Colegio Muntinlupa Sucat, Muntinlupa, Philippines; [Jacob, Jomarie; Gumalin, Daxjhed Louis] Polytech Univ Philippines Lower Bicutan, Taguig City, Philippines		Giray, L (corresponding author), Colegio Muntinlupa Sucat, Muntinlupa, Philippines.	lgiray@cdm.edu.ph	Giray, Louie/AGV-8089-2022	Giray, Louie/0000-0002-1940-035X				Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Arvanitis L., 2023, NewsGuardMarch; Azaria A, 2023, Arxiv, DOI [arXiv:2306.03102, DOI 10.48550/ARXIV.2306.03102, 10.48550/arXiv.2306.03102]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Benzaghta M.A., 2021, J. Glob. Bus. Insights, V6, P55, DOI [DOI 10.5038/2640-6489.6.1.1148, 10.5038/2640-6489.6.1.1148]; Bin-Hady WRA, 2023, LIBR HI TECH, DOI 10.1108/LHT-05-2023-0200; Chowdhury N., 2023, A brief review of ChatGPT: Limitations, challenges and ethicalsocial implications, DOI [10.5281/zenodo.7629888, DOI 10.5281/ZENODO.7629888]; Chubb J, 2022, AI SOC, V37, P1439, DOI 10.1007/s00146-021-01259-0; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019; Furman Jason, 2019, Innovation Policy and the Economy, V19, P161, DOI [10.1086/699936, DOI 10.1086/699936]; Gao Y, 2023, Arxiv, DOI [arXiv:2304.02182, 10.48550/arXiv.2304.02182]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Goodin D, 2023, Hackers are selling a service that bypasses ChatGPT restrictions on malware; Helms MM, 2010, J STRATEGY MANAG, V3, P215, DOI 10.1108/17554251011064837; Huang JS, 2023, AM J CANCER RES, V13, P1148; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Jain S., 2019, International Journal of Research and Analytical Reviews, V6, P144; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kalla D., 2023, International Journal of Innovative Science and Research Technology, V8, P827; Kasneci E., 2023, arXiv, DOI [10.35542/osf.io/5-r8f, DOI 10.35542/OSF.IO/5-R8F]; Kengam J., 2020, Artificial intelligence in education, DOI [10.13140/RG.2.2.16375.65445, DOI 10.13140/RG.2.2.16375.65445]; Khalil M, 2023, Arxiv, DOI arXiv:2302.04335; Khan S., 2023, YourStoryJune 15; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lyu C, 2024, Arxiv, DOI [arXiv:2305.01181, 10.48550/arXiv.2305.01181, DOI 10.48550/ARXIV.2305.01181]; Mauran C., 2023, Samsung bans ChatGPT, AI chatbots after data leak blunder; McGee R. W., 2023, Is ChatGPT biased against conservatives? An empirical study, DOI DOI 10.2139/SSRN.4359405; Mijwil M., 2023, Mesopotamian J Cyber Secur, P18, DOI DOI 10.58496/MJCS/2023/004; Naik N, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.862322; Nandalwar J., 2023, International Journal for Multidisciplinary Research, V5, DOI [10.36948/ijfmr.2023.v05i02.2397, DOI 10.36948/IJFMR.2023.V05I02.2397]; Onat O., 2023, International Journal of Technology in Education and Science (IJTES), V7, P483, DOI [10.46328/ijtes.511, DOI 10.46328/IJTES.511]; Opara E., 2023, Glob Acad J Humanit Soc Sci, V5, P33, DOI DOI 10.36348/GAJHSS.2023.V05I02.001; Qasem Fawaz, 2023, Library Hi Tech News, P30, DOI 10.1108/LHTN-03-2023-0043; Rahimi F, 2023, ARCH MED RES, V54, P272, DOI 10.1016/j.arcmed.2023.03.004; Rahman M., 2023, Journal of Education, Management and Development Studies, V3, P1, DOI [10.52631/jemds.v3i1.175, DOI 10.52631/JEMDS.V3I1.175]; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Santra Patit Paban, 2023, SRELS Journal of Information Management, P173, DOI 10.17821/srels/2023/v60i3/171028; Shidaganti Ganeshayya, 2023, 2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS), P1264, DOI 10.1109/ICICCS56967.2023.10142461; Simpson D, 2023, BMJ-BRIT MED J, V381, DOI 10.1136/bmj.p1403; Stojanov A, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00404-7; Strubell E., 2019, 57 ANN M ASS COMP LI, DOI [10.48550/arXiv.1906.02243, DOI 10.48550/ARXIV.1906.02243]; Ufuk F, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230276; Van der Vorst T., 2019, 30 EUROPEAN C INT TE; Wardat Y., 2023, Eurasia Journal of Mathematics, Science and Technology Education, V19, DOI DOI 10.29333/EJMSTE/13272; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Zhai X, 2023, COMPLEX INTELL SYST, V9, P2865, DOI 10.1007/s40747-021-00617-1	57	2	2	15	15	INT SOC TECHNOLOGY EDUCATION & SCIENCE-ISTES	MONUMENT	19723 LINDENMERE DR, MONUMENT, COLORADO, UNITED STATES		2689-2758		INT J TECHNOL EDUC	Int. J. Technol. Educ.		2024	7	1			SI		40	58		10.46328/ijte.618	http://dx.doi.org/10.46328/ijte.618			19	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	NB4F0		gold			2024-07-03	WOS:001197961000003
J	Chu, CP				Chu, Candice P.			ChatGPT in veterinary medicine: a practical guidance of generative artificial intelligence in clinics, education, and research	FRONTIERS IN VETERINARY SCIENCE			English	Review						artificial intelligence; AI; generative AI; GenAI; large language model; prompt engineering; machine learning; GPT-4		ChatGPT, the most accessible generative artificial intelligence (AI) tool, offers considerable potential for veterinary medicine, yet a dedicated review of its specific applications is lacking. This review concisely synthesizes the latest research and practical applications of ChatGPT within the clinical, educational, and research domains of veterinary medicine. It intends to provide specific guidance and actionable examples of how generative AI can be directly utilized by veterinary professionals without a programming background. For practitioners, ChatGPT can extract patient data, generate progress notes, and potentially assist in diagnosing complex cases. Veterinary educators can create custom GPTs for student support, while students can utilize ChatGPT for exam preparation. ChatGPT can aid in academic writing tasks in research, but veterinary publishers have set specific requirements for authors to follow. Despite its transformative potential, careful use is essential to avoid pitfalls like hallucination. This review addresses ethical considerations, provides learning resources, and offers tangible examples to guide responsible implementation. A table of key takeaways was provided to summarize this review. By highlighting potential benefits and limitations, this review equips veterinarians, educators, and researchers to harness the power of ChatGPT effectively.	[Chu, Candice P.] Texas A&M Univ, Coll Vet Med & Biomed Sci, Dept Vet Pathobiol, College Stn, TX 77843 USA	Texas A&M University System; Texas A&M University College Station	Chu, CP (corresponding author), Texas A&M Univ, Coll Vet Med & Biomed Sci, Dept Vet Pathobiol, College Stn, TX 77843 USA.	cchu@cvm.tamu.edu			Texas AM University	Texas AM University	The author(s) declare that financial support was received for the research, authorship, and/or publication of this article. Texas A&M University start-up funds were used for publication of this article.	Abani S, 2023, FRONT VET SCI, V10, DOI 10.3389/fvets.2023.1245168; Abani S, 2023, FRONT VET SCI, V10, DOI 10.3389/fvets.2023.1272755; Adrien-Maxence H, 2022, VET RADIOL ULTRASOUN, V63, P456, DOI 10.1111/vru.13069; Akin FK, 2024, Awesome ChatGPT prompts; Alivecor, 2020, FDA clears first of its kind algorithm suite for personal ECG; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Antropic, 2024, Prompt library; Antropic, 2024, Introducing the next generation of Claude; Banks Jeanine, 2024, Gemma: Introducing new state-of-the-art open models; Bellamy James E C, 2023, Can Vet J, V64, P968; Ben Chrisinger, 2023, Chron High Educ; Bohannan Z, 2021, VET COMP ONCOL, V19, P160, DOI 10.1111/vco.12656; Boissady E, 2021, FRONT VET SCI, V8, DOI 10.3389/fvets.2021.764570; Boissady E, 2020, VET RADIOL ULTRASOUN, V61, P619, DOI 10.1111/vru.12912; Boscardin CK, 2024, ACAD MED, V99, P22, DOI 10.1097/ACM.0000000000005439; Callegari AJ, 2024, FRONT ONCOL, V14, DOI 10.3389/fonc.2024.1304144; Chu CP., VetClinPathGPT: Your veterinary clinical pathology AI tutor; Cirone Katrina, 2024, JMIR Dermatol, V7, pe55508, DOI 10.2196/55508; Cohen EB, 2022, VET RADIOL ULTRASOUN, V63, P840, DOI 10.1111/vru.13171; Coleman Michelle C, 2024, J Am Vet Med Assoc, V262, P692, DOI 10.2460/javma.23.12.0666; Coursera, 2024, Generative AI: Prompt Engineering Basics Course by IBM; DAIR.AI, 2024, Prompt engineering guide; Desaire H, 2023, CELL REP PHYS SCI, V4, DOI 10.1016/j.xcrp.2023.101672; Desaire H, 2023, CELL REP PHYS SCI, V4, DOI 10.1016/j.xcrp.2023.101426; Digitail, 2023, All-in-one veterinary practice management software; Dourson A, 2023, Arxiv, DOI [arXiv:2305.15424, 10.48550/arXiv.2305.15424, DOI 10.48550/ARXIV.2305.15424]; Dragon Veterinary, 2020, Dragon veterinary; Dreaver-Charles K., 2022, Otessaconference, V2, P1, DOI [10.18357/otessac.2022.2.1.97, DOI 10.18357/OTESSAC.2022.2.1.97]; Eerdekens A, 2024, EQUINE VET J, DOI 10.1111/evj.14069; Ekin S., 2023, PREPRINT; Eriksen AV., 2023, NEJM AI, V1, DOI [DOI 10.1056/AIP2300031, 10.1056/AIp2300031]; Fijacko N, 2023, RESUSCITATION, V193, DOI 10.1016/j.resuscitation.2023.110009; Fins IS, 2024, VET REC, V194, DOI 10.1002/vetr.3669; Galyna Danylenko, 2024, AI in veterinary medicine: The next paradigm shift; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Goldberg CB., 2024, NEJM AI, V1, pAIp2400036, DOI [DOI 10.1056/AIP2400036, 10.1056/AIp2400036]; Google, 2024, Veterinary medicine: Google scholar metrics; Google, 2024, Gemini for Google Workspace prompt guide; Grisham John, 2023, 13 other authors file class-action suit against OpenAI; Grynbaum MM., 2023, N Y Times; Guida SJ, 2023, J VET EMERG CRIT CAR, V33, P715, DOI 10.1111/vec.13352; Harvard University Information Technology, 2024, Generative artificial intelligence (AI); Holly Hartigan, 2024, Cornell Chron; Hugging Face, 2024, Gemma release; ICMJE, 2024, Recommendations for the conduct, reporting, editing, and publication of scholarly work in medical journals; ImpriMed, 2024, Find the best drugs for treating your dog's lymphoma BEFORE treatment begins; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jennings R., 2017, Veterinary Histology; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Jokar M, 2024, VET MED SCI, V10, DOI 10.1002/vms3.1464; Jules White, 2024, Prompt engineering for ChatGPT; Kahveci ZU, 2023, J INTELLET PROP LAW, V18, P796, DOI 10.1093/jiplp/jpad076; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kim E, 2022, VET RADIOL ULTRASOUN, V63, P292, DOI 10.1111/vru.13062; Kim H, 2024, KOREAN J RADIOL, V25, P403, DOI 10.3348/kjr.2024.0017; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Koller D., 2023, NEJM AI, V1, pAI, DOI [10.1056/AIe2300128, DOI 10.1056/AIE2300128]; Koo J, 2021, VET SCI, V8, DOI 10.3390/vetsci8120301; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P., 2023, The AI revolution in medicine: GPT-4 and beyond, P289; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Meta. Llama, 2023, ABOUT US; MetronMind, 2023, Metron IQ: Veterinary AI radiology report software; Miao J, 2024, AM J CLIN PATHOL, DOI 10.1093/ajcp/aqae030; Michigan Institute for Data Science, 2024, A quick guide of using GAI for scientific research; Microsoft, 2024, Microsoft Copilot for Microsoft 365 overview; Mirza FN., 2024, NEJM AI, V1, pAIcs2300145, DOI [10.1056/AIcs2300145, DOI 10.1056/AICS2300145]; Müller TR, 2022, VET RADIOL ULTRASOUN, V63, P573, DOI 10.1111/vru.13089; Nguyen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1324; Noy S., 2023, SSRN Journal, DOI [10.2139/ssrn.4375283, DOI 10.2139/SSRN.4375283]; Nyquist ML, 2024, J VET DENT, DOI 10.1177/08987564231221071; OpenAI, 2024, OpenAI help center; OpenAI, 2022, Introducing chatgpt; OpenAI, 2024, GPT-4 Turbo and GPT-4; OpenAI, 2024, What is ChatGPT?; OpenAI, 2023, Introducing ChatGPT Plus; OpenAI, 2023, Privacy policy; OpenAI, 2023, New ai classifier for indicating aiwritten text; OpenAI, 2024, Hello gpt-4o; OpenAI, 2024, GPTs; OpenAI, 2023, GPT-4; OpenAI, 2023, OpenAI DevDay: Opening keynote; Paslia S, 2024, AM J EMERG MED, V78, P170, DOI 10.1016/j.ajem.2024.01.037; peakcooper, 2023, GPT4 saved my dog's life; PetsApp, 2020, Veterinary engagement and communication platform | PetsApp; PicoxIA, 2022, AI designed for veterinarians; PubMed, 2024, ChatGPTTitle/Abstract-Search results; Rahmani AM, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9222970; Rai T, 2024, CANCERS, V16, DOI 10.3390/cancers16030644; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Rosenbaum CS, 2021, J VET DIAGN INVEST, V33, P1008, DOI 10.1177/10406387211027162; Rule A, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.15334; Schmid P., 2024, Welcome llama 3-Metas new open LLM; ScribbleVet, 2023, AI for busy veterinarians; Sharma P, 2024, J PERINATOL, DOI 10.1038/s41372-024-01912-8; Sievert M, 2024, EUR ARCH OTO-RHINO-L, V281, P2115, DOI 10.1007/s00405-024-08476-5; Souza GV, 2021, VET ANIM SCI, V11, DOI 10.1016/j.vas.2020.100161; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Stokol Tracy., 2024, eClinPath; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tierney AA, 2024, NEJM Catal Innov Care Deliv., V5, DOI [10.1056/cat.23.0404, DOI 10.1056/CAT.23.0404]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; U.S. Food and Drug Administration, 2024, Artificial intelligence and machine learning (AI/ML)-enabled medical devices; Vetology, 2023, Veterinary radiology and artificial intelligence; Walters WH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41032-5; Warren W, 2022, SCI ADV, V8, DOI 10.1126/sciadv.add9147; Wolkovich E M, 2024, Nature, DOI 10.1038/d41586-024-00349-5; Wu S., 2024, NEJM AI, V1, pAIdbp2300092, DOI 10.1056/AIdbp2300092; Yao XX, 2021, NAT MED, V27, P815, DOI 10.1038/s41591-021-01335-4; Zhou Yiliang, 2024, Radiology, V311, pe233270, DOI 10.1148/radiol.233270	114	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2297-1769		FRONT VET SCI	Front. Vet. Sci.	JUN 7	2024	11								1395934	10.3389/fvets.2024.1395934	http://dx.doi.org/10.3389/fvets.2024.1395934			9	Veterinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Veterinary Sciences	UX3T2	38911678	gold, Green Submitted			2024-07-03	WOS:001251331900001
C	Li, CT; Ku, LW			ACM	Li, Cheng-Te; Ku, Lun-Wei			SocialNLP'23: 11th International Workshop on Natural Language Processing for Social Media	COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023			English	Proceedings Paper	32nd World Wide Web Conference (WWW)	APR 30-MAY 04, 2023	Austin, TX	Assoc Comp Machinery, Amazon Science, Baidu, Megagon Labs, Zhipu AI, Google, Booking Com, eBay, Bloomberg Engn, Netflix, ACM SIGWEB, Univ Texas Austin, Sch Informat, Data World, Inst Fdn Machine Learning		Natural Language Processing; Social Media; Machine Learning; Deep Learning; Text Mining; Large Language Models; ChatGPT		SocialNLP is an inter-disciplinary area of natural language processing (NLP) and social computing. SocialNLP has three directions: (1) addressing issues in social computing using NLP techniques; (2) solving NLP problems using information from social networks or social media; and (3) handling new problems related to both social computing and natural language processing. The 11th SocialNLP workshop is held at TheWebConf 2023. We accepted nine papers with acceptance ratio 56%. We sincerely thank to all authors, program committee members, and workshop chairs, for their great contributions and help in this edition of SocialNLP workshop.	[Li, Cheng-Te] Natl Cheng Kung Univ, Tainan, Taiwan; [Ku, Lun-Wei] Acad Sinica, Taipei, Taiwan	National Cheng Kung University; Academia Sinica - Taiwan	Li, CT (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.	chengte@ncku.edu.tw; lwku@iis.sinica.edu.tw	Ku, Lun-Wei/ABD-3101-2020	Ku, Lun-Wei/0000-0003-2691-5404	National Science and Technology Council (NSTC) of Taiwan [110-2221-E-006-136-MY3, 111-2221-E-006-001, 111-2634-F-002-022]	National Science and Technology Council (NSTC) of Taiwan	This work is supported by the National Science and Technology Council (NSTC) of Taiwan under grants 110-2221-E-006-136-MY3, 111-2221-E-006-001, and 111-2634-F-002-022.	google, About us	1	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9416-1				2023							994	994		10.1145/3543873.3589754	http://dx.doi.org/10.1145/3543873.3589754			1	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SF					2024-07-03	WOS:001124276300193
J	Kanbach, DK; Heiduk, L; Blueher, G; Schreiter, M; Lahmann, A				Kanbach, Dominik K.; Heiduk, Louisa; Blueher, Georg; Schreiter, Maximilian; Lahmann, Alexander			The GenAI is out of the bottle: generative artificial intelligence from a business model innovation perspective	REVIEW OF MANAGERIAL SCIENCE			English	Review						Artificial intelligence; Generative AI; ChatGPT; Business model innovation; Large language models; M10; M13; M15; M19	CHATGPT	The introduction of ChatGPT in November 2022 by OpenAI has stimulated substantial discourse on the implementation of artificial intelligence (AI) in various domains such as academia, business, and society at large. Although AI has been utilized in numerous areas for several years, the emergence of generative AI (GAI) applications such as ChatGPT, Jasper, or DALL-E are considered a breakthrough for the acceleration of AI technology due to their ease of use, intuitive interface, and performance. With GAI, it is possible to create a variety of content such as texts, images, audio, code, and even videos. This creates a variety of implications for businesses requiring a deeper examination, including an influence on business model innovation (BMI). Therefore, this study provides a BMI perspective on GAI with two primary contributions: (1) The development of six comprehensive propositions outlining the impact of GAI on businesses, and (2) the discussion of three industry examples, specifically software engineering, healthcare, and financial services. This study employs a qualitative content analysis using a scoping review methodology, drawing from a wide-ranging sample of 513 data points. These include academic publications, company reports, and public information such as press releases, news articles, interviews, and podcasts. The study thus contributes to the growing academic discourse in management research concerning AI's potential impact and offers practical insights into how to utilize this technology to develop new or improve existing business models.	[Kanbach, Dominik K.; Heiduk, Louisa; Blueher, Georg; Schreiter, Maximilian; Lahmann, Alexander] HHL Leipzig Grad Sch Management, Jahnallee 59, D-04109 Leipzig, Germany; [Kanbach, Dominik K.] Woxsen Univ, Sch Business, Hyderabad, India	HHL Leipzig Graduate School of Management	Kanbach, DK (corresponding author), HHL Leipzig Grad Sch Management, Jahnallee 59, D-04109 Leipzig, Germany.; Kanbach, DK (corresponding author), Woxsen Univ, Sch Business, Hyderabad, India.	dominik.kanbach@hhl.de; louisa.heiduk@hhl.de; georg.blueher@hhl.de; maximilian.schreiter@hhl.de; alexander.lahmann@hhl.de	Kanbach, Dominik K./AAW-8271-2021	Kanbach, Dominik K./0000-0003-0956-8009; Heiduk, Louisa/0000-0002-2106-7111	HHL Leipzig Graduate School of Management gGmbH (5141)	HHL Leipzig Graduate School of Management gGmbH (5141)	No Statement Available	Adobe, 2023, Adobe News; Agrawal A., 2022, Harvard Business Review; Amit R., 2020, Business model innovation strategy: Transformational concepts and tools for entrepreneurial leaders; Ancillai C, 2023, TECHNOL FORECAST SOC, V188, DOI 10.1016/j.techfore.2022.122307; Åström J, 2022, REV MANAG SCI, V16, P2111, DOI 10.1007/s11846-022-00521-z; Aydin O., 2023, IS CHATGPT LEADING G; Baker V, 2023, TechRepublic; Berg JM, 2022, ADMIN SCI QUART, V67, P630, DOI 10.1177/00018392221083650; Biswas S, 2023, Commentary/Viewpoint; Biswas S., 2023, Importance of chat GPT in Agriculture: According to chat GPT; Bloomberg, 2023, Introducing BloombergGPT, Bloomberg's 50-billion parameter large language model, purpose-built from scratch for finance; Boza P, 2021, INSEAD working paper collection, P1; Brady D, 2023, How generative AI is changing the way developers work; Breier M, 2021, INT J HOSP MANAG, V92, DOI 10.1016/j.ijhm.2020.102723; BUCHANAN BG, 1988, ANNU REV COMPUT SCI, V3, P23, DOI 10.1146/annurev.cs.03.060188.000323; Burger B, 2023, EUR J INNOV MANAG, V26, P233, DOI 10.1108/EJIM-02-2023-0156; Cai K, 2023, Forbes; Canva, 2023, Magic write: AI text generator and AI writer; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Chen HM, 2022, J MED CHEM, V65, P100, DOI 10.1021/acs.jmedchem.1c02042; Cheong SHR, 2022, PREV MED, V162, DOI 10.1016/j.ypmed.2022.107170; Chow A. R., 2023, Time; Clauss T, 2020, INT J INNOV MANAG, V24, DOI 10.1142/S1363919620500152; Clauss T, 2017, R&D MANAGE, V47, P385, DOI 10.1111/radm.12186; Coldewey D, 2023, The takeaways from Stanford's 386-page report on the state of AI; Cribben I., 2023, Operations Management and Data Analytics, DOI [10.2139/ssrn.4404276, DOI 10.2139/SSRN.4404276]; Daugherty PR, 2023, Harvard business review; Davenport T. H., 2022, Harvard Business Review; Dean G, 2023, Insider; Desai P.Rajesh., 2014, International Journal of Engineering Trends and Technology, V13, P175, DOI [10.14445/22315381/IJETT-V13P237, DOI 10.14445/22315381/IJETT-V13P237]; Dilmegani C., 2023, AI Multiple; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dymitrowski A, 2021, J THEOR APPL EL COMM, V16, P2110, DOI 10.3390/jtaer16060118; Elias J., 2023, CNBC; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Erul E., 2023, J Tour Gastron Stud, DOI [10.21325/JOTAGS.2023.1217, DOI 10.21325/JOTAGS.2023.1217]; Eshghi B, 2023, AI multiple; Fairclough N., 2007, Discourse and contemporary social change, DOI [10.3726/978-3-0351-0351-9, DOI 10.3726/978-3-0351-0351-9]; Felten E. W., 2023, SSRN, DOI DOI 10.2139/SSRN.4375268; Foss NJ, 2017, J MANAGE, V43, P200, DOI 10.1177/0149206316675927; Fridman L, 2019, Spotify; Getchell KM, 2022, BUS PROF COMMUN Q, V85, P7, DOI 10.1177/23294906221074311; Gimpel H., 2023, Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher education: A guide for students and lecturers; GitHub, 2023, GitHub copilot your AI pair programmer; GitHub, 2023, GitHub-biobootloader/wolverine; Glader Paul, 2017, Forbes; Goldman Sachs, 2023, Stability AI CEO says AI will prove more disruptive than the pandemic; Goldstein J. A., 2023, arXiv, DOI [10.48550/arXiv.2301.04246, DOI 10.48550/ARXIV.2301.04246]; Google, 2023, Google AI principles -google AI; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Greymatter, 2023, OpenAI's Sam Altman | AI for the next era-greymatter | podcast on spotify; Greymatter, 2023, Spotify; Gupta Rishi R, 2022, Methods Mol Biol, V2390, P113, DOI 10.1007/978-1-0716-1787-8_4; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Hamdoun S, 2023, IEEE TECHNOL SOC MAG, V42, P25, DOI 10.1109/MTS.2023.3241309; Hardy C., 2001, INT STUD MANAG ORG, V31, P25, DOI DOI 10.1080/00208825.2001.11656819; Hassan M, 2023, Medium; Hinkfuss S, 2023, How fintech can jump on the generative AI bandwagon-bain capital ventures; Hochberg I, 2020, J MED INTERNET RES, V22, DOI 10.2196/15065; House B, 2019, Medium; Hu K., 2023, REUTERS, V12; Huang H., 2023, Ars technica; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Jorzik P, 2023, IEEE T ENG MANAGE, DOI 10.1109/TEM.2023.3275643; Kagermann H., 2015, Management of Permanent Change, P23, DOI [10.1007/978-3-658-05014-6_2, DOI 10.1007/978-3-658-05014-6_2]; Kalliamcakou E, 2022, Research: quantifying GitHub Copilot's impact on developer productivity and happiness; Katsamakas E., 2020, J. Bus. Model, V8, P22, DOI DOI 10.2139/SSRN.3554286; Kelly J., 2023, Forbes; Ko H., 2023, SSRN Electron J, DOI [10.2139/SSRN.4390529, DOI 10.2139/SSRN.4390529]; Konrad A., 2023, Forbes; Korherr P, 2023, J DECIS SYST, V32, P600, DOI 10.1080/12460125.2022.2062848; Korherr P, 2023, REV MANAG SCI, V17, P1943, DOI 10.1007/s11846-021-00506-4; Kraus S, 2022, REV MANAG SCI, V16, P2577, DOI 10.1007/s11846-022-00588-8; Kraus S, 2022, INT J ENTREP BEHAV R, V28, P52, DOI 10.1108/IJEBR-12-2021-0984; Kraus S, 2020, INT J INNOV TECHNOL, V17, DOI 10.1142/S0219877020500431; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lau T, 2023, Fintech futures; Lee J., 2019, Journal of Open Innovation: Technology, Market, and Complexity, V5, P44, DOI DOI 10.3390/JOITMC5030044; Lin B, 2023, The wall street journal; Lindgren P., 2016, J Multi Bus Model Innov Technol, V4, P1, DOI [10.13052/jmbmit2245-456x.421, DOI 10.13052/JMBMIT2245-456X.421]; Love J, 2023, Bloomberg law; Lund BD, 2023, Library Hi-tech news; Marr B, 2019, Artificial intelligence in practice: how 50 successful companies used ai and machine learning to solve problems, P1; Maslej, 2023, AI index report; Mathew A., 2023, Recent Prog Sci Technol, V5, P35, DOI DOI 10.9734/BPI/RPST/V5/18240D; Mayring P., 2019, Forum: Qualitative Social Research, V20; Meta AI, 2023, Meta's five pillars of responsible AI that inform our work; Metz Rachel, 2023, Bloomberg; Microsoft, 2023, Introducing Microsoft 365 Copilot-your copilot for work; Microsoft News Center, 2023, Microsoft and epic expand strategic collaboration with integration of azure OpenAI service; Midjourney, 2023, Midjourney; Mok A, 2023, Insider; Motoki Fabio, 2023, HarvardDataverse, V1, DOI 10.7910/DVN/KGMEYI; Mukherjee S, 2023, Reuters; Murphy K, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00577-8; Needleman M., 2021, Proc Assoc Inf Sci Technol, V58, P622, DOI [10.1002/PRA2.513, DOI 10.1002/PRA2.513]; Neves PS, 2022, architecture image studies, V3; Nietzel MT, 2023, ForbesMarch 20; Noy S, 2023, Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; OpenAI, 2023, Pricing; OpenAI, 2018, OPENAI CHART; Orodonez V, 2023, ABC News; Patronov Atanas, 2022, Methods Mol Biol, V2390, P153, DOI 10.1007/978-1-0716-1787-8_6; Pichai S, 2023, Google the keyword; Pilipiszyn A., 2021, Gpt-3 powers the next generation of apps; Pounds E, 2023, NVIDIA; Przegalinska A., 2023, Strategizing AI in business and education, DOI [10.1017/9781009243520, DOI 10.1017/9781009243520]; Rees T., 2023, Time; Reim W, 2020, AI-BASEL, V1, DOI 10.3390/ai1020011; Sáez-Ortuño L, 2023, INT ENTREP MANAG J, V19, P1893, DOI 10.1007/s11365-023-00882-1; Santana M, 2023, REV MANAG SCI, V17, P1971, DOI 10.1007/s11846-022-00613-w; Sauer PC, 2023, REV MANAG SCI, V17, P1899, DOI 10.1007/s11846-023-00668-3; Schafer J, 2023, 20 Jobs GPT4 will replace-ChatGPT. podcast on spotify; Schmidt B, 2023, Bloomberg; Scott K, 2023, Kevin scott on 5 ways generative AI will transform work; Sean, 2023, Introducing miro AI (BETA); Senn-Kalb L, 2023, Artificial intelligence: in-depth market analysis market insights report; Seshia SA, 2022, COMMUN ACM, V65, P46, DOI 10.1145/3503914; Shank M, 2023, Our thinking: the startling power generative AI is bringing to software development; Sheikh, 2023, Forbes; Shepardson David., 2023, Reuters; Spataro J., 2023, Official Microsoft Blog; Spath D, 2020, Automatisierung und Personalisierung von Dienstleistungen-Methoden. Potenziale, Einsatzfelder, P207; Spieth P., 2016, Journal of Business Economics, V86, P671, DOI DOI 10.1007/S11573-015-0794-0; Stokel-Walker Chris, 2022, Nature; Syrowatka A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00459-8; Tarrant G, 2023, The wall street journal; Thompson, 2023, An interview with daniel gross and nat friedman about the AI product revolution-stratechery | podcast on spotify. Spotify; Toews R, 2023, The next generation of large language models; Towson J, 2023, How generative AI services are disrupting platform business models; Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Uludag K, 2023, Testing emotional understanding of ChatGPT: interview with ChatGPT; Valter P, 2018, WIRELESS PERS COMMUN, V100, P97, DOI 10.1007/s11277-018-5612-x; van Gool F, 2023, AI is eating the software world-techspire. techspire; Wakefield J, 2023, BBC News; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P831, DOI 10.1109/JAS.2023.123552; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; WHO, 2022, World mental health day 2022; Wieczerzycki M, 2022, MARKETING THEOR, V22, P445, DOI 10.1177/14705931221075832; Wiggers K., 2023, TechCrunch; Wiles J, 2023, Generative AI use cases for industries and enterprises; Yoo S, 2021, STRUCT MULTIDISCIP O, V64, P2725, DOI 10.1007/s00158-021-02953-9; Youvan DC, 2023, Policing and generative AI is immoral; Yue T., 2023, SSRN Electron J, DOI [10.2139/SSRN.4380516.Accessed18April2023, DOI 10.2139/SSRN.4380516.ACCESSED18APRIL2023]; YuE Thomas, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4346152, DOI 10.2139/SSRN.4346152]; Yurkevich V., 2023, CNN; Zhang CS, 2023, Arxiv, DOI arXiv:2303.07909; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	151	19	19	155	155	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1863-6683	1863-6691		REV MANAG SCI	Rev. Manag. Sci.	APR	2024	18	4					1189	1220		10.1007/s11846-023-00696-z	http://dx.doi.org/10.1007/s11846-023-00696-z		SEP 2023	32	Management	Social Science Citation Index (SSCI)	Business & Economics	MQ5Z9		hybrid			2024-07-03	WOS:001079655700001
J	Wohlfarth, B; Streit, SR; Guttormsen, S				Wohlfarth, Benny; Streit, Samuel R.; Guttormsen, Sissel			Artificial Intelligence in Scientific Writing: A Deuteragonistic Role?	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						ai regulation; large language models (llms); chatbots; swa (scientific writing assistance); research integrity	CHATGPT	In this article, we reflect on the pros and cons of artificial intelligence (AI)-augmented scientific writing for more comprehensible research towards society to gain trust for science-led policy. For this purpose, we integrated our thoughts into the Factors of Perceived Trustworthiness from Mayer, Davis, and Schoorman's Model of Trust and made propositions to define AI's role in trustful scholarly communication.	[Wohlfarth, Benny] Univ Bern, Inst Med Educ, Bern, Switzerland; [Streit, Samuel R.] Univ Hosp Bern, Inselspital Bern, Dept Angiol, Bern, Switzerland; [Guttormsen, Sissel] Univ Bern, Inst Med Educ, Bern, Switzerland	University of Bern; University of Bern; University Hospital of Bern; University of Bern	Wohlfarth, B (corresponding author), Univ Bern, Inst Med Educ, Bern, Switzerland.	benny.wohlfarth@protonmail.com						Abbasi J, 2021, JAMA-J AM MED ASSOC, V326, P1781, DOI 10.1001/jama.2021.18919; Alves Charles Phiilipe de Lucena, 2021, BMJ Open Sci, V5, pe100202, DOI 10.1136/bmjos-2021-100202; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; Andrade C, 2021, J CLIN PSYCHIAT, V82, DOI 10.4088/JCP.20f13804; [Anonymous], 2023, ChatGPT is the fastest growing app in the history of web applications; [Anonymous], 2023, Sony World Photography Awards 2023; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Banerjee D, 2023, AAAI 2023 WORKSH REP; Belenguer Lorenzo, 2022, AI Ethics, V2, P771, DOI 10.1007/s43681-022-00138-8; Bennett M, 2020, KENNEDY INST ETHIC J, V30, P243, DOI 10.1353/ken.2020.0014; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chen Y, 2023, A preliminary study on the capability boundary of LLM and a new path towards AGI; Chiu T.K.F., 2023, Computers and Education: Artificial Intelligence, V4, DOI DOI 10.1016/J.CAEAI.2022.100118; Loureiro SMC, 2021, J BUS RES, V129, P911, DOI 10.1016/j.jbusres.2020.11.001; Deranty JP, 2024, AI SOC, V39, P675, DOI 10.1007/s00146-022-01496-x; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Desaire H, 2023, Cell Rep Phys Sci., V30, P4, DOI [10.48550/arXiv.2303.16352, DOI 10.48550/ARXIV.2303.16352]; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; Easterling P, 1997, The Cambridge Companion to Greek Tragedy, DOI [10.1017/CCOL0521412455, DOI 10.1017/CCOL0521412455]; European Union Agency for Fundamental Rights, 2022, Bias in Algorithms-Artificial Intelligence and Discrimination; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Fei NY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30761-2; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; George SL, 2016, INT J CLIN ONCOL, V21, P15, DOI 10.1007/s10147-015-0887-3; George Stephen L, 2015, Clin Investig (Lond), V5, P161, DOI 10.4155/cli.14.116; Godefroid ME, 2023, MANAG REV Q, V73, P1667, DOI 10.1007/s11301-022-00283-8; Grimm R, 2015, Datenschutz und Datensicherheit, V5, P283, DOI [10.1007/s11623-015-0414-8, DOI 10.1007/S11623-015-0414-8]; Hendriks F, 2016, PROGR IS, P143, DOI 10.1007/978-3-319-28059-2_8; Huang JS, 2023, AM J CANCER RES, V13, P1148; Langner R, 2013, PSYCHOL BULL, V139, P870, DOI 10.1037/a0030694; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Lomis K, 2022, AMEE Lyon 2022; MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792; McCarthy J., 1955, A proposal for the Dartmouth summer research project on artificial intelligence, DOI DOI 10.1609/AIMAG.V27I4.1904; Naaz S, 2022, J ANAESTH CLIN PHARM, V38, P11, DOI 10.4103/joacp.JOACP_139_20; Nazari N, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07014; Ouyang L., 2022, NEURIPS; Pignatiello GA, 2020, J HEALTH PSYCHOL, V25, P123, DOI 10.1177/1359105318763510; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Sinclair BJ, 2023, CURR RES INSECT SCI, V3, DOI 10.1016/j.cris.2023.100057; Sollner M., 2012, P INT C INF SYST ICI, V127, P1; Song F, 2010, HEALTH TECHNOL ASSES, V14, P1, DOI 10.3310/hta14080; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wicherts JM, 2017, ANIMALS-BASEL, V7, DOI 10.3390/ani7120090; Xu YJ, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100179	46	0	0	8	9	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	SEP 18	2023	15	9							e45513	10.7759/cureus.45513	http://dx.doi.org/10.7759/cureus.45513			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	X3YS6	37868501	Green Published, gold			2024-07-03	WOS:001097850200023
J	Henrickson, L; Merono-Penuela, A				Henrickson, Leah; Merono-Penuela, Albert			Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT	AI & SOCIETY			English	Article; Early Access						Hermeneutics; Prompt engineering; Natural language processing; Natural language generation; Large language models; ChatGPT		Recent advances in natural language generation (NLG), such as public accessibility to ChatGPT, have sparked polarised debates about the societal impact of this technology. Popular discourse tends towards either overoptimistic hype that touts the radically transformative potentials of these systems or pessimistic critique of their technical limitations and general 'stupidity'. Surprisingly, these debates have largely overlooked the exegetical capacities of these systems, which for many users seem to be producing meaningful texts. In this paper, we take an interdisciplinary approach that combines hermeneutics-the study of meaning and interpretation-with prompt engineering-task descriptions embedded in input to NLG systems-to study the extent to which a specific NLG system, ChatGPT, produces texts of hermeneutic value. We design prompts with the goal of optimising hermeneuticity rather than mere factual accuracy, and apply them in four different use cases combining humans and ChatGPT as readers and writers. In most cases, ChatGPT produces readable texts that respond clearly to our requests. However, increasing the specificity of prompts' task descriptions leads to texts with intensified neutrality, indicating that ChatGPT's optimisation for factual accuracy may actually be detrimental to the hermeneuticity of its output.	[Henrickson, Leah] Univ Queensland, Sch Commun & Arts, Brisbane, Australia; [Merono-Penuela, Albert] Kings Coll London, Dept Informat, London, England	University of Queensland; University of London; King's College London	Merono-Penuela, A (corresponding author), Kings Coll London, Dept Informat, London, England.	l.henrickson@uq.edu.au; albert.merono@kcl.ac.uk		Merono-Penuela, Albert/0000-0003-4646-5842; Henrickson, Leah/0000-0001-8008-2373	We are grateful to Sheffield's Digital Humanities Institute, which facilitated the authors' meeting and collaboration. We would also like to thank fellow participants of the 2022 Digital Humanities Congress and the 2023 King's College London Creative AI Sy; Sheffield's Digital Humanities Institute	We are grateful to Sheffield's Digital Humanities Institute, which facilitated the authors' meeting and collaboration. We would also like to thank fellow participants of the 2022 Digital Humanities Congress and the 2023 King's College London Creative AI Sy; Sheffield's Digital Humanities Institute	We are grateful to Sheffield's Digital Humanities Institute, which facilitated the authors' meeting and collaboration. We would also like to thank fellow participants of the 2022 Digital Humanities Congress and the 2023 King's College London Creative AI Symposium for their feedback on earlier and alternative versions of this work.	Alexander S, 2022, ASTRAL CODEX 10; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Chomsky N., 2023, NEW YORK TIMES; Christiansen J, 2011, LECT NOTES COMPUT SC, V6539, P160, DOI 10.1007/978-3-642-18378-2_14; Cobley P, 2021, LANG SCI, V84, DOI 10.1016/j.langsci.2021.101359; Edwards B., 2023, Ars Technica; Eisikovits N, 2022, MORAL PHILOS POLIT, V9, P181, DOI 10.1515/mopp-2021-0026; Ethayarajh K, 2021, Arxiv, DOI arXiv:2009.13888; Evans A, 2022, ACTIVITY UK BUSINESS; Frankfurt HG, 2005, ON BULLSHIT, P1; Gadamer H.G., 1975, TRUTH METHOD, V2nd; Gambino Andrew, 2020, HMC, V1, P71, DOI [10.30658/hmc.1.5, DOI 10.30658/HMC.1.5]; Gonen H, 2022, Arxiv, DOI arXiv:2212.04037; Heidegger Martin., 1996, Being and Time: A Translation of Sein and Zeit; Henrickson L, 2022, CONFIGURATIONS, V30, P115; Henrickson Leah, 2021, Reading ComputerGenerated Texts, DOI [10.1017/9781108906463, DOI 10.1017/9781108906463]; Hidalgo CA, 2021, HOW HUMANS JUDGE MACHINES, P87; Holdsworth C, 2007, SOCIOLOGY, V41, P401, DOI 10.1177/0038038507076614; Kirschenbaum Matthew, 2023, Atlantic; Liu J., 2022, LlamaIndex; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Marche S., 2022, The Atlantic; Marcus G, 2023, INSIDE HEART CHATGPT; Milne G., 2020, Smoke Mirrors: How Hype Obscures the Future and How to See Past It; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153; NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703; Natale S, 2024, NEW MEDIA SOC, V26, P1909, DOI 10.1177/14614448221077278; Newport C., 2016, Deep Work: Rules for Focused Success in a Distracted World; Orekhov B, 2020, ORBIS LIT, V75, P230, DOI 10.1111/oli.12274; Postman Neil., 1993, TECHNOPOLY SURRENDER; promptbattle, PROMPT BATTL; Reeves B., 1996, MEDIA EQUATION PEOPL; RICOEUR P, 1991, PHILOS TODAY, V35, P73, DOI 10.5840/philtoday199135136; Robertson A., 2022, The Verge; Sadowski J, 2018, POTEMKIN MANY INSTAN; Sadowski Jathan., 2020, Too Smart: How Digital Capitalism Is Extracting Dta, Controlling Our Lives, and Taking Over the World, DOI [10.7551/mitpress/12240.001.0001, DOI 10.7551/MITPRESS/12240.001.0001]; Schmidt Florian A., 2022, Prompt Battle; Schulman J, 2022, Introducing chatgpt; Sprakel T, 2023, YOUTUBE; UK Government, 2021, NATL STRATEGY; Vincent James, 2023, The Verge; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Warnke G, 2011, REV METAPHYS, V65, P91; Warzel C., 2023, The Atlantic; Weizenbaum J., 1976, Computer Power and Human Reason: From Judgment to Calculation; Wingard J., 2023, Forbes; Winograd T., 2000, UNDERSTANDING COMPUT; Youn S, 2021, COMPUT HUM BEHAV, V119, DOI 10.1016/j.chb.2021.106721	49	9	9	42	77	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2023 SEP 4	2023										10.1007/s00146-023-01752-8	http://dx.doi.org/10.1007/s00146-023-01752-8		SEP 2023	16	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	Q5ZR2		hybrid			2024-07-03	WOS:001058308100001
J	Lan, MF; Cheng, MY; Hoang, L; ter Riet, G; Kilicoglu, H				Lan, Mengfei; Cheng, Mandy; Hoang, Linh; ter Riet, Gerben; Kilicoglu, Halil			Automatic categorization of self-acknowledged limitations in randomized controlled trial publications	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Self-acknowledged limitations; Randomized controlled trials; Reporting quality; Natural language processing; Text classification; Large language models	GUIDELINES; AGREEMENT	Objective: Acknowledging study limitations in a scientific publication is a crucial element in scientific transparency and progress. However, limitation reporting is often inadequate. Natural language processing (NLP) methods could support automated reporting checks, improving research transparency. In this study, our objective was to develop a dataset and NLP methods to detect and categorize self-acknowledged limitations (e.g., sample size, blinding) reported in randomized controlled trial (RCT) publications. Methods: We created a data model of limitation types in RCT studies and annotated a corpus of 200 fulltext RCT publications using this data model. We fine-tuned BERT-based sentence classification models to recognize the limitation sentences and their types. To address the small size of the annotated corpus, we experimented with data augmentation approaches, including Easy Data Augmentation (EDA) and Prompt-Based Data Augmentation (PromDA). We applied the best-performing model to a set of about 12K RCT publications to characterize self-acknowledged limitations at larger scale. Results: Our data model consists of 15 categories and 24 sub-categories (e.g., Population and its sub-category DiagnosticCriteria). We annotated 1090 instances of limitation types in 952 sentences (4.8 limitation sentences and 5.5 limitation types per article). A fine-tuned PubMedBERT model for limitation sentence classification improved upon our earlier model by about 1.5 absolute percentage points in F 1 score (0.821 vs. 0.8) with statistical significance ( p < . 001 ). Our best-performing limitation type classification model, PubMedBERT finetuning with PromDA (Output View), achieved an F 1 score of 0.7, improving upon the vanilla PubMedBERT model by 2.7 percentage points, with statistical significance (p < . 001 ). Conclusion: The model could support automated screening tools which can be used by journals to draw the authors' attention to reporting issues. Automatic extraction of limitations from RCT publications could benefit peer review and evidence synthesis, and support advanced methods to search and aggregate the evidence from the clinical trial literature.	[Lan, Mengfei; Hoang, Linh; Kilicoglu, Halil] Univ Illinois, Sch Informat Sci, 501 Daniel St, Champaign, IL 61820 USA; [Cheng, Mandy] Binghamton Univ, Dept Biol Sci, 4400 Vestal Pkwy East, New York, NY 13902 USA; [ter Riet, Gerben] Amsterdam Univ Appl Sci, Fac Hlth, Tafelbergweg 51, NL-1105 BD Amsterdam, Netherlands	University of Illinois System; University of Illinois Urbana-Champaign; State University of New York (SUNY) System; State University of New York (SUNY) Binghamton	Kilicoglu, H (corresponding author), Univ Illinois, Sch Informat Sci, 501 Daniel St, Champaign, IL 61820 USA.	halil@illinois.edu		ter Riet, Gerben/0000-0002-2231-7637	University of Illinois Campus Re-search Board award, USA; National Library of Medicine of the National Institutes of Health, USA [R01LM014079]	University of Illinois Campus Re-search Board award, USA; National Library of Medicine of the National Institutes of Health, USA	This work was supported by a University of Illinois Campus Research Board award, USA. It was also partially supported by the National Library of Medicine of the National Institutes of Health, USA under the award number R01LM014079. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The funder had no role in considering the study design or in the collection, analysis, interpretation of data, writing of the report, or decision to submit the article for publication.	Alvarez G, 2021, J CLIN EPIDEMIOL, V130, P96, DOI 10.1016/j.jclinepi.2020.10.018; Alvarez G, 2020, J CLIN EPIDEMIOL, V121, P32, DOI 10.1016/j.jclinepi.2020.01.006; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Avidan MS, 2019, BRIT J ANAESTH, V122, P413, DOI 10.1016/j.bja.2018.12.010; BHAPKAR VP, 1966, J AM STAT ASSOC, V61, P228, DOI 10.2307/2283057; Bhide A, 2018, ACTA OBSTET GYN SCAN, V97, P380, DOI 10.1111/aogs.13309; Bramstedt KA, 2020, J MED ETHICS, V46, P803, DOI 10.1136/medethics-2020-106494; Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013; Chalmers I, 2009, LANCET, V374, P86, DOI 10.1016/S0140-6736(09)60329-9; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Demner-Fushman D, 2007, COMPUT LINGUIST, V33, P63, DOI 10.1162/coli.2007.33.1.63; Dernoncourt Franck, 2017, P 15 C EUROPEAN CHAP, V2, P694, DOI DOI 10.18653/V1/E17-2110; Ding B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6045; Else H, 2020, NATURE, V588, P553, DOI 10.1038/d41586-020-03564-y; Feng SY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P968; Gooch P., 2020, bioRxiv; GOODMAN SN, 1994, ANN INTERN MED, V121, P11, DOI 10.7326/0003-4819-121-1-199407010-00003; Grootendorst Maarten, 2021, Zenodo; Hernan Miguel A, 2010, Causal inference; Hoang Linh, 2022, AMIA Annu Symp Proc, V2022, P542; Hoanga Linh, 2022, AMIA Jt Summits Transl Sci Proc, V2022, P254; Hu Y, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad542; Ioannidis JPA, 2007, J CLIN EPIDEMIOL, V60, P324, DOI 10.1016/j.jclinepi.2006.09.011; Ioannidis JPA, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005468; Jin D, 2020, BIOINFORMATICS, V36, P3856, DOI 10.1093/bioinformatics/btaa256; Jin D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3100; Jin YL, 2018, J MULTIDISCIP HEALTH, V11, P495, DOI 10.2147/JMDH.S155103; Jung RG, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21220-5; Kang T, 2021, J AM MED INFORM ASSN, V28, P812, DOI 10.1093/jamia/ocaa309; Kang T, 2019, STUD HEALTH TECHNOL, V264, P188, DOI 10.3233/SHTI190209; Keserlioglu K, 2019, RES INTEGR PEER REV, V4, DOI 10.1186/s41073-019-0078-2; Kilicoglu H, 2023, J CLIN EPIDEMIOL, V162, P19, DOI 10.1016/j.jclinepi.2023.08.004; Kilicoglu H, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103717; Kilicoglu H, 2018, J AM MED INFORM ASSN, V25, P855, DOI 10.1093/jamia/ocy038; Kilicoglu H, 2018, BRIEF BIOINFORM, V19, P1400, DOI 10.1093/bib/bbx057; Kilkenny C, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000412; Kim SN, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-S2-S5; Kiritchenko S, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-56; Krippendorff Klaus., 2004, Content analysis: An introduction to its methodology; Lahav D, 2022, AAAI CONF ARTIF INTE, P11982; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li XC, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2550; Marshall IJ, 2016, J AM MED INFORM ASSN, V23, P193, DOI 10.1093/jamia/ocv044; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Menke J, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101698; Schulz Kenneth F, 2010, Open Med, V4, pe60, DOI [10.1136/bmj.c869, 10.1016/j.jclinepi.2010.03.004, 10.1016/j.ijsu.2011.10.001]; Mutinda F., 2022, P 1 WORKSH INF EXTR, P26; Nye B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P197; Pandis N, 2014, J CLIN EPIDEMIOL, V67, P1044, DOI 10.1016/j.jclinepi.2014.04.001; Passonneau Rebecca., 2006, P INT C LANG RES EV; Price J. H., 2004, American Journal of Health Education, V35, P66, DOI DOI 10.1080/19325037.2004.10603611; Puhan MA, 2012, HEALTH QUAL LIFE OUT, V10, DOI 10.1186/1477-7525-10-23; Quinn TJ, 2021, BMC MED, V19, DOI 10.1186/s12916-021-01920-x; Raffel C, 2020, J MACH LEARN RES, V21; Ratner A, 2020, VLDB J, V29, P709, DOI [10.1007/s00778-019-00552-1, 10.14778/3157794.3157797]; Rose S., 2010, TEXT MINING APPL THE, P1, DOI DOI 10.1002/9780470689646.CH1; Ross PT, 2019, PERSPECT MED EDUC, V8, P261, DOI 10.1007/s40037-019-00530-x; Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.1136/bmj.c332, 10.1016/j.jclinepi.2010.02.005, 10.1136/bmj.c869, 10.4103/0976-500X.72352, 10.1186/1741-7015-8-18, 10.1016/j.ijsu.2011.09.004]; Schulz R, 2022, BMC RES NOTES, V15, DOI 10.1186/s13104-022-06080-6; Stenetorp P, 2012, P DEM 13 C EUR CHAPT, P102, DOI DOI 10.5555/2380921.2380942; Stylianou N, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101949; Sundararajan M, 2017, PR MACH LEARN RES, V70; ter Riet G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073623; Turner L, 2012, SYST REV-LONDON, V1, DOI 10.1186/2046-4053-1-60; Wallace BC, 2016, J MACH LEARN RES, V17; Wang Y., 2022, Long Papers, V1; Watson C, 2022, NAT MED, V28, P2, DOI 10.1038/s41591-021-01654-6; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Weissgerber T, 2021, NAT MED, V27, P6, DOI 10.1038/s41591-020-01203-7; Yang YB, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1008; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zdravkovic M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241826	73	0	0	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	APR	2024	152								104628	10.1016/j.jbi.2024.104628	http://dx.doi.org/10.1016/j.jbi.2024.104628		APR 2024	13	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	QO5S4	38548008	hybrid			2024-07-03	WOS:001221832900001
C	Rathore, SS; Farooq, SU; Tiwari, S		Chakrabarti, SK; Rastogi, A; Ghosh, S; Komondoor, R; Medicherla, RK; Kumar, L; Godboley, S		Rathore, Santosh Singh; Farooq, Sheikh Umar; Tiwari, Saurabh			A Report on the Sixth Workshop on Emerging Software Engineering Education (WESEE 2024)	PROCEEDINGS OF THE 17TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, ISEC 2024			English	Proceedings Paper	17th Innovations in Software Engineering Conference (ISEC)	FEB 22-24, 2024	IIITB Bangalore, Bangalore, INDIA	ACM India SIGSOFT Chapter, ACM In Cooperat, IIITB Bangalore, Ctr Technol Res & Innovat Digital Governance, TCS Res, Microsoft, IBM, ABB, Google, ISoft, ACM Chapter Conference	IIITB Bangalore	Software engineering education; Collaborative and Creative Software Engineering; Large Language models (LLMs) in software engineering education		Software engineering is rapidly adapting to meet the demands of contemporary customers and the challenges posed by relentless technological advancements. A well-prepared and highly competent workforce is crucial to propel this evolution, making it a pivotal element for the successful future of software engineering. To instill the art and science of software engineering across diverse age groups, innovative teaching methods must be introduced at all levels of education dissemination. Software engineering stands out as one of the most dynamic subjects in computer science curricula, spanning both undergraduate and postgraduate levels, given the continuous emergence of new software development process models, methods, and tools. A comprehensive software engineering course should encompass various processes, methods, and tools necessary to support large-scale software systems' development, operation, and maintenance. Moreover, these courses should significantly emphasize developing the interpersonal and communication skills essential for a well-rounded software engineer.	[Rathore, Santosh Singh] ABV IIITM Gwalior, Gwalior, Madhya Pradesh, India; [Farooq, Sheikh Umar] Univ Kashmir, Srinagar, Jammu & Kashmir, India; [Tiwari, Saurabh] DA IICT, Gandhinagar, India	ABV-Indian Institute of Information Technology & Management, Gwalior; University of Kashmir; Dhirubhai Ambani Institute of Information & Communication Technology	Rathore, SS (corresponding author), ABV IIITM Gwalior, Gwalior, Madhya Pradesh, India.	santoshs@iiitm.ac.in; suf.cs@uok.edu.in; saurabh_t@daiict.ac.in						Ebert C, 2023, IEEE SOFTWARE, V40, P30, DOI 10.1109/MS.2023.3265877; Petrovska Olga, 2024, CEP '24: Proceedings of the 8th Conference on Computing Education Practice, P37, DOI 10.1145/3633053.3633057; Singh P, 2019, PROCEEDINGS OF THE 12TH INNOVATIONS ON SOFTWARE ENGINEERING CONFERENCE (ISEC), DOI 10.1145/3299771.3301647; Tiwari Saurabh, 2023, P 16 INNOVATIONS SOF, P1; Tiwari Saurabh, 2021, 14 INNOVATIONS SOFTW, P1; Tiwari Saurabh, 2020, P 13 INNOVATIONS SOF, P1; Yeralan S., 2023, Sustainable Engineering and Innovation, V5, P107, DOI DOI 10.37868/SEI.V5I2.ID196	7	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1767-3				2024									20	10.1145/3641399.3641436	http://dx.doi.org/10.1145/3641399.3641436			2	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6ID		hybrid			2024-07-03	WOS:001174625700020
J	Li, Z; Ma, J; Tan, Y; Guo, C; Li, X				Li, Zheng; Ma, Jun; Tan, Yi; Guo, Cui; Li, Xiao			Combining physical approaches with deep learning techniques for urban building energy modeling: A comprehensive review and future research prospects	BUILDING AND ENVIRONMENT			English	Review						Physics-based urban building energy modeling; Deep learning; Data-driven; Hybrid model; AIGC; Large language model	ARTIFICIAL NEURAL-NETWORKS; RESIDENTIAL BUILDINGS; SIMULATION; FRAMEWORK; DEMAND; RECONSTRUCTION; METHODOLOGY; PROFILES; IMAGES	In recent times, there has been a growing interest in urban building energy modeling (UBEM), owing to its potential benefits for cities. These benefits include aiding city decision-makers in comprehending building energy demand, managing and planning urban energy supply, developing building energy efficiency measures, and analyzing urban building retrofits. The physical approach has historically been a common method for studying energy in urban buildings. Notwithstanding, with the progress of artificial intelligence, powerful deep learning techniques are increasingly being utilized to overcome some of the physical approach's limitations. Consequently, the combination of physical approaches with deep learning algorithms for UBEM research has become a popular area of study. The purpose of this paper is to present an updated review of UBEM studies from three perspectives: model preparation, model simulation, and model calibration. The principal aim of this review is to investigate and analyze the present research status, challenges, obstacles, and research gaps of deep learning techniques in physics-based UBEM. This analysis is followed by a discussion of feasible options. Finally, four distinct viewpoints are provided to explore the future research prospects of deep learning techniques and to propose technically viable pathways for each perspective.	[Li, Zheng; Ma, Jun; Guo, Cui] Univ Hong Kong, Dept Urban Planning & Design, Hong Kong, Peoples R China; [Tan, Yi] Shenzhen Univ, Key Lab Resilient Infrastructures Coastal Cities, Minist Educ, Shenzhen, Peoples R China; [Li, Xiao] Univ Hong Kong, Dept Civil Engn, Hong Kong, Peoples R China	University of Hong Kong; Shenzhen University; University of Hong Kong	Ma, J (corresponding author), Univ Hong Kong, Dept Urban Planning & Design, Hong Kong, Peoples R China.	junma@hku.hk		Guo, Cui/0000-0003-0816-6534	Early Career Scheme from the Hong Kong Research Grant Council [27202521]; Seed Fund for PI Research - Basic Research from The University of Hong Kong [2202100879]	Early Career Scheme from the Hong Kong Research Grant Council; Seed Fund for PI Research - Basic Research from The University of Hong Kong	This study was jointly supported by the Early Career Scheme (No. 27202521) from the Hong Kong Research Grant Council, and the Seed Fund for PI Research - Basic Research (No. 2202100879) from The University of Hong Kong. The authors wish to appreciate the anonymous reviewers for their comments to improve this paper.	Abbasabadi N, 2019, APPL ENERG, V253, DOI 10.1016/j.apenergy.2019.113550; Abbasabadi N, 2019, BUILD ENVIRON, V161, DOI 10.1016/j.buildenv.2019.106270; Aguilar J, 2021, RENEW SUST ENERG REV, V151, DOI 10.1016/j.rser.2021.111530; Ali U, 2020, APPL ENERG, V279, DOI 10.1016/j.apenergy.2020.115834; Alidoost F, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192219; Andrade JR, 2017, IEEE T SUSTAIN ENERG, V8, P1571, DOI 10.1109/TSTE.2017.2694340; Andrade-Cabrera C, 2017, ENERG BUILDINGS, V155, P513, DOI 10.1016/j.enbuild.2017.09.035; Ang YQ, 2020, APPL ENERG, V279, DOI 10.1016/j.apenergy.2020.115738; [Anonymous], 2012, Transient System Simulation Tool; [Anonymous], CitySim Software,"; [Anonymous], 2012, CityGML; Borges P, 2022, BUILD ENVIRON, V215, DOI 10.1016/j.buildenv.2022.108958; Buckley N, 2021, ENERG BUILDINGS, V247, DOI 10.1016/j.enbuild.2021.111115; Bush B, 2017, 2017 IEEE WORKSHOP ON DATA SYSTEMS FOR INTERACTIVE ANALYSIS (DSIA); businesslocationcenter, Berlin 3D-Downloadportal des Business Location Centers; Buyukdemircioglu M., 2021, INT ARCH PHOTOGRAMM, VXLIII-B3-2021, P55, DOI [10.5194/isprs-archives-XLIII-B3-2021-55-2021, DOI 10.5194/ISPRS-ARCHIVES-XLIII-B3-2021-55-2021]; C. of N. Y. Data NYC Open, NYC Open Data; Cao YX, 2021, REMOTE SENS ENVIRON, V264, DOI 10.1016/j.rse.2021.112590; Carnieletto L, 2021, BUILD ENVIRON, V192, DOI 10.1016/j.buildenv.2021.107590; Chakraborty D, 2021, APPL ENERG, V291, DOI 10.1016/j.apenergy.2021.116807; Chen JL, 2019, ENERGY, V188, DOI 10.1016/j.energy.2019.116046; Chen K, 2018, AUTOMAT CONSTR, V93, P22, DOI 10.1016/j.autcon.2018.05.009; Chong A, 2021, ENERG BUILDINGS, V253, DOI 10.1016/j.enbuild.2021.111533; Coakley D, 2014, RENEW SUST ENERG REV, V37, P123, DOI 10.1016/j.rser.2014.05.007; Dahlstrom L, 2022, ENERG BUILDINGS, V266, DOI 10.1016/j.enbuild.2022.112099; Dai ML, 2021, BUILD ENVIRON, V199, DOI 10.1016/j.buildenv.2021.107921; Dasari SV, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P107, DOI 10.1109/IEMTRONICS52119.2021.9422544; Dixit M, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115530; DOE-2, ABOUT US; Dong B, 2021, APPL ENERG, V293, DOI 10.1016/j.apenergy.2021.116856; Dong B, 2016, ENERG BUILDINGS, V117, P341, DOI 10.1016/j.enbuild.2015.09.033; Dridi J, 2022, BUILD ENVIRON, V217, P1, DOI 10.1016/j.buildenv.2022.109057; EnergyPlus, about us; entranze, ENTRANZE Data; Escandón R, 2019, APPL THERM ENG, V150, P492, DOI 10.1016/j.applthermaleng.2019.01.013; Fan C, 2019, APPL ENERG, V235, P1551, DOI 10.1016/j.apenergy.2018.11.081; Fathi S, 2020, RENEW SUST ENERG REV, V133, DOI 10.1016/j.rser.2020.110287; Ferrando M, 2022, SUSTAIN CITIES SOC, V87, DOI 10.1016/j.scs.2022.104164; Ferrando M, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102408; Frayssinet L, 2018, RENEW SUST ENERG REV, V81, P2318, DOI 10.1016/j.rser.2017.06.040; Gao Y, 2021, ENERG BUILDINGS, V252, DOI 10.1016/j.enbuild.2021.111379; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Guo HN, 2021, REMOTE SENS ENVIRON, V264, DOI 10.1016/j.rse.2021.112589; Hinton G.E., 2009, Scholarpedia, V4, P5947, DOI [10.4249/scholarpedia.5947, DOI 10.4249/SCHOLARPEDIA.5947]; Hoffmann EJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111259; Hong TZ, 2020, BUILD ENVIRON, V168, DOI 10.1016/j.buildenv.2019.106508; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; Johari F, 2020, RENEW SUST ENERG REV, V128, DOI 10.1016/j.rser.2020.109902; Karatsiolis S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13122417; Kim CH, 2021, J BUILD ENG, V43, DOI 10.1016/j.jobe.2021.102577; Lee CW, 2014, RENEW ENERG, V68, P761, DOI 10.1016/j.renene.2014.03.015; Li JY, 2022, BUILD SIMUL-CHINA, V15, P1145, DOI 10.1007/s12273-021-0871-y; Li WJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040403; Li WL, 2017, ENERGY, V141, P2445, DOI 10.1016/j.energy.2017.11.071; Li XY, 2018, ENERG BUILDINGS, V169, P417, DOI 10.1016/j.enbuild.2018.03.064; Liasis G, 2016, ISPRS J PHOTOGRAMM, V119, P437, DOI 10.1016/j.isprsjprs.2016.07.006; Lim H, 2017, ENERG BUILDINGS, V155, P66, DOI 10.1016/j.enbuild.2017.09.009; Liu CJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172719; Liu HT, 2020, IEEE T MULTIMEDIA, V22, P3153, DOI 10.1109/TMM.2020.2971431; Liu HC, 2023, ACM T INTEL SYST TEC, V14, DOI 10.1145/3546872; Ma WG, 2021, IEEE GEOSCI REMOTE S, V18, P1009, DOI 10.1109/LGRS.2020.2993451; Magalhaes SMC, 2017, ENERG BUILDINGS, V151, P332, DOI 10.1016/j.enbuild.2017.06.076; Malhotra A, 2022, BUILD ENVIRON, V208, DOI 10.1016/j.buildenv.2021.108552; Medsker L. R., 2001, INT SER COMPUTAT INT, V5, P64; Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437; Mitra Angan, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P93, DOI 10.1109/ICAIS50930.2021.9395938; Moradzadeh A, 2022, IEEE ACCESS, V10, P5037, DOI 10.1109/ACCESS.2021.3139529; Mouakher A, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10020248; Mui KW, 2021, ENERGIES, V14, DOI 10.3390/en14164850; Muroni A, 2019, BUILD SIMUL-CHINA, V12, P1047, DOI 10.1007/s12273-019-0573-x; Nageler P, 2018, ENERG BUILDINGS, V179, P333, DOI 10.1016/j.enbuild.2018.09.034; Nageler P, 2018, ENERGY, V157, P633, DOI 10.1016/j.energy.2018.05.190; Nagpal S, 2019, APPL ENERG, V241, P82, DOI 10.1016/j.apenergy.2019.03.010; Ng, 2011, CS294A LECT NOTES, V72, P1, DOI DOI 10.1371/JOURNAL.PONE.0006098; Nouvel R, 2017, COMPUT ENVIRON URBAN, V64, P68, DOI 10.1016/j.compenvurbsys.2016.12.005; Nutkiewicz A, 2021, ADV APPL ENERGY, V3, DOI 10.1016/j.adapen.2021.100038; Nutkiewicz A, 2018, APPL ENERG, V225, P1176, DOI 10.1016/j.apenergy.2018.05.023; O'Donnell J, 2019, AUTOMAT CONSTR, V107, DOI 10.1016/j.autcon.2019.102905; O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]; OpenStreetMap, US; Pongelli A, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13010040; Qi F, 2016, ENERG BUILDINGS, V118, P123, DOI 10.1016/j.enbuild.2016.02.044; Qian Z, 2022, INT J APPL EARTH OBS, V107, DOI 10.1016/j.jag.2022.102680; Reinhart CF, 2016, BUILD ENVIRON, V97, P196, DOI 10.1016/j.buildenv.2015.12.001; Rhee J, 2022, COMM COM INF SC, V1465, P175, DOI 10.1007/978-981-19-1280-1_11; Sailor DJ, 2004, ATMOS ENVIRON, V38, P2737, DOI 10.1016/j.atmosenv.2004.01.034; Salim FD, 2020, BUILD ENVIRON, V183, DOI 10.1016/j.buildenv.2020.106964; Soroush SA, 2022, J BUILD ENG, V46, DOI 10.1016/j.jobe.2021.103661; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Soni A, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.10.017; Swan LG, 2009, RENEW SUST ENERG REV, V13, P1819, DOI 10.1016/j.rser.2008.09.033; Sweeney C, 2020, WIRES ENERGY ENVIRON, V9, DOI 10.1002/wene.365; Tardioli G, 2018, BUILD ENVIRON, V140, P90, DOI 10.1016/j.buildenv.2018.05.035; THE 17 GOALS, Sustainable Development; Tien PW, 2022, APPL ENERG, V308, DOI 10.1016/j.apenergy.2021.118336; Touzani S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132578; U.N. Environment, 2021, 2021 Global Status Report for Buildings and Construction; Vazquez-Canteli J, 2019, J PHYS CONF SER, V1343, DOI 10.1088/1742-6596/1343/1/012002; Vázquez-Canteli JR, 2019, SUSTAIN CITIES SOC, V45, P243, DOI 10.1016/j.scs.2018.11.021; Wang C, 2022, BUILD ENVIRON, V224, DOI 10.1016/j.buildenv.2022.109541; Wang C, 2022, BUILD ENVIRON, V217, DOI 10.1016/j.buildenv.2022.109056; Wang C, 2021, SUSTAIN CITIES SOC, V71, DOI 10.1016/j.scs.2021.102998; Wang M, 2022, SUSTAIN CITIES SOC, V87, DOI 10.1016/j.scs.2022.104267; Wang YH, 2022, ENERG CONVERS MANAGE, V258, DOI 10.1016/j.enconman.2022.115507; Westermann P, 2021, ENERGY AI, V3, DOI 10.1016/j.egyai.2020.100039; Westermann P, 2020, APPL ENERG, V278, DOI 10.1016/j.apenergy.2020.115563; Wu B, 2018, ISPRS J PHOTOGRAMM, V139, P119, DOI 10.1016/j.isprsjprs.2018.03.004; Xie YQ, 2020, INT J GEOGR INF SCI, V34, P777, DOI 10.1080/13658816.2019.1624761; Xu XQ, 2012, ENERG BUILDINGS, V55, P637, DOI 10.1016/j.enbuild.2012.09.013; Yang Q., 2019, Synth. Lect. Artif. Intell. Mach. Learn., V13, P1, DOI 10.1007/978-3-031-01585-4; Yoon S, 2020, ENERG BUILDINGS, V221, DOI 10.1016/j.enbuild.2020.110026; Yu DW, 2021, ISPRS J PHOTOGRAMM, V171, P155, DOI 10.1016/j.isprsjprs.2020.11.011; Yu YT, 2021, IEEE GEOSCI REMOTE S, V18, P895, DOI 10.1109/LGRS.2020.2986380; Zhan SC, 2022, ENERG BUILDINGS, V270, DOI 10.1016/j.enbuild.2022.112278; Zhang GW, 2022, AUTOMAT CONSTR, V133, DOI 10.1016/j.autcon.2021.104016; Zhang RJ, 2021, BUILD ENVIRON, V195, DOI 10.1016/j.buildenv.2021.107728; Zhao WF, 2022, ISPRS J PHOTOGRAMM, V187, P34, DOI 10.1016/j.isprsjprs.2022.02.022; Zygmunt M, 2021, ENERGIES, V14, DOI 10.3390/en14248285	118	3	3	35	46	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-1323	1873-684X		BUILD ENVIRON	Build. Environ.	DEC 1	2023	246								110960	10.1016/j.buildenv.2023.110960	http://dx.doi.org/10.1016/j.buildenv.2023.110960		NOV 2023	16	Construction & Building Technology; Engineering, Environmental; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	Y8JK6					2024-07-03	WOS:001107666000001
J	Freiman, O				Freiman, Ori			Analysis of Beliefs Acquired from a Conversational AI: Instruments-based Beliefs, Testimony-based Beliefs, and Technology-based Beliefs	EPISTEME-A JOURNAL OF INDIVIDUAL AND SOCIAL EPISTEMOLOGY			English	Article; Early Access						testimony; testimony-based beliefs; technology-based beliefs; personal virtual assistants; conversational AIs; chatbots; AI; anthropomorphism and Large Language Models	EPISTEMOLOGY; KNOWLEDGE	Speaking with conversational AIs, technologies whose interfaces enable human-like interaction based on natural language, has become a common phenomenon. During these interactions, people form their beliefs due to the say-so of conversational AIs. In this paper, I consider, and then reject, the concepts of testimony-based beliefs and instrument-based beliefs as suitable for analysis of beliefs acquired from these technologies. I argue that the concept of instrument-based beliefs acknowledges the non-human agency of the source of the belief. However, the analysis focuses on perceiving signs and indicators rather than content expressed in natural language. At the same time, the concept of testimony-based beliefs does refer to natural language propositions, but there is an underlying assumption that the agency of the testifier is human. To fill the lacuna of analyzing belief acquisition from conversational AIs, I suggest a third concept: technology-based beliefs. It acknowledges the non-human agency-status of the originator of the belief. Concurrently, the focus of analysis is on the propositional content that forms the belief. Filling the lacuna enables analysis that considers epistemic, ethical, and social issues of conversational AIs without excluding propositional content or compromising accepted assumptions about the agency of technologies.	[Freiman, Ori] McMaster Univ, Digital Soc Lab, Hamilton, ON, Canada	McMaster University	Freiman, O (corresponding author), McMaster Univ, Digital Soc Lab, Hamilton, ON, Canada.	freimano@mcmaster.ca		Freiman, Ori/0000-0002-6750-9130				Adewumi T, 2022, Arxiv, DOI arXiv:2205.00965; ADLER J., 2014, The Stanford Encyclopedia of Philosophy; Alvarado R., 2022, AI and Ethics, DOI [10.1007/s43681-022-00224-x.pdf, DOI 10.1007/S43681-022-00224-X.PDF]; Alvarado R, 2022, FOUND SCI, V27, P1183, DOI 10.1007/s10699-021-09812-2; Baird Davis., 2004, THING KNOWLEDGE PHIL; Blake A., 2019, WASHINGTON TIME 1226; Bloor D, 1999, STUD HIST PHILOS SCI, V30A, P81, DOI 10.1016/S0039-3681(98)00038-7; Boland H., 2020, TELEGRAPH 1126; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryson J.J., 2018, AI GLOBAL GOVERNANCE; Carter J.A., 2010, EPISTEMOLOGY TESTIMO; Cetina, 1999, EPISTEMIC CULTURES S; Coady C. A. J., 1992, TESTIMONY PHILOS STU; Coeckelbergh M, 2012, ETHICS INF TECHNOL, V14, P53, DOI 10.1007/s10676-011-9279-1; Collins H.M., 1993, The golem : what everyone should know about science; Collins H.M., 1998, SHAPE ACTIONS WHAT H; Collins H, 2010, SPONTANEOUS GENER, V4, P138, DOI 10.4245/sponge.v4i1.11354; Comesaña J, 2010, NOUS, V44, P571, DOI 10.1111/j.1468-0068.2010.00748.x; Dahl E.S., 2018, PHILOS TECHNOLOGY, V31, P571, DOI 10.1007/s13347-017-0275-1; de Boer B, 2018, FOUND SCI, V23, P739, DOI 10.1007/s10699-018-9545-3; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Faulkner P, 2018, ERGO-ANN ARBOR, V5, P103, DOI 10.3998/ergo.12405314.0005.004; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Freiman O., 2022, TORONTO STAR 0807; Freiman O., 2020, The Oxford Handbook of Assertion, P415, DOI 10.1093/oxfordhb/9780190675233.013.36; Freiman O., 2022, CONSPIR THEOR, V3, P1, DOI [https://doi.org/10.1007/s43681-022-00241-w, DOI 10.1007/S43681-022-00241-W]; Freiman O., 2021, THESIS BARLLAN U; Freiman O, 2014, INT REV INF ETHICS, V22, P6; FRICKER E, 1995, MIND, V104, P393, DOI 10.1093/mind/104.414.393; Fricker E, 2002, STUD HIST PHILOS SCI, V33A, P373, DOI 10.1016/S0039-3681(02)00006-7; Fricker E, 2015, EPISTEME-J INDIV SOC, V12, P173, DOI 10.1017/epi.2015.6; Fricker Elizabeth., 1987, P ARISTOTELIAN SOC S, V61, P57; Fu TC, 2022, AI OPEN, V3, P14, DOI 10.1016/j.aiopen.2022.02.001; Gelfert A, 2018, TESTIMONY; Gelfert A., 2014, CRITICAL INTRO TESTI; Giere R., 2006, Scientific perspectivism; Goldberg SC, 2012, PHILOS EXPLOR, V15, P181, DOI 10.1080/13869795.2012.670719; Goldman A, 2000, LEONARDO SERIES, P126; Goldman Alvin., 2011, Evidentialism and Its Discontents, DOI DOI 10.1093/ACPROF:OSO/9780199563500.003.0017; Green C.R., 2006, THESIS U NOTRE DAME; Green ChristopherR., 2008, Internet Encyclopedia of Philosophy, P1; Hacking Ian., 1985, Images of Science: Essays on Realism and Empiricism; HARDWIG J, 1985, J PHILOS, V82, P335, DOI 10.2307/2026523; Harwell D., 2022, WASHINGTON POST 1210; Henderson D., 2007, ACTA ANAL, V22, P281, DOI [10.1007/s12136-007-0015-8, DOI 10.1007/S12136-007-0015-8]; Humphreys P., 2004, EXTENDING OURSELVES; Humphreys P, 2009, EPISTEME-J INDIV SOC, V6, P221, DOI 10.3366/E1742360009000653; Hurst L., 2022, EURONEWS 1214; Ihde Don., 1991, Instrumental Realism; KITCHER P, 1990, J PHILOS, V87, P5, DOI 10.2307/2026796; Kletzl S, 2014, STUD HIST PHILOS SCI, V47, P118, DOI 10.1016/j.shpsa.2014.06.002; Kusch M., 2002, KNOWLEDGE AGREEMENT; Lackey Jennifer., 2014, Essays in Collective Epistemology. Ed, P64, DOI DOI 10.1093/ACPROF:OSO/9780199665792.003.0004; Lackey Jennifer., 2008, Learning from Words: Testimony as a Source of Knowledge; LATOUR B., 1986, KNOWLEDGE SOC STUDIE, V6, P1, DOI DOI 10.1002/9780470979587.CH9; LAUDAN L, 1981, PHILOS SCI, V48, P19, DOI 10.1086/288975; LEHRER K, 1995, MONIST, V78, P156, DOI 10.5840/monist199578216; Lehrer K., 2000, Theory of Knowledge; Lehrer K, 2018, Theory of knowledge; Lehrer Keith., 2003, EPISTEMOLOGY KEITH L, P309; Lipton P, 1998, STUD HIST PHILOS SCI, V29A, P1, DOI 10.1016/S0039-3681(97)00022-8; Longino H., 2002, The fate of knowledge; Lynch Michael., 1994, Configurations, V2, P137; Matilal BimalKrishna., 1994, KNOWING WORDS W INDI; Meaker M., 2019, MEDIUM ONEZERO 0510; Millar A, 2009, KNOWLEDGE RECOGNITIO, P91; Miller B., 2020, ROUTLEDGE HDB TRUST, P341, DOI DOI 10.4324/9781315542294-26; Miller B, 2015, PHILOS QUART, V65, P417, DOI 10.1093/pq/pqv025; Mollman S., 2022, YAHOO FINANCE 1209; Neges (Kletzl S., 2018, THESIS U VIENNA; Nickel PJ, 2013, MIND MACH, V23, P489, DOI 10.1007/s11023-013-9303-9; Olesen F, 2012, FOUND SCI, V17, P357, DOI 10.1007/s10699-011-9241-z; Olsson Erik., 2014, The Stanford Encyclopedia of Philosophy, VSpring; Pitt J., 2007, METASCIENCE, V16, P51, DOI DOI 10.1007/s11016-006-9070-9; Pitt J. C., 2010, KNOWLEDGE TECHNOLOGY, V23, P445, DOI [https://doi.org/10.1007/s12130-010-9125-5, DOI 10.1007/S12130-010-9125-5]; Pritchard D., 2004, PHILOS ISSUES, V14, P326, DOI DOI 10.1111/J.1533-6077.2004.00033.X; Rieder G, 2020, MACHINES WE TRUST PE; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Ryan M, 2020, SCI ENG ETHICS, V26, P2749, DOI 10.1007/s11948-020-00228-y; Schulman J, 2022, Introducing chatgpt; Shapin Steven., 1994, SOCIAL HIST TRUTH; Smart Paul, 2017, Philos Technol, V30, P357, DOI 10.1007/s13347-016-0250-2; Sosa E., 2006, EPISTEMOLOGY TESTIMO, P116, DOI DOI 10.1093/ACPROF:OSO/9780199276011.003.0006; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Symons J, 2019, MIND MACH, V29, P37, DOI 10.1007/s11023-018-9487-0; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; van Fraassen B. C., 1980, The scientific image; Verbeek P. P., 2005, WHAT THINGS DO PHILO; Waelbers K., 2010, ICAART, V14, P176, DOI [10.5840/techne201014320, DOI 10.5840/TECHNE201014320]	89	2	2	1	8	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1742-3600	1750-0117		EPISTEME-J INDIV SOC	Episteme	2023 MAR 6	2023									PII S1742360023000126	10.1017/epi.2023.12	http://dx.doi.org/10.1017/epi.2023.12		MAR 2023	17	Philosophy	Arts &amp; Humanities Citation Index (A&amp;HCI)	Philosophy	9O8FF		hybrid			2024-07-03	WOS:000943832000001
J	Askarbekuly, N; Anicic, N				Askarbekuly, Nursultan; Anicic, Nenad			LLM examiner: automating assessment in informal self-directed e-learning using ChatGPT	KNOWLEDGE AND INFORMATION SYSTEMS			English	Article; Early Access						Large language models; Retrieval-augmented generation; Assessment; Learning outcomes; Informal e-learning; Educational technology		Informal e-learning systems often lack structured assessment mechanisms, making it difficult to assess the learning outcomes. This work aims to automate outcome-based assessment through the use of a large language AI model, in particular ChatGPT. Such automation can be of value to educators and developers of educational software, as it tackles the non-trivial task of evaluating educational trajectories from the outcome-based perspective. To achieve this aim, we proposed a system and validated it through a case study and two evaluation stages. In the first stage, we generated 40 assessment questions of various types, 12 of which were approved as high quality. In the second stage, we generated another 45 questions and conducted 5 individual peer evaluation sessions. The most significant automation aspects in guaranteeing the assessment quality were found to be the instructor involvement to monitor the process, the use of a high quality custom knowledge base, and formulation of the correct prompt instructions on the basis of the learning outcome statements.	[Askarbekuly, Nursultan] Innopolis Univ, Fac Comp Sci & Engn, Innopolis, Russia; [Askarbekuly, Nursultan; Anicic, Nenad] Univ Belgrade, Fac Org Sci, Belgrade, Serbia	Innopolis University; University of Belgrade	Askarbekuly, N (corresponding author), Innopolis Univ, Fac Comp Sci & Engn, Innopolis, Russia.; Askarbekuly, N (corresponding author), Univ Belgrade, Fac Org Sci, Belgrade, Serbia.	n.askarbekuly@innopolis.university; anicic.nenad@fon.bg.ac.rs						Ajjawi R, 2020, ASSESS EVAL HIGH EDU, V45, P304, DOI 10.1080/02602938.2019.1639613; Al-sadi A., 2023, Int J Technol Innov Manag, V3, P1, DOI DOI 10.54489/IJTIM.V3I1.195; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; apple, NamazApp on Apple Store; Askarbekuly N., 2020, OPEN SOURCE SYSTEMS, V582, P106, DOI 10.1007/978-3-030-47240-5_11; Askarbekuly N, 2021, LECT NOTE NETW SYST, V271, P358, DOI 10.1007/978-3-030-80624-8_44; Badini S, 2023, ADV IND ENG POLY RES, V6, P278, DOI 10.1016/j.aiepr.2023.03.003; Biggs J, 2012, HIGH EDUC RES DEV, V31, P39, DOI 10.1080/07294360.2012.642839; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Cukusic M, 2010, COMPUT EDUC, V55, P554, DOI 10.1016/j.compedu.2010.02.017; DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60; Firat M., 2023, How chat GPT can transform autodidactic experiences and open education?, DOI [10.31219/osf.io/9ge8m, DOI 10.31219/OSF.IO/9GE8M]; Folsom-Kovarik JT., 2013, ACM Trans Intell Syst Technol, V10, P2438664; github, Nurlingo: LLM Examiner; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100115; Jenneboer L, 2022, J THEOR APPL EL COMM, V17, P212, DOI 10.3390/jtaer17010011; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Keramati A, 2011, COMPUT EDUC, V57, P1919, DOI 10.1016/j.compedu.2011.04.005; Kumaran VS, 2013, LECT NOTES COMPUT SC, V8167, P274, DOI 10.1007/978-3-642-41175-5_28; Liu FJ, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P274, DOI 10.1109/ICHIT.2008.184; Meissner N, 2024, SOFTWARE ENG UNTERRI, P53; Myers DS., 2017, J Comput Sci Coll, V33, P260; namaz, Namaz Live; openai, 2023, Best Practices for Prompt Engineering with OpenAI API; Oviedo-Trespalacios O, 2023, SAFETY SCI, V167, DOI 10.1016/j.ssci.2023.106244; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reeves T. C., 2002, Educational Technology, V42, P23; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Saks K, 2014, PROCD SOC BEHV, V112, P190, DOI 10.1016/j.sbspro.2014.01.1155; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Subagja AD., 2023, J Minfo Polgan, V12, P380, DOI [10.33395/jmp.v12i2.12407, DOI 10.33395/JMP.V12I2.12407]; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Union E, 2023, Europass Tools: European qualifications framework	37	0	0	4	4	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377	0219-3116		KNOWL INF SYST	Knowl. Inf. Syst.	2024 JUN 10	2024										10.1007/s10115-024-02156-w	http://dx.doi.org/10.1007/s10115-024-02156-w		JUN 2024	18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TU1E7					2024-07-03	WOS:001243672200003
J	Klenk, M				Klenk, Michael			Ethics of generative AI and manipulation: a design-oriented research agenda	ETHICS AND INFORMATION TECHNOLOGY			English	Article						Generative AI; Large Language Models (LLMs); Manipulation; Value sensitive design; AI ethics; Persuasion; Deception		Generative AI enables automated, effective manipulation at scale. Despite the growing general ethical discussion around generative AI, the specific manipulation risks remain inadequately investigated. This article outlines essential inquiries encompassing conceptual, empirical, and design dimensions of manipulation, pivotal for comprehending and curbing manipulation risks. By highlighting these questions, the article underscores the necessity of an appropriate conceptualisation of manipulation to ensure the responsible development of Generative AI technologies.	[Klenk, Michael] Delft Univ Technol, Dept Values Technol & Innovat, Jaffalaan 5, NL-2628 BX Delft, Netherlands	Delft University of Technology	Klenk, M (corresponding author), Delft Univ Technol, Dept Values Technol & Innovat, Jaffalaan 5, NL-2628 BX Delft, Netherlands.	M.B.O.T.Klenk@tudelft.nl		Klenk, Michael/0000-0002-1483-0799	Nederlandse Organisatie voor Wetenschappelijk Onderzoek	Nederlandse Organisatie voor Wetenschappelijk Onderzoek(Netherlands Organization for Scientific Research (NWO))	I am thankful to Caroline Figueiredo, and to two anonymous referees for helpful feedback.	Askell A, 2021, Arxiv, DOI [arXiv:2112.00861, DOI 10.48550/ARXIV.2112.00861]; Barnhill A., 2022, The philosophy of online manipulation, P49, DOI [10.4324/9781003205425-4, DOI 10.4324/9781003205425-4]; Barnhill A., 2014, MANIPULATION THEORY, P51, DOI DOI 10.1093/ACPROF:OSO/9780199338207.003.0003; Baron M., 2003, Proceedings and Addresses of the American Philosophical Association, V77, P37, DOI [10.2307/3219740, DOI 10.2307/3219740]; Baron Marcia, 2014, MANIPULATION THEORY, P98, DOI [DOI 10.1093/ACPROF:OSO/9780199338207.003.0005, 10.1093/acprof:oso/9780199338207.003.0005]; Beauchamp T.L., 1984, Business Professional Ethics Journal, V3, P1; Beauchamp TL, 2019, Principles of Biomedical Ethics, V8th; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brignull H., 2023, Deceptive Patterns: Exposing the Tricks Tech Companies Use to Control You; Buijsman S., Cambridge Handbook on the Law, Ethics and Policy of AI; Cappuccio ML., 2022, The philosophy of online manipulation, P72, DOI [10.4324/9781003205425-5, DOI 10.4324/9781003205425-5]; Cohen S., 2023, Journal of Ethics and Social Philosophy, DOI [10.26556/jesp.v25i2.1998, DOI 10.26556/JESP.V25I2.1998]; Coons C., 2014, MANIPULATION THEORY; EGE, 2023, Democracy in the digital age; Eliot L., 2023, Forbes; EU, 2000, OJL327, VL327, P1, DOI 10.1039/ap9842100196; European Commission, 2021, Proposal for a regulation of the European Parliament and of the Council establishing a carbon border adjustment mechanism; European Parliamentary Research Services, 2020, European framework on ethical aspects of artificial intelligence, robotics and related technologies: European added value assessment; Faraoni S, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1216340; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Flynn J., 2022, The Stanford encyclopedia of philosophy; Frankfurt HG, 2005, ON BULLSHIT, P1; Friedman B, 2019, VALUE SENSITIVE DESIGN: SHAPING TECHNOLOGY WITH MORAL IMAGINATION, P1, DOI 10.7551/mitpress/7585.001.0001; Gabriel I, 2020, MIND MACH, V30, P411, DOI 10.1007/s11023-020-09539-2; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037/0033-295X.103.4.650; Goldstein J. A., 2023, arXiv, DOI [10.48550/arXiv.2301.04246, DOI 10.48550/ARXIV.2301.04246]; Gorin M., 2014, MANIPULATION THEORY, P73, DOI DOI 10.1093/ACPROF:OSO/9780199338207.003.0004; Gorin M, 2014, AM PHILOS QUART, V51, P51; Hacking, 1999, SOCIAL CONSTRUCTION, DOI DOI 10.2307/J.CTV1BZFP1Z; Himmelreich J., 2022, Philosophy Technology, DOI [10.1007/s13347-022-00542-2, DOI 10.1007/S13347-022-00542-2]; IEEE, 2019, Ethically aligned design: a vision for prioritizing human well-being with autonomous and intelligent systems; Kahneman D, 2015, FORTUNE, V172, P20; Kenton Z, 2021, Arxiv, DOI arXiv:2103.14659; Klenk M., 2022, The philosophy of online manipulation, P15; Klenk M., 2023, Philosophy and Technology, V36, P1, DOI [10.1007/s13347-023-00678-9, DOI 10.1007/S13347-023-00678-9]; Klenk M., 2022, The philosophy of online manipulation, P108, DOI [10.4324/9781003205425-7, DOI 10.4324/9781003205425-7]; Klenk M., 2020, Ethics of digital well-being: A multidisciplinary perspective, P81, DOI DOI 10.1007/978-3-030-50585-1_4; Klenk M., 2022, The philosophy of online manipulation, P1; Klenk M., 2019, Internet Policy Review; Klenk M., 2021, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3859178; Klenk M, 2022, REV SOC ECON, V80, P85, DOI 10.1080/00346764.2021.1894350; Klenk Michael, 2021, Philos Technol, V34, P525, DOI 10.1007/s13347-020-00401-y; Knobe Joshua., 2017, The Stanford Encyclopaedia of Philosophy; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Lupianez-Villanueva F., 2022, BEHAV STUDY UNFAIR C; Matz S.C., 2023, The Potential of Generative AI for Personalized Persuasion at Scale, DOI [10.31234/osf.io/rn97c, DOI 10.31234/OSF.IO/RN97C]; MILLS C, 1995, SOCIAL THEORY PRACTI, V21, P97, DOI DOI 10.5840/soctheorpract199521120; NOGGLE R, 1996, AM PHILOS QUART, V33, P43; Noggle R., 2018, Stanford encyclopedia of philosophy: Summer 2018, V2018; Noggle R., 2022, The Stanford Encyclopedia of Philosophy; Noggle R, 2020, AM PHILOS QUART, V57, P241, DOI 10.2307/48574436; Nyholm S., 2022, The philosophy of online manipulation; Osman M, 2023, PSYCHOL CONSCIOUS, DOI 10.1037/cns0000379; Osman M, 2022, PSYCHOL CONSCIOUS, DOI 10.1037/cns0000343; Osman M, 2021, PSYCHOL CONSCIOUS, DOI 10.1037/cns0000308; Osman M, 2020, CONSCIOUS COGN, V77, DOI 10.1016/j.concog.2019.102860; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pepp J., 2022, The philosophy of online manipulation, P91, DOI DOI 10.4324/9781003205425-6; Pham A., 2022, The philosophy of online manipulation; Sunstein CR, 2016, CAMB STUD ECON CHOIC, P1, DOI 10.1017/CBO9781316493021; Susser D., 2019, Georgetown Law Technol. Rev, V1, P1, DOI DOI 10.2139/SSRN.3306006; Susser D, 2019, INTERNET POLICY REV, V8, DOI 10.14763/2019.2.1410; The Economist, 2023, The Economist, P65; Tremblay MS, 2010, APPL PHYSIOL NUTR ME, V35, P725, DOI 10.1139/H10-079; van de Poel I., 2013, Philosophy and engineering: Reflections on practice, principles and process, P253; Van de Poel I., 2015, HDB ETHICS VALUES TE, P89, DOI DOI 10.1007/978-94-007-6970-0_5; van de Poel I, 2020, MIND MACH, V30, P385, DOI 10.1007/s11023-020-09537-4; Van den Hoven J., 2015, HDB ETHICS VALUES TE, DOI [10.1007/978-94-007-6970-0, DOI 10.1007/978-94-007-6970-0]; Veluwenkamp H, 2023, ETHICS INF TECHNOL, V25, DOI 10.1007/s10676-022-09675-6; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Wilkinson TM, 2013, POLIT STUD-LONDON, V61, P341, DOI 10.1111/j.1467-9248.2012.00974.x	71	0	0	77	77	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	MAR	2024	26	1							9	10.1007/s10676-024-09745-x	http://dx.doi.org/10.1007/s10676-024-09745-x			15	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	GP5T1		hybrid			2024-07-03	WOS:001153891400001
J	Acharya, A; Shrestha, S; Chen, AY; Conte, J; Avramovic, S; Sikdar, S; Anastasopoulos, A; Das, S				Acharya, Angeela; Shrestha, Sulabh; Chen, Anyi; Conte, Joseph; Avramovic, Sanja; Sikdar, Siddhartha; Anastasopoulos, Antonios; Das, Sanmay			Clinical risk prediction using language models: benefits and considerations	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						electronic health records; risk prediction; large language models; substance use disorder; opioid use disorder		Objective The use of electronic health records (EHRs) for clinical risk prediction is on the rise. However, in many practical settings, the limited availability of task-specific EHR data can restrict the application of standard machine learning pipelines. In this study, we investigate the potential of leveraging language models (LMs) as a means to incorporate supplementary domain knowledge for improving the performance of various EHR-based risk prediction tasks.Methods We propose two novel LM-based methods, namely "LLaMA2-EHR" and "Sent-e-Med." Our focus is on utilizing the textual descriptions within structured EHRs to make risk predictions about future diagnoses. We conduct a comprehensive comparison with previous approaches across various data types and sizes.Results Experiments across 6 different methods and 3 separate risk prediction tasks reveal that employing LMs to represent structured EHRs, such as diagnostic histories, results in significant performance improvements when evaluated using standard metrics such as area under the receiver operating characteristic (ROC) curve and precision-recall (PR) curve. Additionally, they offer benefits such as few-shot learning, the ability to handle previously unseen medical concepts, and adaptability to various medical vocabularies. However, it is noteworthy that outcomes may exhibit sensitivity to a specific prompt.Conclusion LMs encompass extensive embedded knowledge, making them valuable for the analysis of EHRs in the context of risk prediction. Nevertheless, it is important to exercise caution in their application, as ongoing safety concerns related to LMs persist and require continuous consideration.	[Acharya, Angeela; Shrestha, Sulabh; Avramovic, Sanja; Sikdar, Siddhartha; Anastasopoulos, Antonios; Das, Sanmay] George Mason Univ, Fairfax, VA USA; [Chen, Anyi; Conte, Joseph] Staten Isl Performing Provider Syst, Staten Isl, NY USA; [Acharya, Angeela] George Mason Univ, Dept Comp Sci, 4400 Univ Dr, Fairfax, VA 22030 USA	George Mason University; George Mason University	Acharya, A (corresponding author), George Mason Univ, Dept Comp Sci, 4400 Univ Dr, Fairfax, VA 22030 USA.	aachary@gmu.edu		Acharya, Angeela/0000-0002-3138-4129	NSF [1945764, 2327143, 1625039, 2018631]	NSF(National Science Foundation (NSF))	This research was supported in part by the NSF grants 1945764 (PI: Sikdar) and 2327143 (PI: Anastasopoulos). The GPU resources were provided by the Office of Research Computing (https://orc.gmu.edu) at George Mason University and funded in part by NSF grants 1625039 and 2018631.	Acharya A., 2022, 2022 IEEE INT C BIG, P685, DOI [10.1109/BigData55660.2022.10021001, DOI 10.1109/BIGDATA55660.2022.10021001]; Acharya A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269509; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen S, 2023, ARXIV; Choi E, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P787, DOI 10.1145/3097983.3098126; Chowdhery A, 2023, J MACH LEARN RES, V24; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gaudet-Blavignac C, 2021, J MED INTERNET RES, V23, DOI 10.2196/24594; Goldstein BA, 2017, J AM MED INFORM ASSN, V24, P198, DOI 10.1093/jamia/ocw042; Hirsch JA, 2016, AM J NEURORADIOL, V37, P596, DOI 10.3174/ajnr.A4696; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Johnson AEW, 2023, SCI DATA, V10, DOI 10.1038/s41597-022-01899-x; Kashyap A, 2023, INT J MED INFORM, V171, DOI 10.1016/j.ijmedinf.2022.104979; Kaushik P., 2021, CoRR, abs/2102.11343; Li Y., 2022, CoRR; Li YK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62922-y; Luo FJ, 2021, MMWR-MORBID MORTAL W, V70, P541, DOI 10.15585/mmwr.mm7015a1; McKenna N., 2023, Findings of the Association for Computational Linguistics: EMNLP 2023, P2758, DOI DOI 10.18653/V1/2023.FINDINGS-EMNLP; McLellan A Thomas, 2017, Trans Am Clin Climatol Assoc, V128, P112; Naveed H., 2023, ARXIV; Pang Chao, 2021, Machine Learning for Health, P239; Pendergrass SA., 2018, Curr Protoc Hum Genet, V100, pe80; Peng Baolin, 2023, ARXIV; Prakash PKS, 2021, AAAI CONF ARTIF INTE, V35, P453; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Shang J., 2019, CoRR; Shickel B., 2017, CoRR, abs/1706.03446; Shrestha Sulabh, 2024, 2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), P625, DOI 10.1109/WACVW60836.2024.00072; Touvron H., 2023, arXiv; Walonoski J, 2018, J AM MED INFORM ASSN, V25, P230, DOI 10.1093/jamia/ocx079; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	32	0	0	8	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 FEB 27	2024										10.1093/jamia/ocae030	http://dx.doi.org/10.1093/jamia/ocae030		FEB 2024	9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	JN3J4	38412328	Green Submitted			2024-07-03	WOS:001173805600001
J	Padovan, M; Cosci, B; Petillo, A; Nerli, G; Porciatti, F; Scarinci, S; Carlucci, F; Dell'Amico, L; Meliani, N; Necciari, G; Lucisano, VC; Marino, R; Foddis, R; Palla, A				Padovan, Martina; Cosci, Bianca; Petillo, Armando; Nerli, Gianluca; Porciatti, Francesco; Scarinci, Sergio; Carlucci, Francesco; Dell'Amico, Letizia; Meliani, Niccolo; Necciari, Gabriele; Lucisano, Vincenzo Carmelo; Marino, Riccardo; Foddis, Rudy; Palla, Alessandro			ChatGPT in Occupational Medicine: A Comparative Study with Human Experts	BIOENGINEERING-BASEL			English	Article						artificial intelligence; ChatGPT; occupational health and safety; health promotion; digital health; large language model		The objective of this study is to evaluate ChatGPT's accuracy and reliability in answering complex medical questions related to occupational health and explore the implications and limitations of AI in occupational health medicine. The study also provides recommendations for future research in this area and informs decision-makers about AI's impact on healthcare. A group of physicians was enlisted to create a dataset of questions and answers on Italian occupational medicine legislation. The physicians were divided into two teams, and each team member was assigned a different subject area. ChatGPT was used to generate answers for each question, with/without legislative context. The two teams then evaluated human and AI-generated answers blind, with each group reviewing the other group's work. Occupational physicians outperformed ChatGPT in generating accurate questions on a 5-point Likert score, while the answers provided by ChatGPT with access to legislative texts were comparable to those of professional doctors. Still, we found that users tend to prefer answers generated by humans, indicating that while ChatGPT is useful, users still value the opinions of occupational medicine professionals.	[Padovan, Martina; Cosci, Bianca; Petillo, Armando; Nerli, Gianluca; Porciatti, Francesco; Scarinci, Sergio; Carlucci, Francesco; Dell'Amico, Letizia; Meliani, Niccolo; Necciari, Gabriele; Lucisano, Vincenzo Carmelo; Marino, Riccardo; Foddis, Rudy] Univ Pisa, Dept Translat Res & New Technol Med & Surg, I-56126 Pisa, Italy; [Palla, Alessandro] Intel Corp, Santa Clara, CA 95054 USA	University of Pisa; Intel Corporation	Foddis, R (corresponding author), Univ Pisa, Dept Translat Res & New Technol Med & Surg, I-56126 Pisa, Italy.	padovan.martina@gmail.com; coscibianca@gmail.com; armando.petillo@virgilio.it; g.nerli@studenti.unipi.it; f.porciatti@studenti.unipi.it; scasers@gmail.com; f.carlucci@studenti.unipi.it; letizia.dellamico@gmail.com; n.meliani1@studenti.unipi.it; gabriele.necciari@gmail.com; riccardo.marino@med.unipi.it; rudy.foddis@unipi.it; alessandro.palla@intel.com		PADOVAN, MARTINA/0000-0001-8461-1527				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amato FDF, Gianfranco Decreto Legislativo 81/08: Test Unico Sulla Salute e Sicurezza Sul Lavoro; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Aung YYM, 2021, BRIT MED BULL, V139, P4, DOI 10.1093/bmb/ldab016; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen DJ, 2022, INT J BIOL SCI, V18, P360, DOI 10.7150/ijbs.66913; Chintagunta B, 2021, P 6 MACHINE LEARNING, P354; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Fogel AL, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0012-2; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Jones E, 2023, Arxiv, DOI arXiv:2310.06827; Joshi A, 2020, Arxiv, DOI arXiv:2009.08666; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Maliha G, 2021, MILBANK Q, V99, P629, DOI 10.1111/1468-0009.12504; Moassefi M, 2023, SEMIN ROENTGENOL, V58, P170, DOI 10.1053/j.ro.2023.01.005; Nananukul N, 2024, Arxiv, DOI [arXiv:2310.06174, 10.48550/arXiv.2310.06174, DOI 10.48550/ARXIV.2310.06174]; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Raghunath S, 2021, CIRCULATION, V143, P1287, DOI 10.1161/CIRCULATIONAHA.120.047829; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Rebuffel C, 2022, DATA MIN KNOWL DISC, V36, P318, DOI 10.1007/s10618-021-00801-4; Sivasubramanian J, 2023, INDIAN J MED MICROBI, V45, DOI 10.1016/j.ijmmb.2023.100380; Sridi C, 2023, ANN OCCUP ENVIRON ME, V35, DOI 10.35371/aoem.2023.35.e42; Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852; Taori Rohan, 2023, Stanford Center for Research on Foundation Models, V3, P7; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Wang JY, 2023, Arxiv, DOI arXiv:2308.15126; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Zhu YT, 2024, Arxiv, DOI arXiv:2308.07107	46	3	3	15	15	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2306-5354		BIOENGINEERING-BASEL	Bioengineering-Basel	JAN	2024	11	1							57	10.3390/bioengineering11010057	http://dx.doi.org/10.3390/bioengineering11010057			16	Biotechnology & Applied Microbiology; Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Engineering	FY7D4	38247934	gold, Green Submitted, Green Published			2024-07-03	WOS:001149470600001
C	Clavié, B; Soulié, G; Naylor, F; Brightwell, T		Lukowicz, P; Mayer, S; Koch, J; Shawe-Taylor, J; Tiddi, I		Clavie, Benjamin; Soulie, Guillaume; Naylor, Frederick; Brightwell, Thomas			Towards Simple Hybrid Language Model Reasoning Through Human Explanations Enhanced Prompts	HHAI 2023: AUGMENTING HUMAN INTELLECT	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	2nd International Conference on Hybrid Human-Artificial Intelligence (HHAI)	JUN 26-30, 2023	Munich, GERMANY	Munich Ctr Machine Learning, German Entrepreneurship, AI Journal, MDPI, Multimodal Technologies & Interact		Large Language Models; Text Classification; Prompt Engineering; Human-feedback Enhanced Prompts; Human-in-the-Loop		Large Pre-Trained Models (LLMs) have reached state-of-the-art performance in various Ntural Language Processing (NLP) application tasks. However, an issue remains these models may confidently output incorrect answers, flawed reasoning, or even entirely hallucinate answers. Truly integrating human feedback and corrections is difficult for LLMs, as the traditional approach of fine-tuning is challenging and compute-intensive for LLMs, and the weights for the best models are often not publicly available. However, the ability to interact with these models in natural language opens up new possibilities for Hybrid AI. In this work, we present a very early exploration of Human-Explanations-Enhanced Prompting (HEEP), an approach that aims to help LLMs learn from human annotators' input by storing corrected reasonings and retrieving them on the fly to integrate them into prompts given to the model. Our preliminary results support the idea that HEEP could represent an initial step towards cheap alternatives to fine-tuning and developing human-in-the-loop classification methods at scale, encouraging more efficient interactions between human annotators and LLMs.	[Clavie, Benjamin; Soulie, Guillaume; Naylor, Frederick; Brightwell, Thomas] Bright Network, Edinburgh, Midlothian, Scotland		Clavié, B (corresponding author), Bright Network, Edinburgh, Midlothian, Scotland.							Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Clavie B., 2023, P 28 C NATURAL LANGU; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kojima Takeshi, ADV NEURAL INFORM PR; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Wang L, 2024, Arxiv, DOI arXiv:2212.03533	8	0	0	4	4	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-394-2; 978-1-64368-395-9	FRONT ARTIF INTEL AP			2023	368						379	381		10.3233/FAIA230103	http://dx.doi.org/10.3233/FAIA230103			3	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KF		hybrid			2024-07-03	WOS:001150361600032
J	Yu, SD; Meng, JJ; Fan, WQ; Chen, Y; Zhu, B; Yu, H; Xie, YQ; Sun, Q				Yu, Shaode; Meng, Jiajian; Fan, Wenqing; Chen, Ye; Zhu, Bing; Yu, Hang; Xie, Yaoqin; Sun, Qiuirui			Speech Emotion Recognition Using Dual-Stream Representation and Cross-Attention Fusion	ELECTRONICS			English	Article						speech emotion recognition; dual-stream representation; cross-attention fusion; large language model; text processing network	CONVOLUTIONAL NEURAL-NETWORKS	Speech emotion recognition (SER) aims to recognize human emotions through in-depth analysis of audio signals. However, it remains challenging to encode emotional cues and to fuse the encoded cues effectively. In this study, dual-stream representation is developed, and both full training and fine-tuning of different deep networks are employed for encoding emotion patterns. Specifically, a cross-attention fusion (CAF) module is designed to integrate the dual-stream output for emotion recognition. Using different dual-stream encoders (fully training a text processing network and fine-tuning a pre-trained large language network), the CAF module is compared to other three fusion modules on three databases. The SER performance is quantified with weighted accuracy (WA), unweighted accuracy (UA), and F1-score (F1S). The experimental results suggest that the CAF outperforms the other three modules and leads to promising performance on the databases (EmoDB: WA, 97.20%; UA, 97.21%; F1S, 0.8804; IEMOCAP: WA, 69.65%; UA, 70.88%; F1S, 0.7084; RAVDESS: WA, 81.86%; UA, 82.75.21%; F1S, 0.8284). It is also found that fine-tuning a pre-trained large language network achieves superior representation than fully training a text processing network. In a future study, improved SER performance could be achieved through the development of a multi-stream representation of emotional cues and the incorporation of a multi-branch fusion mechanism for emotion recognition.	[Yu, Shaode; Meng, Jiajian; Fan, Wenqing; Chen, Ye; Zhu, Bing] Commun Univ China, Sch Informat & Commun Engn, Beijing 100024, Peoples R China; [Yu, Hang] Xidian Univ, Sch Aerosp Sci & Technol, Xian 710126, Peoples R China; [Xie, Yaoqin] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China; [Sun, Qiuirui] Beijing Normal Univ, Ctr Informat & Network Technol, Beijing 100875, Peoples R China	Communication University of China; Xidian University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Beijing Normal University	Sun, Q (corresponding author), Beijing Normal Univ, Ctr Informat & Network Technol, Beijing 100875, Peoples R China.	yushaodemia@163.com; mengjiajian@cuc.edu.cn; fanwenqing@cuc.edu.cn; 2020211023044@cuc.edu.cn; zhubing1218@163.com; yuhang9551@163.com; yq.xie@siat.ac.cn; qiuruisun@bnu.edu.cn		XIE, Yaoqin/0000-0002-1412-2354	National Key Research and Develop Program of China	National Key Research and Develop Program of China	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Atmaja BT, 2022, SPEECH COMMUN, V140, P11, DOI 10.1016/j.specom.2022.03.002; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Baevski A, 2022, PR MACH LEARN RES; Burkhardt F., 2005, INTERSPEECH 2005 9 E, VVolume 5, P1517; Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6; Cao Q, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6334, DOI 10.1109/ICASSP39728.2021.9414540; Chen L.W., 2023, P IEEE INT C AC SPEE, P1; Chen M, 2020, INTERSPEECH, P374, DOI 10.21437/Interspeech.2020-3156; Chen WD, 2023, IEEE-ACM T AUDIO SPE, V31, P775, DOI 10.1109/TASLP.2023.3235194; de Lope J, 2023, NEUROCOMPUTING, V528, P1, DOI 10.1016/j.neucom.2023.01.002; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eyben F., 2010, P 18 ACM INT C MULT, P1459; Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417; Feng T., 2024, P IEEE INT C AC SPEE, P12116; Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025; Guizzo E, 2020, INT CONF ACOUST SPEE, P6489, DOI [10.1109/ICASSP40776.2020.9053727, 10.1109/icassp40776.2020.9053727]; Habimana O, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-018-9941-6; Hashem A, 2023, SPEECH COMMUN, V154, DOI 10.1016/j.specom.2023.102974; Hou MX, 2022, IEEE-ACM T AUDIO SPE, V30, P218, DOI 10.1109/TASLP.2021.3133196; Houssein EH, 2022, NEURAL COMPUT APPL, V34, P12527, DOI 10.1007/s00521-022-07292-4; Hsu WN, 2021, IEEE-ACM T AUDIO SPE, V29, P3451, DOI 10.1109/TASLP.2021.3122291; Hu Y, 2023, IEEE INT CON MULTI, P1715, DOI 10.1109/ICME55011.2023.00295; Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894; Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052; Kaisiyuan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P700, DOI 10.1007/978-3-030-58589-1_42; Khan M, 2024, EXPERT SYST APPL, V245, DOI 10.1016/j.eswa.2023.122946; Kheddar H, 2024, INFORM FUSION, V109, DOI 10.1016/j.inffus.2024.102422; Kim E, 2019, INT CONF ACOUST SPEE, P6720, DOI 10.1109/ICASSP.2019.8683077; Lai SW, 2015, AAAI CONF ARTIF INTE, P2267; Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827; Liu F., 2023, IEEE Trans. Affect. Comput, P1, DOI [10.1109/TAFFC.2023.3334520, DOI 10.1109/TAFFC.2023.3334520]; Liu K, 2022, IEEE SIGNAL PROC LET, V29, P2278, DOI 10.1109/LSP.2022.3219352; Liu MY, 2024, SPEECH COMMUN, V156, DOI 10.1016/j.specom.2023.103010; Liu W, 2022, IEEE T COGN DEV SYST, V14, P715, DOI 10.1109/TCDS.2021.3071170; Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391; López-Gil JM, 2024, EXPERT SYST APPL, V243, DOI 10.1016/j.eswa.2023.122905; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lu ZY, 2020, INT CONF ACOUST SPEE, P7149, DOI [10.1109/ICASSP40776.2020.9052937, 10.1109/icassp40776.2020.9052937]; Ma Z., 2024, P IEEE INT C AC SPEE, P11146; Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009; Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552; Muppidi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6309, DOI 10.1109/ICASSP39728.2021.9414248; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Parry J, 2019, INTERSPEECH, P1656, DOI 10.21437/Interspeech.2019-2753; Pepino L, 2021, Arxiv, DOI arXiv:2104.03502; Perez E, 2018, AAAI CONF ARTIF INTE, P3942; Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471; Schneider S., 2019, arXiv; Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340; Sha M, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13030588; Soltani R, 2024, ENG APPL ARTIF INTEL, V133, DOI 10.1016/j.engappai.2024.108293; Sun CJ, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13061103; Tan L, 2022, IEEE T INTELL TRANSP, V23, P2830, DOI 10.1109/TITS.2021.3119921; Tan Y, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103029; Tang YW, 2022, SPEECH COMMUN, V143, P21, DOI 10.1016/j.specom.2022.07.004; Tellai Mohammed, 2023, International Journal of Speech Technology, P541, DOI 10.1007/s10772-023-10035-y; Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788; Tuncer T, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106547; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2022, INFORM FUSION, V83, P19, DOI 10.1016/j.inffus.2022.03.009; Wu HW, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13061151; Xia YY, 2021, INTERSPEECH, P3370, DOI 10.21437/Interspeech.2021-1840; Yang SW, 2021, Arxiv, DOI arXiv:2105.01051; Ye J., 2023, P IEEE INT C AC SPEE, P1; Yi L, 2022, IEEE T NEUR NET LEAR, V33, P172, DOI 10.1109/TNNLS.2020.3027600; Zhang J., 2021, P IEEE INT C MULT EX, P1; Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843; Zhang T, 2024, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-17944-9; Zhang TZ, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14072817; Zhang XW, 2024, BIOMED SIGNAL PROCES, V93, DOI 10.1016/j.bspc.2024.106140; Zhang ZC, 2020, BIOINFORMATICS, V36, P4968, DOI 10.1093/bioinformatics/btaa621; Zhu Bing, 2023, 2023 8th International Conference on Signal and Image Processing (ICSIP), P49, DOI 10.1109/ICSIP57908.2023.10270843; Zou HQ, 2022, INT CONF ACOUST SPEE, P7367, DOI 10.1109/ICASSP43922.2022.9747095	74	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2191	10.3390/electronics13112191	http://dx.doi.org/10.3390/electronics13112191			18	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UF7I1		gold			2024-07-03	WOS:001246705900001
J	Watanabe, Y; Ogawa, N; Maeda, K; Ogawa, T; Haseyama, M				Watanabe, Yuto; Ogawa, Naoki; Maeda, Keisuke; Ogawa, Takahiro; Haseyama, Miki			Automatic Findings Generation for Distress Images Using In-Context Few-Shot Learning of Visual Language Model Based on Image Similarity and Text Diversity	JOURNAL OF ROBOTICS AND MECHATRONICS			English	Article						automatic findings generation; infrastruc- ture maintenance; large language model; visual language model; in-context few-shot learning		This study proposes an automatic findings generation method that performs in-context few-shot learning of a visual language model. The automatic generation of findings can reduce the burden of creating inspection records for infrastructure facilities. However, the findings must include the opinions and judgments of engineers, in addition to what is recognized from the image; therefore, the direct generation of findings is still challenging. With this background, we introduce incontext few-short learning that focuses on image similarity and text diversity in the visual language model, which enables text output with a highly accurate understanding of both vision and language. Based on a novel in-context few-shot learning strategy, the proposed method comprehensively considers the characteristics of the distress image and diverse findings and can achieve high accuracy in generating findings. In the experiments, the proposed method outperformed the comparative methods in generating findings for distress images captured during bridge inspections.	[Watanabe, Yuto; Ogawa, Naoki] Hokkaido Univ, Grad Sch Informat Sci & Technol, Kita 14 Nishi 9,Kita-ku, Sapporo 0600814, Japan; [Maeda, Keisuke; Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Fac Informat Sci & Technol, Kita 14 Nishi 9,Kita-ku, Sapporo 0600814, Japan	Hokkaido University; Hokkaido University	Watanabe, Y (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Kita 14 Nishi 9,Kita-ku, Sapporo 0600814, Japan.	y_watanabe@lmd.ist.hokudai.ac.jp; naoki@lmd.ist.hokudai.ac.jp; maeda@lmd.ist.hokudai.ac.jp; ogawa@lmd.ist.hokudai.ac.jp; mhaseyama@lmd.ist.hokudai.ac.jp		Maeda, Keisuke/0000-0001-8039-3462	JSPS KAKENHI [JP21H03456, JP23K11211]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	Acknowledgments This work was partly supported by JSPS KAKENHI Grant Num- bers JP21H03456 and JP23K11211.	Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chun PJ, 2022, COMPUT-AIDED CIV INF, V37, P1387, DOI 10.1111/mice.12793; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Guu K, 2020, PR MACH LEARN RES, V119; Kasano H., 2010, J. of Japan Society of Civil Engineers A, V66, P312, DOI [10.2208/jsceja.66.312, DOI 10.2208/JSCEJA.66.312]; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li B, 2023, Arxiv, DOI arXiv:2306.05425; Li B, 2023, Arxiv, DOI arXiv:2305.03726; Li JN, 2022, PR MACH LEARN RES; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Maeda K, 2018, IEEE J-STSP, V12, P633, DOI 10.1109/JSTSP.2018.2849593; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Ogawa N, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010382; Radford A, 2021, PR MACH LEARN RES, V139; Shaghlil N, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: INFRASTRUCTURE AND FACILITY MANAGEMENT, P486; Tai M., 2015, J. of Structural Engineering A, V61A, P416, DOI [10.11532/structcivil.61A.416, DOI 10.11532/STRUCTCIVIL.61A.416]; Varghese A, 2017, IEEE IJCNN, P1681, DOI 10.1109/IJCNN.2017.7966053; Vaswani A, 2017, ADV NEUR IN, V30; Watanabe Y., 2023, Artificial Intelligence and Data Science, V4, P223, DOI [10.11532/jsceiii.4.3_223, DOI 10.11532/JSCEIII.4.3_223]; Yamane T., 2023, arXiv; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]	25	0	0	0	0	FUJI TECHNOLOGY PRESS LTD	TOKYO	1-15-7, UCHIKANDA, CHIYODA-KU, UNIZO UCHIKANDA 1-CHOME BLDG 2F, TOKYO, 101-0047, JAPAN	0915-3942	1883-8049		J ROBOT MECHATRON	J. Robot. Mechatron.	APR	2024	36	2			SI		353	364		10.20965/jrm.2024.p0353	http://dx.doi.org/10.20965/jrm.2024.p0353			12	Robotics	Emerging Sources Citation Index (ESCI)	Robotics	OR7B4		gold			2024-07-03	WOS:001209055800020
J	Lawrence, KW; Habibi, AA; Ward, SA; Lajam, CM; Schwarzkopf, R; Rozell, JC				Lawrence, Kyle W.; Habibi, Akram A.; Ward, Spencer A.; Lajam, Claudette M.; Schwarzkopf, Ran; Rozell, Joshua C.			Human versus artificial intelligence-generated arthroplasty literature: A single-blinded analysis of perceived communication, quality, and authorship source	INTERNATIONAL JOURNAL OF MEDICAL ROBOTICS AND COMPUTER ASSISTED SURGERY			English	Article						artificial intelligence; ChatGPT; large language models; medical literature; total hip arthroplasty; total knee arthroplasty		BackgroundLarge language models (LLM) have unknown implications for medical research. This study assessed whether LLM-generated abstracts are distinguishable from human-written abstracts and to compare their perceived quality.MethodsThe LLM ChatGPT was used to generate 20 arthroplasty abstracts (AI-generated) based on full-text manuscripts, which were compared to originally published abstracts (human-written). Six blinded orthopaedic surgeons rated abstracts on overall quality, communication, and confidence in the authorship source. Authorship-confidence scores were compared to a test value representing complete inability to discern authorship.ResultsModestly increased confidence in human authorship was observed for human-written abstracts compared with AI-generated abstracts (p = 0.028), though AI-generated abstract authorship-confidence scores were statistically consistent with inability to discern authorship (p = 0.999). Overall abstract quality was higher for human-written abstracts (p = 0.019).ConclusionsAI-generated abstracts' absolute authorship-confidence ratings demonstrated difficulty in discerning authorship but did not achieve the perceived quality of human-written abstracts. Caution is warranted in implementing LLMs into scientific writing.	[Lawrence, Kyle W.; Habibi, Akram A.; Ward, Spencer A.; Lajam, Claudette M.; Schwarzkopf, Ran; Rozell, Joshua C.] NYU Langone Hlth, Dept Orthoped Surg, New York, NY USA; [Lawrence, Kyle W.] NYU Langone Hlth, Dept Orthoped Surg, 301 East 17th St,15th Floor Suite 1518, New York, NY 10003 USA	NYU Langone Medical Center; NYU Langone Medical Center	Lawrence, KW (corresponding author), NYU Langone Hlth, Dept Orthoped Surg, 301 East 17th St,15th Floor Suite 1518, New York, NY 10003 USA.	kyle.lawrence8@gmail.com		Habibi, Akram/0000-0002-3776-1888; Lawrence, Kyle/0000-0002-3356-3227				Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; [Anonymous], 2023, ChatGPT General FAQ; Bi AS., What's Important: The Next Academic-ChatGPT AI? JBJS; Brameier Devon T, 2023, J Bone Joint Surg Am, V105, P1388, DOI 10.2106/JBJS.23.00473; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Hammad M, 2023, ANN BIOMED ENG, V51, P459, DOI 10.1007/s10439-023-03140-1; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Matsuo Y, 2022, NEURAL NETWORKS, V152, P267, DOI 10.1016/j.neunet.2022.03.037; Medenilla A., 2023, PLoS Digital Health, V2; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Portney L. G., 2000, FDN CLIN RES APPL PR, V2nd; Ramkumar PN, 2023, ARTHROSCOPY, V39, P787, DOI 10.1016/j.arthro.2022.07.012; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1	24	1	1	13	13	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1478-5951	1478-596X		INT J MED ROBOT COMP	Int. J. Med. Robot. Comput. Assist. Surg.	FEB	2024	20	1							e2621	10.1002/rcs.2621	http://dx.doi.org/10.1002/rcs.2621			9	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	HO4R6	38348740				2024-07-03	WOS:001160438000001
J	Bhanot, K; Erickson, JS; Bennett, KP				Bhanot, Karan; Erickson, John S.; Bennett, Kristin P.			MortalityMinder: Visualization and AI Interpretations of Social Determinants of Premature Mortality in the United States	INFORMATION			English	Article						social determinants; mortality; deaths of despair; risk factors; public health; large language models; interactive machine learning; eDiscovery		MortalityMinder enables healthcare researchers, providers, payers, and policy makers to gain actionable insights into where and why premature mortality rates due to all causes, cancer, cardiovascular disease, and deaths of despair rose between 2000 and 2017 for adults aged 25-64. MortalityMinder is designed as an open-source web-based visualization tool that enables interactive analysis and exploration of social, economic, and geographic factors associated with mortality at the county level. We provide case studies to illustrate how MortalityMinder finds interesting relationships between health determinants and deaths of despair. We also demonstrate how GPT-4 can help translate statistical results from MortalityMinder into actionable insights to improve population health. When combined with MortalityMinder results, GPT-4 provides hypotheses on why socio-economic risk factors are associated with mortality, how they might be causal, and what actions could be taken related to the risk factors to improve outcomes with supporting citations. We find that GPT-4 provided plausible and insightful answers about the relationship between social determinants and mortality. Our work is a first step towards enabling public health stakeholders to automatically discover and visualize relationships between social determinants of health and mortality based on available data and explain and transform these into meaningful results using artificial intelligence.	[Bhanot, Karan] Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; [Erickson, John S.] Rensselaer Polytech Inst, Future Comp Inst, Troy, NY 12180 USA; [Bennett, Kristin P.] Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute	Bennett, KP (corresponding author), Rensselaer Polytech Inst, Dept Math Sci, Troy, NY 12180 USA.	bhanotkaran22@gmail.com; erickj4@rpi.edu; bennek@rpi.edu			United Health Foundation; Rensselaer Institute for Data Exploration and Applications (IDEA); Tom White, Capital District Physicians' Health Plan (CDPHP)	United Health Foundation; Rensselaer Institute for Data Exploration and Applications (IDEA); Tom White, Capital District Physicians' Health Plan (CDPHP)	MortalityMinder and COVIDMINDER was created by students in the Rensselaer Data INCITE Lab with support from the United Health Foundation and the Rensselaer Institute for Data Exploration and Applications (IDEA). We thank Resnsselaer students Lilian Ngweta, Jocelyn McConnon and Skye Jacobson for helping to draft an early version of this paper. The MortalityMinder Team would like to thank our advisory board, including Anne Yau, United Health Foundation; Dan Fabius, Continuum Health; Melissa Kamal, New York State Department of Health; and Tom White, Capital District Physicians' Health Plan (CDPHP). We would also like to thank the communication and design professionals at Rensselaer Polytechnic Institute, who helped with design.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; AHRQ, 2020, Announcing the Winners of AHRQs Visualization of Community-Level Social Determinants of Health Challenge; [Anonymous], Alvaro fullPage; [Anonymous], ChatBS: A Context-Aware LLM Exploratory Sandbox (App); [Anonymous], RinteRface fullPage; [Anonymous], 2020, IDEA MortalityMinder; Case A, 2015, P NATL ACAD SCI USA, V112, P15078, DOI 10.1073/pnas.1518393112; Centers for Disease Control and Prevention, 2020, CDC Behavioral Risk Factor Surveillance System; Chang W, 2022, shiny: Web Application Framework for R; ChatBS, A Context-Aware LLM Exploratory Sandbox; Chen M., 2021, arXiv; Cohn M., 2020, Accounting Today; COVIDMINDER (APPLICATION), Revealing the Regional Disparities in Outcomes, Determinants, and Mediations of the COVID-19 Pandemic; COVIDMINDER (WEBSITE), Revealing the Regional Disparities in Outcomes, Determinants, and Mediations of the COVID-19 Pandemic; Debopadhaya S., 2020, medRxiv, DOI [10.1101/2020.08.28.20183848, DOI 10.1101/2020.08.28.20183848]; Debopadhaya S., 2021, medRxiv, DOI [10.1101/2021.06.22.21258971, DOI 10.1101/2021.06.22.21258971]; FRIEDE A, 1993, AM J PUBLIC HEALTH, V83, P1289, DOI 10.2105/AJPH.83.9.1289; Haynes W., 2013, Encyclopedia of Systems Biology, P78, DOI DOI 10.1007/978-1-4419-9863-7_1215; Honaker J, 2011, J STAT SOFTW, V45, P1; Hood CM, 2016, AM J PREV MED, V50, P129, DOI 10.1016/j.amepre.2015.08.024; Kino S, 2021, SSM-POPUL HLTH, V15, DOI 10.1016/j.ssmph.2021.100836; Kristof N., 2020, The New York Times9 January; Lippold K, 2020, DRUG ALCOHOL DEPEN, V212, DOI 10.1016/j.drugalcdep.2020.108059; McNeill E, 2023, J AM HEART ASSOC, V12, DOI 10.1161/JAHA.123.030571; Ong JCL, 2024, CELL REP MED, V5, DOI 10.1016/j.xcrm.2023.101356; Ratnayake I, 2024, INT J SOC DETER HLTH, V54, P21, DOI 10.1177/27551938231201011; Remington T.F., 2023, COVID-19 Pandemic: Problems Arising in Health and Social Policy, P57; Shiels MS, 2022, JAMA INTERN MED, V182, P883, DOI 10.1001/jamainternmed.2022.2476; Stein EM, 2017, AM J PUBLIC HEALTH, V107, P1541, DOI [10.2105/AJPH.2017.303941, 10.2105/ajph.2017.303941]; U.S. Bureau of Labor Statistics, 2020, U.S. Bureau of Labor Statistics Web Site; U.S. Federal Bureau of Investigation, 2020, National Archive of Criminal Justice Data Uniform Crime Reporting Program Data Series; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Winnegar A., 2020, Santa Fe New Mexican; Yancy CW, 2020, JAMA-J AM MED ASSOC, V323, P1891, DOI 10.1001/jama.2020.6548	34	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	MAY	2024	15	5							254	10.3390/info15050254	http://dx.doi.org/10.3390/info15050254			17	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	SK2N5		gold			2024-07-03	WOS:001234282800001
J	Tortora, L				Tortora, Leda			Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry	FRONTIERS IN PSYCHIATRY			English	Review						forensic psychiatry; forensic AI; generative AI; generative artificial intelligence; discriminative AI; ethical AI; large language models; large generative AI models	ARTIFICIAL-INTELLIGENCE; RISK-ASSESSMENT; DISORDERS; BIAS	The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.	[Tortora, Leda] Trinity Coll Dublin, Sch Nursing & Midwifery, Dublin, Ireland	Trinity College Dublin	Tortora, L (corresponding author), Trinity Coll Dublin, Sch Nursing & Midwifery, Dublin, Ireland.	ltortora@tcd.ie			European Commission the European Union [861047]	European Commission the European Union	The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article. LT is funded by the European Commission the European Union's Horizon 2020 research and innovation programme under the Marie Sk & lstrok;odowska-Curie grant agreement No. 861047.	Acres T., 2023, Lawyers used ChatGPT to help with a case-it backfired massively; Ahmed N, 2023, SCIENCE, V379, P884, DOI 10.1126/science.ade2420; Ahn J, 2021, Arxiv, DOI arXiv:2109.05704; Alikhademi K, 2022, ARTIF INTELL LAW, V30, P1, DOI 10.1007/s10506-021-09286-4; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Assari S, 2018, J RACIAL ETHN HEALTH, V5, P243, DOI 10.1007/s40615-017-0364-y; Bao C, 2023, PROC CVPR IEEE, P20919, DOI 10.1109/CVPR52729.2023.02004; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berk R, 2021, SOCIOL METHOD RES, V50, P3, DOI 10.1177/0049124118782533; Bianchi F, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1493, DOI 10.1145/3593013.3594095; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bordukova M, 2024, EXPERT OPIN DRUG DIS, V19, P33, DOI 10.1080/17460441.2023.2273839; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai L., 2019, P 2019 SIAM INT C DA, P630; Ceccarelli F, 2022, PATTERN ANAL APPL, V25, P493, DOI 10.1007/s10044-021-01001-y; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chekroud AM, 2021, WORLD PSYCHIATRY, V20, P154, DOI 10.1002/wps.20882; Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J; Constantinou AC, 2015, DECIS SUPPORT SYST, V80, P42, DOI 10.1016/j.dss.2015.09.006; Corona-Figueroa Abril, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P3843, DOI 10.1109/EMBC48229.2022.9871757; Cowls J, 2023, AI SOC, V38, P283, DOI 10.1007/s00146-021-01294-x; Delfino RA, 2023, HASTINGS LAW J, V74, P293; Denton, 2020, ARXIV; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dimitri GM, 2022, INFORM FUSION, V88, P146, DOI 10.1016/j.inffus.2022.07.017; Dubey SR, 2023, Arxiv, DOI [arXiv:2302.08641, DOI 10.48550/ARXIV.2302.08641]; Duwe G., 2017, Criminal Justice Policy Review, V28, P570, DOI [DOI 10.1177/0887403415604899, 10.1177/0887403415604899]; EagleAI, 2022, Forensic sketch AIrtist; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00140-5; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Farah Hibaq, 2023, THE GUARDIAN; Gao KY, 2023, Arxiv, DOI arXiv:2210.00379; George Amy, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P229; Ghasemi M, 2021, CRIM JUSTICE BEHAV, V48, P518, DOI 10.1177/0093854820969753; Gipson Rankin S., 2020, WASH LEE LAW REV, DOI [10.2139/ssrn.3662761, DOI 10.2139/SSRN.3662761]; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gou NZ, 2021, PSYCHIAT RES, V306, DOI 10.1016/j.psychres.2021.114294; Gozalo-Brizuela R., 2023, arXiv; Grossman MR., 2023, Duke Law Technol Rev, V23; Gundersen T, 2022, AM J BIOETHICS, V22, P26, DOI 10.1080/15265161.2022.2075053; Guo R, 2020, Arxiv, DOI [arXiv:2010.06230, DOI 10.48550/ARXIV.2010.06230]; Gutierrez JD., 2023, ChatGPT in Colombian Courts: Why we need to have a conversation about the digital literacy of the judiciary; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285; Herz J., 2023, New York Post; Hofmann LA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020819; Hogan NR, 2021, J AM ACAD PSYCHIATRY, V49, P326, DOI 10.29158/JAAPL.200116-20; Huang J, 2022, Arxiv, DOI arXiv:2205.12628; Huang JAT, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36100; Huang RJ, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2595, DOI 10.1145/3503161.3547855; Hutchinson Ben, 2022, arXiv, DOI 10.48550/ARXIV.2210.05815; Jamal S., 2023, Pakistani judge uses ChatGPT to make court decision; Jan Smits TB., 2022, Law and Artificial Intelligence Information Technology and Law Series, P323, DOI DOI 10.1007/978-94-6265-523-2; Jigsaw K., 2019, Jigsaw unintended bias in toxicity classification; Jorm AF, 2012, AUST NZ J PSYCHIAT, V46, P1029, DOI 10.1177/0004867412442406; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Large M, 2017, WORLD PSYCHIATRY, V16, P25, DOI 10.1002/wps.20394; Li HY, 2022, NEUROCOMPUTING, V479, P47, DOI 10.1016/j.neucom.2022.01.029; Li K, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P739, DOI 10.1109/VRW58643.2023.00212; Li ZQ, 2022, Arxiv, DOI arXiv:2204.08329; Liesenfeld A, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3604316; Liu B., 2011, Encyclopedia of machine learning, DOI [10.1007/978-0-387-30164-8_332, DOI 10.1007/978-0-387-30164-8_332]; Liu R, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3219551; Luccioni A. S., 2021, arXiv; Magee L, 2021, Arxiv, DOI arXiv:2107.07691; Mandal A, 2023, Arxiv, DOI arXiv:2309.04997; Markovski Y., 2023, How Your Data is Used to Improve Model Performance; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Menger V, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.6709; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mezey G, 2016, J FORENSIC PSYCHI PS, V27, P517, DOI 10.1080/14789949.2016.1172658; Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250; Mittelstadt BD, 2016, LAW GOV TECHNOL SER, V29, P445, DOI 10.1007/978-3-319-33525-4_19; Mittelstadt BD, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716679679; Morgan J, 2023, J FORENSIC SCI, V68, P908, DOI 10.1111/1556-4029.15233; Muralidhar D, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P273, DOI 10.1145/3461702.3462469; Nazábal A, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107501; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Perry B.L., 2013, Race and Social Problems, V5, P239, DOI DOI 10.1007/S12552-013-9100-3; Pol Adrian Alan, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P1651, DOI 10.1109/ICMLA.2019.00270; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Rematas K, 2022, PROC CVPR IEEE, P12922, DOI 10.1109/CVPR52688.2022.01259; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saadatinia M, 2023, Arxiv, DOI arXiv:2310.16867; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Salewski L, 2023, Arxiv, DOI arXiv:2305.14930; Saxena D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446374; Scarpazza C, 2018, TRANSL PSYCHIAT, V8, DOI 10.1038/s41398-018-0274-8; Semeniuta S, 2017, Arxiv, DOI arXiv:1702.02390; Sheng E., 2023, In generative AI legal wild west, the courtroom battles are just getting started; Singer U, 2022, Arxiv, DOI arXiv:2209.14792; Singh A., 2020, SN Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]; Singh A, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24010055; Singh A, 2021, IEEE ACCESS, V9, P135024, DOI 10.1109/ACCESS.2021.3116205; Slapak E, 2023, Arxiv, DOI arXiv:2308.07118; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Starke G., 2023, AI Ethics, V3, P303, DOI [10.1007/s43681-022-00177-1, DOI 10.1007/S43681-022-00177-1]; Steiger S, 2022, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.819573; Strowel A, 2023, IIC-INT REV INTELL P, DOI 10.1007/s40319-023-01321-y; Suchting R, 2018, PSYCHIAT RES, V268, P217, DOI 10.1016/j.psychres.2018.07.004; Sun J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P212, DOI 10.1145/3490099.3511119; Sun LH, 2023, Arxiv, DOI arXiv:2305.10566; Sun Mingyang, 2022, 2022 14th International Conference on Signal Processing Systems (ICSPS), P818, DOI 10.1109/ICSPS58776.2022.00148; Taddeo M, 2021, ONE EARTH, V4, P776, DOI 10.1016/j.oneear.2021.05.018; Tamburrini G, 2022, PHILOSOPHIES, V7, DOI 10.3390/philosophies7010004; Thakur V, 2023, Arxiv, DOI arXiv:2307.09162; Tollenaar N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213245; Tortora L, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00220; Travaini GV, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191710594; Trinhammer ML, 2022, J PSYCHIATR RES, V152, P194, DOI 10.1016/j.jpsychires.2022.06.009; Tutun S, 2023, INFORM SYST FRONT, V25, P1261, DOI 10.1007/s10796-022-10282-5; Ungless EL, 2023, Arxiv, DOI arXiv:2305.17072; Vaswani A, 2017, ADV NEUR IN, V30; Venkit P., 2022, P 29 INT C COMP LING, P1324; Walker R, 2023, NURS OUTLOOK, V71, DOI 10.1016/j.outlook.2023.102023; Wang KZ, 2020, PSYCHIAT RES, V289, DOI 10.1016/j.psychres.2020.112960; Watts D, 2021, J PSYCHIATR RES, V138, P146, DOI 10.1016/j.jpsychires.2021.03.026; Weisz Justin D., 2023, arXiv; Wen SP, 2019, IEEE T CIRC SYST VID, V29, P2337, DOI 10.1109/TCSVT.2018.2867934; West ML, 2014, INT J FORENSIC MENT, V13, P75, DOI 10.1080/14999013.2014.885471; Xu JL, 2023, PROC CVPR IEEE, P20908, DOI 10.1109/CVPR52729.2023.02003; Yang L, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3626235; Yang Y., 2020, Advances in Neural Information Processing Systems, P573; Yu T, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.799899; Zhang P, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15090286; Zheng ZR, 2022, PROC CVPR IEEE, P15872, DOI 10.1109/CVPR52688.2022.01543; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhu ZX, 2023, IEEE INT CONF ROBOT, P8326, DOI 10.1109/ICRA48891.2023.10161570	135	0	0	47	47	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-0640			FRONT PSYCHIATRY	Front. Psychiatry	MAR 8	2024	15								1346059	10.3389/fpsyt.2024.1346059	http://dx.doi.org/10.3389/fpsyt.2024.1346059			13	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	LV1M4	38525252	gold, Green Published			2024-07-03	WOS:001189484000001
J	Kaebnick, GE; Magnus, DC; Kao, A; Hosseini, M; Resnik, D; Dubljevic, V; Rentmeester, C; Gordijn, B; Cherry, MJ; Maschke, KJ; Rasmussen, LM; Haupt, L; Schüklenk, U; Chadwick, R; Diniz, D				Kaebnick, Gregory E.; Magnus, David Christopher; Kao, Audiey; Hosseini, Mohammad; Resnik, David; Dubljevic, Veljko; Rentmeester, Christy; Gordijn, Bert; Cherry, Mark J.; Maschke, Karen J.; Rasmussen, Lisa M.; Haupt, Laura; Schuklenk, Udo; Chadwick, Ruth; Diniz, Debora			Editors' Statement on the Responsible Use of Generative AI Technologies in Scholarly Journal Publishing	HASTINGS CENTER REPORT			English	Editorial Material						generative AI; ChatGPT; large language models; transparency; accountability; community of scholars; journal publishing; bioethics; humanities		Generative artificial intelligence (AI) has the potential to transform many aspects of scholarly publishing. Authors, peer reviewers, and editors might use AI in a variety of ways, and those uses might augment their existing work or might instead be intended to replace it. We are editors of bioethics and humanities journals who have been contemplating the implications of this ongoing transformation. We believe that generative AI may pose a threat to the goals that animate our work but could also be valuable for achieving those goals. In the interests of fostering a wider conversation about how generative AI may be used, we have developed a preliminary set of recommendations for its use in scholarly publishing. We hope that the recommendations and rationales set out here will help the scholarly community navigate toward a deeper understanding of the strengths, limits, and challenges of AI for responsible scholarly work.					Hosseini, Mohammad/X-6867-2019	Hosseini, Mohammad/0000-0002-2385-985X				da Silva JAT, 2023, LEARN PUBL, V36, P453, DOI 10.1002/leap.1547; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; International Committee of Medical Journal Editors, 2023, REC COND REP ED PUBL; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; nih, 2023, US GEN ART INT TECHN; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; wame, 2023, CHATB GEN AI S UNPUB	10	5	5	18	32	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0093-0334	1552-146X		HASTINGS CENT REP	Hastings Cent. Rep.	SEP	2023	53	5					3	6		10.1002/hast.1507	http://dx.doi.org/10.1002/hast.1507		OCT 2023	4	Ethics; Health Care Sciences & Services; Medical Ethics; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Health Care Sciences & Services; Medical Ethics; Biomedical Social Sciences	AF6F4	37777997	Bronze			2024-07-03	WOS:001078413600001
J	Valencia, OAG; Thongprayoon, C; Jadlowiec, CC; Mao, SA; Leeaphorn, N; Budhiraja, P; Craici, IM; Suarez, MLG; Cheungpasitporn, W				Valencia, Oscar A. Garcia; Thongprayoon, Charat; Jadlowiec, Caroline C.; Mao, Shennen A.; Leeaphorn, Napat; Budhiraja, Pooja; Craici, Iasmina M.; Suarez, Maria L. Gonzalez; Cheungpasitporn, Wisit			AI-driven translations for kidney transplant equity in Hispanic populations	SCIENTIFIC REPORTS			English	Article						Artificial intelligence; Large language models; Health equity; Kidney transplant information; Spanish translation; Cultural sensitivity; ChatGPT	HEALTH-CARE; DISPARITIES; LANGUAGE; OUTCOMES; DISEASE	Health equity and accessing Spanish kidney transplant information continues being a substantial challenge facing the Hispanic community. This study evaluated ChatGPT's capabilities in translating 54 English kidney transplant frequently asked questions (FAQs) into Spanish using two versions of the AI model, GPT-3.5 and GPT-4.0. The FAQs included 19 from Organ Procurement and Transplantation Network (OPTN), 15 from National Health Service (NHS), and 20 from National Kidney Foundation (NKF). Two native Spanish-speaking nephrologists, both of whom are of Mexican heritage, scored the translations for linguistic accuracy and cultural sensitivity tailored to Hispanics using a 1-5 rubric. The inter-rater reliability of the evaluators, measured by Cohen's Kappa, was 0.85. Overall linguistic accuracy was 4.89 +/- 0.31 for GPT-3.5 versus 4.94 +/- 0.23 for GPT-4.0 (non-significant p = 0.23). Both versions scored 4.96 +/- 0.19 in cultural sensitivity (p = 1.00). By source, GPT-3.5 linguistic accuracy was 4.84 +/- 0.37 (OPTN), 4.93 +/- 0.26 (NHS), 4.90 +/- 0.31 (NKF). GPT-4.0 scored 4.95 +/- 0.23 (OPTN), 4.93 +/- 0.26 (NHS), 4.95 +/- 0.22 (NKF). For cultural sensitivity, GPT-3.5 scored 4.95 +/- 0.23 (OPTN), 4.93 +/- 0.26 (NHS), 5.00 +/- 0.00 (NKF), while GPT-4.0 scored 5.00 +/- 0.00 (OPTN), 5.00 +/- 0.00 (NHS), 4.90 +/- 0.31 (NKF). These high linguistic and cultural sensitivity scores demonstrate Chat GPT effectively translated the English FAQs into Spanish across systems. The findings suggest Chat GPT's potential to promote health equity by improving Spanish access to essential kidney transplant information. Additional research should evaluate its medical translation capabilities across diverse contexts/languages. These English-to-Spanish translations may increase access to vital transplant information for underserved Spanish-speaking Hispanic patients.	[Valencia, Oscar A. Garcia; Thongprayoon, Charat; Craici, Iasmina M.; Suarez, Maria L. Gonzalez; Cheungpasitporn, Wisit] Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA; [Jadlowiec, Caroline C.; Budhiraja, Pooja] Mayo Clin, Div Transplant Surg, Phoenix, AZ USA; [Mao, Shennen A.; Leeaphorn, Napat] Mayo Clin, Dept Transplantat, Div Transplant Surg, Jacksonville, FL USA; [Leeaphorn, Napat] Mayo Clin, Dept Transplant, Jacksonville, FL USA	Mayo Clinic; Mayo Clinic; Mayo Clinic Phoenix; Mayo Clinic; Mayo Clinic	Cheungpasitporn, W (corresponding author), Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA.	wcheungpasitporn@gmail.com						Al Shamsi Hilal, 2020, Oman Med J, V35, pe122, DOI 10.5001/omj.2020.40; Anderson LM, 2003, AM J PREV MED, V24, P68, DOI 10.1016/S0749-3797(02)00657-8; [Anonymous], 2011, Frequently asked questions about health care for the homeless; Barwise AK, 2024, J AM MED INFORM ASSN, V31, P611, DOI 10.1093/jamia/ocad224; Benabe JE, 2004, J NATL MED ASSOC, V96, P789; Bozza S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46390-8; Braveman P, 2006, ANNU REV PUBL HEALTH, V27, P167, DOI 10.1146/annurev.publhealth.27.021405.102103; Braveman PA, 2011, AM J PUBLIC HEALTH, V101, pS149, DOI 10.2105/AJPH.2010.300062; Breithaupt F, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-023-50229-7; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brooks LA, 2019, COLLEGIAN, V26, P383, DOI 10.1016/j.colegn.2018.09.007; Caballero AE, 2011, AM J MED, V124, pS10, DOI 10.1016/j.amjmed.2011.07.018; Choi J, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-51531-8; Costa-jussa, 2022, arXiv, DOI DOI 10.48550/ARXIV.2207.04672; Desai N, 2019, AM J KIDNEY DIS, V73, P102, DOI 10.1053/j.ajkd.2018.02.354; Diamond L, 2019, J GEN INTERN MED, V34, P1591, DOI 10.1007/s11606-019-04847-5; Fernandez A, 2011, J GEN INTERN MED, V26, P170, DOI 10.1007/s11606-010-1507-6; Futterer T, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-42227-6; Gan Rick Kye, 2023, Sci Rep, V13, P20350, DOI 10.1038/s41598-023-46986-0; Garbers Samantha, 2004, Prev Chronic Dis, V1, pA07; Gordon EJ, 2015, TRANSPLANT DIRECT, V1, DOI 10.1097/TXD.0000000000000540; Gordon EJ, 2010, SEMIN NEPHROL, V30, P81, DOI 10.1016/j.semnephrol.2009.10.009; Govere L, 2016, WORLDV EVID-BASED NU, V13, P402, DOI 10.1111/wvn.12176; Handtke O, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219971; Herbold Steffen, 2023, Sci Rep, V13, P18617, DOI 10.1038/s41598-023-45644-9; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jo H, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-49710-0; Kaushik P, 2020, PRIM CARE DIABETES, V14, P401, DOI 10.1016/j.pcd.2019.12.009; kidney, Kidney Transplant; Madrid-Garcia A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-49483-6; Manakhimova S., P 8 C MACH TRANSL, P224; Miao J, 2024, KIDNEY360, V5, P765, DOI 10.34067/KID.0000000000000430; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; Nastasi AJ, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45223-y; nhs, Kidney transplant FAQs; Odlum M, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.25134; Onder CE, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-023-50884-w; OpenAI, 2023, Introducing ChatGPT; Pande M, 2022, BMC NEPHROL, V23, DOI 10.1186/s12882-022-02879-4; Peeters MJ, 2010, AM J PHARM EDUC, V74, DOI 10.5688/aj7409171; Peralta CA, 2006, J AM SOC NEPHROL, V17, P2892, DOI 10.1681/ASN.2005101122; Pérez-Escamilla R, 2010, ANN ANTHROPL PRACT, V34, P47, DOI 10.1111/j.1556-4797.2010.01051.x; Perez-Stable EJ, 1997, MED CARE, V35, P1212, DOI 10.1097/00005650-199712000-00005; Renzaho AMN, 2013, INT J QUAL HEALTH C, V25, P261, DOI 10.1093/intqhc/mzt006; Rosol M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46995-z; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Shepherd SM, 2019, BMC HEALTH SERV RES, V19, DOI 10.1186/s12913-019-3959-7; Siu S.C., 2023, Chatgpt and GPT-4 for professional translators: Exploring the potential of large language models in translation; Stap D., P WORKSH NAT LANG PR, P163; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Timmins CL, 2002, J MIDWIFERY WOM HEAL, V47, P80, DOI 10.1016/S1526-9523(02)00218-0; Valencia OAG, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11182518; Velasco-Mondragon E, 2016, PUBLIC HEALTH REV, V37, DOI 10.1186/s40985-016-0043-2; Walters WH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41032-5	54	0	0	3	3	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 12	2024	14	1							8511	10.1038/s41598-024-59237-7	http://dx.doi.org/10.1038/s41598-024-59237-7			7	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	NQ3G3	38609476	gold, Green Published			2024-07-03	WOS:001201873900044
J	Huber, E; Sauppe, S; Isasi-Isasmendi, A; Bornkessel-Schlesewsky, I; Merlo, P; Bickel, B				Huber, Eva; Sauppe, Sebastian; Isasi-Isasmendi, Arrate; Bornkessel-Schlesewsky, Ina; Merlo, Paola; Bickel, Balthasar			Surprisal From Language Models Can Predict ERPs in Processing Predicate-Argument Structures Only if Enriched by an Agent Preference Principle	NEUROBIOLOGY OF LANGUAGE			English	Article						artificial neural networks; computational modeling; event cognition; ERP; sentence processing; surprisal; large language models (LLMs)	R PACKAGE; BRAIN; COMPREHENSION; EVENTS; ROLES; ORDER; INFORMATION; REANALYSIS; SPEAKERS; ANIMACY	Language models based on artificial neural networks increasingly capture key aspects of how humans process sentences. Most notably, model-based surprisals predict event-related potentials such as N400 amplitudes during parsing. Assuming that these models represent realistic estimates of human linguistic experience, their success in modeling language processing raises the possibility that the human processing system relies on no other principles than the general architecture of language models and on sufficient linguistic input. Here, we test this hypothesis on N400 effects observed during the processing of verb-final sentences in German, Basque, and Hindi. By stacking Bayesian generalised additive models, we show that, in each language, N400 amplitudes and topographies in the region of the verb are best predicted when model-based surprisals are complemented by an Agent Preference principle that transiently interprets initial role-ambiguous noun phrases as agents, leading to reanalysis when this interpretation fails. Our findings demonstrate the need for this principle independently of usage frequencies and structural differences between languages. The principle has an unequal force, however. Compared to surprisal, its effect is weakest in German, stronger in Hindi, and still stronger in Basque. This gradient is correlated with the extent to which grammars allow unmarked NPs to be patients, a structural feature that boosts reanalysis effects. We conclude that language models gain more neurobiological plausibility by incorporating an Agent Preference. Conversely, theories of human processing profit from incorporating surprisal estimates in addition to principles like the Agent Preference, which arguably have distinct evolutionary roots.	[Huber, Eva; Sauppe, Sebastian; Isasi-Isasmendi, Arrate; Bickel, Balthasar] Univ Zurich, Dept Comparat Language Sci, Zurich, Switzerland; [Huber, Eva; Sauppe, Sebastian; Isasi-Isasmendi, Arrate; Bickel, Balthasar] Univ Zurich, Ctr Interdisciplinary Study Language Evolut, Zurich, Switzerland; [Sauppe, Sebastian] Univ Zurich, Dept Psychol, Zurich, Switzerland; [Bornkessel-Schlesewsky, Ina] Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Cognit Neurosci Lab, Adelaide, Australia; [Merlo, Paola] Univ Geneva, Dept Linguist, Geneva, Switzerland; [Merlo, Paola] Univ Geneva, Univ Ctr Comp Sci, Geneva, Switzerland	University of Zurich; University of Zurich; University of Zurich; University of South Australia; University of Geneva; University of Geneva	Huber, E (corresponding author), Univ Zurich, Dept Comparat Language Sci, Zurich, Switzerland.; Huber, E (corresponding author), Univ Zurich, Ctr Interdisciplinary Study Language Evolut, Zurich, Switzerland.	eva.huber@uzh.ch		Bickel, Balthasar/0000-0002-9087-0565; Sauppe, Sebastian/0000-0001-8670-8197	National Center of Competence Evolving Language [51NF40_180888]; Swiss National Science Foundation [100015_182845, TMAG-1_209426/1]; Centre of Excellence in Future Low-Energy Electronics Technologies, Australian Research Council [FT160100437]; Swiss National Science Foundation (SNF) [TMAG-1_209426, 100015_182845] Funding Source: Swiss National Science Foundation (SNF)	National Center of Competence Evolving Language; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); Centre of Excellence in Future Low-Energy Electronics Technologies, Australian Research Council; Swiss National Science Foundation (SNF)(Swiss National Science Foundation (SNSF))	Balthasar Bickel, National Center of Competence Evolving Language, Award ID: No.51NF40_180888. Balthasar Bickel, Swiss National Science Foundation Grant, Award ID:100015_182845. Paola Merlo, Swiss National Science Foundation Grant, Award ID:TMAG-1_209426/1. Ina Bornkessel-Schlesewsky, Centre of Excellence in Future Low-Energy Electronics Technologies, Australian Research Council (https://dx.doi.org/10.13039/501100019891), Award ID: FT160100437.	Agerri R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4781; [Anonymous], 2013, Proceedings of the 51st annual meeting of the Association for Computational Linguistics (short papers); [Anonymous], 1986, Parallel Distributed Processing: Explorations in the Microstructure of Cognition, DOI 10.1016/B978-1-4832-1446-7.50010-8; Arehalli S., 2022, P 26 C COMPUTATIONAL, P301, DOI [10.18653/v1/2022.conll-1.20, DOI 10.18653/V1/2022.CONLL-1.20]; Arehalli S, 2020, PsyArXiv, DOI [10.31234/osf.io/97qcg, DOI 10.31234/OSF.IO/97QCG]; Armeni K, 2017, NEUROSCI BIOBEHAV R, V83, P579, DOI 10.1016/j.neubiorev.2017.09.001; Aurnhammer C., 2018, PsyArXiv, DOI [10.31234/osf.io/wec74, DOI 10.31234/OSF.IO/WEC74]; Bader M, 1999, J PSYCHOLINGUIST RES, V28, P121, DOI 10.1023/A:1023206208142; Bader M, 2010, LINGUA, V120, P717, DOI 10.1016/j.lingua.2009.05.007; Bentz C, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060275; Bickel B, 2003, LANGUAGE, V79, P708, DOI 10.1353/lan.2003.0205; Bickel B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132819; Bickel Balthasar., 2010, OXFORD HDB LINGUISTI, P399, DOI [DOI 10.1093/OXFORDHB/9780199281251.013.0020, 10.1093/oxfordhb/9780199281251.013.0020]; Borer Hagit., 2005, STRUCTURING SENSE VO, DOI [DOI 10.1093/ACPROF:OSO/9780199263905.001.0001, 10.1093/acprof:oso/9780199263905.001.0001]; Bornkessel I, 2003, LANG COGNITIVE PROC, V18, P269, DOI 10.1080/01690960244000018; Bornkessel I, 2006, PSYCHOL REV, V113, P787, DOI 10.1037/0033-295X.113.4.787; Bornkessel-Schlesewsky I., 2020, The cognitive neurosciences, V6th ed., P841, DOI [10.7551/mitpress/11442.003.0094, DOI 10.7551/MITPRESS/11442.003.0094]; Bornkessel-Schlesewsky I, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.817516; Bornkessel-Schlesewsky I, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00298; Bornkessel-Schlesewsky I, 2009, LINGUA, V119, P1541, DOI 10.1016/j.lingua.2008.03.005; Brennan JR, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107479; Brennan JR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207741; Brothers T, 2021, J MEM LANG, V116, DOI 10.1016/j.jml.2020.104174; Bürkner PC, 2018, R J, V10, P395; Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01; Bürkner PC, 2021, COMPUTATION STAT, V36, P1243, DOI 10.1007/s00180-020-01045-4; Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01; Caucheteux C, 2020, bioRxiv, DOI [10.1101/2020.07.03.186288, 10.1101/2020.07.03.186288, DOI 10.1101/2020.07.03.186288]; Cisek P, 2022, PHILOS T R SOC B, V377, DOI 10.1098/rstb.2020.0522; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Cohn N, 2013, COGNITIVE PSYCHOL, V67, P73, DOI 10.1016/j.cogpsych.2013.07.002; Constant A, 2022, MIND LANG, V37, P373, DOI 10.1111/mila.12330; Coupé C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw2594; De Cat C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00077; de Vries W, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P836; Demiral SB, 2008, COGNITION, V106, P484, DOI 10.1016/j.cognition.2007.01.008; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dobel C, 2007, ACTA PSYCHOL, V125, P129, DOI 10.1016/J.ACTPSY.2006.07.004; DOWTY D, 1991, LANGUAGE, V67, P547, DOI 10.2307/415037; Erdocia K, 2009, BRAIN LANG, V109, P1, DOI 10.1016/j.bandl.2008.12.003; Fanselow G., 1999, CONSTRAINTS LANGUAGE, P171, DOI DOI 10.1007/0-306-46902-2_7; Foglia L, 2013, WIRES COGN SCI, V4, P319, DOI 10.1002/wcs.1226; Frank SL, 2019, HUMAN LANGUAGE: FROM GENES AND BRAINS TO BEHAVIOR, P277; Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006; Frank SL, 2013, BEHAV RES METHODS, V45, P1182, DOI 10.3758/s13428-012-0313-y; FRAZIER L, 1989, J MEM LANG, V28, P331, DOI 10.1016/0749-596X(89)90037-5; Frenzel S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00001; Friedmann N, 2008, LINGUIST INQ, V39, P355, DOI 10.1162/ling.2008.39.3.355; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Futrell R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P32; Futrell R, 2015, COGNITION, V136, P215, DOI 10.1016/j.cognition.2014.11.022; Gennari SP, 2008, J MEM LANG, V58, P161, DOI 10.1016/j.jml.2007.07.004; Gerwien J., 2016, Proceedings of the 38th annual meeting of the Cognitive Science Society (CogSci 2016), P2633; Gibson E, 2019, TRENDS COGN SCI, V23, P389, DOI 10.1016/j.tics.2019.02.003; Goldin-Meadow S, 2008, P NATL ACAD SCI USA, V105, P9163, DOI 10.1073/pnas.0710060105; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Goodkind A., 2018, P 8 WORKSHOP COGNITI, P10, DOI [10.18653/v1/W18-0102, DOI 10.18653/V1/W18-0102]; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Hafri A, 2018, COGNITION, V175, P36, DOI 10.1016/j.cognition.2018.02.011; Hafri A, 2013, J EXP PSYCHOL GEN, V142, P880, DOI 10.1037/a0030045; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Haupt FS, 2008, J MEM LANG, V59, P54, DOI 10.1016/j.jml.2008.02.003; HEMFORTH B, 1993, PROCEEDINGS OF THE FIFTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P539; Henderson JM, 2016, NEUROIMAGE, V132, P293, DOI 10.1016/j.neuroimage.2016.02.050; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Höge M, 2020, WATER-SUI, V12, DOI 10.3390/w12020309; Hollenstein N., 2021, P C N AM CHAPT ASS L, P106, DOI DOI 10.18653/V1/2021.NAACL-MAIN.10; Hörberg T, 2013, LANG COGNITIVE PROC, V28, P388, DOI 10.1080/01690965.2011.651345; Hosseini E. A., 2022, bioRxiv, DOI DOI 10.1101/2022.10.04.510681; Huebner P. A., 2021, P 25 C COMPUTATIONAL, P624, DOI DOI 10.18653/V1/2021.CONLL-1.49; Hugging Face, Huggingface; Isasi-Isasmendi A, 2024, LANG COGN NEUROSCI, V39, P76, DOI 10.1080/23273798.2023.2250023; Isasi-Isasmendi Arrate, 2023, Open Mind (Camb), V7, P240, DOI 10.1162/opmi_a_00083; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Krebs J, 2018, BRAIN RES, V1691, P105, DOI 10.1016/j.brainres.2018.03.029; Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299; Kuribayashi Tatsuki., 2021, P 59 ANN M ASS COMPU, P5203, DOI [DOI 10.18653/V1/2021.ACL-LONG.405, 10.18653/v1/2021.acl, DOI 10.18653/V1/2021.ACL]; Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123; Laka I., 1996, BRIEF GRAMMAR EUSKAR; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Lindborg A., 2023, Neuroimage: Reports, V3, P100161, DOI DOI 10.1016/J.YNIRP.2023.100161; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lopopolo A, 2021, bioRxiv, DOI [10.1101/2021.05.12.443787, 10.1101/2021.05.12.443787, DOI 10.1101/2021.05.12.443787]; Lopopolo A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177794; MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226; Mak WM, 2002, J MEM LANG, V47, P50, DOI 10.1006/jmla.2001.2837; McClelland J. L., 2020, PsyArXiv, DOI [10.31234/osf.io/3m5sb, DOI 10.31234/OSF.IO/3M5SB]; McElreath R., 2020, Statistical Rethinking: A Bayesian Course with Examples in R and Stan, DOI [10.1201/9780429029608, DOI 10.1201/9780429029608]; Meir I, 2017, COGNITION, V158, P189, DOI 10.1016/j.cognition.2016.10.011; Merkx D., 2021, P WORKSH COGN MOD CO, P12, DOI [10.18653/v1/2021.cmcl-1.2, DOI 10.18653/V1/2021.CMCL-1.2]; Michaelov J. A., 2020, Proceedings of the 24th conference on computational natural language learning, P652, DOI DOI 10.18653/V1/2020.CONLL-1.53; Michaelov JA, 2023, IEEE T COGN DEV SYST, V15, P1033, DOI 10.1109/TCDS.2022.3176783; Mohanan Tara., 1994, ARGUMENT STRUCTURE H; Mohanan Tara., 1994, THEORETICAL PERSPECT, P185; Næss A, 2021, OCEAN LINGUIST, V60, P160; Næss A, 2015, J LINGUIST, V51, P75, DOI 10.1017/S0022226714000048; Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114; Paszke A, 2019, ADV NEUR IN, V32; Perconti P, 2020, COGNITION, V203, DOI 10.1016/j.cognition.2020.104365; Perlmutter D., 1978, P 4 ANN M BERKELEY L, P159, DOI [DOI 10.3765/BLS.V4I0.2198, 10.3765/bls.v4i0.2198]; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Primus Beatrice., 1999, CASES THEMATIC ROLES, DOI 10.1515/9783110912463; Rabovsky M, 2018, NAT HUM BEHAV, V2, P693, DOI 10.1038/s41562-018-0406-4; Ramstead MJD, 2018, PHYS LIFE REV, V24, P1, DOI 10.1016/j.plrev.2017.09.001; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rosenbaum R, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266102; Rumelhart D., 1987, MECH LANGUAGE ACQUIS, P195; Sauppe S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13340; Sauppe S, 2021, COGNITION, V206, DOI 10.1016/j.cognition.2020.104516; Schouwstra M, 2014, COGNITION, V131, P431, DOI 10.1016/j.cognition.2014.03.004; Schrimpf M, 2020, bioRxiv, DOI [10.1101/2020.06.26.174482, 10.1101/2020.06.26.174482, DOI 10.1101/2020.06.26.174482]; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shain C, 2020, NEUROPSYCHOLOGIA, V138, DOI 10.1016/j.neuropsychologia.2019.107307; Simpson GL, 2018, FRONT ECOL EVOL, V6, DOI 10.3389/fevo.2018.00149; Slaats S., 2023, PsyArXiv, DOI [10.31234/osf.io/7pvau, DOI 10.31234/OSF.IO/7PVAU]; Stevenson S, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.796741; Stoll S, 2010, CROSSLINGUISTIC APPROACHES TO THE PSYCHOLOGY OF LANGUAGE: RESEARCH IN THE TRADITION OF DAN ISAAC SLOBIN, P543; Su YQ, 2023, PLOS BIOL, V21, DOI 10.1371/journal.pbio.3002046; Suarez P.J.O., 2019, P WORKSHOP CHALLENGE, P9, DOI [10.14618/ids-pub-9021, DOI 10.14618/IDS-PUB-9021]; Suitner C, 2021, APPL PSYCHOLINGUIST, V42, P657, DOI 10.1017/S0142716420000831; Szewczyk JM, 2022, J MEM LANG, V123, DOI 10.1016/j.jml.2021.104311; Thomas MSC, 2008, CAMB HANDB PSYCHOL, P23; Tremblay A, 2015, PSYCHOPHYSIOLOGY, V52, P124, DOI 10.1111/psyp.12299; van Schijndel M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5831; van Schijndel M, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12988; van Schijndel M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4704; Van Valin R. D., 2001, Semantic macroroles in role and reference grammar; Van Valin RobertD., 1980, SYNTAX SEMANTICS 13, P329, DOI DOI 10.1163/9789004373105_014; VANVALIN RD, 1990, LANGUAGE, V66, P221, DOI 10.2307/414886; Vaswani A, 2017, ADV NEUR IN, V30; Vehtari A, 2017, STAT COMPUT, V27, P1413, DOI 10.1007/s11222-016-9696-4; Wang LM, 2012, STUD THEOR PSYCHOLIN, V40, P91, DOI 10.1007/978-94-007-1463-2_5; Wang LM, 2009, LANG COGNITIVE PROC, V24, P1180, DOI 10.1080/01690960802159937; Warstadt A, 2024, Arxiv, DOI [arXiv:2208.07998, DOI 10.48550/ARXIV.2208.07998, 10.48550/arXiv.2208.07998]; Wilcox EG., 2022, Linguistic Inquiry, V1, DOI DOI 10.1162/LING_A_00491; Wilcox EG, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P939; Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075; Wilson F., 2011, Proceedings of the 33th Annual Conference of the Cognitive Science Society, P1206; Wilson VAD, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn8464; Yao YL, 2018, BAYESIAN ANAL, V13, P917, DOI 10.1214/17-BA1091	143	2	2	1	1	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	2641-4368			NEUROBIOL LANG	Neurobiol. Lang.	APR 1	2024	5	1			SI		167	200		10.1162/nol_a_00121	http://dx.doi.org/10.1162/nol_a_00121			34	Linguistics; Neurosciences; Psychology, Experimental	Emerging Sources Citation Index (ESCI)	Linguistics; Neurosciences & Neurology; Psychology	NK3U7	38645615	gold, Green Published			2024-07-03	WOS:001200316700005
J	Marian, V				Marian, Viorica			Studying second language acquisition in the age of large language models: Unlocking the mysteries of language and learning, A commentary on "Age effects in second language acquisition: Expanding the emergentist account" by Catherine L. Caldwell-Harris and Brian MacWhinney	BRAIN AND LANGUAGE			English	Editorial Material									[Marian, Viorica] Northwestern Univ, Evanston, IL 60208 USA	Northwestern University	Marian, V (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.	v-marian@northwestern.edu			Eunice Kennedy Shriver National Institute of Child Health and Human Development of the National Institutes of Health [R01HD059858]	Eunice Kennedy Shriver National Institute of Child Health and Human Development of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD))	The preparation of this manuscript was supported in part by the Eunice Kennedy Shriver National Institute of Child Health and Human Development of the National Institutes of Health under Award Number R01HD059858. The content is solely the responsibility of the author and does not necessarily represent the official views of the National Institutes of Health. The author thanks Sirada Rochanavibhata, Ashley Chung-Fat-Yim, Matias Fernandez-Duque, Siqi Ning, and Aya Williams for comments on an earlier draft. Correspondence about this article should be addressed to Professor Viorica Marian, Department of Communication Sciences and Disorders, Northwestern University, Evanston, Illinois 60208, USA. Email: v-marian@northwestern.edu.	Fernandez-Duque M, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adh0064; Isurin L, 2015, LANG LEARN, V65, P761, DOI 10.1111/lang.12133; Marian V., 2023, The power of language: How the codes we use to think, speak, and live transform our minds; Marian Viorica., 2009, ASHA Leader, V14, P10; Ornes S., 2023, Quanta Magazine; Pierce LJ, 2014, P NATL ACAD SCI USA, V111, P17314, DOI 10.1073/pnas.1409411111; Rochanavibhata S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-39947-0; Rochanavibhata S, 2022, LANG LEARN DEV, V18, P294, DOI 10.1080/15475441.2021.1954929; Sapir E., 1921, Language. Harcourt, Brace, and World.; Schaeffer R, 2023, Arxiv, DOI [arXiv:2304.15004, DOI 10.48550/ARXIV.2304.15004, 10.48550/arXiv.2304.15004]; Whorf B. L., 1956, LANGUAGE THOUGHT REA	11	0	0	11	11	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0093-934X	1090-2155		BRAIN LANG	Brain Lang.	NOV	2023	246								105338	10.1016/j.bandl.2023.105338	http://dx.doi.org/10.1016/j.bandl.2023.105338		OCT 2023	3	Audiology & Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Audiology & Speech-Language Pathology; Linguistics; Neurosciences & Neurology; Psychology	IG1F2	38469544	Bronze			2024-07-03	WOS:001165077200001
J	Hassan, A; Javed, S; Hussain, S; Ahmad, R; Qazi, S				Hassan, Ali; Javed, Sadaf; Hussain, Sajjad; Ahmad, Rizwan; Qazi, Shams			Arithmetic N-gram: an efficient data compression technique	DISCOVER COMPUTING			English	Article						Data compression; Huffman; LZW; N-gram; Arithmetic coding; Compression ratio; Large language models		Due to the increase in the growth of data in this era of the digital world and limited resources, there is a need for more efficient data compression techniques for storing and transmitting data. Data compression can significantly reduce the amount of storage space and transmission time to store and transmit given data. More specifically, text compression has got more attention for effectively managing and processing data due to the increased use of the internet, digital devices, data transfer, etc. Over the years, various algorithms have been used for text compression such as Huffman coding, Lempel-Ziv-Welch (LZW) coding, arithmetic coding, etc. However, these methods have a limited compression ratio specifically for data storage applications where a considerable amount of data must be compressed to use storage resources efficiently. They consider individual characters to compress data. It can be more advantageous to consider words or sequences of words rather than individual characters to get a better compression ratio. Compressing individual characters results in a sizeable compressed representation due to their less repetition and structure in the data. In this paper, we proposed the ArthNgram model, in which the N-gram language model coupled with arithmetic coding is used to compress data more efficiently for data storage applications. The performance of the proposed model is evaluated based on compression ratio and compression speed. Results show that the proposed model performs better than traditional techniques.	[Hassan, Ali; Javed, Sadaf; Hussain, Sajjad; Ahmad, Rizwan; Qazi, Shams] Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Islamabad 44000, Pakistan	National University of Sciences & Technology - Pakistan	Ahmad, R (corresponding author), Natl Univ Sci & Technol NUST, Sch Elect Engn & Comp Sci SEECS, Islamabad 44000, Pakistan.	hassan.phdee21seecs@seecs.edu.pk; sjaved.phdee22seecs@seecs.edu.pk; sajjad.hussain2@seecs.edu.pk; rizwan.ahmad@seecs.edu.pk; shams.qazi@seecs.edu.pk						Aburomman FTA., 2016, Int J Comput Appl, V975, P8887; [Anonymous], 2019, U.S; Banerjee S, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104127; Chatterjee A, 2018, IEEE INT CONF BIG DA, P5137, DOI 10.1109/BigData.2018.8622282; Fauzan MN., 2023, IT J Res Develop, V7, P155, DOI [10.25299/itjrd.2023.10437, DOI 10.25299/ITJRD.2023.10437]; Gupta A, 2021, A review on different types of lossless data compression techniques; Gupta M, 2022, ACM T KNOWL DISCOV D, V16, DOI 10.1145/3487045; Habib A., 2020, Iran J Comput Sci, V3, P127, DOI [10.1007/s42044-019-00047-w, DOI 10.1007/S42044-019-00047-W]; Hameed M., 2016, J Eng Appl Sci, V100, P402; Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094; Ignatoski M, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8071059; Jayasankar U, 2021, J KING SAUD UNIV-COM, V33, P119, DOI 10.1016/j.jksuci.2018.05.006; Kotha HD, 2019, J PHYS CONF SER, V1228, DOI 10.1088/1742-6596/1228/1/012007; LANGDON GG, 1984, IBM J RES DEV, V28, P135, DOI 10.1147/rd.282.0135; Lin J, 2024, Arxiv, DOI arXiv:2306.00978; Ma XY, 2023, Arxiv, DOI arXiv:2305.11627; Mantoro T, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING, AND DESIGN (ICCED); Nguyen VH, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/9483646; Otair M, 2022, MULTIMED TOOLS APPL, V81, P28509, DOI 10.1007/s11042-022-12846-8; Rahman MA, 2021, 2021 IEEE 14TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2021), P287, DOI 10.1109/MCSoC51149.2021.00049; Shanmugasundaram S., 2011, Int J Wisdom Based Computer, V1, P68, DOI [10.21917/ijct.2011.0062, DOI 10.21917/IJCT.2011.0062]; Shrividhiya G, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P234, DOI 10.1109/ESCI50559.2021.9396785; Zhu XY, 2023, Arxiv, DOI arXiv:2308.07633	23	0	0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	2948-2984	2948-2992		DISCOV COMPUT	Discov. Comput.	MAR 13	2024	27	1							1	10.1007/s10791-024-09431-y	http://dx.doi.org/10.1007/s10791-024-09431-y			14	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PA5Q4		hybrid			2024-07-03	WOS:001211376400001
J	Waqas, A; Bui, MM; Glassy, EF; El Naqa, I; Borkowskif, P; Borkowski, AA; Rasool, G				Waqas, Asim; Bui, Marilyn M.; Glassy, Eric F.; El Naqa, Issam; Borkowskif, Piotr; Borkowski, Andrew A.; Rasool, Ghulam			Revolutionizing Digital Pathology With the Power of Generative Artificial Intelligence and Foundation Models	LABORATORY INVESTIGATION			English	Review						artificial intelligence; computational and digital pathology; foundation models; large language models; multimodal data; vision-language models	AI; REPRODUCIBILITY; TRANSPARENCY; IMAGES	Digital pathology has transformed the traditional pathology practice of analyzing tissue under a microscope into a computer vision workfiow. Whole-slide imaging allows pathologists to view and analyze microscopic images on a computer monitor, enabling computational pathology. By leveraging artificial intelligence (AI) and machine learning (ML), computational pathology has emerged as a promising field in recent years. Recently, task-specific AI/ML (eg, convolutional neural networks) has risen to the forefront, achieving above-human performance in many imageprocessing and computer vision tasks. The performance of task-specific AI/ML models depends on the availability of many annotated training datasets, which presents a rate-limiting factor for AI/ML development in pathology. Task-specific AI/ML models cannot benefit from multimodal data and lack generalization, eg, the AI models often struggle to generalize to new datasets or unseen variations in image acquisition, staining techniques, or tissue types. The 2020s are witnessing the rise of foundation models and generative AI. A foundation model is a large AI model trained using sizable data, which is later adapted (or fine-tuned) to perform different tasks using a modest amount of task-specific annotated data. These AI models provide in-context learning, can selfcorrect mistakes, and promptly adjust to user feedback. In this review, we provide a brief overview of recent advances in computational pathology enabled by task-specific AI, their challenges and limitations, and then introduce various foundation models. We propose to create a pathologyspecific generative AI based on multimodal foundation models and present its potentially transformative role in digital pathology. We describe different use cases, delineating how it could serve as an expert companion of pathologists and help them efficiently and objectively perform routine laboratory tasks, including quantifying image analysis, generating pathology reports, diagnosis, and prognosis. We also outline the potential role that foundation models and generative AI can play in standardizing the pathology laboratory workfiow, education, and training.(c) 2023 United States & Canadian Academy of Pathology. Published by Elsevier Inc. All rights reserved.	[Waqas, Asim; Bui, Marilyn M.; El Naqa, Issam; Rasool, Ghulam] H Lee Moffitt Canc Ctr & Res Inst, Dept Machine Learning, Tampa, FL 33612 USA; [Waqas, Asim; Rasool, Ghulam] Univ S Florida, Dept Elect Engn, Tampa, FL 33620 USA; [Bui, Marilyn M.] H Lee Moffitt Canc Ctr & Res Inst, Dept Pathol, Tampa, FL USA; [Bui, Marilyn M.; Borkowski, Andrew A.; Rasool, Ghulam] Univ S Florida, Morsani Coll Med, Tampa, FL 33620 USA; [Glassy, Eric F.] Affiliated Pathologists Med Grp Inc, Rancho Dominguez, CA USA; [Borkowskif, Piotr] Quest Diagnost Ameripath, Tampa, FL USA; [Borkowskif, Piotr] Quest Diagnost, Ctr Excellence Digital & AI Empowered Pathol, Tampa, FL USA; [Borkowski, Andrew A.] James A Haley Vet Hosp, Tampa, FL USA; [Borkowski, Andrew A.] Natl Artificial Intelligence Inst, Washington, DC USA; [Rasool, Ghulam] H Lee Moffitt Canc Ctr & Res Inst, Dept Neurooncol, Tampa, FL USA	H Lee Moffitt Cancer Center & Research Institute; State University System of Florida; University of South Florida; H Lee Moffitt Cancer Center & Research Institute; State University System of Florida; University of South Florida; US Department of Veterans Affairs; Veterans Health Administration (VHA); James A. Haley Veterans Hospital; H Lee Moffitt Cancer Center & Research Institute	Waqas, A (corresponding author), H Lee Moffitt Canc Ctr & Res Inst, Dept Machine Learning, Tampa, FL 33612 USA.; Waqas, A (corresponding author), Univ S Florida, Dept Elect Engn, Tampa, FL 33620 USA.	Asim.Waqas@moffitt.org	Waqas, Asim/KEH-8791-2024; Rasool, Ghulam/T-7960-2019	Waqas, Asim/0000-0002-6834-4710; Rasool, Ghulam/0000-0001-8551-0090	United States National Science Foundation [ECCS-1903466, OAC-20 08690, OAC-2234836]	United States National Science Foundation(National Science Foundation (NSF))	This work was partly supported by the United States National Science Foundation awards ECCS-1903466, OAC-20 08690, and OAC-2234836.	Abels E, 2019, J PATHOL, V249, P286, DOI 10.1002/path.5331; Adam G, 2020, NPJ PRECIS ONCOL, V4, DOI 10.1038/s41698-020-0122-1; Adnan M, 2020, IEEE COMPUT SOC CONF, P4254, DOI 10.1109/CVPRW50498.2020.00502; Ahmed S, 2023, Arxiv, DOI arXiv:2205.01138; Ahmed S, 2022, FRONT MED TECHNOL, V4, DOI 10.3389/fmedt.2022.919046; Ahmedt-Aristizabal D, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102027; Ahn E, 2019, I S BIOMED IMAGING, P1915, DOI [10.1109/ISBI.2019.8759275, 10.1109/isbi.2019.8759275]; Aiforia Team, 2023, AI for Image Analysis (AIFORIA); Alayrac JB., 2022, Advances in Neural Information Processing Systems (NeurIPS); Albahra S, 2023, SEMIN DIAGN PATHOL, V40, P71, DOI 10.1053/j.semdp.2023.02.002; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Alsaafin A, 2023, COMMUN BIOL, V6, DOI 10.1038/s42003-023-04583-x; Alwosheel A, 2018, J CHOICE MODEL, V28, P167, DOI 10.1016/j.jocm.2018.07.002; Aubreville M, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102699; Azad R, 2023, Arxiv, DOI arXiv:2301.03505; Bai BJ, 2023, LIGHT-SCI APPL, V12, DOI 10.1038/s41377-023-01104-7; Bera K, 2019, NAT REV CLIN ONCOL, V16, P703, DOI 10.1038/s41571-019-0252-y; Berkeley and Change Healthcare and Duke Health and Google and JHU and Mayo Clinic and Microsoft and MITRE and SAS and Stanford Medicine and UCSF and Vanderbilt University Medical Center, 2023, Coalition for Health AI.; Boehm KM, 2022, NAT REV CANCER, V22, P114, DOI 10.1038/s41568-021-00408-3; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Braman N, 2021, LECT NOTES COMPUT SC, V12905, P667, DOI 10.1007/978-3-030-87240-3_64; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bulten W, 2022, NAT MED, V28, P154, DOI 10.1038/s41591-021-01620-2; Cai ZW, 2022, LECT NOTES COMPUT SC, V13696, P290, DOI 10.1007/978-3-031-20059-5_17; Carannante G, 2020, IEEE INT WORKS MACH, DOI 10.1109/mlsp49062.2020.9231550; Carannante G, 2023, Arxiv, DOI [arXiv:2111.05978, DOI 10.48550/ARXIV.2111.05978]; Chen H, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102691; Chen RJ, 2022, PROC CVPR IEEE, P16123, DOI 10.1109/CVPR52688.2022.01567; Chen RJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3995, DOI 10.1109/ICCV48922.2021.00398; Chen RJ, 2022, IEEE T MED IMAGING, V41, P757, DOI [10.1109/TITS.2020.3030218, 10.1109/TMI.2020.3021387]; Cheng BW, 2022, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR52688.2022.00135; Cifci D, 2023, ANNU REV CANC BIOL, V7, P57, DOI 10.1146/annurev-cancerbio-061521-092038; Cifci D, 2022, J PATHOL, V257, P430, DOI 10.1002/path.5898; Clark J., 2019, Better language models and their implications; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Coalition for Health AI, 2023, BLUEPR TRUSTW AI IMP; Computational Pathology & AI, 2023, FDA has cleared four pathology AI algorithms.; Cui M, 2021, LAB INVEST, V101, P412, DOI 10.1038/s41374-020-00514-0; Cui Y, 2023, 11 ICLR; Demetriou D, 2023, Artificial Intelligence and Precision Oncology: Bridging Cancer Research and Clinical Decision Support, P93; Dera D, 2019, 2019 IEEE 29 INT WOR, P1; Dera D, 2021, IEEE T SIGNAL PROCES, V69, P4669, DOI 10.1109/TSP.2021.3096804; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dick S., 2019, Harv Data Sci Rev, V1, DOI DOI 10.1162/99608F92.92FE150C; Dirik A, 2023, A dive into vision-language models; Dorr DA, 2023, JAMA-J AM MED ASSOC, V329, P1347, DOI 10.1001/jama.2023.2771; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Drogt J, 2022, MODERN PATHOL, V35, P1540, DOI 10.1038/s41379-022-01123-6; Echle A, 2021, BRIT J CANCER, V124, P686, DOI 10.1038/s41416-020-01122-x; Edara Deepak Chowdary, 2023, Journal of Ambient Intelligence and Humanized Computing, P5309, DOI 10.1007/s12652-019-01399-8; Ellis MJ, 2013, CANCER DISCOV, V3, P1108, DOI 10.1158/2159-8290.CD-13-0219; Falahkheirkhah K, 2023, LAB INVEST, V103, DOI 10.1016/j.labinv.2022.100006; FDA, 2022, FDA approved (AI/ML)-enabled medical devices.; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Fu Y, 2020, NAT CANCER, V1, P800, DOI 10.1038/s43018-020-0085-8; Gadiya S, 2020, Medical Imaging 2020: Digital Pathology, P11320; Gan Z, 2022, FOUND TRENDS COMPUT, V14, P163, DOI 10.1561/0600000105; Gao Y, 2018, I S BIOMED IMAGING, P1104, DOI 10.1109/ISBI.2018.8363764; Laleh NG, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33266-0; Ghiasi G, 2022, LECT NOTES COMPUT SC, V13696, P540, DOI 10.1007/978-3-031-20059-5_31; Gibson BA, 2022, ARCH PATHOL LAB MED, V146, P886, DOI 10.5858/arpa.2020-0761-OA; Gu X., 2022, ICLR; Guo RY, 2023, MED IMAGE ANAL, V86, DOI 10.1016/j.media.2023.102790; Gupta R, 2019, CURR PATHOBIOL REP, V7, P73, DOI 10.1007/s40139-019-00200-x; Gurcan Metin N, 2009, IEEE Rev Biomed Eng, V2, P147, DOI 10.1109/RBME.2009.2034865; Haibe-Kains B, 2020, NATURE, V586, pE14, DOI 10.1038/s41586-020-2766-y; Hassell LA, 2023, ARCH PATHOL LAB MED, V147, P474, DOI 10.5858/arpa.2021-0473-RA; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Huang SC, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00811-0; Hudson D. A., 2021, PMLR, P4487; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Ibrahim A, 2020, BREAST, V49, P267, DOI 10.1016/j.breast.2019.12.007; Institution of Analysts & Programmers, 2023, Trustworthy Software Foundation.; Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804; Jaegle A, 2022, Arxiv, DOI arXiv:2107.14795; Jain J, 2023, PROC CVPR IEEE, P2989, DOI 10.1109/CVPR52729.2023.00292; Jardim-Perassi BV, 2021, THERANOSTICS, V11, P5313, DOI 10.7150/thno.56595; Jia C, 2021, PR MACH LEARN RES, V139; Jin WA, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102684; Kather JN, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00634-5; Khan H, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892970; Kiehl TR, 2022, The Future Cycle of Healthcare, P227, DOI [DOI 10.1007/978-3-030-99838-7_12, 10.1007/978-3-030-99838-7_12]; Kim I, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112794; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Leevy JL, 2020, 2020 IEEE 6TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2020), P117, DOI 10.1109/CIC50333.2020.00023; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Li B., 2022, ICLR; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li LH, 2022, PROC CVPR IEEE, P10955, DOI 10.1109/CVPR52688.2022.01069; Lipkova J, 2022, CANCER CELL, V40, P1095, DOI 10.1016/j.ccell.2022.09.012; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu SC, 2022, J BIOMED INFORM, V127, DOI 10.1016/j.jbi.2022.104011; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu HY, 2022, Arxiv, DOI arXiv:2208.08263; Lu MY, 2023, Arxiv, DOI [arXiv:2307.12914, 10.48550/arxiv.2307.12914]; Lüddecke T, 2022, PROC CVPR IEEE, P7076, DOI 10.1109/CVPR52688.2022.00695; Ma RB, 2019, Arxiv, DOI [arXiv:1911.01226, DOI 10.48550/ARXIV.1911.01226, 10.48550/arXiv.1911.01226]; Ma X, 2020, LECT NOTES COMPUT SC, V11993, P343, DOI 10.1007/978-3-030-46643-5_34; Mahmood F, 2020, IEEE T MED IMAGING, V39, P3257, DOI 10.1109/TMI.2019.2927182; McKinney SM, 2020, NATURE, V586, pE17, DOI 10.1038/s41586-020-2767-x; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Minderer M, 2022, LECT NOTES COMPUT SC, V13670, P728, DOI 10.1007/978-3-031-20080-9_42; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nakagawa K, 2023, SEMIN DIAGN PATHOL, V40, P100, DOI 10.1053/j.semdp.2023.02.006; Niehues JM, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.100980; Nielsen IE, 2023, IEEE ACCESS, V11, P82556, DOI 10.1109/ACCESS.2023.3300242; Nielsen IE, 2022, IEEE SIGNAL PROC MAG, V39, P73, DOI 10.1109/MSP.2022.3142719; OpenAI, 2022, OpenA I; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems; Ozoani E, 2022, Model Cards; Paige Team, 2023, Pathology Artificial Intelligence Guidance Engine (PAIGE); Pantanowitz L, 2020, DIAGN PATHOL, V15, DOI 10.1186/s13000-020-00995-z; Patel AU, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081778; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Qiu YX, 2023, MACH INTELL RES, V20, P147, DOI 10.1007/s11633-022-1382-8; Radford A., 2018, IMPROVING LANGUAGE U; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Rajeev R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1371-9; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Rao YM, 2022, PROC CVPR IEEE, P18061, DOI 10.1109/CVPR52688.2022.01755; Rasool G., 2023, HOME: hands-on machine learning course for medical professionals; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Scopio Team. Scopio Labs, 2023, About us; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]; Shmatko A, 2022, NAT CANCER, V3, P1026, DOI 10.1038/s43018-022-00436-4; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Smith S, 2022, arXiv; Studer L, 2021, INT C PATT RECOG, P3636, DOI 10.1109/ICPR48806.2021.9412535; Sureka M, 2020, IEEE INT C BIOINF BI, P331, DOI 10.1109/BIBE50027.2020.00060; Surís D, 2023, Arxiv, DOI [arXiv:2303.08128, DOI 10.48550/ARXIV.2303.08128(2023).2303.08128]; Swanson K, 2023, CELL, V186, P1772, DOI 10.1016/j.cell.2023.01.035; Tizhoosh Hamid Reza, 2018, J Pathol Inform, V9, P38, DOI 10.4103/jpi.jpi_53_18; Tomczak Katarzyna, 2015, Contemp Oncol (Pozn), V19, pA68, DOI 10.5114/wo.2014.47136; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384; Turkki R, 2016, Medical Imaging 2016: Digital Pathology, P9791; Vanguri RS, 2022, NAT CANCER, V3, P1151, DOI 10.1038/s43018-022-00416-8; Vaswani A, 2017, ADV NEUR IN, V30; Veta M, 2015, MED IMAGE ANAL, V20, P237, DOI 10.1016/j.media.2014.11.010; Vu QD, 2023, MED IMAGE ANAL, V85, DOI 10.1016/j.media.2023.102743; Wang JW, 2020, I S BIOMED IMAGING, P239, DOI [10.1109/ISBI45749.2020.9098534, 10.1109/isbi45749.2020.9098534]; Wang X., 2022, Advances in neural information processing systems, V35, P18009; Wang Ziqiao, 2022, ICLR; Waqas A., 2022, COMMUN ENG, V1, P46, DOI DOI 10.1038/S44172-022-00043-2; Waqas A., 2021, Deep Learning for Biomedical Data Analysis: Techniques, Approaches, and Applications, P311; Waqas A, 2024, Arxiv, DOI arXiv:2303.06471; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Willemink MJ, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210284; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xia K., 2023, MEDCOMM FUTUR MED, V2, pe38, DOI DOI 10.1002/MEF2.38; Xu JR, 2022, PROC CVPR IEEE, P18113, DOI 10.1109/CVPR52688.2022.01760; Yan B, 2022, AAAI CONF ARTIF INTE, P2982; Yang J., 2022, Proceedings of the ieee/cvf conference on computer vision and pattern recognition, P19163; Yu J., 2022, TMLR; Zang YH, 2022, LECT NOTES COMPUT SC, V13669, P106, DOI 10.1007/978-3-031-20077-9_7; Zhong YW, 2022, PROC CVPR IEEE, P16772, DOI 10.1109/CVPR52688.2022.01629; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhou C, 2022, LECT NOTES COMPUT SC, V13688, P696, DOI 10.1007/978-3-031-19815-1_40; Zhou XY, 2022, LECT NOTES COMPUT SC, V13669, P350, DOI 10.1007/978-3-031-20077-9_21; Zhou YN, 2019, IEEE INT CONF COMP V, P388, DOI 10.1109/ICCVW.2019.00050	168	3	3	23	26	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0023-6837	1530-0307		LAB INVEST	Lab. Invest.	NOV	2023	103	11							100255	10.1016/j.labinv.2023.100255	http://dx.doi.org/10.1016/j.labinv.2023.100255		NOV 2023	18	Medicine, Research & Experimental; Pathology	Science Citation Index Expanded (SCI-EXPANDED)	Research & Experimental Medicine; Pathology	Z6HQ2	37757969				2024-07-03	WOS:001113071200001
J	Dwivedi, YK; Hughes, L; Bhadeshia, HKDH; Ananiadou, S; Cohn, AG; Cole, JM; Conduit, GJ; Desarkar, MS; Wang, XW				Dwivedi, Yogesh K.; Hughes, Laurie; Bhadeshia, Harshad K. D. H.; Ananiadou, Sophia; Cohn, Anthony G.; Cole, Jacqueline M.; Conduit, Gareth J.; Desarkar, Maunendra Sankar; Wang, Xinwei			Artificial intelligence (AI) futures: India-UK collaborations emerging from the 4th Royal Society Yusuf Hamied workshop	INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT			English	Editorial Material						Artificial intelligence; ChatGPT; Generative AI; Gen AI; Large language models; Technological disruption uncertainties; Natural Language Processing	DESIGN; INFORMATION	"Artificial Intelligence" in all its forms has emerged as a transformative technology that is in the process of reshaping many aspects of industry and wider society at a global level. It has evolved from a concept to a technology that is driving innovation, transforming productivity and disrupting existing business models across numerous sectors. The industrial and societal impact of AI is profound and multifaceted, offering opportunities for growth, efficiency, and improved healthcare, but also raising ethical and societal challenges as the method is integrated into many aspects of human life and work. This editorial is developed by contributors of the 4th Royal Society Yusef Hamied Workshop ( in 2023 devoted to Artificial Intelligence), designed to enhance collaboration between Indian and the UK scientists and to explore future research opportunities. The insights shared at the workshop are shared here.	[Dwivedi, Yogesh K.] Swansea Univ, Sch Management, Digital Futures Sustainable Business & Soc Res Gr, Bay Campus, Swansea, Wales; [Dwivedi, Yogesh K.] Symbiosis Int, Pune, India; [Hughes, Laurie] Edith Cowan Univ, Sch Business & Law, Joondalup, WA, Australia; [Bhadeshia, Harshad K. D. H.] Univ Cambridge, Dept Mat Sci & Met, 27 Charles Babbage Rd, Cambridge CB3 0FS, England; [Bhadeshia, Harshad K. D. H.] Queen Mary Univ London, Sch Engn & Mat Sci, Mile End Rd, London E1 4NS, England; [Ananiadou, Sophia] Univ Manchester, Natl Ctr Text Min, Dept Comp Sci, Manchester, England; [Ananiadou, Sophia; Cohn, Anthony G.] Alan Turing Inst, London, England; [Cohn, Anthony G.] Univ Leeds, Sch Comp, Leeds, England; [Cohn, Anthony G.] Tongji Univ, Dept Comp Sci & Technol, Shanghai, Peoples R China; [Cole, Jacqueline M.; Conduit, Gareth J.] Univ Cambridge, Cavendish Lab, JJ Thomson Ave, Cambridge CB3 0HE, England; [Cole, Jacqueline M.] STFC Rutherford Appleton Lab, ISIS Neutron & Muon Source, Harwell Sci & Innovat Campus, Didcot OX11 0QX, England; [Desarkar, Maunendra Sankar] Indian Inst Technol Hyderabad, Dept CSE, Kandi, India; [Desarkar, Maunendra Sankar] Indian Inst Technol Hyderabad, Dept AI, Kandi, India; [Wang, Xinwei] Queen Mary Univ London, Sch Engn & Mat Sci, London E1 4NS, England	Swansea University; Symbiosis International University; Edith Cowan University; University of Cambridge; University of London; Queen Mary University London; University of Manchester; University of Leeds; Tongji University; University of Cambridge; UK Research & Innovation (UKRI); Science & Technology Facilities Council (STFC); STFC Rutherford Appleton Laboratory; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Hyderabad; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Hyderabad; University of London; Queen Mary University London	Dwivedi, YK (corresponding author), Swansea Univ, Sch Management, Digital Futures Sustainable Business & Soc Res Gr, Bay Campus, Swansea, Wales.; Dwivedi, YK (corresponding author), Symbiosis Int, Pune, India.	y.k.dwivedi@swansea.ac.uk	Wang, Xinwei/AAT-8080-2021	Wang, Xinwei/0000-0003-4988-222X				Abduljabbar R, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11010189; Ahmed N, 2020, Arxiv, DOI arXiv:2010.15581; Ali O, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100333; Andersen CW, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00974-z; Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6; Bai H., 2023, Artificial intelligence can persuade humans on political issues; Beard EJ, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01355-w; Beard EJ, 2020, J CHEM INF MODEL, V60, P2059, DOI 10.1021/acs.jcim.0c00042; Beard EJ, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0306-0; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bishop JA, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P220; Budhwar P, 2023, HUM RESOUR MANAG J, V33, P606, DOI 10.1111/1748-8583.12524; Bundy A, 2017, COMMUN ACM, V60, P40, DOI 10.1145/2950042; Burnell R, 2023, SCIENCE, V380, P136, DOI 10.1126/science.adf6369; Choudhury A., 2022, Human Factors in Healthcare, V2, DOI DOI 10.1016/J.HFH.2022.100021; Cohn A. G., 2023, arXiv; Cole JM, 2020, ACCOUNTS CHEM RES, V53, P599, DOI 10.1021/acs.accounts.9b00470; Collins KM, 2023, Arxiv, DOI arXiv:2306.01694; Conduit BD, 2018, SCRIPTA MATER, V146, P82, DOI 10.1016/j.scriptamat.2017.11.008; Conduit BD, 2017, MATER DESIGN, V131, P358, DOI 10.1016/j.matdes.2017.06.007; Cooper CB, 2019, ADV ENERGY MATER, V9, DOI 10.1002/aenm.201802820; Davis E, 2023, Arxiv, DOI [arXiv:2302.04752, DOI 10.48550/ARXIV.2302.04752]; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Deliotte, 2023, Artificial Intelligence-Jobs crash, productivity boom?; Dennehy D, 2023, INFORM SYST FRONT, V25, P1, DOI 10.1007/s10796-022-10365-3; Dey S., 2023, 37 PAC AS C LANG INF; Dey S., 24 M SPEC INT GROUPS; Dey S, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P218; Dignum V, 2019, ARTIF INTELL-FOUND, P1, DOI 10.1007/978-3-030-30371-6; Dimitrova V, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2019.103450; Dwivedi YK, 2024, INT J CONTEMP HOSP M, V36, P1, DOI 10.1108/IJCHM-05-2023-0686; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dwivedi YK, 2023, PSYCHOL MARKET, V40, P750, DOI 10.1002/mar.21767; Dwivedi YK, 2022, INT J INFORM MANAGE, V63, DOI 10.1016/j.ijinfomgt.2021.102456; Dwivedi YK, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102211; Dwivedi YK, 2021, INT J INFORM MANAGE, V59, DOI 10.1016/j.ijinfomgt.2020.102168; Dwivedi YK, 2021, INT J INFORM MANAGE, V57, DOI 10.1016/j.ijinfomgt.2019.08.002; Dwivedi YK, 2015, INFORM SYST FRONT, V17, P143, DOI 10.1007/s10796-014-9500-y; Fadlullah ZM, 2017, IEEE COMMUN SURV TUT, V19, P2432, DOI 10.1109/COMST.2017.2707140; Feng S, 2023, NATURE, V615, P620, DOI 10.1038/s41586-023-05732-2; Glikson E, 2020, ACAD MANAG ANN, V14, P627, DOI 10.5465/annals.2018.0057; Goldman Sachs, 2023, Generative AI could raise global GDP by 7%; Hadi M.U., 2023, TECHRXIV; Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8; Heikkila M., 2023, MIT Technology Review: Google is throwing generative AI at everything; Hentzen JK, 2022, INT J BANK MARK, V40, P1299, DOI 10.1108/IJBM-09-2021-0417; Huang S, 2022, CHEM SCI, V13, P11487, DOI 10.1039/d2sc04322j; Huang S, 2022, J CHEM INF MODEL, V62, P6365, DOI 10.1021/acs.jcim.2c00035; Huang S, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00602-2; Isazawa T, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02511-6; Isazawa T, 2022, J CHEM INF MODEL, V62, P1207, DOI 10.1021/acs.jcim.1c01199; Jaheer Mukthar K. P., 2022, Future of Organizations and Work After the 4th Industrial Revolution: The Role of Artificial Intelligence. Big Data, Automation, and Robotics, P41; Khan S., 2022, 2022 INT C EL COMP E, P1; Kiseleva A, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.879603; Kocijan V, 2023, ARTIF INTELL-AMST, V325, DOI 10.1016/j.artint.2023.103971; Kshetri N, 2024, INT J INFORM MANAGE, V75, DOI 10.1016/j.ijinfomgt.2023.102716; La Malfa E, 2023, Arxiv, DOI arXiv:2309.16573; Lefevre S., 2014, ROBOMECH J., V1, P1, DOI [10.1186/s40648-014-0001-z, DOI 10.1186/S40648-014-0001-Z]; LENAT DB, 1990, COMMUN ACM, V33, P30, DOI 10.1145/79173.79176; Li SB, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3551869; Li Y, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P206; Luo LC, 2019, AAAI CONF ARTIF INTE, P6794; Luo Z., 2022, Computational Linguistics: EMNLP, V2022, P4667; Luo ZH, 2023, Arxiv, DOI arXiv:2303.15621; Mavracic J, 2021, J CHEM INF MODEL, V61, P4280, DOI 10.1021/acs.jcim.1c00446; McCarthy J., 1959, P S NAT PHYS LAB 24, V1, P75; McCarthy John., 2003, ELABORATION TOLERANC; McKinsey, 2023, Why Business Leaders Need Explainable AI and How to Deliver It; Mukaddem KT, 2020, J CHEM INF MODEL, V60, P2492, DOI 10.1021/acs.jcim.9b00734; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; NBER, 2023, Generative AI at; OpenAI, 2023, ChatGPT can now see, hear, and speak; Pawelec Maria, 2022, Digit Soc, V1, P19, DOI 10.1007/s44206-022-00010-6; Peters MA, 2023, EDUC PHILOS THEORY, DOI 10.1080/00131857.2023.2213437; Ramachandran D., 2005, AAAI WORKSH CONT ONT, P33; Rastogi A, 2020, Arxiv, DOI arXiv:2002.01359; Richey RG Jr, 2023, J BUS LOGIST, V44, P532, DOI 10.1111/jbl.12364; Sezgin E, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231186520; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Srivastava Aarohi, 2022, arXiv; Stahl BC, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102700; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Tunyasuvunakool K, 2021, NATURE, V596, P590, DOI 10.1038/s41586-021-03828-1; Ufuk F, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230276; Ullman T., 2023, PREPRINT; VANMELLE W, 1978, INT J MAN MACH STUD, V10, P313, DOI 10.1016/S0020-7373(78)80049-2; von Foerster H., 2003, SELF ORG SYSTEMS, DOI [10.1007/0-387-21722-3_1, DOI 10.1007/0-387-21722-3_1]; Wang XW, 2022, IEEE T INTELL TRANSP, V23, P19399, DOI 10.1109/TITS.2022.3164469; Wilary DM, 2023, J CHEM INF MODEL, V63, P6053, DOI 10.1021/acs.jcim.3c00422; Wilary DM, 2021, J CHEM INF MODEL, V61, P4962, DOI 10.1021/acs.jcim.1c01017; Wirtz BW, 2022, GOV INFORM Q, V39, DOI 10.1016/j.giq.2022.101685; Xie Qianqian, 2022, Knowledge-Based Systems, DOI 10.1016/j.knosys.2022.109460; Xie QQ, 2024, IEEE J BIOMED HEALTH, V28, P1836, DOI 10.1109/JBHI.2023.3308064; Xie Qianqian, 2022, P 29 INT C COMP LING, P6259; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yildirim B, 2021, J CHEM INF MODEL, V61, P1136, DOI 10.1021/acs.jcim.0c01455; Zhao JY, 2023, J CHEM INF MODEL, V63, P1961, DOI 10.1021/acs.jcim.2c01259; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	98	1	1	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0268-4012	1873-4707		INT J INFORM MANAGE	Int. J. Inf. Manage.	JUN	2024	76								102725	10.1016/j.ijinfomgt.2023.102725	http://dx.doi.org/10.1016/j.ijinfomgt.2023.102725			12	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	RO1U9					2024-07-03	WOS:001228521300001
J	Hirosawa, T; Mizuta, K; Harada, Y; Shimizu, T				Hirosawa, Takanobu; Mizuta, Kazuya; Harada, Yukinori; Shimizu, Taro			Comparative Evaluation of Diagnostic Accuracy Between Google Bard and Physicians	AMERICAN JOURNAL OF MEDICINE			English	Article						Clinical decision supporting system; Diagnosis; Diagnostic excellence; Generative artificial intelligence; Large language model; Natural language processing	ARTIFICIAL-INTELLIGENCE	BACKGROUND: In this study, we evaluated the diagnostic accuracy of Google Bard, a generative artificial intelligence (AI) platform. METHODS: We searched published case reports from our department for difficult or uncommon case descriptions and mock cases created by physicians for common case descriptions. We entered the case descriptions into the prompt of Google Bard to generate the top 10 differential-diagnosis lists. As in previous studies, other physicians created differential-diagnosis lists by reading the same clinical descriptions.RESULTS: A total of 82 clinical descriptions (52 case reports and 30 mock cases) were used. The accuracy rates of physicians were still higher than Google Bard in the top 10 (56.1% vs 82.9%, P < .001), the top 5 (53.7% vs 78.0%, P = .002), and the top differential diagnosis (40.2% vs 64.6%, P = .003). Even within the specific context of case reports, physicians consistently outperformed Google Bard. When it came to mock cases, the performances of the differential-diagnosis lists by Google Bard were no different from those of the physicians in the top 10 (80.0% vs 96.6%, P = .11) and the top 5 (76.7% vs 96.6%, P = .06), except for those in the top diagnoses (60.0% vs 90.0%, P = .02).CONCLUSION: While physicians excelled overall, and particularly with case reports, Google Bard dis -played comparable diagnostic performance in common cases. This suggested that Google Bard possesses room for further improvement and refinement in its diagnostic capabilities. Generative AIs, including Google Bard, are anticipated to become increasingly beneficial in augmenting diagnostic accuracy.	[Hirosawa, Takanobu; Mizuta, Kazuya; Harada, Yukinori; Shimizu, Taro] Dokkyo Med Univ, Dept Diagnost & Generalist Med, Mibu, Tochigi, Japan; [Hirosawa, Takanobu] Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu, Tochigi 3210293, Japan	Dokkyo Medical University; Dokkyo Medical University	Hirosawa, T (corresponding author), Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Mibu, Tochigi 3210293, Japan.	hirosawa@dokkyomed.ac.jp	Hirosawa, Takanobu/AFS-0531-2022	Hirosawa, Takanobu/0000-0002-3573-8203				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Hirosawa T KR, 2023, PREPRINT; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Meunier PY, 2023, ANN FAM MED, V21, P57, DOI 10.1370/afm.2908; Riches N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148991; Schmieding ML, 2022, J MED INTERNET RES, V24, DOI 10.2196/31810; Siad S, 2023, The Promise and Perils of Google's Bard for Scientific Research, DOI [10.17613/yb4n-mc79, DOI 10.17613/YB4N-MC79]; Singh H, 2022, BMJ-BRIT MED J, V376, DOI 10.1136/bmj-2021-068044; Sutton RT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0221-y	11	4	4	8	9	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0002-9343	1555-7162		AM J MED	Am. J. Med.	NOV	2023	136	11					1119	+		10.1016/j.amjmed.2023.08.003	http://dx.doi.org/10.1016/j.amjmed.2023.08.003		OCT 2023	23	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	W9YU2	37643659				2024-07-03	WOS:001095121700001
J	Schonfeld, E; Pant, A; Shah, ARY; Sadeghzadeh, S; Pangal, D; Rodrigues, A; Yoo, K; Marianayagam, N; Haider, G; Veeravagu, A				Schonfeld, Ethan; Pant, Aaradhya; Shah, Aaryan; Sadeghzadeh, Sina; Pangal, Dhiraj; Rodrigues, Adrian; Yoo, Kelly; Marianayagam, Neelan; Haider, Ghani; Veeravagu, Anand			Evaluating Computer Vision, Large Language, and Genome-Wide Association Models in a Limited Sized Patient Cohort for Pre-Operative Risk Stratification in Adult Spinal Deformity Surgery	JOURNAL OF CLINICAL MEDICINE			English	Article						adult spinal deformity; computer vision; large language model; genome wide associated study; sepsis; neurological complication; spine surgery	COMPLICATIONS	Background: Adult spinal deformities (ASD) are varied spinal abnormalities, often necessitating surgical intervention when associated with pain, worsening deformity, or worsening function. Predicting post-operative complications and revision surgery is critical for surgical planning and patient counseling. Due to the relatively small number of cases of ASD surgery, machine learning applications have been limited to traditional models (e.g., logistic regression or standard neural networks) and coarse clinical variables. We present the novel application of advanced models (CNN, LLM, GWAS) using complex data types (radiographs, clinical notes, genomics) for ASD outcome prediction. Methods: We developed a CNN trained on 209 ASD patients (1549 radiographs) from the Stanford Research Repository, a CNN pre-trained on VinDr-SpineXR (10,468 spine radiographs), and an LLM using free-text clinical notes from the same 209 patients, trained via Gatortron. Additionally, we conducted a GWAS using the UK Biobank, contrasting 540 surgical ASD patients with 7355 non-surgical ASD patients. Results: The LLM notably outperformed the CNN in predicting pulmonary complications (F1: 0.545 vs. 0.2881), neurological complications (F1: 0.250 vs. 0.224), and sepsis (F1: 0.382 vs. 0.132). The pre-trained CNN showed improved sepsis prediction (AUC: 0.638 vs. 0.534) but reduced performance for neurological complication prediction (AUC: 0.545 vs. 0.619). The LLM demonstrated high specificity (0.946) and positive predictive value (0.467) for neurological complications. The GWAS identified 21 significant (p < 10(-5)) SNPs associated with ASD surgery risk (OR: mean: 3.17, SD: 1.92, median: 2.78), with the highest odds ratio (8.06) for the LDB2 gene, which is implicated in ectoderm differentiation. Conclusions: This study exemplifies the innovative application of cutting-edge models to forecast outcomes in ASD, underscoring the utility of complex data in outcome prediction for neurosurgical conditions. It demonstrates the promise of genetic models when identifying surgical risks and supports the integration of complex machine learning tools for informed surgical decision-making in ASD.	[Schonfeld, Ethan; Pant, Aaradhya; Sadeghzadeh, Sina] Stanford Univ, Sch Med, Stanford, CA 94304 USA; [Shah, Aaryan] Stanford Univ, Dept Comp Sci, Stanford, CA 94304 USA; [Pangal, Dhiraj; Yoo, Kelly; Marianayagam, Neelan; Haider, Ghani; Veeravagu, Anand] Stanford Univ, Dept Neurosurg, Sch Med, Stanford, CA 94304 USA; [Rodrigues, Adrian] Massachusetts Gen Hosp, Dept Neurosurg, Boston, MA 02114 USA	Stanford University; Stanford University; Stanford University; Harvard University; Massachusetts General Hospital	Schonfeld, E (corresponding author), Stanford Univ, Sch Med, Stanford, CA 94304 USA.	ethan.schonfeld@stanford.edu; rdpant@stanford.edu; aaryans@stanford.edu; sinas@stanford.edu; pangal@stanford.edu; arodrigues11@mgb.org; kellyyoo@stanford.edu; njm39@stanford.edu; ghanih@stanford.edu; anand.veeravagu@stanford.edu		Haider, Ghani/0000-0003-4337-2464; Schonfeld, Ethan/0000-0001-7633-0450; Pant, Aaradhya/0000-0003-3236-8216; Yoo, Hyeon Joo/0000-0002-5516-9431				Cerpa M, 2019, GLOB SPINE J, V9, p8S, DOI 10.1177/2192568219828729; Chang MC, 2020, FRONT SURG, V7, DOI 10.3389/fsurg.2020.00054; Chen ZZ, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0355-9; Fu KMG, 2014, SPINE, V39, P1401, DOI 10.1097/BRS.0000000000000414; Hiyama A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06389-z; Huang BB, 2022, WORLD NEUROSURG, V167, P156, DOI 10.1016/j.wneu.2022.08.109; Jamaludin A, 2020, CALCIFIED TISSUE INT, V106, P378, DOI 10.1007/s00223-019-00651-9; Karhade AV, 2022, SPINE J, V22, P272, DOI 10.1016/j.spinee.2021.08.002; Karhade AV, 2020, SPINE J, V20, P1602, DOI 10.1016/j.spinee.2020.02.021; Karhade AV, 2020, SPINE J, V20, P695, DOI 10.1016/j.spinee.2019.12.006; Karhade AV, 2021, SPINE J, V21, P1635, DOI 10.1016/j.spinee.2020.04.001; Kim HJ, 2020, ASIAN SPINE J, V14, P886, DOI 10.31616/asj.2020.0568; Laverdière C, 2022, GLOB SPINE J, V12, P689, DOI 10.1177/21925682211004250; Lee NJ, 2023, INT J SPINE SURG, V17, pS18, DOI 10.14444/8503; Loftus TJ, 2020, JAMA SURG, V155, P148, DOI 10.1001/jamasurg.2019.4917; Mascagni P, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00707-5; Nguyen HT, 2021, LECT NOTES COMPUT SC, V12905, P291, DOI 10.1007/978-3-030-87240-3_28; Noh SH, 2023, NEUROSPINE, V20, P265, DOI 10.14245/ns.2244854.427; Rodrigues AJ, 2022, SPINE, V47, P1637, DOI 10.1097/BRS.0000000000004481; Roller BL, 2021, SKELETAL RADIOL, V50, P69, DOI 10.1007/s00256-020-03505-w; Saravi B, 2022, J PERS MED, V12, DOI 10.3390/jpm12040509; Scheer JK, 2017, J NEUROSURG-SPINE, V26, P736, DOI 10.3171/2016.10.SPINE16197; Sharma A, 2019, NEUROSURGERY, V84, P733, DOI 10.1093/neuros/nyy190; Simón-Sánchez J, 2008, LANCET NEUROL, V7, P1067, DOI 10.1016/S1474-4422(08)70241-2; Smith Colleen, 2019, J Spine Surg, V5, P223, DOI 10.21037/jss.2019.03.06; Wang LH, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21041267; Wondra JP, 2023, SPINE, V48, P21, DOI 10.1097/BRS.0000000000004416; Yagi M, 2023, J CLIN MED, V12, DOI 10.3390/jcm12134188; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zaidat B, 2023, GLOB SPINE J, DOI 10.1177/21925682231224753	30	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-0383		J CLIN MED	J. Clin. Med.	FEB	2024	13	3							656	10.3390/jcm13030656	http://dx.doi.org/10.3390/jcm13030656			13	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	HQ6E1	38337352	Green Published, gold			2024-07-03	WOS:001161003400001
J	Moulin, TC				Moulin, Thiago C.			Learning with AI Language Models: Guidelines for the Development and Scoring of Medical Questions for Higher Education	JOURNAL OF MEDICAL SYSTEMS			English	Letter						AI-assisted learning; Language models; ChatGPT; Learning outcomes; SOLO taxonomy; Large language models; Generative AI; LLMs; GTP-3; GTP-4		In medical and biomedical education, traditional teaching methods often struggle to engage students and promote critical thinking. The use of AI language models has the potential to transform teaching and learning practices by offering an innovative, active learning approach that promotes intellectual curiosity and deeper understanding. To effectively integrate AI language models into biomedical education, it is essential for educators to understand the benefits and limitations of these tools and how they can be employed to achieve high-level learning outcomes. This article explores the use of AI language models in biomedical education, focusing on their application in both classroom teaching and learning assignments. Using the SOLO taxonomy as a framework, I discuss strategies for designing questions that challenge students to exercise critical thinking and problem-solving skills, even when assisted by AI models. Additionally, I propose a scoring rubric for evaluating student performance when collaborating with AI language models, ensuring a comprehensive assessment of their learning outcomes. AI language models offer a promising opportunity for enhancing student engagement and promoting active learning in the biomedical field. Understanding the potential use of these technologies allows educators to create learning experiences that are fit for their students' needs, encouraging intellectual curiosity and a deeper understanding of complex subjects. The application of these tools will be fundamental to provide more effective and engaging learning experiences for students in the future.	[Moulin, Thiago C.] Lund Univ, Dept Expt Med Sci, Lund, Sweden; [Moulin, Thiago C.] Uppsala Univ, Dept Surg Sci, Uppsala, Sweden	Lund University; Uppsala University	Moulin, TC (corresponding author), Lund Univ, Dept Expt Med Sci, Lund, Sweden.; Moulin, TC (corresponding author), Uppsala Univ, Dept Surg Sci, Uppsala, Sweden.	thiago.moulin@neuro.uu.se		Moulin, Thiago/0000-0001-7811-5383	Royal Physiographic Society of Lund	Royal Physiographic Society of Lund	I am grateful to Sten Erici and Kristina Lundholm Fors, instructors at Lund University's Perspectives on Learning course, which inspired this article.	[Anonymous], 2023, NAT BIOMED ENG, V7, P85, DOI 10.1038/s41551-023-01012-6; Biggs J.B., 1982, Evaluating the quality of learning: The SOLO taxonomy (Structure of the Observed Learning Outcome); Biggs John., 2011, TEACHING QUALITY LEA, V2011; Brabrand C, 2009, HIGH EDUC, V58, P531, DOI 10.1007/s10734-009-9210-4; Burk-Rafel J, 2017, ACAD MED, V92, pS67, DOI 10.1097/ACM.0000000000001916; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mertler C.A., 2001, Practical Assessment, Research and Evaluation, V7, DOI DOI 10.7275/GCY8-0W24; Moskal B. M., 2000, PRACTICAL ASSESSMENT, V7, DOI DOI 10.7275/Q7RM-GG74; Nori H., 2023, 2 Capabilities of GPT-4 on Medical Challenge Problems; Prince M, 2004, J ENG EDUC, V93, P223, DOI 10.1002/j.2168-9830.2004.tb00809.x; Rembach L., 2016, Perspectives in Education, V34, DOI [10.18820/0258-2236/pie.%20v34i1.6, 10.18820/2519593X/pie.v34i1.6, DOI 10.18820/0258-2236/PIE.V34I1.6]; Seetharaman R, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01957-w; Svensäter G, 2023, EUR J DENT EDUC, V27, P149, DOI 10.1111/eje.12787; Yang Z, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103408	17	1	1	16	16	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	APR 23	2024	48	1							45	10.1007/s10916-024-02069-9	http://dx.doi.org/10.1007/s10916-024-02069-9			8	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	OK6N6	38652327				2024-07-03	WOS:001207204600001
J	Luo, ST; Canavese, F; Aroojis, A; Andreacchio, A; Anticevic, D; Bouchard, M; Castaneda, P; De Rosa, V; Fiogbe, MA; Frick, SL; Hui, JH; Johari, AN; Loro, A; Lyu, XM; Matsushita, M; Omeroglu, H; Roye, DP; Shah, MM; Yong, BC; Li, LY				Luo, Shaoting; Canavese, Federico; Aroojis, Alaric; Andreacchio, Antonio; Anticevic, Darko; Bouchard, Maryse; Castaneda, Pablo; De Rosa, Vincenzo; Fiogbe, Michel Armand; Frick, Steven L.; Hui, James H.; Johari, Ashok N.; Loro, Antonio; Lyu, Xuemin; Matsushita, Masaki; Omeroglu, Hakan; Roye, David P.; Shah, Maulin M.; Yong, Bicheng; Li, Lianyong			Are Generative Pretrained Transformer 4 Responses to Developmental Dysplasia of the Hip Clinical Scenarios Universal? An International Review	JOURNAL OF PEDIATRIC ORTHOPAEDICS			English	Article						chat generative pretrained transformer; pediatric Orthopaedic; developmental dysplasia of the hip; large language models		Objective: There is increasing interest in applying artificial intelligence chatbots like generative pretrained transformer 4 (GPT-4) in the medical field. This study aimed to explore the universality of GPT-4 responses to simulated clinical scenarios of developmental dysplasia of the hip (DDH) across diverse global settings. Methods: Seventeen international experts with more than 15 years of experience in pediatric orthopaedics were selected for the evaluation panel. Eight simulated DDH clinical scenarios were created, covering 4 key areas: (1) initial evaluation and diagnosis, (2) initial examination and treatment, (3) nursing care and follow-up, and (4) prognosis and rehabilitation planning. Each scenario was completed independently in a new GPT-4 session. Interrater reliability was assessed using Fleiss kappa, and the quality, relevance, and applicability of GPT-4 responses were analyzed using median scores and interquartile ranges. Following scoring, experts met in ZOOM sessions to generate Regional Consensus Assessment Scores, which were intended to represent a consistent regional assessment of the use of the GPT-4 in pediatric orthopaedic care. Results: GPT-4's responses to the 8 clinical DDH scenarios received performance scores ranging from 44.3% to 98.9% of the 88-point maximum. The Fleiss kappa statistic of 0.113 (P = 0.001) indicated low agreement among experts in their ratings. When assessing the responses' quality, relevance, and applicability, the median scores were 3, with interquartile ranges of 3 to 4, 3 to 4, and 2 to 3, respectively. Significant differences were noted in the prognosis and rehabilitation domain scores (P < 0.05 for all). Regional consensus scores were 75 for Africa, 74 for Asia, 73 for India, 80 for Europe, and 65 for North America, with the Kruskal-Wallis test highlighting significant disparities between these regions (P = 0.034). Conclusions: This study demonstrates the promise of GPT-4 in pediatric orthopaedic care, particularly in supporting preliminary DDH assessments and guiding treatment strategies for specialist care. However, effective integration of GPT-4 into clinical practice will require adaptation to specific regional health care contexts, highlighting the importance of a nuanced approach to health technology adaptation.	[Luo, Shaoting; Li, Lianyong] China Med Univ, Shengjing Hosp, Dept Pediat Orthopaed, Shenyang, Liaoning, Peoples R China; [Lyu, Xuemin] Beijing Jishuitan Hosp, Dept Pediat Orthopaed, Beijing, Peoples R China; [Canavese, Federico] Lille Univ Ctr, Dept Pediat Orthopaed Surg, Lille, France; [Canavese, Federico] Lille Univ, Fac Med, Lille, France; [Canavese, Federico] Jeanne De Flandre Hosp, Lille, France; [Aroojis, Alaric] Bai Jerbai Wadia Hosp Children, Dept Paediat Orthopaed, Mumbai, India; [Johari, Ashok N.] Childrens Orthopaed Ctr, Dept Pediat Orthopaed & Spine Surg, Mumbai, India; [Shah, Maulin M.] OrthoKids Clin, Golden Icon Satellite, Ahmadabad, GJ, India; [Andreacchio, Antonio] Buzzi Childrens Hosp, Dept Pediat Orthopaed, Milan, Italy; [Anticevic, Darko] Univ JJ Strossmayer, Special Hosp St Catherine, Fac Dent Med & Hlth, Dept Orthopaed, Zagreb, Croatia; [Bouchard, Maryse] Univ Toronto, Hosp Sick Children, Div Orthopaed Surg, Toronto, ON, Canada; [Castaneda, Pablo] Texas Childrens Hosp Houston, Div Orthoped Surg, Houston, TX USA; [Roye, David P.] Columbia Univ, Irving Med Ctr, New York Presbyterian Morgan Stanley Childrens Hos, Div Pediat Orthopaed Surg, New York, NY USA; [De Rosa, Vincenzo] Pediat Inst Southern Switzerland IPSI, Pediat Orthoped Clin Pediat Surg & Orthoped, Via Athos Gallino, Bellinzona, Switzerland; [Fiogbe, Michel Armand] Univ Abomey Calavi, Natl Univ Hosp Ctr Hubert Koutoukou Maga CNHU HKM, Univ Clin Pediat Surg, Fac Hlth Sci, Cotonou, Benin; [Frick, Steven L.] Stanford Univ, Sch Med, Dept Orthopaed Surg, Palo Alto, CA USA; [Hui, James H.] Natl Univ Hlth Syst NUHS, Dept Orthopaed Surg, Singapore, Singapore; [Loro, Antonio] Comprehens Rehabil Serv People Disabil Uganda CoRS, Kisubi, Uganda; [Matsushita, Masaki] Nagoya Univ, Grad Sch Med, Dept Orthopaed Surg, Nagoya, Aichi, Japan; [Omeroglu, Hakan] Ufuk Univ, Fac Med, Ankara, Turkiye; [Yong, Bicheng] Beit CURE Childrens Hosp Malawi, Dept Pediat Orthopaed, Chichiri Blantyre, Malawi; [Li, Lianyong] 36 Sanhao St, Shenyang 110004, Liaoning, Peoples R China; [Canavese, Federico] Rue Eugene Avinee, F-59037 Lille, France	China Medical University; Universite de Lille; Universite de Lille; CHU Lille; University of JJ Strossmayer Osijek; University of Toronto; Hospital for Sick Children (SickKids); Columbia University; NewYork-Presbyterian Hospital; University of Abomey Calavi; Stanford University; National University of Singapore; Nagoya University; Ufuk University	Li, LY (corresponding author), 36 Sanhao St, Shenyang 110004, Liaoning, Peoples R China.; Canavese, F (corresponding author), Rue Eugene Avinee, F-59037 Lille, France.	lst634747560@163.com; canavese_federico@yahoo.fr; aaroojis@gmail.com; prof.andreacchio@gmail.com; darko.anticevic@gmail.com; maryse.bouchard@sickkids.ca; pablocastaneda@me.com; vincenzo.derosa@eoc.ch; michfiogbe@yahoo.fr; sfrick01@stanford.edu; doshuij@nus.edu.sg; drashokjohari@hotmail.com; antonioloro@libero.it; lxuemin98@hotmail.com; masakim@med.nagoya-u.ac.jp; omeroglu.h@gmail.com; dpr2@columbia.edu; maulinmshah@gmail.com; bicheng.yong@cureinternational.org; loyo_ldy@163.com			Applied Basic Research Program of Liaoning Province [2023JH2/101300022]	Applied Basic Research Program of Liaoning Province	This work was supported by the"2023 Applied Basic Research Program of Liaoning Province"(Project Number: 2023JH2/101300022).	Agha R, 2019, INT J SURG, V72, P156, DOI 10.1016/j.ijsu.2019.11.002; Canavese F, 2020, ORTHOP TRAUMATOL-SUR, V106, P1243, DOI 10.1016/j.otsr.2020.09.004; Cheng AL, 2022, CLIN ORTHOP RELAT R, V480, P325, DOI 10.1097/CORR.0000000000002044; Cheng KM, 2023, INT J SURG, V109, P1545, DOI 10.1097/JS9.0000000000000388; Den H, 2023, J EPIDEMIOL, V33, P186, DOI 10.2188/jea.JE20210074; Dimeglio A, 2001, J PEDIATR ORTHOPED, V21, P549, DOI 10.1097/00004694-200107000-00026; Fingerhut A., 2002, Oral Presentation in Medicine, P47; Gottschalk A, 2014, J CLIN ANESTH, V26, P455, DOI 10.1016/j.jclinane.2014.02.001; Greene Sarah M, 2012, Perm J, V16, P49; Haneda M, 2020, AM J SPORT MED, V48, P1647, DOI 10.1177/0363546520918804; Hermes S., 2020, Business Res, V13, P1033, DOI [10.1007/s40685-020-00125-x, DOI 10.1007/S40685-020-00125-X]; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kuitunen I, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.27638; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; Li SW., 2023, Am J Obstet Gynecol, V229, p172.; Liang SC, 2021, J PEDIATR ORTHOPED, V41, pE80, DOI 10.1097/BPO.0000000000001661; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Longo UG, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18126589; Lyu XM, 2020, J PEDIATR ORTHOP B, V29, P415, DOI 10.1097/BPB.0000000000000739; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Najafali D, 2023, AESTHET SURG J, V43, pNP591, DOI 10.1093/asj/sjad056; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Prober CG, 2023, ACAD MED, V98, P983, DOI 10.1097/ACM.0000000000005262; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Tammela O, 2013, ACTA PAEDIATR, V102, P111, DOI 10.1111/apa.12120; Temsah MH, 2023, PEDIATR RES, V94, P856, DOI 10.1038/s41390-023-02571-9; Tuncdogan A, 2017, LEADERSHIP QUART, V28, P40, DOI 10.1016/j.leaqua.2016.10.011; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Woodacre T, 2016, J CHILD ORTHOP, V10, P633, DOI 10.1007/s11832-016-0798-5	32	0	0	1	1	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0271-6798	1539-2570		J PEDIATR ORTHOPED	J. Pediatr. Orthop.	JUL	2024	44	6					e504	e511		10.1097/BPO.0000000000002682	http://dx.doi.org/10.1097/BPO.0000000000002682			8	Orthopedics; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Pediatrics	TD8G3	38597198				2024-07-03	WOS:001239409500027
J	Smoke, S				Smoke, Steven			Artificial intelligence in pharmacy: A guide for clinicians	AMERICAN JOURNAL OF HEALTH-SYSTEM PHARMACY			English	Editorial Material; Early Access						artificial intelligence; clinical decision support; clinical pharmacy; large language models; machine learning; medication use	HEALTH; FUTURE; LIMITS		[Smoke, Steven] Newark Beth Israel Med Ctr, Newark, NJ 07112 USA	Newark Beth Israel Medical Center	Smoke, S (corresponding author), Newark Beth Israel Med Ctr, Newark, NJ 07112 USA.	Steven.smoke@rwjbh.org	Smoke, Steven/KHX-5389-2024	Smoke, Steven/0000-0003-4847-3432				Bitterman DS, 2023, JAMA ONCOL, V9, P612, DOI 10.1001/jamaoncol.2023.0012; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Dvijotham K, 2023, NAT MED, DOI 10.1038/s41591-023-02437-x; England I, 2000, Aust Health Rev, V23, P176; Food and Drug Administration, 2022, Final Guidance: Clinical Decision Support Software; Food and Drug Administration, Artificial intelligence and machine learning (AI/ML)-enabled medical devices; Goodman KE, 2023, NEW ENGL J MED, P483, DOI 10.1056/NEJMp2304839; Goodman KE, 2022, OPEN FORUM INFECT DI, V9, DOI 10.1093/ofid/ofac289; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Karmakar S, 2022, IRISH J MED SCI, V191, P1991, DOI 10.1007/s11845-021-02853-3; King M, 2022, LANCET PSYCHIAT, V9, pE48, DOI 10.1016/S2215-0366(22)00312-1; Kluwer Wolters, How Sentri7 sepsis monitor helps improve outcomes; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu Y, 2019, JAMA-J AM MED ASSOC, V322, P1806, DOI 10.1001/jama.2019.16489; Lunde JL, 2007, PHARMACOTHERAPY, V27, P1202, DOI 10.1592/phco.27.8.1202; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Nelson SD, 2020, AM J HEALTH-SYST PH, V77, P1556, DOI 10.1093/ajhp/zxaa218; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Obermeyer Z, 2017, NEW ENGL J MED, V377, P1209, DOI 10.1056/NEJMp1705348; Office of the National Coordinator for Health Information Technology, Call for eCQM testing volunteers; Pak H., Unstructured Data In Healthcare; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Preininger AM, 2020, JAMIA OPEN, V3, P225, DOI 10.1093/jamiaopen/ooaa009; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Sahni NR, 2023, NEW ENGL J MED, V389, P348, DOI 10.1056/NEJMra2204673; Schutz Nick, 2020, Am J Health Syst Pharm, V77, P2015, DOI 10.1093/ajhp/zxaa249; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; US Government Accountability Office, 2021, Artificial Intelligence: An Accountability Framework for Federal Agencies and Other Entities; Vaid A, 2023, ANN INTERN MED, V176, P1358, DOI 10.7326/M23-0949; Wong A, 2023, J AM COLL CLIN PHARM, V6, P1237, DOI 10.1002/jac5.1856; Yu J, 2022, ISCIENCE, V25, DOI 10.1016/j.isci.2022.104814	34	1	1	5	5	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1079-2082	1535-2900		AM J HEALTH-SYST PH	Am. J. Health-Syst. Pharm.	2024 FEB 23	2024										10.1093/ajhp/zxae051	http://dx.doi.org/10.1093/ajhp/zxae051		FEB 2024	6	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	KH9E7	38394361				2024-07-03	WOS:001179179400001
J	Saturno, MP; Mejia, MR; Wang, AY; Kwon, D; Oleru, O; Seyidova, N; Henderson, PW				Saturno, Michael P.; Mejia, Mateo Restrepo; Wang, Anya; Kwon, Daniel; Oleru, Olachi; Seyidova, Nargiz; Henderson, Peter W.			Generative artificial intelligence fails to provide sufficiently accurate recommendations when compared to established breast reconstruction surgery guidelines	JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY			English	Letter						Large language model; ChatGPT; Artificial intelligence; Reconstructive breast surgery; Plastic and reconstructive surgery; Guidelines			[Saturno, Michael P.; Mejia, Mateo Restrepo; Wang, Anya; Kwon, Daniel; Oleru, Olachi; Seyidova, Nargiz; Henderson, Peter W.] Icahn Sch Med Mt Sinai, Div Plast & Reconstruct Surg, New York, NY 10029 USA; [Henderson, Peter W.] Icahn Sch Med Mt Sinai, Div Plast & Reconstruct Surg, 5 East 98th St, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai	Henderson, PW (corresponding author), Icahn Sch Med Mt Sinai, Div Plast & Reconstruct Surg, 5 East 98th St, New York, NY 10029 USA.	peter.henderson@mountsinai.org		Restrepo Mejia, Mateo/0009-0003-0457-3308; Wang, Anya/0009-0001-9133-027X				Alderman A, 2014, PLAST RECONSTR SURG, V134, p648E, DOI 10.1097/PRS.0000000000000541; Jeha GM, 2023, J INVEST DERMATOL, V143, P2105, DOI 10.1016/j.jid.2023.05.018; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee BT, 2017, PLAST RECONSTR SURG, V140, p651E, DOI 10.1097/PRS.0000000000003768; Perdikis G, 2022, PLAST RECONSTR SURG, V149, p392E, DOI 10.1097/PRS.0000000000008860	5	0	0	4	5	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1748-6815	1878-0539		J PLAST RECONSTR AES	J. Plast. Reconstr. Aesthet. Surg.	NOV	2023	86						248	250		10.1016/j.bjps.2023.09.030	http://dx.doi.org/10.1016/j.bjps.2023.09.030		OCT 2023	3	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	IG1K9	37793197	Green Accepted			2024-07-03	WOS:001165083300001
J	Jung, KH				Jung, Kyu-Hwan			Uncover This Tech Term: Foundation Model	KOREAN JOURNAL OF RADIOLOGY			English	Editorial Material						Foundation model; Artificial intelligence; Transformer; Large language model; ChatGPT; Representation; Few shot; Zero shot			[Jung, Kyu-Hwan] Sungkyunkwan Univ, Samsung Adv Inst Hlth Sci & Technol, Dept Med Device Management & Res, Seoul, South Korea; [Jung, Kyu-Hwan] Samsung Med Ctr, Dataset Sci Res Inst, Res Inst Future Med, Seoul, South Korea; [Jung, Kyu-Hwan] Sungkyunkwan Univ, Samsung Adv Inst Hlth Sci & Technol, Dept Med Device Management & Res, 115 Irwon Ro, Seoul 06355, South Korea	Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); Samsung Medical Center	Jung, KH (corresponding author), Sungkyunkwan Univ, Samsung Adv Inst Hlth Sci & Technol, Dept Med Device Management & Res, 115 Irwon Ro, Seoul 06355, South Korea.	khwanjung@skku.edu		Jung, Kyu-Hwan/0000-0002-6626-6800				Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Fei NY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30761-2; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gu JD, 2023, Arxiv, DOI arXiv:2307.12980; Harshvardhan GM, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100285; Huang Z, 2023, NAT MED, V29, P2307, DOI 10.1038/s41591-023-02504-3; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kirillov A, Segment Anything; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Li J, 2023, Arxiv, DOI [arXiv:2303.12311, 10.48550/arXiv.2303.12311]; Liu ZL, 2024, Arxiv, DOI [arXiv:2306.08666, DOI 10.48550/ARXIV.2306.08666, 10.48550/arXiv.2306.08666]; Ma J, 2024, Arxiv, DOI [arXiv:2304.12306, DOI 10.48550/ARXIV.2304.12306]; Radford A, 2021, PR MACH LEARN RES, V139; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Tian SB, 2023, Arxiv, DOI [arXiv:2306.10070, 10.48550/arXiv.2306.10070]; Tiu E, 2022, NAT BIOMED ENG, V6, P1399, DOI 10.1038/s41551-022-00936-9; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang GY, 2023, Arxiv, DOI [arXiv:2306.09968, 10.48550/arXiv.2306.09968]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu CY, 2023, Arxiv, DOI [arXiv:2308.02463, DOI 10.48550/ARXIV.2308.02463]; Zhang K, 2024, Arxiv, DOI [arXiv:2305.17100, DOI 10.48550/ARXIV.2305.17100]; Zhou JX, 2023, Arxiv, DOI [arXiv:2304.10691, 10.48550/arXiv.2304.10691, DOI 10.48550/ARXIV.2304.10691]	30	7	7	7	9	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	OCT	2023	24	10					1038	1041		10.3348/kjr.2023.0790	http://dx.doi.org/10.3348/kjr.2023.0790			4	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	Z0CB8	37793672	Green Published			2024-07-03	WOS:001108838500004
C	Nakanishi, T			IEEE	Nakanishi, Takafumi			An Inquirer-Responder Architecture Using LLMs: Emulating Virtual Hearing Q&A in Education	2023 IEEE INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT			English	Proceedings Paper	22nd IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	OCT 26-29, 2023	Venice, ITALY	Inst Elect & Elect Engineers, IEEE Comp Soc, Web Intelligence Consortium, Ca Foscari Univ Venice, IOS Press		inquirer-responder architecture; Large Language Model (LLM); educational applications; automatic feedback comment generation; document understanding		This paper presents an Inquirer-Responder architecture consisting of multiple LLM instances and applies it to a method for automatically generating feedback comments on student reports by emulating virtual hearing Q&A. This method uses faculty education materials and student reports as inputs for multiple LLM instances. In education, quickly returning personalized feedback to each student is crucial but burdensome for faculty. The implementation of a system that automatically and promptly returns feedback on student submissions can improve student learning efficiency and reduce the faculty workload. Our proposed architecture consists of two LLM instances, referred to as inquirer and responder. The inquirer is an LLM instance that reads the material (e.g., lecture materials) provided by the faculty, poses questions, and evaluates the responses from the responder. The responder is an LLM instance that reads student submissions (e.g., reports) and answers questions posed by the inquirer based on the contents of those submissions. This architecture uses faculty materials and student submissions to emulate a virtual hearing, with evaluation based on the knowledge extracted from both the faculty materials and student submissions. This architecture can be applied to various systems that automatically and quickly check submissions and return feedback. In this study, we established a hypothetical use case for a university class and conducted experiments. As a result, there were some cases in which the evaluation was difficult owing to the performance of the current LLM. However, the proposed architecture provides a new perspective on the design of automatic feedback systems and is a step toward their improvement.	[Nakanishi, Takafumi] Musashino Univ, Dept Data Sci, Tokyo, Japan		Nakanishi, T (corresponding author), Musashino Univ, Dept Data Sci, Tokyo, Japan.	takafumi.nakanishi@musashino-u.ac.jp	Nakanishi, Takafumi/HKP-2510-2023; Nakanishi, Takafumi/JXN-6051-2024	Nakanishi, Takafumi/0000-0003-1029-6063; 				Abdelghani R, 2024, INT J ARTIF INTELL E, V34, P483, DOI 10.1007/s40593-023-00340-7; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bhat S., 2022, P 15 INT C ED DATA M, V701; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dijkstra R., 2022, Reading comprehension quiz generation using generative pre-trained transformers; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jia QJ, 2021, Arxiv, DOI [arXiv:2110.03895, DOI 10.48550/ARXIV.2110.03895, 10.48550/arXiv.2110.03895]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Moore S, 2022, LECT NOTES COMPUT SC, V13450, P243, DOI 10.1007/978-3-031-16290-9_18; Page SE, 2007, DIFFERENCE: HOW THE POWER OF DIVERSITY CREATES BETTER GROUPS, FIRMS, SCHOOLS, AND SOCIETIES, P1; Wu QY, 2023, Arxiv, DOI arXiv:2308.08155	12	0	0	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0918-8				2023							526	533		10.1109/WI-IAT59888.2023.00088	http://dx.doi.org/10.1109/WI-IAT59888.2023.00088			8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3LB					2024-07-03	WOS:001139644800081
J	Rillig, MC; Kasirzadeh, A				Rillig, Matthias C.; Kasirzadeh, Atoosa			AI Personal Assistants and Sustainability: Risks and Opportunities	ENVIRONMENTAL SCIENCE & TECHNOLOGY			English	Editorial Material						AI personal assistants; large language models; environmental education; environmental impact; digital divide; environmental literacy; artificial intelligence			[Rillig, Matthias C.] Free Univ Berlin, Inst Biol, D-14195 Berlin, Germany; [Rillig, Matthias C.] Berlin Brandenburg Inst Adv Biodivers Res BBIB, D-14195 Berlin, Germany; [Kasirzadeh, Atoosa] Univ Edinburgh, Edinburgh Futures Inst, Edinburgh EH3 9EF, Scotland; [Kasirzadeh, Atoosa] Alan Turing Inst, London NW1 2DB, England	Free University of Berlin; University of Edinburgh	Rillig, MC (corresponding author), Free Univ Berlin, Inst Biol, D-14195 Berlin, Germany.; Rillig, MC (corresponding author), Berlin Brandenburg Inst Adv Biodivers Res BBIB, D-14195 Berlin, Germany.	matthias.rillig@fu-berlin.de	Rillig, Matthias/B-3675-2009	Rillig, Matthias/0000-0003-3541-7853				Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Crawford Kate, 2024, Nature, V626, P693, DOI 10.1038/d41586-024-00478-x; Hu Q, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102250; Kasirzadeh A., 2024, ARXIV; Messeri L, 2024, NATURE, V627, P49, DOI 10.1038/s41586-024-07146-0; Ponciano R, 2015, PROCEDIA COMPUT SCI, V52, P310, DOI 10.1016/j.procs.2015.05.090; Rillig MC, 2024, ECOL LETT, V27, DOI 10.1111/ele.14397; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Silva AD, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113193; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Yeung LKC, 2023, AI SOC, DOI 10.1007/s00146-023-01776-0	11	0	0	14	14	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0013-936X	1520-5851		ENVIRON SCI TECHNOL	Environ. Sci. Technol.	APR 18	2024	58	17					7237	7239		10.1021/acs.est.4c03300	http://dx.doi.org/10.1021/acs.est.4c03300		APR 2024	3	Engineering, Environmental; Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Environmental Sciences & Ecology	RD6E8	38634356	hybrid			2024-07-03	WOS:001205546900001
J	Haindl, P; Weinberger, G				Haindl, Philipp; Weinberger, Gerald			Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course	IEEE ACCESS			English	Article						Chatbots; Codes; Programming profession; Task analysis; Education; Artificial intelligence; Surveys; Programming education; ChatGPT; generative AI; large language models		Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students' learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT's generated code to the exercises' implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education.	[Haindl, Philipp; Weinberger, Gerald] St Polten Univ Appl Sci, Dept Comp Sci & Secur, A-3100 St Polten, Austria	St. Polten University of Applied Sciences	Haindl, P (corresponding author), St Polten Univ Appl Sci, Dept Comp Sci & Secur, A-3100 St Polten, Austria.	philipp.haindl@fhstp.ac.at		Haindl, Philipp/0000-0001-6075-5286				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Adolph S, 2011, EMPIR SOFTW ENG, V16, P487, DOI 10.1007/s10664-010-9152-6; [Anonymous], 2024, Prompt Engineering for Educators-Making Generative AI Work for You.; Benotti L, 2018, IEEE T LEARN TECHNOL, V11, P179, DOI 10.1109/TLT.2017.2682084; Bull C, 2024, IEEE SOFTWARE, V41, P52, DOI 10.1109/MS.2023.3300574; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Sáiz-Manzanares MC, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e12843; Daun M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P110, DOI 10.1145/3587102.3588815; Essel HB, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00362-6; Urquiza-Yllescas JF, 2022, J INTELL FUZZY SYST, V43, P5095, DOI 10.3233/JIFS-213275; Golafshani N., 2003, QUAL REP, V8, P597, DOI [DOI 10.46743/2160-3715/2003.1870, 10.46743/2160-3715/2003.1870]; Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93; Jacques Lorraine, 2023, ACM Inroads, P40, DOI 10.1145/3595634; Karyotaki M., 2022, Technium Social Sciences Journal, V30, P109; Kazemitabaar M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580919; Lee K., 2019, HCI International 2019-Posters: 21st International Conference, HCII 2019, Orlando, FL, USA, July 26-31, 2019, Proceedings, Part I 21, P348; Ndukwe IG, 2019, LECT NOTES ARTIF INT, V11626, P365, DOI 10.1007/978-3-030-23207-8_67; Nguyen H, 2023, COMPUT EDUC, V192, DOI 10.1016/j.compedu.2022.104661; Nguyen T. T., 2021, Comput. Educ.,Artif. Intell., V2; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Onwuegbuzie AJ, 2007, QUAL QUANT, V41, P233, DOI 10.1007/s11135-006-9000-3; Opara E., 2023, Glob Acad J Humanit Soc Sci, V5, P33, DOI DOI 10.36348/GAJHSS.2023.V05I02.001; Ouh EL, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P54, DOI 10.1145/3587102.3588794; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3278056; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3248401; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Savelka J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P117, DOI 10.1145/3587102.3588792; Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862; Sweller J., 2011, Cognitive load theory, P111, DOI [DOI 10.1007/978-1-4419-8126-4_9, 10.1007/978-1-4419-8126-4_92]; Sweller J., 2011, COGNITIVE LOAD THEOR, P99; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Yang S., 2019, PROC 3 INT C ED E LE	32	0	0	40	40	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						43519	43529		10.1109/ACCESS.2024.3380909	http://dx.doi.org/10.1109/ACCESS.2024.3380909			11	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	ML3S0		gold			2024-07-03	WOS:001193742900001
J	Nyqvist, R; Peltokorpi, A; Seppänen, O				Nyqvist, Roope; Peltokorpi, Antti; Seppanen, Olli			Can ChatGPT exceed humans in construction project risk management?	ENGINEERING CONSTRUCTION AND ARCHITECTURAL MANAGEMENT			English	Article						Artificial intelligence (AI); Large language models (LLM); ChatGPT; GPT-4; Risk management; Construction management; Project management; Risk analysis		PurposeThe objective of this research is to investigate the capabilities of the ChatGPT GPT-4 model, a form of artificial intelligence (AI), in comparison to human experts in the context of construction project risk management.Design/methodology/approachEmploying a mixed-methods approach, the study draws a qualitative and quantitative comparison between 16 human risk management experts from Finnish construction companies and the ChatGPT AI model utilizing anonymous peer reviews. It focuses primarily on the areas of risk identification, analysis, and control.FindingsChatGPT has demonstrated a superior ability to generate comprehensive risk management plans, with its quantitative scores significantly surpassing the human average. Nonetheless, the AI model's strategies are found to lack practicality and specificity, areas where human expertise excels.Originality/valueThis study marks a significant advancement in construction project risk management research by conducting a pioneering blind-review study that assesses the capabilities of the advanced AI model, GPT-4, against those of human experts. Emphasizing the evolution from earlier GPT models, this research not only underscores the innovative application of ChatGPT-4 but also the critical role of anonymized peer evaluations in enhancing the objectivity of findings. It illuminates the synergistic potential of AI and human expertise, advocating for a collaborative model where AI serves as an augmentative tool, thereby optimizing human performance in identifying and managing risks.	[Nyqvist, Roope] Aalto Univ, Sch Engn, Espoo, Finland; [Peltokorpi, Antti; Seppanen, Olli] Insinooritieteiden Korkeakoulu, Dept Civil Engn, Espoo, Finland	Aalto University	Nyqvist, R (corresponding author), Aalto Univ, Sch Engn, Espoo, Finland.	roope.nyqvist@aalto.fi; antti.peltokorpi@aalto.fi; olli.seppanen@aalto.fi	Seppänen, Olli/G-1594-2015	Seppänen, Olli/0000-0002-2008-5924; Nyqvist, Roope/0000-0003-0711-1574				Abioye SO, 2021, J BUILD ENG, V44, DOI 10.1016/j.jobe.2021.103299; Agarwal R., 2016, Imagining construction's digital future; Akinosho TD, 2020, J BUILD ENG, V32, DOI 10.1016/j.jobe.2020.101827; Aladag H, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su152216071; [Anonymous], 2021, Pulse of the profession 2021; [Anonymous], 2016, CONSTRUCTION EXTENSI; Arabi S, 2022, J CONSTR ENG M, V148, DOI 10.1061/(ASCE)CO.1943-7862.0002310; Armstrong G., 2023, FAMILIAR CHALLENGES; Barcaui A., 2023, PROJECT LEADERSHIP S, V4, P1, DOI [10.1016/j.plas.2023.100101, DOI 10.1016/J.PLAS.2023.100101]; Chapman C., 2011, MANAGE PROJECT OPPOR, DOI [10.1002/9781119208587, DOI 10.1002/9781119208587]; Chui M., 2023, The economic potential of generative AI; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; Ghimire P., 2023, ARXIV, P1, DOI [10.48550/arXiv2310.04427, DOI 10.48550/ARXIV2310.04427]; Google, 2023, GEMINI FAMILY HIGHLY; Hofert M, 2023, RISKS, V11, DOI 10.3390/risks11090166; International Organization for Standardization, 2018, INT STANDARD ISO 310; Kamari M, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104091; Kim JY, 2022, INFORM TECHNOL PEOPL, V35, P861, DOI 10.1108/ITP-04-2019-0173; Klepo M.S., 2023, P CREATIVE CONSTRUCT, P1, DOI [10.3311/CCC2023-028, DOI 10.3311/CCC2023-028]; Liu T, 2019, FACILITIES, V37, P254, DOI 10.1108/F-08-2017-0078; Maldonato M., 2011, World Futures, V67, P569, DOI [DOI 10.1080/02604027.2011.615591, 10.1080/02604027.2011.615591]; Monaghan TF, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57070647; Nyqvist R, 2024, CONSTR MANAG ECON, V42, P346, DOI 10.1080/01446193.2023.2266760; OpenAI, 2023, GPT 4 TECHNICAL REPO; Rane N.L., 2023, SSRN, P1, DOI DOI 10.2139/SSRN.4598258; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Ribeiro D., 2021, IND 40 BUILT ENV MET; Shoham N, 2021, BJPSYCH ADV, V27, P247, DOI 10.1192/bja.2020.61; Smith N., 2006, Managing risk in construction projects; Touvron H., 2023, Llama: Open and efficient foundation language models; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Zhao XB, 2024, ENG CONSTR ARCHIT MA, V31, P1408, DOI 10.1108/ECAM-09-2022-0853	32	0	0	48	48	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	0969-9988	1365-232X		ENG CONSTR ARCHIT MA	Eng. Constr. Archit. Manag.	MAR 25	2024	31	13					223	243		10.1108/ECAM-08-2023-0819	http://dx.doi.org/10.1108/ECAM-08-2023-0819		MAR 2024	21	Engineering, Industrial; Engineering, Civil; Management	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Engineering; Business & Economics	LZ5K6		hybrid			2024-07-03	WOS:001189055900001
J	Chavez, MR; Butler, TS; Rekawek, P; Heo, H; Kinzler, WL				Chavez, Martin R.; Butler, Thomas S.; Rekawek, Patricia; Heo, Hye; Kinzler, Wendy L.			Chat Generative Pre-trained Transformer: why we should embrace this technology	AMERICAN JOURNAL OF OBSTETRICS AND GYNECOLOGY			English	Article						artificial intelligence; Chat Generative Pre-trained Transformer; future of medicine; large language models; OpenAI; plain conversational language interfaces		With the advent of artificial intelligence that not only can learn from us but also can communicate with us in plain language, humans are embarking on a brave new future. The interaction between humans and artificial intelligence has never been so widespread. Chat Generative Pre-trained Transformer is an artificial intelligence resource that has potential uses in the practice of medicine. As clinicians, we have the opportunity to help guide and develop new ways to use this powerful tool. Optimal use of any tool requires a certain level of comfort. This is best achieved by appreciating its power and limitations. Being part of the process is crucial in maximizing its use in our field. This clinical opinion demonstrates the potential uses of Chat Generative Pre-trained Transformer for obstetrician-gynecologists and encourages readers to serve as the driving force behind this resource.	[Chavez, Martin R.; Rekawek, Patricia; Heo, Hye; Kinzler, Wendy L.] NYU Langone Hosp Long Isl, NYU Long Isl Sch Med, Dept Obstet Gynecol, Div Maternal Fetal Med, Mineola, NY 11501 USA; [Butler, Thomas S.] NYU Langone Hosp Long Isl, NYU Langone Long Isl Sch Med, NYU Langone Reprod Specialists New York, Mineola, NY USA		Chavez, MR (corresponding author), NYU Langone Hosp Long Isl, NYU Long Isl Sch Med, Dept Obstet Gynecol, Div Maternal Fetal Med, Mineola, NY 11501 USA.	Martin.Chavez@nyulangone.org		Butler, Thomas/0000-0003-1515-0098; Chavez, Martin/0000-0003-2452-715X				Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19; Bavarian M, 2022, Arxiv, DOI [arXiv:2207.14255, 10.48550/arXiv.2207.14255]; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Buchholz K., 2023, ChatGPT sprints to one million users; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; Das R, 2022, INTERDISCIP SCI, V14, P566, DOI 10.1007/s12539-022-00515-1; Dhombres F, 2022, J MED INTERNET RES, V24, DOI 10.2196/35465; Doshi RH, 2023, STAT; Doximity, 2023, FREE CHATGPT COLL DO; Drukker L, 2020, ULTRASOUND OBST GYN, V56, P498, DOI 10.1002/uog.22122; Elsevier AJOG, 2023, DUT AUTH US AI AI AS; Emin EI, 2019, IN VIVO, V33, P1547, DOI 10.21873/invivo.11635; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Hughes A, 2023, SCI FOCUS; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; OBrien M., 2023, AP News; OpenAI, 2023, NTROD GPT 4 OPENAIS; OpenAI, 2023, ABOUT US; OpenAI, 2022, OpenA I; OpenAI. GPT, 2023, CHATGPT TEXT INP PAG; Sarno L, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2022.100792; Sharma A., 2022, Bleeping Computer; Shen YT, 2021, EUR J RADIOL, V139, DOI 10.1016/j.ejrad.2021.109717; Southern M.G., 2023, OpenAI's ChatGPT update brings improved accuracy; Stermer C, 2022, CHATGPT SAVE TIME IN; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Yurkevich V, 2023, Experts warn about possible misuse of new ai tool chatgpt	32	22	24	37	86	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0002-9378	1097-6868		AM J OBSTET GYNECOL	Am. J. Obstet. Gynecol.	JUN	2023	228	6					706	711		10.1016/j.ajog.2023.03.010	http://dx.doi.org/10.1016/j.ajog.2023.03.010		JUN 2023	6	Obstetrics & Gynecology	Science Citation Index Expanded (SCI-EXPANDED)	Obstetrics & Gynecology	K3GB5	36924908				2024-07-03	WOS:001015344500001
C	Wang, YH; Xu, N; Tian, HS; Lv, B; Duan, YL; Li, XY; Liu, AA			IEEE	Wang, Yanhui; Xu, Ning; Tian, Hongshuo; Lv, Bo; Duan, YuLong; Li, Xuanya; Liu, An-An			Knowledge Prompt Makes Composed Pre-Trained Models Zero-Shot News Captioner	2023 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, ICME	IEEE International Conference on Multimedia and Expo		English	Proceedings Paper	IEEE International Conference on Multimedia and Expo (ICME)	JUL 10-14, 2023	Brisbane, AUSTRALIA	IEEE, IEEE Circuits & Syst Soc, IEEE Commun Soc, IEEE Comp Soc, IEEE Signal Proc Soc, TENCENT, Meta, Youtube, Google		News Image Captioning; Image Captioning; Zero-Shot Inference; Large Language Model; Transformer; Vision and Language		News image captioning aims to generate descriptions containing concrete named entities for news images by leveraging relevant news articles. However, existing approaches suffer from two shortcomings: 1) lack of commonsense knowledge required to understand named entities, and 2) limited multimodal context modeling capabilities. In this paper, we propose to migrate the ability of large-scale pre-trained models for news image captioning. To acquire factual knowledge for describing named entities, we induce a pre-trained language model for commonsense knowledge reasoning using context-aware knowledge prompts. To compose a new multimodal context modeling capability, we coordinate pre-trained models by a unified language representation and constrain joint multimodal context reasoning with cross-modal consistency objective. Experimental results on GoodNews and NYTimes datasets show that our proposed method exhibits considerable captioning capabilities even without training on news data.	[Wang, Yanhui; Xu, Ning; Tian, Hongshuo; Liu, An-An] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China; [Wang, Yanhui; Liu, An-An] Inst Artificial Intelligence Sci Ctr, Hefei, Peoples R China; [Lv, Bo; Duan, YuLong] China Elect Technol Corp, Res Inst 30, Chengdu, Peoples R China; [Li, Xuanya] Baidu Inc, Beijing, Peoples R China	Tianjin University; Baidu	Li, XY (corresponding author), Baidu Inc, Beijing, Peoples R China.	wangyanhui@tju.edu.cn; ningxu@tju.edu.cn; kellyeden@tju.edu.cn; lv1985bo@163.com; thor830428@163.com; lixuanya@baidu.com; anan0422@gmail.com	WANG, Yanhui/AAS-3446-2020	WANG, Yanhui/0000-0002-3214-2711	National Natural Science Foundation of China [U21B2024, U22A2068, 62002257]; China Postdoctoral Science Foundation [2021M692395]; Baidu Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Baidu Program	This work was supported in part by the National Natural Science Foundation of China (U21B2024, U22A2068, 62002257), the China Postdoctoral Science Foundation (2021M692395), and the Baidu Program.	Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Flick Carlos, 2018, ACL WORKSH; Biten AF, 2019, PROC CVPR IEEE, P12458, DOI 10.1109/CVPR.2019.01275; Heinzerline B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1772; Hu AW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4217, DOI 10.1145/3394171.3413576; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Li J., 2022, International Conference on Machine Learning, V162, P12888, DOI DOI 10.48550/ARXIV.2201.12086; Liu FX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6761; Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Ramisa A, 2018, IEEE T PATTERN ANAL, V40, P1072, DOI 10.1109/TPAMI.2017.2721945; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Tewel Y, 2022, PROC CVPR IEEE, P17897, DOI 10.1109/CVPR52688.2022.01739; Tran Alasdair, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13032, DOI 10.1109/CVPR42600.2020.01305; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang P., 2022, INT C MACHINE LEARNI, P23318; Wang ZHL, 2022, Arxiv, DOI arXiv:2205.10747; Wei Jiaheng, 2022, ICLR; Zhao WT, 2021, Arxiv, DOI arXiv:2107.11970	26	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1945-7871		978-1-6654-6891-6	IEEE INT CON MULTI			2023							2879	2884		10.1109/ICME55011.2023.00489	http://dx.doi.org/10.1109/ICME55011.2023.00489			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV6UD					2024-07-03	WOS:001062707300468
J	Wan, H; Luo, HZ; Li, MY; Luo, XY				Wan, Han; Luo, Hongzhen; Li, Mengying; Luo, Xiaoyan			Automated Program Repair for Introductory Programming Assignments	IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES			English	Article						Codes; Maintenance engineering; Programming profession; Context modeling; Syntactics; Computer bugs; Problem-solving; Large language model; program repair; programming education	GENERATION	Automatic program repair (APR) tools are valuable for students to assist them with debugging tasks since program repair captures the code modification to make a buggy program pass the given test-suite. However, the process of manually generating catalogs of code modifications is intricate and time-consuming. This article proposes contextual error model repair (CEMR), an automated program repair tool for introductory programming assignments. CEMR is designed to learn program code modifications from incorrect-correct code pairs automatically. Then, it utilizes these code modifications along with CodeBERT, a generative AI, to repair students' new incorrect programs in the same programming assignment. CEMR builds on the observation that code edits performed by students in pairs of incorrect-correct code can be used as input-output examples for learning code modifications. The key idea of CEMR is to leverage the wisdom of the crowd: it uses the existing code modifications of incorrect-correct student code pairs to repair the new incorrect student attempts. We chose three of the most related APR tools, Refazer, Refactory, and AlphaRepair, as the baselines to compare against CEMR. The experimental results demonstrate that, on public and real classroom datasets, CEMR achieves higher repair rates than the baselines. Through further analysis, CEMR has demonstrated promising effectiveness in addressing semantical and logical errors while its performance in fixing syntactical errors is limited. In terms of time for repairing buggy programs, CEMR costs approximately half as much as AlphaRepair requires. We opine that CEMR not only be seen as a program repair method that achieves good results with incorrect-correct code pairs but also be further utilized to generate hints to better assist students in learning programming.	[Wan, Han; Luo, Hongzhen; Li, Mengying] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Luo, Xiaoyan] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China	Beihang University; Beihang University	Luo, XY (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.	wanhan@buaa.edu.cn; luohz@buaa.edu.cn; mengyingli@buaa.edu.cn; luoxy@buaa.edu.cn	Luo, Xiaoyan/KSM-6392-2024	Luo, Xiaoyan/0000-0002-7256-4329	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	An G, 2018, 2018 ACM/IEEE 4TH INTERNATIONAL GENETIC IMPROVEMENT WORKSHOP (GI@ICSE 2018), P19, DOI 10.1145/3194810.3194814; Barnes T, 2008, LECT NOTES COMPUT SC, V5091, P373; Carter J., 2015, P 46 ACM TECH S COMP, P241, DOI [10.1145/2676723.2677294.2C.L., DOI 10.1145/2676723.2677294.2C.L]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Fluri B, 2007, IEEE T SOFTWARE ENG, V33, P725, DOI 10.1109/TSE.2007.70731; Gao L, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P164, DOI 10.1145/3300115.3309515; Gross S, 2014, INT J LEARN TECHNOL, V9, P248, DOI 10.1504/IJLT.2014.065752; Gulwani S, 2018, PROCEEDINGS OF THE 39TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, PLDI 2018, P465, DOI [10.1145/3192366.3192387, 10.1145/3296979.3192387]; Nguyen HDT, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P772, DOI 10.1109/ICSE.2013.6606623; Hu Y, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P388, DOI 10.1109/ASE.2019.00044; Hua JR, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P888, DOI 10.1145/236024.3264600; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Kim D, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P802, DOI 10.1109/ICSE.2013.6606626; Kolak R., 2022, P INT C LEARN REPR W, P1; Koyuncu A, 2020, EMPIR SOFTW ENG, V25, P1980, DOI 10.1007/s10664-019-09780-z; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Le XBD, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P213, DOI 10.1109/SANER.2016.76; Liu K, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P31, DOI 10.1145/3293882.3330577; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Marwan S, 2023, IEEE T LEARN TECHNOL, V16, P399, DOI 10.1109/TLT.2022.3223577; Marwan S, 2022, IEEE T LEARN TECHNOL, V15, P406, DOI 10.1109/TLT.2022.3180984; McBroom J, 2018, LECT NOTES ARTIF INT, V10947, P324, DOI 10.1007/978-3-319-93843-1_24; McCall D, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3335814; Mechtaev S, 2016, PROC INT CONF SOFTW, P691, DOI 10.1145/2884781.2884807; Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365; Ngo NV, 2022, Arxiv, DOI arXiv:2105.07918; Piech C., 2015, P 2 ACM C LEARN SCAL, P195, DOI DOI 10.1145/2724660.2724668.20T.W; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Price T., 2015, P EDM WORKSH, P1; Price T.W., 2016, Proceedings of the 9th International Conference on Educational Data Mining pp, P191; Ray B, 2016, PROC INT CONF SOFTW, P428, DOI 10.1145/2884781.2884848; Rivers Kelly, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P591, DOI 10.1007/978-3-642-30950-2_80; Rivers K., 2013, 1 WORKSH AI SUPP ED, P50; Rivers K, 2017, INT J ARTIF INTELL E, V27, P37, DOI 10.1007/s40593-015-0070-z; Rolim R, 2017, PROC INT CONF SOFTW, P404, DOI 10.1109/ICSE.2017.44; Schulman J, 2022, Introducing chatgpt; Singh R, 2013, ACM SIGPLAN NOTICES, V48, P15, DOI 10.1145/2499370.2462195; Solar-Lezama A., 2008, Ph.D. dissertation; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wen M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/3180155.3180233; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xia CS, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P959, DOI 10.1145/3540250.3549101; ZHANG KZ, 1989, SIAM J COMPUT, V18, P1245, DOI 10.1137/0218082	44	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1939-1382			IEEE T LEARN TECHNOL	IEEE Trans. Learn. Technol.		2024	17						1745	1760		10.1109/TLT.2024.3403710	http://dx.doi.org/10.1109/TLT.2024.3403710			16	Computer Science, Interdisciplinary Applications; Education & Educational Research	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Education & Educational Research	UH9P7					2024-07-03	WOS:001247287100003
J	Madyatmadja, ED; Sianipar, CPM; Wijaya, C; Sembiring, DJM				Madyatmadja, Evaristus D.; Sianipar, Corinthias P. M.; Wijaya, Cristofer; Sembiring, David J. M.			Classifying Crowdsourced Citizen Complaints through Data Mining: Accuracy Testing of k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost	INFORMATICS-BASEL			English	Article						public complaint; citizen science; crowdsourcing; sustainable city; machine learning; smart city; knowledge extraction; text mining; large language model; generative AI	E-GOVERNMENT; CLASSIFICATION; SVM; MANAGEMENT; ALGORITHM; CHINA; KNN	Crowdsourcing has gradually become an effective e-government process to gather citizen complaints over the implementation of various public services. In practice, the collected complaints form a massive dataset, making it difficult for government officers to analyze the big data effectively. It is consequently vital to use data mining algorithms to classify the citizen complaint data for efficient follow-up actions. However, different classification algorithms produce varied classification accuracies. Thus, this study aimed to compare the accuracy of several classification algorithms on crowdsourced citizen complaint data. Taking the case of the LAKSA app in Tangerang City, Indonesia, this study included k-Nearest Neighbors, Random Forest, Support Vector Machine, and AdaBoost for the accuracy assessment. The data were taken from crowdsourced citizen complaints submitted to the LAKSA app, including those aggregated from official social media channels, from May 2021 to April 2022. The results showed SVM with a linear kernel as the most accurate among the assessed algorithms (89.2%). In contrast, AdaBoost (base learner: Decision Trees) produced the lowest accuracy. Still, the accuracy levels of all algorithms varied in parallel to the amount of training data available for the actual classification categories. Overall, the assessments on all algorithms indicated that their accuracies were insignificantly different, with an overall variation of 4.3%. The AdaBoost-based classification, in particular, showed its large dependence on the choice of base learners. Looking at the method and results, this study contributes to e-government, data mining, and big data discourses. This research recommends that governments continuously conduct supervised training of classification algorithms over their crowdsourced citizen complaints to seek the highest accuracy possible, paving the way for smart and sustainable governance.	[Madyatmadja, Evaristus D.; Wijaya, Cristofer] Bina Nusantara Univ, Informat Syst Dept, Jakarta 11530, Indonesia; [Sianipar, Corinthias P. M.] Kyoto Univ, Dept Global Ecol, Kyoto 6068501, Japan; [Sianipar, Corinthias P. M.] Kyoto Univ, Div Environm Sci & Technol, Sakyo Ku, Kyoto 6068502, Japan; [Sembiring, David J. M.] Indonesian Inst Technol & Business ITBI, Deli Serdang 20374, Indonesia	Universitas Bina Nusantara; Kyoto University; Kyoto University	Madyatmadja, ED (corresponding author), Bina Nusantara Univ, Informat Syst Dept, Jakarta 11530, Indonesia.; Sianipar, CPM (corresponding author), Kyoto Univ, Dept Global Ecol, Kyoto 6068501, Japan.; Sianipar, CPM (corresponding author), Kyoto Univ, Div Environm Sci & Technol, Sakyo Ku, Kyoto 6068502, Japan.	emadyatmadja@binus.edu; iam@cpmsianipar.com	Sianipar, Corinthias P. M./J-4952-2012	Sianipar, Corinthias P. M./0000-0003-0718-6162	Research and Technology Transfer Office (RTTO), Bina Nusantara University	Research and Technology Transfer Office (RTTO), Bina Nusantara University	The authors would like to thank the government officers of Tangerang City for their help in the acquisition of the crowdsourced citizen complaint data used in this research.	Adeniyi D. A., 2016, Applied Computing and Informatics, V12, P90, DOI 10.1016/j.aci.2014.10.001; Ahmad I, 2018, IEEE ACCESS, V6, P33789, DOI 10.1109/ACCESS.2018.2841987; Airports Council International, 2022, Annual World Airport Traffic Report: 2022 Edition; Almira P.D., 2019, P 15 INT AS URB C, P355, DOI [10.1007/978-981-15-5608-1_28, DOI 10.1007/978-981-15-5608-1_28]; Almunawar MN, 2022, ROU ADV ORG LEARN KN, pXV; Alsaidi S.A., 2020, Bull. Electr. Eng. Inform, V9, P1701, DOI [10.11591/eei.v9i4.1898, DOI 10.11591/EEI.V9I4.1898]; Angeline M., 2016, Humaniora, V7, P441, DOI [10.21512/humaniora.v7i4.3597, DOI 10.21512/HUMANIORA.V7I4.3597]; [Anonymous], 2018, Government of Indonesia Peraturan Presiden (Perpres) No. 95 Tahun 2018 Tentang Sistem Pemerintahan Berbasis Elektronik. Pub. L. No. 95/2018; Archer KJ, 2008, COMPUT STAT DATA AN, V52, P2249, DOI 10.1016/j.csda.2007.08.015; Awajan Albara, 2022, International Journal of Internet Technology and Secured Transactions, P387, DOI 10.1504/IJITST.2022.125788; Bakunzibake P, 2019, BUS SYST RES J, V10, P53, DOI 10.2478/bsrj-2019-0005; Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011; Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25; Blumenthal D, 2020, NEW ENGL J MED, V383, P1483, DOI 10.1056/NEJMsb2021088; Boateng E.Y., 2020, J. Data Anal. Inf. Process, V8, P341, DOI DOI 10.4236/JDAIP.2020.84020; Borges L.C., 2013, Proceedings of the International C* Conference on Computer Science and Software Engineering, P113, DOI [DOI 10.1145/2494444.2494451, 10.1145/2494444.2494451]; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Bzdok D, 2017, NAT METHODS, V14, P1119, DOI 10.1038/nmeth.4526; Cheng MY, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103265; Christian H., 2016, ComTech: Comput. Math. Eng. Appl., V7, P285, DOI DOI 10.21512/COMTECH.V7I4.3746; Condrobimo A.R., 2016, ComTech Comput. Math. Eng. Appl, V7, P151, DOI [10.21512/comtech.v7i2.2256, DOI 10.21512/COMTECH.V7I2.2256]; Cury RM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0208-1; Denisko D, 2018, P NATL ACAD SCI USA, V115, P1690, DOI 10.1073/pnas.1800256115; Devos O, 2014, FOOD CHEM, V148, P124, DOI 10.1016/j.foodchem.2013.10.020; Dhote S, 2020, ELECTRON COMMER RES, V20, P259, DOI 10.1007/s10660-019-09383-2; Dias D, 2023, INFORMATICS-BASEL, V10, DOI 10.3390/informatics10010017; Dimitrov MK, 2014, E EUR POLIT SOC, V28, P271, DOI 10.1177/0888325413506933; Dudhat A., 2023, IAIC Trans. Sustain. Digit. Innov. ITSDI, V4, P109, DOI [10.34306/itsdi.v4i2.580, DOI 10.34306/ITSDI.V4I2.580]; El Alaoui I, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0120-0; Epp DA, 2023, POLIT RES QUART, V76, P3, DOI 10.1177/10659129211070306; Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028; Fan WG, 2006, COMMUN ACM, V49, P77, DOI 10.1145/1151030.1151032; Freeman J., 2013, Media Asia, V40, P354, DOI [10.1080/01296612.2013.11689988, DOI 10.1080/01296612.2013.11689988]; Freund Y., 1996, P 13 INT C MACH LEAR, V96, P148; Goel S., 2013, Global Journal of Flexible Systems Management, V13, P233, DOI DOI 10.1007/S40171-013-0021-1; Gong YH, 2023, Arxiv, DOI [arXiv:2307.13221, 10.48550/arxiv.2307.13221, DOI 10.48550/ARXIV.2307.13221]; Guo F, 2017, J PHYS CONF SER, V910, DOI 10.1088/1742-6596/910/1/012021; Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986; Halachmi A, 2013, PUBLIC PERFORM MANAG, V36, P562, DOI 10.2753/PMR1530-9576360404; Handayeni K.D.M.E., 2018, IOP Conf. Ser. Earth Environ. Sci, V202, P012019, DOI [10.1088/1755-1315/202/1/012019, DOI 10.1088/1755-1315/202/1/012019]; Hariri RH, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0206-3; Hidayat ART, 2023, LAND-BASEL, V12, DOI 10.3390/land12101847; Hsu C.-W., 2003, Practical Guide to Support Vector Classification, P12; Huazhu Song, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P838, DOI 10.1109/CSSE.2008.1231; Iqbal M., 2023, ComTech Comput. Math. Eng. Appl, V14, P11, DOI [10.21512/comtech.v14i1.8243, DOI 10.21512/COMTECH.V14I1.8243]; Jalal N, 2022, J KING SAUD UNIV-COM, V34, P2733, DOI 10.1016/j.jksuci.2022.03.012; Jung KJ, 2015, QUAL QUANT, V49, P1465, DOI 10.1007/s11135-014-0092-x; Kale SS, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI 10.1109/punecon46936.2019.9105741; Karimpanal TG, 2019, ADAPT BEHAV, V27, P111, DOI 10.1177/1059712318818568; Kesavaraj G., 2013, P 2013 4 INT C COMPU, P1, DOI [10.1109/ICCCNT.2013.6726842, DOI 10.1109/ICCCNT.2013.6726842]; Ketu S, 2021, COMPLEX INTELL SYST, V7, P2597, DOI 10.1007/s40747-021-00435-5; Klamo L., 2006, Electronic Government, V3, P158, DOI 10.1504/EG.2006.009216; Kramer O., 2013, DIMENSIONALITY REDUC, V51, P13, DOI [10.1007/978-3-642-38652-7_2, DOI 10.1007/978-3-642-38652-7_2]; Lan CF, 2022, ENERGY REP, V8, P13129, DOI 10.1016/j.egyr.2022.09.142; Lee G, 2012, GOV INFORM Q, V29, P492, DOI 10.1016/j.giq.2012.06.001; Lei YG, 2009, MECH SYST SIGNAL PR, V23, P1535, DOI 10.1016/j.ymssp.2009.01.009; Li HS, 2006, APPL MATH MECH-ENGL, V27, P1295, DOI 10.1007/s10483-006-1001-z; Li J., 2020, Proc. VLDB Endow, V13, P2549, DOI DOI 10.14778/3407790.3407844; Li JL, 2020, OPTIK, V206, DOI 10.1016/j.ijleo.2020.164248; Li K, 2020, ELECTRON COMMER R A, V44, DOI 10.1016/j.elerap.2020.101004; Li L, 2021, J CLEAN PROD, V303, DOI 10.1016/j.jclepro.2021.126814; Lohr SL., 2021, SAMPLING DESIGN ANAL, DOI DOI 10.1201/9780429298899; Ma LJ, 2005, GOV INFORM Q, V22, P20, DOI 10.1016/j.giq.2004.10.001; Madyatmadja Evaristus Didik, 2021, ICIC Express Letters, Part B: Applications, V12, P957, DOI 10.24507/icicelb.12.10.0000/957; Madyatmadja E.D., 2019, Int. J. Recent Technol. Eng, V8, P3345, DOI [10.35940/ijrte.C5011.098319, DOI 10.35940/IJRTE.C5011.098319]; Madyatmadja ED, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P841, DOI [10.1109/ICIMTech50083.2020.9211277, 10.1109/icimtech50083.2020.9211277]; Mahajan S, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13020356; Martínez F, 2019, ARTIF INTELL REV, V52, P2019, DOI 10.1007/s10462-017-9593-z; Martinez R, 2020, CITIES, V106, DOI 10.1016/j.cities.2020.102868; Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13; Mian MM, 2017, J MATER CYCLES WASTE, V19, P1127, DOI 10.1007/s10163-016-0509-9; Ngai EWT, 2009, EXPERT SYST APPL, V36, P2592, DOI 10.1016/j.eswa.2008.02.021; Nindito Hendro, 2019, 2019 International Conference on Information Management and Technology (ICIMTech). Proceedings, P78, DOI 10.1109/ICIMTech.2019.8843723; Nurhasanah N., 2022, Eng. Math. Comput. Sci. J. (EMACS), V4, P103, DOI [10.21512/emacsjournal.v4i3.8670, DOI 10.21512/EMACSJOURNAL.V4I3.8670]; Nyansiro Joseph B., 2021, AJIC, V28, P1, DOI 10.23962/10539/32210; Oxford Analytica, 2023, GenAI Will Transform Workplace Tasks across Industries Expert Briefings, DOI [10.1108/oxan-db279960, DOI 10.1108/OXAN-DB279960]; Palma Ingrid, 2021, DG.O'21: DG.O2021: The 22nd Annual International Conference on Digital Government Research, P76, DOI 10.1145/3463677.3463715; Pan YK, 2023, Arxiv, DOI arXiv:2305.13661; Parmar A, 2019, LECT NOTE DATA ENG, V26, P758, DOI 10.1007/978-3-030-03146-6_86; Peters BG, 1998, PUBLIC ADMIN, V76, P295, DOI 10.1111/1467-9299.00102; Noi PT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010018; Pillai TR, 2018, J ENTERP COMMUNITIES, V12, P232, DOI 10.1108/JEC-08-2017-0063; Pin LA, 2021, TECHNOL SOC, V66, DOI 10.1016/j.techsoc.2021.101658; Prahono A, 2015, PROCEDIA COMPUT SCI, V59, P27, DOI 10.1016/j.procs.2015.07.334; Putri T.T., 2019, J. Inform. Pelita Nusant, V4, P19; Raghavendra NS, 2014, APPL SOFT COMPUT, V19, P372, DOI 10.1016/j.asoc.2014.02.002; Ramadhan R., 2019, Responsive, V2, P140, DOI [10.24198/responsive.v2i3.26083, DOI 10.24198/RESPONSIVE.V2I3.26083]; Relly JE, 2009, GOV INFORM Q, V26, P148, DOI 10.1016/j.giq.2008.04.002; Reyzin L., 2006, Proceedings of the 23rd international conference on Machine learning, P753, DOI DOI 10.1145/1143844.1143939; Riccucci NM, 2017, PUBLIC ADMIN REV, V77, P21, DOI 10.1111/puar.12649; Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002; Rosnelly R., 2021, Turk. J. Comput. Math. Educ, V12, P1415, DOI [10.17762/turcomat.v12i3.938, DOI 10.17762/TURCOMAT.V12I3.938]; Sala E.E., 2023, Winners, V23, P131, DOI [10.21512/tw.v23i2.7423, DOI 10.21512/TW.V23I2.7423]; Sano A.V.D., 2016, ComTech Comput. Math. Eng. Appl, V7, P141, DOI [10.21512/comtech.v7i2.2254, DOI 10.21512/COMTECH.V7I2.2254]; Sano Y., 2015, Inf. Eng. Express, V1, P119, DOI DOI 10.52731/IEE.V1.I4.35; Santra A., 2012, International Journal of Computer Science Issues, V9, P322; Sarasati R., 2020, IOP Conference Series: Earth and Environmental Science, V426, DOI 10.1088/1755-1315/426/1/012165; Sarica A, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00329; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schapire RE, 2013, EMPIRICAL INFERENCE, P37, DOI [10.1007/978-3-642-41136-6_5, DOI 10.1007/978-3-642-41136-6_5]; Shabani S, 2020, ATMOSPHERE-BASEL, V11, DOI 10.3390/atmos11010066; Sianipar CPM, 2014, SUSTAIN CITIES SOC, V12, P31, DOI 10.1016/j.scs.2014.01.002; Singh B, 2017, MODEL EARTH SYST ENV, V3, P996, DOI 10.1007/s40808-017-0347-3; Sulistyo M.E., 2015, Telematika, V12, P146, DOI [10.31315/telematika.v12i2.1422, DOI 10.31315/TELEMATIKA.V12I2.1422]; Sunindyo W, 2014, LECT NOTES COMPUT SC, V8407, P338, DOI 10.1007/978-3-642-55032-4_33; Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207; Sutranggono A.N., 2023, CommIT Commun. Inf. Technol. J, V17, P13, DOI [10.21512/commit.v17i1.8189, DOI 10.21512/COMMIT.V17I1.8189]; Syukri A., 2023, P 7 INT C INF COMM T, V464, P343, DOI [10.1007/978-981-19-2394-4_32, DOI 10.1007/978-981-19-2394-4_32]; Tejedo-Romero F, 2022, TECHNOL SOC, V70, DOI 10.1016/j.techsoc.2022.101978; Thongkam J., 2008, HDKM 08, V46, P55; Tjandra S, 2015, INT CONF ICT KNOWL, P1, DOI 10.1109/ICTKE.2015.7368461; Trstenjak B, 2014, PROCEDIA ENGINEER, V69, P1356, DOI 10.1016/j.proeng.2014.03.129; Vijayarani S, 2015, International Journal of Computing and Business Research (IJCBR), V6, P2229; Wang F, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010028; Wang XD, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P948; Wibowo M.I., 2018, CommIT Journal, V12, P51, DOI DOI 10.21512/COMMIT.V12I1.4361; Widagdo B., 2019, Indones. J. Bus. Econ, V2, P255, DOI [10.25134/ijbe.v2i1.1625, DOI 10.25134/IJBE.V2I1.1625]; Wijaya A., 2015, COMMIT COMMUNICATION, V10, P41, DOI DOI 10.21512/COMMIT.V10I1.1660; Wismansyah A.R., 2023, P 7 INT C ACCOUNTING, P367, DOI [10.2991/978-94-6463-146-3_37, DOI 10.2991/978-94-6463-146-3_37]; Wowczko IA, 2015, INFORMATICS-BASEL, V2, P31, DOI 10.3390/informatics2040031; Yan H, 2020, AUTOMAT CONSTR, V119, DOI 10.1016/j.autcon.2020.103331; Yan XA, 2018, NEUROCOMPUTING, V313, P47, DOI 10.1016/j.neucom.2018.05.002; Yenkar P., 2022, Machine Intelligence and Smart Systems, P65, DOI [10.1007/978-981-16-9650-3_5, DOI 10.1007/978-981-16-9650-3_5]; Yusliani N., 2019, Int. J. Comput. Appl, V182, P15, DOI [10.5120/ijca2019918476, DOI 10.5120/IJCA2019918476]; Zhang JW, 2019, INT CONF AWARE SCI, P389, DOI 10.1109/icawst.2019.8923186; Zhang JL, 2021, IEEE INTERNET THINGS, V8, P3323, DOI 10.1109/JIOT.2020.3043289; Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241; Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.03.37	129	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9709		INFORMATICS-BASEL	Informatics-Basel	DEC	2023	10	4							84	10.3390/informatics10040084	http://dx.doi.org/10.3390/informatics10040084			24	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	DF4G2		gold			2024-07-03	WOS:001130595500001
J	DeJeu, E				DeJeu, Emily			A Rhetorical Approach for Reimagining Business Writing Instruction in the AI Age	BUSINESS AND PROFESSIONAL COMMUNICATION QUARTERLY			English	Article; Early Access						Generative AI; ChatGPT; professional writing; business communication; rhetorical theory; rhetorical canons; large language models	STANCE; GENERALITY; KNOWLEDGE; 1ST-YEAR; EXPLICIT; STUDENT; ERASURE	Generative AI could disrupt professional writing instruction, but banning AI tools seems unproductive. This article outlines a rhetorical approach for adapting business writing instruction for the AI age: It suggests AI use cases that align with the rhetorical canons, illustrates each with real-world business examples, and ends with suggestions for using AI to build students' critical genre awareness. This approach should prove useful for business writing instructors who want to ground their AI-related instruction in enduring pedagogical theory.	[DeJeu, Emily] Carnegie Mellon Univ, Tepper Sch Business, Business Management Commun, Pittsburgh, PA 15213 USA; [DeJeu, Emily] Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University	DeJeu, E (corresponding author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	edejeu@andrew.cmu.edu			Center for Intelligent Business at Carnegie Mellon's Tepper School of Business	Center for Intelligent Business at Carnegie Mellon's Tepper School of Business	The author disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The author acknowledges a fellowship from the Center for Intelligent Business at Carnegie Mellon's Tepper School of Business that supported these research efforts	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anderson R., 2023, The Atlantic; ANSON CM, 1990, WRIT COMMUN, V7, P200, DOI 10.1177/0741088390007002002; Aristotle, 2004, Rhetoric; Artemeva N., 2006, Becoming an engineering communicator: A study of novices' trajectories in learning genres of their profession; Artemeva N, 2008, J BUS TECH COMMUN, V22, P160, DOI 10.1177/1050651907311925; Aull LL, 2017, J ENGL ACAD PURP, V26, P29, DOI 10.1016/j.jeap.2017.01.005; Aull LL, 2014, WRIT COMMUN, V31, P151, DOI 10.1177/0741088314527055; Bazerman C., 1992, Writing teaching, and learning in the disciplines, P61; Beaufort Anne., 1999, Writing in the Real World: Making the Transition from School to Work; Bitzer Lloyd., 1968, PHILOS RHETORIC, V1, P1; Brent D, 2011, J BUS TECH COMMUN, V25, P396, DOI 10.1177/1050651911410951; Brittain B, 2023, Reuters; Brown DW, 2017, RES TEACH ENGL, V51, P394; Butler P, 2008, OUT OF STYLE: REANIMATING STYLISTIC STUDY IN COMPOSITION AND RHETORIC, P1; Carter M, 2007, COLL COMPOS COMMUN, V58, P385; Connors RJ, 2000, COLL COMPOS COMMUN, V52, P96, DOI 10.2307/358546; Corbett EdwardP.J., 1990, CLASSICAL RHETORIC M, V3rd; Couture B., 1992, J BUS TECH COMMUN, V6, P5, DOI [10.1177/1050651992006001001, DOI 10.1177/1050651992006001001]; Crowley Sharon., 2010, METHODICAL MEMORY IN; DANGELO FJ, 1986, COLL COMPOS COMMUN, V37, P431, DOI 10.2307/357913; DeJeu E. B., Composition Forum; Dejeu EB, 2024, J BUS TECH COMMUN, V38, P225, DOI 10.1177/10506519241239923; DeJeu EB, 2024, BUS PROF COMMUN Q, V87, P122, DOI 10.1177/23294906231182616; DeJeu EB, 2023, WRIT COMMUN, V40, P1144, DOI 10.1177/07410883231171866; DellAcqua F., 2023, Navigating the gagged technological frontier: Field experimental evidence of the effects of AI on knowledge worker productivity and quality, DOI [10.2139/ssrn.4573321, DOI 10.2139/SSRN.4573321]; Deloitte, 2022, Deloitte and IOC announce global partnership to advance the Olympic movement; Devitt A.J., 2009, GENRE CHANGING WORLD, P337, DOI [10.37514/PER-B.2009.2324.2.17, DOI 10.37514/PER-B.2009.2324.2.17]; Driscoll DL, 2020, WRIT COMMUN, V37, P69, DOI 10.1177/0741088319882313; FAHNESTOCK J, 1986, WRIT COMMUN, V3, P275, DOI 10.1177/0741088386003003001; Fahnestock J., 1991, TEXTUAL DYNAMICS PRO, P76; Fahnestock Jeanne., 1999, Rhetorical Figures in Science; Fahnestock Jeanne., 2011, Promise of Reason: Studies in The New Rhetoric, P29; Felten E. W., 2023, SSRN, DOI DOI 10.2139/SSRN.4375268; Flower L., 1981, College Composition & Communication, V32, P365, DOI [10.2307/356600, DOI 10.2307/356600]; FREEDMAN A, 1993, RES TEACH ENGL, V27, P222; Gee J.P., 1989, J ED, V171, P5, DOI DOI 10.1177/002205748917100101; Gere AR, 2021, COLL COMPOS COMMUN, V72, P384; Ghaffary S., 2023, Bloomberg; Hartenberger L., 2023, Noema; Heikkil M., 2023, MIT Technology Review; Hyland K, 2005, DISCOURSE STUD, V7, P173, DOI 10.1177/146144560505050365; Hyland K., 2004, DISCIPLINARY DISCOUR, DOI 10.35360/njes.220; Hyland K, 2010, J ENGL ACAD PURP, V9, P116, DOI 10.1016/j.jeap.2010.02.003; Keegin J. M., 2023, The Chronicle of Higher Education; Laquintano T., 2023, TextGenEd: Teaching with text generation technologies, DOI [10.37514/TWR-J.2023.1.1.02, DOI 10.37514/TWR-J.2023.1.1.02]; Lauer Janice., 2004, INVENTION RHETORIC C; Leffler L., 2023, The Scientific American; Leijten M, 2014, J WRIT RES, V5, P285, DOI 10.17239/jowr-2014.05.03.3; Locker KO, 1999, J BUS TECH COMMUN, V13, P5, DOI 10.1177/105065199901300101; Lunsford A. A., 2006, Computer and Composition, V23, P169, DOI 10.1016/j.compcom.2006.02.002; MacDonald SP, 2007, COLL COMPOS COMMUN, V58, P585; May J., 2023, The Conversation; Miller C., 1986, Writing in Nonacademic Settings, P309; Mollick E., 2023, ONE USEFUL THING; Nadeau Ray., 1959, Greek, Roman and Byzantine studies, V2, P51; Nicoletti L., 2023, Bloomberg; Nield D., 2023, Wired; Olympics 2012: The alternative medals table, 2012, The Guardian; OpenAI, 2023, ChatGPT Plus; Perelman Ch., 1971, The New Rhetoric: A Treatise on Argumentation; Peters M., 2023, Stop focusing on plagiarism, even though ChatGPT is here to stay; Porter James E., 2009, Computers and Composition, V26, P207, DOI 10.1016/j.compcom.2009.09.004; Richter F., 2023, ChatGPT is the most tried and true AI tool and users stick to it; Rickey N., 2023, The Conversation; Schappert S., 2023, Cybernews; Sensemed, 2017, Sense Media Blog; Terry Owen Kichizo., 2023, The Chronicle of Higher EducationMay 12; Toulmin S.E., 1979, An introduction to reasoning; Turow S., 2010, One L: The turbulent true story of a first year at Harvard law school; Vee A., 2023, Computation and Writing; Wilder L, 2005, WRIT COMMUN, V22, P76, DOI 10.1177/0741088304272751; Wilder L, 2018, RES TEACH ENGL, V52, P382; Wilder L, 2009, RES TEACH ENGL, V44, P170; Wolfe J., 2014, The WAC Journal, V25, P42; Wolfe J, 2016, BUS PROF COMMUN Q, V79, P397, DOI 10.1177/2329490616671133; Wolfe J, 2015, J BUS TECH COMMUN, V29, P344, DOI 10.1177/1050651915573944; Wolfe J, 2011, J BUS TECH COMMUN, V25, P119, DOI 10.1177/1050651910385785; Zhu WH, 2012, RELC J, V43, P217, DOI 10.1177/0033688212449936; Zinsser W. K., 2001, On writing well: The classic guide to writing nonfiction	80	0	0	0	0	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	2329-4906	2329-4922		BUS PROF COMMUN Q	Bus. Prof. Commun. Q.	2024 JUN 10	2024										10.1177/23294906241255301	http://dx.doi.org/10.1177/23294906241255301		JUN 2024	27	Communication	Emerging Sources Citation Index (ESCI)	Communication	TP0Y7					2024-07-03	WOS:001242358800001
J	Agbavor, F; Liang, HL				Agbavor, Felix; Liang, Hualou			Artificial Intelligence-Enabled End-To-End Detection and Assessment of Alzheimer's Disease Using Voice	BRAIN SCIENCES			English	Article						Alzheimer's disease; dementia; end-to-end; data2vec; large language models; speech and language		There is currently no simple, widely available screening method for Alzheimer's disease (AD), partly because the diagnosis of AD is complex and typically involves expensive and sometimes invasive tests not commonly available outside highly specialized clinical settings. Here, we developed an artificial intelligence (AI)-powered end-to-end system to detect AD and predict its severity directly from voice recordings. At the core of our system is the pre-trained data2vec model, the first high-performance self-supervised algorithm that works for speech, vision, and text. Our model was internally evaluated on the ADReSSo (Alzheimer's Dementia Recognition through Spontaneous Speech only) dataset containing voice recordings of subjects describing the Cookie Theft picture, and externally validated on a test dataset from DementiaBank. The AI model can detect AD with average area under the curve (AUC) of 0.846 and 0.835 on held-out and external test set, respectively. The model was well-calibrated (Hosmer-Lemeshow goodness-of-fit p-value = 0.9616). Moreover, the model can reliably predict the subject's cognitive testing score solely based on raw voice recordings. Our study demonstrates the feasibility of using the AI-powered end-to-end model for early AD diagnosis and severity prediction directly based on voice, showing its potential for screening Alzheimer's disease in a community setting.	[Agbavor, Felix; Liang, Hualou] Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA	Drexel University	Liang, HL (corresponding author), Drexel Univ, Sch Biomed Engn Sci & Hlth Syst, Philadelphia, PA 19104 USA.	hualou.liang@drexel.edu						Agbavor Felix, 2022, PLOS Digit Health, V1, pe0000168, DOI 10.1371/journal.pdig.0000168; Amini S, 2023, ALZHEIMERS DEMENT, V19, P946, DOI 10.1002/alz.12721; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Baevski A, 2022, Arxiv, DOI arXiv:2202.03555; Balagopalan A, 2021, Arxiv, DOI arXiv:2106.01555; Balagopalan A, 2020, Arxiv, DOI arXiv:2008.01551; BECKER JT, 1994, ARCH NEUROL-CHICAGO, V51, P585, DOI 10.1001/archneur.1994.00540180063015; DEGROOT MH, 1983, J ROY STAT SOC D-STA, V32, P12; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Dogo EM, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P92, DOI 10.1109/CTEMS.2018.8769211; Efron B, 1994, INTRO BOOTSTRAP, DOI DOI 10.1201/9780429246593; ERNST RL, 1994, AM J PUBLIC HEALTH, V84, P1261, DOI 10.2105/AJPH.84.8.1261; Eyben F., 2010, P 18 ACM INT C MULT, P1459; Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417; Eyigoz E, 2020, ECLINICALMEDICINE, V28, DOI 10.1016/j.eclinm.2020.100583; Fan Jerome, 2006, CJEM, V8, P19; FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6; Fraser KC, 2016, J ALZHEIMERS DIS, V49, P407, DOI 10.3233/JAD-150520; Fratiglioni L, 1999, DRUG AGING, V15, P365, DOI 10.2165/00002512-199915050-00004; Garcia SD, 2020, J ALZHEIMERS DIS, V78, P1547, DOI 10.3233/JAD-200888; Goodglass H., 2001, BDAE: The Boston diagnostic aphasia examination; Guo Y, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.642517; Gupta Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222446; Haider F, 2020, IEEE J-STSP, V14, P272, DOI 10.1109/JSTSP.2019.2955022; Hosmer DW, 2013, WILEY SER PROBAB ST, P89; Jack CR, 2022, LANCET NEUROL, V21, P866, DOI 10.1016/S1474-4422(22)00298-8; Lin Honghuang, 2020, Explor Med, V1, P406, DOI 10.37349/emed.2020.00028; Luz S, 2021, Arxiv, DOI arXiv:2104.09356; Luz S, 2020, Arxiv, DOI arXiv:2004.06833; McFee B., 2015, P 14 PYTH SCI C, V8, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]; Meek PD, 1998, PHARMACOTHERAPY, V18, P68; Murphy Allan H., 1977, Journal of the Royal Statistical Society. Series C (Applied Statistics), V26, P41, DOI DOI 10.2307/2346866; Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x; Pan YL, 2021, INTERSPEECH, P3810, DOI 10.21437/Interspeech.2021-1519; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Robertson T., 1988, ORDER RESTRICTED STA; ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41; Seeley W.W., 2018, Harrison's Principles of Internal Medicine, V20; Seitz DP, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011415.pub2; Weiner M.W., 2013, Alzheimer's Dement, V9, pe111, DOI [10.1016/j.jalz.2013.05.1769, DOI 10.1016/J.JALZ.2013.05.1769]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wong Winston, 2020, Am J Manag Care, V26, pS177, DOI 10.37765/ajmc.2020.88482; Yamada Y, 2021, J ALZHEIMERS DIS, V84, P315, DOI 10.3233/JAD-210684; Yiannopoulou KG, 2020, J CENT NERV SYST DIS, V12, DOI 10.1177/1179573520907397	44	9	9	8	26	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3425		BRAIN SCI	Brain Sci.	JAN	2023	13	1							28	10.3390/brainsci13010028	http://dx.doi.org/10.3390/brainsci13010028			13	Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	7Y0RI	36672010	Green Published, gold			2024-07-03	WOS:000914597300001
J	García-Díaz, JA; Pan, RH; Valencia-García, R				Garcia-Diaz, Jose Antonio; Pan, Ronghao; Valencia-Garcia, Rafael			Leveraging Zero and Few-Shot Learning for Enhanced Model Generality in Hate Speech Detection in Spanish and English	MATHEMATICS			English	Article						hate speech detection; zero-shot learning; few-shot learning; fine-tuning; large language models; natural language processing	SEXISM IDENTIFICATION	Supervised training has traditionally been the cornerstone of hate speech detection models, but it often falls short when faced with unseen scenarios. Zero and few-shot learning offers an interesting alternative to traditional supervised approaches. In this paper, we explore the advantages of zero and few-shot learning over supervised training, with a particular focus on hate speech detection datasets covering different domains and levels of complexity. We evaluate the generalization capabilities of generative models such as T5, BLOOM, and Llama-2. These models have shown promise in text generation and have demonstrated the ability to learn from limited labeled data. Moreover, by evaluating their performance on both Spanish and English datasets, we gain insight into their cross-lingual applicability and versatility, thus contributing to a broader understanding of generative models in natural language processing. Our results highlight the potential of generative models to bridge the gap between data scarcity and model performance across languages and domains.	[Garcia-Diaz, Jose Antonio; Pan, Ronghao; Valencia-Garcia, Rafael] Univ Murcia, Fac Informat, Campus Espinardo, Murcia 30100, Spain	University of Murcia	Pan, RH (corresponding author), Univ Murcia, Fac Informat, Campus Espinardo, Murcia 30100, Spain.	joseantonio.garcia8@um.es; ronghao.pan@um.es; valencia@um.es	; Valencia-Garcia, Rafael/L-4759-2014	Garcia, Jose Antonio/0000-0002-3651-2660; Pan, Ronghao/0009-0008-7317-7145; Valencia-Garcia, Rafael/0000-0003-2457-1791	LT-SWM	LT-SWM	No Statement Available	Alkomah F, 2022, INFORMATION, V13, DOI 10.3390/info13060273; García-Díaz JA, 2023, COMPLEX INTELL SYST, V9, P2893, DOI 10.1007/s40747-022-00693-x; García-Díaz JA, 2022, COMPLEX INTELL SYST, V8, P1723, DOI 10.1007/s40747-021-00625-1; García-Díaz JA, 2021, FUTURE GENER COMP SY, V114, P506, DOI 10.1016/j.future.2020.08.032; Basile Valerio, 2019, P 13 INT WORKSHOP SE, P54, DOI [DOI 10.18653/V1/S19-2007, 10.18653/v1/S19-2007]; Canete J., 2020, P PML4DC ICLR 2020 A; Cañete J, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4291; Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214654; Carta S, 2023, Arxiv, DOI arXiv:2307.01128; Chi E.A., 2020, P 58 ANN M ASS COMPU, P5564, DOI [DOI 10.18653/V1/2020.ACL-MAIN.493, 10.18653/v1/2020.acl-main.493]; Chia YK, 2023, Arxiv, DOI arXiv:2306.04757; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cong Khanh L., 2022, Int. J. TESOL Educ, V3, P19, DOI [10.54855/ijte.23312, DOI 10.54855/IJTE.23312]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; El-Kishky A, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P2842, DOI 10.1145/3534678.3539080; Fersini E., 2018, IberEval@ SEPLN, t, V2150, P214; Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676; García-Díaz JA, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6035; García-Díaz JA, 2022, PROCES LENG NAT, P265, DOI 10.26342/2022-69-23; Guarasci R, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101261; Guarasci R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03297-4; Gunel B, 2021, Arxiv, DOI [arXiv:2011.01403, DOI 10.48550/ARXIV.2011.01403]; Gutierrez Fandino A., 2022, Proces. Leng. Nat, V68, P1; He P., 2021, arXiv; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Kirk H., 2023, P THE 17 INT WORKSHO, P2193; Labrak Y, 2024, Arxiv, DOI arXiv:2307.12114; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Liaw R, 2018, Arxiv, DOI [arXiv:1807.05118, 10.48550/arXiv.1807.05118]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mikolov Tomas, 2018, P 11 INT C LANGUAGE; Montesinos-Cánovas E, 2023, PROCES LENG NAT, P15, DOI 10.26342/2023-71-1; Mozafari M, 2022, IEEE ACCESS, V10, P14880, DOI 10.1109/ACCESS.2022.3147588; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; Mukherjee S, 2023, Arxiv, DOI arXiv:2306.02707; Nguyen H.T.T., 2021, P FPT C HA NOI VIETN, P1; Nichols Johanna., 2018, Linguistic diversity in space and time; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Plaza L., 2023, P INT C CROSS LANGUA, P316; Plaza-del-Arco FM, 2024, Arxiv, DOI arXiv:2307.12973; Raffel C, 2020, J MACH LEARN RES, V21; Rodríguez-Sánchez F, 2022, PROCES LENG NAT, P229, DOI 10.26342/2022-69-20; Rodríguez-Sánchez F, 2021, PROCES LENG NAT, P195, DOI 10.26342/2021-67-17; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Winata G., 2022, P 2 C ASIA PACIFIC C, P777; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	50	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	DEC	2023	11	24							5004	10.3390/math11245004	http://dx.doi.org/10.3390/math11245004			19	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	DI5T6		gold			2024-07-03	WOS:001131422200001
J	Horiuchi, D; Tatekawa, H; Shimono, T; Walston, SL; Takita, H; Matsushita, S; Oura, T; Mitsuyama, Y; Miki, Y; Ueda, D				Horiuchi, Daisuke; Tatekawa, Hiroyuki; Shimono, Taro; Walston, Shannon L.; Takita, Hirotaka; Matsushita, Shu; Oura, Tatsushi; Mitsuyama, Yasuhito; Miki, Yukio; Ueda, Daiju			Accuracy of ChatGPT generated diagnosis from patient's medical history and imaging findings in neuroradiology cases	NEURORADIOLOGY			English	Article						Artificial intelligence; Chat Generative Pre-trained Transformer (ChatGPT); Generative Pre-trained Transformer (GPT)-4; Large language models		Purpose The noteworthy performance of Chat Generative Pre-trained Transformer (ChatGPT), an artificial intelligence text generation model based on the GPT-4 architecture, has been demonstrated in various fields; however, its potential applications in neuroradiology remain unexplored. This study aimed to evaluate the diagnostic performance of GPT-4 based ChatGPT in neuroradiology.Methods We collected 100 consecutive "Case of the Week" cases from the American Journal of Neuroradiology between October 2021 and September 2023. ChatGPT generated a diagnosis from patient's medical history and imaging findings for each case. Then the diagnostic accuracy rate was determined using the published ground truth. Each case was categorized by anatomical location (brain, spine, and head & neck), and brain cases were further divided into central nervous system (CNS) tumor and non-CNS tumor groups. Fisher's exact test was conducted to compare the accuracy rates among the three anatomical locations, as well as between the CNS tumor and non-CNS tumor groups.Results ChatGPT achieved a diagnostic accuracy rate of 50% (50/100 cases). There were no significant differences between the accuracy rates of the three anatomical locations (p = 0.89). The accuracy rate was significantly lower for the CNS tumor group compared to the non-CNS tumor group in the brain cases (16% [3/19] vs. 62% [36/58], p < 0.001).Conclusion This study demonstrated the diagnostic performance of ChatGPT in neuroradiology. ChatGPT's diagnostic accuracy varied depending on disease etiologies, and its diagnostic accuracy was significantly lower in CNS tumors compared to non-CNS tumors.	[Horiuchi, Daisuke; Tatekawa, Hiroyuki; Shimono, Taro; Walston, Shannon L.; Takita, Hirotaka; Matsushita, Shu; Oura, Tatsushi; Mitsuyama, Yasuhito; Miki, Yukio; Ueda, Daiju] Osaka Metropolitan Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Osaka, Japan; [Ueda, Daiju] Osaka Metropolitan Univ, Ctr Hlth Sci Innovat, Smart Life Sci Lab, Osaka, Japan	Osaka Metropolitan University; Osaka Metropolitan University	Ueda, D (corresponding author), Osaka Metropolitan Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Osaka, Japan.; Ueda, D (corresponding author), Osaka Metropolitan Univ, Ctr Hlth Sci Innovat, Smart Life Sci Lab, Osaka, Japan.	ai.labo.ocu@gmail.com	Ueda, Daiju/AAG-2167-2021	Ueda, Daiju/0000-0002-3878-3616; Walston, Shannon/0000-0002-7268-8313; Matsushita, Shu/0000-0003-1132-9736; Shimono, Taro/0000-0001-5847-6587; Takita, Hirotaka/0000-0003-2860-4503; Miki, Yukio/0000-0003-0621-0044; Mitsuyama, Yasuhito/0000-0001-7979-2300; Tatekawa, Hiroyuki/0000-0002-8050-4895; Horiuchi, Daisuke/0000-0002-8929-8098				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; [Anonymous], 2021, World Health Organization Classification of Tumours of the Central Nervous System; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12712; Eloundou T., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.10130; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hendee WR, 2010, RADIOLOGY, V257, P240, DOI 10.1148/radiol.10100063; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Iorga M, 2022, AM J NEURORADIOL, V43, P721, DOI 10.3174/ajnr.A7500; Ivanovic V, 2023, AM J ROENTGENOL, V221, P355, DOI 10.2214/AJR.22.28925; Juluru K, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210013; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Kumamaru KK, 2018, JPN J RADIOL, V36, P273, DOI 10.1007/s11604-018-0724-5; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Li David, 2023, Radiology, V308, pe232082, DOI 10.1148/radiol.232082; Liu F, 2021, AM J NEURORADIOL, V42, P1755, DOI 10.3174/ajnr.A7241; McNamara C, 2022, NEURORADIOLOGY, V64, P1919, DOI 10.1007/s00234-022-03008-6; Mollura DJ, 2020, RADIOLOGY, V297, P513, DOI 10.1148/radiol.2020201434; OpenAI, 2023, GPT-4 Technical Report, DOI [10.48550/arXiv.2303.08774, DOI 10.48550/ARXIV.2303.08774]; Osborn AG, 2022, AM J NEURORADIOL, DOI 10.3174/ajnr.A7462; Osborn A.G., 2017, Osborn's Brain: Imaging, Pathology, and Anatomy; Patel SH, 2019, AM J NEURORADIOL, V40, P1252, DOI 10.3174/ajnr.A6125; Rigsby RK, 2023, AM J NEURORADIOL, V44, P367, DOI 10.3174/ajnr.A7827; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Ueda D, 2019, JPN J RADIOL, V37, P15, DOI 10.1007/s11604-018-0795-3; Wood DA, 2022, EUR RADIOL, V32, P725, DOI 10.1007/s00330-021-08132-0	31	8	8	8	11	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0028-3940	1432-1920		NEURORADIOLOGY	Neuroradiology	JAN	2024	66	1					73	79		10.1007/s00234-023-03252-4	http://dx.doi.org/10.1007/s00234-023-03252-4		NOV 2023	7	Clinical Neurology; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	ED9I6	37994939				2024-07-03	WOS:001107545700001
J	Gurrapu, S; Kulkarni, A; Huang, LF; Lourentzou, I; Batarseh, FA				Gurrapu, Sai; Kulkarni, Ajay; Huang, Lifu; Lourentzou, Ismini; Batarseh, Feras A.			Rationalization for explainable NLP: a survey	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Review						rationalization; explainable NLP; rationales; abstractive rationale; extractive rationale; large language models; natural language generation; Natural Language Processing		Recent advances in deep learning have improved the performance of many Natural Language Processing (NLP) tasks such as translation, question-answering, and text classification. However, this improvement comes at the expense of model explainability. Black-box models make it difficult to understand the internals of a system and the process it takes to arrive at an output. Numerical (LIME, Shapley) and visualization (saliency heatmap) explainability techniques are helpful; however, they are insufficient because they require specialized knowledge. These factors led rationalization to emerge as a more accessible explainable technique in NLP. Rationalization justifies a model's output by providing a natural language explanation (rationale). Recent improvements in natural language generation have made rationalization an attractive technique because it is intuitive, human-comprehensible, and accessible to non-technical users. Since rationalization is a relatively new field, it is disorganized. As the first survey, rationalization literature in NLP from 2007 to 2022 is analyzed. This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization. Further, a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization. A discussion on observed insights, challenges, and future directions is provided to point to promising research opportunities.	[Gurrapu, Sai; Huang, Lifu; Lourentzou, Ismini] Virginia Tech, Dept Comp Sci, Blacksburg, VA USA; [Kulkarni, Ajay; Batarseh, Feras A.] Virginia Tech, Commonwealth Cyber Initiat, Arlington, VA 22203 USA; [Batarseh, Feras A.] Virginia Tech, Dept Biol Syst Engn, Blacksburg, VA 24060 USA	Virginia Polytechnic Institute & State University; Virginia Polytechnic Institute & State University; Virginia Polytechnic Institute & State University	Batarseh, FA (corresponding author), Virginia Tech, Commonwealth Cyber Initiat, Arlington, VA 22203 USA.; Batarseh, FA (corresponding author), Virginia Tech, Dept Biol Syst Engn, Blacksburg, VA 24060 USA.	batarseh@vt.edu			Commonwealth Cyber Initiative (CCI)	Commonwealth Cyber Initiative (CCI)	This work was funded by the Commonwealth Cyber Initiative (CCI).	Agrawal Aishwarya, 2016, P 2016 C EMPIRICAL M, DOI DOI 10.18653/V1/D16-1203; Alhindi Tariq, 2018, P 1 WORKSHOP FACT EX, P85, DOI [DOI 10.18653/V1/W18-5513, 10.18653/v1/W18-5513,eprint:https://aclanthology.org/W18-5513.pdf]; Alvarez-Melis David, 2017, P EMNLP, P412; [Anonymous], 2011, P 49 ANN M ASS COMPU; Antognini D, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P761; Antognini D, 2021, AAAI CONF ARTIF INTE, V35, P12507; Apperly I, 2011, MINDREADERS: THE COGNITIVE BASIS OF THEORY OF MIND, P1; Atanasova Pepa, 2020, P 58 ANN M ASS COMPU, DOI 10.18653/v1/2020.acl-main.656; Baradaran R, 2022, NAT LANG ENG, V28, P683, DOI 10.1017/S1351324921000395; Bastings J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2963; Batarseh FA, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00445-7; Bowman S. R., 2015, arXiv, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camburu OM, 2018, ADV NEUR IN, V31; Chan A., 2021, CoRR, DOI [10.18653/v1/2022.bigscience-1.5, DOI 10.18653/V1/2022.BIGSCIENCE-1.5]; Chang S., 2020, INT C MACHINE LEARNI; Chang SY, 2019, 33 C NEURAL INFORM P, V32; Chaumond Julien, 2019, P 33 C NEURAL INFORM; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; Das D, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P510, DOI 10.1145/3377325.3377512; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DeYoung J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4443; Doshi-Velez F., 2017, RIGOROUS SCI INTERPR, DOI 10.48550/arXiv.1702.08608; Du MN, 2019, IEEE DATA MINING, P150, DOI 10.1109/ICDM.2019.00025; Ehsan U, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P81, DOI 10.1145/3278721.3278736; El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Fomicheva Specia Aletras., 2021, Translation Error Detection As Rationale Extraction; Fox J.E., 2015, P 2015 FEDERAL COMMI, P1; Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018; Graves L., 2016, Digital News Project Report; Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009; Gupta S, 2019, EXPERT SYST APPL, V121, P49, DOI 10.1016/j.eswa.2018.12.011; Gurrapu S., 2022, 2022 IEEE 29th Annual Software Technology Conference; Hansen AT, 2020, ACTA ONCOL, V59, P558, DOI 10.1080/0284186X.2019.1701200; Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255; Jansen P., 2018, NAACL HLT 2018, P12, DOI 10.18653/v1/W18-1703; Kumar Sawan, 2020, P ANN M ASS COMP LIN, DOI 10.18653/v1/2020.acl-main.771; Lakhotia K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3712; Lei T., 2016, RATIONALIZING NEURAL, P107; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Li S, 2019, PROC CVPR IEEE, P10514, DOI 10.1109/CVPR.2019.01077; Li SY, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P327, DOI 10.1145/3523227.3546783; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin YZ, 2021, I C NETWORK PROTOCOL, DOI 10.1109/ICNP52444.2021.9651964; Ling W, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P158, DOI 10.18653/v1/P17-1015; Liu G., 2019, MACHINE LEARNING HEA, P249; Liu H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5570; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Lundberg SM, 2017, ADV NEUR IN, V30; MacCartney B., 2009, Natural Logic and Natural Language; Madsen A., 2021, Post-Hoc Interpretability for Neural nlp: A Survey; Majumder B., 2021, Rationale-Inspired Natural Language Explanations with commonsense; McAuley J, 2012, IEEE DATA MINING, P1020, DOI 10.1109/ICDM.2012.110; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Mittelstadt B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P279, DOI 10.1145/3287560.3287574; Narang S., 2020, ArXiv; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Plyler M., 2022, Making a (counterfactual) Difference One Rationale at a Time; Putnam Vanessa, 2019, IUI Workshops, V2327; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Rana A., 2022, Rerrfact: Reduced Evidence Retrieval Representations for Scientific Claim Verification; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Riedl MO, 2019, HUM BEHAV EMERG TECH, V1, P33, DOI 10.1002/hbe2.117; Russell SJ., 2016, ARTIF INTELL; Sap Maarten, 2020, P 58 ANN M ASS COMPU, P27; Sharma A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5263; Sharp R., 2017, Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), P69, DOI 10.18653/v1/K17-1009; Sperrle F, 2021, COMPUT GRAPH FORUM, V40, P543, DOI 10.1111/cgf.14329; Stamper J., 2010, International Conference on Intelligent Tutoring Systems; Strout J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P56; Sundararajan M, 2017, PR MACH LEARN RES, V70; Sutskever I, 2014, ADV NEUR IN, V27; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Tang XJ, 2021, LECT NOTES COMPUT SC, V12925, P81, DOI 10.1007/978-3-030-86534-4_7; Thayaparan M., 2020, A survey on explainability in machine reading comprehension; Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314; Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086; Vaswani A, 2017, ADV NEUR IN, V30; Wadden D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7534; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Wiegreffe S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10266; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Xie ZN, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5456; Yang S, 2020, A survey of deep learning techniques for neural machine translation; Yu M., 2021, Understanding Interlocking Dynamics of Cooperative Rationalization; Yu M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4094; Zaidan Omar, 2007, HUMAN LANGUAGE TECHN, P260; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253; Zhang YJ, 2016, ADV INTEL SYS RES, V138, P795; Zhang ZJ, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P418, DOI 10.1145/3437963.3441758	97	4	4	12	13	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	SEP 25	2023	6								1225093	10.3389/frai.2023.1225093	http://dx.doi.org/10.3389/frai.2023.1225093			19	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	AO0W7	37818431	Green Submitted, Green Published, gold			2024-07-03	WOS:001119299500001
J	Soomro, SEH; Boota, MW; Zwain, HM; Soomro, GEZ; Shi, XT; Guo, JL; Li, YH; Tayyab, M; Hu, CH; Liu, CS; Soomro, MHAA; Wang, YY; Wahid, JA; Bai, YQ; Nazli, S; Yu, J				Soomro, Shan-e-hyder; Boota, Muhammad Waseem; Zwain, Haider M.; Soomro, Gul-e-Zehra; Shi, Xiaotao; Guo, Jiali; Li, Yinghai; Tayyab, Muhammad; Hu, Caihong; Liu, Chengshuai; Soomro, Mairaj Hyder Alias Aamir; Wang, Yuanyang; Wahid, Junaid Abdul; Bai, Yanqin; Nazli, Sana; Yu, Jia			How effective is twitter (X) social media data for urban flood management?	JOURNAL OF HYDROLOGY			English	Article						Artificial intelligence (AI); Large language model (LLM); Natural language processiong (NLP); Resilience; Sentiment analysis (SA); Urban flood	SPATIOTEMPORAL EVOLUTION; RESILIENCE; COVER; RISK	Social media has been an instant source of information for natural disasters, such as urban floods, throughout the world. Ex-post evaluation of the information is considered more important after a flood disaster with devastating consequences on critical infrastructure, the environment, and the well-being of the society. Research proposes an evaluation framework for integrating the disorganized online public opinion on urban flood disaster events towards emotional and conceptual characteristics for better ex-post analysis and public participation. Social media posts on an urban flood were acquired using a search engine, and then sentiment analysis, topic modeling, and spatial-temporal analysis were performed to generate measures of online public opinion about the urban flood crisis. Twitter (X) is the most popular microblogging service presently available. As per the methodology, we analyzed all tweets regarding the 2022 urban flood in the cosmopolitan city (Karachi) of Pakistan from users all over the world. The evaluation results demonstrated that the distribution patterns of post intensities and emotion polarity in response to the floods emphasized crucial aspects with contradictory emotions and highlighted the strategic implications. Experimental results on real datasets show relatively better performance than the baseline and state-of-the-art approaches and achieved the highest 91% score. Online public opinion is a valuable supplement to ex post-disaster evaluation as it helps the project (e.g., flood management) better perform and provides suggestions for future flood mitigation, especially public participation management.	[Soomro, Shan-e-hyder; Shi, Xiaotao; Guo, Jiali; Li, Yinghai; Tayyab, Muhammad; Wang, Yuanyang; Bai, Yanqin; Yu, Jia] China Three Gorges Univ, Coll Hydraul & Environm Engn, Yichang 443002, Peoples R China; [Boota, Muhammad Waseem] Henan Univ, Coll Geog & Environm Sci, Kaifeng 475004, Peoples R China; [Zwain, Haider M.] Al Qasim Green Univ, Coll Engn, Water Resources Management Engn Dept, Babylon 51013, Iraq; [Soomro, Gul-e-Zehra] Quaid e Awam Univ Engn Sci & Technol, Dept Artificial Intelligence, Nawabshah 67450, Pakistan; [Soomro, Mairaj Hyder Alias Aamir] Univ Wollongong, Sch Civil Min & Environm, Northfields Ave, Wollongong, NSW 2522, Australia; [Soomro, Shan-e-hyder; Hu, Caihong; Liu, Chengshuai] Zhengzhou Univ, Coll Water Conservancy & Transportat, Zhengzhou 450001, Peoples R China; [Wahid, Junaid Abdul] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Peoples R China; [Nazli, Sana] China Inst Water Resources & Hydropower Res, State Key Lab Simulat & Regulat Water Cycle River, Beijing 100038, Peoples R China	China Three Gorges University; Henan University; Al Qasim Green University; University of Wollongong; Zhengzhou University; Zhengzhou University; China Institute of Water Resources & Hydropower Research	Guo, JL; Bai, YQ (corresponding author), China Three Gorges Univ, Coll Hydraul & Environm Engn, Yichang 443002, Peoples R China.	shanhydersoomro110@hotmail.com; waseem.boota@henu.edu.cn; haider.zwain@wrec.uoqasim.edu.iq; gulezehrasoomro37@gmail.com; fishlab@163.com; jiali.guo@ctgu.edu.cn; liyinghai@ctgu.edu.cn; mtayyab@outlook.com; mairaj_hyder@hotmail.com; hucaihong@zzu.edu.cn; mairaj_hyder@hotmail.com; liucs@gs.zzu.edu.cn; wangyuanyang911@163.com; junaidzzu@hotmail.com; 958634286@qq.com; sananazli550@gmail.com		Boota, Muhammad Waseem/0000-0003-0770-0715	Projects of National Natural Science Foundation of China [52179018]; National Natural Science Foundation of China [51922065, 52279069]; Talent Scientific Research Startup Fund Projects [2023RCKJ0048]	Projects of National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Talent Scientific Research Startup Fund Projects	This work was supported by the Projects of National Natural Science Foundation of China (52179018) , National Natural Science Foundation of China (51922065, 52279069) , and Talent Scientific Research Startup Fund Projects (2023RCKJ0048) .	Al-Saggaf Y, 2015, TECHNOL FORECAST SOC, V95, P3, DOI 10.1016/j.techfore.2014.08.013; Alimonti G, 2022, EUR PHYS J PLUS, V137, DOI 10.1140/epjp/s13360-021-02243-9; Amen ARM, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15041102; Aranda AM, 2021, EUR MANAG REV, V18, P197, DOI 10.1111/emre.12452; Aubert AH, 2013, WATER RESOUR RES, V49, P8187, DOI 10.1002/2013WR014086; Baqa MF, 2021, LAND-BASEL, V10, DOI 10.3390/land10070700; Bertilsson L, 2019, J HYDROL, V573, P970, DOI 10.1016/j.jhydrol.2018.06.052; Boota M.W., 2023, Acta Geophys, P1; Cao Z, 2020, ENVIRON RES, V188, DOI 10.1016/j.envres.2020.109813; Cappato Alessandro, 2022, Journal of Hydrology, DOI 10.1016/j.jhydrol.2022.128545; Chan FKS, 2021, ENVIRON SCI POLICY, V122, P101, DOI 10.1016/j.envsci.2021.04.009; Chen W, 2023, OCEAN ENG, V270, DOI 10.1016/j.oceaneng.2023.113646; Chen YQ, 2022, ACTA GEOPHYS, V70, P819, DOI 10.1007/s11600-022-00728-4; Cheng H, 2021, J HYDROL-REG STUD, V37, DOI 10.1016/j.ejrh.2021.100909; Cheng XX, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11195330; Chifu AG, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11224647; Chitwatkulsiri D, 2023, WATER-SUI, V15, DOI 10.3390/w15010178; Coulthard Malcolm., 2002, ADV WRITTEN TEXT ANA; Daron J, 2021, CLIM DEV, V13, P543, DOI 10.1080/17565529.2020.1825920; Dilawar A, 2022, GEOMAT NAT HAZ RISK, V13, P1700, DOI 10.1080/19475705.2022.2090863; Du Q, 2023, INT J DISAST RISK RE, V95, DOI 10.1016/j.ijdrr.2023.103836; Faasse K, 2016, CURR DIR PSYCHOL SCI, V25, P438, DOI 10.1177/0963721416657316; Farias DIH, 2017, SENTIMENT ANALYSIS IN SOCIAL NETWORKS, P113, DOI 10.1016/B978-0-12-804412-4.00007-3; Foroumandi E, 2023, WATER RESOUR RES, V59, DOI 10.1029/2023WR036288; Guo J., 2023, Pol. J. Environ. Stud., V32; Helsloot I., 2012, Mega-crises: Understanding the prospects, nature, characteristics, and the effects of cataclysmic events; Huong TTL, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e10701; Hussain M, 2020, ENVIRON MONIT ASSESS, V192, DOI 10.1007/s10661-019-7956-4; Ilieva RT, 2018, NAT SUSTAIN, V1, P553, DOI 10.1038/s41893-018-0153-6; Jamali M, 2019, INT J INFORM MANAGE, V44, P25, DOI 10.1016/j.ijinfomgt.2018.09.005; Kankanamge N, 2020, INT J DISAST RISK RE, V42, DOI 10.1016/j.ijdrr.2019.101360; Kanth AK, 2022, STOCH ENV RES RISK A, V36, P473, DOI 10.1007/s00477-021-02161-3; Kim J, 2018, INT J INFORM MANAGE, V38, P86, DOI 10.1016/j.ijinfomgt.2017.08.003; Knox CC, 2023, DISASTERS, V47, P247, DOI 10.1111/disa.12544; Kreibich H, 2022, NATURE, V608, P80, DOI 10.1038/s41586-022-04917-5; Kumar V, 2023, HYDROLOGY-BASEL, V10, DOI 10.3390/hydrology10070141; Lai KL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102735; Lan TJ, 2022, J GLOB HEALTH, V12, DOI 10.7189/jogh.12.11007; Li R., 2023, Hydrol. Earth Syst. Sci. Discuss, V2023, P1; Li WL, 2023, T GIS, V27, P1766, DOI 10.1111/tgis.13097; Lin XR, 2023, ATMOS RES, V296, DOI 10.1016/j.atmosres.2023.107070; Liu HM, 2018, J GEOGR SCI, V28, P919, DOI 10.1007/s11442-018-1513-x; Liu Q., 2023, Global Transitions, V5, P149; Liu Q, 2022, J HYDROL, V612, DOI 10.1016/j.jhydrol.2022.128218; Liu YK, 2012, J VEG SCI, V23, P406, DOI 10.1111/j.1654-1103.2011.01373.x; Lu XS, 2021, IEEE T SYST MAN CY-S, V51, P4324, DOI 10.1109/TSMC.2019.2932436; Ma BY, 2022, J HYDROL, V605, DOI 10.1016/j.jhydrol.2021.127269; Maier R, 2020, WATER-SUI, V12, DOI 10.3390/w12041157; Manandhar B, 2023, LAND-BASEL, V12, DOI 10.3390/land12030627; Manzoor Z, 2022, FRONT ENV SCI-SWITZ, V10, DOI 10.3389/fenvs.2022.1021862; Martin MV, 2023, MANAG ORGAN HIST, V18, P81, DOI 10.1080/17449359.2023.2181184; Minár J, 2020, EARTH-SCI REV, V211, DOI 10.1016/j.earscirev.2020.103414; Mondal SK, 2022, SCI TOTAL ENVIRON, V822, DOI 10.1016/j.scitotenv.2022.153664; Mu XF, 2022, J GEOGR SCI, V32, P1766, DOI 10.1007/s11442-022-2022-5; Mugova E, 2022, WATER RES, V214, DOI 10.1016/j.watres.2021.118033; Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6; Newman D, 2009, J MACH LEARN RES, V10, P1801; Niu CJ, 2023, HYDROL RES, V54, P945, DOI 10.2166/nh.2023.040; Nsangou D, 2022, SCI AFR, V15, DOI 10.1016/j.sciaf.2021.e01043; Ogie RI, 2022, INT J DISAST RISK RE, V70, DOI 10.1016/j.ijdrr.2022.102783; Ouyang M, 2022, J HYDROL-REG STUD, V44, DOI 10.1016/j.ejrh.2022.101261; Parven A, 2022, INT J DISAST RISK RE, V78, DOI 10.1016/j.ijdrr.2022.103119; Pempek TA, 2009, J APPL DEV PSYCHOL, V30, P227, DOI 10.1016/j.appdev.2008.12.010; Piadeh F, 2022, J HYDROL, V607, DOI 10.1016/j.jhydrol.2022.127476; Raisio H, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14073983; Rana IA, 2022, URBAN CLIM, V45, DOI 10.1016/j.uclim.2022.101266; Rasool U, 2023, URBAN CLIM, V49, DOI 10.1016/j.uclim.2023.101573; Razavi S, 2020, HYDROL PROCESS, V34, P1996, DOI 10.1002/hyp.13723; RODRIGUEZ-IBANEZ M., 2023, A review on sentiment analysis from social media platforms; Rufaida A. S. R., 2023, ICAE 2022 P 5 INT C, P258; Ruidas D, 2022, ENVIRON EARTH SCI, V81, DOI 10.1007/s12665-022-10269-0; Rus K, 2018, INT J DISAST RISK RE, V31, P311, DOI 10.1016/j.ijdrr.2018.05.015; Saddiqa A., 2022, Pakistan Journal of Humanities and Social Sciences; Sajikumar N, 2015, J ENVIRON MANAGE, V161, P460, DOI 10.1016/j.jenvman.2014.12.041; Sajjad A., 2023, Environmental Sciences Proceedings, V25, P78; Saroj A, 2020, INT J DISAST RISK RE, V48, DOI 10.1016/j.ijdrr.2020.101584; Shah SMH, 2020, SCI AFR, V10, DOI 10.1016/j.sciaf.2020.e00651; Shan SQ, 2023, NAT HAZARDS, V118, P377, DOI 10.1007/s11069-023-06010-0; Shen MX, 2018, J HYDROL, V556, P10, DOI 10.1016/j.jhydrol.2017.11.004; Singh G, 2023, NAT HAZARDS, V117, P2935, DOI 10.1007/s11069-023-05972-5; Sitinjak E, 2018, PROCEDIA ENGINEER, V212, P222, DOI 10.1016/j.proeng.2018.01.029; Smith L, 2017, J FLOOD RISK MANAG, V10, P370, DOI 10.1111/jfr3.12154; Songchon C, 2021, COMPUT ENVIRON URBAN, V90, DOI 10.1016/j.compenvurbsys.2021.101690; Soomro SEH, 2023, APPL WATER SCI, V13, DOI 10.1007/s13201-023-01902-9; Soomro SEH, 2023, J WATER CLIM CHANGE, V14, P1132, DOI 10.2166/wcc.2023.308; Soomro SEH, 2023, NAT HAZARDS, V116, P2191, DOI 10.1007/s11069-022-05760-7; Soomro SEH, 2022, WATER RESOUR MANAG, V36, P2131, DOI 10.1007/s11269-022-03127-y; Soomro SEH, 2021, ACTA GEOPHYS, V69, P2291, DOI 10.1007/s11600-021-00677-4; Soomro SEH, 2021, WATER SUPPLY, V21, P3657, DOI 10.2166/ws.2021.129; Sun Y, 2022, J FLOOD RISK MANAG, V15, DOI 10.1111/jfr3.12826; Suna RR, 2022, INT J DISAST RISK RE, V82, DOI 10.1016/j.ijdrr.2022.103344; Tang YH, 2023, J HYDROL-REG STUD, V47, DOI 10.1016/j.ejrh.2023.101406; Tariq A., 2022, Land change modeler and CA-Markov chain analysis for land use land cover change using satellite data of Peshawar, Pakistan, V128; Treem JW., 2013, Ann. Int. Commun. Assoc., V36, P143, DOI [DOI 10.1080/23808985.2013.11679130, 10.1080/23808985.2013.11679130]; Vayansky I, 2020, INFORM SYST, V94, DOI 10.1016/j.is.2020.101582; Wang Y., 2020, In Social Sensing and Big Data Computing for Disaster Management, P68; Wardekker A, 2023, Urban Resilience: Methodologies, Tools and Evaluation: Theory and Practice, P17; Xie XL, 2021, NAT HAZARDS, V107, P2573, DOI 10.1007/s11069-021-04505-2; Yao F, 2020, COMPUT ENVIRON URBAN, V83, DOI 10.1016/j.compenvurbsys.2020.101522; Yao YC, 2022, J FLOOD RISK MANAG, V15, DOI 10.1111/jfr3.12834; Zafar S., 2019, Regional Environmental Change, P1; Zander K.K., 2022, Int. J. Disaster Risk Reduct.; Zhao W, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/607181; Zou L, 2021, Arxiv, DOI arXiv:2111.07187	104	1	1	4	4	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0022-1694	1879-2707		J HYDROL	J. Hydrol.	MAY	2024	634								131129	10.1016/j.jhydrol.2024.131129	http://dx.doi.org/10.1016/j.jhydrol.2024.131129			16	Engineering, Civil; Geosciences, Multidisciplinary; Water Resources	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Geology; Water Resources	UK5A8					2024-07-03	WOS:001247954000001
J	Pei, KX; Xuan, Z; Yang, JF; Jana, S; Ray, B				Pei, Kexin; Xuan, Zhou; Yang, Junfeng; Jana, Suman; Ray, Baishakhi			Learning Approximate Execution Semantics From Traces for Binary Function Similarity	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						Semantics; Task analysis; Computer architecture; Optimization; Codes; Behavioral sciences; Computational modeling; Binary analysis; large language models; software security		Detecting semantically similar binary functions - a crucial capability with broad security usages including vulnerability detection, malware analysis, and forensics - requires understanding function behaviors and intentions. This task is challenging as semantically similar functions can be compiled to run on different architectures and with diverse compiler optimizations or obfuscations. Most existing approaches match functions based on syntactic features without understanding the functions' execution semantics. We present Trex, a transfer-learning-based framework, to automate learning approximate execution semantics explicitly from functions' traces collected via forced-execution (i.e., by violating the control flow semantics) and transfer the learned knowledge to match semantically similar functions. While it is known that forced-execution traces are too imprecise to be directly used to detect semantic similarity, our key insight is that these traces can instead be used to teach an ML model approximate execution semantics of diverse instructions and their compositions. We thus design a pretraining task, which trains the model to learn approximate execution semantics from the two modalities (i.e., forced-executed code and traces) of the function. We then finetune the pretrained model to match semantically similar functions. We evaluate Trex on 1,472,066 functions from 13 popular software projects, compiled to run on 4 architectures (x86, x64, ARM, and MIPS), and with 4 optimizations (O0-O3) and 5 obfuscations. Trex outperforms the state-of-the-art solutions by 7.8%, 7.2%, and 14.3% in cross-architecture, optimization, and obfuscation function matching, respectively, while running 8x faster. Ablation studies suggest that the pretraining significantly boosts the function matching performance, underscoring the importance of learning execution semantics. Our case studies demonstrate the practical use-cases of Trex - on 180 real-world firmware images, Trex uncovers 14 vulnerabilities not disclosed by previous studies. We release the code and dataset of Trex at https://github.com/CUMLSec/trex.	[Pei, Kexin; Yang, Junfeng; Jana, Suman; Ray, Baishakhi] Columbia Univ, New York, NY 10027 USA; [Xuan, Zhou] Purdue Univ, W Lafayette, IN 47907 USA	Columbia University; Purdue University System; Purdue University	Pei, KX (corresponding author), Columbia Univ, New York, NY 10027 USA.	kpei@cs.columbia.edu; xuan1@purdue.edu; junfeng@cs.columbia.edu; suman@cs.columbia.edu; rayb@cs.columbia.edu		Pei, Kexin/0000-0001-5052-9808	NSF [CCF-18-45893, CCF-18-22965, CCF-16-19123, CNS-18-42456, CNS-18-01426, CNS-16-18771, CNS-16-17670, CNS-15-64055, CNS-15-63843]; ONR [N00014-17-1-2010, N00014-16-1-2263, N00014-17-1-2788]; ARO Young Investigator(YIP) award; Google Faculty Fellowship; MorganFaculty Research Award; Google Cloud Grant; Capital One Research Grant; Amazon Web Services Grant	NSF(National Science Foundation (NSF)); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); ARO Young Investigator(YIP) award; Google Faculty Fellowship(Google Incorporated); MorganFaculty Research Award; Google Cloud Grant(Google Incorporated); Capital One Research Grant; Amazon Web Services Grant	This work was supported in part by NSF under Grants CCF-18-45893, CCF-18-22965, CCF-16-19123, CNS-18-42456, CNS-18-01426, CNS-16-18771,CNS-16-17670, CNS-15-64055, and CNS-15-63843, in part by ONR underGrants N00014-17-1-2010, N00014-16-1-2263, and N00014-17-1-2788, inpart by an NSF CAREER award, in part by an ARO Young Investigator(YIP) award, in part by a Google Faculty Fellowship, in part by a JP MorganFaculty Research Award, in part by a DiDi Faculty Research Award, in partby a Google Cloud Grant, in part by a Capital One Research Grant, and inpart by an Amazon Web Services Grant.	Aghakhani H, 2020, 27TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2020), DOI 10.14722/ndss.2020.24310; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Ahmadi M, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2025; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Amazon Web Services, 2020, OP DISTR EL; [Anonymous], 2013, P 2 ACM SIGPLAN PROG; Arp D, 2021, Arxiv, DOI arXiv:2010.09470; Avgerinos T, 2014, COMMUN ACM, V57, P74, DOI 10.1145/2560217.2560219; Banerjee P, 2021, Arxiv, DOI arXiv:2103.12801; Bardin Sebastien, 2021, P MLPA 2020 MACH LEA; Bayer U., 2009, NDSS, V9, P8; Boytsov L, 2013, LECT NOTES COMPUT SC, V8199, P280, DOI 10.1007/978-3-642-41062-8_28; Brumley D, 2008, P IEEE S SECUR PRIV, P143, DOI 10.1109/SP.2008.17; Cai Lei, 2021, CIKM '21: Proceedings of the 30th ACM International Conference on Information & Knowledge Management, P3747, DOI 10.1145/3459637.3481955; Chandramohan M, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P678, DOI 10.1145/2950290.2950350; Chen YZ, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P477, DOI 10.1145/3460120.3484776; Chua ZL, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P99; Chunrong Fang, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P516, DOI 10.1145/3395363.3397362; Crussell Jonathan, 2013, Computer Security - ESORICS 2013. 18th European Symposium on Research in Computer Security. Proceedings: LNCS 8134, P182, DOI 10.1007/978-3-642-40203-6_11; David Y, 2017, ACM SIGPLAN NOTICES, V52, P79, DOI [10.1145/3140587.3062387, 10.1145/3062341.3062387]; David Y, 2016, ACM SIGPLAN NOTICES, V51, P266, DOI [10.1145/2980983.2908126, 10.1145/2908080.2908126]; David Y, 2014, ACM SIGPLAN NOTICES, V49, P349, DOI [10.1145/2594291.2594343, 10.1145/2666356.2594343]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding SHH, 2019, P IEEE S SECUR PRIV, P472, DOI 10.1109/SP.2019.00003; Duan Y, 2020, 27TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2020), DOI 10.14722/ndss.2020.24311; Egele M, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P303; Eschweiler S, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23185; Fan M, 2019, PROC INT CONF SOFTW, P771, DOI 10.1109/ICSE.2019.00085; Farhadi MR, 2014, INT CONF SOFTW SECUR, P78, DOI 10.1109/SERE.2014.21; Feng Q, 2016, P ACM SIGSAC C COMP, P480, DOI [DOI 10.1145/2976749.2978370, 10.1145/2976749.2978370]; Gao DB, 2008, LECT NOTES COMPUT SC, V5308, P238; Gao J, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P803, DOI 10.1145/3236024.3275524; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gottschall S., 2005, DD WRT; Guo WB, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1787; Heo K, 2017, PROC INT CONF SOFTW, P519, DOI 10.1109/ICSE.2017.54; Hu YK, 2017, INT C PROGRAM COMPRE, P88, DOI 10.1109/ICPC.2017.22; Huang H, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P155, DOI 10.1145/3052973.3052974; Jang J., 2013, P 22 USENIX SEC S US, P81; Jeon M, 2019, ACM T PROGR LANG SYS, V41, DOI 10.1145/3293607; Jiang LX, 2009, ISSTA 2009: INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P81; Jiang Ming, 2013, Information Security and Cryptology - ICISC 2012. 15th International Conference. Revised Selected Papers, P92, DOI 10.1007/978-3-642-37682-5_8; Jiang S, 2022, COMPUT SECUR, V120, DOI 10.1016/j.cose.2022.102804; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Jiang ZY, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1149, DOI 10.1145/3372297.3417240; Kapravelos Alexandros., 2013, Proceedings of the 22nd USENIX conference on Security, SEC'13, P637; Khoo WM, 2013, IEEE WORK CONF MIN S, P329, DOI 10.1109/MSR.2013.6624046; Kim D, 2022, Arxiv, DOI arXiv:2011.10749; Koo Hyungjoon, 2021, Semantic-aware binary code representation with bert; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Li XZX, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P3236, DOI 10.1145/3460120.3484587; Li YJ, 2019, PR MACH LEARN RES, V97; Liu FC, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1777, DOI 10.1145/3319535.3363224; Luo LN, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P389, DOI 10.1145/2635868.2635900; Lutz O, 2021, Arxiv, DOI [arXiv:2103.12607, DOI 10.48550/ARXIV.2103.12607]; Maier A, 2019, LECT NOTES COMPUT SC, V11543, P288, DOI 10.1007/978-3-030-22038-9_14; Marcelli A, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P2099; Massarelli L, 2019, LECT NOTES COMPUT SC, V11543, P309, DOI 10.1007/978-3-030-22038-9_15; McKee D, 2020, Arxiv, DOI arXiv:1906.02928; Mehrotra N, 2020, Arxiv, DOI arXiv:2011.11228; Melicher W, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2684, DOI 10.1145/3442381.3450062; Ming J, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P253; Ming J, 2015, IFIP ADV INF COMM TE, V455, P416, DOI 10.1007/978-3-319-18467-8_28; Mu DL, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P924, DOI 10.1109/ASE.2019.00090; Myles G, 2005, P 2005 ACM S APPL CO, P314, DOI DOI 10.1145/1066677.1066753; Nye Maxwell, 2021, arXiv; Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48; OWASP, 2010, TOP 10 WEB APPL SEC; Parihar S, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P92, DOI 10.1145/3059009.3059026; Paszke A, 2019, ADV NEUR IN, V32; Patrick-Evans J, 2020, ANN COMPUT SECURITY, P373, DOI 10.1145/3427228.3427265; Payer M, 2014, Arxiv, DOI arXiv:1409.7760; Pei KX, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P690, DOI 10.1145/3468264.3468607; Pei KX, 2021, 28TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2021), DOI 10.14722/ndss.2021.23112; Peng F, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P829; Perdisci R, 2008, ANN COMPUT SECURITY, P301, DOI 10.1109/ACSAC.2008.22; Pewny J., 2014, P 30 ANN COMP SEC AP, P406, DOI DOI 10.1145/2664243.2664269; Pewny J, 2015, P IEEE S SECUR PRIV, P709, DOI 10.1109/SP.2015.49; Quynh N.A., 2015, Unicorn: Next generation cpu emulator framework; Reddy S, 2020, PROC INT CONF SOFTW, P1410, DOI 10.1145/3377811.3380399; Redmond K, 2018, Arxiv, DOI arXiv:1812.09652; Rieck K, 2011, J COMPUT SECUR, V19, P639, DOI 10.3233/JCS-2010-0410; Shrestha S.L., 2021, Slgpt: Using transfer learning to directly generate simulink model files and find bugs in the simulink toolchain; Vaswani A, 2017, ADV NEUR IN, V30; Wang HT, 2021, IEEE T INF FOREN SEC, V16, P1943, DOI 10.1109/TIFS.2020.3044773; Wang K., 2017, PROC INT C LEARN REP; Wang K, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P121, DOI 10.1145/3385412.3385999; Wang SQ, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1599; Wang S, 2017, PROC IEEE INT CONF S, P388, DOI 10.1109/ICSME.2017.59; Wartschinski L, 2022, INFORM SOFTWARE TECH, V144, DOI 10.1016/j.infsof.2021.106809; Wen M, 2020, IEEE T SOFTWARE ENG, V46, P1155, DOI 10.1109/TSE.2018.2876256; Wong E, 2018, PR MACH LEARN RES, V80; Xu XJ, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P363, DOI 10.1145/3133956.3134018; Yang J, 2021, IEEE T SOFTWARE ENG, V48, P2224, DOI 10.1109/TSE.2021.3056139; Yang LM, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2327; Yu Zeping, 2020, Advances in Neural Information Processing Systems, V33, P3872; Zhang N., 2017, Hikari-an improvement over Obfuscator; Zhao L, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P149, DOI 10.1145/3372297.3423342; Zuo F, 2018, Arxiv, DOI arXiv:1808.04706; Zynamics, 2019, BINDIFF	100	7	8	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	APR 1	2023	49	4					2776	2790		10.1109/TSE.2022.3231621	http://dx.doi.org/10.1109/TSE.2022.3231621			15	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E9NM9					2024-07-03	WOS:000978723600077
J	Shahin, M; Chen, FF; Hosseinzadeh, A; Maghanaki, M; Eghbalian, A				Shahin, Mohammad; Chen, F. Frank; Hosseinzadeh, Ali; Maghanaki, Mazdak; Eghbalian, Ayda			A novel approach to voice of customer extraction using GPT-3.5 Turbo: linking advanced NLP and Lean Six Sigma 4.0	INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY			English	Article						ChatGPT; Large language model; VoC; Lean Six Sigma; Text mining and analysis; Industry 4.0		This research breaks new ground by utilizing the advanced natural language processing (NLP) capabilities of OpenAI's GPT-3.5 Turbo model for the extraction of voice of customer (VoC) data from online customer support interactions on Twitter. Traditional methods of VoC extraction have typically fallen short in capturing the richness and nuance of customer sentiment. Contemporary machine learning (ML) approaches, while improved, still struggle to interpret the contextual subtleties of digital customer communications effectively. This study showcases the innovative deployment of GPT-3.5 Turbo, demonstrating its superior performance in extracting VoC through a deeper understanding of conversational context and a more intuitive, chat-based data processing. Furthermore, the large-scale, multilingual processing capabilities of this model offer a more comprehensive and inclusive analysis of VoC. The study ties these advancements to Lean Six Sigma 4.0, illustrating how the integration of GPT-3.5 Turbo's transformative capabilities can elevate the customer-centric approach of Lean Six Sigma in the era of Industry 4.0. This innovative exploration points to a significant evolution in VoC analysis, offering potential for more insightful, real-time data-driven customer service strategies and a more substantial foundation for decision-making in product development and process improvement. Future research is encouraged to validate these preliminary findings and to investigate ethical considerations associated with the use of such advanced NLP models.	[Shahin, Mohammad; Chen, F. Frank; Hosseinzadeh, Ali; Maghanaki, Mazdak] Univ Texas San Antonio, Mech Engn Dept, San Antonio, TX 78249 USA; [Eghbalian, Ayda] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX USA	University of Texas System; University of Texas at San Antonio (UTSA); University of Texas System; University of Texas at San Antonio (UTSA)	Chen, FF (corresponding author), Univ Texas San Antonio, Mech Engn Dept, San Antonio, TX 78249 USA.	ff.chen@utsa.edu			U.S. Office of Naval Research MEEP Program [N00014-19-1-2728]; U.S. Department of Energy/NNSA [DE-NA0004003]; Lutcher Brown Distinguished Chair Professorship fund of the University of Texas at San Antonio	U.S. Office of Naval Research MEEP Program(United States Department of DefenseUnited States NavyOffice of Naval Research); U.S. Department of Energy/NNSA(National Nuclear Security AdministrationUnited States Department of Energy (DOE)); Lutcher Brown Distinguished Chair Professorship fund of the University of Texas at San Antonio	The reported research work received partial financial support from the U.S. Office of Naval Research MEEP Program (Award Number: N00014-19-1-2728), U.S. Department of Energy/NNSA (Award Number: DE-NA0004003), as well as from the Lutcher Brown Distinguished Chair Professorship fund of the University of Texas at San Antonio.	Ahmad Z, 2023, INDIAN EXPRESS; [Anonymous], 6 SIGM CERT; Barravecchia F, 2022, QUAL ENG, V34, P344, DOI 10.1080/08982112.2022.2057805; Barravecchia F, 2022, INT J QUAL RELIAB MA, V39, P1453, DOI 10.1108/IJQRM-07-2021-0217; Bi JW, 2019, INT J PROD RES, V57, P7068, DOI 10.1080/00207543.2019.1574989; CheshmehSohrabi M, 2023, J PSYCHOLINGUIST RES, V52, P607, DOI 10.1007/s10936-022-09911-6; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Devlin J., 2018, BERT PRE TRAINING DE; Elg M, 2021, PROD PLAN CONTROL, V32, P990, DOI 10.1080/09537287.2020.1780509; Found P, 2012, INT J LEAN SIX SIG, V3, P251, DOI 10.1108/20401461211282736; Ganjavi N, 2023, IEEE T ENG MANAGE, V70, P2320, DOI 10.1109/TEM.2021.3078169; Gedeon T, 2019, NEURAL INFORM PROCES, V11955; Groves RM, 2006, PUBLIC OPIN QUART, V70, P646, DOI 10.1093/poq/nfl033; Huang Y, 2023, MEDIUM; kaggle, Customer Support on Twitter; Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003; Koodiani HK, 2024, J BUILD ENG, V84, DOI 10.1016/j.jobe.2024.108492; Koodiani HK, 2023, STRUCTURES, V56, DOI 10.1016/j.istruc.2023.105060; Kovacs Mate, 2021, CCIOT2021: 2021 6th International Conference on Cloud Computing and Internet of Things, P41, DOI 10.1145/3493287.3493294; Kovalev AK, 2022, DOKL MATH, V106, pS85, DOI 10.1134/S1064562422060138; Kumar M, 2020, INT J PROD ECON, V219, P469, DOI 10.1016/j.ijpe.2018.04.007; Leippold M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2022.103617; Levesque TJ, 1996, REV CAN SCI ADMIN, V13, P264; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Mastrogiacomo L, 2021, QUAL ENG, V33, P425, DOI 10.1080/08982112.2021.1877305; Mastrogiacomo L, 2019, INT J ADV MANUF TECH, V103, P3927, DOI 10.1007/s00170-019-03740-z; Mohammad S, 2023, WASTE REDUCTION VIA; Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116; Ohlig J., 2021, PROC INT C IND ENG O, P232; OpenAI R, 2023, arXiv; Orsingher C, 2010, J ACAD MARKET SCI, V38, P169, DOI 10.1007/s11747-009-0155-z; Özdagoglu G, 2018, TOTAL QUAL MANAG BUS, V29, P1545, DOI 10.1080/14783363.2016.1273106; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3248401; Patel L, 2020, INNOVATIVE STARTUPS; Radford A., 2018, IMPROVING LANGUAGE U; Raghavan VA, 2014, INT J LEAN SIX SIG, V5, P342, DOI 10.1108/IJLSS-07-2013-0042; Rand G, 1997, J OPER RES SOC, V48, P1148, DOI 10.2307/3010314; Sánchez-Núñez P, 2020, IEEE ACCESS, V8, P134563, DOI 10.1109/ACCESS.2020.3009482; Shahin M., 2023, Flex. Autom. Intell. Manuf. Hum.-Data-Technol. Nexus, P99, DOI [10.1007/978-3-031-18326-3_10, DOI 10.1007/978-3-031-18326-3_10]; Shahin M, 2023, INT J ADV MANUF TECH, V128, P3857, DOI 10.1007/s00170-023-12020-w; Shahin M, 2022, INT J ADV MANUF TECH, V123, P1973, DOI 10.1007/s00170-022-10329-6; Shahin M, 2022, INT J ADV MANUF TECH, V123, P2017, DOI 10.1007/s00170-022-10259-3; Shahin M, 2020, PROCEDIA MANUF, V51, P1184, DOI 10.1016/j.promfg.2020.10.166; Shahin M, 2020, INT J ADV MANUF TECH, V107, P2927, DOI 10.1007/s00170-020-05124-0; Shams R, 2014, ARXIV; SONG X, 2023, NEURAL PROCESS LETT, P1; Song XA, 2023, NEUROCOMPUTING, V550, DOI 10.1016/j.neucom.2023.126498; Sony M, 2020, TQM J, V32, P779, DOI 10.1108/TQM-12-2019-0275; Stentoft J, 2021, PROD PLAN CONTROL, V32, P811, DOI 10.1080/09537287.2020.1768318; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Thomas T., 2023, MATER TODAY-PROC, DOI [10.1016/j.matpr.2023.06.010, DOI 10.1016/J.MATPR.2023.06.010]; Thorpe C.T., 2021, Scale development: theory and applications, V4th ed., DOI [10.1111/peps.12499, DOI 10.1111/PEPS.12499]; Tirunillai S, 2014, J MARKETING RES, V51, P463, DOI 10.1509/jmr.12.0106; Tronvoll B, 2012, EUR J MARKETING, V46, P284, DOI 10.1108/03090561211189338; Vaswani A, 2017, ADV NEUR IN, V30; Veres C, 2022, IEEE ACCESS, V10, P61970, DOI 10.1109/ACCESS.2022.3182505; Virmani Naveen, 2018, International Journal of Productivity and Quality Management, V23, P385; Virmani Naveen, 2017, International Journal of Productivity and Quality Management, V22, P499; Virmani N, 2023, TECHNOL FORECAST SOC, V188, DOI 10.1016/j.techfore.2023.122317; Virmani N, 2023, IEEE T ENG MANAGE, V70, P3976, DOI 10.1109/TEM.2021.3091398; Virmani N, 2019, EUR J IND ENG, V13, P701, DOI 10.1504/EJIE.2019.104293; Walsh T., 2022, The Conversation; Yang ZL, 2019, ADV NEUR IN, V32; Zhang M, 2022, INT J PROD ECON, V254, DOI 10.1016/j.ijpe.2022.108641; Zhou QY, 2019, INT J ADV MANUF TECH, V104, P3229, DOI 10.1007/s00170-017-1192-2; Zonnenshain A, 2020, QUAL ENG, V32, P614, DOI 10.1080/08982112.2019.1706744	67	1	1	13	13	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0268-3768	1433-3015		INT J ADV MANUF TECH	Int. J. Adv. Manuf. Technol.	APR	2024	131	7-8					3615	3630		10.1007/s00170-024-13167-w	http://dx.doi.org/10.1007/s00170-024-13167-w		FEB 2024	16	Automation & Control Systems; Engineering, Manufacturing	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Engineering	MD5F6		Green Submitted			2024-07-03	WOS:001164366100007
C	Bhowmick, AK; Jagmohan, A; Vempaty, A; Dey, P; Hall, L; Hartman, J; Kokku, R; Maheshwari, H		Bramer, M; Stahl, F		Bhowmick, Ayan Kumar; Jagmohan, Ashish; Vempaty, Aditya; Dey, Prasenjit; Hall, Leigh; Hartman, Jeremy; Kokku, Ravi; Maheshwari, Hema			Automating Question Generation From Educational Text	ARTIFICIAL INTELLIGENCE XL, AI 2023	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	43rd SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence (AI)	DEC 12-14, 2023	Cambridge, ENGLAND	British Comp Soc Specialist Grp Artificial Intelligence, Chartered Inst IT		Automatic question generation; Large language models; Generative AI; Distractors; Question-based activities; Multiple-choice questions		The use of question-based activities (QBAs) is wide-spread in education, traditionally forming an integral part of the learning and assessment process. In this paper, we design and evaluate an automated question generation tool for formative and summative assessment in schools. We present an expert survey of one hundred and four teachers, demonstrating the need for automated generation of QBAs, as a tool that can significantly reduce the workload of teachers and facilitate personalized learning experiences. Leveraging the recent advancements in generative AI, we then present a modular framework employing transformer based language models for automatic generation of multiple-choice questions (MCQs) from textual content. The presented solution, with distinct modules for question generation, correct answer prediction, and distractor formulation, enables us to evaluate different language models and generation techniques. Finally, we perform an extensive quantitative and qualitative evaluation, demonstrating trade-offs in the use of different techniques and models.	[Bhowmick, Ayan Kumar; Jagmohan, Ashish; Vempaty, Aditya; Dey, Prasenjit; Hall, Leigh; Hartman, Jeremy; Kokku, Ravi; Maheshwari, Hema] Merlyn Mind Inc, New York, NY 10174 USA		Bhowmick, AK (corresponding author), Merlyn Mind Inc, New York, NY 10174 USA.	ayan@merlyn.org; ashish@merlyn.org; aditya@merlyn.org; prasenjit@merlyn.org; leigh@merlyn.org; jeremy@merlyn.org; ravi@merlyn.org; hema@merlyn.org						Ahmad B., 2019, European Journal of Business Social Sciences, V7, P776; Ahmad SF, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132212902; Bethencourt-Aguilar A., 2023, Use of generative adversarial networks (GANS) in educational technology research; Chen Stanley F., 1998, Evaluation Metrics for Language Models; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ethayarajh K, 2019, Arxiv, DOI [arXiv:1909.00512, DOI 10.18653/V1/D19]; Faruqui M., 2018, arXiv; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Griffith Shane, 2013, Advances in neural information processing systems, V26; Grover K., 2021, Revised Selected Papers, P243; Kriangchaivech K, 2019, Arxiv, DOI arXiv:1909.05017; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lee Jinhyuk, 2021, arXiv; Liang C., 2018, P 13 WORKSHOP INNOVA, P284; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Miles M. B., 2014, QUALITATIVE DATA ANA, DOI DOI 10.1080/10572252.2015.975966; Radford A., 2018, IMPROVING LANGUAGE U; Radford A, 2016, Arxiv, DOI arXiv:1511.06434; Salda├a┬▒a J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004; Schluter N., 2017, P 15 C EUROPEAN CHAP, P41, DOI 10.18653/v1/e17-2007; Solas E., 2018, Res. Soc. Sci. Technol., V3, P1; Stanja J, 2023, BRIT J EDUC TECHNOL, V54, P58, DOI 10.1111/bjet.13288; Zhang CN, 2023, Arxiv, DOI arXiv:2303.11717	24	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-47993-9; 978-3-031-47994-6	LECT NOTES ARTIF INT			2023	14381						437	450		10.1007/978-3-031-47994-6_38	http://dx.doi.org/10.1007/978-3-031-47994-6_38			14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5JS		Green Submitted			2024-07-03	WOS:001162078800038
J	Sohail, SS; Farhat, F; Himeur, Y; Nadeem, M; Madsen, DO; Singh, Y; Atalla, S; Mansoor, W				Sohail, Shahab Saquib; Farhat, Faiza; Himeur, Yassine; Nadeem, Mohammad; Madsen, Dag Oivind; Singh, Yashbir; Atalla, Shadi; Mansoor, Wathiq			Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions	JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES			English	Article						ChatGPT; Large language models (LLMs); Generative Pre-trained Transformer (GPT); AI Generated Content (AIGC); Systematic review; Trustworthy AI	ARTIFICIAL-INTELLIGENCE	Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.(c) 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	[Sohail, Shahab Saquib] Jamia Hamdard, Sch Engn Sci & Technol, Dept Comp Sci & Engn, New Delhi 110062, India; [Farhat, Faiza] Aligarh Muslim Univ, Dept Zool, Aligarh, Uttar Pradesh, India; [Himeur, Yassine; Atalla, Shadi; Mansoor, Wathiq] Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates; [Nadeem, Mohammad] Aligarh Muslim Univ, Dept Comp Sci, Aligarh, Uttar Pradesh, India; [Madsen, Dag Oivind] Univ South Eastern Norway, Notodden, Norway; [Singh, Yashbir] Mayo Clin, Dept Radiol, Rochester, MN USA	Jamia Hamdard University; Aligarh Muslim University; University of Dubai; Aligarh Muslim University; University College of Southeast Norway; Mayo Clinic	Farhat, F (corresponding author), Aligarh Muslim Univ, Dept Zool, Aligarh, Uttar Pradesh, India.; Madsen, DO (corresponding author), Univ South Eastern Norway, Notodden, Norway.	shahabssohail@jamiahamdard.ac.in; faizahaque16@gmail.com; yhimeur@ud.ac.ae; nadeem.amu@gmail.com; dag.oivind.madsen@usn.no; Singh.Yashbir@mayo.edu; satalla@ud.ac.ae; wathiq.mansoor@ud.ac.ae	sohail, shahab/O-3263-2019; Atalla, Shadi/KAO-2626-2024; FARHAT, FAIZA/KIK-8175-2024; Himeur, Yassine/AAK-7814-2021; Madsen, Dag Øivind/I-1587-2016	sohail, shahab/0000-0002-5944-7371; Himeur, Yassine/0000-0001-8904-5587; Madsen, Dag Øivind/0000-0001-8735-3332				Abdel-Messih M.S., 2023, JMIR. Med. Educ., V9; Aczel B., 2023, Transparency guidance for chatgpt usage in scientific writing; Agathokleous E, 2023, SCI TOTAL ENVIRON, V888, DOI 10.1016/j.scitotenv.2023.164154; Ahmad A., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2302.14600; Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; AI O., 2023, GPT-4 Technical Report; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; Ali J. K. M., 2023, Journal of English Studies in Arabia Felix, V2, P41, DOI DOI 10.56540/JESAF.V2I1.51; Ali M.J., 2023, Seminars Ophthalmol; Ali MJ, 2023, SEMIN OPHTHALMOL, V38, P403, DOI 10.1080/08820538.2023.2193444; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Alkhaqani A. L., 2023, Al-Rafidain Journal of Medical Sciences, V4, P50; Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; Amancio DR, 2015, SCIENTOMETRICS, V105, P1763, DOI 10.1007/s11192-015-1637-z; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; Aminah S, 2023, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdad065; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Arif T.B., 2023, The future of medical education and research: Is chatgpt a blessing or blight in disguise?; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Bashshur R, 2020, TELEMED E-HEALTH, V26, P571, DOI 10.1089/tmj.2020.29040.rb; Batko K, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-021-00553-4; Beerbaum D.O., 2023, Generative Artificial Intelligence (GAI) with Chat GPT for Accounting-A business case; Bhattacharyya R., 2023, Journal of SAARC Psychiatric Federation, V1, P6; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bishop L., 2023, Res. Writing, V26; Biswas S., 2023, Reducing cardiologist's burden: Can chatgpt assist in writing discharge summaries of cardiac icu patients?; Biswas S., 2023, Chatgpt and the future of medical writing; Biswas S., 2023, Prospective Role of Chat GPT in the Military: According to ChatGPT; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bom HSH, 2023, NUCL MED MOLEC IMAG, V57, P165, DOI 10.1007/s13139-023-00809-2; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Budler LC, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1487; Budzianowski P, 2019, Arxiv, DOI arXiv:1907.05774; Cahan P, 2023, STEM CELL REP, V18, P1, DOI 10.1016/j.stemcr.2022.12.009; Çaliyurt O, 2023, ALPHA PSYCHIAT, V24, P41, DOI 10.5152/alphapsychiatry.2023.010223; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chen AK, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104370; Chen H, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-023-3740-x; Chen M., 2021, arXiv; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Chen X., 2023, Internet Ref. Serv. Quart.; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Christiano PF, 2017, ADV NEUR IN, V30; Chuma E., 2023, Business ai decision-making tools: Case chatgpt evaluation; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Corrêa EA, 2019, PHYSICA A, V523, P180, DOI 10.1016/j.physa.2019.02.032; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; Cox L.A., 2023, Global Epidemiol., V5; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Domnich A, 2021, Arxiv, DOI [arXiv:2103.11436, 10.48550/arXiv.2103.11436, DOI 10.48550/ARXIV.2103.11436]; DONMEZ I., 2023, J STEAM ED, V6, P101, DOI DOI 10.55290/STEAM.1263404; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Du H., 2023, IEEE Trans. Intell. Vehic; Dugan L, 2022, Arxiv, DOI arXiv:2212.12672; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dwivedi YK, 2021, INT J INFORM MANAGE, V59, DOI 10.1016/j.ijinfomgt.2020.102168; Editorialge, 2023, Elsevier and Cambridge university allow use of chatgpt for academic writing; Eggmann F., 2023, J. Esthetic Restorat. Dentist.; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Ernst NA, 2022, IEEE SOFTWARE, V39, P106, DOI 10.1109/MS.2021.3133805; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Firat M., 2023, How Chat Gpt Can Transform Autodidactic Experiences and Open Education; Frye B.L., 2022, Fordham Intell. Property, Media Entertain. Law J; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gao MQ, 2023, Arxiv, DOI arXiv:2304.02554; Gao Y., 2023, IEEE Trans. Intell. Vehic., P1; Gasevic D., 2023, Artif. Intell.; Geerling W., 2023, Is ChatGPT Smarter than a student in principles of economics?; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Gilson A., 2023, JMIR Med. Educ., V9; Gilson A., 2022, MEDRXIV; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gravel J., 2023, medRxiv; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Guo C, 2023, IEEE-CAA J AUTOMATIC, V10, P835, DOI 10.1109/JAS.2023.123555; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Harskamp R.E., 2023, medRxiv; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Hill-Yardin Elisa L., 2023, Brain, Behavior, and Immunity, pS0889; Himeur Y., 2022, Sustainable Cities and Society; Himeur Y, 2023, ARTIF INTELL REV, V56, P4929, DOI 10.1007/s10462-022-10286-2; Hirosawa T., 2023, Int. J. Env. Res. Pub. He, V20; Hisan U. K., 2023, Journal of Pedagogy and Education Science, V2, P71, DOI [DOI 10.56741/JPES.V2I01.302, 10.56741/jpes.v2i01.302]; Hong W.C.H., 2023, J. Educ. Technol. Innovat., V3; Hoppner T., 2023, An Introduction to AI for Competition and Regulatory Lawyers, P9; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Huang JS, 2023, AM J CANCER RES, V13, P1148; Huh S, 2023, SCI EDIT, V10, P1, DOI 10.6087/kcse.290; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Jain D.K., ACM Trans. Asian Low-Resour. Lang. Inf. Process; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jawahar G, 2020, Arxiv, DOI arXiv:2011.01314; Johinke R, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.01; Jungwirth D, 2023, INT J ENV RES PUB HE, V20; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kaneda Y., 2023, Can chatgpt pass the 2023 japanese national medical licensing examination?; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Kitchenham B., 2004, Keele, U.K., Keele Univ., VVolume 33, P1; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Koo M, 2023, RADIOLOGY, V307; Kshetri N, 2023, IT PROF, V25, P16, DOI 10.1109/MITP.2023.3254639; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Lei L., 2023, Intell. Robot., V3, P145, DOI [DOI 10.20517/IR.2023.08, 10.20517/ir.2023.08]; Li LY, 2023, Arxiv, DOI [arXiv:2305.02201, 10.48550/arXiv.2305.02201]; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lim W.M., 2023, Int. J. Manage. Educ., V21; Lin CC, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15054012; Lin F, 2023, CCF T HIGH PERFORM C, V5, P442, DOI 10.1007/s42514-023-00173-9; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lubiana T, 2023, Arxiv, DOI [arXiv:2303.16429, DOI 10.48550/ARXIV.2303.16429]; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Lund B. D., 2023, Library Hi Tech News; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Maad M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P65, DOI DOI 10.52866/IJCSM.2023.01.01.0019; Maddigan P, 2023, Arxiv, DOI arXiv:2302.02094; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; McGee R.W., 2023, Capitalism, socialism and chatgpt; McGee R.W., 2023, Chatgpt Reply; Medenilla A., 2023, PLoS Digital Health, V2; Megahed F. M., 2023, How generative ai models such as chatgpt can be (mis)used in spc practice, education, DOI 10.48550/ARXIV.2302.10916; Melis G, 2017, Arxiv, DOI arXiv:1707.05589; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Mitrovic Sandra, 2023, arXiv; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nakaya Y., 2023, Eur. Heart J.-Digital Health; Naumova E.N., 2023, J. Public Health Policy; NewsGuard, 2023, The Next Great Misinformation Superspreader: How ChatGPT Could Spread Toxic Misinformation At Unprecedented Scale; Odir J., 2023, 2023 IEEE GLOB ENG E, P1; Odom-Forren J, 2023, J PERIANESTH NURS, V38, P176, DOI 10.1016/j.jopan.2023.02.006; OpenAI, 2023, Chatgpt: Optimizing language models for dialogue; Ortega-Martin M, 2023, Arxiv, DOI arXiv:2302.06426; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pahl J., 2022, 2022 ACM C FAIRN ACC; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Prada Paco, 2023, Rev Med Suisse, V19, P532, DOI 10.53738/REVMED.2023.19.818.532; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Qiu H., 2023, PREPRINT; Quispe LVC, 2021, PHYSICA A, V562, DOI 10.1016/j.physa.2020.125344; Rahimi F., 2023, Arch. Med. Res.; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Rathore B., 2023, Eduzone: International Peer Reviewed/Refereed Multidisciplinary Journal, V12, P52; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Roosan D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P285, DOI 10.1109/ICHI.2016.39; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Sallam M, 2023, medRxiv; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sedaghat S, 2023, CLIN MED, V23, P278, DOI 10.7861/clinmed.2023-0078; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Siegerink B, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103599; Sifat RI, 2023, ANN BIOMED ENG, V51, P1357, DOI 10.1007/s10439-023-03204-2; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Skalidis I., 2023, Eur. Heart J.-Digital Health; Slapeta J, 2023, TRENDS PARASITOL, V39, P314, DOI 10.1016/j.pt.2023.02.006; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sohail S. S., 2023, ChatGPT and vaccines: Can AI Chatbots boost awareness and uptake?; Sohail S.S., 2023, Using chatgpt to navigate ambivalent and contradictory research findings on artificial intelligence; Stella M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222870; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker Chris, 2022, Nature; Street D., 2023, applying chatgpt and other large language models to the practice of forensic accounting; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Talan T., 2023, Uluslararasi Yonetim Bilisim Sistemleri ve Bilgisayar Bilimleri Dergisi, V7, P33, DOI [DOI 10.33461/UYBISBBD.1244777, https://doi.org/10.33461/uybisbbd.1244777]; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tomlinson B, 2023, Arxiv, DOI arXiv:2305.03722; Tong YJ, 2023, SYN SYST BIOTECHNO, V8, P220, DOI 10.1016/j.synbio.2023.02.004; Tregoning J., 2023, Nature; Ufuk F, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230276; Uludag K., 2023, Testing creativity of chatgpt in psychology: Interview with chatgpt; Van Bulck L, 2023, EUR J CARDIOVASC NUR; van Schalkwyk G., 2023, Artificial intelligence in pediatric behavioral health; Vemprala S., 2023, Microsoft Auton. Syst. Robot. Res; Wake N, 2023, Arxiv, DOI arXiv:2304.03893; Wang CG, 2019, Arxiv, DOI [arXiv:1904.09408, DOI 10.48550/ARXIV.1904.09408]; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P2011, DOI 10.1109/TIV.2023.3256799; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang SH, 2023, NATURE, V615, P34, DOI 10.1038/d41586-023-00553-9; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Williams M.C., 2023, J. Cardiovasc. Comput. Tomogr.; Wu JG, 2024, Arxiv, DOI arXiv:2305.10163; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; You HX, 2023, Arxiv, DOI arXiv:2304.11018; Zhang J., 2023, IEEE Trans. Intell. Vehic; Zhang M, 2021, FUND RES-CHINA, V1, P831, DOI 10.1016/j.fmre.2021.11.011; Zheng O, 2023, Arxiv, DOI arXiv:2303.05382; Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046; Zhu J.-J., 2023, Environ. Sci. Technol.; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	227	19	19	149	149	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1319-1578	2213-1248		J KING SAUD UNIV-COM	J. King Saud Univ.-Comput. Inf. Sci.	SEP	2023	35	8							101675	10.1016/j.jksuci.2023.101675	http://dx.doi.org/10.1016/j.jksuci.2023.101675		AUG 2023	23	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GA8T2		Green Submitted, gold, Green Published			2024-07-03	WOS:001150035400001
J	Nguyen, T				Nguyen, Tina			ChatGPT in Medical Education: A Precursor for Automation Bias?	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; artificial intelligence; AI; medical students; residents; medical school curriculum; medical education; automation bias; large language models; LLMs; bias		Artificial intelligence (AI) in health care has the promise of providing accurate and efficient results. However, AI can also be a black box, where the logic behind its results is nonrational. There are concerns if these questionable results are used in patient care. As physicians have the duty to provide care based on their clinical judgment in addition to their patients' values and preferences, it is crucial that physicians validate the results from AI. Yet, there are some physicians who exhibit a phenomenon known as automation bias, where there is an assumption from the user that AI is always right. This is a dangerous mindset, as users exhibiting automation bias will not validate the results, given their trust in AI systems. Several factors impact a user's susceptibility to automation bias, such as inexperience or being born in the digital age. In this editorial, I argue that these factors and a lack of AI education in the medical school curriculum cause automation bias. I also explore the harms of automation bias and why prospective physicians need to be vigilant when using AI. Furthermore, it is important to consider what attitudes are being taught to students when introducing ChatGPT, which could be some students' first time using AI, prior to their use of AI in the clinical setting. Therefore, in attempts to avoid the problem of automation bias in the long-term, in addition to incorporating AI education into the curriculum, as is necessary, the use of ChatGPT in medical education should be limited to certain tasks. Otherwise, having no constraints on what ChatGPT should be used for could lead to automation bias.	[Nguyen, Tina] Univ Texas Med Branch, 301 Univ Blvd, Galveston, TX 77551 USA	University of Texas System; University of Texas Medical Branch Galveston	Nguyen, T (corresponding author), Univ Texas Med Branch, 301 Univ Blvd, Galveston, TX 77551 USA.	nguy.t921@gmail.com	Nguyen, Tina/KGL-3734-2024	Nguyen, Tina/0000-0002-3021-8161				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Blanco-González A, 2022, Arxiv, DOI arXiv:2212.08104; Civaner MM, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03852-3; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Feng SW, 2023, ACAD MED, V98, P867, DOI 10.1097/ACM.0000000000005242; Gaube S, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00385-9; Goddard K, 2014, INT J MED INFORM, V83, P368, DOI 10.1016/j.ijmedinf.2014.01.001; Ho Anita., 2023, Live Like Nobody Is Watching; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Johnston SC, 2018, ACAD MED, V93, P1105, DOI 10.1097/ACM.0000000000002175; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Klugman CM, 2017, J MED HUMANIT, V38, P419, DOI 10.1007/s10912-017-9453-5; Landsbach Grant D, 2016, J AHIMA, V87, P40; Logg JM, 2019, ORGAN BEHAV HUM DEC, V151, P90, DOI 10.1016/j.obhdp.2018.12.005; Lubell J, 2023, What does it mean for med ed?; Lyell D, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0425-5; Nabi W, 2021, Utilizing technology to address gaps in medical education; Ngo B, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220074; Nguyen T, 2023, J MED ETHICS, V49, P549, DOI 10.1136/jme-2023-109112; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Pfeifer CM, 2018, MED EDUC ONLINE, V23, DOI 10.1080/10872981.2018.1427988; Pozzi G, 2023, J MED ETHICS, V49, P536, DOI 10.1136/jme-2022-108630; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; students-residents.aamc.org, What to expect in medical school; Tiwari CK, 2023, INTERACT TECHNOL SMA, DOI 10.1108/ITSE-04-2023-0061; van de Ridder JMM, 2023, ACAD MED, V98, P867, DOI 10.1097/ACM.0000000000005254; Wang DY, 2023, J AM MED INFORM ASSN, V30, P1684, DOI 10.1093/jamia/ocad118; Yun Heather C, 2020, J Grad Med Educ, V12, P797, DOI 10.4300/JGME-D-20-00794.1; Yusof YAM, 2022, ADV HUM BIOL, V12, P101, DOI 10.4103/aihb.aihb_150_21	29	2	2	14	14	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e50174	10.2196/50174	http://dx.doi.org/10.2196/50174			6	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	GY2O3	38231545	Green Published, gold			2024-07-03	WOS:001156171900001
J	Woelfel, M; Shirzad, MB; Reich, A; Anderer, K; Leung, CK				Woelfel, Matthias; Shirzad, Mehrnoush Barani; Reich, Andreas; Anderer, Katharina; Leung, Carson K.			Knowledge-Based and Generative-AI-Driven Pedagogical Conversational Agents: A Comparative Study of Grice's Cooperative Principles and Trust	BIG DATA AND COGNITIVE COMPUTING			English	Article						conversational agent; chatbot; education; large language model; generative language model; retrieval augmented generation; generative AI; digital tutor; digital assistant		The emergence of generative language models (GLMs), such as OpenAI's ChatGPT, is changing the way we communicate with computers and has a major impact on the educational landscape. While GLMs have great potential to support education, their use is not unproblematic, as they suffer from hallucinations and misinformation. In this paper, we investigate how a very limited amount of domain-specific data, from lecture slides and transcripts, can be used to build knowledge-based and generative educational chatbots. We found that knowledge-based chatbots allow full control over the system's response but lack the verbosity and flexibility of GLMs. The answers provided by GLMs are more trustworthy and offer greater flexibility, but their correctness cannot be guaranteed. Adapting GLMs to domain-specific data trades flexibility for correctness.	[Woelfel, Matthias; Anderer, Katharina] Karlsruhe Univ Appl Sci, Fac Comp Sci & Business Informat Syst, Moltkestr 30, D-76131 Karlsruhe, Germany; [Woelfel, Matthias; Shirzad, Mehrnoush Barani; Reich, Andreas] Univ Hohenheim, Fac Business Econ & Social Sci, Schloss Hohenheim 1, D-70599 Stuttgart, Germany; [Anderer, Katharina] Karlsruher Inst Technol KIT, Fac Comp Sci, Inst Anthropomat & Robot IAR, Kaiserstr 12, D-76131 Karlsruhe, Germany	Karlsruhe University of Applied Sciences; University Hohenheim; Helmholtz Association; Karlsruhe Institute of Technology	Woelfel, M (corresponding author), Karlsruhe Univ Appl Sci, Fac Comp Sci & Business Informat Syst, Moltkestr 30, D-76131 Karlsruhe, Germany.; Woelfel, M (corresponding author), Univ Hohenheim, Fac Business Econ & Social Sci, Schloss Hohenheim 1, D-70599 Stuttgart, Germany.	matthias.woelfel@h-ka.de; katharina.anderer@kit.edu	Leung, Carson/M-8682-2013	Leung, Carson/0000-0002-7541-9127; Reich, Andreas/0000-0002-2426-6490; Wolfel, Matthias/0000-0003-1601-5146	Stiftung Innovation in der Hochschullehre	Stiftung Innovation in der Hochschullehre	No Statement Available	Abbas N, 2022, INT J LIFELONG EDUC, V41, P308, DOI 10.1080/02601370.2022.2066213; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, Apache Apache Solr; [Anonymous], 2022, Chase LangChain; [Anonymous], 2023, Teaching with AI; Ashok M, 2021, 2021 SIXTH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P241, DOI [10.1109/WISPNET51692.2021.9419403, 10.1109/WiSPNET51692.2021.9419403]; Atapattu T, 2017, COMPUT EDUC, V115, P96, DOI 10.1016/j.compedu.2017.08.001; Bocklisch T, 2017, Arxiv, DOI arXiv:1712.05181; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bunk T, 2020, Arxiv, DOI [arXiv:2004.09936, DOI 10.48550/ARXIV.2004.09936]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chopra Sahil., 2016, ACM Transactions on Graphics, V1, P1; D'Mello S.K., 2012, ACM Transactions on Interactive Intelligent Systems, V2, P1, DOI [10.1145/2395123.2395128, DOI 10.1145/2395123.2395128]; Dai WL, 2023, Arxiv, DOI arXiv:2305.06500; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dibitonto M, 2018, LECT NOTES COMPUT SC, V10903, P103, DOI 10.1007/978-3-319-91250-9_9; Dijkstra R., 2022, Reading comprehension quiz generation using generative pre-trained transformers; Ekin S, 2023, TechRxiv, DOI [10.36227/techrxiv.22683919.v2, DOI 10.36227/TECHRXIV.22683919.V2]; Feldman P, 2023, Arxiv, DOI arXiv:2306.06085; Fugen C., 2006, P INTERSPEECH; Gabajiwala E., 2022, FUTURISTIC TRENDS NE, P523, DOI DOI 10.1007/978-981-19-5037; Gajra V., 2020, P 3 INT C ADV SCI TE; Galko L, 2018, 2018 16TH INTERNATIONAL CONFERENCE ON EMERGING ELEARNING TECHNOLOGIES AND APPLICATIONS (ICETA), P179, DOI 10.1109/ICETA.2018.8572054; Gao T., 2020, arXiv; Golbeck J., 2010, Proceedings of the American Society for Information Science and Technology, V47, P1, DOI [10.1002/meet.14504701048, DOI 10.1002/MEET.14504701048]; Graesser AC, 2016, INT J ARTIF INTELL E, V26, P124, DOI 10.1007/s40593-015-0086-4; Grice HP., 1975, SYNTAX SEMANTICS, P41, DOI [DOI 10.1163/9789004368811_003, 10.1163/9789004368811_003]; Gupta A., 2019, P EMNLP 2019 HONG KO; Gupta S., 2022, Journal of Information Systems Education, V33, P98; Harrington S.A, 2023, The Ultimate Study Partner: Using a Custom Chatbot to Optimize Student Studying During Law School; Hew KF, 2023, J COMPUT HIGH EDUC, V35, P40, DOI 10.1007/s12528-022-09338-x; Hien HT, 2018, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2018), P69, DOI 10.1145/3287921.3287937; Hoang T.N., 2022, 20. Fachtagung Bildungstechnologien (DELFI); Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu ZQ, 2023, Arxiv, DOI arXiv:2304.01933; Intelligent, 2023, New Survey Finds Students Are Replacing Human Tutors with ChatGPT; Kaplan M., 2020, J. Mach. Learn. Res, V64, P1; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khalil M, 2022, LECT NOTES COMPUT SC, V13329, P188, DOI 10.1007/978-3-031-05675-8_15; Kolss M., 2008, P INT WORKSH SPOK LA; Kooli C, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15075614; Liang ZW, 2023, Arxiv, DOI arXiv:2305.14386; Lucassen T, 2013, J AM SOC INF SCI TEC, V64, P254, DOI 10.1002/asi.22743; Macina J, 2023, Arxiv, DOI arXiv:2305.14536; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; Massaro D.W., 2005, P 38 ANN HAW INT C S, p296b; Ni JJ, 2023, ARTIF INTELL REV, V56, P3055, DOI 10.1007/s10462-022-10248-8; OpenAI, 2022, OpenA I; Perez Marin D., 2021, Digital, V1, P18, DOI DOI 10.3390/DIGITAL1010002; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh K, 2017, COMM COM INF SC, V750, P336, DOI 10.1007/978-981-10-6544-6_31; RASA, 2023, Open Source Conversational AI|Rasa; Samtani P., 2008, P AAAI FALL S AD AG, P53; Shen JT, 2021, Arxiv, DOI [arXiv:2106.07340, DOI 10.48550/ARXIV.2106.07340]; Sonkar S, 2023, Arxiv, DOI arXiv:2305.13272; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tom B., 2017, Rasa AI: Building Clever Chatbots; VMware RabbitMQ, 2023, Easy to Use, Flexible Messaging and Streaming-RabbitMQ; Wang L, 2024, Arxiv, DOI arXiv:2212.03533; Wang LZ, 2023, Arxiv, DOI arXiv:2302.13496; Winkler R., 2018, ANN AC MAN M; Wolfel Matthias, 2021, Multimedia Technology and Enhanced Learning: Third EAI International Conference, ICMTEL 2021, Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (388), P216, DOI 10.1007/978-3-030-82565-2_18; Wolfel M., 2009, Robust Automatic Transcription of Lectures; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Yadav G, 2023, Arxiv, DOI arXiv:2306.00190; Yager KG, 2023, DIGIT DISCOV, V2, P1850, DOI 10.1039/d3dd00112a; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou J, 2024, FRONT INFORM TECH EL, V25, P6, DOI 10.1631/FITEE.2300089; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592; Zylowski T., 2023, P 6 INT C NAT LANG S	75	1	1	23	23	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2504-2289		BIG DATA COGN COMPUT	Big Data Cogn. Comput.	JAN	2024	8	1							2	10.3390/bdcc8010002	http://dx.doi.org/10.3390/bdcc8010002			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	FY6Y0		gold			2024-07-03	WOS:001149465100001
J	Triguero, I; Molina, D; Poyatos, J; Del Ser, J; Herrera, F				Triguero, Isaac; Molina, Daniel; Poyatos, Javier; Del Ser, Javier; Herrera, Francisco			General Purpose Artificial Intelligence Systems (GPAIS): Properties, definition, taxonomy, societal implications and responsible governance	INFORMATION FUSION			English	Article						General-purpose AI; Meta -learning; Reinforcement learning; Neuroevolution; Few -shot learning; AutoML; Transfer learning; Generative AI; Large language models	NEURAL-NETWORKS	Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research. This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgement of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI (commonly referred to as AI-powered AI) or (single) foundation models. As a prime example, we delve into generative AI (GenAI), aligning them with the terms and concepts presented in the taxonomy. Similarly, we explore the challenges and prospects of multi-modality, which involves fusing various types of data sources to expand the capabilities of GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general purpose tasks, as they share many common aspects. Finally, with the goal of providing a holistic view of GPAIS, we discuss the current state of GPAIS, its prospects, implications for our society, and the need for regulation and governance of GPAIS to ensure their responsible and trustworthy development.	[Triguero, Isaac; Molina, Daniel; Poyatos, Javier; Herrera, Francisco] Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, Granada 18071, Spain; [Del Ser, Javier] TECNALIA, Basque Res & Technol Alliance BRTA, Derio 48160, Spain; [Del Ser, Javier] Univ Basque Country UPV EHU, Bilbao 48013, Spain; [Triguero, Isaac] Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England	University of Granada; University of Basque Country; University of Nottingham	Triguero, I (corresponding author), Univ Granada, Andalusian Res Inst Data Sci & Computat Intelligen, Dept Comp Sci & Artificial Intelligence, Granada 18071, Spain.	triguero@decsai.ugr.es; dmolina@decsai.ugr.es; jpoyatosamador@ugr.es; javier.delser@tecnalia.com; herrera@decsai.ugr.es	Triguero, Isaac/AAU-3586-2021; Cabrera, Daniel Molina/X-4025-2019	Triguero, Isaac/0000-0002-0150-0651; Cabrera, Daniel Molina/0000-0002-4175-2204	Maria Zambrano Senior Fellowship at the University of Granada; R&D and Innovation project [PID2020-119478GB-I00]; Spain's Ministry of Science and Innovation; European Regional Development Fund (ERDF); Basque Government, Spain [KK-2023/00012, IT1456-22]; Department of Education of this institution	Maria Zambrano Senior Fellowship at the University of Granada; R&D and Innovation project; Spain's Ministry of Science and Innovation(Spanish Government); European Regional Development Fund (ERDF)(European Union (EU)); Basque Government, Spain(Basque Government); Department of Education of this institution	I. Triguero is funded by a Maria Zambrano Senior Fellowship at the University of Granada. I. Triguero, F. Herrera, D. Molina, and J. Poyatos are supported by the R&D and Innovation project with reference PID2020-119478GB-I00 granted by Spain's Ministry of Science and Innovation and European Regional Development Fund (ERDF) . J. Del Ser would like to thank the Basque Government, Spain for the funding support received through the EMAITEK and ELKARTEK programs (ref. KK-2023/00012) , as well as the Consolidated Research Group MATHMODE (IT1456-22) granted by the Department of Education of this institution.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Almeida V, 2023, IEEE INTERNET COMPUT, V27, P70, DOI 10.1109/MIC.2022.3186030; Ashmore R, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453444; Balestriero R, 2023, Arxiv, DOI arXiv:2304.12210; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Barros RC, 2014, IEEE T EVOLUT COMPUT, V18, P873, DOI 10.1109/TEVC.2013.2291813; Bengio Y, 2023, Arxiv, DOI [arXiv:2310.17688, 10.48550/arXiv.2310.17688]; Bergstra James, 2015, Computational Science and Discovery, V8, DOI 10.1088/1749-4699/8/1/014008; Betker J., 2023, Improving image generation with better captions; Bissoto A, 2021, IEEE COMPUT SOC CONF, P1847, DOI 10.1109/CVPRW53098.2021.00204; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bommasani R., 2023, Do Foundation Model Providers Comply with the EU AI Act?; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Budd S, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102062; Burke EK, 2013, J OPER RES SOC, V64, P1695, DOI 10.1057/jors.2013.71; Burnell R, 2023, SCIENCE, V380, P136, DOI 10.1126/science.adf6369; Campos S., 2023, SSRN 4423706., P1, DOI [10.2139/ssrn.4423706, DOI 10.2139/SSRN.4423706]; Chatzilygeroudis K., 2021, Black Box Optimization, Machine Learning, and No-Free Lunch Theorems, P109, DOI 10.1007/978-3-030-66515-9_4; Chebotar Y, 2021, PR MACH LEARN RES, V139; Chen X, 2022, INFORM SCIENCES, V592, P156, DOI 10.1016/j.ins.2022.01.051; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Clune J, 2020, Arxiv, DOI arXiv:1905.10985; Conover M., 2023, Free Dolly: Introducing the world's first truly open instructiontuned LLM; Critch A., 2023, TASRA: A Taxonomy and Analysis of Societal-Scale Risks from AI; Cully A, 2018, IEEE T EVOLUT COMPUT, V22, P245, DOI 10.1109/TEVC.2017.2704781; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Díaz-Rodríguez N, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101896; Dorigo M, 2021, P IEEE, V109, P1152, DOI 10.1109/JPROC.2021.3072740; Elsken T, 2019, J MACH LEARN RES, V20; European Commission, 2021, COM/2021/564 final; Fang M, 2017, IEEE T CYBERNETICS, V47, P3906, DOI 10.1109/TCYB.2016.2590023; Felix S., 2018, presented at 2018 2nd International Conference on Trends in Electronics and Informatics, P1245, DOI [DOI 10.1109/ICOEI.2018.8553750, 10.1109/ICOEI.2018.8553750]; Feurer M., 2022, The Journal of Machine Learning Research, V23, P1; Fjelland R, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0494-4; Future of Life Institute, 2022, General Purpose AI and the AI Act; Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813; Gao J, 2020, NEURAL COMPUT, V32, P829, DOI 10.1162/neco_a_01273; Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293; Gong T, 2023, Arxiv, DOI [arXiv:2305.04790, 10.48550/arXiv.2305.04790]; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Grudin J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300439; Guan SY, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031411; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; Gutierrez C.I., 2023, Digital Society, V2, DOI [10.1007/s44206-023-00068-w, DOI 10.1007/S44206-023-00068-W]; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hall DL, 1997, P IEEE, V85, P6, DOI 10.1109/ISCAS.1998.705329; Hanxiao Chen, 2022, 2022 IEEE International Conference on Robotics and Biomimetics (ROBIO), P129, DOI 10.1109/ROBIO55434.2022.10011896; He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622; Hendrycks D, 2023, Arxiv, DOI [arXiv:2306.12001, 10.48550/arXiv.2306.12001, DOI 10.48550/ARXIV.2306.12001]; Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036; Hollmann N, 2023, Arxiv, DOI arXiv:2207.01848; Hong S, 2023, Arxiv, DOI arXiv:2308.00352; Hupont I, 2023, COMPUTER, V56, P18, DOI 10.1109/MC.2023.3235712; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Javed K., 2019, P ADV NEUR INF PROC, P1820; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004; Kazuhiro K, 2018, TOMOGRAPHY, V4, P159, DOI 10.18383/j.tom.2018.00042; Khan A, 2023, Arxiv, DOI arXiv:2305.14485; Koch G., 2015, ICML Deep Learning Workshop, VVolume 2, DOI DOI 10.1007/S11263-015-0816-Y; König A, 2022, LECT NOTES COMPUT SC, P207, DOI 10.1007/978-3-031-08648-9_24; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Kwa HL, 2023, FRONT ROBOT AI, V10, DOI 10.3389/frobt.2023.1163185; Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y; Li K., 2017, 5 INT C LEARN REPR I, P1; Martinez AD, 2022, IEEE T EVOLUT COMPUT, V26, P233, DOI 10.1109/TEVC.2021.3083362; Martinez AD, 2021, INFORM FUSION, V67, P161, DOI 10.1016/j.inffus.2020.10.014; McAlpine Ewen, 2022, J Am Soc Cytopathol, V11, P123, DOI 10.1016/j.jasc.2022.02.001; Meng T, 2020, INFORM FUSION, V57, P115, DOI 10.1016/j.inffus.2019.12.001; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Nguyen C. V., 2018, INT C LEARNING REPRE; Nichol A., 2022, Dall-e 2 pre-training mitigations; Oussidi A, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018); Palladino N, 2023, TELECOMMUN POLICY, V47, DOI 10.1016/j.telpol.2022.102479; Panait L, 2005, AUTON AGENT MULTI-AG, V11, P387, DOI 10.1007/s10458-005-2631-2; James AP, 2015, Arxiv, DOI arXiv:1506.00097; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Parker-Holder J, 2022, J ARTIF INTELL RES, V74, P517, DOI 10.1613/jair.1.13596; Parmar J, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3561381; Patrizio A., 2023, Google Bard; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Podell D, 2023, Arxiv, DOI arXiv:2307.01952; Real E., 2020, AutoML-Zero: Evolving Machine Learning Algorithms From Scratch, P8007; Reed S., 2022, Trans. Mach. Learn. Res., P1; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Schaeffer R, 2023, Arxiv, DOI [arXiv:2304.15004, DOI 10.48550/ARXIV.2304.15004, 10.48550/arXiv.2304.15004]; Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4; Schrodi S, 2023, Arxiv, DOI [arXiv:2211.01842, DOI 10.48550/ARXIV.2211.01842]; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Settles, 2012, ACTIVE LEARNING, V6, P1, DOI DOI 10.2200/S00429ED1V01Y201207AIM018; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Shen ZQ, 2024, Arxiv, DOI [arXiv:1810.13306, DOI 10.48550/ARXIV.1810.13306]; Shevlin H, 2019, EMBO REP, V20, DOI 10.15252/embr.201949177; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Silva PR, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1486; Silver D, 2021, ARTIF INTELL, V299, DOI 10.1016/j.artint.2021.103535; Snoek J., 2012, ADV NEURAL INFORM PR, P2951, DOI [10.5555/2999325.2999464, DOI 10.48550/ARXIV.1206.2944]; Song HD, 2019, PROG ARTIF INTELL, V8, P143, DOI 10.1007/s13748-019-00185-z; Sosnina EA, 2023, J COMPUT AID MOL DES, V37, P183, DOI 10.1007/s10822-023-00500-w; Stanley KO, 2019, NAT MACH INTELL, V1, P24, DOI 10.1038/s42256-018-0006-z; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Thambawita V, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01295-2; Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629; Toutouh J, 2023, APPL SOFT COMPUT, V148, DOI 10.1016/j.asoc.2023.110890; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Vaswani A, 2017, ADV NEUR IN, V30; Verdecchia R, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1507; Vinyals O, 2016, 30 C NEURAL INFORM P, V29; Wang R., 2019, arXiv; Wang Y.-X., 2017, Advances in Neural Information Processing Systems, P7032; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wei J, 2022, Trans. Mach. Learn. Res.; Wei J., 2023, Advances in Neural Information Processing Systems, P1; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xu J, 2018, ADV NEUR IN, V31; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Yi WJ, 2023, IEEE T EVOLUT COMPUT, V27, P1072, DOI 10.1109/TEVC.2022.3197298; Yu J, 2021, IEEE T CYBERNETICS, V51, P4350, DOI 10.1109/TCYB.2020.2972944; Zhan ZH, 2022, NEUROCOMPUTING, V483, P42, DOI 10.1016/j.neucom.2022.01.099; Zhang Y., 2023, ARXIV; Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203; Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105; Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333; Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001; Zhu WW, 2020, IEEE T CIRC SYST VID, V30, P3740, DOI 10.1109/TCSVT.2019.2940647; Zweig A, 2017, MACH LEARN, V106, P1747, DOI 10.1007/s10994-017-5661-5	138	1	1	36	47	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	MAR	2024	103								102135	10.1016/j.inffus.2023.102135	http://dx.doi.org/10.1016/j.inffus.2023.102135		NOV 2023	16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z5GF8		Green Submitted			2024-07-03	WOS:001112351800001
J	Luke, WANV; Chong, LS; Ban, KH; Wong, AH; Xiong, CZ; Shing, LS; Taneja, R; Samarasekera, DD; Yap, CT				Luke, W. A. Nathasha V.; Chong, Lee Seow; Ban, Kenneth H.; Wong, Amanda H.; Xiong, Chen Zhi; Shing, Lee Shuh; Taneja, Reshma; Samarasekera, Dujeepa D.; Yap, Celestial T.			Is ChatGPT 'ready' to be a learning tool for medical undergraduates and will it perform equally in different subjects? Comparative study of ChatGPT performance in tutorial and case-based learning questions in physiology and biochemistry	MEDICAL TEACHER			English	Article; Early Access						ChatGPT; GPT-3.5; GPT-4 generative AI (artificial intelligence); LLM (large language model); physiology biochemistry		PurposeGenerative AI will become an integral part of education in future. The potential of this technology in different disciplines should be identified to promote effective adoption. This study evaluated the performance of ChatGPT in tutorial and case-based learning questions in physiology and biochemistry for medical undergraduates. Our study mainly focused on the performance of GPT-3.5 version while a subgroup was comparatively assessed on GPT-3.5 and GPT-4 performances.Materials and methodsAnswers were generated in GPT-3.5 for 44 modified essay questions (MEQs) in physiology and 43 MEQs in biochemistry. Each answer was graded by two independent examiners. Subsequently, a subset of 15 questions from each subject were selected to represent different score categories of the GPT-3.5 answers; responses were generated in GPT-4, and graded.ResultsThe mean score for physiology answers was 74.7 (SD 25.96). GPT-3.5 demonstrated a statistically significant (p = .009) superior performance in lower-order questions of Bloom's taxonomy in comparison to higher-order questions. Deficiencies in the application of physiological principles in clinical context were noted as a drawback. Scores in biochemistry were relatively lower with a mean score of 59.3 (SD 26.9) for GPT-3.5. There was no statistically significant difference in the scores for higher and lower-order questions of Bloom's taxonomy. The deficiencies highlighted were lack of in-depth explanations and precision. The subset of questions where the GPT-4 and GPT-3.5 were compared demonstrated a better overall performance in GPT-4 responses in both subjects. This difference between the GPT-3.5 and GPT-4 performance was statistically significant in biochemistry but not in physiology.ConclusionsThe differences in performance across the two versions, GPT-3.5 and GPT-4 across the disciplines are noteworthy. Educators and students should understand the strengths and limitations of this technology in different fields to effectively integrate this technology into teaching and learning.	[Luke, W. A. Nathasha V.; Wong, Amanda H.; Xiong, Chen Zhi; Taneja, Reshma; Yap, Celestial T.] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Physiol, Singapore, Singapore; [Chong, Lee Seow; Ban, Kenneth H.] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Biochem, Singapore, Singapore; [Xiong, Chen Zhi; Shing, Lee Shuh; Samarasekera, Dujeepa D.] Natl Univ Singapore, Ctr Med Educ, Yong Loo Lin Sch Med, Singapore, Singapore; [Luke, W. A. Nathasha V.; Yap, Celestial T.] Natl Univ Singapore, 2 Med Dr, MD 9, Singapore 117593, Singapore	National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore	Luke, WANV; Yap, CT (corresponding author), Natl Univ Singapore, 2 Med Dr, MD 9, Singapore 117593, Singapore.	nathasha@nus.edu.sg; phsyapc@nus.edu.sg			Teaching Enhancement Grant	Teaching Enhancement Grant	We thank the academic staff of the Departments of Physiology and Biochemistry, Yong Loo Lin School of Medicine for grading the ChatGPT answers.	Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Choi JH, 2022, J LEGAL EDUC, V71, P387; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Mahat RK, 2023, ADV PHYSIOL EDUC, V47, P528, DOI 10.1152/advan.00076.2023; Mishra V., 2023, J Qual Health Care Econ, V6, P1, DOI [10.23880/jqhe-16000319, DOI 10.23880/JQHE-16000319]; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946	20	1	1	42	42	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0142-159X	1466-187X		MED TEACH	Med. Teach.	2024 JAN 30	2024										10.1080/0142159X.2024.2308779	http://dx.doi.org/10.1080/0142159X.2024.2308779		JAN 2024	7	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	GQ3O1	38295769				2024-07-03	WOS:001154097600001
J	Suhaeni, C; Yong, HS				Suhaeni, Cici; Yong, Hwan-Seung			Enhancing Imbalanced Sentiment Analysis: A GPT-3-Based Sentence-by-Sentence Generation Approach	APPLIED SCIENCES-BASEL			English	Article						GPT-3; imbalanced sentiment analysis; sentiment analysis; synthetic data generation; text classification; text generation; large language model (LLM)		This study addresses the challenge of class imbalance in sentiment analysis by utilizing synthetic data to balance training datasets. We introduce an innovative approach using the GPT-3 model's sentence-by-sentence generation technique to generate synthetic data, specifically targeting underrepresented negative and neutral sentiments. Our method aims to align these minority classes with the predominantly positive sentiment class in a Coursera course review dataset, with the goal of enhancing the performance of sentiment classification. This research demonstrates that our proposed method successfully enhances sentiment classification performance, as evidenced by improved accuracy and F1-score metrics across five deep-learning models. However, when compared to our previous research utilizing fine-tuning techniques, the current method shows a relative shortfall. The fine-tuning approach yields better results in all models tested, indicating the importance of data novelty and diversity in synthetic data generation. In terms of the deep-learning model used for classification, the notable finding is the significant performance improvement of the Recurrent Neural Network (RNN) model compared to other models like CNN, LSTM, BiLSTM, and GRU, highlighting the impact of the model choice and architecture depth. This study emphasizes the critical role of synthetic data quality and strategic deep-learning model implementation in sentiment analysis. The results suggest that the careful consideration of training data and model attributes is vital for optimal sentiment classification.	[Suhaeni, Cici; Yong, Hwan-Seung] Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 03760, South Korea	Ewha Womans University	Suhaeni, C (corresponding author), Ewha Womans Univ, Dept Comp Sci & Engn, Seoul 03760, South Korea.	cici.suhaeny@gmail.com; hsyong@ewha.ac.kr			Korea Agency for Infrastructure Technology Advancement (KAIA)	Korea Agency for Infrastructure Technology Advancement (KAIA)(Korea Agency for Infrastructure Technology Advancement (KAIA))	No Statement Available	Abramski K, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7030124; Akkaradamrongrat S, 2019, INT JOINT CONF COMP, P181, DOI [10.1109/jcsse.2019.8864181, 10.1109/JCSSE.2019.8864181]; Bordoloi M, 2023, ARTIF INTELL REV, V56, P12505, DOI 10.1007/s10462-023-10442-2; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai TT, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042257; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; George S., 2022, INDIAN J SCI TECHNOL, V15, P790, DOI [10.17485/IJST/v15i17.2339, DOI 10.17485/IJST/v15i17.2339]; Grandini M, 2020, Arxiv, DOI [arXiv:2008.05756, DOI 10.48550/ARXIV.2008.05756]; Habbat Nassera, 2023, ITM Web of Conferences, DOI 10.1051/itmconf/20235202008; Habbat N, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106999; Imran AS, 2022, EGYPT INFORM J, V23, P547, DOI 10.1016/j.eij.2022.05.006; Kandpal N, 2022, Arxiv, DOI arXiv:2202.06539; Kastrati Zenun, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P510, DOI 10.1145/3404555.3404633; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Liu ZY, 2019, Arxiv, DOI [arXiv:1911.06641, 10.48550/ARXIV.1911.06641, DOI 10.48550/ARXIV.1911.06641]; Obiedat R, 2022, IEEE ACCESS, V10, P22260, DOI 10.1109/ACCESS.2022.3149482; Padurariu C, 2019, PROCEDIA COMPUT SCI, V159, P736, DOI 10.1016/j.procs.2019.09.229; Qurashi A.W., 2020, P IEEE 2020 INT C IN, P1; Sangeetha J., 2023, Meas. Sens, V27, P100790, DOI [10.1016/j.measen.2023.100790, DOI 10.1016/J.MEASEN.2023.100790]; Schofield A., 2017, P 2017 C EMP METH NA, P2737, DOI DOI 10.18653/V1/D17-1290; Shaikh S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020869; Skondras P, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15110363; Suhaeni C, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13179766; Tan KL, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063915; Wen Han, 2023, 2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD), P312, DOI 10.1109/ICAIBD57115.2023.10206154; Wu HL, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110964; Yanling Li, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P301, DOI 10.1109/ISIP.2010.47; Zhao HL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102656	29	0	0	18	18	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	JAN	2024	14	2							622	10.3390/app14020622	http://dx.doi.org/10.3390/app14020622			24	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	FX0C5		gold			2024-07-03	WOS:001149023700001
J	Crothers, EN; Japkowicz, N; Viktor, HL				Crothers, Evan N.; Japkowicz, Nathalie; Viktor, Herna L.			Machine-Generated Text: A Comprehensive Survey of Threat Models and Detection Methods	IEEE ACCESS			English	Article						Artificial intelligence; cybersecurity; disinformation; generative AI; large language models; machine learning; text generation; threat modeling; transformer; trustworthy AI		Machine-generated text is increasingly difficult to distinguish from text authored by humans. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first edition of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine-generated text is a key countermeasure for reducing the abuse of NLG models, and presents significant technical challenges and numerous open problems. We provide a survey that includes 1) an extensive analysis of threat models posed by contemporary NLG systems and 2) the most complete review of machine-generated text detection methods to date. This survey places machine-generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models. While doing so, we highlight the importance that detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability.	[Crothers, Evan N.; Viktor, Herna L.] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada; [Japkowicz, Nathalie] Amer Univ, Dept Comp Sci, Washington, DC 20016 USA	University of Ottawa; American University	Crothers, EN (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.	ecrot027@uottawa.ca		Viktor, Herna L/0000-0003-1914-5077; Crothers, Evan/0000-0001-6177-0525; Japkowicz, Nathalie/0000-0003-1176-1617	Natural Sciences and Engineering Research Council of Canada (NSERC) [RGPIN-2018-04047]	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) under Reference RGPIN-2018-04047.	Adelani David Ifeoluwa, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P1341, DOI 10.1007/978-3-030-44041-1_114; Aghajanyan A., 2021, P ICLR, P1; Alkhalil Z, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.563060; Andrews P. C., 2021, WHAT IS BRIGADING; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2018, Guidelines on Automated Individual Decision -Making and Profiling for the Purposes of Regulation 2016/679, at art. 9,17/ENWP251rev.01; [Anonymous], 2018, P IJCAI; [Anonymous], 2014, AM GET THEIR NEWS; [Anonymous], 2022, BEST AI WRIT ASS; [Anonymous], 2007, P ANT WORK GROUP 2 A, DOI DOI 10.1145/1299015.1299021; [Anonymous], 2022, OP COV LETT GEN COV; [Anonymous], 2022, THREAT MOD; [Anonymous], 2018, Facebook Launches New Initiative to Help Scholars Assess Social Media's Impact on Elections; [Anonymous], 2021, DIR AUT DEC MAK; [Anonymous], 2010, P 6 INLG ACL JUL; Antoun W, 2021, Arxiv, DOI arXiv:2003.00104; Auxier B., 2021, SOCIAL MEDIA USE 202, DOI DOI 10.4135/9781412963947.N376; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baevski A., 2021, Advances in Neural Information Processing Systems, V34, P27826, DOI 10.48550/arXiv.2105.11084; Bakhtin A, 2021, J MACH LEARN RES, V22; Bakhtin A, 2019, Arxiv, DOI arXiv:1906.03351; Baki S, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P469, DOI 10.1145/3052973.3053037; Baracaldo N., 2017, P 10 ACM WORKSHOP AR, P103, DOI [DOI 10.1145/3128572.3140450, 10.1145/3128572.3140450]; BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Baumgartner J, 2020, Arxiv, DOI arXiv:2001.08435; Bellinger C, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P102, DOI 10.1109/ICMLA.2012.212; Beresneva D, 2016, LECT NOTES COMPUT SC, V9612, P421, DOI 10.1007/978-3-319-41754-7_43; Berger J, 2012, J MARKETING RES, V49, P192, DOI 10.1509/jmr.10.0353; Bhat M. M., 2020, P 1 WORKSHOP INSIGHT, P48; Bhatt P., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.01170; Biderman S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2933, DOI 10.1145/3511808.3557079; Bitton R., 2021, arXiv; Black S., 2022, PREPRINT; Boyd-Graber J., 2023, Acl 2023 policy on ai writing assistance; Braiterman Zoe, 2020, Threat Modeling Manifesto; Brief C. P., 2021, AI FUTURE DISINFORMA; Bromander S., 2016, STIDS, P74; Burns AJ, 2019, J ORG COMP ELECT COM, V29, P24, DOI 10.1080/10919392.2019.1552745; Cabanac G, 2021, J ASSOC INF SCI TECH, V72, P1461, DOI 10.1002/asi.24495; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Chakraborty A, 2018, Arxiv, DOI arXiv:1810.00069; ChatGPT, 2022, ChatGPT: Optimizing Language Models for Dialogue; Chen M., 2021, arXiv; Chen Xingyuan, 2022, 2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), P2257, DOI 10.1109/ITAIC54216.2022.9836571; Chiew KL, 2018, EXPERT SYST APPL, V106, P1, DOI 10.1016/j.eswa.2018.03.050; Chorowski J, 2015, ADV NEUR IN, V28; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Clive J, 2022, Arxiv, DOI arXiv:2110.08329; Commission E, 2019, Ethics Guidelines for Trustworthy Al, DOI DOI 10.2759/346720; Crothers E, 2019, IEEE INT WORKS MACH, DOI 10.1109/mlsp.2019.8918842; Crothers E, 2021, TH CO SC GE ISS, V13116, P305, DOI 10.1007/978-3-030-91434-9_27; Crothers E, 2022, Arxiv, DOI arXiv:2203.07983; Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365; Cutler J., 2022, Automatic Detection of Hybrid Human-Machine Text Boundaries; Dadas Slawomir, 2020, Artificial Intelligence and Soft Computing. 19th International Conference, ICAISC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12416), P301, DOI 10.1007/978-3-030-61534-5_27; Dathathri S., 2020, ICLR, P1; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong C., 2022, ACM COMPUT SURV; Dou Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7250; Duboue PA, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P121; Dugan L, 2020, Arxiv, DOI arXiv:2010.03070; Edwards B., 2022, Flooded with AI-generated images, some art communities ban them completely; Fagni T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251415; Feng XC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4078; Ferrandis C. M., 2022, BigScience RAIL License v1.0; Fröhling L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.443; Gabielkov M, 2016, SIGMETRICS/PERFORMANCE 2016: PROCEEDINGS OF THE SIGMETRICS/PERFORMANCE JOINT INTERNATIONAL CONFERENCE ON MEASUREMENT AND MODELING OF COMPUTER SCIENCE, P179, DOI [10.1145/2896377.2901462, 10.1145/2964791.2901462]; GAGIANO R., 2021, P THE 19 ANN WORKSHO, P119; Galle M, 2021, Arxiv, DOI arXiv:2111.02878; Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P50, DOI 10.1109/SPW.2018.00016; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P111; Giaretta Alberto, 2020, Proceedings of 6th International Conference in Software Engineering for Defence Applications (SEDA 2018). Advances in Intelligent Systems and Computing (AISC 925), P86, DOI 10.1007/978-3-030-14687-0_8; Gooden D., 2022, USING AI WRITE YOUTU; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Goodside R., 2022, Exploiting gpt-3 prompts with malicious inputs that order the model to ignore its previous directions; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; Guerar M., 2021, ACM Computing Surveys (CSUR), V54, P1; Hargrave J., 2005, SCIGEN AN AUTOMATIC; Harkous H., 2020, P 28 INT C COMP LING, P2410; He S, 2022, MARKET SCI, V41, P896, DOI 10.1287/mksc.2022.1353; Nguyen-Son HQ, 2017, ASIAPAC SIGN INFO PR, P1504; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Huq A, 2020, Arxiv, DOI arXiv:2005.14108; Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1808; Janarthanam Srinivasan, 2009, PROC 12 ENLG, P74; Japkowicz N., 2000, Learning from Imbalanced Data Sets. Papers from the AAAI Workshop (Technical Report WS-00-05), P10; Jawahar G., 2020, P 28 INT C COMPUTATI, P2296, DOI [10.18653/v1/2020.coling-main.208, DOI 10.18653/V1/2020.COLING-MAIN.208]; Jin D, 2022, COMPUT LINGUIST, V48, P155, DOI 10.1162/coli_a_00426; Jin D, 2020, Arxiv, DOI arXiv:1907.11932; Kalchbrenner N., 2013, EMNLP 2013 2013 C EM, P1700; Kanapala A, 2019, ARTIF INTELL REV, V51, P371, DOI 10.1007/s10462-017-9566-2; Kaur D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491209; Kemp S., 2022, CONTENT CULTURES DAT; KEMP Simon, 2022, DATAREPORTAL; Khrushchev M., 2022, Yalm 100b; Kilcher Y., 2022, THIS IS WORST AI EVE; Kim S., 2019, P CHI C HUM FACT COM, P1; Kohnfelder L., 1999, THREATS OUR PRODUCTS, V33; Kondadadi Ravi, 2013, Proc. ACL, V1, P1406; Kowalczyk P., 2022, P 55 HAW INT C SYST, P10; Krause B, 2020, Arxiv, DOI arXiv:2009.06367; Kurenkov A., 2022, GRADIENT JUN; Kushnareva L, 2022, Arxiv, DOI arXiv:2109.04825; Labbé C, 2013, SCIENTOMETRICS, V94, P379, DOI 10.1007/s11192-012-0781-y; Langkilde I., 1998, P 17 INT C COMP LING, V1, P1; Latah M, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113383; Lavoie A, 2010, Arxiv, DOI arXiv:1008.0706; LeCun Y, 2006, PREDICTING STRUCTURE, V1; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902; Li Haoran, 2017, P 2017 C EMP METH NA, P1092; Li J., 2021, P 30 INT JOINT C ART, P4492, DOI DOI 10.24963/IJCAI.2021/612SURVEYTRACK; Li J., 2016, EMPIRICAL METHODS NA, DOI DOI 10.18653/V1/D16-1127.URL; Li ZM, 2018, Arxiv, DOI arXiv:1812.03509; Liang P., 2022, The time is now to develop community norms for the release of foundation models; Liang WX, 2023, Arxiv, DOI [arXiv:2304.02819, DOI 10.48550/ARXIV.2304.02819]; Lin K., 2017, P NIPS, P1; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lufkin B., 2021, WHY DO COVER LETT ST; LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159; Lundberg SM, 2017, ADV NEUR IN, V30; Lyons J., 1991, Natural Language and Universal Grammar: Essays in Linguistic Theory, V1; Manjaramkar A., 2021, CodeGenX; Martin L, 2020, Arxiv, DOI arXiv:1911.03894; McGufe K, 2020, arXiv; Meister C, 2023, T ASSOC COMPUT LING, V11, P102, DOI 10.1162/tacl_a_00536; Meleshevich K., 2018, Online information laundering: The role of social media; Merity S, 2017, Arxiv, DOI arXiv:1708.02182; Merono-Penuela A., SEMANTIC WEB ESWC 20; Mikolov T., 2012, Google, Mountain View, 2nd April, 80; Mink J, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P1669; Munir S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1811; Nassim D., 2021, ETHICS SCI ENV POLIT, V21, P17; Natural Language Processing Benchmarks, 2022, NAT LANG PROC BENCHM; OpenAI, 2020, GPT 3 GITH REP; Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48; Pawade Dipti, 2018, International Journal of Information Technology and Computer Science, V10, P44, DOI 10.5815/ijitcs.2018.06.05; Perera R, 2017, COMPUT INFORM, V36, P1, DOI 10.4149/cai_2017_1_1; Phillips P. J., 2020, 8312 NAT I STAND TEC; Phillips P. J., P NAT ACAD SCI; Radford A., 2019, GPT-2 Output Dataset; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Raiko T., 2015, P NIPS, P1; Ramesh A, 2021, PR MACH LEARN RES, V139; Ranade P., 2021, 2021 International Joint Conference on Neural Networks (IJCNN), P1; Reddit, 2018, REDD TRANSP REP SUSP; Reed Scott E., 2022, arXiv; Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502; Rodriguez JD, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1213; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rosati D., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2209.03742, 10.48550/ARXIV.2209.03742]; Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771; Santhanam S, 2019, Arxiv, DOI arXiv:1906.00500; Schuster R, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1559; See A., 2019, P 23 C COMPUTATIONAL, P843, DOI DOI 10.18653/V1/K19-1079; Selbst AD, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P59, DOI 10.1145/3287560.3287598; Shamardina T, 2022, Arxiv, DOI arXiv:2206.01583; Sheikha F. A., 2011, PROC 13 EUROPEAN WOR, P187; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Shostack A., 2021, Shostack's 4 Question Frame for Threat Modeling; Shostack A., 2014, Threat modeling: Designing for security; Shu K., 2020, Disinformation, Misinformation, and Fake News in Social Media: Emerging Research Challenges and Opportunities, P1; Shuster K., 2022, arXiv; Skrylnikov S., 2022, P INT C DIAL JUN, P1; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Song KT, 2019, PR MACH LEARN RES, V97; Stieglitz S, 2017, LECT NOTES COMPUT SC, V10282, P379, DOI 10.1007/978-3-319-58559-8_30; Stiff H, 2022, INT J DATA SCI ANAL, V13, P363, DOI 10.1007/s41060-021-00299-5; Sudhakar A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3269; Tay Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P275; Tesfagergish SG, 2021, LECT NOTES COMPUT SC, V12954, P523, DOI 10.1007/978-3-030-86979-3_37; Topal MO, 2021, Arxiv, DOI arXiv:2102.08036; Tourille J, 2022, 1ST ACM INTERNATIONAL WORKSHOP ON MULTIMEDIA AI AGAINST DISINFORMATION, MAD 2022, P44, DOI 10.1145/3512732.3533584; Twitter, 2019, Twitter Elections Integrity Datasets; Ucedavelez T, 2015, RISK CENTRIC THREAT MODELING: PROCESS FOR ATTACK SIMULATION AND THREAT ANALYSIS, P1, DOI 10.1002/9781118988374; Uchendu A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2001; Uchendu A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8384; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang JF, 2022, Arxiv, DOI arXiv:2205.14100; Wang J, 2022, Arxiv, DOI arXiv:2208.01813; Wang MQ, 2021, J AM MED INFORM ASSN, V28, P2287, DOI 10.1093/jamia/ocab143; Wang W., 2019, arXiv; Weiss M., 2019, TECHNOL SCI DEC; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Willison S., 2022, S WILLISONS WEBL SEP; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Zapata J. P. O., 2022, GPT 3 PROMPT INJECTI; Zellers R., 2019, GRADIENT JUL; Zellers R., 2019, Adv. Neural Inf.Process. Syst., V32, P1; Zeng W., 2021, PREPRINT; Zhang L., 2009, Text Generation, P3048, DOI [DOI 10.1007/978-0-387-39940-9_416, 10.1007/978-0-387-39940-9_416]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041; Zhuang ZM, 2007, ACM-IEEE J CONF DIG, P225, DOI 10.1145/1255175.1255220; Zipf GK, 1950, J CLIN PSYCHOL, V6, P306	203	9	10	18	48	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						70977	71002		10.1109/ACCESS.2023.3294090	http://dx.doi.org/10.1109/ACCESS.2023.3294090			26	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	M9QS6		Green Submitted, gold			2024-07-03	WOS:001033493400001
J	Moya, BA; Eaton, SE				Moya, Beatriz Antonieta; Eaton, Sarah Elaine			Examining Recommendations for Generative Artificial Intelligence Use with Integrity from a Scholarship of Teaching and Learning Lens	RELIEVE-REVISTA ELECTRONICA DE INVESTIGACION Y EVALUACION EDUCATIVA			English	Article						Artificial Intelligence; Generative Artificial Intelligence (GenAI); Large Language Models; Academic Integrity; Scholarship of Teaching and Learning; Systems Approach	SOTL	New developments in the Artificial Intelligence (AI) field allowed the development of Generative Artificial Intelligence (GenAI), capable of creating text resembling what humans can produce. As a result, educators' concerns in the higher education sector quickly emerged. Many organizations and experts have addressed these concerns through recommendations. In this conceptual paper, we draw from the Integrated Model for Academic Integrity through a Scholarship of Teaching and Learning Lens to examine and stimulate discussion from twelve documents that focus on using GenAI with integrity. We identified recommendations suitable for the individual (micro), the departmental/program (meso), the institutional (macro), and the interinstitutional/ national/ international (mega) levels concerning two core elements of the model: "high-impact professional learning for individuals and groups" and "local-level leadership and microcultures." Suggestions around the core element "scholarship, research and inquiry" were lacking at the micro and meso levels; likewise, recommendations for the core element "learning spaces, pedagogies, and technologies" were also absent at the meso, macro, and mega levels. We acknowledge that these recommendations focus on learning, involve various stakeholders, and go beyond student conduct, which aligns with current approaches to academic integrity. However, some gaps need further exploration. We highlight the need to develop more specific and practical guidance and resources for educational stakeholders around GenAI issues related to academic integrity, explore how to better support networks and leaders in higher education in creating the conditions for ethical GenAI use, and emphasizing the need for an Equity, Diversity, and Inclusion lens on GenAI.	[Moya, Beatriz Antonieta] Univ Calgary, Werklund Sch Educ, Educ Res Program, Calgary, AB, Canada; [Eaton, Sarah Elaine] Univ Calgary, Educ, Calgary, AB, Canada	University of Calgary; University of Calgary	Moya, BA (corresponding author), Univ Calgary, Calgary, AB, Canada.	beatriz.moya@ucalgary.ca; seaton@ucalgary.ca			University of Calgary Teaching and Learning Grant; Social Sciences and Humanities Research Council of Canada (SSHRC) [611-2022-0398]	University of Calgary Teaching and Learning Grant; Social Sciences and Humanities Research Council of Canada (SSHRC)(Social Sciences and Humanities Research Council of Canada (SSHRC)CGIAR)	We are grateful to the University of Calgary Teaching and Learning Grant and to the Social Sciences and Humanities Research Council of Canada (SSHRC) (Grant #611-2022-0398) for supporting this research.	Anson C. M., 2022, Composition Studies, V50, P37; Australian Academic Integrity Network (AAIN), 2023, AAIN generative artificial intelligence guidelines; Bearman M., 2020, Re-imagining university assessment in a digital world, P49, DOI [https://doi.org/10.1007/978-3-030-41956-15, DOI 10.1007/978-3-030-41956-15]; Bertram Gallant T., 2008, Academic integrity in the twentyfirst century: A teaching and learning imperative; Boyer EL., 1990, Scholarship reconsidered: Priorities of the professoriate; Brake J., 2022, The Absent-Minded Professor; Bretag T., 2013, Global corruption report: Education, P171, DOI [10.4324/9780203109816, DOI 10.4324/9780203109816]; Bretag T, 2016, HANDBOOK OF ACADEMIC INTEGRITY, P3, DOI 10.1007/978-981-287-098-8_76; Bronfenbrenner U., 1976, Educational Researcher, V5, P5, DOI [10.2307/1174755, DOI 10.2307/1174755]; Canadian Center for Cybersecurity, 2023, Generative artificial intelligence (AI)-ITSAP.00.041; Delisio L A., 2019, What really works with universal design for learning, P157; Dignum V, 2021, LOND REV EDUC, V19, DOI 10.14324/LRE.19.1.01; Eaton S.E, 2023, A comprehensive academic integrity (CAI) framework: An overview; Eaton S. E., 2023, Learning, Teaching and Leadership; Eaton S. E., 2023, 10 PRIMER CONGRESO I; Eaton S. E., 2020, INTEGRIDAD ACAD ENFO; Eaton SE., 2020, Understanding academic integrity from a teaching and learning perspective: Engaging with the 4M framework; Eaton SE., 2021, Plagiarism in higher education: Tackling tough topics in academic integrity, DOI [10.5040/9798400697142, DOI 10.5040/9798400697142]; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Emenike ME, 2023, J CHEM EDUC, V100, P1413, DOI 10.1021/acs.jchemed.3c00063; European Commission, 2022, Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for educators; Felten P, 2013, TEACH LEARN INQ, V1, P121, DOI 10.2979/teachlearninqu.1.1.121; Foltynek T, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00133-4; Fyfe P, 2023, AI SOC, V38, P1395, DOI 10.1007/s00146-022-01397-z; Gallant TB, 2016, HANDBOOK OF ACADEMIC INTEGRITY, P975, DOI 10.1007/978-981-287-098-8_81; Hannah ST, 2009, LEADERSHIP QUART, V20, P34, DOI 10.1016/j.leaqua.2008.11.003; Hemsley B., 2023, The Conversation January 18; Hubball H, 2013, TEACH LEARN INQ, V1, P41, DOI 10.2979/teachlearninqu.1.1.41; Hubball H, 2010, CAN J SCHOLARSH TEA, V1, DOI 10.5206/cjsotl-rcacea.2010.1.2; Hutchings P., 2011, The scholarship of teaching and learning reconsidered: Institutional integration and impact, P1; ICAI, 2021, FUNDAMENTAL VALUES A; Illia L, 2023, BUS ETHICS ENV RESP, V32, P201, DOI 10.1111/beer.12479; Kenny N., 2016, New Directions for Teaching and Learning, V146, P87, DOI [10.1002/tl.20191, DOI 10.1002/TL.20191]; Kenny N., 2022, Academic integrity in Canada: An enduring and essential challenge, DOI [10.1007/978-3-030-83255-1, DOI 10.1007/978-3-030-83255-1]; Kenny N, 2017, CAN J SCHOLARSH TEA, V8, DOI 10.5206/cjsotl-rcacea.2017.2.10; Khan Z. R., 2023, Artificial intelligence content generators in education for schools and universities: A good practice guide; Kreber C, 2002, STUD HIGH EDUC, V27, P151, DOI 10.1080/03075070220119995; Kreber C, 2013, TEACH LEARN INQ, V1, P5, DOI 10.2979/teachlearninqu.1.1.5; Kumar R., 2023, Handbook of academic integrity, DOI [10.1007/978-981-287-079-7_153-1, DOI 10.1007/978-981-287-079-7_153-1]; Kumar R., 2022, CANADIAN SOC STUDY H; Lancaster T, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00131-6; Lesage J, 2024, INT J MECH ENG EDUC, V52, P88, DOI 10.1177/03064190231166665; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Mårtensson K, 2016, EDUC MANAG ADM LEAD, V44, P247, DOI 10.1177/1741143214549977; Miller--Young J, 2015, TEACH LEARN INQ, V3, P37, DOI 10.2979/teachlearninqu.3.2.37; Miller-Young JE, 2017, CAN J SCHOLARSH TEA, V8, DOI 10.5206/cjsotl-rcacea.2017.2.4; Mills A., 2023, What to do about AI text generators; Mindzak M., 2020, University Affairs February 17; Munoko I, 2020, J BUS ETHICS, V167, P209, DOI 10.1007/s10551-019-04407-1; National Academic Integrity Network (NAIN), 2023, Generative artificial intelligence: Guidelines for educators; O'Brien M., 2008, International Journal for the Scholarship of Teaching and Learning, V2, P1, DOI [10.20429/ijsotl.2008.020215, DOI 10.20429/IJSOTL.2008.020215]; Ouyang F, 2022, EDUC INF TECHNOL, V27, P7893, DOI 10.1007/s10639-022-10925-9; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Poole G, 2013, INT STUD HIGH EDUC, P118; Roe J, 2023, Journal of English and Applied Linguistics, V2, P3, DOI 10.59588/2961-3094.1035; Roxa T., 2012, Teacher Development in Higher Education: Existing Programs, Program Impact, and Future Trends, P1, DOI DOI 10.4324/9780203096826; Roxå T, 2015, INT J ACAD DEV, V20, P193, DOI 10.1080/1360144X.2015.1029929; Sabzalieva E., 2023, ChatGPT and artificial intelligence in higher education quick start guide; Sharples M, 2022, INT J ARTIF INTELL E, V32, P1119, DOI 10.1007/s40593-022-00300-7; Simmons N., 2016, New Directions for Teaching and Learning, V146, P13, DOI [10.1002/tl.20182, DOI 10.1002/TL.20182]; Simmons N., 2016, New Directions for Teaching and Learning, V146, P95, DOI [10.1002/tl.20192, DOI 10.1002/TL.20192]; Simmons N, 2019, CAN J SCHOLARSH TEA, V10, DOI 10.5206/cjsotl-rcacea.2019.1.7995; Stanford University, What is AI? / Basic Questions; Tauginiene L., Glossary for Academic Integrity; Taylor KL, 2022, INT J ACAD DEV, V27, P279, DOI 10.1080/1360144X.2021.1899931; TEQSA (Tertiary Education Quality and Standards Agency), 2017, GOOD PRACTICE NOTE A; Trigwell K., 2021, University teaching in focus: A learning-centred approach, V2nd, P286, DOI [10.4324/9781003008330, DOI 10.4324/9781003008330]; UNESCO, 2023, Harnessing the era of artificial intelligence in higher education; Unesco, 2021, The ethics of artificial intelligence; Verwood R., 2016, New Directions for Teaching and Learning, V146, P79, DOI [10.1002/tl, DOI 10.1002/TL]; Weber-Wulff D., 2023, Computation and Language; Whitford E., 2022, Forbes December 9; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zohny H, 2023, J MED ETHICS, V49, P79, DOI 10.1136/jme-2023-108909	75	0	0	12	12	ASOC INTERUNIVERSITARIA INVESTIGACION PEDAGOGICA	VALENCIA	AVE BLASCO IBANEZ NO 30, VALENCIA, 46010, SPAIN	1134-4032			RELIEVE	RELIEVE		2023	29	2								10.30827/relieve.v29i2.29295	http://dx.doi.org/10.30827/relieve.v29i2.29295			21	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	JF8X8		gold			2024-07-03	WOS:001171855700010
J	Chen, ZT; Peng, C; Petsch, AN; Chitturi, SR; Okullo, A; Chowdhury, S; Yoon, CH; Turner, JJ				Chen, Zhantao; Peng, Cheng; Petsch, Alexander N.; Chitturi, Sathya R.; Okullo, Alana; Chowdhury, Sugata; Yoon, Chun Hong; Turner, Joshua J.			Bayesian experimental design and parameter estimation for ultrafast spin dynamics	MACHINE LEARNING-SCIENCE AND TECHNOLOGY			English	Article						machine learning; Bayesian experimental design; ultrafast x-ray scattering; parameter estimation; spin fluctuations	RAY; SPECTROSCOPY; SINGLE; INTENSITY	Advanced experimental measurements are crucial for driving theoretical developments and unveiling novel phenomena in condensed matter and materials physics, which often suffer from the scarcity of large-scale facility resources, such as x-ray or neutron scattering centers. To address these limitations, we introduce a methodology that leverages the Bayesian optimal experimental design paradigm to efficiently uncover key quantum spin fluctuation parameters from x-ray photon fluctuation spectroscopy (XPFS) data. Our method is compatible with existing theoretical simulation pipelines and can also be used in combination with fast machine learning surrogate models in the event that real-time simulations are unfeasible. Our numerical benchmarks demonstrate the superior performance in predicting model parameters and in delivering more informative measurements within limited experimental time. Our method can be adapted to many different types of experiments beyond XPFS and spin fluctuation studies, facilitating more efficient data collection and accelerating scientific discoveries.	[Chen, Zhantao; Peng, Cheng; Petsch, Alexander N.; Turner, Joshua J.] Stanford Univ, Stanford Inst Mat & Energy Sci, Stanford, CA 94305 USA; [Chen, Zhantao; Petsch, Alexander N.; Chitturi, Sathya R.; Yoon, Chun Hong; Turner, Joshua J.] SLAC Natl Accelerator Lab, Linac Coherent Light Source, Menlo Pk, CA 94025 USA; [Chitturi, Sathya R.] Stanford Univ, Dept Mat Sci & Engn, Stanford, CA USA; [Okullo, Alana; Chowdhury, Sugata] Howard Univ, Dept Phys & Astron, Washington, DC USA	Stanford University; Stanford University; United States Department of Energy (DOE); SLAC National Accelerator Laboratory; Stanford University; Howard University	Chen, ZT; Turner, JJ (corresponding author), Stanford Univ, Stanford Inst Mat & Energy Sci, Stanford, CA 94305 USA.; Chen, ZT; Yoon, CH; Turner, JJ (corresponding author), SLAC Natl Accelerator Lab, Linac Coherent Light Source, Menlo Pk, CA 94025 USA.	zhantao@stanford.edu; yoon82@slac.stanford.edu; joshuat@slac.stanford.edu	Chen, Zhantao/HNB-7839-2023; Peng, Cheng/R-4428-2018	Chen, Zhantao/0000-0003-1954-3868; Turner, Joshua J./0000-0002-2106-7955; Chowdhury, Sugata/0000-0001-5480-6075; Peng, Cheng/0000-0002-9267-1789	National Energy Research Scientific Computing Centerhttp://dx.doi.org/10.13039/100017223 [DE-SC0022216]; U.S. Department of Energy, Office of Science, Basic Energy Sciences [DE-AC02-76SF00515]; U.S. Department of Energy, Office of Science, Basic Energy Sciences, through the Materials Sciences and Engineering Division; U.S. DOE, Office of Science, Basic Energy Sciences through the Early Career Research Program; DOE Office of Science User Facility [BES-ERCAP0023852]; Office of Science of the U.S. Department of Energy	National Energy Research Scientific Computing Centerhttp://dx.doi.org/10.13039/100017223; U.S. Department of Energy, Office of Science, Basic Energy Sciences(United States Department of Energy (DOE)); U.S. Department of Energy, Office of Science, Basic Energy Sciences, through the Materials Sciences and Engineering Division(United States Department of Energy (DOE)); U.S. DOE, Office of Science, Basic Energy Sciences through the Early Career Research Program(United States Department of Energy (DOE)); DOE Office of Science User Facility(United States Department of Energy (DOE)); Office of Science of the U.S. Department of Energy(United States Department of Energy (DOE))	This work was supported by the U.S. Department of Energy, Office of Science, Basic Energy Sciences under Award No. DE-SC0022216. Portions of this work were also supported by the U.S. Department of Energy, Office of Science, Basic Energy Sciences, through the Materials Sciences and Engineering Division, as well as the Scientific User Facilities Division through the Linac Coherent Light Source (LCLS), SLAC National Accelerator Laboratory, both operating under Contract DE-AC02-76SF00515. J J Turner acknowledges support from the U.S. DOE, Office of Science, Basic Energy Sciences through the Early Career Research Program. This research used resources of the National Energy Research Scientific Computing Center, a DOE Office of Science User Facility supported by the Office of Science of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231 using NERSC award BES-ERCAP0023852. We thank Lichuan Zhang for enlightening discussions and are grateful for the insightful comments and suggestions from Dr Robert D McMichael. We acknowledge the assistance of the large language model ChatGPT by OpenAI in refining the language and enhancing the readability of this paper.	Ament LJP, 2011, REV MOD PHYS, V83, DOI 10.1103/RevModPhys.83.705; Bandyopadhyay R, 2005, REV SCI INSTRUM, V76, DOI 10.1063/1.2037987; Bernitt S, 2012, NATURE, V492, P225, DOI 10.1038/nature11627; Bielecki J, 2020, STRUCT DYNAM-US, V7, DOI 10.1063/4.0000024; Bogan MJ, 2008, NANO LETT, V8, P310, DOI 10.1021/nl072728k; Burdet NG, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98774-3; Burkel E, 2000, REP PROG PHYS, V63, P171, DOI 10.1088/0034-4885/63/2/203; Caouette-Mansour M, 2022, PHYS REV APPL, V17, DOI 10.1103/PhysRevApplied.17.064031; Chen HW, 2022, 2022 4TH ANNUAL WORKSHOP ON EXTREME-SCALE EXPERIMENT-IN-THE-LOOP COMPUTING, XLOOP, P1, DOI 10.1109/XLOOP56614.2022.00006; Chen LB, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.041028; Chen Y, 2019, PHYS REV B, V99, DOI 10.1103/PhysRevB.99.104306; Chitturi SR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-41378-4; Cimini V, 2023, ADV PHOTONICS, V5, DOI 10.1117/1.AP.5.1.016005; Donatelli JJ, 2017, P NATL ACAD SCI USA, V114, P7222, DOI 10.1073/pnas.1708217114; Dushenko S, 2020, PHYS REV APPL, V14, DOI 10.1103/PhysRevApplied.14.054036; Elfring J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020438; Esposito V, 2020, APPL PHYS LETT, V116, DOI 10.1063/5.0004879; Fadley CS, 2010, J ELECTRON SPECTROSC, V178, P2, DOI 10.1016/j.elspec.2010.01.006; Fiderer LJ, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.020303; Gelman A., 2013, BAYESIAN DATA ANAL; Granade CE, 2012, NEW J PHYS, V14, DOI 10.1088/1367-2630/14/10/103013; Gutt C, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.024801; Gutt C, 2009, OPT EXPRESS, V17, P55, DOI 10.1364/OE.17.000055; Hendrickson WA, 2000, TRENDS BIOCHEM SCI, V25, P637, DOI 10.1016/S0968-0004(00)01721-7; Hruszkewycz SO, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.185502; Huan X, 2013, J COMPUT PHYS, V232, P288, DOI 10.1016/j.jcp.2012.08.013; Husband RJ, 2021, COMMUN MATER, V2, DOI 10.1038/s43246-021-00158-7; Hwang H, 2021, J PHYS CHEM LETT, V12, P3246, DOI 10.1021/acs.jpclett.1c00150; Jo W, 2023, OPT EXPRESS, V31, P3315, DOI 10.1364/OE.477774; Kim SK, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.227201; Kingma D. P., 2017, ARXIV; Lee I, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.017201; Lehmkühler F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136179; Livet F, 2000, NUCL INSTRUM METH A, V451, P596, DOI 10.1016/S0168-9002(00)00333-8; Long Q, 2013, COMPUT METHOD APPL M, V259, P24, DOI 10.1016/j.cma.2013.02.017; Martin-Garcia JM, 2021, CRYSTALS, V11, DOI 10.3390/cryst11050521; McMichael RD, 2022, PHYS REV APPL, V18, DOI [10.1103/PhysRevApplied.18.054001, 10.1103/physrevapplied.18.054001]; McMichael RD, 2021, J APPL PHYS, V130, DOI 10.1063/5.0055630; McMichael RD, 2021, J RES NATL INST STAN, V126, DOI 10.6028/jres.126.002; Mitrano M, 2020, COMMUN PHYS-UK, V3, DOI 10.1038/s42005-020-00447-6; Mohanty S, 2022, MODEL SIMUL MATER SC, V30, DOI 10.1088/1361-651X/ac860c; Neppl S, 2015, J ELECTRON SPECTROSC, V200, P64, DOI 10.1016/j.elspec.2015.03.002; Nolan S, 2021, NPJ QUANTUM INFORM, V7, DOI 10.1038/s41534-021-00497-w; Owerre SA, 2016, J PHYS-CONDENS MAT, V28, DOI 10.1088/0953-8984/28/38/386001; Pellegrini C, 2016, PHYS SCRIPTA, VT169, DOI 10.1088/1402-4896/aa5281; Plumley R, 2023, Arxiv, DOI arXiv:2305.07787; Ribic PR, 2012, J PHYS D APPL PHYS, V45, DOI 10.1088/0022-3727/45/21/213001; Robert C P., 2007, The Bayesian Choice: From Decision-Theoretic Foundations to Computational Implementation, pp 105; Ryan EG, 2016, INT STAT REV, V84, P128, DOI 10.1111/insr.12107; Sachdev S, 2011, PHYS TODAY, V64, P29, DOI 10.1063/1.3554314; Seaberg MH, 2021, PHYS REV RES, V3, DOI 10.1103/PhysRevResearch.3.033249; Seaberg MH, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.067403; Shen L, 2021, MRS ADV, V6, P221, DOI 10.1557/s43580-021-00051-y; Sutton M, 2008, CR PHYS, V9, P657, DOI 10.1016/j.crhy.2007.04.008; Takabe H, 2021, HIGH POWER LASER SCI, V9, DOI 10.1017/hpl.2021.35; Toth S, 2015, J PHYS-CONDENS MAT, V27, DOI 10.1088/0953-8984/27/16/166002; Wark JS, 2022, J APPL PHYS, V132, DOI 10.1063/5.0089388; Zhang LC, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.134414; Zhu FF, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abi7532	59	0	0	3	3	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND		2632-2153		MACH LEARN-SCI TECHN	Mach. Learn.-Sci. Technol.	DEC 1	2023	4	4							045056	10.1088/2632-2153/ad113a	http://dx.doi.org/10.1088/2632-2153/ad113a			18	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Science & Technology - Other Topics	CO9C0		gold			2024-07-03	WOS:001126295700001
J	Le, KDR; Tay, SBP; Choy, KT; Verjans, J; Sasanelli, N; Kong, JCH				Le, Khang Duy Ricky; Tay, Samuel Boon Ping; Choy, Kay Tai; Verjans, Johan; Sasanelli, Nicola; Kong, Joseph C. H.			Applications of natural language processing tools in the surgical journey	FRONTIERS IN SURGERY			English	Review						natural language processing; artificial intelligence; large language models; ChatGPT; generative pre-training transformer; surgery; surgical research; surgical education	PATHOLOGICAL FINDINGS; QUALITY MEASUREMENT; OPERATIVE NOTES; SURGERY; CHATGPT; SYSTEM; IDENTIFICATION; VALIDATION; ALGORITHM; EDUCATION	Background Natural language processing tools are becoming increasingly adopted in multiple industries worldwide. They have shown promising results however their use in the field of surgery is under-recognised. Many trials have assessed these benefits in small settings with promising results before large scale adoption can be considered in surgery. This study aims to review the current research and insights into the potential for implementation of natural language processing tools into surgery.Methods A narrative review was conducted following a computer-assisted literature search on Medline, EMBASE and Google Scholar databases. Papers related to natural language processing tools and consideration into their use for surgery were considered.Results Current applications of natural language processing tools within surgery are limited. From the literature, there is evidence of potential improvement in surgical capability and service delivery, such as through the use of these technologies to streamline processes including surgical triaging, data collection and auditing, surgical communication and documentation. Additionally, there is potential to extend these capabilities to surgical academia to improve processes in surgical research and allow innovation in the development of educational resources. Despite these outcomes, the evidence to support these findings are challenged by small sample sizes with limited applicability to broader settings.Conclusion With the increasing adoption of natural language processing technology, such as in popular forms like ChatGPT, there has been increasing research in the use of these tools within surgery to improve surgical workflow and efficiency. This review highlights multifaceted applications of natural language processing within surgery, albeit with clear limitations due to the infancy of the infrastructure available to leverage these technologies. There remains room for more rigorous research into broader capability of natural language processing technology within the field of surgery and the need for cross-sectoral collaboration to understand the ways in which these algorithms can best be integrated.	[Le, Khang Duy Ricky] Royal Melbourne Hosp, Dept Gen Surg Specialties, Melbourne, Vic, Australia; [Le, Khang Duy Ricky; Kong, Joseph C. H.] Peter MacCallum Canc Ctr, Dept Surg Oncol, Melbourne, Vic, Australia; [Le, Khang Duy Ricky] Deakin Univ, Geelong Clin Sch, Sch Med, Geelong, Vic 3220, Australia; [Le, Khang Duy Ricky] Univ Melbourne, Dept Med Educ, Melbourne, Vic, Australia; [Tay, Samuel Boon Ping] Eastern Hlth, Dept Anaesthesia & Pain Med, Box Hill, Box Hill, Vic, Australia; [Choy, Kay Tai] Austin Hlth, Dept Surg, Melbourne, Vic, Australia; [Verjans, Johan] Univ Adelaide, Australian Inst Machine Learning AIML, Adelaide, SA, Australia; [Verjans, Johan] South Australian Hlth & Med Res Inst, Lifelong Hlth Theme Platform AIl, Adelaide, SA, Australia; [Sasanelli, Nicola] Univ South Australia, Div Informat Technol Engn & Environm, Adelaide, SA, Australia; [Sasanelli, Nicola] SmartSat Cooperat Res Ctr, Adelaide, SA 5000, Australia; [Sasanelli, Nicola] Agora High Tech, Adelaide, SA, Australia; [Kong, Joseph C. H.] Monash Univ, Alfred Hosp, Dept Surg, Melbourne, Vic, Australia; [Kong, Joseph C. H.] Alfred Hosp, Dept Colorectal Surg, Melbourne, Vic, Australia; [Kong, Joseph C. H.] Univ Melbourne, Sir Peter MacCallum Dept Oncol, Melbourne, Vic, Australia	Melbourne Health; Royal Melbourne Hospital; Peter Maccallum Cancer Center; Deakin University; University of Melbourne; Eastern Health; Florey Institute of Neuroscience & Mental Health; Austin Research Institute; University of Adelaide; South Australian Health & Medical Research Institute (SAHMRI); University of South Australia; University of Western Australia; Florey Institute of Neuroscience & Mental Health; Monash University; Florey Institute of Neuroscience & Mental Health; Peter Maccallum Cancer Center; University of Melbourne	Le, KDR (corresponding author), Royal Melbourne Hosp, Dept Gen Surg Specialties, Melbourne, Vic, Australia.; Le, KDR (corresponding author), Peter MacCallum Canc Ctr, Dept Surg Oncol, Melbourne, Vic, Australia.; Le, KDR (corresponding author), Deakin Univ, Geelong Clin Sch, Sch Med, Geelong, Vic 3220, Australia.; Le, KDR (corresponding author), Univ Melbourne, Dept Med Educ, Melbourne, Vic, Australia.	khangduyricky.le@petermac.org						Abedian S, 2021, JCO CLIN CANCER INFO, V5, P1054, DOI 10.1200/CCI.21.00065; Al-Haddad MA, 2010, HPB, V12, P688, DOI 10.1111/j.1477-2574.2010.00235.x; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; Ali H, 2023, OBES SURG, V33, P1605, DOI 10.1007/s11695-023-06576-5; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Ali SR, 2023, BRIT J SURG, V110, P1072, DOI 10.1093/bjs/znad055; Ali SR, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.870494; Ananthakrishnan AN, 2013, INFLAMM BOWEL DIS, V19, P1411, DOI 10.1097/MIB.0b013e31828133fd; Atkinson CJ, 2024, J CLIN MED, V13, DOI 10.3390/jcm13030900; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Bian YY, 2020, J MED INTERNET RES, V22, DOI 10.2196/16896; Boitano LT, 2023, J VASC SURG, V77, P922, DOI 10.1016/j.jvs.2022.10.034; Bozbiyik O, 2020, ASIAN J SURG, V43, P755, DOI 10.1016/j.asjsur.2019.10.002; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bucher BT, 2020, ANN SURG, V272, P629, DOI 10.1097/SLA.0000000000004133; Buckley Julliette M, 2012, J Pathol Inform, V3, P23, DOI 10.4103/2153-3539.97788; Chapman AB., 2017, AMIA ANN S P; Chen KJ, 2020, J SURG RES, V256, P557, DOI 10.1016/j.jss.2020.07.015; Cheng KM, 2023, INT J SURG, V109, P1545, DOI 10.1097/JS9.0000000000000388; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Cohen KB, 2016, BIOMED INFORM INSIGH, V8, P11, DOI 10.4137/BII.S38308; Danilov Gleb, 2022, Stud Health Technol Inform, V295, P555, DOI 10.3233/SHTI220788; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Fevrier HB, 2020, J MED SYST, V44, DOI 10.1007/s10916-020-01604-8; Freedman JD, 2023, Arxiv, DOI arXiv:2304.01503; Glaser AP, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.17.00128; Groot OQ, 2020, ACTA ONCOL, V59, P1455, DOI 10.1080/0284186X.2020.1819563; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Han ZY, 2024, MED TEACH, V46, P657, DOI 10.1080/0142159X.2023.2271159; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Hou JK, 2014, CLIN GASTROENTEROL H, V12, P1257, DOI 10.1016/j.cgh.2014.05.013; Hu W, 2022, TRANSL VIS SCI TECHN, V11, DOI 10.1167/tvst.11.3.37; Imamguluyev R., 2023, Int J Res Pub Rev, V2582, P7421, DOI [10.55248/gengpi.2023.4.33987, DOI 10.55248/GENGPI.2023.4.33987]; Imler TD, 2018, GASTROINTEST ENDOSC, V87, P164, DOI 10.1016/j.gie.2017.04.030; Imler TD, 2015, AM J GASTROENTEROL, V110, P543, DOI 10.1038/ajg.2015.51; Karhade AV, 2022, CLIN ORTHOP RELAT R, V480, P1766, DOI 10.1097/CORR.0000000000002200; Karhade AV, 2022, SPINE J, V22, P272, DOI 10.1016/j.spinee.2021.08.002; Karhade AV, 2021, SPINE J, V21, P1635, DOI 10.1016/j.spinee.2020.04.001; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khilnani AK., 2023, GAIMS J Med Sci, V3, P1, DOI [10.5281/zenodo.7751267, DOI 10.5281/ZENODO.7751267]; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kim BJ, 2014, J ENDOUROL, V28, P1474, DOI 10.1089/end.2014.0221; Kim JS, 2023, GLOB SPINE J, V13, P1946, DOI 10.1177/21925682211062831; Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173; Kooragayala K, 2022, ANN SURG ONCOL, V29, P8513, DOI 10.1245/s10434-022-12391-6; Kunz V, 2023, INT J COMPUT ASS RAD, V18, P961, DOI 10.1007/s11548-022-02791-0; Laique SN, 2021, GASTROINTEST ENDOSC, V93, P750, DOI 10.1016/j.gie.2020.08.038; Le KDR., 2024, Int Med Educ, V3, P100, DOI [10.3390/ime3010009, DOI 10.3390/IME3010009]; Le Q., 2024, JVS-Vascular Insights, V2, P100052, DOI [10.1016/j.jvsvi.2023.100052, DOI 10.1016/J.JVSVI.2023.100052]; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Li MD, 2022, ACAD RADIOL, V29, P479, DOI 10.1016/j.acra.2021.01.017; Lilley EJ, 2018, ANN SURG, V267, P823, DOI 10.1097/SLA.0000000000002579; Mohan S, 2023, CRANIOMAX TRAUM REC, DOI 10.1177/19433875231222803; Morris MX, 2023, AM SURGEON, V89, P43, DOI 10.1177/00031348221117039; Muhlestein WE, 2021, NEUROSURGERY, V88, P838, DOI 10.1093/neuros/nyaa585; Murff HJ, 2011, JAMA-J AM MED ASSOC, V306, P848, DOI 10.1001/jama.2011.1204; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Ötles E, 2021, ACAD MED, V96, P1457, DOI 10.1097/ACM.0000000000004153; Parreco J, 2018, AM SURGEON, V84, P1190; Patel TA, 2017, CANCER-AM CANCER SOC, V123, P114, DOI 10.1002/cncr.30245; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sagheb E, 2021, J ARTHROPLASTY, V36, P922, DOI 10.1016/j.arth.2020.09.029; Sakowski JA, 2009, HEALTH AFFAIR, V28, pW544, DOI 10.1377/hlthaff.28.4.w544; Sasanelli F, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app132011586; Savova GK, 2017, CANCER RES, V77, pE115, DOI 10.1158/0008-5472.CAN-17-0615; Sohn S, 2017, J SURG RES, V209, P168, DOI 10.1016/j.jss.2016.09.058; Sok S., 2023, ChatGPT for education and research: A review of benefits and risks; Solomon MD, 2021, CARDIOVASC DIGIT HLT, V2, P156, DOI 10.1016/j.cvdhj.2021.03.003; Suh HS, 2022, ANESTH ANALG, V135, P1162, DOI 10.1213/ANE.0000000000006152; Tibbo ME, 2019, J ARTHROPLASTY, V34, P2216, DOI 10.1016/j.arth.2019.07.025; Tinmouth J, 2023, GASTROINTEST ENDOSC, V97, P121, DOI 10.1016/j.gie.2022.07.009; Wauben LSGL, 2011, BRIT J SURG, V98, P1431, DOI 10.1002/bjs.7576; Weissler EH, 2020, CIRC-CARDIOVASC INTE, V13, DOI 10.1161/CIRCINTERVENTIONS.120.009447; Wissel BD, 2020, EPILEPSIA, V61, P39, DOI 10.1111/epi.16398; Wu GS, 2023, ANN SURG ONCOL, V30, P2095, DOI 10.1245/s10434-022-12955-6; Wyles CC, 2023, J ARTHROPLASTY, V38, P2081, DOI 10.1016/j.arth.2022.10.031; Xu H., 2004, MEDINFO 2004. Studies in Health Technology and Informatics; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zaidat B, 2023, GLOB SPINE J, DOI 10.1177/21925682231164935; Zhao Z., 2021, PMLR; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	85	0	0	4	4	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2296-875X			FRONT SURG	Front. Surg.	MAY 17	2024	11								1403540	10.3389/fsurg.2024.1403540	http://dx.doi.org/10.3389/fsurg.2024.1403540			11	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	SN9V2	38826809	gold			2024-07-03	WOS:001235257700001
J	Lissak, S; Ophir, Y; Tikochinski, R; Klomek, AB; Sisso, I; Fruchter, E; Reichart, R				Lissak, Shir; Ophir, Yaakov; Tikochinski, Refael; Brunstein Klomek, Anat; Sisso, Itay; Fruchter, Eyal; Reichart, Roi			Bored to death: Artificial Intelligence research reveals the role of boredom in suicide behavior	FRONTIERS IN PSYCHIATRY			English	Article						boredom; social media; large language models; natural language processing; deep learning; risk factors discovery; suicide research; suicide prevention	SEVERITY RATING-SCALE; DEPRESSION; THOUGHTS; ADOLESCENTS; VALIDATION; VALIDITY; RISK	Background Recent advancements in Artificial Intelligence (AI) contributed significantly to suicide assessment, however, our theoretical understanding of this complex behavior is still limited.Objective This study aimed to harness AI methodologies to uncover hidden risk factors that trigger or aggravate suicide behaviors.Methods The primary dataset included 228,052 Facebook postings by 1,006 users who completed the gold-standard Columbia Suicide Severity Rating Scale. This dataset was analyzed using a bottom-up research pipeline without a-priory hypotheses and its findings were validated using a top-down analysis of a new dataset. This secondary dataset included responses by 1,062 participants to the same suicide scale as well as to well-validated scales measuring depression and boredom.Results An almost fully automated, AI-guided research pipeline resulted in four Facebook topics that predicted the risk of suicide, of which the strongest predictor was boredom. A comprehensive literature review using APA PsycInfo revealed that boredom is rarely perceived as a unique risk factor of suicide. A complementing top-down path analysis of the secondary dataset uncovered an indirect relationship between boredom and suicide, which was mediated by depression. An equivalent mediated relationship was observed in the primary Facebook dataset as well. However, here, a direct relationship between boredom and suicide risk was also observed.Conclusion Integrating AI methods allowed the discovery of an under-researched risk factor of suicide. The study signals boredom as a maladaptive 'ingredient' that might trigger suicide behaviors, regardless of depression. Further studies are recommended to direct clinicians' attention to this burdening, and sometimes existential experience.	[Lissak, Shir; Ophir, Yaakov; Tikochinski, Refael; Reichart, Roi] Technion Israel Inst Technol, Fac Data & Decis Sci, Haifa, Israel; [Ophir, Yaakov] Univ Cambridge, Ctr Human Inspired Artificial Intelligence CHIA, Cambridge, England; [Brunstein Klomek, Anat] Reichman Univ, Baruch Ivcher Sch Psychol, Herzliyya, Israel; [Sisso, Itay] Hebrew Univ Jerusalem, Cognit Sci Dept, Jerusalem, Israel; [Fruchter, Eyal] Technion Israel Inst Technol, Rappaport Fac Med, Haifa, Israel	Technion Israel Institute of Technology; University of Cambridge; Reichman University; Hebrew University of Jerusalem; Technion Israel Institute of Technology; Rappaport Faculty of Medicine	Ophir, Y (corresponding author), Technion Israel Inst Technol, Fac Data & Decis Sci, Haifa, Israel.; Ophir, Y (corresponding author), Univ Cambridge, Ctr Human Inspired Artificial Intelligence CHIA, Cambridge, England.	yaakovophir@gmail.com			VATAT; Israeli higher education council	VATAT; Israeli higher education council	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. A grant for data science by VATAT, the Israeli higher education council was used to partially fund the scholarships of Shir Lissak.	Alishahi A, 2019, NAT LANG ENG, V25, P543, DOI 10.1017/S135132491900024X; American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU; Badian Y, 2024, J CLIN PSYCHIAT, V85, DOI 10.4088/JCP.23m14962; Bargdill R.W., 2000, J PHENOMENOL PSYCHOL, V31, P188, DOI DOI 10.1163/15691620051090979; Bargdill RW, 2019, J HUMANIST PSYCHOL, V59, P294, DOI 10.1177/0022167816637948; Ben-Zeev D, 2012, PSYCHIAT RES, V197, P55, DOI 10.1016/j.psychres.2011.11.025; Bench SW, 2019, EMOTION, V19, P242, DOI 10.1037/emo0000433; Bernert RA, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17165929; Bilu Y, 2023, J AM ACAD CHILD PSY, V62, P920, DOI 10.1016/j.jaac.2022.12.026; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chapman AL, 2006, BEHAV RES THER, V44, P371, DOI 10.1016/j.brat.2005.03.005; Chin A, 2017, EMOTION, V17, P359, DOI 10.1037/emo0000232; CHOQUET M, 1993, ADOLESCENCE, V28, P649; D'Agostino A, 2020, HARVARD REV PSYCHIAT, V28, P287, DOI 10.1097/HRP.0000000000000269; Drapeau CW, 2019, SLEEP MED REV, V46, P17, DOI 10.1016/j.smrv.2019.03.009; El-Den S, 2018, J AFFECT DISORDERS, V225, P503, DOI 10.1016/j.jad.2017.08.060; Fahlman SA, 2013, ASSESSMENT, V20, P68, DOI 10.1177/1073191111421303; FARMER R, 1986, J PERS ASSESS, V50, P4, DOI 10.1207/s15327752jpa5001_2; Finkielsztein M., 2023, J Boredom Stud, V1, P1; Franklin JC, 2017, PSYCHOL BULL, V143, P187, DOI 10.1037/bul0000084; Goldberg YK, 2011, J SOC CLIN PSYCHOL, V30, P647, DOI 10.1521/jscp.2011.30.6.647; Heckler WF, 2022, COMPUT HUM BEHAV, V128, DOI 10.1016/j.chb.2021.107095; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; Jimenez M., 2012, An analysis of neuropsychological functioning and psychopathic traits in correctional patients with histories of suicidal behavior; King LA, 2021, ANNU REV PSYCHOL, V72, P561, DOI 10.1146/annurev-psych-072420-122921; Kleiman EM, 2013, PSYCHIAT RES, V210, P934, DOI 10.1016/j.psychres.2013.08.002; Klonsky ED, 2007, CLIN PSYCHOL REV, V27, P226, DOI 10.1016/j.cpr.2006.08.002; Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x; Land K.C., 1969, SOCIOL METHODOL, V1, P3, DOI DOI 10.2307/270879; LESTER D, 1993, PSYCHOL REP, V73, P622, DOI 10.2466/pr0.1993.73.2.622; Levi-Belz Y, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00214; Markowitz John C, 2004, World Psychiatry, V3, P136; Masland SR, 2020, PSYCHOPATHOLOGY, V53, P239, DOI 10.1159/000511312; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mogotsi I. C., 2010, Information Retrieval, V13, P192, DOI [10.1007/s10791-009-9115-y, DOI 10.1007/S10791-009-9115-Y]; Mundt JC, 2010, J PSYCHIATR RES, V44, P1224, DOI 10.1016/j.jpsychires.2010.04.025; Nederkoorn C, 2016, PSYCHIAT RES, V237, P127, DOI 10.1016/j.psychres.2016.01.063; OpenAI, 2023, ChatGPT (September 24 version) Large language model; Ophir Y, 2022, CLIN PSYCHOL SCI, V10, P212, DOI 10.1177/21677026211022013; Ophir Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73917-0; Ophir Y, 2020, CLIN PSYCHOL SCI, V8, P65, DOI 10.1177/2167702619865973; Ophir Y, 2019, COMPUT HUM BEHAV, V91, P62, DOI 10.1016/j.chb.2018.09.025; Posner K, 2011, AM J PSYCHIAT, V168, P1266, DOI 10.1176/appi.ajp.2011.10111704; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Resnik P, 2021, SUICIDE LIFE-THREAT, V51, P88, DOI 10.1111/sltb.12674; Ribeiro JD, 2019, CLIN PSYCHOL SCI, V7, P941, DOI 10.1177/2167702619838464; Samji H, 2022, CHILD ADOL MENT H-UK, V27, P173, DOI 10.1111/camh.12501; Schafer KM, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249833; Spitzer RL, 1999, JAMA-J AM MED ASSOC, V282, P1737, DOI 10.1001/jama.282.18.1737; Stanley B, 2009, J AM ACAD CHILD PSY, V48, P1005, DOI 10.1097/CHI.0b013e3181b5dbfe; Todman M., 2013, Educ Res Int, V1, P40; Vallat R., 2018, Journal of Open Source Software, V3, P1026, DOI DOI 10.21105/JOSS.01026; van Tilburg WAP, 2017, EMOTION, V17, P309, DOI 10.1037/emo0000233; Viguera AC, 2015, PSYCHOSOMATICS, V56, P460, DOI 10.1016/j.psym.2015.04.005; WANGH M, 1975, SOC RES, V42, P538; Weber AN, 2017, MED CLIN N AM, V101, P553, DOI 10.1016/j.mcna.2016.12.006; Weingarten N., 2016, Maastricht Student J Psychol Neurosci, V5, P66; Weiss ER, 2022, BEHAV SCI-BASEL, V12, DOI 10.3390/bs12080298; Westgate EC, 2020, SOC PERSONAL PSYCHOL, V14, DOI 10.1111/spc3.12562; Westgate EC, 2020, CURR DIR PSYCHOL SCI, V29, P33, DOI 10.1177/0963721419884309; Wilson TD, 2014, SCIENCE, V345, P75, DOI 10.1126/science.1250830; Yao H, 2020, LANCET PSYCHIAT, V7, pE21, DOI 10.1016/S2215-0366(20)30090-0; Yusoufzai MK, 2022, MOTIV EMOTION, V46, P689, DOI 10.1007/s11031-022-09970-1; Zuckerman M., 1979, OPTIMAL LEVEL AROUSA	64	0	0	1	1	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-0640			FRONT PSYCHIATRY	Front. Psychiatry	MAY 3	2024	15								1328122	10.3389/fpsyt.2024.1328122	http://dx.doi.org/10.3389/fpsyt.2024.1328122			8	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	RR1F2	38784160	gold, Green Submitted			2024-07-03	WOS:001229289800001
J	Kim, H; Kim, P; Joo, I; Kim, JH; Park, CM; Yoon, SH				Kim, Hyungjin; Kim, Paul; Joo, Ijin; Kim, Jung Hoon; Park, Chang Min; Yoon, Soon Ho			ChatGPT Vision for Radiological Interpretation: An Investigation Using Medical School Radiology Examinations	KOREAN JOURNAL OF RADIOLOGY			English	Editorial Material						ChatGPT; GPT-4 vision; Artificial intelligence; Large language model; Vision language model; Foundation model; Transformer; Generative model; Chatbot			[Kim, Hyungjin; Joo, Ijin; Kim, Jung Hoon; Park, Chang Min; Yoon, Soon Ho] Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Radiol, Seoul, South Korea; [Kim, Paul] Stanford Univ, Grad Sch Educ, Stanford, CA USA; [Yoon, Soon Ho] Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Radiol, 101 Daehak Ro, Seoul 03080, South Korea	Seoul National University (SNU); Seoul National University Hospital; Stanford University; Seoul National University (SNU); Seoul National University Hospital	Yoon, SH (corresponding author), Seoul Natl Univ, Seoul Natl Univ Hosp, Coll Med, Dept Radiol, 101 Daehak Ro, Seoul 03080, South Korea.	yshoka@gmail.com		Yoon, Soon Ho/0000-0002-3700-0165; Kim, Hyungjin/0000-0003-0722-0033				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Jung KH, 2023, KOREAN J RADIOL, V24, P1038, DOI 10.3348/kjr.2023.0790; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970	6	1	1	5	5	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	APR	2024	25	4					403	406		10.3348/kjr.2024.0017	http://dx.doi.org/10.3348/kjr.2024.0017			4	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	ML2Z2	38528699	Green Published			2024-07-03	WOS:001193724100003
J	Shay, D; Kumar, B; Redaelli, S; von Wedel, D; Liu, MQ; Dershwitz, M; Schaefer, MS; Beam, A				Shay, Denys; Kumar, Bhawesh; Redaelli, Simone; von Wedel, Dario; Liu, Manqing; Dershwitz, Mark; Schaefer, Maximilian S.; Beam, Andrew			Could ChatGPT-4 pass an anaesthesiology board examination? Follow-up assessment of a comprehensive set of board examination practice questions	BRITISH JOURNAL OF ANAESTHESIA			English	Article						artificial intelligence; board examination; ChatGPT; GPT-4; large language models; medical knowledge; mul-tiple-choice questions; specialty qualifications	PERFORMANCE		[Shay, Denys; Kumar, Bhawesh; Liu, Manqing; Beam, Andrew] Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA 02115 USA; [Shay, Denys; Liu, Manqing; Beam, Andrew] Harvard TH Chan Sch Publ Hlth, The CAUSALab, Boston, MA 02115 USA; [Shay, Denys; Redaelli, Simone; von Wedel, Dario; Schaefer, Maximilian S.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Dept Anesthesia Crit Care & Pain Med, Boston, MA USA; [Shay, Denys; Redaelli, Simone; von Wedel, Dario; Schaefer, Maximilian S.] Harvard Med Sch, Ctr Anesthesia Res Excellence CARE, Beth Israel Deaconess Med Ctr, Boston, MA USA; [Redaelli, Simone] Univ Milano Bicocca, Sch Med & Surg, Milan, Italy; [Dershwitz, Mark] Univ Massachusetts, Dept Anesthesiol & Perioperat Med, Chan Med Sch, Worcester, MA USA; [Schaefer, Maximilian S.] Duesseldorf Univ Hosp, Dept Anesthesiol, Dusseldorf, Germany	Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Harvard Medical School; Beth Israel Deaconess Medical Center; Harvard University; Harvard Medical School; Beth Israel Deaconess Medical Center; University of Milano-Bicocca; University of Massachusetts System; University of Massachusetts Worcester	Beam, A (corresponding author), Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA 02115 USA.; Beam, A (corresponding author), Harvard TH Chan Sch Publ Hlth, The CAUSALab, Boston, MA 02115 USA.	andrew_beam@hms.harvard.edu	Liu, Man-Qing/M-9598-2014; Schaefer, Maximilian/F-2964-2013	Liu, Man-Qing/0000-0002-9754-3102; REDAELLI, SIMONE/0000-0003-0128-7376; Beam, Andrew/0000-0002-6657-2787; Schaefer, Maximilian/0000-0001-8186-4748; von Wedel, Dario/0000-0001-8102-0254; Kumar, Bhawesh/0009-0007-3550-1170				Aldridge MJ, 2023, BRIT J ANAESTH, V131, pe36, DOI 10.1016/j.bja.2023.04.033; Beam K, 2023, JAMA PEDIATR, V177, P977, DOI 10.1001/jamapediatrics.2023.2373; Kearney RA, 2000, CAN J ANAESTH, V47, P914, DOI 10.1007/BF03019676; Massey PA, 2023, J AM ACAD ORTHOP SUR, V31, P1173, DOI 10.5435/JAAOS-D-23-00396; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Shay D, 2023, BRIT J ANAESTH, V131, DOI 10.1016/j.bja.2023.04.017; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	8	1	1	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	JAN	2024	132	1					172	174		10.1016/j.bja.2023.10.025	http://dx.doi.org/10.1016/j.bja.2023.10.025		JAN 2024	3	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	IF9V7	37996275				2024-07-03	WOS:001165041400001
J	Lucas, H				Lucas, Hannah			Negative Capabilities: Investigating Apophasis in AI Text-to-Image Models	RELIGIONS			English	Article						artificial intelligence; religion; apophasis; mysticism; mystical theology; negative theology; semiotics; large language models; Julian of Norwich; medieval literature		Through a case study of images generated by Swedish artist Steph Maj Swanson using an AI text-to-image (T2I) model, this article explores the strategy of negative weight prompting in T2I models as a phenomenon of apophasis. Apophasis is a linguistic strategy commonly deployed in texts of mystical theology to express the ineffability of God through negative concepts. In this article, a comparison of apophatic strategies in mystical texts and T2I models is engaged to highlight the mutual benefit of theorising AI with the help of religious theory and concepts. With this, the article builds on previous work on the New Visibility of Religion, enchantment, and post-secularism-especially the research of Beth Singler on religious continuities in representations of AI. Recent work on AI prompt engineering, computational linguistics, and computational geometry is invoked to explain the linguistic processes of T2I models. Poststructuralist semiotics is then employed to theorise the search for the Transcendental Signified in apophatic theology. The article concludes that linguistic theology can help to elucidate technological use cases, subsequently arguing for further dialogue between scholars in artificial intelligence and religious studies, and for a revaluation of religion in the technological sphere.	[Lucas, Hannah] Univ Cambridge, Newnham Coll, Cambridge CB3 9DF, England	University of Cambridge	Lucas, H (corresponding author), Univ Cambridge, Newnham Coll, Cambridge CB3 9DF, England.	hal32@cam.ac.uk		Lucas, Hannah/0000-0003-0664-2859				Adobe Firefly, AD FIR; Anderson Martin., 2022, METAPHYSIC AI 1117; [Anonymous], 2011, LOOKING HOLY BOOKS E; Bellar W., 2013, Journal of Religion, Media and Digital Culture, V2, P1, DOI [10.1163/21659214-90000031, DOI 10.1163/21659214-90000031]; Butcher C.A., 2009, The cloud of unknowing with the book of privy counsel; Cervone CM, 2012, MIDDLE AGES SER, P1; Derrida J., 2000, The Routledge language and cultural theory reader, P241; DERRIDA Jacques, 1972, Positions; Ethan Smith, 2022, TRAVELERS GUIDE LATE; GELLNER Ernst., 1979, SPECTACLES PREDICAME; Geraci RobertM., 2010, APOCALYPTIC VISIONS; Glasscoe Marion., 1993, REVELATION LOVE; Graham Elaine., 2013, PAPER PRESENTED IMAG; Hoelzl Michael., 2008, The New Visibility of Religion: Studies in Religion and Cultural Hermeneutics. Continuum Resources in Religion and Political Culture; Jantzen Grace., 2000, Julian of Norwich: Mystic and Theologian; Josephson-Storm JasonA., 2017, The Myth of Disenchantment: Magic, Modernity, and the Birth of the Human Sciences; KIECKHEFER R, 1994, AM HIST REV, V99, P813, DOI 10.2307/2167771; Latour B., 1993, WE HAVE NEVER BEEN M; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Luccioni AS, 2023, Arxiv, DOI arXiv:2303.11408; McNamer S, 2010, MIDDLE AGES SER, P1; Midjourney, Midjourney; Mohamed Kiara., DIGITAL MYSTICISM DM; Musk Elon., 2014, TESLAS E MUSK WERE S; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Pagh R, 2015, LECT NOTES COMPUT SC, V9371, P3, DOI 10.1007/978-3-319-25087-8_1; Parsons Guy, 2022, The Dall-E 2 Prompt Book; Pressman John David., 2021, TWITTER THREAD KING; Qiao H, 2022, PROCEEDINGS OF THE 14TH CREATIVITY AND COGNITION, C&C 2022, P15, DOI 10.1145/3527927.3532792; Rassin R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2210.10606; Ringer Jeffrey., 2003, CHRISTIAN LIT, V53, P3, DOI DOI 10.1177/014833310305300101; Saharia C, 2022, Arxiv, DOI arXiv:2205.11487; Singler B, 2020, RELIGIONS, V11, DOI 10.3390/rel11050253; Singler B, 2020, AI SOC, V35, P945, DOI 10.1007/s00146-020-00968-2; Skala Matthew., 2022, TWITTER THREAD OKAY; Stable Diffusion, Stable Diffusion; Swanson Steph Maj., 2022, TWITTER POST CLARIFY; Tassi P, 2022, Forbes; Wang J., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2112.00718	40	0	0	1	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-1444		RELIGIONS	Religions	JUN	2023	14	6							812	10.3390/rel14060812	http://dx.doi.org/10.3390/rel14060812			15	Religion	Arts &amp; Humanities Citation Index (A&amp;HCI)	Religion	K7CP2		Green Published, gold			2024-07-03	WOS:001017986000001
C	Bonifacio, L; Abonizio, H; Fadaee, M; Nogueira, R			ACM	Bonifacio, Luiz; Abonizio, Hugo; Fadaee, Marzieh; Nogueira, Rodrigo			InPars: Unsupervised Dataset Generation for Information Retrieval	PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22)			English	Proceedings Paper	45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 11-15, 2022	Madrid, SPAIN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Few-shot Models; Large Language Models; Generative Models; Question Generation; Synthetic Datasets; Multi-stage Ranking		The Information Retrieval (IR) community has recently witnessed a revolution due to large pretrained transformer models. Another key ingredient for this revolution was the MS MARCO dataset, whose scale and diversity has enabled zero-shot transfer learning to various tasks. However, not all IR tasks and domains can benefit from one single dataset equally. Extensive research in various NLP tasks has shown that using domain-specific training data, as opposed to a general-purpose one, improves the performance of neural models [45, 56]. In this work, we harness the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks. We show that models fine-tuned solely on our synthetic datasets outperform strong base-lines such as BM25 as well as recently proposed self-supervised dense retrieval methods. Code, models, and data are available at https://github.com/zetaalphavector/inpars.	[Bonifacio, Luiz; Abonizio, Hugo; Fadaee, Marzieh; Nogueira, Rodrigo] Zeta Alpha, Amsterdam, Netherlands; [Bonifacio, Luiz; Abonizio, Hugo; Nogueira, Rodrigo] NeuralMind, Campinas, SP, Brazil; [Bonifacio, Luiz; Nogueira, Rodrigo] Univ Estadual Campinas, Campinas, SP, Brazil; [Nogueira, Rodrigo] Univ Waterloo, Waterloo, ON, Canada	Universidade Estadual de Campinas; University of Waterloo	Bonifacio, L (corresponding author), Zeta Alpha, Amsterdam, Netherlands.; Bonifacio, L (corresponding author), NeuralMind, Campinas, SP, Brazil.; Bonifacio, L (corresponding author), Univ Estadual Campinas, Campinas, SP, Brazil.		Nogueira, Rodrigo/AAX-1610-2020		Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2020/09753-5, 2022/01640-2]; Google Cloud for credits	Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)); Google Cloud for credits	This research was partially funded by grants 2020/09753-5 and 2022/01640-2 from Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP). We also would like to thank Google Cloud for credits to support this work.	Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen RC, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P445, DOI 10.1145/3077136.3080819; Craswell Nick, 2021, CoRR abs/2102.07662; Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303; Demidenko GV, 2006, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON BIOINFORMATICS OF GENOME REGULATION AND STRUCTURE, VOL 3, P43; Duta IC, 2016, INT WORK CONTENT MUL; Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090; Gao Luyu, 2021, ARXIV210805540; Han Jesse Michael, 2021, ARXIV211005448; Hasibi F, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1265, DOI 10.1145/3077136.3080751; Holtzman A., 2019, P INT C LEARN REPR; Izacard Gautier, 2021, ARXIV211209118; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khattab Omar, 2020, ABS200412832 CORR; Kobayashi S., 2018, P 2018 C N AM CHAPT, V2, P452, DOI DOI 10.18653/V1/N18-2072; Kumar Varun, 2020, P 2 WORKSHOP LIFE LO, P18; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Liu Alisa, 2022, ARXIV220105955CSCL; Liu SC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1557, DOI 10.1145/3097983.3098011; Ma J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1075; Maia M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1941, DOI 10.1145/3184558.3192301; Meng Yu, 2022, ARXIV220204538CSCL; Mohapatra B, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1190; Mokrii I, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2081, DOI 10.1145/3404835.3463093; Neelakantan Arvind, 2022, ARXIV220110005; Ni Jianmo, 2021, ARXIV211207899; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Papanikolaou Yannis, 2020, ARXIV200413845; Pradeep Ronak, 2021, ARXIV210105667; Pradeep Ronak, 2020, CORPUS, V5, pd3; Qu Yanru, 2021, INT C LEARN REPR; Rae Jack W, 2021, arXiv:2112.11446; Raffel C, 2020, J MACH LEARN RES, V21; Ram Ori, 2021, ARXIV211207708; Roberts K, 2020, J AM MED INFORM ASSN, V27, P1431, DOI 10.1093/jamia/ocaa091; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Sanh Victor., 2021, MULTITASK PROMPTED T; Santhanam Keshav, 2021, ARXIV211201488; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Schick Timo, 2021, ARXIV210407540; Sean M., 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), P4171; Sharami Javad Pourmostafa Roshan, 2022, ARXIV211206096CSCL; Thakur Nandan, 2021, 35 C NEURAL INFORM P; Voorhees Ellen, 2005, OVERVIEW TREC 2004 R, DOI [10.6028/NIST.SP.500-261, DOI 10.6028/NIST.SP.500-261]; Voorhees EM., 2004, Overview of the TREC 2004 Robust Track. Thirteenth Text Retrieval Conference; Voorhees EM, 1999, NIST Special Publication, P77, DOI DOI 10.1017/S1351324901002789; Wang Kexin, 2021, ARXIV211207577; Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231; Wei J., 2022, INT C LEARN REPR; Winata G. I., 2021, P 1 WORKSH MULT REPR, P1, DOI DOI 10.18653/V1/2021.MRL-1.1; Yang Yiben, 2020, 2020 of Findings of ACL, P1008; Yilmaz E, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2101, DOI 10.1145/3397271.3401317; Yu Tiezheng, 2021, ARXIV210311332CSCL	56	17	19	1	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-8732-3				2022							2387	2392		10.1145/3477495.3531863	http://dx.doi.org/10.1145/3477495.3531863			6	Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT8CB					2024-07-03	WOS:000852715902079
J	Kozlikhin, I; Demidov, A				Kozlikhin, Igor; Demidov, Alexey			Using Generative Neural Networks as a Media in Education: Formal Analysis in the Context of the Russian Legal System	MEDIA EDUCATION-MEDIAOBRAZOVANIE			English	Article						law; media education; media and information literacy; MIL; new media; mass communication; neural networks; generative AI; large language models		The article discusses using of generative neural networks in education, especially in legal education, as an example, employing formal analysis in the context of the Russian legal system. Neural networks are considered as a kind of media and hence the issue of using neural networks by students is by nature a question of media education, its application, and its limits. The core question is whether it is possible to give students the opportunity to use generative neural networks when performing tasks like writing a diploma. Neural networks are considered as a kind of "new media" that must be assessed in the context of the media philosophy dichotomy between "tool" and "body". The article reviews several scenarios of law students using neural networks and the conclusion is provided that not in all cases it is inadmissible. However, in the cases that concern the core competences that relate to understanding law as a phenomenon of information and communication, it is inadmissible. Such core competences imply command of natural language and writing reasoning skills. It is critical to take into an account the provisions of the legislation that focus on the concept and purposes of education which clarify the matter on the formal side. Ultimately, the "blackout test" is suggested to discern the cases were using of neural networks in education is not possible.	[Kozlikhin, Igor] St Petersburg State Univ, St Petersburg, Russia; [Demidov, Alexey] Moscow State Inst Culture, Moscow, Russia	Saint Petersburg State University	Demidov, A (corresponding author), Moscow State Inst Culture, Moscow, Russia.	aademidov@yandex.ru; igkoz52@mail.ru						Belov S.A., 2023, Zakon, V1, P23; Brennan T, 2009, CRIM JUSTICE BEHAV, V36, P21, DOI 10.1177/0093854808326545; Fedorov A.V., 2013, Distancionnoe i virtual'noe obuchenie, V10, P72; Hunter D, 2020, U NSW LAW J, V43, P1199; Kacinová V, 2018, COMMUN TODAY, V9, P38; Lee NT, 2018, J INF COMMUN ETHICS, V16, P252, DOI 10.1108/JICES-06-2018-0056; Manovich L., 2001, The Language of New Media; Ocheretyany K.A., 2015, Ph.D. Dis; Petranová D, 2017, COMMUN TODAY, V8, P52; Polyakov Timoshina, 2017, General theory of law; Sharikov A.V., 2012, Media Education, V4, P61; Sidorkin A.M., 2024, Embracing chatbots in higher education: the use of artificial intelligence in teaching, administration, and scholarship; Southerland Vincent M., 2021, MD. L. REV., V80, P487; Supsáková B, 2016, COMMUN TODAY, V7, P32; Susskind RE., 2019, Online courts and the future of justice (illustrated edition); Werth R, 2019, SOCIOL COMPASS, V13, DOI 10.1111/soc4.12659; Yaroshenko Savushkin, 2023, Scholar Notes, V3, P278	17	0	0	2	2	Cherkas Global Univ Press	Washington	1717 N Street NW, Suite 1, Washington, District of Columbia, UNITED STATES	1994-4160	1994-4195		MEDIA EDUC-RUSS	Media Educ.		2024		1					32	39		10.13187/me.2024.1.32	http://dx.doi.org/10.13187/me.2024.1.32			8	Communication	Emerging Sources Citation Index (ESCI)	Communication	MX8X2		Bronze			2024-07-03	WOS:001197037900006
J	Wagner, T; Guhl, D; Langhals, B				Wagner, Torrey; Guhl, Dennis; Langhals, Brent			The Impact of Data Preparation and Model Complexity on the Natural Language Classification of Chinese News Headlines	ALGORITHMS			English	Article						multinomial Na & iuml;ve Bayes; ensemble model; neural network; multi-class classification; large language models; BERT; data preprocessing		Given the emergence of China as a political and economic power in the 21st century, there is increased interest in analyzing Chinese news articles to better understand developing trends in China. Because of the volume of the material, automating the categorization of Chinese-language news articles by headline text or titles can be an effective way to sort the articles into categories for efficient review. A 383,000-headline dataset labeled with 15 categories from the Toutiao website was evaluated via natural language processing to predict topic categories. The influence of six data preparation variations on the predictive accuracy of four algorithms was studied. The simplest model (Na & iuml;ve Bayes) achieved 85.1% accuracy on a holdout dataset, while the most complex model (Neural Network using BERT) demonstrated 89.3% accuracy. The most useful data preparation steps were identified, and another goal examined the underlying complexity and computational costs of automating the categorization process. It was discovered the BERT model required 170x more time to train, was slower to predict by a factor of 18,600, and required 27x more disk space to save, indicating it may be the best choice for low-volume applications when the highest accuracy is needed. However, for larger-scale operations where a slight performance degradation is tolerated, the Na & iuml;ve Bayes algorithm could be the best choice. Nearly one in four records in the Toutiao dataset are duplicates, and this is the first published analysis with duplicates removed.	[Wagner, Torrey; Guhl, Dennis; Langhals, Brent] Air Force Inst Technol, Grad Sch Engn & Management, Data Analyt Certificate Program, Wright Patterson Afb, OH 45433 USA	Air Force Institute of Technology (AFIT); Air Force Institute of Technology; Air Force Institute of Technology Graduate School of Engineering & Management	Wagner, T (corresponding author), Air Force Inst Technol, Grad Sch Engn & Management, Data Analyt Certificate Program, Wright Patterson Afb, OH 45433 USA.	torrey.wagner.2@us.af.mil; brent.langhals@afit.edu						[Anonymous], 2011, IBM SPSS Modeler CRISP-DM Guide; Das M, 2021, 5 INT C COMPUTATIONA, V2870; Deb N., 2020, Int. J. Sci. Technol. Res, V9, P2469; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Di Pietro M., 2020, Toward Data SCience; Duan WY, 2021, INTERSPEECH, P3216, DOI 10.21437/Interspeech.2021-229; Github User Aceimnorstuvwxz Github User Aceimnorstuvwxz, 2018, Github Toutiao Text Classfication Dataset (Public); Google, 2022, Google Machine Learning Course Step 3: Prepare Your Data; Grandini M, 2020, Arxiv, DOI [arXiv:2008.05756, DOI 10.48550/ARXIV.2008.05756]; Gron A., 2019, Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, DOI DOI 10.1201/9780367816377; Huan H, 2020, IEEE ACCESS, V8, P199629, DOI 10.1109/ACCESS.2020.3035669; James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1; Junwei Ge, 2021, Journal of Physics: Conference Series, V1748, DOI 10.1088/1742-6596/1748/3/032036; Kung S., 2020, Chinese Natural Language (Pre)processing: An Introduction Towards Data Science; Lakshmanan V, 2020, Machine Learning Design Patterns Solutions to Common Challenges in Data Preparation, Model Building, and MLOps; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Li J., 2020, P INT C ARTIFICIAL I; Liu B, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1785, DOI 10.1145/3397271.3401248; Liu X, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11090483; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Luo X, 2022, DIGIT COMMUN NETW, V8, P942, DOI 10.1016/j.dcan.2022.09.015; Policy Planning Staff, 2020, The Elements of the China Challenge; Saul J., 2023, P WORLD C COMPUTER S; Shishupal R.S., 2021, Int. J. Adv. Res. Sci. Commun. Technol, V5, P286, DOI [10.48175/IJARSCT-1241, DOI 10.48175/IJARSCT-1241]; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Soma J., Data Science for Journalism; Sun Junyi, 2020, fxsjy/jieba; Tucker T., 2023, P WORLD C COMPUTER S; Wang S., 2021, arXiv; Widrow B., 1987, P 1 INT C NEURAL NET; Williams H.J., 2018, DEFINING 2 GENERATIO; Xia F., 2022, Acad. J. Eng. Technol. Sci, V5, P53; Xu L, 2020, Arxiv, DOI arXiv:2004.05986; Xu QQ, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3582301; Zhang A., 2023, Medium, P2; Zhang J., 2020, P 37 INT C MACHINE L; Zhang M, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1411744	37	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1999-4893		ALGORITHMS	Algorithms	APR	2024	17	4							132	10.3390/a17040132	http://dx.doi.org/10.3390/a17040132			17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	OY6L3		gold			2024-07-03	WOS:001210876400001
J	Fogleman, BM; Goldman, M; Holland, AB; Dyess, G; Patel, A				Fogleman, Brody M.; Goldman, Matthew; Holland, Alexander B.; Dyess, Garrett; Patel, Aashay			Charting Tomorrow's Healthcare: A Traditional Literature Review for an Artificial Intelligence-Driven Future	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						large language models (llms); electronic health record (ehr); electronic medical record (emr); patient care; efficiency; note writing; artificial intelligence	PATIENT COMMUNICATION; RESIDENTS SPEND; RECORDS; TIME; IMPACT; MEDICINE; IMPLEMENTATION; PERCEPTIONS; IMPROVEMENT; PHYSICIANS	Electronic health record (EHR) systems have developed over time in parallel with general advancements in mainstream technology. As artificially intelligent (AI) systems rapidly impact multiple societal sectors, it has become apparent that medicine is not immune from the influences of this powerful technology. Particularly appealing is how AI may aid in improving healthcare efficiency with note-writing automation. This literature review explores the current state of EHR technologies in healthcare, specifically focusing on possibilities for addressing EHR challenges through the automation of dictation and note-writing processes with AI integration. This review offers a broad understanding of existing capabilities and potential advancements, emphasizing innovations such as voice-to-text dictation, wearable devices, and AI-assisted procedure note dictation. The primary objective is to provide researchers with valuable insights, enabling them to generate new technologies and advancements within the healthcare landscape. By exploring the benefits, challenges, and future of AI integration, this review encourages the development of innovative solutions, with the goal of enhancing patient care and healthcare delivery efficiency.	[Fogleman, Brody M.] Edward Via Coll Osteopath Med Carolinas, Internal Med, Spartanburg, SC 29303 USA; [Goldman, Matthew] Houston Methodist Hosp, Neurol Surg, Houston, TX USA; [Holland, Alexander B.] Edward Via Coll Osteopath Med Carolinas, Gen Surg, Spartanburg, SC USA; [Dyess, Garrett] Univ S Alabama, Med, Coll Med, Mobile, AL USA; [Patel, Aashay] Univ Florida, Neurol Surg, Coll Med, Gainesville, FL USA	Houston Methodist Hospital; The Methodist Hospital - Houston; University of South Alabama; State University System of Florida; University of Florida	Fogleman, BM (corresponding author), Edward Via Coll Osteopath Med Carolinas, Internal Med, Spartanburg, SC 29303 USA.	brodyfogleman@gmail.com		Fogleman, Brody/0009-0003-9919-2769				Antun V, 2020, P NATL ACAD SCI USA, V117, P30088, DOI 10.1073/pnas.1907377117; Anyanwu Emeka C, 2021, J Grad Med Educ, V13, P103, DOI 10.4300/JGME-D-20-00642.1; Appari A, 2014, AM J MANAG CARE, V20, pESP39; Arndt BG, 2017, ANN FAM MED, V15, P419, DOI 10.1370/afm.2121; Arquilla K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041013; Issa WB, 2020, INT NURS REV, V67, P218, DOI 10.1111/inr.12585; Battles James B., 2002, Biomedical Instrumentation and Technology, V36, P84; Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; Beam KS, 2017, APPL CLIN INFORM, V8, P337, DOI 10.4338/ACI-2016-09-RA-0153; Berman Anthony C, 2016, Korean J Med Educ, V28, P243, DOI 10.3946/kjme.2016.21; Bradshaw JC, 2023, ANN EMERG MED, V81, P764, DOI 10.1016/j.annemergmed.2023.01.022; Brandt PS, 2020, LEARN HEALTH SYST, V4, DOI 10.1002/lrh2.10233; Bucher BT, 2016, J AM COLL SURGEONS, V223, pE33, DOI 10.1016/j.jamcollsurg.2016.08.088; Budd J, 2023, J PRIM CARE COMMUNIT, V14, DOI 10.1177/21501319231166921; Busnatu S, 2022, J CLIN MED, V11, DOI 10.3390/jcm11082265; Callaway EC, 2002, J DIGIT IMAGING, V15, P43, DOI 10.1007/BF03191902; Carter SM, 2020, BREAST, V49, P25, DOI 10.1016/j.breast.2019.10.001; Chao TN, 2021, J SURG EDUC, V78, P346, DOI 10.1016/j.jsurg.2020.06.039; Chekijian SA, 2018, AEM EDUC TRAIN, V2, pS48, DOI 10.1002/aet2.10207; Cline Laura, 2020, Nurs Manage, V51, P6, DOI 10.1097/01.NUMA.0000654880.27546.6a; Coiera E, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0066-9; Coit MH, 2011, J GEN INTERN MED, V26, P28, DOI 10.1007/s11606-010-1465-z; Cox Morgan L, 2018, J Surg Educ, V75, pe97, DOI 10.1016/j.jsurg.2018.10.010; Craig KJT, 2021, J AM MED INFORM ASSN, V28, P985, DOI 10.1093/jamia/ocaa301; CRUICKSHANK PJ, 1984, J ROY COLL GEN PRACT, V34, P77; Dahiya ES, 2024, SENSORS-BASEL, V24, DOI 10.3390/s24041318; DeChant Paul F, 2019, Mayo Clin Proc Innov Qual Outcomes, V3, P384, DOI 10.1016/j.mayocpiqo.2019.07.006; Derman YD, 2010, BMC MED INFORM DECIS, V10, DOI 10.1186/1472-6947-10-44; DiAngi Y T, 2016, J Fam Med, V3; Diaz-Garelli F, 2021, JCO CLIN CANCER INFO, V5, P527, DOI 10.1200/CCI.20.00174; Doherty Gerard M, 2019, Adv Surg, V53, P131, DOI 10.1016/j.yasu.2019.04.017; Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7; Eberts M, 2019, APPL CLIN INFORM, V10, P729, DOI 10.1055/s-0039-1696667; Epstein JA, 2021, J GEN INTERN MED, V36, P580, DOI 10.1007/s11606-020-06188-0; Falcetta FS, 2023, ARTIF INTELL MED, V137, DOI 10.1016/j.artmed.2023.102487; Fang M, 2017, BMC MED EDUC, V17, DOI 10.1186/s12909-017-0874-7; Fragidis LL, 2016, TECHNOL HEALTH CARE, V24, P827, DOI 10.3233/THC-161231; Friedberg MW., 2013, Factors Affecting Physician Professional Satisfaction and Their Implications for Patient Care, Health Systems, and Health Policy; Gamal A, 2021, J BIOMED INFORM, V117, DOI 10.1016/j.jbi.2021.103770; Gao KP, 2020, IEEE SENS J, V20, P10393, DOI 10.1109/JSEN.2020.2987969; Gidwani R, 2017, ANN FAM MED, V15, P427, DOI 10.1370/afm.2122; Green K, 2017, DePaul J Health Care Law, V19; Gretton C, 2018, HUM-COMPUT INT-SPRIN, P279, DOI 10.1007/978-3-319-90403-0_14; Grote T, 2020, J MED ETHICS, V46, P205, DOI 10.1136/medethics-2019-105586; Hashimoto DA, 2018, ANN SURG, V268, P70, DOI 10.1097/SLA.0000000000002693; He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0; Hesselink G, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2022-062939; Hobensack M, 2022, APPL CLIN INFORM, V13, P439, DOI 10.1055/s-0042-1746169; Holst H, 2000, EUR J NUCL MED, V27, P300, DOI 10.1007/s002590050522; Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312; Huang EY, 2022, The SAGES Manual of Quality, Outcomes and Patient Safety, P407, DOI [10.1007/978-3-030-94610-4_21, DOI 10.1007/978-3-030-94610-4_21]; Hughes JW, 2021, JAMA CARDIOL, V6, P1285, DOI 10.1001/jamacardio.2021.2746; Hulsen T, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17093046; Jalal-Karim A, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P149, DOI 10.1109/INMIC.2008.4777726; Johnson M, 2014, BMC MED INFORM DECIS, V14, DOI 10.1186/1472-6947-14-94; Joukes E, 2018, APPL CLIN INFORM, V9, DOI 10.1055/s-0037-1615747; Kaufman DR, 2016, JMIR MED INF, V4, P21, DOI 10.2196/medinform.5544; King J, 2014, HEALTH SERV RES, V49, P392, DOI 10.1111/1475-6773.12135; Koivikko MP, 2008, J DIGIT IMAGING, V21, P378, DOI 10.1007/s10278-008-9121-4; Kokkonen EWJ, 2013, J AM MED INFORM ASSN, V20, pE33, DOI 10.1136/amiajnl-2012-001609; Komal K, 2024, EPILEPSY RES, V201, DOI 10.1016/j.eplepsyres.2024.107334; Kreeftenberg Herman G, 2020, Crit Care Explor, V2, pe0101, DOI 10.1097/CCE.0000000000000101; Kwekkeboom K L, 1997, Oncol Nurs Forum, V24, P1393; Larson DB, 2021, J AM COLL RADIOL, V18, P413, DOI [10.1016/j.jacr.2020.09.060, 10.1016/j.jacr.2020.09.060413]; Lindsell CJ, 2020, JAMA-J AM MED ASSOC, V323, P2141, DOI 10.1001/jama.2020.5035; Luh JY, 2019, J AM COLL RADIOL, V16, P1343, DOI 10.1016/j.jacr.2019.05.044; Mamykina L, 2016, ACAD MED, V91, P827, DOI 10.1097/ACM.0000000000001148; Markus AF, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103655; Marmor RA, 2018, APPL CLIN INFORM, V9, P11, DOI 10.1055/s-0037-1620263; Masud JHB, 2022, J PERS MED, V12, DOI 10.3390/jpm12050707; Mazer L, 2022, SURG ENDOSC, V36, P1090, DOI 10.1007/s00464-021-08375-4; Mazur LM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1709; McMahon GT, 2010, NEW ENGL J MED, V362, P1304, DOI 10.1056/NEJMsa0908136; McQueen S, 2019, J SURG EDUC, V76, P1645, DOI 10.1016/j.jsurg.2019.05.013; Miksanek TJ, 2021, ANN INTERN MED, V174, P1, DOI 10.7326/M20-0428; Moore GE., 1965, Electronics, V38, P8, DOI [DOI 10.1109/N-SSC.2006.4785860, DOI 10.1109/JPROC.1998.658762]; Naguib RN, 2001, Artificial neural networks in cancer diagnosis, prognosis, and patient management, DOI [10.1201/9781420036381, DOI 10.1201/9781420036381]; Neri L, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23104805; Nuckols TK, 2009, NEW ENGL J MED, V360, P2202, DOI 10.1056/NEJMsa0810251; Ong LML, 2000, PATIENT EDUC COUNS, V41, P145, DOI 10.1016/S0738-3991(99)00108-1; Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886; Phillips SP, 2022, CAN FAM PHYSICIAN, V68, P570, DOI 10.46747/cfp.6808570; Pinevich Y, 2021, APPL CLIN INFORM, V12, P788, DOI 10.1055/s-0041-1733909; Poissant L, 2005, J AM MED INFORM ASSN, V12, P505, DOI 10.1197/jamia.M1700; Prigoff JG, 2016, ANN SURG, V264, P34, DOI 10.1097/SLA.0000000000001652; Quiroz JC, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0190-1; Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1; Reick-Mitrisin V, 2020, J ALLERGY CLIN IMMUN, V145, P479, DOI 10.1016/j.jaci.2019.12.900; Reith TP, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.3681; Roy S, 2021, EBIOMEDICINE, V66, DOI 10.1016/j.ebiom.2021.103275; Rudin RS, 2020, ANN INTERN MED, V172, pS130, DOI 10.7326/M19-0878; Salna Michael, 2022, J Chest Surg, V55, P429; Sanderson AL, 2020, CRIT CARE MED, V48, P579, DOI 10.1097/CCM.0000000000004200; Sattler A, 2018, J AM BOARD FAM MED, V31, P49, DOI 10.3122/jabfm.2018.01.170314; Shaarani I, 2017, INT J MED INFORM, V108, P152, DOI 10.1016/j.ijmedinf.2017.10.007; Shah NA, 2020, ANN SURG, V271, P431, DOI 10.1097/SLA.0000000000003510; Shanafelt TD, 2019, MAYO CLIN PROC, V94, P1681, DOI 10.1016/j.mayocp.2018.10.023; Shu K, 2001, ST HEAL T, V84, P1207; Siegler James E, 2015, J Grad Med Educ, V7, P16, DOI 10.4300/JGME-D-14-00494.1; Silas MR, 2015, J SURG RES, V197, P272, DOI 10.1016/j.jss.2015.03.097; Silverman J, 2010, BRIT J GEN PRACT, V60, P76, DOI 10.3399/bjgp10X482293; Singh M, 2011, ARCH PATHOL LAB MED, V135, P1476, DOI 10.5858/arpa.2010-0714-OA; Soman Sumit, 2020, CSI Transactions on ICT, V8, P355, DOI 10.1007/s40012-020-00301-8; Street RL, 2009, PATIENT EDUC COUNS, V74, P295, DOI 10.1016/j.pec.2008.11.015; Sun H, 2015, J BIOMED INFORM, V58, P247, DOI 10.1016/j.jbi.2015.10.009; Toth R, 2020, IEEE SYS MAN CYBERN, P3433, DOI [10.1109/smc42975.2020.9283187, 10.1109/SMC42975.2020.9283187]; van Dalen ASHM, 2019, BRIT J SURG, V106, P1433, DOI 10.1002/bjs.11198; Victores AJ, 2015, LARYNGOSCOPE, V125, P594, DOI 10.1002/lary.24848; Wang C, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/3293457; Wang XQ, 2020, J AM COLL RADIOL, V17, P796, DOI 10.1016/j.jacr.2020.01.006; Wani D, 2018, J OPER MANAG, V60, P1, DOI 10.1016/j.jom.2018.06.003; Watson MD, 2020, J SURG EDUC, V77, pE237, DOI 10.1016/j.jsurg.2020.06.017; Weze Clare, 2004, Eur J Oncol Nurs, V8, P40, DOI 10.1016/j.ejon.2003.10.004; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; Zhou DD, 2022, J BIOMED INFORM, V133, DOI 10.1016/j.jbi.2022.104147; Zhou MH, 2012, SAGES MANNUAL OF QUALITY, OUTCOMES AND PATIENT SAFETY, P547, DOI 10.1007/978-1-4419-7901-8_56	116	0	0	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	APR 11	2024	16	4							e58032	10.7759/cureus.58032	http://dx.doi.org/10.7759/cureus.58032			12	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	OT4T1	38738104	gold, Green Accepted			2024-07-03	WOS:001209524400040
J	Evkoski, B; Novak, PK; Ljubesic, N				Evkoski, Bojan; Novak, Petra Kralj; Ljubesic, Nikola			Content-based comparison of communities in social networks: Ex-Yugoslavian reactions to the Russian invasion of Ukraine	APPLIED NETWORK SCIENCE			English	Article						Social network analysis; Community detection; Community comparison; Topology versus content; Large language models; Russian invasion of Ukraine; Ex-Yugoslavia		We discuss the added value of various approaches for identifying similarities in social network communities based on the content they produce. We show the limitations of observing communities using topology-only and illustrate the benefits and complementarity of including supplementary data when analyzing social networks. As a case study, we analyze the reactions of the Ex-Yugoslavian retweet communities to the Russian invasion of Ukraine, comparing topological inter-community interaction with their content-based similarity (hashtags, news sources, topics and sentiment). The findings indicate that despite the Ex-Yugoslavian countries having a common macro-language, their retweet communities exhibit diverse responses to the invasion. Certain communities exhibit a notable level of content-based similarity, although their topological similarity remains relatively low. On the other hand, there are communities that display high similarity in specific types of content, but demonstrate less similarity when considering other aspects. For example, we identify a strong echo-chamber community linked to the Serbian government that deliberately avoids the invasion topic, despite showing news source similarities with other communities highly active on the subject. In summary, our study highlights the importance of employing multifaceted approaches to analyzing community similarities, as they enable a more comprehensive understanding of social media discourse. This approach extends beyond the confines of our specific case study, presenting opportunities to gain valuable insights into complex social events across various contexts.	[Evkoski, Bojan] Inst Contemporary Hist, Ljubljana, Slovenia; [Novak, Petra Kralj; Ljubesic, Nikola] Jozef Stefan Insitute, Dept Knowledge Technol, Ljubljana, Slovenia; [Novak, Petra Kralj] Cent European Univ, Dept Network & Data Sci, Vienna, Austria; [Ljubesic, Nikola] Univ Ljubljana, Fac Informat & Commun Sci, Ljubljana, Slovenia	University of Ljubljana	Evkoski, B (corresponding author), Inst Contemporary Hist, Ljubljana, Slovenia.	bojanevkoski@outlook.com			Slovenian Research Agency; Slovenian Research Agency within the Slovenian-Flemish bilateral basic research project "Linguistic landscape of hate speech on social media" [FWO-G070619N]; programme "Language resources and technologies for Slovene" [P6-0411]	Slovenian Research Agency(Slovenian Research Agency - Slovenia); Slovenian Research Agency within the Slovenian-Flemish bilateral basic research project "Linguistic landscape of hate speech on social media"; programme "Language resources and technologies for Slovene"	BE received funding from the Slovenian Research Agency research programme, research infrastructure P6-0436: Digital Humanities: resources, tools, and methods (2022-2027). NL received funding from the Slovenian Research Agency within the Slovenian-Flemish bilateral basic research project "Linguistic landscape of hate speech on social media" (N06-0099 and FWO-G070619N, 2019-2023) and the research programme "Language resources and technologies for Slovene" (P6-0411).	Amaral LAN, 2004, EUR PHYS J B, V38, P147, DOI 10.1140/epjb/e2004-00110-5; Banac I, 2009, E EUR POLIT SOC, V23, P461, DOI 10.1177/0888325409346821; Bisgin H., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P533, DOI 10.1109/WI-IAT.2010.61; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Chang HC, 2012, LIBR TRENDS, V61, P248, DOI 10.1353/lib.2012.0024; Cherepnalkoski Darko, 2016, Appl Netw Sci, V1, P2, DOI 10.1007/s41109-016-0001-4; Cinelli M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2023301118; Cordeiro M, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0325-1; Dakiche N, 2019, INFORM PROCESS MANAG, V56, P1084, DOI 10.1016/j.ipm.2018.03.005; Ding Y, 2011, J INFORMETR, V5, P498, DOI 10.1016/j.joi.2011.02.006; Djordjevic J., 2020, DIGITALNE MEDIJSKE T, V9, P87; Durazzi F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99301-0; Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506; Evkoski B, 2022, THESIS, DOI [10.13140/RG.2.2.21595.64806, DOI 10.13140/RG.2.2.21595.64806]; Evkoski B, 2021, APPL NETW SCI, V6, DOI 10.1007/s41109-021-00439-7; Evkoski B, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256175; Ezugwu AE, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104743; Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Gleich DF, 2015, SIAM REV, V57, P321, DOI 10.1137/140976649; Grcar Miha, 2017, Comput Soc Netw, V4, P6, DOI 10.1186/s40649-017-0042-6; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Jia WK, 2022, COMPLEX INTELL SYST, V8, P2663, DOI 10.1007/s40747-021-00637-x; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lancichinetti A, 2012, SCI REP-UK, V2, DOI 10.1038/srep00336; Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.056117; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Lin T., 2022, OPEN; Ljubesic N., 2021, P 8 WORKSHOP BALTO S, P37; Ljubesic N, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2279; Malin Bradley., 2005, SIAM INT C DATA MINI, P93; Mazzucchelli F, 2012, SOC SCI INFORM, V51, P631, DOI 10.1177/0539018412456781; Metaxas PT., 2015, P INT AAAI C WEB SOC, V9, P658, DOI DOI 10.1609/ICWSM.V9I1.14661; Mochtak M, 2022, SENTIMENT CORPUS PAR; Mochtak M, 2022, ARXIV; Morini V, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125390; Muchnik L, 2013, SCI REP-UK, V3, DOI 10.1038/srep01783; Newman MEJ, 2004, EUR PHYS J B, V38, P321, DOI 10.1140/epjb/e2004-00124-y; Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480; Novak Petra Kralj, 2018, Appl Netw Sci, V3, P40, DOI 10.1007/s41109-018-0097-9; Oliveira M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0208-2; Papic Zarana, 1994, WOMENS HIST REV, V3, P115, DOI DOI 10.1080/09612029400200048; Poulin V, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0162-z; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rossetti G, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3172867; Spertus E., 2005, Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, P678, DOI DOI 10.1145/1081870.1081956; Srivastava Aarohi, 2022, arXiv; Strogatz SH, 2001, NATURE, V410, P268, DOI 10.1038/35065725; Surian D, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6045; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wang A, 2019, ADV NEUR IN, V32; Webber W, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852106; Wei Weng, 2014, Journal of Digital Information Management, V12, P274; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wong Felix., 2013, ICWSM, V13, P640	55	0	0	1	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2364-8228		APPL NETW SCI	Appl. Netw. Sci.	JUN 28	2023	8	1							40	10.1007/s41109-023-00561-8	http://dx.doi.org/10.1007/s41109-023-00561-8			24	Computer Science, Theory & Methods; Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Computer Science; Science & Technology - Other Topics	L1JI3		Green Submitted, gold, Green Published			2024-07-03	WOS:001020884200001
J	Chun, J; Elkins, K				Chun, Jon; Elkins, Katherine			THE CRISIS OF ARTIFICIAL INTELLIGENCE: A NEW DIGITAL HUMANITIES CURRICULUM FOR HUMAN-CENTRED AI	INTERNATIONAL JOURNAL OF HUMANITIES AND ARTS COMPUTING-A JOURNAL OF DIGITAL HUMANITIES			English	Article						digital humanities; artificial intelligence; large language models; generative AI; AI alignment; AI safety; AI curriculum; AI ethics; computational digital humanities		This article outlines what a successful artificial intelligence digital humanities (AI DH) curriculum entails and why it is so critical now. Artificial intelligence is rapidly reshaping our world and is poised to exacerbate long-standing crises including (1) the crisis of higher education and the humanities, (2) the lack of diversity, equity and inclusion (DEI) in computer science and technology fields and (3) the wider social and economic crises facilitated by new technologies. We outline a number of ways in which an AI DH curriculum offers concrete and impactful responses to these many crises. AI DH yields meaningful new avenues of research for the humanities and the humanistic social sciences, and offers new ways that higher education can better prepare students for the world into which they graduate. DEI metrics show how an AI DH curriculum can engage students traditionally underserved by conventional STEM courses. Finally, AI DH educates all students for civic engagement in order to address both the social and economic impacts of emerging AI technologies. This article provides an overview of an AI DH curriculum, the motivating theory behind design decisions, and a detailed look into two sample courses.	[Chun, Jon] Kenyon Coll, Humanities, Gambier, OH 43022 USA; [Chun, Jon] Kenyon DH Lab, Gambier, OH 43022 USA; [Chun, Jon] Symantec, Dev, Tempe, AZ 85281 USA; [Elkins, Katherine] Kenyon, Human & Comparat Literature, Gambier, OH USA	University System of Ohio; Kenyon College; Symantec	Chun, J (corresponding author), Kenyon Coll, Humanities, Gambier, OH 43022 USA.; Chun, J (corresponding author), Kenyon DH Lab, Gambier, OH 43022 USA.; Chun, J (corresponding author), Symantec, Dev, Tempe, AZ 85281 USA.			Elkins, Katherine/0000-0001-9887-4854				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adams A., 2019, Stanford News18 March; [Anonymous], 2017, Quartz; [Anonymous], 2022, AI Impacts3 August; [Anonymous], 2023, TurnItIn.com13 February; [Anonymous], 2018, CMU started its undergraduate AI degree. In 2021 Oregon State University started an interdisciplinary MS/PhD. In 2021 the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) accepted its first students. These are all STEM-based and not humanities-focused; [Anonymous], 2023, Thomasreuters.com23 February; [Anonymous], 2018, Twitter; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Berk R. A, 2021, Annual Review of Criminology, V4, DOI [10.1146/annurevcriminol-051520-012342, DOI 10.1146/ANNUREVCRIMINOL-051520-012342]; BlueWeave Consulting, 2023, GlobalNewsWire.com15 March; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Brown N, 2018, SCIENCE, V359, P418, DOI 10.1126/science.aao1733; Case JN., 2017, The evolution of trust; Case K., 2020, GPT-2 AI poetry generation: Writing like Donne, Kenyon Digital Humanities; Christian Brian, 2021, ALIGNMENT PROBLEM MA; Chun J., 2023, Programming humanity; Chun J., 2023, Digital humanities at Kenyon; Chun J, 2021, Arxiv, DOI arXiv:2110.09454; Colby College, 2021, Colby News29 January; Connor J., 2023, Tweaktown.com8 May; Copilot, Your AI pair programmer Copilot; DAgostino S., 2023, Insider Higher Ed19 May; Datta T, 2023, Arxiv, DOI [arXiv:2303.06223, 10.48550/arXiv.2303.06223, DOI 10.48550/ARXIV.2303.06223]; Dayma B., 2022, wandb.ai4 July; De Silva C., 2022, How Did Sri Lankan protestors end up in the president's pool? Understanding the evolution of an occupy -style protest: A story of economic turmoil, declining social sentiment and resulting political change'; Edwards B., 2022, Arstechnica.com25 October; Elkins K, 2022, The shapes of stories: Sentiment analysis for narrative; Elkins K., 2020, Journal of Cultural Analytics; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Engler A., 2023, Brookings Institute25 April; Epstein R, 2015, P NATL ACAD SCI USA, V112, pE4512, DOI 10.1073/pnas.1419828112; Escalante-De Mattei S., 2023, ArtNews.com5 May; European Commission, 2023, EUR APPR ART INT; Ford B., 2023, Bloomberg.com1 May; Future of Life Institute, 2023, FutureofLie22 March; Gill I., 2020, WHOEVER LEADS ARTIFI; Gimbel B., 2022, Quantifying polarization around election denial: Measuring public sentiment changes in the 2022 midterms'; github.com, These statistics are based upon web analytics of our digital humanities research archive hosted by bepress.com; Goldenberg A, 2023, NAT HUM BEHAV, V7, P845, DOI 10.1038/s41562-023-01604-x; Goldin C. D., 2007, Labor: Human Capital eJournal; Google, 2023, PALM 2 TECHN REP; Gow A., 2021, Blood in the water: Storytelling and sentiment analysis in ABC's Shark Tank'; Grant D., 2023, TheArtNewspaper15 February; Gunderson K., 1975, MINNESOTA STUDIES PH, P131, DOI DOI 10.1017/CBO9780511625251.014; Harari Y. N., 2018, 21 Lessons for the 21st Century; Hartikainen M, 2022, NORD HUM COMP INT C, P1; Hatzius J., 2023, Goldman Sachs Economic Research26 March; Heller N., 2023, The New Yorker; Henshall W., 2023, TheBulletin.org12 May; Hulick K., 2023, ScienceNews.org12 April; Institute of Education Sciences and National Center for Education Statistics (IES-NCES), Tables 322.40 and 322.50-Bachelor's degrees conferred to females and males by postsecondary institutions, by race/ethnicity and field of study (2020-2021)'; Johnson S., 2022, BigThink13 June; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kanter D., Meditations in an emergency: A regional analysis of the relationship between union membership and minimum wage in an age of labor decline'; Kantor J., 2013, The New York Times7 September; Karger G., 2023, Columbia Science & Technology Law Review25 January; Kenyon College, 2023, Digital Kenyon: Digital Humanities Archive; Khan FA, 2023, Arxiv, DOI arXiv:2302.08704; Kinsella E., 2018, Artnet.com25 October; Kissinger H., 2023, WALL STR J; Köchling A, 2021, BUS INFORM SYST ENG+, V63, P39, DOI 10.1007/s12599-020-00673-w; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Lai Yuhang, 2022, arXiv; Liu ML, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19095164; Lowrey A., 2023, The Atlantic Monthly20 January; Marche S., 2022, The Atlantic Monthly6 December; McKinsey & Company, 2022, McKinsey.com17 August; Melonio Priya, 2020, TikTok's non-inclusive beauty algorithm and why we should care'; Merchant B., 2023, The Los Angeles Times11 May; MetaAI, 2022, Facebook Blog; Metz C., 2023, New York Times; Mollman S., 2023, Fortune; Morrissey E., 2019, Topic modeling analysis of Supreme Court opinions focusing on privacy rights in the context of abortion law'; NetworkX Developers, 2023, Networkx.com; Noorily J., 2022, AI reads Playboy (but not for the articles): Revealing cover trends with deep neural networks'; Olejarz J. M., 2017, Harvard Business ReviewJuly-August; OpenAI, 2023, : GPT-4 technical report.; Osnos E., 2021, The New Yorker15 November; PaperWithCode, 2023, Browse state-of-the-art models; Peng Sida, 2023, arXiv, DOI DOI 10.48550/ARXIV.2302.06590; Pfeiffer F., 2022, Black box Karl Marx: What do large language models have to say about Das Kapital? A comparison of GPT-2 and GPT-3 outputs'; Prakash P., 2023, FORTUNE         0417; programminghumanity.wordpress.com, About us; Ramesh A., 2022, arXiv; Ray T., 2022, ZDNet1 December; Reagan AJ, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0093-1; Reddy G. Divakara, 2022, 2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA), P1165, DOI 10.1109/ICIRCA54612.2022.9985674; Roose Kevin, 2022, New York Times; Rosenfeld R., 2022, The second meaning: Uncovering the linguistic interpretation of Simone de Beauvoir's The Second Sex'; Rotman D., 2022, MIT TECHNOL REV; Ryo M, 2022, SSRN Electronic Journal, DOI [10.13140/RG.2.2.19044.24967, DOI 10.13140/RG.2.2.19044.24967]; Sanger DE., 2023, The New York Times; Santariano A., 2023, The New York Times5 March; Schmidt B., 2018, The Atlantic Monthly23 August; Sevillano E. G., 2023, El Pais21 April; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Study.com, 2023, Productive teaching tool or innovative cheating?; Sutton R, 2017, The Bitter Lesson (blog); Thompson N., 2018, Wired4 October; Toner H., 2023, A DigiChina forum19 April; Turner D., 2022, When AI meet screenwriting: Can AI generate beat sheets and storyboards?'; University of Florida, 2023, Building an AI university; University of Oxford, 2018, Oxford and AI; Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619; Whang O., 2023, The New York Times1 May; Yang X., 2022, Journal of Economic Behavior & Organization, V196, P207; Yao Y., 2022, The Crimson3 March; Ziatdinov R., 2023, Korea Times8 May	109	0	0	35	44	EDINBURGH UNIV PRESS	EDINBURGH	THE TUN-HOLYROOD RD, 12 2F JACKSONS ENTRY, EDINBURGH EH8 8PJ, SCOTLAND	1753-8548	1755-1706		INT J HUMANIT ARTS C	Int. J. Humanit. Arts Comput.	OCT	2023	17	2			SI		147	167		10.3366/ijhac.2023.0310	http://dx.doi.org/10.3366/ijhac.2023.0310			21	Humanities, Multidisciplinary; Computer Science, Interdisciplinary Applications	Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; Computer Science	U8DG0					2024-07-03	WOS:001087046600008
J	Ayoub, M; Ballout, AA; Zayek, RA; Ayoub, NF				Ayoub, Marc; Ballout, Ahmad A.; Zayek, Rosana A.; Ayoub, Noel F.			Mind	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						large language model; generative artificial intelligence; triage; clinical decision support system; artificial intelligence in healthcare; chatgpt		Background Generative artificial intelligence (AI) has integrated into various industries as it has demonstrated enormous potential in automating elaborate processes and enhancing complex decision-making. The ability of these chatbots to critically triage, diagnose, and manage complex medical conditions, remains unknown and requires further research.Objective This cross-sectional study sought to quantitatively analyze the appropriateness of ChatGPT (OpenAI, San Francisco, CA, US) in its ability to triage, synthesize differential diagnoses, and generate treatment plans for nine diverse but common clinical scenarios.Methods Various common clinical scenarios were developed. Each was input into ChatGPT, and the chatbot was asked to develop diagnostic and treatment plans. Five practicing physicians independently scored ChatGPT's responses to the clinical scenarios.Results The average overall score for the triage ranking was 4.2 (SD 0.7). The lowest overall score was for the completeness of the differential diagnosis at 4.1 (0.5). The highest overall scores were seen with the accuracy of the differential diagnosis, initial treatment plan, and overall usefulness of the response (all with an average score of 4.4). Variance among physician scores ranged from 0.24 for accuracy of the differential diagnosis to 0.49 for appropriateness of triage ranking.Discussion ChatGPT has the potential to augment clinical decision-making. More extensive research, however, is needed to ensure accuracy and appropriate recommendations are provided.	[Ayoub, Marc] Northshore Univ Hosp, Neurocrit Care, Northwell, Manhasset, NY USA; [Ayoub, Marc] Elmhurst Hosp Ctr, Mt Sinai Sch Med, Internal Med, New York, NY USA; [Ballout, Ahmad A.] Donald & Barbara Zucker Sch Med Hofstra Northwell, Neurol, Long Isl City, NY USA; [Zayek, Rosana A.] Torrance Mem Med Ctr, Internal Med, Torrance, CA USA; [Ayoub, Noel F.] Stanford Hlth Care, Otolaryngol Head & Neck Surg, Palo Alto, CA 94305 USA	Icahn School of Medicine at Mount Sinai; Northwell Health; Stanford University	Ayoub, NF (corresponding author), Stanford Hlth Care, Otolaryngol Head & Neck Surg, Palo Alto, CA 94305 USA.	noelayoub@gmail.com						[Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Makary MA, 2016, BMJ-BRIT MED J, V353, DOI 10.1136/bmj.i2139; Murray NM, 2020, J NEUROINTERV SURG, V12, P156, DOI 10.1136/neurintsurg-2019-015135; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044	9	2	2	5	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 18	2023	15	8							e43690	10.7759/cureus.43690	http://dx.doi.org/10.7759/cureus.43690			4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	R5SG9	37724211	gold, Green Published			2024-07-03	WOS:001064944100009
J	Cankurtaran, RE; Polat, YH; Aydemir, NG; Umay, E; Yurekli, OT				Cankurtaran, Rasim Eren; Polat, Yunus Halil; Aydemir, Neslihan Gunes; Umay, Ebru; Yurekli, Oyku Tayfur			Reliability and Usefulness of ChatGPT for Inflammatory Bowel Diseases: An Analysis for Patients and Healthcare Professionals	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						ulcerative colitis (uc); crohn's disease (cd); healthcare research; artificial intelligence (ai); inflammatory; bowel diseases (ibd); large language model; chatgpt		Aim: We aimed to evaluate the performance of Chat Generative Pre-trained Transformer (ChatGPT) within the context of inflammatory bowel disease (IBD), which is expected to become an increasingly significant health issue in the future. In addition, the objective of the study was to assess whether ChatGPT serves as a reliable and useful resource for both patients and healthcare professionals.Methods: For this study, 20 specific questions were identified for the two main components of IBD, which are Crohn's disease (CD) and ulcerative colitis (UC). The questions were divided into two sets: one set contained questions directed at healthcare professionals while the second set contained questions directed toward patients. The responses were evaluated with seven-point Likert-type reliability and usefulness scales.Results: The distribution of the reliability and utility scores was calculated into four groups (two diseases and two question sources) by averaging the mean scores from both raters. The highest scores in both reliability and usefulness were obtained from professional sources (5.00 +/- 1.21 and 5.15 +/- 1.08, respectively). The ranking in terms of reliability and usefulness, respectively, was as follows: CD questions (4.70 +/- 1.26 and 4.75 +/- 1.06) and UC questions (4.40 +/- 1.21 and 4.55 +/- 1.31). The reliability scores of the answers for the professionals were significantly higher than those for the patients (both raters, p=0.032).Conclusion: Despite its capacity for reliability and usefulness in the context of IBD, ChatGPT still has some limitations and deficiencies. The correction of ChatGPT's deficiencies and its enhancement by developers with more detailed and up-to-date information could make it a significant source of information for both patients and medical professionals.	[Cankurtaran, Rasim Eren] Ankara Etlik City Hosp, Dept Perinatol, Ankara, Turkiye; [Polat, Yunus Halil] Ankara Numune Training & Res Hosp, Dept Gastroenterol, Ankara, Turkiye; [Aydemir, Neslihan Gunes] Akdeniz Univ, Fac Med, Dept Gastroenterol, Antalya, Turkiye; [Umay, Ebru] Univ Hlth Sci, Ankara Etlik City Hosp, Phys Med & Rehabil, Ankara, Turkiye; [Yurekli, Oyku Tayfur] Ankara Yildirim Beyazit Univ, Fac Med, Dept Gastroenterol, Ankara, Turkiye	Ankara Numune Training & Research Hospital; Akdeniz University; University of Health Sciences Turkey; Ankara Yildirim Beyazit University	Cankurtaran, RE (corresponding author), Ankara Etlik City Hosp, Dept Perinatol, Ankara, Turkiye.	drcankurtaran88@gmail.com						Ferdush J, 2024, ANN BIOMED ENG, V52, P1119, DOI 10.1007/s10439-023-03329-4; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Kao YS, 2024, ANN BIOMED ENG, V52, P455, DOI 10.1007/s10439-023-03308-9; Kleebayoon A, 2024, GASTROENTEROLOGY, V166, P219, DOI 10.1053/j.gastro.2023.05.012; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lamb CA, 2019, GUT, V68, pS1, DOI 10.1136/gutjnl-2019-318484; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; Ng SC, 2017, LANCET, V390, P2769, DOI 10.1016/S0140-6736(17)32448-0; Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749	13	4	4	5	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	OCT 9	2023	15	10							e46736	10.7759/cureus.46736	http://dx.doi.org/10.7759/cureus.46736			21	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	X2SN5	38022227	gold, Green Published, Green Submitted			2024-07-03	WOS:001097006600039
C	Fischer, JE			ACM	Fischer, Joel E.			Generative AI Considered Harmful	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023			English	Proceedings Paper	5th International Conference on Conversational User Interfaces (CUI)	JUL 19-21, 2023	Eindhoven Univ Technol, Eindhoven, NETHERLANDS	Assoc Comp Machinery, ACM SIGCHI, Bold Insight UK, Eindhoven Univ Technol, Eindhoven AI Syst Inst, HMD Res	Eindhoven Univ Technol	Large Language Models; LLM; GPT-3; GPT-4; ChatGPT; generative AI; text generation; natural language; NLP; NLG		The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs-harmful and otherwise-are produced, by whom, to what end, and with what consequences on societies.	[Fischer, Joel E.] Univ Nottingham, Mixed Real Lab, Sch Comp Sci, Nottingham, England	University of Nottingham	Fischer, JE (corresponding author), Univ Nottingham, Mixed Real Lab, Sch Comp Sci, Nottingham, England.	joel.fischer@nottingham.ac.uk		Fischer, Joel Ewert/0000-0001-8878-2454	Engineering and Physical Sciences Research Council [EP/V00784X/1]	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the Engineering and Physical Sciences Research Council [grant number EP/V00784X/1].	Arsht Andrew, 2018, Harvard Journal of Law and Technology, V2018; Bansal Gagan, 2022, WORKSH TRUST REL AI, DOI [10.1145/3491101.3503704, DOI 10.1145/3491101.3503704]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bolukbasi T, 2016, ADV NEUR IN, V29; Brown B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P416, DOI 10.1145/3025453.3025462; Brown Barry., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1031, DOI [10.1145/2470654.2466132, DOI 10.1145/2470654.2466132]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crabtree A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P879; Crawford K., 2018, ANATOMY AI SYSTEM AM; Dubiel M, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544518; Edwards J, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342809; Fischer JE, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342788; Irani L., 2016, XRDS, V23, P34, DOI [10.1145/3014390, DOI 10.1145/3014390]; Irani L. C., 2013, P SIGCHI C HUM FACT, P611, DOI DOI 10.1145/2470654.2470742; Jaber R, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3543833; Lee Minha, 2020, P 2 C CONVERSATIONAL, DOI 10.1145/3405755.3406124; Norman D. A., 2005, Interactions, V12, P14, DOI 10.1145/1070960.1070976; Porcheron Martin, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432942; Porcheron M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174214; Reeves S, 2019, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES (CUI 2019), DOI 10.1145/3342775.3342796; Wu YH, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3543839	21	0	0	25	25	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0014-9				2023									7	10.1145/3571884.3603756	http://dx.doi.org/10.1145/3571884.3603756			5	Computer Science, Cybernetics; Psychology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Psychology	BW2OK		Green Accepted			2024-07-03	WOS:001122710800007
J	García-Herrero, A; Krystyanczuk, M				Garcia-Herrero, Alicia; Krystyanczuk, Michal			How Does China Conduct Industrial Policy: Analyzing Words Versus Deeds	JOURNAL OF INDUSTRY COMPETITION & TRADE			English	Article						Industrial policy; China; Large-language models (LLM); L5; L52		This paper analyzes how China's industrial policy works focusing on the setting of objectives ("words") and their implementation ("deeds"). In particular, we investigate how objectives vary across central and local Five-Year Plans (FYPs), in terms of industry preferences, and also compare such objectives with those included in China's landmark industrial policy, "Made in China 2025." Notwithstanding China's centralization of policy planning, we find relevant sectoral differences between central and provincial planning and key industrial policy documents. Secondly, we look at how decisions are made in the realm of China's industrial policy ("deeds"). To this end, we assess empirically why certain companies are selected under the most recent grand industrial policy strategy, the 10,000 Little Giants, a spin-off of "Made in China 2025." Out of the key four criteria of selection (i.e., "words"), one is missed in most cases, namely the concentration of the business activity in the relevant sector. Secondly, the intensity of R&D is only significant in the most recent batches of selected companies. For the last two (revenue generation and leverage), there is no noticeable difference between the selected companies and the others. Our results point to the complexities in conducting industrial policy in China as words and deeds do not necessarily align.	[Garcia-Herrero, Alicia] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Garcia-Herrero, Alicia; Krystyanczuk, Michal] Bruegel, Brussels, Belgium	Hong Kong University of Science & Technology	García-Herrero, A (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.; García-Herrero, A (corresponding author), Bruegel, Brussels, Belgium.	Alicia.garcia-Herrero@bruegel.org; michal.krystyanczuk@bruegel.org			Hong Kong University of Science and Technology	Hong Kong University of Science and Technology	The authors would like to thank Robin Schindowki, research assistant at Breugel, for his contribution to this paper and Alessia Amighini and Jianwei Xu, both non-resident fellow at Bruegel for the comments offered.	Brandt L, 2017, AM ECON REV, V107, P2784, DOI 10.1257/aer.20121266; Branstetter LG, 2022, NBER Working Papers, V30676; Brown A, 2023, MERICS Report; Chen DH, 2017, CHINA J ACCOUNT RES, V10, P189, DOI 10.1016/j.cjar.2017.06.001; Colonnelli E, 2023, Investing with the government: a field experiment in China; DiPippo G., 2022, RED INK ESTIMATING C; Heilmann S, 2018, Red Swan: how unorthodox policy-making facilitated China's rise, DOI [10.2307/j.ctv2n7q6b, DOI 10.2307/J.CTV2N7Q6B]; Kajitani K, 2022, Discussion papers, V22110; Leszczensky L, 2022, SOCIOL METHOD RES, V51, P837, DOI 10.1177/0049124119882473; Li J, 2022, Government as an equity investor. Evidence from Chinese government venture capitalthrough Cycles; Li M, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e19091; Ling C, 2016, RES POLICY, V45, P2138, DOI 10.1016/j.respol.2016.09.014; Luong N., 2021, UNDERSTANDING CHINES; Naughton Barry., 2021, The Rise of China's Industrial Policy: 1978 to 2020; Rodrik D., 2004, IND POLICY 21 CENTUR; Tan Y, 2021, Cornell Studies in Political Economy; Wei YF, 2023, CHINA QUART, V256, P939, DOI 10.1017/S0305741023000280; Wu YY, 2019, CHINA ECON REV, V53, P225, DOI 10.1016/j.chieco.2018.09.010	18	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1566-1679	1573-7012		J IND COMPET TRADE	J. Ind. Compet. Trade	DEC	2024	24	1							10	10.1007/s10842-024-00413-w	http://dx.doi.org/10.1007/s10842-024-00413-w			25	Business	Emerging Sources Citation Index (ESCI)	Business & Economics	OU2Q3					2024-07-03	WOS:001209733500001
J	Shaikh, AJ; Mirza, Z; Parkar, FJ; Shaikh, MMA; Ahmed, A; Khan, AQAR				Shaikh, Ayan J.; Mirza, Zainab; Parkar, Fazal J.; Shaikh, Mohd Maaz A.; Ahmed, Afeef; Khan, Abdul Qayyum A. R.			Chat Kanoon: A Novel Approach to Legal Assistance in India	JOURNAL OF ELECTRICAL SYSTEMS			English	Article						ChatKanoon; Generative AI; Natural Language Processing (NLP); GPT-4; LLAMA 2; Large Language Models (LLMs); Indian Law; Ethical AI; Societal Impact of AI; Indian Legal System		- This paper presents ChatKanoon, an innovative multilingual AI chatbot tailored for the Indian legal system. Utilising advanced language models like GPT-4 and Llama2 70B, ChatKanoon employs instructional techniques rather than traditional model fine-tuning, to provide contextually relevant legal advice. This approach addresses critical challenges in India's legal sector, including limited access to legal information, high service costs, and the scarcity of specialised guidance. ChatKanoon's development involved using a diverse array of legal documents and case laws, which enabled the chatbot to deliver precise and reliable legal information. The paper describes the application of instructional techniques in guiding language models, the process of dataset utilisation, and the development of an intuitive chatbot interface. ChatKanoon is positioned as a tool to democratise legal information, making it more accessible and affordable, thereby enhancing the efficiency of legal procedures in India. The paper concludes by discussing the current limitations and future potential of ChatKanoon, along with the broader impact of AI -driven legal assistance tools in developing countries. ChatKanoon exemplifies the transformative role of AI in the legal domain, with the potential to revolutionise legal aid in India and beyond.										Ahuja K, 2023, Arxiv, DOI arXiv:2303.12528; Amato F, 2023, INFORMATION, V14, DOI 10.3390/info14060307; [Anonymous], 2021, IEEE Journals & Magazine | IEEE Xplore; [Anonymous], 2022, IEEE Journals & Magazine | IEEE Xplore; [Anonymous], 2021, LexNLP: Natural Language Processing and Information Extraction for Legal and Regulatory Texts, DOI [10.4337/9781788972826.00017, DOI 10.4337/9781788972826.00017]; Brooks C, 2020, CAMB J REG ECON SOC, V13, P135, DOI 10.1093/cjres/rsz026; Chalkidis I, 2023, Arxiv, DOI [arXiv:2304.12202, 10.2139/ssrn.4385460]; Chen WX, 2024, Arxiv, DOI [arXiv:2401.12292, 10.48550/arxiv.2401.12292, DOI 10.48550/ARXIV.2401.12292]; Devaraj Prathab, 2023, arXiv, DOI [10.48550/arxiv.2311.12719, DOI 10.48550/ARXIV.2311.12719]; Hasal M, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6426; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kalyan K.S., 2023, Nat. Lang. Process. J, V6, P100048, DOI [10.1016/j.nlp.2023.100048, DOI 10.1016/J.NLP.2023.100048]; Liu ALS, 2024, Arxiv, DOI arXiv:2401.08565; Mehrotra A, 2023, Arxiv, DOI [arXiv:2312.02119, 10.48550/arxiv.2312.02119, DOI 10.48550/ARXIV.2312.02119]; Muñoz-Soro JF, 2024, ARTIF INTELL LAW, DOI 10.1007/s10506-023-09380-9; Zhang XM, 2024, Arxiv, DOI [arXiv:2401.11356, 10.48550/arxiv.2401.11356]	16	0	0	1	1	ENGINEERING & SCIENTIFIC RESEARCH GROUPS	PARIS	2 RUE BAUDRICOURT, PARIS, 75013, FRANCE	1112-5209			J ELECTR SYST	J. Electr. Syst.	SEP	2024	20	3					763	774						12	Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Engineering	QO2R5					2024-07-03	WOS:001221753500025
J	Stroop, R				Stroop, Ralf			Answer to the letter to the editor of H. Daungsupawong et al. concerning &quot;Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?" by R. Stroop et al. (Eur Spine J [2023]; doi:10.1007/s00586-023-07975-z)	EUROPEAN SPINE JOURNAL			English	Letter									[Stroop, Ralf] Witten Herdecke Univ, Fac Hlth, Dept Med, Alfred Herrhausen Str 45, D-58455 Witten, Germany		Stroop, R (corresponding author), Witten Herdecke Univ, Fac Hlth, Dept Med, Alfred Herrhausen Str 45, D-58455 Witten, Germany.	ralf.stroop@uni-wh.de							0	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0940-6719	1432-0932		EUR SPINE J	Eur. Spine J.	JAN	2024	33	1					39	46		10.1007/s00586-023-08038-z	http://dx.doi.org/10.1007/s00586-023-08038-z		NOV 2023	8	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	IX6F8	37980277	Bronze			2024-07-03	WOS:001105493600001
J	Dehbozorgi, N; Kunuku, MT				Dehbozorgi, Nasrin; Kunuku, Mourya Teja			Exploring the Influence of Emotional States in Peer Interactions on Students’ Academic Performance	IEEE TRANSACTIONS ON EDUCATION			English	Article						Academic performance; affecting computing; GPT 3.5; large language models (LLMs); natural language processing (NLP); speech emotion recognition (SER)		Contribution: An AI model for speech emotion recognition (SER) in the educational domain to analyze the correlation between students' emotions, discussed topics in teams, and academic performance.Background: Research suggests that positive emotions are associated with better academic performance. On the other hand, negative emotions have a detrimental impact on academic achievement. This highlights the importance of taking into account the emotional states of the students to promote a supportive learning environment and improve their motivation and engagement. This line of research allows the development of tools that allow educators to address students' emotional needs and provide timely support and interventions.Intended Outcome: This work analyzes students' conversations and their expressed emotions as they work on class activities in teams and investigates if their conversations are course-related or not by applying topic extraction to the conversations. Furthermore, a comprehensive analysis is conducted to identify the correlation between emotions expressed by students and the discussed topics with their performance in the course in terms of their grades.Application Design: The student's performance is formatively evaluated, taking into account a combination of their scores in various components. The core of the developed model comprises a speech transcriber module, an emotion analysis module, and a topic extraction module. The outputs of all these modules are processed to identify the correlations. Findings: The findings show a strong positive correlation between the expressed emotions of "relief" and "satisfaction" with students' grades and a strong negative correlation between "frustration" and grades. Data also shows a strong positive correlation between course-related topics discussed in teams and grades and a strong negative correlation between noncourse-related topics and grades.	[Dehbozorgi, Nasrin] Kennesaw State Univ, Coll Comp & Software Engn, Dept Software Engn, Marietta, GA 30060 USA; [Kunuku, Mourya Teja] Kennesaw State Univ, Coll Comp & Amp Software Engn, Dept Comp Sci, Marietta, GA 30060 USA	University System of Georgia; Kennesaw State University; University System of Georgia; Kennesaw State University	Dehbozorgi, N (corresponding author), Kennesaw State Univ, Coll Comp & Software Engn, Dept Software Engn, Marietta, GA 30060 USA.							Bahreini K, 2016, EDUC INF TECHNOL, V21, P1367, DOI 10.1007/s10639-015-9388-2; Chowdary attota Dinesh, 2022, 2022 IEEE Frontiers in Education Conference (FIE), P1, DOI 10.1109/FIE56618.2022.9962701; DEHBOZORGI N, 2019, PROC FRONT EDUC CONF, P1; DEHBOZORGI N, 2018, PROC IEEE FRONT ED C, P1; Dehbozorgi N., 2021, PROC IEEE FRONTIERS, P1; Dehbozorgi N, 2020, PROC FRONT EDUC CONF; Dehbozorgi N, 2021, 2021 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE 2021), DOI 10.1109/FIE49875.2021.9637330; Dehbozorgi N, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P291, DOI 10.1145/3105726.3105741; Feng X, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17061941; Keith-Le J. A., 2020, FACULTY EXPERIENCES, P130; Kerkeni L, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P1; Li W, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 5, PROCEEDINGS, P809; Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003; Suganya S., 2020, Proceedings of the Indian National Science Academy Part B Biological Sciences, V90, P811, DOI 10.1007/s40011-019-01152-3; Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045	15	0	0	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9359	1557-9638		IEEE T EDUC	IEEE Trans. Educ.	JUN	2024	67	3					405	412		10.1109/TE.2023.3335171	http://dx.doi.org/10.1109/TE.2023.3335171		DEC 2023	8	Education, Scientific Disciplines; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Engineering	UB1O8					2024-07-03	WOS:001129741000001
J	Kharitonova, K; Pérez-Fernández, D; Gutiérrez-Hernando, J; Gutiérrez-Fandiño, A; Callejas, Z; Griol, D				Kharitonova, Ksenia; Perez-Fernandez, David; Gutierrez-Hernando, Javier; Gutierrez-Fandino, Asier; Callejas, Zoraida; Griol, David			Incorporating evidence into mental health Q&A: a novel method to use generative language models for validated clinical content extraction	BEHAVIOUR & INFORMATION TECHNOLOGY			English	Article; Early Access						Question-answering; generative language model; large language model; retrieval-augmented generation; clinical practice guide; mental health		Generative language models have changed the way we interact with computers using natural language. With the release of increasingly advanced GPT models, systems are able to correctly respond to questions in various domains. However, they still have important limitations, such as hallucinations, lack of substance in answers, inability to justify responses, or showing high confidence with fabricated content. In digital mental health, every decision must be traceable and based on scientific evidence and these shortcomings are hindering the integration of LLMs into clinical practice. In this paper, we provide a novel automated method to develop evidence-based question answering systems. Powerful state-of-the-art generalist language models are used and forced to employ only contents in validated clinical guidelines, tracking the source of the evidence for each generated response. This way, the system is able to protect users from hallucinatory responses. As a proof of concept, we present the results obtained building question-answering systems circumscribed to the clinical practice guidelines of the Spanish National Health System about the management of depression and attention deficit hyperactivity disorder. The coherence, veracity, and evidence supporting the responses have been evaluated by human experts obtaining high reliability, clarity, completeness, and traceability of evidence results.	[Kharitonova, Ksenia; Gutierrez-Hernando, Javier; Callejas, Zoraida; Griol, David] Univ Granada, Dept Software Engn, Avda Hosp, Granada 18071, Spain; [Perez-Fernandez, David] Univ Autonoma Madrid, Dept Matemat, Ciudad Univ Cantoblanco, Madrid 28049, Spain; [Gutierrez-Fandino, Asier] LHF Labs, Bilbao, Bizkaia, Spain; [Callejas, Zoraida] Univ Granada, Res Ctr Informat & Commun Technol CIT UGR, Granada, Spain	University of Granada; Autonomous University of Madrid; University of Granada	Callejas, Z (corresponding author), Univ Granada, Dept Software Engn, Avda Hosp, Granada 18071, Spain.; Callejas, Z (corresponding author), Univ Granada, Res Ctr Informat & Commun Technol CIT UGR, Granada, Spain.	zoraida@ugr.es	Carrion, Zoraida Callejas/C-6851-2012	Carrion, Zoraida Callejas/0000-0001-8891-5237	Agencia Estatal de Investigacion - MCIN/AEI [TED2021- 132470B-I00]; European Union 'NextGenerationEU/PRTR'; European Union [823907]	Agencia Estatal de Investigacion - MCIN/AEI; European Union 'NextGenerationEU/PRTR'; European Union(European Union (EU))	This publication is part of the 'CONVERSA: Effective and efficient resources and models for transformative conversational AI in Spanish and co-official languages' project with reference (Agencia Estatal de Investigacion) TED2021- 132470B-I00, funded by MCIN/AEI/10.13039/501100011033 and by the European Union 'NextGenerationEU/PRTR' and the European Union's Horizon 2020 research and innovation programme under grant agreement No 823907 (MENHIR, https://menhir-project.eu).	Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Arias D, 2022, ECLINICALMEDICINE, V54, DOI 10.1016/j.eclinm.2022.101675; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cabrera Johana, 2023, Bioinformatics and Biomedical Engineering: 10th International Work-Conference, IWBBIO 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Bioinformatics (13920), P313, DOI 10.1007/978-3-031-34960-7_22; Callejas Z., 2021, Dialog systems: a perspective from language, logic and computation, P219, DOI [10.1007/978-3-030-61438-6_11, DOI 10.1007/978-3-030-61438-6_11]; Chen SY, 2023, Arxiv, DOI arXiv:2305.13614; Chronopoulou A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2089; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Garg RK, 2023, medRxiv, DOI [10.1101/2023.06.13.23291311, 10.1101/2023.06.13.23291311, DOI 10.1101/2023.06.13.23291311]; Ge Y, 2023, J BIOMED INFORM, V144, DOI 10.1016/j.jbi.2023.104458; Guo Z., 2023, Evaluating large language models: A comprehensive survey; Haidich AB, 2010, HIPPOKRATIA, V14, P29; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Ji SX, 2021, Arxiv, DOI arXiv:2110.15621; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X; Lai V. D., 2023, Chatgpt Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Lee Eric W, 2020, Proc ACM Conf Health Inference Learn (2020), V2020, P139, DOI 10.1145/3368555.3384463; Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Liu X, 2019, J VIS COMMUN IMAGE R, V60, P1, DOI 10.1016/j.jvcir.2019.02.001; Madrid-Garcia A., 2023, medRxiv, DOI [DOI 10.1101/2023.07, 10.1101/2023.07.]; Matthews A., 2003, J MENTAL HLTH, V12, P235, DOI DOI 10.1080/0963823031000118221; McCullock SP, 2023, CLIN PSYCHOL REV, V100, DOI 10.1016/j.cpr.2022.102242; Miwa M, 2014, J BIOMED INFORM, V51, P242, DOI 10.1016/j.jbi.2014.06.005; Murad M Hassan, 2016, Evid Based Med, V21, P125, DOI 10.1136/ebmed-2016-110401; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; NousResearch, 2023, Hugging Face; Pan Y., 2024, Retrieval-augmented generation for large language models: A survey; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Richens JG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17419-7; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; SIGN, 2014, Scottish Intercollegiate Guidelines Network- SIGN 50: A Guideline Developer's Handbook; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Taylor R, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wallace BC, 2016, J MACH LEARN RES, V17; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7; Yang Rui, 2023, Health Care Sci, V2, P255, DOI 10.1002/hcs2.61; Yousaf F, 2023, BIOMED SIGNAL PROCES, V85, DOI 10.1016/j.bspc.2023.104875; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Ziyu Z., 2023, P 22 CHINESE NATL C, V2, P88	61	0	0	12	12	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0144-929X	1362-3001		BEHAV INFORM TECHNOL	Behav. Inf. Technol.	2024 MAR 2	2024										10.1080/0144929X.2024.2321959	http://dx.doi.org/10.1080/0144929X.2024.2321959		MAR 2024	18	Computer Science, Cybernetics; Ergonomics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KD2C8		hybrid			2024-07-03	WOS:001177946500001
J	Birks, D; Clare, J				Birks, Daniel; Clare, Joseph			Linking artificial intelligence facilitated academic misconduct to existing prevention frameworks	INTERNATIONAL JOURNAL FOR EDUCATIONAL INTEGRITY			English	Article						Artificial intelligence; Large language models; Academic integrity; Academic misconduct; Prevention; Detection; Opportunity reduction; Situational crime prevention	DISHONESTY	This paper connects the problem of artificial intelligence (AI)-facilitated academic misconduct with crime-prevention based recommendations about the prevention of academic misconduct in more traditional forms. Given that academic misconduct is not a new phenomenon, there are lessons to learn from established information relating to misconduct perpetration and frameworks for prevention. The relevance of existing crime prevention frameworks for addressing AI-facilitated academic misconduct are discussed and the paper concludes by outlining some ideas for future research relating to preventing AI-facilitated misconduct and monitoring student attitudes and behaviours with respect to this type of behaviour.	[Birks, Daniel] Univ Leeds, Sch Law, 2-04 Liberty Bldg,Woodhouse, Leeds LS2 9JT, England; [Clare, Joseph] Univ Western Australia, Sch Law, M253,35 Stirling Highway, Perth, WA 6009, Australia	University of Leeds; University of Western Australia	Clare, J (corresponding author), Univ Western Australia, Sch Law, M253,35 Stirling Highway, Perth, WA 6009, Australia.	joe.clare@uwa.edu.au		Clare, Joseph/0000-0003-0444-4189	No acknowledgements to add.	No acknowledgements to add.	No acknowledgements to add.	Arhin AO, 2009, NURS EDUC TODAY, V29, P710, DOI 10.1016/j.nedt.2009.03.001; Awdry R, 2021, ASSESS EVAL HIGH EDU, V46, P1255, DOI 10.1080/02602938.2020.1851651; Baird M, 2017, INT J EDUC INTEGR, V13, DOI 10.1007/s40979-017-0018-1; Bove T., 2023, Fortune; Bretag T, 2019, STUD HIGH EDUC, V44, P1837, DOI 10.1080/03075079.2018.1462788; Cassidy C, 2023, The Guardian Australia; Clare J., Academic integrity in the social sciences-perspectives on pedagogy and practice; Clare J., 2022, Contract Cheating in Higher Education: Global Perspectives on Theory, Practice and Policy, P153; Clare J, 2017, INT J EDUC INTEGR, V13, DOI 10.1007/s40979-017-0015-4; Clarke R.V., 2005, Crime analysis for problem solvers in 60 small steps; Clarke R.V., 2017, Environmental criminology and crime analysis, P286; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Curtis GJ., 2023, Academic integrity in the social sciences-perspectives on pedagogy and practice; Curtis GJ, 2016, HIGH EDUC RES DEV, V35, P1167, DOI 10.1080/07294360.2016.1161602; Dawson P., 2020, Defending Assessment Security in a Digital World: Preventing E-Cheating and Supporting Academic Integrity in Higher Education, DOI [10.4324/9780429324178, DOI 10.4324/9780429324178]; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eaton S. E., 2022, CONTRACT CHEATING HI; Eaton SE, 2023, Handbook of academic integrity; Felson Marcus., 1998, POLICE RES SERIES, V98, P1; Foltynek T, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00133-4; Guerette R., 2009, CRIME PREVENTION STU, V24, P29; Hodgkinson T, 2016, J CRIM JUSTICE EDUC, V27, P1, DOI 10.1080/10511253.2015.1064982; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Koubaa A., 2023, PREPRINT, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Kumar R, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00130-7; Leclerc B., 2017, ENV CRIMINOLOGY CRIM, P119; Lowrey A., 2023, The Atlantic; McKendrick Joe., 2022, Forbes; Ogilvie J, 2010, AUST NZ J CRIMINOL, V43, P130, DOI 10.1375/acri.43.1.130; OpenAI, 2023, ABOUT US; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Prichard J, 2022, SEX ABUSE-J RES TR, V34, P106, DOI 10.1177/10790632211013809; Rundle K., 2020, RES AGENDA ACAD INTE, P100, DOI [DOI 10.4337/9781789903775, 10.4337/9781789903775.00014, DOI 10.4337/9781789903775.00014]; Rundle K, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00132-5; Salleh A., 2023, ChatGPT-generated scientific papers could be picked up by new AI-detection tool, say researchers; Sanders NE, 2023, How ChatGPT hijacks democracy; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Sutherland-Smith W., 2022, CONTRACT CHEATING HI, P91; Thaler R. H., 2009, Nudge; Vjestica A, 2023, The Shortcut; Yukhymenko-Lescroart MA, 2014, J ACAD ETHICS, V12, P29, DOI 10.1007/s10805-013-9198-3	42	4	4	13	27	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1833-2595			INT J EDUC INTEGR	Int. J. Educ. Intege.	OCT 15	2023	19	1							20	10.1007/s40979-023-00142-3	http://dx.doi.org/10.1007/s40979-023-00142-3			10	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	U1NM2		gold			2024-07-03	WOS:001082539400001
J	Ayoub, NF; Lee, YJ; Grimm, D; Divi, V				Ayoub, Noel F.; Lee, Yu-Jin; Grimm, David; Divi, Vasu			Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition	OTOLARYNGOLOGY-HEAD AND NECK SURGERY			English	Article						artificial intelligence; ChatGPT; generative artificial intelligence; health literacy; large language models; online search engines; patient education		ObjectiveChat Generative Pretrained Transformer (ChatGPT) is the newest iteration of OpenAI's generative artificial intelligence (AI) with the potential to influence many facets of life, including health care. This study sought to assess ChatGPT's capabilities as a source of medical knowledge, using Google Search as a comparison. Study DesignCross-sectional analysis. SettingOnline using ChatGPT, Google Seach, and Clinical Practice Guidelines (CPG). MethodsCPG Plain Language Summaries for 6 conditions were obtained. Questions relevant to specific conditions were developed and input into ChatGPT and Google Search. All questions were written from the patient perspective and sought (1) general medical knowledge or (2) medical recommendations, with varying levels of acuity (urgent or emergent vs routine clinical scenarios). Two blinded reviewers scored all passages and compared results from ChatGPT and Google Search, using the Patient Education Material Assessment Tool (PEMAT-P) as the primary outcome. Additional customized questions were developed that assessed the medical content of the passages. ResultsThe overall average PEMAT-P score for medical advice was 68.2% (standard deviation [SD]: 4.4) for ChatGPT and 89.4% (SD: 5.9) for Google Search (p < .001). There was a statistically significant difference in the PEMAT-P score by source (p < .001) but not by urgency of the clinical situation (p = .613). ChatGPT scored significantly higher than Google Search (87% vs 78%, p = .012) for patient education questions. ConclusionChatGPT fared better than Google Search when offering general medical knowledge, but it scored worse when providing medical recommendations. Health care providers should strive to understand the potential benefits and ramifications of generative AI to guide patients appropriately.	[Ayoub, Noel F.; Lee, Yu-Jin; Grimm, David; Divi, Vasu] Stanford Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Div Head & Neck Surg, Stanford, CA USA; [Ayoub, Noel F.] Stanford Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Div Head & Neck Surg, 801 Welch Rd, Stanford, CA 94305 USA	Stanford University; Stanford University	Ayoub, NF (corresponding author), Stanford Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Div Head & Neck Surg, 801 Welch Rd, Stanford, CA 94305 USA.	nfa@stanford.edu		Ayoub, Noel/0000-0003-1867-994X				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2022, Clinical Practice Guidelines; Beus Johannes, 2020, Why (almost) everything you knew about Google CTR is no longer valid; De Oliveira GS, 2015, BMC SURG, V15, DOI 10.1186/s12893-015-0073-6; Eligibility Team, 2019, EL MED; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gabriel I, 2020, MIND MACH, V30, P411, DOI 10.1007/s11023-020-09539-2; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Kelly PA, 2007, PATIENT EDUC COUNS, V66, P119, DOI 10.1016/j.pec.2006.10.007; Lakens Daniel, 2013, Front Psychol, V4, P863, DOI 10.3389/fpsyg.2013.00863; Murphy M., 2019, DR GOOGLE WILL SEE Y; Pérez-Stable EJ, 2018, PATIENT EDUC COUNS, V101, P2186, DOI 10.1016/j.pec.2018.08.021; Roose K., 2023, NEW YORK TIMES; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Schulman J, 2022, Introducing chatgpt; Schwab PN, 2023, MINDS           0424; Shoemaker SJ., 2013, AHRQ PUBLICATION, V1402; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Vaswani A, 2017, ADV NEUR IN, V30; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216	21	18	18	31	60	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0194-5998	1097-6817		OTOLARYNG HEAD NECK	Otolaryngol. Head Neck Surg.	JUN	2024	170	6			SI		1484	1491		10.1002/ohn.465	http://dx.doi.org/10.1002/ohn.465		AUG 2023	8	Otorhinolaryngology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology; Surgery	SO7F2	37529853				2024-07-03	WOS:001040937600001
J	Wang, CY; Liu, SR; Yang, H; Guo, JL; Wu, YX; Liu, JL				Wang, Changyu; Liu, Siru; Yang, Hao; Guo, Jiulin; Wu, Yuxuan; Liu, Jialin			Ethical Considerations of Using ChatGPT in Health Care	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						ethics; ChatGPT; artificial intelligence; AI; large language models; health care; artificial intelligence development; development; algorithm; patient safety; patient privacy; safety; privacy	ARTIFICIAL-INTELLIGENCE; AUTOMATION BIAS; MEDICINE	ChatGPT has promising applications in health care, but potential ethical issues need to be addressed proactively to prevent harm. ChatGPT presents potential ethical challenges from legal, humanistic, algorithmic, and informational perspectives. Legal ethics concerns arise from the unclear allocation of responsibility when patient harm occurs and from potential breaches of patient privacy due to data collection. Clear rules and legal boundaries are needed to properly allocate liability and protect users. Humanistic ethics concerns arise from the potential disruption of the physician-patient relationship, humanistic care, and issues of integrity. Overreliance on artificial intelligence (AI) can undermine compassion and erode trust. Transparency and disclosure of AI-generated content are critical to maintaining integrity. Algorithmic ethics raise concerns about algorithmic bias, responsibility, transparency and explainability, as well as validation and evaluation. Information ethics include data bias, validity, and effectiveness. Biased training data can lead to biased output, and overreliance on ChatGPT can reduce patient adherence and encourage self-diagnosis. Ensuring the accuracy, reliability, and validity of ChatGPT-generated content requires rigorous validation and ongoing updates based on clinical practice. To navigate the evolving ethical landscape of AI, AI in health care must adhere to the strictest ethical standards. Through comprehensive ethical guidelines, health care professionals can ensure the responsible use of ChatGPT, promote accurate and reliable information exchange, protect patient privacy, and empower patients to make informed decisions about their health care.	[Wang, Changyu; Wu, Yuxuan; Liu, Jialin] Sichuan Univ, West China Med Sch, Dept Med Informat, Chengdu, Peoples R China; [Wang, Changyu] Sichuan Univ, West China Coll Stomatol, Chengdu, Peoples R China; [Liu, Siru] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN USA; [Yang, Hao; Guo, Jiulin; Liu, Jialin] Sichuan Univ, West China Hosp, Informat Ctr, 37 Guo Xue Xiang, Chengdu 610041, Peoples R China; [Liu, Jialin] Sichuan Univ, West China Hosp, Dept Otolaryngol Head & Neck Surg, Chengdu, Peoples R China	Sichuan University; Sichuan University; Vanderbilt University; Sichuan University; Sichuan University	Liu, JL (corresponding author), Sichuan Univ, West China Hosp, Informat Ctr, 37 Guo Xue Xiang, Chengdu 610041, Peoples R China.	DLJL8@163.com	Wang, Jiawei/KHC-8971-2024; Yang, YiChen/KEI-0140-2024; Li, Zexi/KFA-6939-2024; li, tong/JYO-7530-2024; Zhang, Yulin/KEI-1610-2024; YANG, DAN/KCL-5217-2024; Wang, Fei/KEH-6292-2024; LIU, JIALIN/JXN-8034-2024; zhang, zhang/KBQ-9978-2024; liu, zhao/KGM-5884-2024; Liu, Siru/AAM-8737-2021	Liu, Siru/0000-0002-5003-5354; Wang, Changyu/0000-0003-4548-331X; Wu, Yuxuan/0000-0003-1333-4627; yang, hao/0000-0002-3505-9403				Akter S, 2022, J BUS RES, V144, P201, DOI 10.1016/j.jbusres.2022.01.083; Akter S, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102387; Alvero R, 2023, FERTIL STERIL, V119, P930, DOI 10.1016/j.fertnstert.2023.03.010; Anders BA, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100694; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], Privacy Policy; [Anonymous], Summary of the HIPAA security rule; [Anonymous], DEF ROL AUTH CONTR; [Anonymous], Ethics guidelines for trustworthy AI; [Anonymous], Best Practice Guidelines for the Use of CFD in Nuclear Reactor Safety Applications; [Anonymous], ChatGPT and more: large scale AI models entrench big tech power; [Anonymous], Introducing ChatGPT.; [Anonymous], Promoting integrity in research and its publication; [Anonymous], Terms of use; [Anonymous], Chatbots, generative AI, and scholarly manuscripts; [Anonymous], GPT-4 is OpenAI's most advanced system, producing safer and more useful responses; [Anonymous], March 20 ChatGPT outage: here's what happened; Balasubramaniam N, 2023, INFORM SOFTWARE TECH, V159, DOI 10.1016/j.infsof.2023.107197; Bazoukis G, 2022, CELL REP MED, V3, DOI 10.1016/j.xcrm.2021.100485; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Busuioc M, 2021, PUBLIC ADMIN REV, V81, P825, DOI 10.1111/puar.13293; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Cath C, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2018.0080; ChatGPT, about us; Choi Y, 2023, RADIOGRAPHICS, V43, DOI 10.1148/rg.220105; Coghlan S, 2022, INT J SOC ROBOT, V14, P2095, DOI 10.1007/s12369-021-00804-7; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; DiGiorgio AM, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01926-3; El Emam K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0028071; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Fletcher RR, 2021, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.561802; Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5; Ford E, 2020, J MED ETHICS, V46, P367, DOI 10.1136/medethics-2019-105472; Goldsack JC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0260-4; Goodman RS, 2023, MED-CAMBRIDGE, V4, P139, DOI 10.1016/j.medj.2023.02.008; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Health CFD, 2022, Artificial intelligence and machine learning in software as a medical device; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Huse SM, 2014, MICROBIOME, V2, DOI 10.1186/2049-2618-2-5; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jeffrey D, 2016, J ROY SOC MED, V109, P446, DOI 10.1177/0141076816680120; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kerasidou A, 2021, J MED ETHICS, V47, DOI 10.1136/medethics-2019-105921; Kordzadeh N, 2022, EUR J INFORM SYST, V31, P388, DOI 10.1080/0960085X.2021.1927212; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Liu XX, 2022, LANCET DIGIT HEALTH, V4, pE384, DOI 10.1016/S2589-7500(22)00003-6; Luo ET, 2018, IEEE COMMUN MAG, V56, P163, DOI 10.1109/MCOM.2018.1700364; Lyell D, 2017, J AM MED INFORM ASSN, V24, P423, DOI 10.1093/jamia/ocw105; Madhusoodanan J, 2020, NATURE, V588, P546, DOI 10.1038/d41586-020-03419-6; Mitchell M, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P117, DOI 10.1145/3375627.3375832; Naik N, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.862322; Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Raghavan M, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P469, DOI 10.1145/3351095.3372828; Rider EA, 2014, PATIENT EDUC COUNS, V96, P273, DOI 10.1016/j.pec.2014.06.017; Safety critical AI, Partnership on AI; Sardana D, 2023, J AM DENT ASSOC, V154, P361, DOI 10.1016/j.adaj.2023.02.008; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Skitka LJ, 2000, INT J HUM-COMPUT ST, V52, P701, DOI 10.1006/ijhc.1999.0349; Skitka LJ, 1999, INT J HUM-COMPUT ST, V51, P991, DOI 10.1006/ijhc.1999.0252; Solimini R, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57121314; Starke G, 2021, MED HEALTH CARE PHIL, V24, P341, DOI 10.1007/s11019-021-10008-5; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Su ZH, 2021, J MED INTERNET RES, V23, DOI 10.2196/26109; Sun WL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235502; Taggart G, 2016, EUR EARLY CHILD EDUC, V24, P173, DOI 10.1080/1350293X.2014.970847; Tan J, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1313-0; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Tsamados A, 2022, AI SOC, V37, P215, DOI 10.1007/s00146-021-01154-8; Vearrier L, 2021, HEC FORUM, V33, P45, DOI 10.1007/s10730-020-09431-7; Wachter S, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aan6080; Wang G, 2022, NAT MACH INTELL, V4, P922, DOI 10.1038/s42256-022-00549-6; Williams R, 2022, DATA POLICY, V4, DOI 10.1017/dap.2021.37; Zanca F, 2022, SEMIN RADIAT ONCOL, V32, P432, DOI 10.1016/j.semradonc.2022.06.012; Zhang J, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02103-9	83	56	57	89	128	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	AUG 11	2023	25								e48009	10.2196/48009	http://dx.doi.org/10.2196/48009			9	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	R6BN5	37566454	Green Published, gold			2024-07-03	WOS:001065186800002
J	Lowe, M; Prusa, JD; Leevy, JL; Khoshgoftaar, TM				Lowe, Michael; Prusa, Joseph D.; Leevy, Joffrey L.; Khoshgoftaar, Taghi M.			Advancing machine learning with OCR2SEQ: an innovative approach to multi-modal data augmentation	JOURNAL OF BIG DATA			English	Article						Large language models; Optical character recognition; Sequence-to-sequence models; Text-to-text transformers; Data augmentation; Noise correction		OCR2SEQ represents an innovative advancement in Optical Character Recognition (OCR) technology, leveraging a multi-modal generative augmentation strategy to overcome traditional limitations in OCR systems. This paper introduces OCR2SEQ's unique approach, tailored to enhance data quality for sequence-to-sequence models, especially in scenarios characterized by sparse character sets and specialized vocabularies. At the heart of OCR2SEQ lies a set of novel augmentation techniques designed to simulate realistic text extraction errors. These techniques are adept at generating diverse and challenging data scenarios, thereby substantially improving the training efficacy and accuracy of text-to-text transformers. The application of OCR2SEQ has shown notable improvements in data processing accuracy, particularly in sectors heavily dependent on OCR technologies such as healthcare and library sciences. This paper demonstrates the capability of OCR2SEQ to transform OCR systems by enriching them with augmented, domain-specific data, paving the way for more sophisticated and reliable machine learning interpretations. This advancement in OCR technology, as presented in the study, not only enhances the accuracy and reliability of data processing but also sets a new benchmark in the integration of augmented data for refining OCR capabilities.	[Lowe, Michael; Prusa, Joseph D.; Leevy, Joffrey L.; Khoshgoftaar, Taghi M.] Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA	State University System of Florida; Florida Atlantic University	Leevy, JL (corresponding author), Florida Atlantic Univ, 777 Glades Rd, Boca Raton, FL 33431 USA.	jleevy2017@fau.edu						Berabi B, 2021, PMLR, P780; Bradski G, 2000, J Softw Tools, V120, P122; Cleland I., 2013, Ambient Assisted Living and Active Aging, P9, DOI DOI 10.1007/978-3-319-03092-0_2; Hugging Face Team, Hugging Face Data Repository; Jockers ML, 2015, Wiley Online Library, P291; Johnson A., 2021, Mimic-iv. PhysioNet, DOI [DOI 10.13026/A3WN-HQ05,2020, DOI 10.13026/S6N6-XD98]; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kuang ZH, 2021, Arxiv, DOI arXiv:2108.06543; Li M., 2023, P AAAI C ARTIFICIAL, VVolume 37, P13094; Lihui F., 2021, Foreign Lit Stud, V43, P1; Ma E., 2019, Nlp augmentation; Papanikolaou Y, 2022, Arxiv, DOI arXiv:2109.08564; Patel C., 2012, Int J Comput Appl, V55, P50, DOI [DOI 10.5120/8794-2784, 10.5120/8794-2784]; Raffel C, 2020, J MACH LEARN RES, V21; Saoji S., 2021, J Interdiscip Cycle Res, V13, P1674; Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Shull JG, 2019, JMIR MED INF, V7, P259, DOI 10.2196/12712; Shushkevich E, 2022, LECT NOTES ARTIF INT, V13502, P263, DOI 10.1007/978-3-031-16270-1_22; Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991; Srivastava Ankit, 2020, P 6 WORKSHOP NOISY U, P16, DOI DOI 10.18653/V1/2020.WNUT-1.3; Vaswani A, 2017, ADV NEUR IN, V30; Were MC, 2019, J AM MED INFORM ASSN, V26, P884, DOI 10.1093/jamia/ocz071; Xue LT, 2022, T ASSOC COMPUT LING, V10, P291, DOI 10.1162/tacl_a_00461	24	0	0	0	0	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2196-1115		J BIG DATA-GER	J. Big Data	JUN 13	2024	11	1							86	10.1186/s40537-024-00927-4	http://dx.doi.org/10.1186/s40537-024-00927-4			20	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UK9U9		gold			2024-07-03	WOS:001248079600002
J	Ngo, NK; Hy, TS				Khang Ngo, Nhat; Son Hy, Truong			Multimodal protein representation learning and target-aware variational auto-encoders for protein-binding ligand generation	MACHINE LEARNING-SCIENCE AND TECHNOLOGY			English	Article						protein representation learning; protein-ligand binding; ligand generation; geometric deep learning; large language models; multimodal architecture; variational autoencoder	SCORING FUNCTION; SOFTWARE; DESIGN	Without knowledge of specific pockets, generating ligands based on the global structure of a protein target plays a crucial role in drug discovery as it helps reduce the search space for potential drug-like candidates in the pipeline. However, contemporary methods require optimizing tailored networks for each protein, which is arduous and costly. To address this issue, we introduce TargetVAE, a target-aware variational auto-encoder that generates ligands with desirable properties including high binding affinity and high synthesizability to arbitrary target proteins, guided by a multimodal deep neural network built based on geometric and sequence models, named Protein Multimodal Network (PMN), as the prior for the generative model. PMN unifies different representations of proteins (e.g. primary structure-sequence of amino acids, 3D tertiary structure, and residue-level graph) into a single representation. Our multimodal architecture learns from the entire protein structure and is able to capture their sequential, topological, and geometrical information by utilizing language modeling, graph neural networks, and geometric deep learning. We showcase the superiority of our approach by conducting extensive experiments and evaluations, including predicting protein-ligand binding affinity in the PBDBind v2020 dataset as well as the assessment of generative model quality, ligand generation for unseen targets, and docking score computation. Empirical results demonstrate the promising and competitive performance of our proposed approach. Our software package is publicly available at https://github.com/HySonLab/Ligand_Generation.	[Khang Ngo, Nhat; Son Hy, Truong] FPT Software, AI Ctr, Hanoi, Vietnam; [Son Hy, Truong] Indiana State Univ, Dept Math & Comp Sci, Terre Haute, IN USA	Indiana State University	Hy, TS (corresponding author), FPT Software, AI Ctr, Hanoi, Vietnam.; Hy, TS (corresponding author), Indiana State Univ, Dept Math & Comp Sci, Terre Haute, IN USA.	khangnn4@fpt.com; TruongSon.Hy@indstate.edu		Hy, Truong Son/0000-0002-5092-3757				Anderson B, 2019, ADV NEUR IN, V32; Asgari E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38746-w; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020; Burley SK, 2019, NUCLEIC ACIDS RES, V47, pD464, DOI 10.1093/nar/gky1004; Cai C., 2023, INT C MACHINE LEARNI; Chen DL, 2020, AAAI CONF ARTIF INTE, V34, P3438; Dai H., 2018, INT C LEARNING REPRE; De Cao N., 2018, ICML 2018 WORKSHOP T; Dwivedi V. P., 2022, Advances in Neural Information Processing Systems, V35, P22326; Gao KF, 2020, J CHEM INF MODEL, V60, P5682, DOI 10.1021/acs.jcim.0c00599; Gao Wenhao., 2022, Advances in neural information processing systems, V35, P21342, DOI DOI 10.48550/ARXIV.2206.12411; Gapsys V, 2022, J CHEM INF MODEL, V62, P1172, DOI 10.1021/acs.jcim.1c01445; Gilmer J, 2017, PR MACH LEARN RES, V70; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Guan J, 2023, 11 INT C LEARNING RE; Guan J., 2023, INT C LEARNING REPRE; Harvey W., 2022, INT C LEARNING REPRE; He T, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0209-z; Thiede EH, 2020, Arxiv, DOI arXiv:2004.03990; Hughes JP, 2011, BRIT J PHARMACOL, V162, P1239, DOI 10.1111/j.1476-5381.2010.01127.x; Hy TS, 2023, MACH LEARN-SCI TECHN, V4, DOI 10.1088/2632-2153/acc0d8; Ivanov O., 2019, INT C LEARNING REPRE; Jin WG, 2020, PR MACH LEARN RES, V119; Jin WG, 2018, PR MACH LEARN RES, V80; Jing B., 2021, INT C LEARNING REPRE; Jing Bowen, 2021, arXiv; Kim Jinwoo, 2022, Advances in Neural Information Processing Systems; Koh HY, 2023, bioRxiv, DOI [10.1101/2023.09.17.558145, 10.1101/2023.09.17.558145, DOI 10.1101/2023.09.17.558145]; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kusner MJ, 2017, PR MACH LEARN RES, V70; Lin Z., 2022, bioRxiv, DOI [10.1126/science.ade2574, DOI 10.1126/SCIENCE.ADE2574]; Liu M, 2022, PR MACH LEARN RES; Liu ZH, 2017, ACCOUNTS CHEM RES, V50, P302, DOI 10.1021/acs.accounts.6b00491; Luo S., 2021, Advances in Neural Information Processing Systems; Luo ST, 2021, Advances in Neural Information Processing Systems, V34; Luo YZ, 2021, PR MACH LEARN RES, V139; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Merz KM Jr, 2020, J CHEM INF MODEL, V60, P5635, DOI 10.1021/acs.jcim.0c01388; Mysinger MM, 2012, J MED CHEM, V55, P6582, DOI 10.1021/jm300687e; Nascimento ACA, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-0890-3; Ngo NK, 2023, J CHEM PHYS, V159, DOI 10.1063/5.0152833; Notin P, 2022, PR MACH LEARN RES; O'Boyle NM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-33; Öztürk H, 2018, BIOINFORMATICS, V34, P821, DOI 10.1093/bioinformatics/bty593; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Peng XG, 2022, 38 INT C MACHINE LEA; Scantlebury J, 2023, J CHEM INF MODEL, V63, P2960, DOI 10.1021/acs.jcim.3c00322; Schneuing A, 2023, Arxiv, DOI [arXiv:2210.13695, 10.48550/arXiv.2210.13695]; Segler MHS, 2018, ACS CENTRAL SCI, V4, P120, DOI 10.1021/acscentsci.7b00512; Simonovsky Martin, 2018, arXiv; Sohn K, 2015, ADV NEUR IN, V28; Stark H, 2022, 39 INT C MACHINE LEA; Nguyen T, 2021, BIOINFORMATICS, V37, P1140, DOI 10.1093/bioinformatics/btaa921; Topping Jake, 2022, INT C LEARNING REPRE; Townshend RJL, 2022, Arxiv, DOI [arXiv:2012.04035, 10.48550/arXiv.2012.04035]; Trott O, 2010, J COMPUT CHEM, V31, P455, DOI 10.1002/jcc.21334; Verkhivker G M., 2001, Combinatorial Library Design and Evaluation, P177; Voitsitskyi T, 2023, RSC ADV, V13, P10261, DOI 10.1039/d3ra00281k; Wan ZY, 2021, Arxiv, DOI arXiv:2103.14031; Wu ZC, 2021, CURR OPIN CHEM BIOL, V65, P18, DOI 10.1016/j.cbpa.2021.04.004; Yang KK, 2018, BIOINFORMATICS, V34, P2642, DOI 10.1093/bioinformatics/bty178; You JX, 2018, ADV NEUR IN, V31; Zhang CH, 2021, ACS CENTRAL SCI, V7, P467, DOI 10.1021/acscentsci.1c00039; Zhao CG, 2022, NAR GENOM BIOINFORM, V4, DOI 10.1093/nargab/lqac004; Zhao LL, 2020, FRONT GENET, V10, DOI 10.3389/fgene.2019.01243; Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153	67	0	0	3	3	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND		2632-2153		MACH LEARN-SCI TECHN	Mach. Learn.-Sci. Technol.	JUN 1	2024	5	2							025021	10.1088/2632-2153/ad3ee4	http://dx.doi.org/10.1088/2632-2153/ad3ee4			15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Science & Technology - Other Topics	ON8S3		Green Submitted, gold			2024-07-03	WOS:001208051400001
J	Gasparovic, M; Jungová, P; Tomásik, J; Mrináková, B; Hirjak, D; Timková, S; Danisovic, L; Janek, M; Baca, L; Peciar, P; Thurzo, A				Gasparovic, Michal; Jungova, Petra; Tomasik, Juraj; Mrinakova, Bela; Hirjak, Dusan; Timkova, Silvia; Danisovic, Lubos; Janek, Marian; Baca, Lubos; Peciar, Peter; Thurzo, Andrej			Evolving Strategies and Materials for Scaffold Development in Regenerative Dentistry	APPLIED SCIENCES-BASEL			English	Review						regenerative medicine; scaffolds; mesenchymal stem cells; 3D printing; bioprinting; tissue engineering; whole tooth regeneration; large language model research; AI; LLM; Bard; ChatGPT	CALCIUM-PHOSPHATE CERAMICS; STEM-CELLS; BIOLOGICAL-PROPERTIES; GROWTH-FACTORS; BONE; ACID; BIOMATERIALS; HYDROGEL; CHITOSAN; ANTIBACTERIAL	Regenerative dentistry has experienced remarkable advancement in recent years. The interdisciplinary discoveries in stem cell applications and scaffold design and fabrication, including novel techniques and biomaterials, have demonstrated immense potential in the field of tissue engineering and regenerative therapy. Scaffolds play a pivotal role in regenerative dentistry by facilitating tissue regeneration and restoring damaged or missing dental structures. These biocompatible and biomimetic structures serve as a temporary framework for cells to adhere, proliferate, and differentiate into functional tissues. This review provides a concise overview of the evolution of scaffold strategies in regenerative dentistry, along with a novel analysis (Bard v2.0 based on the Gemini neural network architecture) of the most commonly employed materials used for scaffold fabrication during the last 10 years. Additionally, it delves into bioprinting, stem cell colonization techniques and procedures, and outlines the prospects of regenerating a whole tooth in the future. Moreover, it discusses the optimal conditions for maximizing mesenchymal stem cell utilization and optimizing scaffold design and personalization through precise 3D bioprinting. This review highlights the recent advancements in scaffold development, particularly with the advent of 3D bioprinting technologies, and is based on a comprehensive literature search of the most influential recent publications in this field.	[Gasparovic, Michal; Jungova, Petra; Tomasik, Juraj; Thurzo, Andrej] Comenius Univ, Fac Med, Dept Orthodont Regenerat & Forens Dent, Bratislava 81102, Slovakia; [Mrinakova, Bela] Comenius Univ, St Elisabeth Canc Inst, Fac Med, Dept Oncol 1, Bratislava 81250, Slovakia; [Hirjak, Dusan] Comenius Univ, Fac Med, Dept Stomatol & Maxillofacial Surg, Bratislava 81250, Slovakia; [Timkova, Silvia] Pavol Jozef Safarik Univ, Fac Med, Dept Stomatol & Maxilofacial Surg, Kosice 04190, Slovakia; [Timkova, Silvia] Louis Pasteur Univ Hosp, Kosice 04190, Slovakia; [Danisovic, Lubos] Comenius Univ, Inst Med Biol Genet & Clin Genet, Fac Med, Bratislava 81108, Slovakia; [Janek, Marian; Baca, Lubos] Slovak Univ Technol Bratislava, Fac Chem & Food Technol, Dept Inorgan Mat, Bratislava 81237, Slovakia; [Janek, Marian] Comenius Univ, Fac Nat Sci, Dept Phys & Theoret Chem, Bratislava 84215, Slovakia; [Peciar, Peter] Slovak Univ Technol Bratislava, Inst Proc Engn, Fac Mech Engn, Bratislava 81231 1, Slovakia	Comenius University Bratislava; Comenius University Bratislava; Comenius University Bratislava; University of Pavol Jozef Safarik Kosice; Comenius University Bratislava; Slovak University of Technology Bratislava; Comenius University Bratislava; Slovak University of Technology Bratislava	Gasparovic, M; Jungová, P; Thurzo, A (corresponding author), Comenius Univ, Fac Med, Dept Orthodont Regenerat & Forens Dent, Bratislava 81102, Slovakia.	gasparovic58@uniba.sk; jungova2@uniba.sk; tomasik7@uniba.sk; bela.mrinakova@fmed.uniba.sk; dusan.hirjak@fmed.uniba.sk; silvia.timkova@upjs.sk; lubos.danisovic@fmed.uniba.sk; marian.janek@stuba.sk; lubos.baca@stuba.sk; peter.peciar@stuba.sk; thurzo3@uniba.sk	Thurzo, Andrej/AAX-7034-2021; Mrinakova, Bela/IWE-5296-2023	Thurzo, Andrej/0000-0002-7810-5721; Mrinakova, Bela/0000-0001-9795-0640; Peciar, Peter/0000-0003-4684-2943; Tomasik, Juraj/0009-0000-1096-4485; Danisovic, Lubos/0000-0002-5074-9621	Slovak Research and Development Agency	Slovak Research and Development Agency(Slovak Research and Development Agency)	The authors gratefully acknowledge the technical support of the digital dental lab infrastructure of 3Dent Medical Ltd. Company, as well as the dental clinic Sangre Azul Ltd.	Aghali A, 2021, CELLS-BASEL, V10, DOI 10.3390/cells10112993; Ahmadian E, 2019, INT J BIOL MACROMOL, V140, P245, DOI 10.1016/j.ijbiomac.2019.08.119; Al-Harbi N, 2021, PHARMACEUTICALS-BASE, V14, DOI 10.3390/ph14020075; Alipour M, 2021, BMC BIOTECHNOL, V21, DOI 10.1186/s12896-020-00666-3; Almeida LDF, 2018, J MATER SCI-MATER M, V29, DOI 10.1007/s10856-018-6088-7; Ambard Alberto J, 2006, J Prosthodont, V15, P321, DOI 10.1111/j.1532-849X.2006.00129.x; Ana ID, 2021, FUTUR SCI OA, V7, DOI 10.2144/fsoa-2021-0050; Anastasiou AD, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50916-4; Angelis N.D., 2023, Biology, V12, DOI [10.3390/biology12121474, DOI 10.3390/BIOLOGY12121474]; Athanasiou KA, 1998, ARTHROSCOPY, V14, P726, DOI 10.1016/S0749-8063(98)70099-4; Athanasiou KA, 1996, BIOMATERIALS, V17, P93, DOI 10.1016/0142-9612(96)85754-1; Atia GAN, 2023, PHARMACEUTICALS-BASE, V16, DOI 10.3390/ph16050702; Atia GAN, 2022, ACS OMEGA, V7, P44532, DOI 10.1021/acsomega.2c05596; Ballal NV, 2009, AUST ENDOD J, V35, P29, DOI 10.1111/j.1747-4477.2008.00126.x; Baranova J, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21114031; Bohner M, 2020, ACTA BIOMATER, V113, P23, DOI 10.1016/j.actbio.2020.06.022; Bouler JM, 2017, ACTA BIOMATER, V53, P1, DOI 10.1016/j.actbio.2017.01.076; Burdick JA, 2011, ADV MATER, V23, pH41, DOI 10.1002/adma.201003963; Cabaña-Muñoz ME, 2023, PHARMACEUTICS, V15, DOI 10.3390/pharmaceutics15082109; Cama G., 2014, BIOMATERIALS BONE RE, P3, DOI DOI 10.1533/9780857098104.1.3; Cao C, 2020, STEM CELL RES THER, V11, DOI 10.1186/s13287-020-01605-x; Chrcanovic B., 2023, Medicina, V60, DOI [10.3390/MEDICINA60010007, DOI 10.3390/MEDICINA60010007]; Chung C, 2009, TISSUE ENG PT A, V15, P243, DOI 10.1089/ten.tea.2008.0067; Cordonnier T, 2011, ADV ENG MATER, V13, pB135, DOI 10.1002/adem.201080098; Cverha M, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8070536; DACULSI G, 1989, J BIOMED MATER RES, V23, P883, DOI 10.1002/jbm.820230806; Daghrery A, 2023, ACTA BIOMATER, V156, P88, DOI 10.1016/j.actbio.2022.01.010; Dahiya Parveen, 2013, N Am J Med Sci, V5, P309, DOI 10.4103/1947-2714.112473; Dal-Fabbro R, 2023, GELS-BASEL, V9, DOI 10.3390/gels9110897; Diana R, 2020, REGEN THER, V15, P243, DOI 10.1016/j.reth.2020.09.007; Dissanayaka WL, 2020, J ENDODONT, V46, pS81, DOI 10.1016/j.joen.2020.06.022; Dong X, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10030354; Draget KI, 2011, FOOD HYDROCOLLOID, V25, P251, DOI 10.1016/j.foodhyd.2009.10.007; Ducret M, 2019, DENT MATER, V35, P523, DOI 10.1016/j.dental.2019.01.018; Eck U, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131810199; Enukashvily NI, 2021, BIOENGINEERING-BASEL, V8, DOI 10.3390/bioengineering8060075; Eshwar S, 2023, GELS-BASEL, V9, DOI 10.3390/gels9070573; EzEldeen M, 2021, EUR CELLS MATER, V40, P485, DOI 10.22203/eCM.v041a31; Fabricky MMC, 2021, MATERIALS, V14, DOI 10.3390/ma14092266; Fakheran O, 2023, DENT J-BASEL, V11, DOI 10.3390/dj11040100; Farina NM, 2008, J MATER SCI-MATER M, V19, P1565, DOI 10.1007/s10856-008-3400-y; Fathi M, 2019, MATER TODAY-PROC, V13, P876, DOI 10.1016/j.matpr.2019.04.051; Fujioka-Kobayashi M, 2020, MATERIALS, V13, DOI 10.3390/ma13122682; FUKASE Y, 1990, J DENT RES, V69, P1852, DOI 10.1177/00220345900690121201; Furquim CP, 2022, TISSUE ENG PART C-ME, V28, P104, DOI [10.1089/ten.tec.2022.0022, 10.1089/ten.TEC.2022.0022]; Gauthier O, 1998, BIOMATERIALS, V19, P133, DOI 10.1016/S0142-9612(97)00180-4; Gentile P, 2014, INT J MOL SCI, V15, P3640, DOI 10.3390/ijms15033640; Giordano-Kelhoffer B, 2023, MATERIALS, V16, DOI 10.3390/ma16020685; Grant PV, 2006, NATO SCI SER II-MATH, V228, P215, DOI 10.1007/1-4020-4741-X_19; Granz CL, 2020, WORLD J STEM CELLS, V12, P897, DOI 10.4252/wjsc.v12.i9.897; Guazzo R, 2018, NANOMATERIALS-BASEL, V8, DOI 10.3390/nano8050349; Gupta P, 2024, INT J BIOL MACROMOL, V254, DOI 10.1016/j.ijbiomac.2023.127660; Gwon K, 2017, ACTA BIOMATER, V49, P284, DOI 10.1016/j.actbio.2016.12.001; Ha M, 2020, DENT MATER, V36, P88, DOI 10.1016/j.dental.2019.10.013; Habibovic P, 2006, J BIOMED MATER RES A, V77A, P747, DOI 10.1002/jbm.a.30712; Heng B. C., 2022, Smart Polym. Mater. Biomed. Appl, V3, P4, DOI [10.1016/j.smaim.2021.11.003, DOI 10.1016/J.SMAIM.2021.11.003]; Hengtrakool C, 2023, POLYMERS-BASEL, V15, DOI 10.3390/polym15173511; Hu D, 2020, MOLECULES, V25, DOI 10.3390/molecules25204785; Hu Y, 2022, MATER TODAY COMMUN, V33, DOI 10.1016/j.mtcomm.2022.104231; Husain S, 2017, MATERIALS, V10, DOI 10.3390/ma10060602; Iacob MC, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app132212149; Iftikhar S, 2021, SAUDI DENT J, V33, P229, DOI 10.1016/j.sdentj.2021.01.002; Inchingolo AM, 2023, J FUNCT BIOMATER, V14, DOI 10.3390/jfb14030132; Inchingolo F, 2023, MATERIALS, V16, DOI 10.3390/ma16186293; Ivanov AA, 2023, CELLS-BASEL, V12, DOI 10.3390/cells12192335; Jamari J, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e12050; Jamari J, 2022, METALS-BASEL, V12, DOI 10.3390/met12081241; Julien M, 2007, BIOMATERIALS, V28, P956, DOI 10.1016/j.biomaterials.2006.10.018; Kaiser L R, 1992, Top Health Care Financ, V18, P32; Kanjevac T, 2019, CURR STEM CELL RES T, V14, P320, DOI 10.2174/1574888X14666190103170109; Keyhan S.O., 2016, Tissue Engineering Applications in Maxillofacial Surgery, DOI [10.5772/intechopen.70904, DOI 10.5772/INTECHOPEN.70904]; Kim HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00257-w; Kishen A, 2008, J ENDODONT, V34, P1515, DOI 10.1016/j.joen.2008.08.035; Kolodziejska B, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242316751; Koyanagi M, 2022, TISSUE ENG PT A, V28, P749, DOI [10.1089/ten.tea.2021.0225, 10.1089/ten.TEA.2021.0225]; Krasilnikova O, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242216250; LANGER R, 1993, SCIENCE, V260, P920, DOI 10.1126/science.8493529; Ledesma-Martínez E, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/4709572; Lee KY, 2012, PROG POLYM SCI, V37, P106, DOI 10.1016/j.progpolymsci.2011.06.003; Li RT, 2022, ADV SCI, V9, DOI 10.1002/advs.202105152; Lin GSS, 2022, MAR DRUGS, V20, DOI 10.3390/md20080539; Lowe B, 2019, J FUNCT BIOMATER, V10, DOI 10.3390/jfb10010016; Ma Y, 2019, BIOTECHNOL BIOENG, V116, P452, DOI 10.1002/bit.26882; Malcangi G, 2023, J PERS MED, V13, DOI 10.3390/jpm13050725; Malhotra Neeraj, 2019, Curr Stem Cell Res Ther, V14, P351, DOI 10.2174/1574888X14666190111105504; Malik S, 2023, MOLECULES, V28, DOI 10.3390/molecules28186624; Masoud AR, 2023, COATINGS, V13, DOI 10.3390/coatings13030542; Matichescu A, 2020, MATERIALS, V13, DOI 10.3390/ma13225303; Matthews JA, 2002, BIOMACROMOLECULES, V3, P232, DOI 10.1021/bm015533u; Meyer U., 2009, FUNDAMENTALS TISSUE, DOI DOI 10.1007/978-3-540-77755-7; Mishchenko O, 2023, POLYMERS-BASEL, V15, DOI 10.3390/polym15183822; Mishima S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93256-y; Mohabatpour F, 2023, BIOFABRICATION, V15, DOI 10.1088/1758-5090/acab35; Mohd N, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms241612881; Mondal S, 2023, ADV COLLOID INTERFAC, V321, DOI 10.1016/j.cis.2023.103013; Monteiro N, 2018, DENT MATER, V34, P389, DOI 10.1016/j.dental.2017.11.020; Morrison Devin Grace, 2021, Bioprinting, V23, pe00153, DOI 10.1016/j.bprint.2021.e00153; Mosaddad SA, 2020, J MATER RES TECHNOL, V9, P14799, DOI 10.1016/j.jmrt.2020.10.065; Murashima-Suginami A, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abf1798; Murashima-Suginami A, 2007, BIOCHEM BIOPH RES CO, V359, P549, DOI 10.1016/j.bbrc.2007.05.148; Mylonaki I, 2017, BIOMATERIALS, V128, P56, DOI 10.1016/j.biomaterials.2017.02.028; Naeem MM, 2023, J FUNCT BIOMATER, V14, DOI 10.3390/jfb14030144; Naik SV, 2023, SAUDI DENT J, V35, P559, DOI 10.1016/j.sdentj.2023.05.010; Oshima M, 2014, NEW TRENDS IN TISSUE ENGINEERING AND REGENERATIVE MEDICINE - OFFICIAL BOOK OF THE JAPANESE SOCIETY FOR REGENERATIVE MEDICINE, P109, DOI 10.5772/58908; Oshima M, 2014, SCI REP-UK, V4, DOI 10.1038/srep06044; Ostrovidov S, 2023, FRONT BIOENG BIOTECH, V11, DOI 10.3389/fbioe.2023.991821; Osypko KF, 2023, ADV CLIN EXP MED, V32, P921, DOI 10.17219/acem/159091; Parthiban SP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78176-7; Paschos NK, 2015, J TISSUE ENG REGEN M, V9, P488, DOI 10.1002/term.1870; Prahasanti C, 2020, CLIN COSMET INV DENT, V12, P79, DOI 10.2147/CCIDE.S245678; Quirino LC, 2023, POLYMERS-BASEL, V15, DOI 10.3390/polym15040868; Rad RM, 2019, J BIOMATER APPL, V33, P834, DOI 10.1177/0885328218812487; Ramezanzade S, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8020142; Raus RA, 2021, ASIAN J PHARM SCI, V16, P280, DOI 10.1016/j.ajps.2020.10.001; Ricci JL, 2011, INT DENT J, V61, P2, DOI 10.1111/j.1875-595X.2011.00024.x; Roi A, 2023, BIOMEDICINES, V11, DOI 10.3390/biomedicines11092436; Rokaya D, 2023, J COMPOS SCI, V7, DOI 10.3390/jcs7010024; Rossi T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131910757; Safari B, 2021, INT J BIOL MACROMOL, V175, P544, DOI 10.1016/j.ijbiomac.2021.02.052; Safari B, 2021, COLLOID SURFACE B, V198, DOI 10.1016/j.colsurfb.2020.111462; Samiei M, 2022, CURR STEM CELL RES T, V17, P606, DOI 10.2174/1574888X17666211220100521; Sato TP, 2021, CLIN ORAL INVEST, V25, P3095, DOI 10.1007/s00784-020-03633-6; Shenoi Pratima R., 2016, General Dentistry, V64, P60; Shopova D, 2023, J FUNCT BIOMATER, V14, DOI 10.3390/jfb14100530; Shrestha A, 2016, J ENDODONT, V42, P1417, DOI 10.1016/j.joen.2016.05.021; Singh PN, 2023, TISSUE ENG PART C-ME, V29, P242, DOI [10.1089/ten.tec.2023.0070, 10.1089/ten.TEC.2023.0070]; Soares DG, 2021, J DENT RES, V100, P1118, DOI 10.1177/00220345211024207; Song XZ, 2023, MOLECULES, V28, DOI 10.3390/molecules28196967; Sorushanova A, 2019, ADV MATER, V31, DOI 10.1002/adma.201801651; Souza AP, 2023, J BIOMATER APPL, DOI 10.1177/08853282231155570; Stevens MM, 2008, MATER TODAY, V11, P18, DOI 10.1016/S1369-7021(08)70086-5; Strunga M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11050683; Sugiaman VK, 2023, POLYMERS-BASEL, V15, DOI 10.3390/polym15051082; Suh H, 2000, YONSEI MED J, V41, P681, DOI 10.3349/ymj.2000.41.6.681; Sukpaita T, 2021, MAR DRUGS, V19, DOI 10.3390/md19100551; Surovková J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085212; Swanson W Benton, 2023, Methods Mol Biol, V2588, P493, DOI 10.1007/978-1-0716-2780-8_30; Tahriri M, 2019, MAT SCI ENG C-MATER, V102, P171, DOI 10.1016/j.msec.2019.04.051; Takahashi K., 2013, Gene Therapy-Tools and Potential Applications, DOI [10.5772/52529, DOI 10.5772/52529, 10.5772/52529.]; Takahashi K, 2020, INFLAMM REGEN, V40, DOI 10.1186/s41232-020-00130-x; Tatullo M, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17093001; Tatullo M, 2019, MATERIALS, V12, DOI 10.3390/ma12040597; Tauviqirrahman M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30725-6; Thalakiriyawa DS, 2024, INT DENT J, V74, P25, DOI 10.1016/j.identj.2023.07.008; Thesleff I, 2018, EUR J ORAL SCI, V126, P67, DOI 10.1111/eos.12421; Thurzo A, 2010, BRATISL MED J, V111, P168; Thurzo A, 2022, SEMIN ORTHOD, V28, P92, DOI 10.1053/j.sodo.2022.10.005; Thurzo A, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms232314870; Thurzo A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207752; Thurzo A, 2022, MOLECULES, V27, DOI 10.3390/molecules27134035; Tollemar V, 2016, GENES DIS, V3, P56, DOI 10.1016/j.gendis.2015.09.004; Urban R, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12071710; Vacanti CA, 2006, J CELL MOL MED, V10, P569, DOI 10.1111/j.1582-4934.2006.tb00421.x; Vaiani L, 2023, J FUNCT BIOMATER, V14, DOI 10.3390/jfb14030146; Vance RJ, 2004, BIOMATERIALS, V25, P2095, DOI 10.1016/j.biomaterials.2003.08.064; Verykokou S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12155023; Wang QQ, 2019, MAT SCI ENG C-MATER, V99, P1469, DOI 10.1016/j.msec.2019.02.091; Wang XG, 2021, BIOACT MATER, V6, P4517, DOI 10.1016/j.bioactmat.2021.05.003; Wei FL, 2013, STEM CELLS DEV, V22, P1752, DOI 10.1089/scd.2012.0688; Wu DT, 2021, MOLECULES, V26, DOI 10.3390/molecules26227043; Xie ZJ, 2019, BIOMED PHARMACOTHER, V112, DOI 10.1016/j.biopha.2019.01.039; Yazdanian M, 2021, MINI-REV MED CHEM, V21, P899, DOI 10.2174/1389557520666201124143449; Yelick PC, 2019, J DENT RES, V98, P1173, DOI 10.1177/0022034519861903; Yu P, 2022, ADV MATER, V34, DOI 10.1002/adma.202107922; Zamudio-Ceja RB, 2023, J FUNCT BIOMATER, V14, DOI 10.3390/jfb14050252; Zawadzka-Knefel A, 2023, FRONT BIOENG BIOTECH, V11, DOI 10.3389/fbioe.2023.1254506; Zhang DW, 2018, BIOACT MATER, V3, P129, DOI 10.1016/j.bioactmat.2017.08.004; Zhang L, 2023, INT J BIOL MACROMOL, V253, DOI 10.1016/j.ijbiomac.2023.126960; Zhang YZ, 2008, BIOMATERIALS, V29, P4314, DOI 10.1016/j.biomaterials.2008.07.038	169	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	6							2270	10.3390/app14062270	http://dx.doi.org/10.3390/app14062270			22	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	MD9O6		gold			2024-07-03	WOS:001191807800001
J	Jung, H; Kim, KJ				Jung, Hoyoun; Kim, Kyung-Joong			Discrete Prompt Compression With Reinforcement Learning	IEEE ACCESS			English	Article						Training; Task analysis; Optimization; Closed box; Computational efficiency; Chatbots; Reinforcement learning; Large language models; Application programming interfaces; prompt compression; reinforcement learning; computational efficiency; black-box APIs		Compressed prompts aid instruction-tuned language models (LMs) in overcoming context window limitations and reducing computational costs. Existing methods, which are primarily based on training embeddings, face various challenges associated with interpretability, the fixed number of embedding tokens, reusability across different LMs, and inapplicability when interacting with black-box APIs. This study proposes prompt compression with reinforcement learning (PCRL), which is a discrete prompt compression method that addresses these issues. The proposed PCRL method utilizes a computationally efficient policy network that edits prompts directly. The training approach employed in the proposed PCRLs can be applied flexibly to various types of LMs, including both decoder-only and encoder-decoder architecture and it can be trained without gradient access to the LMs or labeled data. The proposed PCRL achieves an average reduction of 24.6% in terms of the token count across various instruction prompts while maintaining sufficient performance. In addition, we demonstrate that the learned policy can be transferred to larger LMs, and through a comprehensive analysis, we explore the token importance within the prompts. The source code is available at https://github.com/nenomigami/PromptCompressor.	[Jung, Hoyoun; Kim, Kyung-Joong] Gwangju Inst Sci & Technol, Sch Integrated Technol, Gwangju 61005, South Korea	Gwangju Institute of Science & Technology (GIST)	Kim, KJ (corresponding author), Gwangju Inst Sci & Technol, Sch Integrated Technol, Gwangju 61005, South Korea.	kjkim@gist.ac.kr			Culture, Sports and Tourism R&D Program through the Korea Creative Content Agency	Culture, Sports and Tourism R&D Program through the Korea Creative Content Agency	No Statement Available	Bird S., 2009, NATURAL LANGUAGE PRO; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chevalier A, 2023, Arxiv, DOI arXiv:2305.14788; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Deng M., 2022, PROC EMNLP, P3369; Falcon LLM Team, 2023, Arxiv, DOI [arXiv:2311.16867, DOI 10.48550/ARXIV.2311.16867]; Ghalandari DG, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1267; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Haarnoja T, 2017, PR MACH LEARN RES, V70; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Kordi Yeganeh, 2022, P 2022 C EMPIRICAL M, P5085; Laban P., 2020, P 58 ANN M ASS COMP, P5135, DOI DOI 10.18653/V1/2020.ACL-MAIN.460; Laban P., 2021, arXiv; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li YC, 2023, Arxiv, DOI arXiv:2304.12102; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Lu T., 2010, P 13 INT C ARTIFICIA, V9, P485; Mu J, 2024, Arxiv, DOI arXiv:2304.08467; Narayan S, 2018, Arxiv, DOI [arXiv:1802.08636, DOI 10.48550/ARXIV.1802.08636]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Prasad A, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3845; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sanh Victor, 2022, INT C LEARNING REPRE; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schumann Raphael, 2020, P 58 ANN M ASS COMP, P5032, DOI 10.18653/v1/2020.acl-main.452; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang JA, 2023, Arxiv, DOI arXiv:2303.04048; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Webson A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2300; Wei J., 2021, P INT C LEARN REPR; Wingate M., 2022, FINDINGS ASS COMPUTA, P5621; Zhang X., 2022, P 11 INT C LEARN REP; Zhou JW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5101; Zhou Y., 2022, P 11 INT C LEARN REP	40	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						72578	72587		10.1109/ACCESS.2024.3403426	http://dx.doi.org/10.1109/ACCESS.2024.3403426			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	SQ6D0		Green Submitted, gold			2024-07-03	WOS:001235947000001
J	Haq, I; Qiu, WD; Guo, J; Tang, P				Haq, Ijazul; Qiu, Weidong; Guo, Jie; Tang, Peng			Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT	PEERJ COMPUTER SCIENCE			English	Article						BERT; Large language models; Low-resource languages; NLP; Offensive language detection; Pashto; Social media; Osn; Text processing; LLMs		Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: "offensive"and "not offensive". To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%.	[Haq, Ijazul; Qiu, Weidong; Guo, Jie; Tang, Peng] Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China	Shanghai Jiao Tong University	Haq, I (corresponding author), Shanghai Jiao Tong Univ, Sch Cyber Sci & Engn, Shanghai, Minhang, Peoples R China.	hanjie@sjtu.edu.cn	Haq, Ijazul/HKV-9993-2023	Haq, Ijazul/0000-0002-5594-7504				Alakrot A, 2018, PROCEDIA COMPUT SCI, V142, P315, DOI 10.1016/j.procs.2018.10.491; Benítez-Andrades JA, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.906; Ali R, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101365; Allan James., 2013, Constitutional Commentary, V29, P59; Alsafari Safa, 2020, Online Social Networks and Media, DOI 10.1016/j.osnem.2020.100096; Althobaiti MJ, 2022, INT J ADV COMPUT SC, V13, P972; Anand M, 2023, THEOR COMPUT SCI, V943, P203, DOI 10.1016/j.tcs.2022.06.020; Aragon M. E., 2019, IBERLEF SEPLN, P478; Ataei TS, 2023, IEEE T AFFECT COMPUT, V14, P2787, DOI 10.1109/TAFFC.2022.3219229; Basile Valerio, 2019, P 13 INT WORKSHOP SE, P54, DOI [DOI 10.18653/V1/S19-2007, 10.18653/v1/S19-2007]; Pereira-Kohatsu JC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214654; Chen Y, 2012, PROCEEDINGS OF 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON PRIVACY, SECURITY, RISK AND TRUST AND 2012 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM/PASSAT 2012), P71, DOI 10.1109/SocialCom-PASSAT.2012.55; Cohen-Almagor R, 2011, POLICY INTERNET, V3, DOI 10.2202/1944-2866.1059; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Dadvar Maral, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P693, DOI 10.1007/978-3-642-36973-5_62; Davidson Thomas, 2017, 11 INT AAAI C WEB SO; Del Vigna12 F., 2017, P 1 ITALIAN C CYBERS, P86; Deng JW, 2022, Arxiv, DOI arXiv:2201.06025; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; El-Alami FZ, 2022, J KING SAUD UNIV-COM, V34, P6048, DOI 10.1016/j.jksuci.2021.07.013; Haq I, 2023, SPEECH COMMUN, V153, DOI 10.1016/j.specom.2023.102970; Haq I, 2023, INT J ADV COMPUT SC, V14, P1344; Husain F, 2022, INT CONF ASIAN LANG, P196, DOI 10.1109/IALP57159.2022.9961263; Hussain S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1169; Ibrohim MO, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P46; Iqbal S, 2022, J INTERNET TECHNOL, V23, P1669, DOI 10.53106/160792642022122307021; Jay T, 2008, J POLITENESS RES-LAN, V4, P267, DOI 10.1515/JPLR.2008.013; Khan S, 2022, J KING SAUD UNIV-COM, V34, P4335, DOI 10.1016/j.jksuci.2022.05.006; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Kumar R., 2018, P 1 WORKSH TROLL AGG, P1; Lepe-Faúndez M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210706; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Machová K, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176468; Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584; Mazari AC, 2024, CLUSTER COMPUT, V27, P325, DOI 10.1007/s10586-022-03956-x; Min CR, 2023, INFORM FUSION, V96, P214, DOI 10.1016/j.inffus.2023.03.015; Mubarak H, 2017, ALW@ACL; Ozberk Anil, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P517, DOI 10.1109/UBMK52708.2021.9559000; Pitenis Z, 2020, Arxiv, DOI arXiv:2003.07459; Raj C, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222810; Ranasinghe Tharindu, 2021, Transactions on Asian and Low-Resource Language Information Processing; Risch J., 2021, P GERMEVAL 2021 SHAR, P1; Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Subramanian M, 2022, COMPUT SPEECH LANG, V76, DOI 10.1016/j.csl.2022.101404; Vasantharajan C., 2022, SN Comput Sci, V3, P1, DOI DOI 10.1007/S42979-021-00977-Y; Wadud MAH, 2023, COMPUT SYST SCI ENG, V44, P1775, DOI 10.32604/csse.2023.027841; Zampieri M, 2019, Arxiv, DOI [arXiv:1902.09666, 10.48550/ARXIV.1902.09666]	48	2	2	1	4	PEERJ INC	LONDON	341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND		2376-5992		PEERJ COMPUT SCI	PeerJ Comput. Sci.	OCT 18	2023	9								e1617	10.7717/peerj-cs.1617	http://dx.doi.org/10.7717/peerj-cs.1617			26	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	U9CW2	38077561	gold			2024-07-03	WOS:001087716100002
J	Rodriguez, D; del Alamo, JM; Fernández-Aller, C; Sadeh, N				Rodriguez, David; del Alamo, Jose M.; Fernandez-Aller, Celia; Sadeh, Norman			Sharing is Not Always Caring: Delving Into Personal Data Transfer Compliance in Android Apps	IEEE ACCESS			English	Article						Android; compliance assessment; data protection; data transfer; dynamic analysis; GDPR; large language model; personal data; privacy policy; third-party		In an era marked by ubiquitous reliance on mobile applications for nearly every need, the opacity of apps' behavior poses significant threats to their users' privacy. Although major data protection regulations require apps to disclose their data practices transparently, previous studies have pointed out difficulties in doing so. To further delve into this issue, this article describes an automated method to capture data-sharing practices in Android apps and assess their proper disclosure according to the EU General Data Protection Regulation. We applied the method to 9,000 random Android apps, unveiling an uncomfortable reality: over 80% of Android applications that transfer personal data off device potentially fail to meet GDPR transparency requirements. We further investigate the role of third-party libraries, shedding light on the source of this problem and pointing towards measures to address it.	[Rodriguez, David; del Alamo, Jose M.] Univ Politecn Madrid, ETSI Telecomunicac, Madrid 28040, Spain; [Fernandez-Aller, Celia] UNED Madrid, CA, Madrid 28040, Spain; [Sadeh, Norman] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Universidad Politecnica de Madrid; Universidad Nacional de Educacion a Distancia (UNED); Carnegie Mellon University	del Alamo, JM (corresponding author), Univ Politecn Madrid, ETSI Telecomunicac, Madrid 28040, Spain.	jm.delalamo@upm.es	Rodriguez, David/JXL-7010-2024; del Álamo, José/A-4121-2009; FERNANDEZ ALLER, MARIA CELIA/F-4018-2016	del Álamo, José/0000-0002-6513-0303; Rodriguez Torrado, David/0000-0002-0911-4608; FERNANDEZ ALLER, MARIA CELIA/0000-0002-0642-2058	Ministerio de Ciencia e Innovacin (MCIN)/Agencia Estatal de Investigacin (AEI)/10.13039/501100011033	Ministerio de Ciencia e Innovacin (MCIN)/Agencia Estatal de Investigacin (AEI)/10.13039/501100011033	No Statement Available	Andow B, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P985; [Anonymous], 2023, Views from Southern Europe, P1; [Anonymous], 2023, Crunchbase; Apple Developer, App Privacy Details-App Store; Backes M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P356, DOI 10.1145/2976749.2978333; Binns R, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3176246; Cheng H., 2022, P CHIN AUT C CAC NOV, P5053, DOI [10.1109/CAC57257.2022.10054907, DOI 10.1109/CAC57257.2022.10054907]; Choi JH, 2022, J LEGAL EDUC, V71, P387; Court of Justice of the European Union, 2023, RW v Osterreichische Post AGCase C-154/21; Del Alamo JM, 2022, COMPUTING, V104, P2053, DOI 10.1007/s00607-022-01076-3; E. Commission, 2018, Article29-Transparency Guidelines; EUR-Lex, 2016, EUR-Lex-32016R0679-EN; European Commission, 2018, Guidelines on Transparency Under Regulation 2016/679 (wp260rev.01); European Data Protection Board, 2023, Guidelines 01/2022 on Data Subject Rights-Right of Access; European Data Protection Board, 2022, Binding Decision 4/2022 on the Dispute Submitted by the Irish SA on Meta Platforms Ireland Limited and its Instagram Service (Art. 65 GDPR); Ferrara P., 2018, P IT C CYB, P1; Frida, 2023, A World-Class Dynamic Instrumentation Framework; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; github, 2023, MyTracker Android SDK; Goddard M, 2017, INT J MARKET RES, V59, P703, DOI 10.2501/IJMR-2017-050; Google Android Developers, 2023, UI/Application Exerciser Monkey; Google Play Store, Google Play SDK Index; Google Play Store Support, 2023, Google Play's Data Safety Section; Guamán DS, 2023, COMPUT SECUR, V130, DOI 10.1016/j.cose.2023.103262; Han S., 2012, Tech. Rep. UW-CSE-12-03; He YZ, 2019, J INF SECUR APPL, V46, P259, DOI 10.1016/j.jisa.2019.03.014; Hoofnagle CJ, 2019, INF COMMUN TECHNOL L, V28, P65, DOI 10.1080/13600834.2019.1573501; Hu W., 2014, P 2014 ACM C SECURIT, P141, DOI DOI 10.1145/2627393.2627404; Information Commissioner's Office, 2020, Data Protection Act 2018. Enforcement Powers of the Information Commissioner. Penalty Notice; Jain A, 2023, Security and Privacy, P94, DOI 10.1109/EuroSPW59978.2023.00016; Jia QW, 2019, LECT NOTES COMPUT SC, V11604, P137, DOI 10.1007/978-3-030-23597-0_11; Kelley PG., 2013, P SIGCHI C HUM FACT, P3393, DOI DOI 10.1145/2470654.2466466; Khandelwal R, 2023, Arxiv, DOI arXiv:2306.08111; Kollnig K, 2021, PROCEEDINGS OF THE SEVENTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2021), P181; Li L, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P403, DOI 10.1109/SANER.2016.52; Libert T., 2015, International Journal of Communication; Ma Z, 2016, 2016 IEEE/ACM 38TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING COMPANION (ICSE-C), P653, DOI 10.1145/2889160.2889178; Maven Repository, 2023, about us; Montani Ines, 2023, Zenodo, DOI 10.5281/ZENODO.8225292; Morel Victor, 2020, WPES'20: Proceedings of the 19th Workshop on Privacy in the Electronic Society, P41, DOI 10.1145/3411497.3420216; Novovic M., 2022, J. Data Protection Privacy, V5, P267; Patel P, 2018, INT WORKSH AUTOMAT, P34, DOI 10.1145/3194733.3194742; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Rodriguez David, 2024, Computing, V106, P163, DOI 10.1007/s00607-023-01209-2; Rodriguez D, 2023, Security and Privacy, P150, DOI 10.1109/EuroSPW59978.2023.00022; Schindler C., 2022, P7 INT C MOB SEC SER, P1, DOI [10.1109/mobisecserv50855.2022.9727217, DOI 10.1109/MOBISECSERV50855.2022.9727217]; Square I., 2019, Okhttp; Tan ZY, 2023, PROC INT CONF SOFTW, P473, DOI 10.1109/ICSE48619.2023.00050; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Vallina-Rodriguez N, 2016, Arxiv, DOI arXiv:1609.07190; Wang H., 2015, P 2015 INT S SOFTW T, P71, DOI [10.1145/2771783.2771795, DOI 10.1145/2771783.2771795]; Yu ZH, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P121, DOI 10.1145/2872427.2883028; Zhang JX, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P55, DOI 10.1145/3293882.3330563; Zheng HZ, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23009	54	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						5256	5269		10.1109/ACCESS.2024.3349425	http://dx.doi.org/10.1109/ACCESS.2024.3349425			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	EZ4L2		Green Accepted, gold			2024-07-03	WOS:001142745000001
C	Belfathi, A; Hernandez, N; Monceaux, L		Spanakis, J; VanDijck, G; Sileno, G		Belfathi, Anas; Hernandez, Nicolas; Monceaux, Laura			Harnessing GPT-3.5-Turbo for Rhetorical Role Prediction in Legal Cases	LEGAL KNOWLEDGE AND INFORMATION SYSTEMS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	36th Annual International Conference on Legal Knowledge and Information Systems (JURIX)	DEC 18-20, 2023	Maastricht Univ, Maastricht, NETHERLANDS	JURIX Fdn Legal Knowledge Based Syst	Maastricht Univ	rhetorical role prediction; legal domain; case law; in-context learning; prompt engineering; generative large language model; gpt-3.5-turbo		We propose a comprehensive study of one-stage elicitation techniques for querying a large pre-trained generative transformer (GPT-3.5-turbo) in the rhetorical role prediction task of legal cases. This task is known as requiring textual context to be addressed. Our study explores strategies such as zero-few shots, task specification with definitions and clarification of annotation ambiguities, textual context and reasoning with general prompts and specific questions. We show that the number of examples, the definition of labels, the presentation of the (labelled) textual context and specific questions about this context have a positive influence on the performance of the model. Given non-equivalent test set configurations, we observed that prompting with a few labelled examples from direct context can lead the model to a better performance than a supervised fined-tuned multi-class classifier based on the BERT encoder (weighted F1 score of approximate to 72%). But there is still a gap to reach the performance of the best systems approximate to 86%) in the LegalEval 2023 task which, on the other hand, require dedicated resources, architectures and training.	[Belfathi, Anas; Hernandez, Nicolas; Monceaux, Laura] Nantes Univ, Ecole Cent Nantes, CNRS, LS2N,UMR 6004, Nantes, France	Nantes Universite; Ecole Centrale de Nantes; Centre National de la Recherche Scientifique (CNRS)	Belfathi, A (corresponding author), Nantes Univ, Ecole Cent Nantes, CNRS, LS2N,UMR 6004, Nantes, France.				l'Agence Nationale de la Recherche (ANR) [ANR-22-CE38-0004]	l'Agence Nationale de la Recherche (ANR)(Agence Nationale de la Recherche (ANR))	This research was funded, in whole or in part, by l'Agence Nationale de la Recherche (ANR), project ANR-22-CE38-0004.	Belfathi A, 2023, P 6 WORKSH AUT SEM A, P19; Brack A, 2022, ACM-IEEE J CONF DIG, DOI 10.1145/3529372.3530922; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Diao S, 2023, Active prompting with chain-ofthought for large language models; Fu Y, 2023, 11 INT C LEARN REPR; Huang J, 2023, FINDINGS ASS COMPUTA, P1049, DOI [DOI 10.18653/V1/2023.FINDINGS-ACL.67, 10.18653/v1/2023.findings-acl.67]; Huo J, 2023, P 17 INT WORKSH SEM, P402; Kalamkar P, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4420; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Lomeli M, 2023, Transactions on Machine Learning Research; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Malik V, 2022, P NATURAL LEGAL LANG, P153; Modi A, 2023, P 17 INT WORKSH SEM, P2362; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Qiao SF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5368; Savelka J, 2023, P 6 WORKSH AUT SEM A, P1; Savelka J, 2023, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023, P447, DOI 10.1145/3594536.3595161; Wei J., 2021, FINETUNED LANGUAGE M; Wei JS, 2022, ADV NEUR IN; Wei JH, 2022, PR MACH LEARN RES; Ye S, 2023, In-Context Instruction Learning; Ye Xi, 2022, Advances in neural information processing systems, V35, P30378; Yu F., 2023, FINDINGS ASS COMPUTA, P13582; Zhao TZ, 2021, PR MACH LEARN RES, V139	25	0	0	2	2	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-472-7; 978-1-64368-473-4	FRONT ARTIF INTEL AP			2023	379						187	196		10.3233/FAIA230964	http://dx.doi.org/10.3233/FAIA230964			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Information Science & Library Science; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science; Government & Law	BW6JJ		Green Submitted, hybrid			2024-07-03	WOS:001175464100024
C	Mohapatra, B			ACM	Mohapatra, Biswesh			Conversational Grounding in Multimodal Dialog Systems	PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023			English	Proceedings Paper	25th International Conference on Multimodal Interaction (ICMI)	OCT 09-13, 2023	Sorbonne Univ, Paris, FRANCE	Assoc Comp Machinery, ACM SIGCHI, Openstreams Ai, Living & Learning Lab Neurodevelopment, CCC Comp Community Consortium Catalyst, AFIHM, Persyval Lab, Grenoble Informat Lab, Univ Grenoble Alpes, Sorbonne Ctr Artificial Intelligence	Sorbonne Univ	Multimodal Dialog Systems; Large Language Models; Conversational Grounding; Reference Resolution		The process of "conversational grounding" is an interactive process that has been studied extensively in cognitive science, whereby participants in a conversation check to make sure their interlocutors understand what is being referred to. This interactive process uses multiple modes of communication to establish the information between the participants. This could include information provided through eye-gaze, head movements, intonation in speech, along with the content of the speech. While the process is essential to successful communication between humans and between humans and machines, work needs to be done on testing and building the capabilities of the current dialogue system in managing conversational grounding, especially in multimodal medium of communication. Recent work such as Benotti and Blackburn [3] have shown the importance of conversational grounding in dialog systems and how current systems fail in them which is essential for the advancement of Embodied Conversational Agents and Social Robots. Thus my Ph.D. project aims to test, understand and improve the functioning of current dialog models with respect to Conversational Grounding.	[Mohapatra, Biswesh] INRIA, Paris, Ile De France, France	Inria	Mohapatra, B (corresponding author), INRIA, Paris, Ile De France, France.	biswesh.mohapatra@inria.fr			CORDI-S	CORDI-S	This research was funded by CORDI-S to which I am grateful for the opportunity. I would also like to thank my doctoral advisors Prof. Justine Cassell and Dr. laurent Romary for their constant support and feedback. I would also like to express my sincere gratitude to the members of the ArticuLab at Inria Paris for their invaluable assistance in my PhD journey.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bara CP, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1112; Benotti L, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P515; CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006; CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1207/s15516709cog1302_7; Denis Alexandre, 2010, P 6 INT NATURAL LANG; Fried D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2130; Grosz Aravind Joshi Barbara, 1986, Towards a computational theory of discourse interpretation; Grosz B. J., 1983, 21st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, P44; Ilinykh Nikolai, 2019, P 23 WORKSHOP SEMANT; Kontogiorgos D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.623657; Kontogiorgos D, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P414, DOI 10.1145/3340555.3353722; Lopes Jose, 2018, P 11 INT C LANGUAGE; Nakano YI, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P553; OpenAI, 2022, Introducing chatgpt; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Paek Tim, 2000, P 16 C UNC ART INT, P455; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Peng Baolin, 2022, arXiv; Raffel C, 2020, J MACH LEARN RES, V21; Roque Antonio, 2008, WORKSHOP SIGDIAL; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Traum David, 1994, A "Speech Acts" Approach To Grounding In Conversation; Traum David Rood, 1995, UMI Order No. GAX95-23171	24	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0055-2				2023							706	710		10.1145/3577190.3614226	http://dx.doi.org/10.1145/3577190.3614226			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GP		Green Published			2024-07-03	WOS:001147764700083
C	Wei, XK; Gonugondla, SK; Wang, SQ; Ahmad, W; Ray, B; Qian, HF; Li, XP; Kumar, V; Wang, ZJ; Tian, YC; Sun, Q; Athiwaratkun, B; Shang, MY; Ramanathan, MK; Bhatia, P; Xiang, B		Chandra, S; Blincoe, K; Tonella, P		Wei, Xiaokai; Gonugondla, Sujan Kumar; Wang, Shiqi; Ahmad, Wasi; Ray, Baishakhi; Qian, Haifeng; Li, Xiaopeng; Kumar, Varun; Wang, Zijian; Tian, Yuchen; Sun, Qing; Athiwaratkun, Ben; Shang, Mingyue; Ramanathan, Murali Krishna; Bhatia, Parminder; Xiang, Bing			Towards Greener Yet Powerful Code Generation via Quantization: An Empirical Study	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Quantization; Code Generation; Large Language Models; Generative AI; Model Hosting		ML-powered code generation aims to assist developers to write code in a more productive manner by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have pushed the boundary of code generation and achieved impressive performance.] However, the huge number of model parameters poses a significant challenge to their adoption in a typical software development environment, where a developer might use a standard laptop or mid-size server to develop code. Such large models cost significant resources in terms of memory, latency, dollars, as well as carbon footprint. Model compression is a promising approach to address these challenges. We have identified quantization as one of the most promising compression techniques for code-generation as it avoids expensive retraining costs. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit.] We empirically evaluate quantized models on code generation tasks across different dimensions: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. Through systematic experiments we find a code-aware quantization recipe that could run even a 6-billion-parameter model in a regular laptop without significant accuracy or robustness degradation. We find that the recipe is readily applicable to code summarization task as well.	[Wei, Xiaokai; Gonugondla, Sujan Kumar; Wang, Shiqi; Ahmad, Wasi; Ray, Baishakhi; Qian, Haifeng; Li, Xiaopeng; Kumar, Varun; Wang, Zijian; Tian, Yuchen; Sun, Qing; Athiwaratkun, Ben; Shang, Mingyue; Ramanathan, Murali Krishna; Bhatia, Parminder; Xiang, Bing] AWS AI Labs, Palo Alto, CA 94303 USA		Wei, XK (corresponding author), AWS AI Labs, Palo Alto, CA 94303 USA.	xiaokaiw@amazon.com; gsujan@amazon.com; wshiqi@amazon.com; wuahmad@amazon.com; rabaisha@amazon.com; qianhf@amazon.com; xiaopel@amazon.com; kuvrun@amazon.com; zijwan@amazon.com; tiayuche@amazon.com; qinsun@amazon.com; benathi@amazon.com; myshang@amazon.com; mkraman@amazon.com; parmib@amazon.com; bxiang@amazon.com	Xiao Peng, LI/AAZ-6199-2021; Tian, Yuchen/AAM-4917-2021; Gonugondla, Sujan Kumar/U-2067-2019	Wang, Shiqi/0000-0002-6338-1432; Qian, Haifeng/0000-0002-7189-6903; Gonugondla, Sujan Kumar/0000-0003-4743-6461				Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Alzantot M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2890; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bondarenko Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7947; Chen M., 2021, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dhole KD, 2022, Arxiv, DOI arXiv:2112.02721; Ebrahimi J, 2018, Arxiv, DOI arXiv:1712.06751; Fay MP, 2010, STAT SURV, V4, P1, DOI 10.1214/09-SS051; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P50, DOI 10.1109/SPW.2018.00016; Goel K, 2021, Arxiv, DOI arXiv:2101.04840; Han WJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2327; Henderson P, 2020, J MACH LEARN RES, V21; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Kulal S, 2019, ADV NEUR IN, V32; Lagunas F, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10619; Le H, 2022, Arxiv, DOI arXiv:2207.01780; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li Z, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P203; Li Zhenhao, 2019, Improving neural machine translation robustness via data augmentation: beyond back translation. arXiv preprint arXiv:1910.03009; 2019; Lin C.-Y., 2004, COLING 2004, P501, DOI DOI 10.3115/1220355.1220427; Ma L, 2018, IEEE INT CONF AUTOM, P120, DOI 10.1145/3238147.3238202; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI GitHub, 2022, GitHub Copilot.; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ren SH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1085; Roziere B., 2020, Advances in neural information processing systems, V33, P20601; Sakr C, 2017, PR MACH LEARN RES, V70; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Sugiyama Amane., 2019, P 4 WORKSHOP DISCOUR, P35, DOI 10.18653/v1/D19-6504; Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158; Tao CF, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4821; Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220; Wang Fusheng, 2021, P ANN M ASS COMPUTAT, V1, P6456; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wang Z, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6151; X MZ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1513; Morris JX, 2020, Arxiv, DOI arXiv:2005.05909; Xiao G., 2023, INT C MACHINE LEARNI, P38087; Yao Z., 2022, Advances in Neural Information Processing Systems, V35, P27168; Zang Y, 2020, P 58 ANN M ASS COMP, P6066, DOI DOI 10.18653/V1/2020.ACL-MAIN.540; Zhang JM, 2022, IEEE T SOFTWARE ENG, V48, P1, DOI 10.1109/TSE.2019.2962027; Zhang W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P509; Zhang YX, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3993	50	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							224	236		10.1145/3611643.3616302	http://dx.doi.org/10.1145/3611643.3616302			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Bronze			2024-07-03	WOS:001148157800020
J	Croft, J; Gao, LY; Sheng, V; Zhang, J				Croft, Jacob; Gao, Liyuan; Sheng, Victor; Zhang, Jun			Deep-Learning Uncovers certain CCM Isoforms as Transcription Factors	FRONTIERS IN BIOSCIENCE-LANDMARK			English	Article						cerebral cavernous malformations; CCM2 isoforms; transcription factors; deep-learning; Evolutionary Scale Modeling; Large Language Model; Support Vector Machine; Biased SVM model	PROTEIN-STRUCTURE; PATHOGENESIS; KRIT1; NETWORK; CANCER	Background: Cerebral Cavernous Malformations (CCMs) are brain vascular abnormalities associated with an increased risk of hemorrhagic strokes. Familial CCMs result from autosomal dominant inheritance involving three genes: KRIT1 (CCM1), MGC4607 (CCM2), and PDCD10 (CCM3). CCM1 and CCM3 form the CCM Signal Complex (CSC) by binding to CCM2. Both CCM1 and CCM2 exhibit cellular heterogeneity through multiple alternative spliced isoforms, where exons from the same gene combine in diverse ways, leading to varied mRNA transcripts. Additionally, both demonstrate nucleocytoplasmic shuttling between the nucleus and cytoplasm, suggesting their potential role in gene expression regulation as transcription factors (TFs). Due to the accumulated data indicating the cellular localization of CSC proteins in the nucleus and their interaction with progesterone receptors, which serve dual roles as both cellular signaling components and TFs, a question has arisen regarding whether CCMs could also function in both capacities like progesterone receptors. Methods: To investigate this potential, we employed our proprietary deep-learning (DL)-based algorithm, specifically utilizing a biasedSupport Vector Machine (SVM) model, to explore the plausible cellular function of any of the CSC proteins, particularly focusing on CCM gene isoforms with nucleocytoplasmic shuttling, acting as TFs in gene expression regulation. Results: Through a comparative DL-based predictive analysis, we have effectively discerned a collective of 11 isoforms across all CCM proteins (CCM1-3). Additionally, we have substantiated the TF functionality of 8 isoforms derived from CCM1 and CCM2 proteins, marking the inaugural identification of CCM isoforms in the role of TFs. Conclusions: This groundbreaking discovery directly challenges the prevailing paradigm, which predominantly emphasizes the involvement of CSC solely in endothelial cellular functions amid various potential cellular signal cascades during angiogenesis.	[Croft, Jacob; Zhang, Jun] TTUHSCEP, Dept Mol & Translat Med MTM, El Paso, TX 79905 USA; [Gao, Liyuan; Sheng, Victor] Texas Tech Univ, Dept Comp Sci, Lubbock, TX 79409 USA	Texas Tech University System; Texas Tech University	Zhang, J (corresponding author), TTUHSCEP, Dept Mol & Translat Med MTM, El Paso, TX 79905 USA.	jun.zhang2000@gmail.com	Zhang, Jun/G-9091-2017; Croft, Jacob R/JDD-7285-2023	Zhang, Jun/0000-0002-4379-3616; Croft, Jacob R/0000-0001-7892-0534				Abou-Fadel J, 2022, CANCER BIOMARK, V34, P607, DOI 10.3233/CBM-210351; Aickareth J, 2023, MEMBRANES-BASEL, V13, DOI 10.3390/membranes13030260; AlQuraishi M, 2021, CURR OPIN CHEM BIOL, V65, P1, DOI 10.1016/j.cbpa.2021.04.005; Anil BC, 2022, International Journal of Cloud Applications and Computing (IJCAC), V12, P13; Avraham Orly, 2023, BMC Bioinformatics, V24, P433, DOI 10.1186/s12859-023-05549-w; Biswas N, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.588221; Buehler MJ, 2022, ACCOUNTS CHEM RES, V55, P3387, DOI 10.1021/acs.accounts.2c00330; Cao P, 2013, An Optimized Cost-Sensitive SVM for Imbalanced Data Learning, DOI [10.1007/978-3-642-37456-2_24, DOI 10.1007/978-3-642-37456-2_24]; Croft J, 2023, bioRxiv; Ding K, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1113402; Faurobert E, 2013, J CELL BIOL, V202, P545, DOI 10.1083/jcb.201303044; Ferruz N, 2023, COMPUT STRUCT BIOTEC, V21, P238, DOI 10.1016/j.csbj.2022.11.014; Flores JE, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1098308; Francalanci F, 2009, EXP CELL RES, V315, P285, DOI 10.1016/j.yexcr.2008.10.006; Gao Liyuan, 2023, 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P853, DOI 10.1109/BIBM58861.2023.10385498; Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011; He XJ, 2023, SEMIN CANCER BIOL, V88, P187, DOI 10.1016/j.semcancer.2022.12.009; Hu M., 2023, arXiv; Jiang XT, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52386-0; Khoudja MA, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297042; Kim GB, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2021171118; Koo PK, 2020, CURR OPIN SYST BIOL, V19, P16, DOI 10.1016/j.coisb.2020.04.001; Kumar Krishna, 2023, Methods Mol Biol, V2634, P139, DOI 10.1007/978-1-0716-3008-2_6; Lee NK, 2023, GENOME BIOL, V24, DOI 10.1186/s13059-023-02941-w; Li RF, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab460; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Liu HL, 2011, J VASC RES, V48, P130, DOI 10.1159/000316851; Liu HL, 2010, TRANSL STROKE RES, V1, P146, DOI 10.1007/s12975-010-0010-z; Liu RW, 2023, IEEE T IND INFORM, V19, P1581, DOI 10.1109/TII.2022.3170594; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Majdandzic Antonio, 2022, Proc Mach Learn Res, V200, P131; Mardikoraem M, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad358; Picard M, 2021, COMPUT STRUCT BIOTEC, V19, P3735, DOI [10.1016/j.csbj.2021.06.0302001-0370/, 10.1016/j.csbj.2021.06.030]; Pokharel S, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242116000; Retta SF, 2004, GENE, V325, P63, DOI 10.1016/j.gene.2003.09.046; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Sgarbossa D, 2023, ELIFE, V12, DOI 10.7554/eLife.79854; Shen Z, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33321-1; Wang Y, 2023, ARXIV; Wu F, 2023, COMMUN BIOL, V6, DOI 10.1038/s42003-023-05133-1; Wu IW, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00713-7; Xie WJ, 2023, bioRxiv; Yue TW, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242115858; Zhang J, 2001, HUM MOL GENET, V10, P2953, DOI 10.1093/hmg/10.25.2953; Zhang J, 2001, AM J HUM GENET, V69, P178; Zhang J, 2008, NEUROSURGERY, V63, P571, DOI 10.1227/01.NEU.0000325255.30268.B0; Zhang J, 2007, NEUROSURGERY, V60, P353, DOI 10.1227/01.NEU.0000249268.11074.83; Zhang Q, 2023, PATTERN RECOGN LETT, V168, P31, DOI 10.1016/j.patrec.2023.02.026	48	0	0	0	0	IMR PRESS	ROBINSON	112 ROBINSON RD, ROBINSON, SINGAPORE	2768-6701	2768-6698		FRONT BIOSCI-LANDMRK	Front. Biosci.	FEB	2024	29	2							75	10.31083/j.fbl2902075	http://dx.doi.org/10.31083/j.fbl2902075			8	Biochemistry & Molecular Biology; Cell Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology	JU3J6	38420834	gold			2024-07-03	WOS:001175634000029
J	Hirani, R; Farabi, B; Marmon, S				Hirani, Rahim; Farabi, Banu; Marmon, Shoshana			Experimenting with ChatGPT: Concerns for academic medicine	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Letter						academic publishing; artificial intelli-gence (AI); ChatGPT; dermatology journals; gender bias; large language model; machine learning; racial bias; scientific integrity			[Farabi, Banu; Marmon, Shoshana] New York Med Coll, Valhalla, NY USA; [Farabi, Banu; Marmon, Shoshana] NYC Hlth Hosp, Metropolitan Med Ctr, Dept Dermatol, New York, NY USA; [Marmon, Shoshana] NYC Hlth Hosp South Brooklyn Hlth, Ruth Bader Ginsburg Hosp, Dept Med, Brooklyn, NY USA; [Marmon, Shoshana] NYC Hlth Hosp South Brooklyn Hlth, Ruth Bader Ginsburg Hosp, Dept Med, 2601 Ocean Pkwy, Brooklyn, MD 11235 USA	New York Medical College	Marmon, S (corresponding author), NYC Hlth Hosp South Brooklyn Hlth, Ruth Bader Ginsburg Hosp, Dept Med, 2601 Ocean Pkwy, Brooklyn, MD 11235 USA.	Shoshana.Marmon@nychhc.org	Hirani, Rahim/HKV-4353-2023	Hirani, Rahim/0000-0002-9304-9916				[Anonymous], 2022, UCL News; Bolukbasi T, 2016, ADV NEUR IN, V29; Daneshjou R, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq6147; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Sample I. In: I S S, 2023, GUARDIAN	5	8	8	12	30	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	SEP	2023	89	3					E127	E129		10.1016/j.jaad.2023.04.045	http://dx.doi.org/10.1016/j.jaad.2023.04.045		AUG 2023	3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	R7QL3	37179029				2024-07-03	WOS:001066263300001
J	Bokolo, BG; Liu, QZ				Bokolo, Biodoumoye George; Liu, Qingzhong			Deep Learning-Based Depression Detection from Social Media: Comparative Evaluation of ML and Transformer Techniques	ELECTRONICS			English	Article						depression detection; social media analysis; deep learning models; NLP techniques; user tweets; mental health identification; sentiment analysis; large language models	FUTURE	Detecting depression from user-generated content on social media platforms has garnered significant attention due to its potential for the early identification and monitoring of mental health issues. This paper presents a comprehensive approach for depression detection from user tweets using machine learning techniques. The study utilizes a dataset of 632,000 tweets and employs data preprocessing, feature selection, and model training with logistic regression, Bernoulli Naive Bayes, random forests, DistilBERT, SqueezeBERT, DeBERTA, and RoBERTa models. Evaluation metrics such as accuracy, precision, recall, and F1 score are employed to assess the models' performance. The results indicate that the RoBERTa model achieves the highest accuracy ratio of 0.981 and the highest mean accuracy of 0.97 (across 10 cross-validation folds) in detecting depression from tweets. This research demonstrates the effectiveness of machine learning and advanced transformer-based models in leveraging social media data for mental health analysis. The findings offer valuable insights into the potential for early detection and monitoring of depression using online platforms, contributing to the growing field of mental health analysis based on user-generated content.	[Bokolo, Biodoumoye George; Liu, Qingzhong] Sam Houston State Univ, Dept Comp Sci, Huntsville, TX 77341 USA	Texas State University System; Sam Houston State University	Bokolo, BG (corresponding author), Sam Houston State Univ, Dept Comp Sci, Huntsville, TX 77341 USA.	bgb023@shsu.edu; qxl005@shsu.edu		Bokolo, Biodoumoye/0000-0003-2327-6109				Aggarwal C.C., 2018, Neural Networks and Deep Learning: A Textbook, P399; Alfarizi M.I., 2022, JUITA J. Inform, V10, P225, DOI [10.30595/juita.v10i2.13262, DOI 10.30595/JUITA.V10I2.13262]; Association A. P., 1994, Diagnostic and statistical manual of mental disorders: DSM-IV, V4; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Coppersmith G., 2014, P WORKSH COMP LING C, P51, DOI [10.3115/v1/w14-3207, DOI 10.3115/V1/W14-3207]; De Choudhury M., 2013, P INT AAAI C WEB SOC, V7, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998]; Garron A., 2013, P C EMPIRICAL METHOD, P1146; Gkotsis G, 2017, SCI REP-UK, V7, DOI 10.1038/srep45141; Golrooy Motlagh F., 2022, Ph.D. Thesis; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005; Hassani H, 2020, BIG DATA COGN COMPUT, V4, DOI 10.3390/bdcc4010001; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Huang L., 2009, P INT C MACH LEARN M, VVolume 3, P1; Iandola F. N., 2020, arXiv; Jain S, 2023, MARK INTELL PLAN, V41, P156, DOI 10.1108/MIP-05-2022-0207; Jo T., 2021, Machine Learning Foundations, DOI DOI 10.1007/978-3-030-65900-4; Kim P., 2017, MATLAB deep learning: with machine learning, neural networks and artificial intelligence, P121, DOI [DOI 10.1007/978-1-4842-2845-6, 10.1007/978-1-4842-2845-66]; Kingma D. P., 2017, ARXIV; Lepine Jean-Pierre, 2011, Neuropsychiatr Dis Treat, V7, P3, DOI 10.2147/NDT.S19617; Li A, 2018, J AFFECT DISORDERS, V232, P358, DOI 10.1016/j.jad.2018.02.087; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; McCallum A, 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; Mylonas P, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P46, DOI 10.1109/SMAP.2016.7753383; Nesi Jacqueline, 2020, N C Med J, V81, P116, DOI 10.18043/ncm.81.2.116; Nguyen D.P., 2014, P 8 INT C WEBLOGS SO, P308; PYSZCZYNSKI T, 1987, J PERS SOC PSYCHOL, V52, P994, DOI 10.1037/0022-3514.52.5.994; Russell SJ., 2016, ARTIF INTELL; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sarvani K., 2021, J. Eng. Sci, V12, P531; SHORE JE, 1981, IEEE T INFORM THEORY, V27, P472, DOI 10.1109/TIT.1981.1056373; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Tsugawa S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3187, DOI 10.1145/2702123.2702280; WHO, 2017, Other Common Mental Disorders: Global Health Estimates, VVolume 24; Yazdavar Amir Hossein, 2017, Proc IEEE ACM Int Conf Adv Soc Netw Anal Min, V2017, P1191, DOI 10.1145/3110025.3123028	35	1	1	10	12	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	NOV	2023	12	21							4396	10.3390/electronics12214396	http://dx.doi.org/10.3390/electronics12214396			20	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	X7QQ9		gold			2024-07-03	WOS:001100355700001
C	Zhang, YF; Towey, D; Pike, M		Shahriar, H; Teranishi, Y; Cuzzocrea, A; Sharmin, M; Towey, D; Majumder, AKMJA; Kashiwazaki, H; Yang, JJ; Takemoto, M; Sakib, N; Banno, R; Ahamed, SI		Zhang, Yifan; Towey, Dave; Pike, Matthew			Automated Metamorphic-Relation Generation with ChatGPT: An Experience Report	2023 IEEE 47TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE, COMPSAC	Proceedings International Computer Software and Applications Conference		English	Proceedings Paper	47th IEEE-Computer-Society Annual International Conference on Computers, Software, and Applications (COMPSAC)	JUN 27-29, 2023	Univ Torino, Torino, ITALY	IEEE, IEEE Comp Soc	Univ Torino	Autonomous driving system (ADS); metamorphic testing (MT); metamorphic relation (MR); oracle problem; ChatGPT; natural language processing (NLP); large language model (LLM)		This paper reports on a pilot study of using ChatGPT, a language model based on GPT-3.5 architecture, for automatic generation of metamorphic relations (MRs), in the context of testing of autonomous driving systems (ADSs). The oracle problem is a major challenge in testing such systems, where it is difficult to determine whether or not the output of a system is correct. Metamorphic testing (MT) can alleviate this problem by checking the consistency of the system's outputs under various transformations. However, manual generation of MRs is often a time-consuming and error-prone process. Automated MR generation can yield several benefits, including enhanced efficiency, quality, coverage, scalability, and reusability in software testing, thereby facilitating a more comprehensive and effective testing process. In this paper, we investigate the effectiveness of using ChatGPT for automatic generation of MRs for ADSs. We provide a detailed methodology for generating MRs using ChatGPT and evaluate the generated MRs using our domain knowledge and existing MRs. The results of our study indicate that our proposed approach is effective at generating high-quality MRs, and can significantly reduce the manual effort required for MR generation. Furthermore, we discuss the practical implications and limitations of using ChatGPT for MR generation and provide recommendations for future research. Our study contributes to the advancement of automated testing of ADSs, which is crucial for ensuring their safety and reliability in real-world scenarios.	[Zhang, Yifan; Towey, Dave; Pike, Matthew] Univ Nottingham Ningbo China, Sch Comp Sci, Ningbo 315100, Zhejiang, Peoples R China	University of Nottingham Ningbo China	Towey, D (corresponding author), Univ Nottingham Ningbo China, Sch Comp Sci, Ningbo 315100, Zhejiang, Peoples R China.	yifan.zhang@nottingham.edu.cn; dave.towey@nottingham.edu.cn; matthew.pike@nottingham.edu.cn	; Towey, Dave/K-3160-2014	Zhang, Yifan/0000-0003-1289-2192; Towey, Dave/0000-0003-0877-4353	Artificial Intelligence and Optimisation (AIOP) research groups; Sensors, Sensor Networks and Instrumentation (SSNI) research group; Faculty of Science and Engineering (FoSE); International Doctoral Innovation Centre; Ningbo Education Bureau; Ningbo Science and Technology Bureau; University of Nottingham	Artificial Intelligence and Optimisation (AIOP) research groups; Sensors, Sensor Networks and Instrumentation (SSNI) research group; Faculty of Science and Engineering (FoSE); International Doctoral Innovation Centre; Ningbo Education Bureau; Ningbo Science and Technology Bureau; University of Nottingham	The authors acknowledge the financial support from the Artificial Intelligence and Optimisation (AIOP) and Sensors, Sensor Networks and Instrumentation (SSNI) research groups, the Faculty of Science and Engineering (FoSE), the International Doctoral Innovation Centre, Ningbo Education Bureau, Ningbo Science and Technology Bureau, and the University of Nottingham.	[Anonymous], 2014, P 29 ACMIEEE INT C A, DOI [doi:10.1145/2642937.2642994, DOI 10.1145/2642937.2642994]; Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816; Barr ET, 2015, IEEE T SOFTWARE ENG, V41, P507, DOI 10.1109/TSE.2014.2372785; Carzaniga A, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P931, DOI 10.1145/2568225.2568287; Chen TY, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3143561; Chen TY, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5314-x; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Harman M., 2015, 2015 IEEE 8 INT C SO, P1; Kanewala U, 2013, PROC INT SYMP SOFTW, P1, DOI 10.1109/ISSRE.2013.6698899; Krogmeier P, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3563348; Liu H, 2014, IEEE T SOFTWARE ENG, V40, P4, DOI 10.1109/TSE.2013.46; Mahmood Z, 2019, IET INTELL TRANSP SY, V13, P293, DOI 10.1049/iet-its.2018.5021; OpenAI, 2022, OpenA I; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Rudolph J, 2023, Journal of Applied Learning and Teaching, V6; Segura S, 2016, IEEE T SOFTWARE ENG, V42, P805, DOI 10.1109/TSE.2016.2532875; Zhang YF, 2022, IEEE GLOB ENG EDUC C, P2121, DOI 10.1109/EDUCON52537.2022.9766791; Zhou ZQ, 2020, IEEE T SOFTWARE ENG, V46, P1120, DOI 10.1109/TSE.2018.2876433; Zhou ZQ, 2019, COMMUN ACM, V62, P61, DOI 10.1145/3241979	20	1	1	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0730-3157		979-8-3503-2697-0	P INT COMP SOFTW APP			2023							1780	1785		10.1109/COMPSAC57700.2023.00275	http://dx.doi.org/10.1109/COMPSAC57700.2023.00275			6	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5CB					2024-07-03	WOS:001046484100265
C	Vijayakumar, S; Louis, F		Sheng, VS; Hicks, C; Ling, C; Raghavan, V; Wu, X		Vijayakumar, Senthilkumar; Louis, Filious			Revolutionizing Staffing and Recruiting with Contextual Knowledge Graphs and QNLP: An End-to-End Quantum Training Paradigm	2023 IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH, ICKG			English	Proceedings Paper	14th IEEE International Conference on Knowledge Graph (IEEE ICKG)	DEC 01-02, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Minist Educ China, Key Lab Knowledge Engn Big Data, Hefei Univ Technol, Anhui Assoc Artificial Intelligence, Inspur Co Ltd		Artificial Intelligence (AI); Knowledge Graph (KG); Quantum Natural Language Processing (QNLP); Large Language Models (LLM); Contextual Information Extraction & Retrieval Systems		The staffing and recruiting industry is continuously evolving, and recent advancements in Knowledge Graphs (KG) and Quantum Natural Language Processing (QNLP) has garnered considerable attention. The integration of these state-of-the-art technologies is fueled by the necessity to improve language models' capacity to comprehend context and make precise decisions. This research paper presents a novel approach to revolutionize the staffing and recruiting industry by integrating Knowledge Graph (KG) and Quantum Natural Language Processing (QNLP) to formulate an end-to-end QNLP training pipeline. The proposed solution consists of three interdependent subsystems that work in unison to construct contextual KG and train language models. The Information Extraction subsystem extracts semantic relationships and connections between entities from large and complex recruitment data to construct domain specific contextual KG. The QNLP model training pipeline subsystem, which is fed with domain-rich KG data, runs on Quantum Circuits, accelerates the training process by effectively incorporating high-dimensional features to the deep layers of language models. Finally, the Information Retrieval subsystem is based on semantic data taxonomy, retrieving contextual data from the KG for the trained language models to be implemented on various distinctive use cases in the staffing and recruiting industry. This solution provides a faster and more contextual approach to analyze recruitment data, empowering recruiters to concentrate on strategic tasks such as candidate engagement and client relationship building, ultimately leading to better business decision-making capabilities.				senthil.vijayakumar@ieee.com; filious.louis@ieee.com						Chen S, 2020, AAAI CONF ARTIF INTE, V34, P7529; Fan Miao, 2014, P 28 PACIFIC ASIA C, P328; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Kartsaklis D, 2021, Arxiv, DOI arXiv:2110.04236; Le Du S, 2022, Arxiv, DOI arXiv:2202.11766; Moon C, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2215, DOI 10.1145/3132847.3133095; Neelakantan A, 2015, NAACL, P515; Paulheim H, 2013, LECT NOTES COMPUT SC, V8218, P510, DOI 10.1007/978-3-642-41335-3_32; Rossanez A, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01341-5; Verma S, 2023, COMPLEX INTELL SYST, V9, P1059, DOI 10.1007/s40747-022-00806-6; Xie RB, 2016, AAAI CONF ARTIF INTE, P2659; Yang B., 2014, arXiv; Zhao Y., 2020, ACL, P6419; Zhou DZR, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P5074, DOI 10.1145/3511808.3557214; Zhu Q, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2241, DOI 10.1145/3366423.3380289	15	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0709-2				2023							45	51		10.1109/ICKG59574.2023.00011	http://dx.doi.org/10.1109/ICKG59574.2023.00011			7	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5RD					2024-07-03	WOS:001166570200006
J	Heidari, A; Navimipour, NJ; Zeadally, S; Chamola, V				Heidari, Arash; Navimipour, Nima Jafari; Zeadally, Sherali; Chamola, Vinay			Everything you wanted to know about ChatGPT: Components, capabilities, applications, and opportunities	INTERNET TECHNOLOGY LETTERS			English	Letter; Early Access						ChatGPT; conversational artificial intelligence; deep learning; generative pre-trained transformer; large language models; natural language processing; self-attention mechanisms		Conversational Artificial Intelligence (AI) and Natural Language Processing have advanced significantly with the creation of a Generative Pre-trained Transformer (ChatGPT) by OpenAI. ChatGPT uses deep learning techniques like transformer architecture and self-attention mechanisms to replicate human speech and provide coherent and appropriate replies to the situation. The model mainly depends on the patterns discovered in the training data, which might result in incorrect or illogical conclusions. In the context of open-domain chats, we investigate the components, capabilities constraints, and potential applications of ChatGPT along with future opportunities. We begin by describing the components of ChatGPT followed by a definition of chatbots. We present a new taxonomy to classify them. Our taxonomy includes rule-based chatbots, retrieval-based chatbots, generative chatbots, and hybrid chatbots. Next, we describe the capabilities and constraints of ChatGPT. Finally, we present potential applications of ChatGPT and future research opportunities. The results showed that ChatGPT, a transformer-based chatbot model, utilizes encoders to produce coherent responses.	[Heidari, Arash] Halic Univ, Dept Software Engn, Istanbul, Turkiye; [Heidari, Arash] Istanbul Atlas Univ, Fac Engn & Nat Sci, Dept Comp Engn, Istanbul, Turkiye; [Navimipour, Nima Jafari] Kadir Has Univ, Fac Engn & Nat Sci, Dept Comp Engn, TR-34083 Istanbul, Turkiye; [Navimipour, Nima Jafari] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu, Taiwan; [Zeadally, Sherali] Univ Kentucky, Coll Commun & Informat, Lexington, KY USA; [Chamola, Vinay] Birla Inst Technol & Sci BITS, Pilani, India	Halic University; Istanbul Atlas University; Kadir Has University; National Yunlin University Science & Technology; University of Kentucky; Birla Institute of Technology & Science Pilani (BITS Pilani)	Navimipour, NJ (corresponding author), Kadir Has Univ, Fac Engn & Nat Sci, Dept Comp Engn, TR-34083 Istanbul, Turkiye.	nima.navimipour@khas.edu.tr	Heidari, Arash/AAK-9761-2021	Heidari, Arash/0000-0003-4279-8551				Amin MM, 2023, IEEE INTELL SYST, V38, P15, DOI 10.1109/MIS.2023.3254179; Benaddi Lamya, 2024, Procedia Computer Science, V231, P275, DOI 10.1016/j.procs.2023.12.203; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Herbold Steffen, 2023, Sci Rep, V13, P18617, DOI 10.1038/s41598-023-45644-9; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kshetri N, 2023, IT PROF, V25, P16, DOI 10.1109/MITP.2023.3254639; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Lu QH, 2023, IEEE INTELL SYST, V38, P42, DOI 10.1109/MIS.2023.3320437; Moore RJ, 2023, HUM-COMPUT INTERACT, V38, P168, DOI 10.1080/07370024.2022.2081571; OpenAi, ChatGPT; Payne EHM., 2024, Comput Hum Behav, V2; Peyton K, 2023, RESULTS ENG, V17, DOI 10.1016/j.rineng.2022.100856; Prabhakar GA, 2023, IEEE T CONSUM ELECTR, V69, P226, DOI 10.1109/TCE.2023.3236972; Shoufan A, 2023, IEEE ACCESS, V11, P38805, DOI 10.1109/ACCESS.2023.3268224; Wang FY, 2023, IEEE T COMPUT SOC SY, V10, P414, DOI 10.1109/TCSS.2023.3252679; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Zhang J., 2023, HiVeGPT: humanmachineaugmented intelligent vehicles with generative pretrained transformer; Zhang Y, 2023, IEEE COMPUT INTELL M, V18, P68, DOI 10.1109/MCI.2022.3223487	20	0	0	0	0	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND		2476-1508		INTERNET TECHNOL LET	Internet. Technol. Lett.	2024 MAY 30	2024										10.1002/itl2.530	http://dx.doi.org/10.1002/itl2.530		MAY 2024	6	Telecommunications	Emerging Sources Citation Index (ESCI)	Telecommunications	SP9G0					2024-07-03	WOS:001235765500001
C	Goyal, S; Rastogi, E; Rajagopal, SP; Yuan, D; Zhao, F; Chintagunta, J; Naik, G; Ward, J			Assoc computing machinery	Goyal, Sagar; Rastogi, Eti; Rajagopal, Sree Prasanna; Yuan, Dong; Zhao, Fen; Chintagunta, Jai; Naik, Gautam; Ward, Jeff			HealAI: A Healthcare LLM for Effective Medical Documentation	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Large language models; medical note writing; EHR; healthcare; domain-specific LLM; prompt engineering; medical domain; finetuning; retrieval; pretraining; long context LLM		Since the advent of LLM's like GPT4 everyone in various industries has been trying to harness their power. Healthcare is an industry where this is a specifically challenging problem due to the high accuracy requirements. Prompt Engineering is a common technique used to design instructions for model responses, however, its challenges lie in the fact that the generic models may not be trained to accurately execute these specific tasks. We will present our journey of developing a cost-effective medical LLM, surpassing GPT4 in medical note-writing tasks. We'll touch upon our trials with medical prompt engineering, GPT4's limitations, and training an optimized LLM for specific medical tasks. We'll showcase multiple comparisons on model sizes, training data, and pipeline designs that enabled us to outperform GPT4 with smaller models, maintaining precision, reducing biases, preventing hallucinations, and enhancing note-writing style.	[Goyal, Sagar; Rastogi, Eti; Rajagopal, Sree Prasanna; Yuan, Dong; Zhao, Fen; Chintagunta, Jai; Naik, Gautam; Ward, Jeff] DeepScribe Inc, San Francisco, CA 94105 USA		Goyal, S (corresponding author), DeepScribe Inc, San Francisco, CA 94105 USA.	sagar@deepscribe.tech; eti@deepscribe.tech; sree@deepscribe.tech; dong@deepscribe.tech; fen@deepscribe.tech; jai@deepscribe.tech; gautam@deepscribe.tech; jeffw@deepscribe.tech						Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Podder Sassan Ghassemzadeh Vivek, 2022, SOAP Notes; Rastogi Eti, 2023, Overcoming Hallucinations and Biases in LLM: A Step Towards Reliable Medical Application; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Wang BX, 2024, Arxiv, DOI [arXiv:2310.07713, 10.48550/arXiv.2310.07713]; Wei JS, 2022, ADV NEUR IN; Xu P, 2024, Arxiv, DOI [arXiv:2310.03025, 10.48550/arXiv.2310.03025]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206	9	0	0	19	19	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1167	1168		10.1145/3616855.3635739	http://dx.doi.org/10.1145/3616855.3635739			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100151
J	Markos, A; Prentzas, J; Sidiropoulou, M				Markos, Angelos; Prentzas, Jim; Sidiropoulou, Maretta			Pre-Service Teachers' Assessment of ChatGPT's Utility in Higher Education: SWOT and Content Analysis	ELECTRONICS			English	Article						large language models; generative AI; AI literacy; primary education; early childhood education; knowledge extraction; e-learning; clustering; decision trees; educational robotics		ChatGPT (GPT-3.5), an intelligent Web-based tool capable of conducting text-based conversations akin to human interaction across various subjects, has recently gained significant popularity. This surge in interest has led researchers to examine its impact on numerous fields, including education. The aim of this paper is to investigate the perceptions of undergraduate students regarding ChatGPT's utility in academic environments, focusing on its strengths, weaknesses, opportunities, and threats. It responds to emerging challenges in educational technology, such as the integration of artificial intelligence in teaching and learning processes. The study involved 257 students from two university departments in Greece-namely primary and early childhood education pre-service teachers. Data were collected using a structured questionnaire. Various methods were employed for data analysis, including descriptive statistics, inferential analysis, K-means clustering, and decision trees. Additional insights were obtained from a subset of students who undertook a project in an elective course, detailing the types of inquiries made to ChatGPT and their reasons for recommending (or not recommending) it to their peers. The findings offer valuable insights for tutors, researchers, educational policymakers, and ChatGPT developers. To the best of the authors' knowledge, these issues have not been dealt with by other researchers.	[Markos, Angelos] Democritus Univ Thrace, Dept Primary Educ, Nea Chili 68131, Alexandroupoli, Greece; [Prentzas, Jim; Sidiropoulou, Maretta] Democritus Univ Thrace, Dept Educ Sci Early Childhood, Nea Chili 68131, Alexandroupoli, Greece	Democritus University of Thrace; Democritus University of Thrace	Markos, A (corresponding author), Democritus Univ Thrace, Dept Primary Educ, Nea Chili 68131, Alexandroupoli, Greece.	amarkos@eled.duth.gr; dprentza@psed.duth.gr; masidiro@psed.duth.gr	Markos, Angelos/N-9310-2013	Markos, Angelos/0000-0002-4204-3573				Alabool Hamzeh Mohammad, 2023, 2023 International Conference on Information Technology (ICIT), P184, DOI 10.1109/ICIT58056.2023.10225801; Aljawarneh SA, 2020, J COMPUT HIGH EDUC, V32, DOI 10.1007/s12528-019-09207-0; Alnajjar F., 2021, Robots in Education: An Introduction to High-Tech Social Agents, Intelligent Tutors, and Curricular Tools; Atkinson Beth, 2023, CRAN; Biggs J, 2001, BRIT J EDUC PSYCHOL, V71, P133, DOI 10.1348/000709901158433; Blau I, 2017, EDUC INF TECHNOL, V22, P769, DOI 10.1007/s10639-015-9456-7; Bozkurt A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020800; Chamorro-Atalaya O., 2023, Int. J. Learn. Teach. Educ. Res, V22, P281, DOI [10.26803/ijlter.22.7.15, DOI 10.26803/IJLTER.22.7.15]; Chan CKY, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00408-3; Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510; Chrysafiadi K, 2012, EXPERT SYST APPL, V39, P13127, DOI 10.1016/j.eswa.2012.05.089; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Hinojo-Lucena FJ, 2019, EDUC SCI, V9, DOI 10.3390/educsci9010051; Ismail F., 2023, J. App. Learn. Teach, V6, P56, DOI [10.37074/jalt.2023.6.2.34, DOI 10.37074/JALT.2023.6.2.34]; Karipidis N, 2016, INTED PROC, P8456; Khowaja SA, 2024, Arxiv, DOI arXiv:2305.03123; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727; Maher D, 2009, BRIT MED J, V339, DOI 10.1136/bmj.b4037; Mai DTT, 2024, FRONT EDUC, V9, DOI 10.3389/feduc.2024.1328769; Mesiono M., 2024, J. Manaj. Kepemimp. Dan Supervisi Pendidik, V9, P181; Mhlanga D., Open AI in Education, the Responsible and Ethical Use of ChatGPT towards Lifelong Learning; Milborrow S., Plot Rpart Models: An Enhanced Version of Plot.rpart; Murad I.A., 2023, Int. J. Inf. Technol. Comput. Eng, V3, P20, DOI [10.55529/ijitc.35.20.25, DOI 10.55529/IJITC.35.20.25]; Ng D.T.K., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100041; Perikos I, 2017, INT J ARTIF INTELL E, V27, P475, DOI 10.1007/s40593-017-0139-y; Prentzas J., 2023, 2023 14 INT C INF IN, P1, DOI [10.1109/IISA59645.2023.10345910, DOI 10.1109/IISA59645.2023.10345910]; Prentzas J., 2023, Lecture Notes in Networks and Systems; Prentzas Jim., 2013, Artificial Intelligence, Evolutionary Computing and Metaheuristics, V427, P169, DOI [10.1007/978-3-642-29694-98, DOI 10.1007/978-3-642-29694-98]; Puyt RW, 2023, LONG RANGE PLANN, V56, DOI 10.1016/j.lrp.2023.102304; Santiago-Ruiz E., 2023, Int. J. Educ. Dev. Using Inf. Commun. Technol, V19, P28; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Vargas-Murillo A. R., 2023, Int. J. Learn. Teach. Educ. Res, V22, P122, DOI [10.26803/ijlter.22.7.7, DOI 10.26803/IJLTER.22.7.7]; Wang YM, 2021, EDUC TECHNOL SOC, V24, P116; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhu CJ, 2023, KNOWL MANAG E-LEARN, V15, P133, DOI 10.34105/j.kmel.2023.15.008	38	0	0	10	10	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	MAY	2024	13	10							1985	10.3390/electronics13101985	http://dx.doi.org/10.3390/electronics13101985			23	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	SF5M3		gold			2024-07-03	WOS:001233055100001
J	Kheddar, H; Himeur, Y; Al-Maadeed, S; Amira, A; Bensaali, F				Kheddar, Hamza; Himeur, Yassine; Al-Maadeed, Somaya; Amira, Abbes; Bensaali, Faycal			Deep transfer learning for automatic speech recognition: Towards better generalization	KNOWLEDGE-BASED SYSTEMS			English	Article						Automatic speech recognition; Deep transfer learning; Fine-tuning; Domain adaptation; Models fusion; Large language model; semantic knowledge. Acoustic model (AM) processing includes	DOMAIN ADAPTATION; NEURAL-NETWORK; MODELS; CLASSIFICATION; LIGHTWEIGHT; MULTITASK; ATTACKS; SEARCH; JOINT; TEXT	Automatic speech recognition (ASR) has recently become an important challenge when using deep learning (DL). It requires large-scale training datasets and high computational and storage resources. Moreover, DL techniques and machine learning (ML) approaches in general, hypothesize that training and testing data come from the same domain, with the same input feature space and data distribution characteristics. This assumption, however, is not applicable in some real-world artificial intelligence (AI) applications. Moreover, there are situations where gathering real data is challenging, expensive, or rarely occurring, which cannot meet the data requirements of DL models. deep transfer learning (DTL) has been introduced to overcome these issues, which helps develop high-performing models using real datasets that are small or slightly different but related to the training data. This paper presents a comprehensive survey of DTL-based ASR frameworks to shed light on the latest developments and helps academics and professionals understand current challenges. Specifically, after presenting the DTL background, a well-designed taxonomy is adopted to inform the state-of-the-art. A critical analysis is then conducted to identify the limitations and advantages of each framework. Moving on, a comparative study is introduced to highlight the current challenges before deriving opportunities for future research.(c) 2023 Elsevier B.V. All rights reserved.	[Kheddar, Hamza] Univ Medea, Elect Engn Dept, LSEA Lab, Medea, Algeria; [Himeur, Yassine] Univ Dubai, Coll Engn & Informat Technol, Dubai, U Arab Emirates; [Himeur, Yassine; Al-Maadeed, Somaya] Qatar Univ, Comp Sci & Engn, Doha, Qatar; [Amira, Abbes] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates; [Amira, Abbes] De Montfort Univ, Inst Artificial Intelligence, Leicester, England; [Bensaali, Faycal] Qatar Univ, Dept Elect Engn, Doha, Qatar	Universite Yahia Fares Medea; University of Dubai; Qatar University; University of Sharjah; De Montfort University; Qatar University	Kheddar, H (corresponding author), Univ Medea, Elect Engn Dept, LSEA Lab, Medea, Algeria.	kheddar.hamza@univ-medea.dz; yhimeur@ud.ac.ae; s_alali@qu.edu.qa; aamira@sharjah.ac.ae; f.bensaali@qu.edu.qa	Kheddar, Hamza/D-7154-2017; Himeur, Yassine/AAK-7814-2021	Kheddar, Hamza/0000-0002-9532-2453; Himeur, Yassine/0000-0001-8904-5587				Abdullah Hadi, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P712, DOI 10.1109/SP40001.2021.00009; Ahmed S, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2703; Alasbahi R, 2022, IEEE ACCESS, V10, P46697, DOI 10.1109/ACCESS.2022.3171569; Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x; Almadhor A, 2023, EXPERT SYST APPL, V222, DOI 10.1016/j.eswa.2023.119797; Alyafeai Z, 2020, Arxiv, DOI arXiv:2007.04239; Ananthram A, 2020, Arxiv, DOI arXiv:2011.07065; Anoop CS, 2023, EXPERT SYST APPL, V220, DOI 10.1016/j.eswa.2023.119722; Arefeen MA, 2021, IEEE INT CONF BIG DA, P978, DOI 10.1109/BigData52589.2021.9671723; Arora P, 2017, IEEE INT WORKSH MULT; Arumugam K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237793; Azizah K, 2020, IEEE ACCESS, V8, P179798, DOI 10.1109/ACCESS.2020.3027619; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Bai Y, 2021, IEEE-ACM T AUDIO SPE, V29, P1897, DOI 10.1109/TASLP.2021.3082299; Bashath S, 2022, INFORM SCIENCES, V585, P498, DOI 10.1016/j.ins.2021.11.061; Biswas A., 2020, arXiv; Boateng G, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P17, DOI 10.1145/3395035.3425253; Boes W, 2021, INTERSPEECH, P2401, DOI 10.21437/Interspeech.2021-695; Boulares M, 2020, IEEE ACCESS, V8, P109475, DOI 10.1109/ACCESS.2020.3002151; Bousmalis K, 2016, ADV NEUR IN, V29; Braunschweiler N, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P24, DOI 10.1109/ASRU51503.2021.9687987; Bu J., 2023, Ph.D. thesis; Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009; Carr T, 2021, INVEST OPHTH VIS SCI, V62; Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621; Chaspari T., 2019, IEEE INT WORKS MACH, P1, DOI DOI 10.1109/mlsp.2019.8918833; Chatziagapi A, 2022, INT CONF AFFECT, DOI 10.1109/ACII55700.2022.9953889; Chen C, 2019, AAAI CONF ARTIF INTE, P3296; Chen HL, 2020, INTERSPEECH, P2312, DOI 10.21437/Interspeech.2020-2787; Chen XZ, 2019, IEICE T INF SYST, VE102D, P2632, DOI 10.1587/transinf.2019EDL8038; Chen YC, 2020, Arxiv, DOI arXiv:2005.07029; Chen YP, 2018, IEEE ACCESS, V6, P61305, DOI 10.1109/ACCESS.2018.2876122; Chen ZH, 2018, IEEE-ACM T AUDIO SPE, V26, P184, DOI 10.1109/TASLP.2017.2765834; Cheng KM, 2023, INT J SURG, V109, P1545, DOI 10.1097/JS9.0000000000000388; Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105; Cho J, 2018, IEEE W SP LANG TECH, P521, DOI 10.1109/SLT.2018.8639655; Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3; Copiaco A, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105775; Das B, 2018, INT J BIOMETEOROL, V62, P1809, DOI 10.1007/s00484-018-1583-6; Deena S, 2019, IEEE-ACM T AUDIO SPE, V27, P572, DOI 10.1109/TASLP.2018.2888814; Delfosse A, 2020, FRONT ARTIF INTEL AP, V325, P2972, DOI 10.3233/FAIA200471; Deng KQ, 2022, INT CONF ACOUST SPEE, P8517, DOI 10.1109/ICASSP43922.2022.9747887; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Di Gangi MA, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2012; Dong LH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5884, DOI 10.1109/ICASSP.2018.8462506; Doulaty M, 2015, Arxiv, DOI arXiv:1509.02409; Durrani S, 2021, Arxiv, DOI arXiv:2103.11764; Elaraby MS, 2016, LECT NOTES COMPUT SC, V9811, P51, DOI 10.1007/978-3-319-43958-7_5; Errattahi R, 2018, PROCEDIA COMPUT SCI, V128, P32, DOI 10.1016/j.procs.2018.03.005; Fahad MS, 2021, CIRC SYST SIGNAL PR, V40, P466, DOI 10.1007/s00034-020-01486-8; Fahmy Fady K., 2020, Artificial Neural Networks in Pattern Recognition. 9th IAPR TC3 Workshop, ANNPR 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12294), P266, DOI 10.1007/978-3-030-58309-5_22; Fan C, 2020, APPL ENERG, V262, DOI 10.1016/j.apenergy.2020.114499; Fan RC, 2022, IEEE J-STSP, V16, P1242, DOI 10.1109/JSTSP.2022.3200910; Filippidou F., 2020, ARTIF INTELL, P73, DOI [DOI 10.1007/978-3-030-49161-1_7, 10.1007/978-3-030-49161-1_7]; Ganin Y, 2016, J MACH LEARN RES, V17; Garofolo J.S., 1993, NASA STI/Recon technical report n, V93, P27403; Ghahremani P, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P279, DOI 10.1109/ASRU.2017.8268947; Glorot X., 2011, P 28 INT C MACH LEAR, P513; Gruetzemacher R, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505245; Gruzitis Normunds, 2022, Intelligent Sustainable Systems: Selected Papers of WorldS4 2021. Lecture Notes in Networks and Systems (333), P267, DOI 10.1007/978-981-16-6309-3_27; Han Z., 2023, IEEE Trans Cogn Dev Syst; Haneche H, 2021, CIRC SYST SIGNAL PR, V40, P5106, DOI 10.1007/s00034-021-01712-x; Harati A., 2022, Biomedical Sensing and Analysis: Signal Processing in Medicine and Biology, P99; Harati A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7273, DOI 10.1109/ICASSP39728.2021.9414208; Hartmann W, 2017, INT CONF ACOUST SPEE, P5765, DOI 10.1109/ICASSP.2017.7953261; Hassan MA, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/6825555; Hazarika D, 2021, INFORM FUSION, V65, P1, DOI 10.1016/j.inffus.2020.06.005; He KQ, 2020, IEEE ACCESS, V8, P29407, DOI 10.1109/ACCESS.2020.2972925; Hentschel M, 2018, ASIAPAC SIGN INFO PR, P1692, DOI 10.23919/APSIPA.2018.8659468; Hettiarachchi R, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401093; Himeur Y, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11020107; Himeur Y, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105698; Himeur Y, 2022, SUSTAIN CITIES SOC, V85, DOI 10.1016/j.scs.2022.104059; Himeur Y, 2022, INT J INTELL SYST, V37, P7124, DOI 10.1002/int.22876; Himeur Y, 2021, APPL ENERG, V287, DOI 10.1016/j.apenergy.2021.116601; Hires M, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105021; Hong QY, 2017, SPEECH COMMUN, V92, P90, DOI 10.1016/j.specom.2017.05.004; Hu A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03542-w; Hu MZ, 2023, Arxiv, DOI arXiv:2304.04920; Hu SS, 2019, IEEE COMMUN MAG, V57, P120, DOI 10.1109/MCOM.2019.1900006; Hu WZ, 2019, BUILDSYS'19: PROCEEDINGS OF THE 6TH ACM INTERNATIONAL CONFERENCE ON SYSTEMS FOR ENERGY-EFFICIENT BUILDINGS, CITIES, AND TRANSPORTATION, P61, DOI 10.1145/3360322.3360843; Huang Z, 2015, Arxiv, DOI arXiv:1503.02108; Huang Z, 2016, NEUROCOMPUTING, V218, P448, DOI 10.1016/j.neucom.2016.09.018; Huzaifah Muhammad, 2023, 2022 IEEE Spoken Language Technology Workshop (SLT), P747, DOI 10.1109/SLT54892.2023.10023147; Ilk G.H., 2022, 2022 7 INT C IM SIGN, P1; Incahuanaco-quispe Filomen, 2022, Information Management and Big Data: 8th Annual International Conference, SIMBig 2021, Proceedings. Communications in Computer and Information Science (1577), P340, DOI 10.1007/978-3-031-04447-2_23; Winata GI, 2019, Arxiv, DOI arXiv:1909.08582; Jain R, 2022, IEEE ACCESS, V10, P47628, DOI 10.1109/ACCESS.2022.3170836; Jha D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13297-w; Jia Y., 2018, arXiv; Jiang D, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3447687; Kadyan V, 2022, NEURAL COMPUT APPL, V34, P21015, DOI 10.1007/s00521-022-07579-6; Karaman O, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115013; Karita S, 2019, INTERSPEECH, P1408, DOI 10.21437/Interspeech.2019-1938; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kessler S, 2022, INT CONF ACOUST SPEE, P3179, DOI 10.1109/ICASSP43922.2022.9747374; Kheddar H., 2018, 2018 INT C APPL SMAR, P1; Kheddar H, 2024, Arxiv, DOI arXiv:2304.10550; Kheddar H, 2022, APPL INTELL, V52, P9441, DOI 10.1007/s10489-021-02938-7; Kheddar H, 2019, IET SIGNAL PROCESS, V13, P396, DOI 10.1049/iet-spr.2018.5339; Khurana S, 2022, INT CONF ACOUST SPEE, P6647, DOI 10.1109/ICASSP43922.2022.9746276; Kim D, 2019, INT CONF BIG DATA, P181, DOI 10.1109/bigcomp.2019.8679150; Kim H, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1741; Kim Joo-Kyung, 2017, P 2017 C EMPIRICAL M, P2832, DOI DOI 10.18653/V1/D17-1302; Kim S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4914, DOI 10.1109/ICASSP.2018.8462201; Kirchhof M, 2021, LECT NOTES COMPUT SC, V13004, P163, DOI 10.1007/978-3-030-87672-2_11; Koike T, 2020, IEEE ENG MED BIO, P74, DOI 10.1109/EMBC44109.2020.9175450; Kubo Y, 2022, INT CONF ACOUST SPEE, P8512, DOI 10.1109/ICASSP43922.2022.9746801; Kumar A., 2021, J. Reliab. Intell. Environ., P1; Kumar GA, 2022, CIRC SYST SIGNAL PR, V41, P2152, DOI 10.1007/s00034-021-01880-w; Kumar Y, 2022, SOFT COMPUT, V26, P1003, DOI 10.1007/s00500-021-06640-1; Kwon H, 2020, IEEE T INF FOREN SEC, V15, P526, DOI 10.1109/TIFS.2019.2925452; Laskar MTR, 2023, Arxiv, DOI arXiv:2305.18486; Lee MH, 2022, INT CONF ACOUST SPEE, P8392, DOI 10.1109/ICASSP43922.2022.9747082; Lee S, 2021, AAAI CONF ARTIF INTE, V35, P8297; Li QX, 2022, 2022 13TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P21, DOI 10.1109/ISCSLP57327.2022.10037857; Li S, 2020, Arxiv, DOI arXiv:2010.11037; Li Y., 2021, Neural Comput. Appl., P1; Lin Jun., 2021, IEEE Trans. Smart Grid, P1; Lin Y, 2021, NEUROCOMPUTING, V445, P287, DOI 10.1016/j.neucom.2020.08.092; Lin YY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062477; Liu CY, 2016, PHYSIOL MEAS, V37, P2181, DOI 10.1088/0967-3334/37/12/2181; Liu DY, 2019, IEEE-CAA J AUTOMATIC, V6, P1187, DOI 10.1109/JAS.2019.1911693; Liu N, 2021, IEEE ACCESS, V9, P95925, DOI 10.1109/ACCESS.2021.3094355; Liu N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5144, DOI 10.1109/ICASSP.2018.8461848; Liu Z, 2023, Arxiv, DOI arXiv:2303.01500; Liu Ziquan, 2022, Advances in Neural Information Processing Systems, V35, P32568; Long MS, 2017, PR MACH LEARN RES, V70; Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010; Lu T, 2021, ECOL INFORM, V62, DOI 10.1016/j.ecoinf.2021.101277; Lu YK, 2021, ENERGY, V217, DOI 10.1016/j.energy.2020.119322; Luo H, 2019, INTERSPEECH, P3247, DOI 10.21437/Interspeech.2019-2041; Luo H, 2020, IEEE-ACM T AUDIO SPE, V28, P2047, DOI 10.1109/TASLP.2020.3006331; Luo W., 2022, ACM Trans. Sensor Netw., V19, P1; Luo Y, 2021, IEEE-ACM T AUDIO SPE, V29, P1752, DOI 10.1109/TASLP.2021.3078640; Ma M, 2017, INTERSPEECH, P259, DOI 10.21437/Interspeech.2017-1310; Monica GM, 2022, LECT NOTES COMPUT SC, V13258, P426, DOI 10.1007/978-3-031-06242-1_42; Malhotra S, 2021, J AMB INTEL HUM COMP, V12, P10267, DOI 10.1007/s12652-020-02800-7; Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7; Manohar V, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P346, DOI 10.1109/ASRU.2017.8268956; Markitantov Maxim, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P326, DOI 10.1007/978-3-030-60276-5_32; Medeiros E, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15050159; Meftah S., 2021, P 2 WORKSHOP DOMAIN, P140; Meghraoui D, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102604; Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424; Michelsanti D, 2021, IEEE-ACM T AUDIO SPE, V29, P1368, DOI 10.1109/TASLP.2021.3066303; Milde B, 2017, INTERSPEECH, P2536, DOI 10.21437/Interspeech.2017-1436; Mimura M, 2016, INTERSPEECH, P3803, DOI 10.21437/Interspeech.2016-388; Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705; Plaza-del-Arco FM, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114120; Mridha MF, 2022, ARTIF INTELL REV, V55, P3431, DOI 10.1007/s10462-021-10083-3; Nedjah N, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120378; Ng SI, 2020, Arxiv, DOI arXiv:2011.06239; Novoa J, 2018, COMPUT SPEECH LANG, V47, P30, DOI 10.1016/j.csl.2017.06.005; Olivieri M, 2021, IEEE INSTRU MEAS MAG, V24, P10, DOI 10.1109/MIM.2021.9549233; Padi Sarala, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P645, DOI 10.1145/3462244.3481003; Pahar M, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105153; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Parthasarathy S, 2019, Arxiv, DOI arXiv:1911.04571; Patricia N, 2014, PROC CVPR IEEE, P1442, DOI 10.1109/CVPR.2014.187; Paul A., INT ARCH PHOTOGRAMME, P845; Peng JH, 2021, IEEE T DEPEND SECURE, V18, P1962, DOI 10.1109/TDSC.2019.2946138; Qin CX, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0141-9; Qin SQ, 2022, EURASIP J AUDIO SPEE, V2022, DOI 10.1186/s13636-021-00233-4; Qing Yu, 2022, Journal of Shanghai Jiaotong University (Science), V27, P90, DOI 10.1007/s12204-021-2376-3; Qiu MH, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4075, DOI 10.1145/3459637.3481911; Ramadan R.A, 2021, Int. J. Speech Technol., P1; Ramakrishnan R., 2016, Towards interpretable explanations for transfer learning in sequential tasks; Ramirez PZ, 2019, IEEE I CONF COMP VIS, P8109, DOI 10.1109/ICCV.2019.00820; Recommendation I.-T., 2001, Rec. ITU-T P. 862; Rejaibi E, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103107; Rolland T, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P7314; Rosenstein MT, 2005, NIPS 2005 WORKSH TRA, V898, P1; Sahoo KK, 2022, IEEE ACCESS, V10, P100797, DOI 10.1109/ACCESS.2022.3208126; Sahraeian R, 2018, IEEE-ACM T AUDIO SPE, V26, P1991, DOI 10.1109/TASLP.2018.2851145; Salazar J, 2019, INT CONF ACOUST SPEE, P7115, DOI [10.1109/ICASSP.2019.8682539, 10.1109/icassp.2019.8682539]; Sancinetti M, 2022, INT CONF ACOUST SPEE, P6812, DOI 10.1109/ICASSP43922.2022.9747727; Sayed AN, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105786; Sayed AN, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105254; Sayed HM, 2023, MACH LEARN, V112, P1201, DOI 10.1007/s10994-021-06112-5; Schlotterbeck D, 2022, LECT NOTES COMPUT SC, V13355, P269, DOI 10.1007/978-3-031-11644-5_22; Schneider S., 2019, arXiv; Sch”nherr L, 2018, Arxiv, DOI arXiv:1808.05665; Schultz T, 2013, INT CONF ACOUST SPEE, P8126, DOI 10.1109/ICASSP.2013.6639248; Sertolli B, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2021.101204; Shahamiri SR, 2021, IEEE T NEUR SYS REH, V29, P852, DOI 10.1109/TNSRE.2021.3076778; Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101077; Shuteng Niu, 2020, IEEE Transactions on Artificial Intelligence, V1, P151, DOI 10.1109/TAI.2021.3054609; Siddiqui S, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206817; Sohail S.S., 2023, Curr. Chall. Possible Future Dir., V2023; Song P, 2019, IEEE T AFFECT COMPUT, V10, P265, DOI 10.1109/TAFFC.2017.2705696; Song XC, 2020, Arxiv, DOI arXiv:1910.10387; Song Y., 2019, arXiv; Song YF, 2019, INTERSPEECH, P829, DOI 10.21437/Interspeech.2019-1694; Sousa R., 2014, PROC 20 PORTUGUESE C, P57; Strzelecki A, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2209881; Subramanian V, 2020, INT CONF ACOUST SPEE, P301, DOI [10.1109/ICASSP40776.2020.9054445, 10.1109/icassp40776.2020.9054445]; Sukhadia Vrunda N., 2023, 2022 IEEE Spoken Language Technology Workshop (SLT), P295, DOI 10.1109/SLT54892.2023.10023233; Sullivan P, 2022, Arxiv, DOI arXiv:2202.05209; Sun SN, 2018, Arxiv, DOI arXiv:1806.02782; Sun SN, 2017, NEUROCOMPUTING, V257, P79, DOI 10.1016/j.neucom.2016.11.063; Tachbelie MY, 2022, SPEECH COMMUN, V140, P71, DOI 10.1016/j.specom.2022.03.006; Takashima Y, 2019, IEEE ACCESS, V7, P164320, DOI 10.1109/ACCESS.2019.2951856; Tang Y, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6209, DOI 10.1109/ICASSP39728.2021.9415058; Tendle A, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100124; Thomas B, 2022, INT CONF ACOUST SPEE, P7102, DOI 10.1109/ICASSP43922.2022.9746223; Tian XH, 2022, INTERSPEECH, P5438, DOI 10.21437/Interspeech.2022-10022; Tits N, 2018, Arxiv, DOI [arXiv:1805.09197, DOI 10.48550/ARXIV.1805.09197]; Tropea M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166292; Tüske Z, 2018, INTERSPEECH, P3358, DOI 10.21437/Interspeech.2018-2476; Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504; Turan MAT, 2021, SPEECH COMMUN, V129, P25, DOI 10.1016/j.specom.2021.02.004; ul Haque A, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P170, DOI [10.1109/ICOIN48656.2020.9016456, 10.1109/icoin48656.2020.9016456]; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; Veaux C., 2016, Cstr vctk corpus: English multi-speaker corpus for cstr voice cloning toolkit; Vryzas N, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100132; Vu L, 2020, IEEE ACCESS, V8, P107335, DOI 10.1109/ACCESS.2020.3000476; Wan ZT, 2021, NEUROCOMPUTING, V421, P1; Wang C., 2022, IEEE/ACM Trans. Audio Speech Lang. Process.; Wang D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081018; Wang JD, 2020, ACM T INTEL SYST TEC, V11, DOI [10.1177/1687814018825375, 10.1145/3360309]; Wang SC, 2020, INT CONF ACOUST SPEE, P6219, DOI [10.1109/ICASSP40776.2020.9054543, 10.1109/icassp40776.2020.9054543]; Wang XD, 2021, IEEE T IND INFORM, V17, P7725, DOI 10.1109/TII.2021.3049405; Wang ZR, 2019, PROC CVPR IEEE, P11285, DOI 10.1109/CVPR.2019.01155; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Weninger F, 2019, Arxiv, DOI arXiv:1907.04916; Winata GI, 2020, INT CONF ACOUST SPEE, P6144, DOI [10.1109/ICASSP40776.2020.9053878, 10.1109/icassp40776.2020.9053878]; Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537; Wu AN, 2020, Arxiv, DOI arXiv:2006.12124; Wu HR, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3309537; Wu QY, 2017, IEEE T KNOWL DATA EN, V29, P1494, DOI 10.1109/TKDE.2017.2685597; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xiong FF, 2020, INT CONF ACOUST SPEE, P7424, DOI [10.1109/ICASSP40776.2020.9054694, 10.1109/icassp40776.2020.9054694]; Xu QT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3030, DOI 10.1109/ICASSP39728.2021.9414641; Xu XZ, 2020, ELECTR ENG, V102, P1371, DOI 10.1007/s00202-020-00930-x; Yamni M, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103251; Yassine H., 2012, Int. J. Comput. Appl., V53, P33; Yi JY, 2020, Arxiv, DOI arXiv:2004.00248; Yi JY, 2019, IEEE-ACM T AUDIO SPE, V27, P621, DOI 10.1109/TASLP.2018.2889606; Yoon JW, 2022, IEEE W SP LANG TECH, P280, DOI 10.1109/SLT54892.2023.10022581; Yu Q, 2021, J. Shanghai Jiaotong Univ. (Science), P1; Yue Zhengjun, 2022, ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7377, DOI 10.1109/ICASSP43922.2022.9746553; Yue ZJ, 2022, IEEE-ACM T AUDIO SPE, V30, P2968, DOI 10.1109/TASLP.2022.3205766; Yusuf B, 2019, IEEE-ACM T AUDIO SPE, V27, P1126, DOI 10.1109/TASLP.2019.2911164; Zelasko P, 2021, Arxiv, DOI arXiv:2103.17122; Zelasko P, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101358; Zhang KL, 2022, INT CONF ACOUST SPEE, P6322, DOI 10.1109/ICASSP43922.2022.9746442; Zhang L, 2021, Arxiv, DOI arXiv:2106.09320; Zhang PY, 2021, IEEE ACCESS, V9, P98630, DOI 10.1109/ACCESS.2021.3095078; Zhang W., 2021, IEEE Trans. Cogn. Dev. Syst.; Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400; Zhang WJ, 2020, IEEE-ACM T AUDIO SPE, V28, P307, DOI 10.1109/TASLP.2019.2955252; Zhang W, 2021, Arxiv, DOI arXiv:2009.00909; Zhang Y., 2017, arXiv; Zhang YX, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONTROL, AND COMPUTING TECHNOLOGIES FOR SMART GRIDS (SMARTGRIDCOMM), DOI 10.1109/smartgridcomm.2019.8909793; Zhang YX, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207525; Zhao KK, 2021, LECT NOTES COMPUT SC, V12878, P466, DOI 10.1007/978-3-030-86608-2_51; Zhao PL, 2014, ARTIF INTELL, V216, P76, DOI 10.1016/j.artint.2014.06.003; Zhao W, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992835; Zhu W., 2021, INT C COGN SYST SIGN, P127; Zhu XJ, 2020, IEEE ACCESS, V8, P170991, DOI 10.1109/ACCESS.2020.3023783; Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555	263	13	13	11	14	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0950-7051	1872-7409		KNOWL-BASED SYST	Knowledge-Based Syst.	OCT 9	2023	277								110851	10.1016/j.knosys.2023.110851	http://dx.doi.org/10.1016/j.knosys.2023.110851		AUG 2023	29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z7CP8		Green Submitted			2024-07-03	WOS:001113618700001
J	Hamed, E; Sharif, A; Eid, A; Alfehaidi, A; Alberry, M				Hamed, Ehab; Sharif, Anna; Eid, Ahmad; Alfehaidi, Alanoud; Alberry, Medhat			Advancing Artificial Intelligence for Clinical Knowledge Retrieval: A Case Study Using ChatGPT-4 and Link Retrieval Plug-In to Analyze Diabetic Ketoacidosis Guidelines	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						clinical decision tool; clinical decision support system; clinical decision support; chatgpt; large language model; generative ai; artificial intelligence in medicine; chatgpt-4		Introduction This case study aimed to enhance the traceability and retrieval accuracy of ChatGPT-4 in medical text by employing a step-by-step systematic approach. The focus was on retrieving clinical answers from three international guidelines on diabetic ketoacidosis (DKA). Methods A systematic methodology was developed to guide the retrieval process. One question was asked per guideline to ensure accuracy and maintain referencing. ChatGPT-4 was utilized to retrieve answers, and the 'Link Reader' plug-in was integrated to facilitate direct access to webpages containing the guidelines. Subsequently, ChatGPT-4 was employed to compile answers while providing citations to the sources. This process was iterated 30 times per question to ensure consistency. In this report, we present our observations regarding the retrieval accuracy, consistency of responses, and the challenges encountered during the process. Results Integrating ChatGPT-4 with the 'Link Reader' plug-in demonstrated notable traceability and retrieval accuracy benefits. The AI model successfully provided relevant and accurate clinical answers based on the analyzed guidelines. Despite occasional challenges with webpage access and minor memory drift, the overall performance of the integrated system was promising. The compilation of the answers was also impressive and held significant promise for further trials. Conclusion The findings of this case study contribute to the utilization of AI text-generation models as valuable tools for medical professionals and researchers. The systematic approach employed in this case study and the integration of the 'Link Reader' plug-in offer a framework for automating medical text synthesis, asking one question at a time before compilation from different sources, which has led to improving AI models' traceability and retrieval accuracy. Further advancements and refinement of AI models and integration with other software utilities hold promise for enhancing the utility and applicability of AI-generated recommendations in medicine and scientific academia. These advancements have the potential to drive significant improvements in everyday medical practice.	[Hamed, Ehab] Qatar Univ Hlth Ctr, Primary Hlth Care Corp, Family Med, Doha, Qatar; [Sharif, Anna; Eid, Ahmad; Alfehaidi, Alanoud] Primary Hlth Care Corp, Family Med, Doha, Qatar; [Alberry, Medhat] Weill Cornell Med Qatar, Obstet & Gynecol, Doha, Qatar; [Alberry, Medhat] Sidra Med, Fetal & Maternal Med, Doha, Qatar	Hamad Medical Corporation; Primary Health Care Corporation (PHCC); Qatar University; Hamad Medical Corporation; Primary Health Care Corporation (PHCC); Qatar Foundation (QF); Weill Cornell Medical College Qatar; Sidra Medical & Research Center	Hamed, E (corresponding author), Qatar Univ Hlth Ctr, Primary Hlth Care Corp, Family Med, Doha, Qatar.	dr.ehabaziz@gmail.com	Hamed, Ehab/R-2413-2018	Hamed, Ehab/0000-0002-4404-1424				Al-Antari MA, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040688; [Anonymous], 2023, MANAGEMENT DIABETIC; Bajgain B, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2022-068373; Bohr A, 2020, ARTIF INTELL, DOI [10.1016/b978-0-12-818438-7.00002-2, DOI 10.1016/B978-0-12-818438-7.00002-2]; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Dua Dheeru, 2022, P 2022 C EMP METH NA, P1251, DOI DOI 10.48550/ARXIV.2212.04092; Dubey S, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1124182; Goguen J, 2018, CAN J DIABETES, V42, pS109, DOI 10.1016/j.jcjd.2017.10.013; Hamed E, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38784; Li Y, 2023, CUREUS J MED SCIENCE, V15; Lou RZ, 2024, Arxiv, DOI [arXiv:2303.10475, 10.48550/ARXIV.2303.10475]; Lund BD, 2023, Arxiv, DOI arXiv:2303.13367; Ramgopal S, 2023, PEDIATR RES, V93, P334, DOI 10.1038/s41390-022-02226-1; Royal Australian College of General Practioners, 2020, Management of Type 2 Diabetes: A Handbook for General Practice; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	15	3	3	4	15	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUL 15	2023	15	7							e41916	10.7759/cureus.41916	http://dx.doi.org/10.7759/cureus.41916			9	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	P9OJ9	37457604	gold, Green Published			2024-07-03	WOS:001053897100021
J	Buchberger, B				Buchberger, Bruno			Automated programming, symbolic computation, machine learning: my personal view	ANNALS OF MATHEMATICS AND ARTIFICIAL INTELLIGENCE			English	Article; Early Access						Automated programming; Symbolic computation; Automated reasoning; Machine learning; Artificial intelligence; Artificial general intelligence; Pretrained large language models; Software industry; Programming assistant.; .		In this note, I present my personal view on the interaction of the three areas Automated Programming, Symbolic Computation, and Machine Learning. Programming is the activity of finding a (hopefully) correct program (algorithm) for a given problem. Programming is central to automation in all areas and is considered one of the most creative human activities. However, already very early in the history of programming, people started to "jump to the meta-level" of programming, i.e., started to develop procedures that automate, or semi-automate, (various aspects or parts of) the process of programming. This area has various names like "Automated Programming", "Automated Algorithm Synthesis", etc. Developing compilers can be considered an early example of a problem in automated programming. Automated reasoners for proving the correctness of programs with respect to a specification is an advanced example of a topic in automated programming. ChatGPT producing (amazingly good) programs from problem specifications in natural language is a recent example of automated programming. Programming tends to become the most important activity as the level of technological sophistication increases. Therefore, automating programming is maybe the most exciting and relevant technological endeavor today. It also will have enormous impact on the global job market in the software industry. Roughly, I see two main approaches to automated programming:symbolic computationand machine learning. In this note, I explain how the two approaches work and that they are fundamentally different because they address two completely different ways of how problems are specified. Together, the two approaches constitute (part of) what some people like to call "artificial intelligence". In my analysis, both approaches are just part of (algorithmic) mathematics. The approaches, like all non-trivial mathematical methods, need quite some intelligence on the side of the human inventors of the methods. However, applying the methods is just "machine execution" of algorithms. It is misleading to call the application "machine intelligence" or "artificial intelligence". The analysis of the two approaches to automated programming also suggests that the two approaches, in the future, should be combined to achieve even higher levels of sophistication. At the end of this note, I propose some research questions for this new direction.	[Buchberger, Bruno] Johannes Kepler Univ Linz, Res Inst Symbol Computat RISC, Linz, Austria	Johannes Kepler University Linz	Buchberger, B (corresponding author), Johannes Kepler Univ Linz, Res Inst Symbol Computat RISC, Linz, Austria.	bruno.buchberger@jku.at			Johannes Kepler University Linz	Johannes Kepler University Linz	Open access funding provided by Johannes Kepler University Linz.	[Anonymous], 1985, J SYMB COMPUT, V1, P1; [Anonymous], 2022, ChatGPT: Optimizing Language Models for Dialogue; Buchberger B., 2023, RISC Report Series, V23-04; Buchberger B., 2003, EPTCS, V93, P24; Buchberger B., 1982, Informatik-Fachberichte, V59, P141; Buchberger B., 2003, P SYNASC 2003 5 INT, P2; Buchberger B., 2022, Meditation in Today's World. Part I: Science, Technology, Economy, Welfare: The Reflexion Principle; Buchberger B, 2021, ELECTRON P THEOR COM, P1, DOI 10.4204/EPTCS.342.1; Buchberger B, 2016, J FORMALIZ REASON, V9, P149; Coquand T., 2022, The Coq Proof Assistant; Grover A., 2021, ACM Comput. Surv, V54, P1; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Kaufmann D, 2019, 2019 FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD), P28, DOI [10.23919/FMCAD.2019.8894250, 10.23919/fmcad.2019.8894250]; Marcus G., 2023, Transcript of an Interview with Ezra Klein; Nipkov T., 2022, The Isabelle Proof Assistant; openai, 2022, Codex	16	2	2	6	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1012-2443	1573-7470		ANN MATH ARTIF INTEL	Ann. Math. Artif. Intell.	2023 OCT 10	2023										10.1007/s10472-023-09894-7	http://dx.doi.org/10.1007/s10472-023-09894-7		OCT 2023	21	Computer Science, Artificial Intelligence; Mathematics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Mathematics	T8PZ2		hybrid			2024-07-03	WOS:001080562200001
J	Hu, XY; Ran, AR; Nguyen, TX; Szeto, S; Yam, JC; Chan, CKM; Cheung, CY				Hu, Xiaoyan; Ran, An Ran; Nguyen, Truong X.; Szeto, Simon; Yam, Jason C.; Chan, Carmen K. M.; Cheung, Carol Y.			What can GPT-4 do for Diagnosing Rare Eye Diseases? A Pilot Study	OPHTHALMOLOGY AND THERAPY			English	Article						Rare eye disease; Generative pretrained transformer; Large language models; Artificial intelligence		Introduction: Generative pretrained transformer-4 (GPT-4) has gained widespread attention from society, and its potential has been extensively evaluated in many areas. However, investigation of GPT-4's use in medicine, especially in the ophthalmology field, is still limited. This study aims to evaluate GPT-4's capability to identify rare ophthalmic diseases in three simulated scenarios for different end-users, including patients, family physicians, and junior ophthalmologists.Methods We selected ten treatable rare ophthalmic disease cases from the publicly available EyeRounds service. We gradually increased the amount of information fed into GPT-4 to simulate the scenarios of patient, family physician, and junior ophthalmologist using GPT-4. GPT-4's responses were evaluated from two aspects: suitability (appropriate or inappropriate) and accuracy (right or wrong) by senior ophthalmologists (> 10 years' experiences).Results: Among the 30 responses, 83.3% were considered "appropriate" by senior ophthalmologists. In the scenarios of simulated patient, family physician, and junior ophthalmologist, seven (70%), ten (100%), and eight (80%) responses were graded as "appropriate" by senior ophthalmologists. However, compared to the ground truth, GPT-4 could only output several possible diseases generally without "right" responses in the simulated patient scenarios. In contrast, in the simulated family physician scenario, 50% of GPT-4's responses were "right," and in the simulated junior ophthalmologist scenario, the model achieved a higher "right" rate of 90%.Conclusion: To our knowledge, this is the first proof-of-concept study that evaluates GPT-4's capacity to identify rare eye diseases in simulated scenarios involving patients, family physicians, and junior ophthalmologists. The results indicate that GPT-4 has the potential to serve as a consultation assisting tool for patients and family physicians to receive referral suggestions and an assisting tool for junior ophthalmologists to diagnose rare eye diseases. However, it is important to approach GPT-4 with caution and acknowledge the need for verification and careful referrals in clinical settings.	[Hu, Xiaoyan; Ran, An Ran; Nguyen, Truong X.; Szeto, Simon; Yam, Jason C.; Cheung, Carol Y.] Chinese Univ Hong Kong, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China; [Chan, Carmen K. M.] Hong Kong Eye Hosp, Hong Kong, Peoples R China	Chinese University of Hong Kong	Cheung, CY (corresponding author), Chinese Univ Hong Kong, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China.	carolcheung@cuhk.edu.hk	Yam, Jason/I-5682-2014; Szeto, Simon KH/HMD-2901-2023	Yam, Jason/0000-0002-2156-1486; Szeto, Simon KH/0000-0001-9377-7377; Nguyen, Truong/0000-0002-8505-6593				[Anonymous], 2014, OPHTH CAS EYEROUNDS; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Black GC, 2021, ORPHANET J RARE DIS, V16, DOI 10.1186/s13023-021-01756-x; Burlina P, 2020, JAMA OPHTHALMOL, V138, P1070, DOI 10.1001/jamaophthalmol.2020.3269; Choi JY, 2023, ANN TRANSL MED; Haendel M, 2020, NAT REV DRUG DISCOV, V19, P77, DOI 10.1038/d41573-019-00180-y; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Mukamal R., 2020, 20 RARE EYE CONDITIO; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Ronicke S, 2019, ORPHANET J RARE DIS, V14, DOI 10.1186/s13023-019-1040-6; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Topsakal O., 2022, The Journal of Cognitive Systems, V7, P33, DOI DOI 10.52876/JCS.1227392; Yoo TK, 2021, MED BIOL ENG COMPUT, V59, P401, DOI 10.1007/s11517-021-02321-1; Zhang C., 2023, ARXIV	20	5	5	4	7	SPRINGER INT PUBL AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2193-8245	2193-6528		OPHTHALMOL THER	OPHTHALMOL. THER.	DEC	2023	12	6					3395	3402		10.1007/s40123-023-00789-8	http://dx.doi.org/10.1007/s40123-023-00789-8		SEP 2023	8	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	LQ7G6	37656399	gold, Green Published			2024-07-03	WOS:001060174400002
J	Xu, QH; Li, P				Xu, Qihui; Li, Ping			Computational Modeling of Language Learning in the Era of Generative Artificial Intelligence: A Response to Open Peer Commentaries	LANGUAGE LEARNING			English	Editorial Material						computational modeling; bilingualism; generative AI; large language models; cross-disciplinary integration	PRINCIPLES		[Xu, Qihui] Basque Ctr Cognit Brain & Language, San Sebastian, Spain; [Li, Ping] Hong Kong Polytech Univ, Hong Kong, Peoples R China; [Li, Ping] Hong Kong Polytech Univ, Fac Humanities, Dept Chinese & Bilingual Studies, Hung Hom,Kowloon, Hong Kong, Peoples R China	Hong Kong Polytechnic University; Hong Kong Polytechnic University	Li, P (corresponding author), Hong Kong Polytech Univ, Fac Humanities, Dept Chinese & Bilingual Studies, Hung Hom,Kowloon, Hong Kong, Peoples R China.	pi2li@polyu.edu.hk		Xu, Qihui/0000-0002-5892-6442; Li, Ping/0000-0002-3314-943X	Hong Kong Re-search Grants Council [PolyU15601520]; Sin Wai Kin Foundation endowment grant; BERC-Spanish State Research Agency through BCBL Severo Ochoa excellence accreditation [CEX2020-001010/AEI]	Hong Kong Re-search Grants Council(Hong Kong Research Grants Council); Sin Wai Kin Foundation endowment grant; BERC-Spanish State Research Agency through BCBL Severo Ochoa excellence accreditation	Preparation of this article has been partially supported by the following grants: Hong Kong Re-search Grants Council (Project #PolyU15601520), Sin Wai Kin Foundation endowment grant, and the BERC 2022-2025 program Funded by the Spanish State Research Agency through BCBL Severo Ochoa excellence accreditation CEX2020-001010/AEI/10.13039/501100011033.We thank Jenny Geng for her editorial assistance with the manuscript	Artetxe M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7674; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Browning J., 2023, DO LARGE LANGUAGE MO; Chomsky N., 2023, NEW YORK TIMES 0301; Chomsky N., 1995, The Minimalist Program; Claussenius-Kalman H, 2021, BRAIN LANG, V222, DOI [10.1016/j.bandl.2021.105013, 10.1016/j.bl.2021.105013]; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; DeLuca V, 2019, P NATL ACAD SCI USA, V116, P7565, DOI 10.1073/pnas.1811513116; Dijkstra T, 2023, LANG LEARN, V73, P65, DOI 10.1111/lang.12532; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Jeong Y, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24269-4; Kachergis G, 2023, LANG LEARN, V73, P70, DOI 10.1111/lang.12531; Kachergis G, 2022, CURR DIR PSYCHOL SCI, V31, P20, DOI 10.1177/09637214211057836; Kriegeskorte N, 2018, NAT NEUROSCI, V21, P1148, DOI 10.1038/s41593-018-0210-5; Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100; Legault J, 2019, LANGUAGES-BASEL, V4, DOI 10.3390/languages4010013; Lepori M. A., 2023, BREAK IT EVIDENCE ST; Li, 2013, PSYCHOLINGUISTICS BI, P5; Li P, 2022, BILING-LANG COGN, V25, P361, DOI 10.1017/S1366728921000353; Li P, 2020, NPJ SCI LEARN, V5, DOI 10.1038/s41539-020-0068-7; Linck JA, 2009, PSYCHOL SCI, V20, P1507, DOI 10.1111/j.1467-9280.2009.02480.x; MacWhinney B., 2000, CHILDES PROJECT TOOL; Marian V, 2023, LANG LEARN, V73, P74, DOI 10.1111/lang.12530; Marjieh R., 2023, WHAT LANGUAGE REVEAL; Mollo D. C., 2023, VECTOR GROUNDING PRO; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ouyang L., 2022, TRAINING LANGUAGE MO, DOI DOI 10.48550/ARXIV.2203.02155; Peeters D, 2019, PSYCHON B REV, V26, P894, DOI 10.3758/s13423-019-01571-3; Peñaloza C, 2023, LANG LEARN, V73, P78, DOI 10.1111/lang.12566; Peng B., 2023, RWKV REINVENTING RNN; Piantadosi S., 2023, PREPRINT; Pinker S., 1994, The Language Instinct: How the Mind Creates Language; Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56; Redcay E, 2019, NAT REV NEUROSCI, V20, P495, DOI 10.1038/s41583-019-0179-4; Taori R., Alpaca: A strong, replicable instructionfollowing model; Tomasello M, 2004, DAEDALUS-US, V133, P51, DOI 10.1162/001152604772746693; Tsoukala C., 2017, P 39 ANN C COGN SCI, P3392; Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833; Xu Q., 2023, DOES CONCEPTUAL REPR; Yang CD, 2004, TRENDS COGN SCI, V8, P451, DOI 10.1016/j.tics.2004.08.006	42	0	0	22	54	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0023-8333	1467-9922		LANG LEARN	Lang. Learn.	DEC	2023	73			2			83	94		10.1111/lang.12605	http://dx.doi.org/10.1111/lang.12605		JUL 2023	12	Education & Educational Research; Linguistics	Social Science Citation Index (SSCI)	Education & Educational Research; Linguistics	CM2Q3					2024-07-03	WOS:001039851400001
J	Liu, XH; Wang, WM				Liu, Xinhe; Wang, Wenmin			Deep Time Series Forecasting Models: A Comprehensive Survey	MATHEMATICS			English	Review						time series forecasting; deep learning; Transformer; convolutional neural network (CNN); recurrent neural network (RNN); multi-layer perceptron (MLP); state space model (SSM); large language model (LLM)	TRANSFORMER; EFFICIENT; SEQUENCE	Deep learning, a crucial technique for achieving artificial intelligence (AI), has been successfully applied in many fields. The gradual application of the latest architectures of deep learning in the field of time series forecasting (TSF), such as Transformers, has shown excellent performance and results compared to traditional statistical methods. These applications are widely present in academia and in our daily lives, covering many areas including forecasting electricity consumption in power systems, meteorological rainfall, traffic flow, quantitative trading, risk control in finance, sales operations and price predictions for commercial companies, and pandemic prediction in the medical field. Deep learning-based TSF tasks stand out as one of the most valuable AI scenarios for research, playing an important role in explaining complex real-world phenomena. However, deep learning models still face challenges: they need to deal with the challenge of large-scale data in the information age, achieve longer forecasting ranges, reduce excessively high computational complexity, etc. Therefore, novel methods and more effective solutions are essential. In this paper, we review the latest developments in deep learning for TSF. We begin by introducing the recent development trends in the field of TSF and then propose a new taxonomy from the perspective of deep neural network models, comprehensively covering articles published over the past five years. We also organize commonly used experimental evaluation metrics and datasets. Finally, we point out current issues with the existing solutions and suggest promising future directions in the field of deep learning combined with TSF. This paper is the most comprehensive review related to TSF in recent years and will provide a detailed index for researchers in this field and those who are just starting out.	[Liu, Xinhe; Wang, Wenmin] Macau Univ Sci & Technol, Sch Comp Sci & Engn, Macau 999078, Peoples R China	Macau University of Science & Technology	Wang, WM (corresponding author), Macau Univ Sci & Technol, Sch Comp Sci & Engn, Macau 999078, Peoples R China.	wmwang@must.edu.mo		Wang, Wenmin/0000-0003-2664-4413				Ashok A, 2023, Arxiv, DOI arXiv:2310.01327; Barrera-Animas AY, 2022, MACH LEARN APPL, V7, DOI 10.1016/j.mlwa.2021.100204; Bergsma S., 2022, Adv. Neural Inf. Process. Syst, V35, P21900; Borovykh A, 2018, Arxiv, DOI arXiv:1703.04691; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao DF, 2024, Arxiv, DOI arXiv:2310.04948; Challu C., 2023, P AAAI C ART INT, V37, P6989, DOI 10.1609/aaai.v37i6.25854; Chang C, 2023, Arxiv, DOI arXiv:2308.08469; Chang P, 2024, COMPUT METH PROG BIO, V246, DOI 10.1016/j.cmpb.2024.108060; Chang YY, 2018, Arxiv, DOI arXiv:1809.02105; Chen SA, 2023, Arxiv, DOI arXiv:2303.06053; Chen WQ, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P146, DOI 10.1145/3534678.3539234; Chen Y., 2023, Adv. Neural Inf. Process. Syst, V36, P47143; Chen YS, 2024, NEURAL NETWORKS, V176, DOI 10.1016/j.neunet.2024.106334; Cheng J., 2019, P AAAI C ART INT HON; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]; Cirstea R.-G., 2022, IJCAI, P1994; Das A, 2024, Arxiv, DOI arXiv:2304.08424; Dauphin YN, 2017, PR MACH LEARN RES, V70; Ding XH, 2024, Arxiv, DOI arXiv:2311.15599; Donghao L., ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Drouin A, 2022, PR MACH LEARN RES; Du D., 2023, P ICASSP 2023 2023 I; Du YT, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P402, DOI 10.1145/3459637.3482315; Ekambaram V, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P459, DOI 10.1145/3580305.3599533; Fan CY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2527, DOI 10.1145/3292500.3330662; Fan W., 2023, P AAAI C ARTIFICIAL, V37, P7522; Fan W., 2022, arXiv; Feng SB, 2024, IEEE T KNOWL DATA EN, V36, P2056, DOI 10.1109/TKDE.2023.3319672; Gao JX, 2023, Arxiv, DOI arXiv:2305.18838; Garza A, 2024, Arxiv, DOI arXiv:2310.03589; Gehring J, 2017, PR MACH LEARN RES, V70; Godfrey LB, 2018, IEEE T NEUR NET LEAR, V29, P2973, DOI 10.1109/TNNLS.2017.2709324; Gong ZY, 2023, Arxiv, DOI arXiv:2310.00655; Gorbett M, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P544, DOI 10.1145/3580305.3599508; Gruver N., 2023, Adv. Neural Inf. Process. Syst, V36, P19622; Gu A, 2024, Arxiv, DOI arXiv:2312.00752; Han L, 2023, Arxiv, DOI arXiv:2304.05206; Haugsdal E, 2023, APPL INTELL, V53, P26781, DOI 10.1007/s10489-023-04927-4; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang ST, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2129, DOI 10.1145/3357384.3358132; Jia Y., 2024, Adv. Neural Inf. Process. Syst., V36; Jin M, 2024, Arxiv, DOI arXiv:2310.01728; Kim T., 2022, P INT C LEARN REPR V; Kollovieh M., 2023, Adv. Neural Inf. Process. Syst, V36, P28341; Koochali A, 2019, IEEE ACCESS, V7, P63868, DOI 10.1109/ACCESS.2019.2915544; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lai GK, 2018, ACM/SIGIR PROCEEDINGS 2018, P95, DOI 10.1145/3209978.3210006; Le CP, 2023, Arxiv, DOI arXiv:2310.01720; Lea C, 2016, LECT NOTES COMPUT SC, V9915, P47, DOI 10.1007/978-3-319-49409-8_7; Li B, 2023, IEEE T PATTERN ANAL, V45, P13586, DOI 10.1109/TPAMI.2023.3293516; Li Y., 2022, Proceedings of the Advances in Neural Information Processing Systems, V35, P23009; Li Y., 2023, Towards Long-Term Time-Series Forecasting: Feature, Pattern, and Distribution, P1611; Li Z., 2023, Adv. Neural Inf. Process. Syst, V36, P49187; Li Z, 2023, Arxiv, DOI arXiv:2302.04501; Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012; Lin SS, 2023, Arxiv, DOI arXiv:2308.04791; Lin SS, 2023, Arxiv, DOI arXiv:2308.11200; Liu HX, 2024, Arxiv, DOI arXiv:2402.16132; Liu M., 2022, Advances in Neural Information Processing Systems, V35, P5816; Liu S., 2022, P INT C LEARN REPR V; Liu Y., 2024, Adv. Neural Inf. Process. Syst., V36; Liu Y., 2022, Advances in Neural Information Processing Systems, V35, P9881; Liu Y, 2024, Arxiv, DOI arXiv:2402.02370; Liu Y, 2024, Arxiv, DOI arXiv:2310.06625; Luo YX, 2023, Arxiv, DOI arXiv:2308.13386; Oreshkin BN, 2020, Arxiv, DOI arXiv:1905.10437; Ni Z., 2024, Adv. Neural Inf. Process. Syst, P36; Nie YQ, 2023, Arxiv, DOI [arXiv:2211.14730, DOI 10.48550/ARXIV.2211.14730]; Nivron O., 2023, P ICML WORKSH NEW FR; Olivares KG, 2023, INT J FORECASTING, V39, P884, DOI 10.1016/j.ijforecast.2022.03.001; Passalis N, 2020, IEEE T NEUR NET LEAR, V31, P3760, DOI 10.1109/TNNLS.2019.2944933; Qi X., 2021, arXiv; Qin Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2627; Rangapuram SS, 2018, ADV NEUR IN, V31; Rasul K, 2021, PR MACH LEARN RES, V139; Rasul K, 2024, Arxiv, DOI arXiv:2310.08278; Rasul K, 2021, Arxiv, DOI arXiv:2002.06103; Salinas D, 2020, INT J FORECASTING, V36, P1181, DOI 10.1016/j.ijforecast.2019.07.001; Sasal L, 2022, 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, ICMLA, P671, DOI 10.1109/ICMLA55696.2022.00111; Schirmer M, 2022, PR MACH LEARN RES, P19388; Shabani MA, 2023, Arxiv, DOI arXiv:2206.04038; Shen L, 2023, KNOWL-BASED SYST, V275, DOI 10.1016/j.knosys.2023.110666; SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017; Smyl S, 2020, INT J FORECASTING, V36, P75, DOI 10.1016/j.ijforecast.2019.03.017; Sun C., 2023, arXiv, DOI 10.48550/arXiv.2308.08241; Sun FK, 2022, Arxiv, DOI arXiv:2205.12301; Tan YX, 2023, Arxiv, DOI arXiv:2306.01674; Tashiro J., 2021, ADV NEUR IN, V34, p24 804; Taylor SJ, 2018, AM STAT, V72, P37, DOI 10.1080/00031305.2017.1380080; Tolstikhin I, 2021, ADV NEUR IN, V34; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; van den Oord A, 2016, ADV NEUR IN, V29; Vaswani A, 2017, ADV NEUR IN, V30; Wang H., 2023, P 11 INT C LEARN REP, P1; Wang JY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2437, DOI 10.1145/3219819.3220060; Wang W, 2023, Arxiv, DOI arXiv:2305.15770; Wang X., 2024, P 12 INT C LEARN REP; Wang X, 2023, Arxiv, DOI arXiv:2306.06895; Wen RF, 2018, Arxiv, DOI arXiv:1711.11053; Woo G., 2023, P MACHINE LEARNING R, P37217; Woo G, 2024, Arxiv, DOI arXiv:2402.02592; Woo G, 2022, Arxiv, DOI arXiv:2202.01381; Wu H., 2023, P 11 INT C LEARN REP; Wu HX, 2021, ADV NEUR IN, V34; Wu N, 2020, Arxiv, DOI [arXiv:2001.08317, 10.48550/arXiv.2001.08317]; Wu SF, 2020, ADV NEUR IN, V33; Xia J, 2020, MOL INFORM, V39, DOI 10.1002/minf.201900151; Xu ZJ, 2024, Arxiv, DOI arXiv:2307.03756; Yi K., 2023, Adv. Neural Inf. Process. Syst, V36, P76656; Yu CQ, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P3062, DOI 10.1145/3583780.3614851; Zeng A, 2023, P AAAI C ART INT WAS, V37, P11121, DOI DOI 10.1609/AAAI.V37I9.26317; Zhang TP, 2022, Arxiv, DOI arXiv:2207.01186; Zhang XY, 2022, Arxiv, DOI arXiv:2212.08151; Zhang Y., 2024, INT C ARTIFICIAL INT, P4222; Zhang Y., 2023, P 11 INT C LEARN REP; Zhang ZW, 2024, IEEE INTERNET THINGS, V11, P18435, DOI 10.1109/JIOT.2024.3363451; Zhao YJ, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P3464, DOI 10.1145/3583780.3615136; Zheng JH, 2020, IEEE ACCESS, V8, P82562, DOI 10.1109/ACCESS.2020.2990738; Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106; Zhou T., 2023, Advances in neural information processing systems, V36, P43322; Zhou T, 2022, PR MACH LEARN RES; Zhou Z., 2022, arXiv	125	1	1	13	13	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	MAY	2024	12	10							1504	10.3390/math12101504	http://dx.doi.org/10.3390/math12101504			33	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	RZ7D4		gold			2024-07-03	WOS:001231535600001
J	Wu, TY; He, SZ; Liu, JP; Sun, SQ; Liu, K; Han, QL; Tang, Y				Wu, Tianyu; He, Shizhu; Liu, Jingping; Sun, Siqi; Liu, Kang; Han, Qing-Long; Tang, Yang			A Brief Overview of ChatGPT: The History, Status Quo and Potential Future Development	IEEE-CAA JOURNAL OF AUTOMATICA SINICA			English	Article						Three-dimensional displays; Web and internet services; Reinforcement learning; Chatbots; Robot sensing systems; Transformers; History; AIGC; ChatGPT; GPT-3; GPT-4; human feedback; large language models	REINFORCEMENT; LANGUAGE; NETWORKS; SYSTEM	ChatGPT, an artificial intelligence generated content (AIGC) model developed by OpenAI, has attracted world-wide attention for its capability of dealing with challenging language understanding and generation tasks in the form of conversations. This paper briefly provides an overview on the history, status quo and potential future development of ChatGPT, helping to provide an entry point to think about ChatGPT. Specifically, from the limited open-accessed resources, we conclude the core techniques of ChatGPT, mainly including large-scale language models, in-context learning, reinforcement learning from human feedback and the key technical steps for developing Chat-GPT. We further analyze the pros and cons of ChatGPT and we rethink the duality of ChatGPT in various fields. Although it has been widely acknowledged that ChatGPT brings plenty of opportunities for various fields, mankind should still treat and use ChatGPT properly to avoid the potential threat, e.g., academic integrity and safety challenge. Finally, we discuss several open problems as the potential development of ChatGPT.	[Wu, Tianyu; Tang, Yang] East China Univ Sci & Technol, Key Lab Smart Mfg Energy Chem Proc, Shanghai 200237, Peoples R China; [Liu, Jingping] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai 200237, Peoples R China; [He, Shizhu; Liu, Kang] Chinese Acad Sci, Inst Automat, Lab Cognit & Decis Intelligence Complex Syst, Beijing 100190, Peoples R China; [He, Shizhu; Liu, Kang] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Sun, Siqi] Fudan Univ, Res Inst Intelligent Complex Syst, Shanghai 200437, Peoples R China; [Han, Qing-Long] Swinburne Univ Technol, Sch Sci Comp & Engn Technol, Melbourne, Vic 3122, Australia	East China University of Science & Technology; East China University of Science & Technology; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Fudan University; Swinburne University of Technology	Tang, Y (corresponding author), East China Univ Sci & Technol, Key Lab Smart Mfg Energy Chem Proc, Shanghai 200237, Peoples R China.; Han, QL (corresponding author), Swinburne Univ Technol, Sch Sci Comp & Engn Technol, Melbourne, Vic 3122, Australia.	y20200093@mail.ecust.edu.cn; shizhu.he@nlpr.ia.ac.cn; jingpingliu@ecust.edu.cn; siqisun@fudan.edu.cn; kliu@nlpr.ia.ac.cn; qhan@swin.edu.au; yangtang@ecust.edu.cn		he, shi zhu/0000-0001-9053-9517; Sun, Siqi/0000-0001-7240-8724	National Key Research and Development Program of China [2021YFB1714300]; National Natural Science Foundation of China [62293502, 61831022, 61976211]; Youth Innovation Promotion Association CAS	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS	This work was supported by National Key Research and Development Program of China (2021YFB1714300), National Natural Science Foundation of China (62293502, 61831022, 61976211) and Youth Innovation Promotion Association CAS.	Bai HL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4334; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Beck J., 2023, arXiv; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen J, 2022, IEEE-CAA J AUTOMATIC, V9, P1698, DOI 10.1109/JAS.2022.105818; Chen T. L., 2020, PROC 34 INT C NEURAL, P1328; Chen X. Y., 2021, PROC 9 INT C LEARNIN; Cheng Y, 2020, Arxiv, DOI [arXiv:1710.09282, DOI 10.48550/ARXIV.1710.09282]; Christiano PF, 2017, ADV NEUR IN, V30; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cohen Deborah, 2022, arXiv, DOI 10.48550/arXiv.2208.02294; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Du H., 2023, arXiv; Ecoffet A, 2021, NATURE, V590, DOI 10.1038/s41586-020-03157-9; Finn C, 2017, PR MACH LEARN RES, V70; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Fujimoto S, 2018, PR MACH LEARN RES, V80; Glaese A, 2022, arXiv; Goldwasser D, 2014, MACH LEARN, V94, P205, DOI 10.1007/s10994-013-5407-y; Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P143; Gottipati SK, 2020, PR MACH LEARN RES, V119; Gusak J, 2022, Arxiv, DOI arXiv:2202.10435; Guu K, 2020, PR MACH LEARN RES, V119; Haarnoja T, 2019, Arxiv, DOI arXiv:1812.05905; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Ieracitano C, 2021, IEEE-CAA J AUTOMATIC, V8, P64, DOI 10.1109/JAS.2020.1003387; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Jin YB, 2022, NAT MACH INTELL, V4, P1198, DOI 10.1038/s42256-022-00576-3; Ju Y. M., 2022, ARXIV; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Khosla M, 2020, Arxiv, DOI [arXiv:1903.07902, 10.48550/arXiv.1903.07902]; Kiegeland S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1673; Knox WB, 2008, INT C DEVEL LEARN, P292, DOI 10.1109/DEVLRN.2008.4640845; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kreutzer J., 2018, P 2018 C N AM CHAPT, P92, DOI DOI 10.18653/V1/N18-3012; Lan YY, 2023, Arxiv, DOI arXiv:2301.02781; Lan Z. Z., 2020, PROC 8 INT C LEARNIN; Lawrence C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1820; Leng CC, 2021, IEEE-CAA J AUTOMATIC, V8, P1025, DOI 10.1109/JAS.2021.1003979; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901; Liu WZ, 2022, IEEE-CAA J AUTOMATIC, V9, P1673, DOI 10.1109/JAS.2022.105809; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Y, 2022, IEEE-CAA J AUTOMATIC, V9, P1528, DOI 10.1109/JAS.2022.105770; Lu JH, 2022, IEEE-CAA J AUTOMATIC, V9, P1366, DOI 10.1109/JAS.2022.105737; MacGlashan J, 2017, PR MACH LEARN RES, V70; Madaan A., 2022, P 2022 C EMPIRICAL M, P2833; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Medenilla A., 2023, PLoS Digital Health, V2; Miao QH, 2023, IEEE-CAA J AUTOMATIC, V10, P877, DOI 10.1109/JAS.2023.123561; Mikolov T., 2013, PROC 1 INT C LEARNIN; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Ming Y, 2022, IEEE-CAA J AUTOMATIC, V9, P1339, DOI 10.1109/JAS.2022.105734; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Paranjape B, 2023, Arxiv, DOI arXiv:2303.09014; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Perez E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2402; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A., 2022, arXiv; Reed S, 2022, Arxiv, DOI arXiv:2205.06175; Ren W. Q., 2022, ARXIV, DOI 10.1109/JAS.2023.123207; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schick T., 2023, arXiv; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Schulman J, 2015, PR MACH LEARN RES, V37, P1889; Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Singer U, 2022, Arxiv, DOI arXiv:2209.14792; Smith S, 2022, arXiv; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; [孙琦钰 Sun Qiyu], 2022, [中国科学. 技术科学, Scientia Sinica Technologica], V52, P26; Sun SQ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4323; Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158; Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z; Wan YN, 2022, IEEE-CAA J AUTOMATIC, V9, P123, DOI 10.1109/JAS.2021.1004287; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P831, DOI 10.1109/JAS.2023.123552; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang JK, 2021, NAT MACH INTELL, V3, P914, DOI 10.1038/s42256-021-00403-1; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Warnell G, 2018, AAAI CONF ARTIF INTE, P1545; Wei J., 2022, PROC 10 INT C LEARNI; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Weng J., 2022, J MACH LEARN RES, V23, P1; Weng YX, 2023, Arxiv, DOI arXiv:2212.09561; Wu RF, 2022, IEEE-CAA J AUTOMATIC, V9, P19, DOI 10.1109/JAS.2021.1004272; Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128; Xue L, 2018, IEEE-CAA J AUTOMATIC, V5, P301, DOI 10.1109/JAS.2017.7510466; Yang L, 2024, Arxiv, DOI [arXiv:2209.00796, DOI 10.48550/ARXIV.2209.00796]; Zhai C. X, 2008, STAT LANGUAGE MODELS, P1; Zhang YZ, 2022, AAAI CONF ARTIF INTE, P11739; Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203; Zhang Z., 2022, arXiv; Zhao CQ, 2020, SCI CHINA TECHNOL SC, V63, P1612, DOI 10.1007/s11431-020-1582-8; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]; Zhou WCS, 2020, AAAI CONF ARTIF INTE, V34, P9717; Zhou WX, 2023, Arxiv, DOI arXiv:2303.11315; Zhu MJ, 2022, COMM COM INF SC, V1711, P154, DOI 10.1007/978-981-19-8300-9_17	128	110	117	663	1636	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9266	2329-9274		IEEE-CAA J AUTOMATIC	IEEE-CAA J. Automatica Sin.	MAY	2023	10	5					1122	1136		10.1109/JAS.2023.123618	http://dx.doi.org/10.1109/JAS.2023.123618			15	Automation & Control Systems	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems	F4FH1					2024-07-03	WOS:000981914800002
J	Watson, RT; Song, YY; Zhao, X; Webster, J				Watson, Richard T.; Song, Yuanyuan (April); Zhao, Xia; Webster, Jane			Extending the Foresight of Phillip Ein-Dor: Causal Knowledge Analytics	JOURNAL OF THE ASSOCIATION FOR INFORMATION SYSTEMS			English	Article						Knowledge; Graph Database; Causal Knowledge Analytics; Network Analysis; Natural Language Processing; Artificial Intelligence; Large Language Models; Machine Learning; Knowledge Engineering	TECHNOLOGY; TRUST	Phillip Ein-Dor advocated that electronic journals be more than a PDF of the established text model. He envisioned a transformation of scholarship. The need for such a transition has only grown since the first issue of JAIS in 2000 because the continuing growth and fragmentation of knowledge limits the generation of new knowledge. We propose drawing on analytics and AI to accelerate and transform scholarship, providing an appropriate tribute to a visionary IS leader.	[Watson, Richard T.] Digital Frontier Partners, Melbourne, Australia; [Watson, Richard T.; Song, Yuanyuan (April); Zhao, Xia] Univ Georgia, Athens, GA 30602 USA; [Webster, Jane] Queens Univ, Kingston, ON, Canada	University System of Georgia; University of Georgia; Queens University - Canada	Watson, RT (corresponding author), Digital Frontier Partners, Melbourne, Australia.; Watson, RT (corresponding author), Univ Georgia, Athens, GA 30602 USA.	richard.watson@digitalfrontierpartners.com; yuanyuan.song@uga.edu; xia.zhao@uga.edu; jane.webster@queensu.ca			Alfred P. Sloan Foundation	Alfred P. Sloan Foundation(Alfred P. Sloan Foundation)	Acknowledgments This research is supported by the Alfred P. Sloan Foundation.	Adjerid I, 2018, MIS QUART, V42, P465, DOI 10.25300/MISQ/2018/14316; Ba SL, 2002, MIS QUART, V26, P243, DOI 10.2307/4132332; Barlaug N, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3442200; Benitez J, 2018, MIS QUART, V42, P25, DOI 10.25300/MISQ/2018/13245; Boell S, 2019, P 2019 AUSTRALASIAN; Borchard A, 2012, ANN SURG, V256, P925, DOI 10.1097/SLA.0b013e3182682f27; Bornmann L, 2015, J ASSOC INF SCI TECH, V66, P2215, DOI 10.1002/asi.23329; BURT RS, 1992, NETWORKS AND ORGANIZATIONS : STRUCTURE, FORM, AND ACTION, P57; Chen ZD, 2020, Arxiv, DOI [arXiv:1705.08415, DOI 10.48550/ARXIV.1705.08415]; Chomsky N., 2002, On nature and language, P92, DOI DOI 10.1017/CBO9780511613876.005; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Cyr D, 2009, MIS QUART, V33, P539; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ein-Dor Phillip., 2011, ENCY KNOWLEDGE MANAG, P1490; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; GARFIELD E, 1955, SCIENCE, V122, P108, DOI 10.1126/science.122.3159.108; Goo J, 2009, MIS QUART, V33, P119; Hui KL, 2007, MIS QUART, V31, P19; Jones BF, 2010, REV ECON STAT, V92, P1, DOI 10.1162/rest.2009.11724; KATZ L, 1953, Psychometrika, V18, P39; Kelley T.L., 1927, Interpretation of educational measurements; Kohlhase M, 2010, An open markup format for mathematical documents; Koncel-Kedziorski R, 2022, Arxiv, DOI arXiv:1904.02342; Larsen KR, 2020, COMMUN ASSOC INF SYS, V46, DOI 10.17705/1CAIS.04601; Liu A, 2023, Arxiv, DOI arXiv:2304.14399; Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727; Locke K, 1997, ACAD MANAGE J, V40, P1023, DOI 10.5465/256926; Matthews D, 2021, NATURE, V597, P141, DOI 10.1038/d41586-021-02346-4; Michels C, 2012, SCIENTOMETRICS, V93, P831, DOI 10.1007/s11192-012-0732-7; Musen MA, 2022, NATURE, V609, P222, DOI 10.1038/d41586-022-02820-7; Negro A., 2021, Graph-powered machine learning; Ou CX, 2014, MIS QUART, V38, P209, DOI 10.25300/MISQ/2014/38.1.10; Park M, 2023, NATURE, V613, P138, DOI 10.1038/s41586-022-05543-x; Pavlou PA, 2007, MIS QUART, V31, P105; Pearl Judea, 2009, CAUSALITY, DOI DOI 10.1017/CBO9780511803161; Peffers K., 2003, The Communications of the Association for Information Systems, V11, P498; Piantadosi ST, 2012, COGNITION, V122, P280, DOI 10.1016/j.cognition.2011.10.004; Piccoli G, 2003, MIS QUART, V27, P365; Quinn T, 2018, TLS-TIMES LIT SUPPL, P31; Rivard S, 2021, J INF TECHNOL-UK, V36, P316, DOI 10.1177/0268396220911938; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Shmueli G., 2017, Data mining for business analytics: concepts, techniques; Song Y, 2021, P INT C INFORM SYSTE; Song Y., Journal of Decision Systems; Sowa J.F, 1999, Knowledge Representation: Logical, Philosophical, and Computational Foundations; SWANSON DR, 1986, LIBR QUART, V56, P103, DOI 10.1086/601720; Templier M, 2015, COMMUN ASSOC INF SYS, V37, P112; Textor J, 2011, EPIDEMIOLOGY, V22, P745, DOI 10.1097/EDE.0b013e318225c2be; Thorndike E., 1913, INTRO THEORY MENTAL; Vial G, 2019, J STRATEGIC INF SYST, V28, P118, DOI 10.1016/j.jsis.2019.01.003; Wagner G, 2022, J INF TECHNOL-UK, V37, P209, DOI 10.1177/02683962211048201; Webster J, 2002, MIS QUART, V26, pXIII; Xiao B, 2007, MIS QUART, V31, P137; Zhang JW, 2023, Arxiv, DOI arXiv:2304.11116; Zhang MH, 2018, ADV NEUR IN, V31; Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001; Zupko RonaldE., 1990, REVOLUTION MEASUREME	57	1	1	4	4	ASSOC INFORMATION SYSTEMS	ATLANTA	GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA	1536-9323	1558-3457		J ASSOC INF SYST	J. Assoc. Inf. Syst.		2024	25	1			SI					10.17705/1jais.00871	http://dx.doi.org/10.17705/1jais.00871			14	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	LB5N1		Bronze			2024-07-03	WOS:001184331000014
J	Kumar, Y; Gordon, Z; Alabi, O; Li, JY; Leonard, K; Ness, L; Morreale, P				Kumar, Yulia; Gordon, Zachary; Alabi, Oluwatunmise; Li, Jenny; Leonard, Kathryn; Ness, Linda; Morreale, Patricia			ChatGPT Translation of Program Code for Image Sketch Abstraction	APPLIED SCIENCES-BASEL			English	Article						MATLAB to Python (M-to-PY) converter; skeletonization; Skeleton App; ChatGPT; generative AI; Large Language Models (LLMs); machine learning; AI pair programming		In this comprehensive study, a novel MATLAB to Python (M-to-PY) conversion process is showcased, specifically tailored for an intricate image skeletonization project involving fifteen MATLAB files and a large dataset. The central innovation of this research is the adept use of ChatGPT-4 as an AI assistant, pivotal in crafting a prototype M-to-PY converter. This converter's capabilities were thoroughly evaluated using a set of test cases generated by the Bard bot, ensuring a robust and effective tool. The culmination of this effort was the development of the Skeleton App, adept at image sketching and skeletonization. This live and publicly available app underscores the enormous potential of AI in enhancing the transition of scientific research from MATLAB to Python. The study highlights the blend of AI's computational prowess and human ingenuity in computational research, making significant strides in AI-assisted scientific exploration and tool development.	[Kumar, Yulia; Gordon, Zachary; Alabi, Oluwatunmise; Li, Jenny; Morreale, Patricia] Kean Univ, Dept Comp Sci & Technol, Union, NJ 07083 USA; [Leonard, Kathryn] Occidental Coll, Dept Comp Sci, Los Angeles, CA 90041 USA; [Ness, Linda] Rutgers State Univ, Ctr Discrete Math & Theoret Comp Sci, New Brunswick, NJ USA	Kean University; Occidental College; Rutgers University System; Rutgers University New Brunswick	Kumar, Y (corresponding author), Kean Univ, Dept Comp Sci & Technol, Union, NJ 07083 USA.	ykumar@kean.edu; gordonza@kean.edu; oalabi@kean.edu; juli@kean.edu; leonardk@oxy.edu; ness.linda@gmail.com; pmorreal@kean.edu		Kumar, Yulia/0000-0002-7621-2734; Morreale, Patricia/0000-0002-7954-2122	NSF	NSF(National Science Foundation (NSF))	No Statement Available	Ali M., 2021, P 2021 12 INT C COMP, P01, DOI [10.1109/ICCCNT51525.2021.9579913, DOI 10.1109/ICCCNT51525.2021.9579913]; [Anonymous], 2023, Skeleton App Repo; [Anonymous], 2023, Benefits of AI Tools Section at Stack Overflow Developer Survey; [Anonymous], 2023, Python Code and Its Results; [Anonymous], 2023, OpenAI Quickstart; Bergstrom AC, 2023, Arxiv, DOI arXiv:2301.00856; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cárdenas JL, 2023, IEEE T VIS COMPUT GR, V29, P4920, DOI 10.1109/TVCG.2022.3193018; Carvalho LE, 2019, PATTERN ANAL APPL, V22, P1243, DOI [10.1007/s10044-019-00804-4, 10.1109/CLEI47609.2019.235114]; Chakraborty D., 2021, OpenCV Contour Approximation (cv2.approxPolyDP) PyImageSearch; CodeConvert, 2023, About us; Crokidakis N, 2023, Arxiv, DOI arXiv:2303.16870; Dennis Layton., 2023, Open AI Code Interpreter; Javaid M.A., 2013, SSRN Electron. J., DOI [10.2139/ssrn.2340905, DOI 10.2139/SSRN.2340905]; Koziolek H, 2023, Arxiv, DOI arXiv:2305.15809; Kumar Y, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12143095; Leonard K, 2016, INT C PATT RECOG, P3216, DOI 10.1109/ICPR.2016.7900130; Li R, 2023, Arxiv, DOI arXiv:2305.11202; Lovanshi M, 2024, MULTIMED TOOLS APPL, V83, P12705, DOI 10.1007/s11042-023-16001-9; Ma J, 2023, IEEE ACCESS, V11, P9547, DOI 10.1109/ACCESS.2023.3240313; Maurer B., 2023, Engrxiv, DOI [10.31224/2858, DOI 10.31224/2858]; Merow C, 2023, NAT ECOL EVOL, V7, P960, DOI 10.1038/s41559-023-02063-3; Meta A.I, 2020, Deep Learning to Translate between Programming Languages; Nikolic S, 2023, EUR J ENG EDUC, V48, P559, DOI 10.1080/03043797.2023.2213169; OMPC, 2008, About us; openai, Discussion with ChatGPT-4 on Motion Detection; pinimg, GIF Image of a Running Cheetah; Singh J., 2022, P 2022 4 INT C INVEN, P1722, DOI [10.1109/ICIRCA54612.2022.9985665, DOI 10.1109/ICIRCA54612.2022.9985665]; Skeleton App, 2023, About us; Soille P., 1999, Morphological Image Analysis: Principles and Applications; Tsai ML, 2023, EDUC CHEM ENG, V44, P71, DOI 10.1016/j.ece.2023.05.001; Usmani A, 2023, MULTIMED TOOLS APPL, V82, P46845, DOI 10.1007/s11042-023-15024-6; Vercel, 2023, AI Code Translator.; Wang TH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23125721; Yang NJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2191, DOI 10.1109/ROBIO.2013.6739794; Yang X., 2022, P INT C GUIDANCE NAV, P3130; Zarka N., 2008, P 2008 3 INT C INFOR, P1, DOI [10.1109/ICTTA.2008.4530098, DOI 10.1109/ICTTA.2008.4530098]	37	0	0	14	14	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	FEB	2024	14	3							992	10.3390/app14030992	http://dx.doi.org/10.3390/app14030992			20	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	HJ5P0		gold			2024-07-03	WOS:001159148100001
J	Montoro-Montarroso, A; Cantón-Correa, J; Rosso, P; Chulvi, B; Panizo-Lledot, A; Huertas-Tato, J; Calvo-Figueras, B; Rementeria, MJ; Gómez-Romero, J				Montoro-Montarroso, Andres; Canton-Correa, Javier; Rosso, Paolo; Chulvi, Berta; Panizo-Lledot, Angel; Huertas-Tato, Javier; Calvo-Figueras, Blanca; Jose Rementeria, M.; Gomez-Romero, Juan			Fighting disinformation with artificial intelligence: fundamentals, advances and challenges	PROFESIONAL DE LA INFORMACION			English	Article						Journalism; Disinformation; Computing; Artificial intelligence; AI; Machine learning; Fact-checking; Datasets; Natural language processing; NLP; Social network analysis; Deepfakes; Large language models.	FAKE NEWS; DEEPFAKES	Internet and social media have revolutionised the way news is distributed and consumed. However, the constant flow of massive amounts of content has made it difficult to discern between truth and falsehood, especially in online platforms plagued with malicious actors who create and spread harmful stories. Debunking disinformation is costly, which has put artificial intelligence (AI) and, more specifically, machine learning (ML) in the spotlight as a solution to this problem. This work revises recent literature on AI and ML techniques to combat disinformation, ranging from automatic classification to feature extraction, as well as their role in creating realistic synthetic content. We conclude that ML advances have been mainly focused on automatic classification and scarcely adopted outside research labs due to their dependence on limited-scope datasets. Therefore, research efforts should be redirected towards developing AI-based systems that are reliable and trustworthy in supporting humans in early disinformation detection instead of fully automated solutions.	[Montoro-Montarroso, Andres; Gomez-Romero, Juan] Univ Granada, Decsai, Citic UGR, Periodista Rafael Gomez Montero 2, Granada 18014, Spain; [Canton-Correa, Javier] Univ Int La Rioja, Fac Ciencias Sociales & Humanidades, La Rioja, Spain; [Canton-Correa, Javier] Univ Granada, Decsai, Citic UGR, Granada, Spain; [Rosso, Paolo; Chulvi, Berta] Univ Politecn Valencia, Pattern Recognit & Human Language Technol PRHLT, Cami Vera,S-N, Valencia 46022, Spain; [Panizo-Lledot, Angel; Huertas-Tato, Javier] Univ Politecn Madrid, Escuela Tecn Super Ingn Sistemas Informat, Alan Turing,S-N, Madrid 28031, Spain; [Calvo-Figueras, Blanca] BSC, Language Technol Unit, Placa Eusebi Guell,1-3, Barcelona 08034, Spain; [Jose Rementeria, M.] BSC, Social & Media Impact Evaluat, Placa Eusebi Guell,1-3, Barcelona 08034, Spain	University of Granada; Universidad Internacional de La Rioja (UNIR); University of Granada; Universitat Politecnica de Valencia; Universidad Politecnica de Madrid	Montoro-Montarroso, A (corresponding author), Univ Granada, Decsai, Citic UGR, Periodista Rafael Gomez Montero 2, Granada 18014, Spain.	andres.montoro@ugr.es; javicanton@ugr.es; prosso@dsic.upv.es; berta.chulvi@upv.es; angel.panizo@upm.es; javier.huertas.tato@upm.es; blanca.calvo@bsc.es; maria.rementeria@bsc.es; jgomez@decsai.ugr.es	Cantón, Javier/A-5771-2019; Gomez Romero, Juan/F-7550-2011	Cantón, Javier/0000-0002-8466-1679; Rementeria Nunez, Maria Jose/0000-0002-3140-1160; Gomez Romero, Juan/0000-0003-0439-3692; Montoro Montarroso, Andres/0000-0003-1893-3346; Chulvi, Berta/0000-0003-1169-0978	European Commission [2020-EU-IA-0252]	European Commission(European Union (EU)European Commission Joint Research Centre)	This work was funded by the European Commission, project Iberifier (Iberian Digital Media Research and Fact-Checking Hub), under the call CEF-TC-2020-2 (European Digital Media Observatory), grant number 2020-EU-IA-0252.	Afroz S, 2012, P IEEE S SECUR PRIV, P461, DOI 10.1109/SP.2012.34; Aggarwal CC, 2011, SOCIAL NETWORK DATA ANALYTICS, P1; Amador Julio, 2019, P C TRUTH TRUST ONL, DOI [10.36370/tto.2019.4, DOI 10.36370/TTO.2019.4]; Arnold Phoebe, 2020, Full fact17 December; Azevedo L, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P41; Barabasi AL, 2016, NETWORK SCIENCE, P1; Bedi P, 2016, WIRES DATA MIN KNOWL, V6, P115, DOI 10.1002/widm.1178; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035; Bonet-Jover A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114340; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buda Jakab, 2020, WORKING NOTES CLEF 2, V2696; Camacho D, 2020, INFORM FUSION, V63, P88, DOI 10.1016/j.inffus.2020.05.009; Cambria E, 2014, KNOWL-BASED SYST, V69, P1, DOI 10.1016/j.knosys.2014.07.002; Castelo S, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P975, DOI 10.1145/3308560.3316739; Dagar D, 2022, INT J MULTIMED INF R, V11, P219, DOI 10.1007/s13735-022-00241-w; Das A, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103219; Davis CA, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P273, DOI 10.1145/2872518.2889302; de Souza MC, 2022, MACH LEARN, V111, P3549, DOI 10.1007/s10994-021-06111-6; Del Vicario M, 2016, SCI REP-UK, V6, DOI 10.1038/srep37825; Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301; des Mesnards NG, 2022, OPER RES, V70, P1, DOI 10.1287/opre.2021.2118; Dong XS, 2020, IEEE T COMPUT SOC SY, V7, P1386, DOI 10.1109/TCSS.2020.3027639; Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Ghanem B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P679; Giachanou A, 2022, DATA KNOWL ENG, V138, DOI 10.1016/j.datak.2021.101960; Giachanou A, 2021, J ASSOC INF SCI TECH, V72, P1117, DOI 10.1002/asi.24480; Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091; Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Graves L., 2018, UNDERSTANDING PROMIS; Graves L, 2016, J COMMUN, V66, P102, DOI 10.1111/jcom.12198; Greengard S, 2020, COMMUN ACM, V63, P17, DOI 10.1145/3371409; Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706; Guo B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3393880; Guo ZJ, 2022, T ASSOC COMPUT LING, V10, P178, DOI 10.1162/tacl_a_00454; Hangloo S, 2022, MULTIMEDIA SYST, V28, P2391, DOI 10.1007/s00530-022-00966-y; Harrigan P, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102246; Jing J, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103120; John O. P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260; Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600; Kang S, 2020, INT CONF UBIQUIT INF, DOI 10.1109/imcom48794.2020.9001800; Karras T., 2017, INT C LEARNING REPRE; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kartal YS, 2023, IEEE T COMPUT SOC SY, V10, P362, DOI 10.1109/TCSS.2021.3138642; Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552; Konstantinovskiy Lev, 2021, ACM Digital Threats: Research Practice, V2, DOI 10.1145/3412869; Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019; La -Barbera David, 2022, P 6 WORKSH NAT LANG, V3287; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li D, 2021, IEEE ACCESS, V9, P29356, DOI 10.1109/ACCESS.2021.3058809; Li S, 2022, INT J INTELL SYST, V37, P12235, DOI 10.1002/int.23084; Li X, 2022, MULTIMED TOOLS APPL, V81, P19341, DOI 10.1007/s11042-021-11065-x; Liu Y, 2018, AAAI CONF ARTIF INTE, P354; Liu Y, 2016, IEEE T COMPUT SOC SY, V3, P46, DOI 10.1109/TCSS.2016.2612980; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Marcus Gary, 2022, Scientific American19 December; Martin A, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109265; Masood M, 2023, APPL INTELL, V53, P3974, DOI 10.1007/s10489-022-03766-z; Meel P, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.115002; Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986; Megahed F. M., 2023, How generative ai models such as chatgpt can be (mis)used in spc practice, education, DOI 10.48550/ARXIV.2302.10916; Mikolov T, 2013, COMPUTING RES REPOSI; Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Molina-Solana M., 2018, I WORKSH DEEP LEARN, P1197; Nakamura K, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6149; Nakov Preslav, 2021, Experimental IR Meets Multilinguality, Multimodality, and Interaction: 12th International Conference of the CLEF Association, CLEF 2021, Proceedings. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (12880), P264, DOI 10.1007/978-3-030-85251-1_19; Nakov P. D., 2021, P 30 INT JOINT C ONA, P4551, DOI [10.24963/ijcai.2021/619, DOI 10.24963/IJCAI.2021/619]; Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133; Oehmichen A, 2019, IEEE ACCESS, V7, P126305, DOI 10.1109/ACCESS.2019.2938389; Paka WS, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107393; Pasi G, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177751; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062; Rana MS, 2022, IEEE ACCESS, V10, P25494, DOI 10.1109/ACCESS.2022.3154404; Rashkin H, 2017, P 2017 C EMP METH NA, P2931, DOI 10.18653/v1/d17-1317; Rath B, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00890-z; Ruffo G, 2023, COMPUT SCI REV, V47, DOI 10.1016/j.cosrev.2022.100531; Russell Stuart, 2020, Artificial intelligence: a modern approach; Saif S, 2022, J INTELL FUZZY SYST, V42, P2989, DOI 10.3233/JIFS-210625; Schuster T, 2020, COMPUT LINGUIST, V46, P499, DOI [10.1162/COLI_a_00380, 10.1162/coli_a_00380]; Serengil SI, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON ENGINEERING AND EMERGING TECHNOLOGIES (ICEET 2021), P863, DOI 10.1109/ICEET53442.2021.9659697; Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040; Shabani S, 2021, CEUR WORKSHOP PROC, V2846; Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7; Shao CC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196087; Shrestha A, 2022, INT J DATA SCI ANAL, V13, P385, DOI 10.1007/s41060-021-00291-z; Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927; Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994; Simko J, 2021, NEW REV HYPERMEDIA M, V27, P97, DOI 10.1080/13614568.2021.1889691; Singh P, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119302; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Song CG, 2022, NEUROCOMPUTING, V505, P362, DOI 10.1016/j.neucom.2022.07.057; Srinivas PYKL, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117952; Stella M, 2018, P NATL ACAD SCI USA, V115, P12435, DOI 10.1073/pnas.1803470115; Tacchini Eugenio, 2017, CEUR Workshop proceedings, V1960; Tingting Wang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P85, DOI 10.1007/978-3-642-37456-2_8; Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014; Vaswani A, 2017, ADV NEUR IN, V30; Vlachos A., 2018, P 27 INT C COMPUTATI, V1, P3346; Vogel I, 2020, CEUR Workshop proceedings, V2696; Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903; Wardle Claire, 2017, Information Disorder: Toward an Interdisciplinary Framework for Research and Policymaking; Xiong SF, 2023, INFORM FUSION, V93, P150, DOI 10.1016/j.inffus.2022.12.016; Xu F, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3477138; Yang J, 2021, IEEE INT WORKS INFOR, P86, DOI 10.1109/WIFS53200.2021.9648388; Yang S, 2019, AAAI CONF ARTIF INTE, P5644; Yin ZJ, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2337542.2337548; Zhang GB, 2024, J INF SCI, V50, P355, DOI 10.1177/01655515221087683; Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004; Zhou X., 2020, DIGITAL THREATS RES, V1, P1; Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046; Zhu Q., 2022, Proceedings of the Design Society, V2, P1825, DOI [DOI 10.1017/PDS.2022.185, https://doi.org/10.1017/pds.2022.185]	120	4	4	40	59	 EDICIONES PROFESIONALES INFORMACION SL-EPI	BARCELONA	MISTRAL, 36, BARCELONA, ALBOLOTE, SPAIN	1386-6710	1699-2407		PROF INFORM	Prof. Inf.		2023	32	3							e320322	10.3145/epi.2023.may.22	http://dx.doi.org/10.3145/epi.2023.may.22			16	Communication; Information Science & Library Science	Social Science Citation Index (SSCI)	Communication; Information Science & Library Science	T0HA0		hybrid			2024-07-03	WOS:001074871700002
C	Dave, VS; Pang, L; Cui, X; Luo, C; Zamani, H; Wu, L; Karypis, G			Assoc computing machinery	Dave, Vachik S.; Pang, Linsey; Cui, Xiquan; Luo, Chen; Zamani, Hamed; Wu, Lingfei; Karypis, George			The 3<SUP>rd</SUP> InternationalWorkshop on Interactive and Scalable Information Retrieval Methods for eCommerce (ISIR-eCom 2024)	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Information Retrieval; Interactive systems; Large Language models (LLMs) in eCommerce; Recommender Systems; eCommerce Search; Ranking models; Natural Language Processing (NLP) for eCommerce			[Dave, Vachik S.] Walmart Global Tech, Sunnyvale, CA 94086 USA; [Pang, Linsey] Salesforce, San Francisco, CA USA; [Cui, Xiquan] Home Depot, Atlanta, GA USA; [Luo, Chen] Amazon, Seattle, WA USA; [Zamani, Hamed] Univ Massachusetts Amherst, Amherst, MA USA; [Wu, Lingfei] Pinterest, New York, NY USA; [Karypis, George] Univ Minnesota Twin Cities, Minneapolis, MN USA	Salesforce; Amazon.com; University of Massachusetts System; University of Massachusetts Amherst; University of Minnesota System; University of Minnesota Twin Cities	Dave, VS (corresponding author), Walmart Global Tech, Sunnyvale, CA 94086 USA.	vachik.dave25@gmail.com; panglinsey@gmail.com; xiquan_cui@homedepot.com; cheluo@amazon.com; zamani@cs.umass.edu; lwu@email.wm.edu; karypis@umn.edu		Cui, Xiquan/0009-0005-5306-8839; Luo, Chen/0000-0001-5339-5817; Zamani, Hamed/0000-0002-0800-3340				[Anonymous], 2023, Statista dossier E-commerce worldwide; U.S. Department of Commerce, 2023, Quarterly Retail E-Commerce Sales	2	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1208	1209		10.1145/3616855.3635724	http://dx.doi.org/10.1145/3616855.3635724			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100171
J	Zhong, YS; Goodfellow, SD				Zhong, Yunshun; Goodfellow, Sebastian D.			Domain-specific language models pre-trained on construction management systems corpora	AUTOMATION IN CONSTRUCTION			English	Review						Construction management; Domain -specific large language models; Pre -training; Natural language processing (NLP); Transfer learning; Text classification (TC); Named entity recognition (NER); Corpus development		The rising demand for automated methods in the Construction Management Systems (CMS) sector highlights opportunities for the Transformer architecture, which enables pre-training Deep Learning models on large, unlabeled datasets for Natural Language Processing (NLP) tasks, outperforming traditional Recurrent Neural Network models. However, their potential in the CMS domain remains underexplored. Therefore, this research produced the first CMS domain corpora from academic papers and introduced an end-to-end pipeline for pretraining and fine-tuning domain-specific Pre-trained Language Models. Four corpora were constructed and transfer learning was employed to pre-train BERT and RoBERTa using the corpora. The best-performing models were then fine-tuned and outperformed models pre-trained on general corpora. In two key NLP tasks, text classification using an infrastructure condition prediction dataset and named entity recognition using an automatic construction control dataset, domain-specific pre-training improved F1 scores by 5.9% and 8.5%, respectively. These promising results demonstrate extended applicability beyond CMS to the Architecture, Engineering, and Construction sectors.	[Zhong, Yunshun; Goodfellow, Sebastian D.] Univ Toronto, Dept Civil & Mineral Engn, 35 St George St, Toronto, ON M5S 1A4, Canada	University of Toronto	Zhong, YS (corresponding author), Univ Toronto, Dept Civil & Mineral Engn, 35 St George St, Toronto, ON M5S 1A4, Canada.	yunshun.zhong@mail.utoronto.ca; sebastian.goodfellow@utoronto.ca						Al Qady M, 2010, J CONSTR ENG M, V136, P294, DOI 10.1061/(ASCE)CO.1943-7862.0000131; Ba JL., 2016, arXiv; Cheng MY, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103265; Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334; Deloose A, 2023, COMPUT IND, V145, DOI 10.1016/j.compind.2022.103830; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fang WL, 2020, ADV ENG INFORM, V44, DOI 10.1016/j.aei.2020.101060; Halevi G, 2017, J INFORMETR, V11, P823, DOI 10.1016/j.joi.2017.06.005; Han X, 2021, AI OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ke Q, 2018, J INFORMETR, V12, P706, DOI 10.1016/j.joi.2018.06.010; Kim Y, 2017, Arxiv, DOI arXiv:1702.00887; Li TS, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101333; Li Y., 2008, C EMPIRICAL METHODS, P21; Liu KJ, 2017, COMPUTING IN CIVIL ENGINEERING 2017: INFORMATION MODELLING AND DATA ANALYTICS, P316; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo X, 2018, IEEE ACCESS, V6, P5705, DOI 10.1109/ACCESS.2017.2785229; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Oktay Ozan, 2018, PREPRINT, DOI [DOI 10.48550/ARXIV, 10.48550/arxiv]; Patil Swati P., 2018, Bull. Pure Appl. Sci. Math. Stat., V37, P311; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Salehinejad H, 2018, Arxiv, DOI [arXiv:1801.01078, 10.48550/arXiv.1801.01078]; TRCA, 2021, 2021 erosion control infrastructures-asset management plan; ul Hassan F, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002122; Vaswani A, 2017, ADV NEUR IN, V30; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wu CK, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104059; Wu LT, 2022, AUTOMAT CONSTR, V135, DOI 10.1016/j.autcon.2021.104108; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Xu N, 2021, J MANAGE ENG, V37, DOI 10.1061/(ASCE)ME.1943-5479.0000870; Xu X, 2021, ADV ENG INFORM, V48, DOI 10.1016/j.aei.2021.101288; Zhang JS, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000536; Zhang RC, 2023, AUTOMAT CONSTR, V145, DOI 10.1016/j.autcon.2022.104540; Zhang RCA, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103834; Zhao J., 2020, P 37 INT C MACH LEAR, V119, P11365; Zheng Z, 2023, Arxiv, DOI [arXiv:2308.08728, DOI 10.48550/ARXIV.2308.08728, 10.48550/arXiv.2308.08728]; Zheng Z, 2024, ENG APPL ARTIF INTEL, V127, DOI 10.1016/j.engappai.2023.107207; Zheng Z, 2022, AUTOMAT CONSTR, V142, DOI 10.1016/j.autcon.2022.104524; Zheng Z, 2022, COMPUT IND, V142, DOI 10.1016/j.compind.2022.103733; Zhou P, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000513; Zhou YC, 2022, COMPUT IND, V142, DOI 10.1016/j.compind.2022.103746; Zhu J, 2005, J COMPUT GRAPH STAT, V14, P185, DOI 10.1198/106186005X25619; Zhuang ZX, 2022, Arxiv, DOI [arXiv:2202.00089, DOI 10.48550/ARXIV.2202.00089]	44	0	0	28	28	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0926-5805	1872-7891		AUTOMAT CONSTR	Autom. Constr.	APR	2024	160								105316	10.1016/j.autcon.2024.105316	http://dx.doi.org/10.1016/j.autcon.2024.105316		FEB 2024	14	Construction & Building Technology; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	KY9V3		hybrid			2024-07-03	WOS:001183655800001
J	Rauniyar, A; Hagos, DH; Jha, D; Hakegard, JE; Bagci, U; Rawat, DB; Vlassov, V				Rauniyar, Ashish; Hagos, Desta Haileselassie; Jha, Debesh; Hakegard, Jan Erik; Bagci, Ulas; Rawat, Danda B.; Vlassov, Vladimir			Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions	IEEE INTERNET OF THINGS JOURNAL			English	Article						Artificial intelligence (AI); communication; data privacy; edge computing; federated learning (FL); foundational model (FMs); large language model (LLM); medical applications; security	OF-THE-ART; HEALTH-CARE; BIG DATA; PRIVACY; COMMUNICATION; FRAMEWORK; SECURITY; TECHNOLOGIES; INTERNET; HIPAA	With the advent of the Internet of Things (IoT), artificial intelligence (AI), machine learning (ML), and deep learning (DL) algorithms, the landscape of data-driven medical applications has emerged as a promising avenue for designing robust and scalable diagnostic and prognostic models from medical data. This has gained a lot of attention from both academia and industry, leading to significant improvements in healthcare quality. However, the adoption of AI-driven medical applications still faces tough challenges, including meeting security, privacy, and Quality-of-Service (QoS) standards. Recent developments in federated learning (FL) have made it possible to train complex machine-learned models in a distributed manner and have become an active research domain, particularly processing the medical data at the edge of the network in a decentralized way to preserve privacy and address security concerns. To this end, in this article, we explore the present and future of FL technology in medical applications where data sharing is a significant challenge. We delve into the current research trends and their outcomes, unraveling the complexities of designing reliable and scalable FL models. This article outlines the fundamental statistical issues in FL, tackles device-related problems, addresses security challenges, and navigates the complexity of privacy concerns, all while highlighting its transformative potential in the medical field. Our study primarily focuses on medical applications of FL, particularly in the context of global cancer diagnosis. We highlight the potential of FL to enable computer-aided diagnosis tools that address this challenge with greater effectiveness than traditional data-driven methods. Recent literature has shown that FL models are robust and generalize well to new data, which is essential for medical applications. We hope that this comprehensive review will serve as a checkpoint for the field, summarizing the current state of the art and identifying open problems and future research directions.	[Rauniyar, Ashish; Hakegard, Jan Erik] SINTEF Digital, Sustainable Commun Technol, N-7034 Trondheim, Norway; [Jha, Debesh; Rawat, Danda B.] Howard Univ, Dept Elect Engn & Comp Sci, Coll Engn & Architecture, DoD Ctr Excellence Artificial Intelligence & Mach, Washington, DC 20059 USA; [Jha, Debesh; Bagci, Ulas] Northwestern Univ, Dept Radiol, Machine & Hybrid Intelligence Lab, Chicago, IL 60611 USA; [Vlassov, Vladimir] KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, Dept Comp Sci, S-11428 Stockholm, Sweden	SINTEF; Howard University; Northwestern University; Royal Institute of Technology	Rauniyar, A (corresponding author), SINTEF Digital, Sustainable Commun Technol, N-7034 Trondheim, Norway.	ashish.rauniyar@sintef.no; desta.hagos@howard.edu; debesh.jha@northwestern.edu; jan.e.hakegard@sintef.n; ulas.bagci@northwestern.edu; danda.rawat@howard.edu; vladv@kth.se	; Rauniyar, Ashish/C-9539-2018; Rawat, Danda B./B-2973-2012	Jha, Debesh/0000-0002-8078-6730; Rauniyar, Ashish/0000-0002-2142-9522; Rawat, Danda B./0000-0003-3638-3464	Comprehensive Privacy and Security for Resilient CPS/IoT (COPS) - Research Council of Norway [300102]	Comprehensive Privacy and Security for Resilient CPS/IoT (COPS) - Research Council of Norway	This work was supported by the Comprehensive Privacy and Security for Resilient CPS/IoT (COPS) Project funded by the Research Council of Norway under Project 300102.	Abdellatif AA, 2020, IEEE NETWORK, V34, P312, DOI 10.1109/MNET.011.1900553; AbdulRahman S, 2021, IEEE INTERNET THINGS, V8, P5476, DOI 10.1109/JIOT.2020.3030072; Abreha HG, 2021, INT J AD HOC UBIQ CO, V36, P114, DOI 10.1504/IJAHUC.2021.113384; Abu Sayeed M, 2019, IEEE T CONSUM ELECTR, V65, P359, DOI 10.1109/TCE.2019.2917895; Adnan M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05539-7; Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056; Aldoj N, 2020, EUR RADIOL, V30, P1243, DOI 10.1007/s00330-019-06417-z; Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]; Ali M, 2023, IEEE J BIOMED HEALTH, V27, P778, DOI 10.1109/JBHI.2022.3181823; Ali S, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-52063-x; Ali S, 2021, Arxiv, DOI arXiv:2106.04463; Allam Z, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8010046; Amin SU, 2021, IEEE ACCESS, V9, P45, DOI 10.1109/ACCESS.2020.3045115; Andrew J, 2021, J BUS ETHICS, V168, P565, DOI 10.1007/s10551-019-04239-z; Annas GJ, 2003, NEW ENGL J MED, V348, P1486, DOI 10.1056/NEJMlim035027; [Anonymous], 2020, Pysyft; [Anonymous], 2019, An application framework optimized for healthcare and life sciences developers; [Anonymous], 2019, An industrial grade federated learning framework; [Anonymous], 2019, TensorFlow federated: Machine learning on decentralized data; [Anonymous], 2016, PaddleFL; Antunes RS, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3501813; Armato SG, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.4.044501; Asif-Ur-Rahman M, 2019, IEEE INTERNET THINGS, V6, P4049, DOI 10.1109/JIOT.2018.2876088; Bagdasaryan E, 2020, PR MACH LEARN RES, V108, P2938; Bai X, 2021, NAT MACH INTELL, V3, P1081, DOI 10.1038/s42256-021-00421-z; Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Banerjee S, 2020, LECT NOTES ARTIF INT, V12576, P3, DOI 10.1007/978-3-030-64984-5_1; Bao XL, 2019, 5TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2019), P151, DOI 10.1109/BIGCOM.2019.00030; Bernecker T, 2022, Arxiv, DOI arXiv:2205.11096; Bhagoji AN, 2019, PR MACH LEARN RES, V97; Bhattacharya A., 2022, arXiv; Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982; Brenci N. S., 2020, Digital Health in Focus of Predictive, Preventive and Personalised Medicine, P101; Brisimi TS, 2018, INT J MED INFORM, V112, P59, DOI 10.1016/j.ijmedinf.2018.01.007; Cai Q, 2019, IEEE ACCESS, V7, P133583, DOI 10.1109/ACCESS.2019.2941419; Caldas S., 2018, arXiv; Cao Y, 2022, COMM COM INF SC, V1554, P21, DOI 10.1007/978-981-19-1166-8_3; Cascini F, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.667819; Cetinkaya A. E., 2021, 2021 6 INT C COMP SC, P429; Cha D, 2021, JMIR MED INF, V9, DOI 10.2196/26598; Chen P, 2022, J SYST ARCHITECT, V126, DOI 10.1016/j.sysarc.2022.102474; Chen T, 2020, PR MACH LEARN RES, V119; Chen X, 2018, IEEE NETWORK, V32, P61, DOI 10.1109/MNET.2018.1700145; Chen XH, 2019, IEEE INT CONF BIG DA, P5469, DOI 10.1109/BigData47090.2019.9006173; Chen YQ, 2020, IEEE INTELL SYST, V35, P83, DOI 10.1109/MIS.2020.2988604; Chen YJ, 2019, Arxiv, DOI arXiv:1905.05142; Cheng Y, 2020, COMMUN ACM, V63, P33, DOI 10.1145/3387107; Choi Young B, 2006, J Med Syst, V30, P57, DOI 10.1007/s10916-006-7405-0; Dang LM, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8070768; Dang TK, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3514500; Dayan I, 2021, NAT MED, V27, P1735, DOI 10.1038/s41591-021-01506-3; de Moura J, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108190; Deng YH, 2022, IEEE T PARALL DISTR, V33, P1996, DOI 10.1109/TPDS.2021.3134647; Desai HB, 2021, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY '21), P101, DOI 10.1145/3422337.3447837; Diddee H, 2020, IEEE INT CONF AUTOM, P1370, DOI 10.1145/3324884.3418911; Dimitrov DV, 2016, HEALTHC INFORM RES, V22, P156; Ding J, 2022, IEEE T SIGNAL PROCES, V70, P2443, DOI 10.1109/TSP.2022.3169432; Nguyen DC, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3501296; Dou Q, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00431-6; Engelhardt MA, 2017, TECHNOL INNOV MANAG, V7, P22, DOI 10.22215/timreview/1111; Fallah A., 2020, Adv. Neural Inf. Proces. Syst., V33, P3557; Fang MH, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1623; Feki I, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107330; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Fredrikson M, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P17; Frizzo-Barker J, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.10.014; García-Valls M, 2020, FUTURE GENER COMP SY, V108, P882, DOI 10.1016/j.future.2018.07.001; Geyer R.C., 2017, arXiv; Görnitz N, 2014, JMLR WORKSH CONF PRO, V33, P293; Grama M, 2020, Arxiv, DOI arXiv:2009.08294; Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Hakak S, 2020, IEEE INT CONF BIG DA, P3423, DOI 10.1109/BigData50022.2020.9377873; Hartzog W., 2020, BCL Rev., V61, P1687, DOI [10.2139/ssrn.3441502, DOI 10.2139/SSRN.3441502]; Hasselgren A, 2020, INT J MED INFORM, V134, DOI 10.1016/j.ijmedinf.2019.104040; He CY, 2020, Arxiv, DOI arXiv:2007.13518; Hesseberg R., 2020, Federated learning for dementia classification in a European multicentre dementia study; Hidalgo M, 2010, NEW ENGL J MED, V362, P1605, DOI 10.1056/NEJMra0901557; Ho Trang-Thi., 2021, arXiv; Hölbl M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100470; Hoofnagle CJ, 2019, INF COMMUN TECHNOL L, V28, P65, DOI 10.1080/13600834.2019.1573501; Huang L, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103291; Internet of Things, 2016, Smart Healthcare Service, Wellness IT; Itahara S, 2021, Arxiv, DOI arXiv:2008.06180; Jaladanki S. K, 2021, PREPRINT; Jayaram KR, 2020, IEEE INT CONF CLOUD, P201, DOI 10.1109/CLOUD49709.2020.00039; Ji SX, 2024, Arxiv, DOI arXiv:2102.12920; Jimenez-Sanchez Amelia, 2023, Comput Methods Programs Biomed, V229, P107318, DOI 10.1016/j.cmpb.2022.107318; Jimenez-Sanchez A, 2021, Arxiv, DOI arXiv:2107.02504; John MM, 2020, 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON SOFTWARE AND SYSTEM PROCESSES, ICSSP, P1, DOI [10.1145/3379177.3388892, 10.1109/IRMMW-THz46771.2020.9370765]; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kallel A, 2022, J SUPERCOMPUT, V78, P7078, DOI 10.1007/s11227-021-04166-9; Kang JW, 2019, IEEE INTERNET THINGS, V6, P10700, DOI 10.1109/JIOT.2019.2940820; Kassem H, 2022, Arxiv, DOI arXiv:2203.07345; Kennedy GT, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30265-z; Kuo TT, 2017, J AM MED INFORM ASSN, V24, P1211, DOI 10.1093/jamia/ocx068; Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666; Li E, 2020, IEEE T WIREL COMMUN, V19, P447, DOI 10.1109/TWC.2019.2946140; Li L, 2020, COMPUT IND ENG, V149, DOI 10.1016/j.cie.2020.106854; Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599; Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057; Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749; Li WQ, 2019, LECT NOTES COMPUT SC, V11861, P133, DOI 10.1007/978-3-030-32692-0_16; Li X, 2020, Arxiv, DOI arXiv:1907.02189; Li XX, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101765; Lim WYB, 2020, IEEE COMMUN SURV TUT, V22, P2031, DOI 10.1109/COMST.2020.2986024; Lin BL, 2022, Arxiv, DOI arXiv:2104.08815; Liu BY, 2020, Arxiv, DOI arXiv:2007.05592; Liu QD, 2021, PROC CVPR IEEE, P1013, DOI 10.1109/CVPR46437.2021.00107; Liu SQ, 2018, LECT NOTES COMPUT SC, V11071, P851, DOI 10.1007/978-3-030-00934-2_94; Liu Y, 2020, Arxiv, DOI [arXiv:2012.01973, 10.48550/ARXIV.2012.01973]; Liu Y, 2020, IEEE INTERNET THINGS, V7, P7751, DOI 10.1109/JIOT.2020.2991401; Lo SK, 2022, J SYST SOFTWARE, V191, DOI 10.1016/j.jss.2022.111357; Lu W., 2022, IEEE Trans. Big Data, DOI DOI 10.1109/TBDATA.2022.3177197; Ludwig H, 2020, Arxiv, DOI arXiv:2007.10987; Fernández-Alemán JL, 2013, J BIOMED INFORM, V46, P541, DOI 10.1016/j.jbi.2012.12.003; Luo J, 2016, BIOMED INFORM INSIGH, V8, P1, DOI 10.4137/BII.S31559; Lv ZH, 2017, IEEE T IND INFORM, V13, P1891, DOI 10.1109/TII.2017.2650204; Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318; Maier-Hein L, 2017, NAT BIOMED ENG, V1, P691, DOI 10.1038/s41551-017-0132-7; Malekzadeh M., 2021, P 2 AAAI WORKSH PRIV, P1; Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Mothukuri V, 2021, FUTURE GENER COMP SY, V115, P619, DOI 10.1016/j.future.2020.10.007; Mugunthan V, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3085, DOI 10.1145/3340531.3412771; Muthukrishnan R, 2023, Arxiv, DOI arXiv:2206.05575; Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28; Galtier MN, 2019, Arxiv, DOI [arXiv:1910.11567, 10.48550/arXiv.1910.11567, DOI 10.48550/ARXIV.1910.11567]; Nakamoto S., 2008, BITCOIN, DOI DOI 10.2139/SSRN.3440802; Naz S, 2022, INT J INTELL SYST, V37, P2371, DOI 10.1002/int.22777; Nguyen DC, 2021, IEEE INTERNET THINGS, V8, P12806, DOI 10.1109/JIOT.2021.3072611; Nguyen DC, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9347951; Nguyen TV, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12833-x; Pace P, 2019, IEEE T IND INFORM, V15, P481, DOI 10.1109/TII.2018.2843169; Paragliola G, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116109; Passerat-Palmbach J, 2019, Arxiv, DOI arXiv:1910.12603; Pati S, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33407-5; Peltonen E., 2020, arXiv; Pfitzner B, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3412357; Polap D, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102748; Pournader M, 2020, INT J PROD RES, V58, P2063, DOI 10.1080/00207543.2019.1650976; Qadri YA, 2020, IEEE COMMUN SURV TUT, V22, P1121, DOI 10.1109/COMST.2020.2973314; Qayyum A, 2021, Arxiv, DOI [arXiv:2101.07511, DOI 10.1109/OJCS.2022.3206407]; Qian Feng, 2021, Int J Qual Health Care, V33, DOI 10.1093/intqhc/mzab010; Qu L., 2021, arXiv; Rafique W, 2020, IEEE COMMUN SURV TUT, V22, P1761, DOI 10.1109/COMST.2020.2997475; Rahman A, 2018, IEEE ACCESS, V6, P72469, DOI 10.1109/ACCESS.2018.2881246; Rahman MA, 2018, IEEE ACCESS, V6, P61876, DOI 10.1109/ACCESS.2018.2875242; Raisaro JL, 2020, J AM MED INFORM ASSN, V27, P1721, DOI 10.1093/jamia/ocaa172; Ramanan P, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2020), P72, DOI 10.1109/Blockchain50366.2020.00017; Rasouli JJ, 2021, GLOB SPINE J, V11, P556, DOI 10.1177/2192568220915718; Rausch T., 2019, P USENIX WORKSH HOT, P1; Rawla P, 2019, WORLD J ONCOL, V10, P10, DOI 10.14740/wjon1166; Ray PP, 2019, J NETW COMPUT APPL, V140, P1, DOI 10.1016/j.jnca.2019.05.005; Reina G.A., 2021, arXiv; Remedios SW, 2020, LECT NOTES COMPUT SC, V12444, P170, DOI 10.1007/978-3-030-60548-3_17; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Rodríguez-Barroso N, 2020, INFORM FUSION, V64, P270, DOI 10.1016/j.inffus.2020.07.009; Romanini D, 2021, Arxiv, DOI arXiv:2104.00489; Roth HR, 2020, LECT NOTES COMPUT SC, V12444, P181, DOI 10.1007/978-3-030-60548-3_18; Díaz JSP, 2023, NEUROCOMPUTING, V518, P142, DOI 10.1016/j.neucom.2022.11.011; Sakib S, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500351; Salam MA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0252573; Samek W, 2017, Arxiv, DOI arXiv:1708.08296; Sarma KV, 2021, J AM MED INFORM ASSN, V28, P1259, DOI 10.1093/jamia/ocaa341; Sha KW, 2020, DIGIT COMMUN NETW, V6, P195, DOI 10.1016/j.dcan.2019.08.006; Shae Z, 2018, INT CON DISTR COMP S, P1290, DOI 10.1109/ICDCS.2018.00129; Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1; Sheller MJ, 2019, LECT NOTES COMPUT SC, V11383, P92, DOI 10.1007/978-3-030-11723-8_9; Shen BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061207; Shen C, 2021, LECT NOTES COMPUT SC, V12969, P101, DOI 10.1007/978-3-030-90874-4_10; Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198; Shi YM, 2020, IEEE COMMUN SURV TUT, V22, P2167, DOI 10.1109/COMST.2020.3007787; Silva S, 2020, LECT NOTES COMPUT SC, V12444, P201, DOI 10.1007/978-3-030-60548-3_20; Slazyk F, 2022, Arxiv, DOI arXiv:2204.05203; Smedsrud PH, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00920-z; Smith WP, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0609-7; Sozinov K, 2018, IEEE INT SYMP PARAL, P1103, DOI 10.1109/BDCloud.2018.00164; Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660; Tan K., 2020, P INT C UK CHIN EM T, P1; Tang ZY, 2018, IEEE T MED IMAGING, V37, P2224, DOI 10.1109/TMI.2018.2824243; Ul Alam M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155025; Ulhaq A, 2020, Arxiv, DOI arXiv:2010.06177; Vaid A, 2021, JMIR MED INF, V9, DOI 10.2196/24207; Vaid Akhil, 2020, medRxiv, DOI 10.1101/2020.08.11.20172809; van Berlo B., 2019, Unsupervised feature learning in a federated setting for human activity detection; Vazirani AA, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0211-0; Wang G, 2019, Arxiv, DOI arXiv:1905.04519; Wang PC, 2020, LECT NOTES COMPUT SC, V12444, P192, DOI 10.1007/978-3-030-60548-3_19; Wang R, 2021, IEEE NETWORK, V35, P14, DOI [10.1109/MNET.011.2000704, 10.1109/MNET.011.2000739]; Wang RJ, 2023, IEEE J BIOMED HEALTH, V27, P854, DOI 10.1109/JBHI.2022.3157725; Wang XF, 2019, IEEE NETWORK, V33, P156, DOI 10.1109/MNET.2019.1800286; Wang Y, 2016, IEEE T MED IMAGING, V35, P589, DOI 10.1109/TMI.2015.2485299; Wu Q, 2022, IEEE T MOBILE COMPUT, V21, P2818, DOI 10.1109/TMC.2020.3045266; Wu R., 2012, Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium, P593; Xia Y., 2021, arXiv; Xiaomeng Chen, 2021, 2021 IEEE 7th International Conference on Cloud Computing and Intelligent Systems (CCIS), P52, DOI 10.1109/CCIS53392.2021.9754623; Xu DL, 2020, Arxiv, DOI arXiv:2003.12172; Xu J, 2021, J HEALTHC INFORM RES, V5, P1, DOI 10.1007/s41666-020-00082-4; Xu XA, 2023, Arxiv, DOI arXiv:2206.07156; Xu Yongchao, 2020, medRxiv, DOI 10.1101/2020.05.10.20096073; Yan B., 2021, P INT C ART INT SEC, P41; Yang D, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.101992; Yu H, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P393, DOI 10.1145/3375627.3375840; Yu H, 2020, IEEE INTELL SYST, V35, P58, DOI 10.1109/MIS.2020.2987774; Yu QH, 2020, PROC CVPR IEEE, P4125, DOI 10.1109/CVPR42600.2020.00418; Yu W, 2018, IEEE ACCESS, V6, P6900, DOI 10.1109/ACCESS.2017.2778504; Yuan BC, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16061070; Zhang PY, 2021, IEEE INTERNET THINGS, V8, P2459, DOI 10.1109/JIOT.2020.3017742; Zhang WS, 2021, IEEE INTERNET THINGS, V8, P15884, DOI 10.1109/JIOT.2021.3056185; Zhao Y, 2021, IEEE INTERNET THINGS, V8, P1817, DOI 10.1109/JIOT.2020.3017377; Zheng SH, 2021, IEEE J SEL AREA COMM, V39, P2150, DOI 10.1109/JSAC.2020.3041388; Zheng ZH, 2022, CONNECT SCI, V34, P1, DOI 10.1080/09540091.2021.1936455; Zhu HY, 2021, NEUROCOMPUTING, V465, P371, DOI 10.1016/j.neucom.2021.07.098; Zubaydi HD, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060679	216	3	3	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2327-4662			IEEE INTERNET THINGS	IEEE Internet Things J.	MAR 1	2024	11	5					7374	7398		10.1109/JIOT.2023.3329061	http://dx.doi.org/10.1109/JIOT.2023.3329061			25	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	NW3X2		Green Submitted, Green Published			2024-07-03	WOS:001203463700006
J	Robinson, MA; Belzberg, M; Thakker, S; Bibee, K; Merkel, E; Macfarlane, DF; Lim, J; Scott, JF; Deng, M; Lewin, J; Soleymani, D; Rosenfeld, D; Liu, R; Liu, TYA; Ng, E				Robinson, Michelle A.; Belzberg, Micah; Thakker, Sach; Bibee, Kristin; Merkel, Emily; Macfarlane, Deborah F.; Lim, Jordan; Scott, Jeffrey F.; Deng, Min; Lewin, Jesse; Soleymani, David; Rosenfeld, David; Liu, Rosemarie; Liu, Tin Yan Alvin; Ng, Elise			Assessing the accuracy, usefulness, and readability of artificialintelligence- generated responses to common dermatologic surgery questions for patient education: A double-blinded comparative study of ChatGPT and Google Bard	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Editorial Material						AI; artificial intelligence chatbots; ChatGPT; dermatologic surgery; Google Bard; health care information delivery; large language models; LLMs; Mohs surgery; patient education			[Robinson, Michelle A.; Belzberg, Micah; Bibee, Kristin; Merkel, Emily; Scott, Jeffrey F.] Johns Hopkins Sch Med, Dept Dermatol, 601 N Caroline St, Fl 8, Baltimore, MD 21287 USA; [Thakker, Sach; Liu, Rosemarie] Georgetown Univ, Sch Med, Washington, DC USA; [Macfarlane, Deborah F.] Univ Texas MD Anderson Canc Ctr, Dept Dermatol, Houston, TX USA; [Lim, Jordan] Emory Univ, Dept Dermatol, Sch Med, Atlanta, GA USA; [Deng, Min] Georgetown Univ Hosp, Medstar Washington Hosp Ctr, Dept Dermatol, Washington, DC USA; [Lewin, Jesse] Icahn Sch Med Mt Sinai, Kimberly & Er J Waldman Dept Dermatol, New York, NY USA; [Soleymani, David; Rosenfeld, David] Dermio Dermatol, Munster, IN USA; [Liu, Rosemarie] Metro Mohs Surg Ctr, Springfield, VA USA; [Liu, Tin Yan Alvin; Ng, Elise] Johns Hopkins Sch Med, Dept Ophthalmol, Baltimore, MD USA	Johns Hopkins University; Johns Hopkins Medicine; Georgetown University; University of Texas System; UTMD Anderson Cancer Center; Emory University; Georgetown University; MedStar Washington Hospital Center; Icahn School of Medicine at Mount Sinai; Johns Hopkins University; Johns Hopkins Medicine	Robinson, MA (corresponding author), Johns Hopkins Sch Med, Dept Dermatol, 601 N Caroline St, Fl 8, Baltimore, MD 21287 USA.	mmcnal11@jhmi.edu		Robinson, Michelle/0009-0007-3357-5467				Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; O'Hern K, 2023, JAAD INT, V12, P168, DOI 10.1016/j.jdin.2023.06.002; Weis B., 2003, Health literacy: a manual for clinicians; Young JN, 2023, J AM ACAD DERMATOL, V89, P602, DOI 10.1016/j.jaad.2023.05.024	4	2	2	2	2	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	MAY	2024	90	5					1078	1080		10.1016/j.jaad.2024.01.037	http://dx.doi.org/10.1016/j.jaad.2024.01.037			3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	SP6F4	38296195				2024-07-03	WOS:001235686700001
J	Abdollahi, H; Junttila, JP; Lehkonen, H				Abdollahi, Hooman; Junttila, Juha-Pekka; Lehkonen, Heikki			Clustering asset markets based on volatility connectedness to political news	JOURNAL OF INTERNATIONAL FINANCIAL MARKETS INSTITUTIONS & MONEY			English	Article						Markets and media; Volatility connectedness; Market clustering; Political news; Large language model	CRUDE-OIL; ECONOMIC-POLICY; EQUITY MARKETS; STOCK; DETERMINANTS; VARIANCE; RETURNS; RISK	To assess similarities in international asset markets' responses to political news, we construct a political news index using advanced natural language processing. We then examine how the volatility across international asset markets is connected to the development of our political news index by measuring the daily directional connectedness using a VAR-based framework. Finally, we apply an unsupervised algorithm to cluster markets based on their volatility connectedness to political news. Our analysis reveals eight distinct clusters that reflect the markets' sensitivities to political dynamics. This data-driven analysis offers insights into the influence of political developments on market volatility.	[Abdollahi, Hooman] UiT The Arctic Univ Norway, Sch Business & Econ, Tromso, Norway; [Junttila, Juha-Pekka] Univ Oulu, Business Sch, Dept Econ Accounting & Finance, Oulu, Finland; [Lehkonen, Heikki] Univ Jyvaskyla, Jyvaskyla Univ Sch Business & Econ, JyIMaF Res Grp, Jyvaskyla, Finland; [Abdollahi, Hooman] UiT, Hansine Hansens Veg 18, N-9019 Tromso, Norway	UiT The Arctic University of Tromso; University of Oulu; University of Jyvaskyla; UiT The Arctic University of Tromso	Abdollahi, H (corresponding author), UiT, Hansine Hansens Veg 18, N-9019 Tromso, Norway.	hooman.abdollahi@uit.no; juha.junttila@oulu.fi; heikki.lehkonen@jyu.fi						Abdollahi H, 2024, N AM J ECON FINANC, V71, DOI 10.1016/j.najef.2024.102091; Abdollahi H, 2023, ENERG ECON, V122, DOI 10.1016/j.eneco.2023.106711; Abolghasemi Y, 2021, INT J FINANC ECON, V26, P4534, DOI 10.1002/ijfe.2029; Al-Maadid A, 2020, RES INT BUS FINANC, V52, DOI 10.1016/j.ribaf.2019.101102; Apostolakis GN, 2021, J INT FINANC MARK I, V74, DOI 10.1016/j.intfin.2021.101383; Ashraf BN, 2021, FINANC RES LETT, V41, DOI 10.1016/j.frl.2020.101857; Bae KH, 2003, REV FINANC STUD, V16, P717, DOI 10.1093/rfs/hhg012; Baker SR, 2016, Q J ECON, V131, P1593, DOI 10.1093/qje/qjw024; Bali TG, 2005, J FUTURES MARKETS, V25, P873, DOI 10.1002/fut.20169; Balli F, 2015, INT REV FINANC ANAL, V42, P349, DOI 10.1016/j.irfa.2015.08.010; Bastos JA, 2014, QUANT FINANC, V14, P2121, DOI 10.1080/14697688.2012.726736; BECKERS S, 1983, J BUS, V56, P97, DOI 10.1086/296188; Ben Rejeb A, 2016, RES INT BUS FINANC, V36, P140, DOI 10.1016/j.ribaf.2015.09.022; Benlagha N, 2022, ENERG ECON, V115, DOI 10.1016/j.eneco.2022.106348; Bialkowski J, 2008, J BANK FINANC, V32, P1941, DOI 10.1016/j.jbankfin.2007.12.021; Bilson C.M., 2002, International Review of Financial Analysis, V11, P1, DOI [https://doi.org/10.1016/S0927-538X(01)00020-8, DOI 10.1016/S0927-538X(01)00020-8]; Bonyadi A, 2013, SAGE OPEN, V3, DOI 10.1177/2158244013494863; Caldara D, 2022, AM ECON REV, V112, P1194, DOI 10.1257/aer.20191823; Cerqueti R., 2023, Ann. Oper. Res., P1; Chan WS, 2003, J FINANC ECON, V70, P223, DOI 10.1016/S0304-405X(03)00146-6; Chavez-Rodriguez MF, 2018, ENERGY STRATEG REV, V20, P35, DOI 10.1016/j.esr.2017.12.011; Chen CD, 2020, N AM J ECON FINANC, V54, DOI 10.1016/j.najef.2020.101234; Chowdhury M.B., 2005, Appl. Econ. Int. Dev., V5; Costola M, 2023, RES INT BUS FINANC, V64, DOI 10.1016/j.ribaf.2023.101881; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diebold FX, 2012, INT J FORECASTING, V28, P57, DOI 10.1016/j.ijforecast.2011.02.006; Ding Q, 2022, RES INT BUS FINANC, V60, DOI 10.1016/j.ribaf.2022.101618; Gala VD, 2023, J EMPIR FINANC, V72, P78, DOI 10.1016/j.jempfin.2023.03.004; Garge R., 2016, Australian J. Maritime Ocean Affairs, V8, P257; Gholipour HF, 2019, RES INT BUS FINANC, V48, P210, DOI 10.1016/j.ribaf.2019.01.004; GRIFFIN D, 1992, COGNITIVE PSYCHOL, V24, P411, DOI 10.1016/0010-0285(92)90013-R; Hanieh A, 2018, GLOB MID EAST, P1, DOI 10.1017/9781108614443; He F, 2021, FINANC RES LETT, V40, DOI 10.1016/j.frl.2020.101753; Hofstede G., 1991, Cultures and organizations; Jaforullah M., 2015, Is New Zealand's Economy Vulnerable to World Oil Market Shocks?; Jiang J., 2022, Expected Returns and Large Language Models; Jiang SR, 2022, RES INT BUS FINANC, V59, DOI 10.1016/j.ribaf.2021.101543; Jung B, 2023, OPEN ECON REV, V34, P617, DOI 10.1007/s11079-022-09690-6; Junttila J, 2018, J INT FINANC MARK I, V56, P255, DOI 10.1016/j.intfin.2018.01.002; Kangogo M, 2022, INT REV FINANC ANAL, V82, DOI 10.1016/j.irfa.2022.102161; Karolyi GA, 2003, HANDB ECON, V21, P975; Kia AN, 2018, EXPERT SYST APPL, V105, P159, DOI 10.1016/j.eswa.2018.03.037; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; Lehkonen H, 2015, J INT MONEY FINANC, V59, P77, DOI 10.1016/j.jimonfin.2015.06.002; León C, 2017, QUANT FINANC, V17, P1905, DOI 10.1080/14697688.2017.1357970; Li XR, 2019, INT J FORECASTING, V35, P1548, DOI 10.1016/j.ijforecast.2018.07.006; Liao JH, 2021, INT REV FINANC ANAL, V77, DOI 10.1016/j.irfa.2021.101822; Lucey B, 2021, ECON MODEL, V104, DOI 10.1016/j.econmod.2021.105635; Lucey B, 2010, JCMS-J COMMON MARK S, V48, P641; MacQueen J., 1967, P 5 BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6; Maghyereh AI, 2016, ENERG ECON, V57, P78, DOI 10.1016/j.eneco.2016.04.010; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; Morocco's foreign trade watchdog Office d'Echange, 2022, Morocco's annual balance of payments and international investment position 2022; Nassirtoussi AK, 2015, EXPERT SYST APPL, V42, P306, DOI 10.1016/j.eswa.2014.08.004; National Treasury Management Agency (NTMA) Economics, 2018, Impacts of the US economy on Ireland: A Quantitative and Qualitative Analysis; Nguyen NH, 2013, J INT FINANC MARK I, V26, P1, DOI 10.1016/j.intfin.2013.03.001; Okoroafor UC, 2022, FINANC RES LETT, V45, DOI 10.1016/j.frl.2021.102191; Pandey D.K., 2023, Research in International Business and Finance; PARKINSON M, 1980, J BUS, V53, P61, DOI 10.1086/296071; Patel R, 2022, INT REV FINANC ANAL, V80, DOI 10.1016/j.irfa.2022.102035; Peters EnriqueDussel., 2019, CHINAS FOREIGN DIREC; Phillips PCB, 2011, INT ECON REV, V52, P201, DOI 10.1111/j.1468-2354.2010.00625.x; Prasad N, 2018, INT REV FINANC ANAL, V60, P115, DOI 10.1016/j.irfa.2018.09.006; Otero JDQ, 2020, ENERG ECON, V86, DOI 10.1016/j.eneco.2020.104691; Santoro M., 2022, Brazil-China Relations in the 21st Century: the making of a strategic partnership; Shekhar V, 2010, ASIA-PAC REV, V17, P76, DOI 10.1080/13439006.2010.531114; Shiller RJ, 2017, AM ECON REV, V107, P967, DOI 10.1257/aer.107.4.967; Smales LA, 2022, INT REV FINANC ANAL, V79, DOI 10.1016/j.irfa.2021.101972; Sun Y., 2014, Africa in China's Foreign Policy, V4; The Swiss Federal Department of Foreign Affairs, 2019, Bilateral relations Switzerland-Czechia; Torrisi C.R., 2015, J. Finance Accountancy, V20, P1; Verma S., 2023, International Studies; Wisniewski TP, 2016, INT REV FINANC ANAL, V47, P15, DOI 10.1016/j.irfa.2016.06.015; Yang YJ, 2023, RES INT BUS FINANC, V66, DOI 10.1016/j.ribaf.2023.102006; Yarovaya L, 2022, J INT FINANC MARK I, V79, DOI 10.1016/j.intfin.2022.101589; Zivot E, 2002, J BUS ECON STAT, V20, P25, DOI 10.1198/073500102753410372	76	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1042-4431	1873-0612		J INT FINANC MARK I	J. Int. Financ. Mark. Inst. Money	JUN	2024	93								102004	10.1016/j.intfin.2024.102004	http://dx.doi.org/10.1016/j.intfin.2024.102004			25	Business, Finance; Economics	Social Science Citation Index (SSCI)	Business & Economics	TM8G8		hybrid			2024-07-03	WOS:001241766800001
C	Mukande, T; Ali, E; Caputo, A; Dong, RH; O'Connor, NE		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Mukande, Tendai; Ali, Esraa; Caputo, Annalina; Dong, Ruihai; O'Connor, Noel E.			MMCRec: Towards Multi-modal Generative AI in Conversational Recommendation	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Generative AI; Large Language Model; Conversational Recommendation; Graph Neural Network; Diffusion Model		Personalized recommendation systems have become integral in this digital age by facilitating content discovery to users and products tailored to their preferences. Since the Generative Artificial Intelligence (GAI) boom, research into GAI-enhanced Conversational Recommender Systems (CRSs) has sparked great interest. Most existing methods, however, mainly rely on one mode of input such as text, thereby limiting their ability to capture content diversity. This is also inconsistent with real-world scenarios, which involve multi-modal input data and output data. To address these limitations, we propose the Multi-Modal Conversational Recommender System (MMCRec) model which harnesses multiple modalities, including text, images, voice and video to enhance the recommendation performance and experience. Our model is capable of not only accepting multi-mode input, but also generating multi-modal output in conversational recommendation. Experimental evaluations demonstrate the effectiveness of our model in real-world conversational recommendation scenarios.	[Mukande, Tendai; Ali, Esraa; Caputo, Annalina; O'Connor, Noel E.] Dublin City Univ, Dublin 9, Ireland; [Dong, Ruihai] Univ Coll Dublin, Dublin 4, Ireland; [Mukande, Tendai; O'Connor, Noel E.] SFI ML LABS, Dublin, Ireland; [Ali, Esraa; Caputo, Annalina] ADAPT Ctr, Dublin, Ireland; [Dong, Ruihai; O'Connor, Noel E.] Insight SFI Res Ctr Data Analyt, Dublin, Ireland	Dublin City University; University College Dublin	Mukande, T (corresponding author), Dublin City Univ, Dublin 9, Ireland.; Mukande, T (corresponding author), SFI ML LABS, Dublin, Ireland.	tendai.mukande2@mail.dcu.ie; esraa.ali@adaptcentre.ie; annalina.caputo@dcu.ie; ruihai.dong@ucd.ie; noel.oconnor@dcu.ie		O'Connor, Noel/0000-0002-4033-9135; Dong, Ruihai/0000-0002-2509-1370	Science Foundation Ireland [18/CRT/6183]; Science Foundation Ireland (SFI) [18/CRT/6183] Funding Source: Science Foundation Ireland (SFI)	Science Foundation Ireland(Science Foundation Ireland); Science Foundation Ireland (SFI)(Science Foundation Ireland)	This publication has emanated from research supported by Science Foundation Ireland under Grant number 18/CRT/6183.	Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Chen X, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165275; Chen X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P765, DOI 10.1145/3331184.3331254; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cui Z., 2022, arXiv; Dai SH, 2023, Arxiv, DOI arXiv:2305.02182; Dong X, 2022, PROC CVPR IEEE, P21220, DOI 10.1109/CVPR52688.2022.02057; Friedman L, 2023, Arxiv, DOI arXiv:2305.07961; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Girdhar R, 2023, PROC CVPR IEEE, P15180, DOI 10.1109/CVPR52729.2023.01457; Gu RT, 2023, LECT NOTES COMPUT SC, V14257, P512, DOI 10.1007/978-3-031-44216-2_42; He M, 2023, KNOWL INF SYST, V65, P261, DOI 10.1007/s10115-022-01766-6; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu Z, 2023, APPL SOFT COMPUT, V144, DOI 10.1016/j.asoc.2023.110518; Huang HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00239-y; Li FL, 2023, Arxiv, DOI arXiv:2308.14263; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Liao LZ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P675, DOI 10.1145/3404835.3462970; Lin JH, 2024, Arxiv, DOI arXiv:2306.05817; Liu HH, 2023, Arxiv, DOI arXiv:2301.12503; Liu QD, 2023, Arxiv, DOI arXiv:2302.03883; Liu Z., 2023, WEB C, P417, DOI DOI 10.1145/3543507.3583386; Luo LH, 2024, Arxiv, DOI arXiv:2309.01538; Lyu C, 2023, Arxiv, DOI arXiv:2306.09093; Radford A, 2021, PR MACH LEARN RES, V139; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Salah A, 2020, J MACH LEARN RES, V21; Su YX, 2023, Arxiv, DOI arXiv:2305.16355; Tao SH, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107217; Viswanathan S., 2020, P 2 C CONV US INT, P1; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wang XL, 2024, MULTIMED TOOLS APPL, V83, P28689, DOI 10.1007/s11042-023-15262-8; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wu LK, 2024, Arxiv, DOI arXiv:2305.19860; Wu SQ, 2023, Arxiv, DOI arXiv:2309.05519; Wu YX, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P362, DOI 10.1145/3604915.3608775; Wu YX, 2023, IEEE T MULTIMEDIA, V25, P3113, DOI 10.1109/TMM.2022.3155900; Xin X, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1347, DOI 10.1145/3477495.3531714; Yan A, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2251, DOI 10.1145/3539618.3592036; Yao Y., 2023, Representation Learning for Natural Language Processing, P211; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]	44	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56062-0; 978-3-031-56063-7	LECT NOTES COMPUT SC			2024	14610						316	325		10.1007/978-3-031-56063-7_23	http://dx.doi.org/10.1007/978-3-031-56063-7_23			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DZ					2024-07-03	WOS:001211833300023
J	Rajjoub, R; Arroyave, JS; Zaidat, B; Ahmed, W; Mejia, MR; Tang, JS; Kim, JS; Cho, SK				Rajjoub, Rami; Arroyave, Juan Sebastian; Zaidat, Bashar; Ahmed, Wasil; Mejia, Mateo Restrepo; Tang, Justin; Kim, Jun S.; Cho, Samuel K.			ChatGPT and its Role in the Decision-Making for the Diagnosis and Treatment of Lumbar Spinal Stenosis: A Comparative Analysis and Narrative Review	GLOBAL SPINE JOURNAL			English	Review						lumbar stenosis; clinical guidelines; artificial intelligence; large language models; spine; decision-making	NATURAL-HISTORY; INJECTIONS; FUSION; TRIAL; METAANALYSIS; MRI	Study Design Comparative Analysis and Narrative Review. Objective To assess and compare ChatGPT's responses to the clinical questions and recommendations proposed by The 2011 North American Spine Society (NASS) Clinical Guideline for the Diagnosis and Treatment of Degenerative Lumbar Spinal Stenosis (LSS). We explore the advantages and disadvantages of ChatGPT's responses through an updated literature review on spinal stenosis. Methods We prompted ChatGPT with questions from the NASS Evidence-based Clinical Guidelines for LSS and compared its generated responses with the recommendations provided by the guidelines. A review of the literature was performed via PubMed, OVID, and Cochrane on the diagnosis and treatment of lumbar spinal stenosis between January 2012 and April 2023. Results 14 questions proposed by the NASS guidelines for LSS were uploaded into ChatGPT and directly compared to the responses offered by NASS. Three questions were on the definition and history of LSS, one on diagnostic tests, seven on non-surgical interventions and three on surgical interventions. The review process found 40 articles that were selected for inclusion that helped corroborate or contradict the responses that were generated by ChatGPT. Conclusions ChatGPT's responses were similar to findings in the current literature on LSS. These results demonstrate the potential for implementing ChatGPT into the spine surgeon's workplace as a means of supporting the decision-making process for LSS diagnosis and treatment. However, our narrative summary only provides a limited literature review and additional research is needed to standardize our findings as means of validating ChatGPT's use in the clinical space.	[Rajjoub, Rami; Arroyave, Juan Sebastian; Zaidat, Bashar; Ahmed, Wasil; Mejia, Mateo Restrepo; Tang, Justin; Kim, Jun S.; Cho, Samuel K.] Icahn Sch Med Mt Sinai, Dept Orthoped Surg, New York, NY USA; [Cho, Samuel K.] Icahn Sch Med Mt Sinai, Dept Orthoped Surg, 5 East 98th St, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai	Cho, SK (corresponding author), Icahn Sch Med Mt Sinai, Dept Orthoped Surg, 5 East 98th St, New York, NY 10029 USA.	samuel.cho@mountsinai.org		Arroyave Villada, Juan Sebastian/0009-0003-9480-0657; Tang, Justin/0000-0003-4544-3262; Rajjoub, Rami/0009-0005-2990-7874; Restrepo Mejia, Mateo/0009-0003-0457-3308				Ammendolia C, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2021-057724; Ammendolia C, 2019, CHIROPR MAN THER, V27, DOI 10.1186/s12998-019-0245-z; Ammendolia C, 2019, SPINE J, V19, P386, DOI 10.1016/j.spinee.2018.07.012; Ammendolia C, 2018, ARCH PHYS MED REHAB, V99, P2408, DOI 10.1016/j.apmr.2018.05.014; Ammendolia C, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010712; Choi J, 2015, J PHYS THER SCI, V27, P1937, DOI 10.1589/jpts.27.1937; Chou R, 2017, ANN INTERN MED, V166, P480, DOI 10.7326/M16-2458; Eberhardt K, 2014, NEURORADIOLOGY, V56, P1069, DOI 10.1007/s00234-014-1433-0; Enthoven WTM, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD012087; Eun SS, 2012, J NEURORADIOLOGY, V39, P104, DOI 10.1016/j.neurad.2011.02.008; Friedly JL, 2017, ARCH PHYS MED REHAB, V98, P1499, DOI 10.1016/j.apmr.2017.02.029; Friedly JL, 2014, NEW ENGL J MED, V371, P11, DOI 10.1056/NEJMoa1313265; Früh A, 2022, NEUROSURG REV, V45, P3739, DOI 10.1007/s10143-022-01875-4; Harmsen JF, 2021, NEUROMODULATION, V24, P1483, DOI 10.1111/ner.13315; Igari T, 2022, J CLIN MED, V11, DOI 10.3390/jcm11195911; Jackson R, 1998, BRIT MED J, V317, P427; Karlsson T, 2022, BONE JOINT J, V104B, P1343, DOI 10.1302/0301-620X.104B12.BJJ-2022-0340.R1; Konno S, 2016, SPINE, V41, P1709, DOI 10.1097/BRS.0000000000001707; Kreiner S., 2011, EVIDENCE BASED CLIN; Kurra S, 2018, SPINE J, V18, P1014, DOI 10.1016/j.spinee.2017.10.063; Kwon JW, 2018, J BACK MUSCULOSKELET, V31, P75, DOI 10.3233/BMR-169674; Liu JJ, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015635; Liu S., 2023, medRxiv; Minetama M, 2019, SPINE J, V19, P1310, DOI 10.1016/j.spinee.2019.04.009; Morgalla M, 2018, J NEUROL SURG PART A, V79, P316, DOI 10.1055/s-0037-1618563; Nakajima N, 2018, J ORTHOP SCI, V23, P282, DOI 10.1016/j.jos.2017.12.006; Natalia F, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241309; Oh Hyunju, 2020, J Phys Ther Sci, V32, P499, DOI 10.1589/jpts.32.499; Otani K, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57101116; Passmore SR, 2019, J MANIP PHYSIOL THER, V42, P23, DOI 10.1016/j.jmpt.2018.10.002; Pietrantonio A, 2019, NEUROSURG FOCUS, V46, DOI 10.3171/2019.2.FOCUS18651; Rao A., 2023, MEDRXIV, V26; Regev GJ, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57101125; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Schöller K, 2017, NEUROSURGERY, V80, P355, DOI 10.1093/neuros/nyw091; Sharma AK, 2017, PAIN MED, V18, P239, DOI 10.1093/pm/pnw131; Smith DL, 2022, J BODYW MOV THER, V32, P60, DOI 10.1016/j.jbmt.2022.05.012; Su ZH, 2022, FRONT ENDOCRINOL, V13, DOI 10.3389/fendo.2022.890371; Tardivo V, 2024, BRIT J NEUROSURG, V38, P765, DOI 10.1080/02688697.2021.1958149; Tominaga R, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0267892; Tsutsumimoto T, 2012, J BONE JOINT SURG BR, V94B, P378, DOI 10.1302/0301-620X.94B3.27867; Wei FL, 2021, INT J SURG, V85, P19, DOI 10.1016/j.ijsu.2020.11.014; Wessberg P, 2017, EUR SPINE J, V26, P2536, DOI 10.1007/s00586-017-5075-x; Wilartratsami S, 2021, SPINE, V46, pE338, DOI 10.1097/BRS.0000000000003781; Wu L., 2022, Lumbar Spinal Stenosis; Yang FG, 2021, J BACK MUSCULOSKELET, V34, P581, DOI 10.3233/BMR-200051; Yang LH, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000020323	47	9	9	5	20	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	2192-5682	2192-5690		GLOB SPINE J	Glob. Spine J.	APR	2024	14	3					998	1017		10.1177/21925682231195783	http://dx.doi.org/10.1177/21925682231195783		AUG 2023	20	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	NB5P2	37560946	gold			2024-07-03	WOS:001046514200001
J	Jin, JQ; Dobry, AS				Jin, Joy Q.; Dobry, Allison S.			ChatGPT for healthcare providers and patients: Practical implications within dermatology	JOURNAL OF THE AMERICAN ACADEMY OF DERMATOLOGY			English	Editorial Material						administrative support; artificial intelligence; ChatGPT; clinical decision-making; clinical research; dermatology; health literacy; healthcare providers; innovation; large language models; medical education; patients; technology			[Jin, Joy Q.] Univ Calif San Francisco, Sch Med, San Francisco, CA USA; [Jin, Joy Q.; Dobry, Allison S.] Univ Calif San Francisco, Dept Dermatol, San Francisco, CA USA; [Jin, Joy Q.] 2340 Sutter St,Box 0808,Floor 04,Room N426, San Francisco, CA 94115 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco	Jin, JQ (corresponding author), 2340 Sutter St,Box 0808,Floor 04,Room N426, San Francisco, CA 94115 USA.	joy.jin@ucsf.edu		Jin, Joy/0000-0002-1283-4665	National Psoriasis Foundation; University of California, San Francisco	National Psoriasis Foundation; University of California, San Francisco(University of California System)	Funding sources: J.Q.J. has received research grant funding from the National Psoriasis Foundation and institutional funding from the University of California, San Francisco. This study was not funded.	Carlisle RP, 2020, JAMA DERMATOL, V156, P1074, DOI 10.1001/jamadermatol.2020.1852; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]	5	11	11	10	21	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0190-9622	1097-6787		J AM ACAD DERMATOL	J. Am. Acad. Dermatol.	OCT	2023	89	4					870	871		10.1016/j.jaad.2023.05.081	http://dx.doi.org/10.1016/j.jaad.2023.05.081		SEP 2023	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	U0UC6	37315798	hybrid			2024-07-03	WOS:001082034300001
J	Meem, JA; Rashid, MS; Hristidis, V				Meem, Jannat Ara; Rashid, Muhammad Shihab; Hristidis, Vagelis			Modeling the impact of out-of-schema questions in task-oriented dialog systems	DATA MINING AND KNOWLEDGE DISCOVERY			English	Article; Early Access						Out-of-schema; Dialogue systems; Conversational agent; Large language models; Few-shot prompting; In-context learning; Task-oriented; User drop-out; Slot-filling		Existing work on task-oriented dialog systems generally assumes that the interaction of users with the system is restricted to the information stored in a closed data schema. However, in practice users may ask 'out-of-schema' questions, that is, questions that the system cannot answer, because the information does not exist in the schema. Failure to answer these questions may lead the users to drop out of the chat before reaching the success state (e.g. reserving a restaurant). A key challenge is that the number of these questions may be too high for a domain expert to answer them all. We formulate the problem of out-of-schema question detection and selection that identifies the most critical out-of-schema questions to answer, in order to maximize the expected success rate of the system. We propose a two-stage pipeline to solve the problem. In the first stage, we propose a novel in-context learning (ICL) approach to detect out-of-schema questions. In the second stage, we propose two algorithms for out-of-schema question selection (OQS): a naive approach that chooses a question based on its frequency in the dropped-out conversations, and a probabilistic approach that represents each conversation as a Markov chain and a question is picked based on its overall benefit. We propose and publish two new datasets for the problem, as existing datasets do not contain out-of-schema questions or user drop-outs. Our quantitative and simulation-based experimental analyses on these datasets measure how our methods can effectively identify out-of-schema questions and positively impact the success rate of the system.	[Meem, Jannat Ara; Rashid, Muhammad Shihab; Hristidis, Vagelis] Univ Calif Riverside, Dept CSE, Riverside, CA 92507 USA	University of California System; University of California Riverside	Meem, JA (corresponding author), Univ Calif Riverside, Dept CSE, Riverside, CA 92507 USA.	jmeem001@ucr.edu; mrash013@ucr.edu; vagelish@cs.ucr.edu			Vagelis Hristidis	Vagelis Hristidis	No Statement Available	Abro WA, 2022, APPL INTELL, V52, P17356, DOI 10.1007/s10489-022-03295-9; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bang Y, 2023, A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Budzianowski P, 2020, Arxiv, DOI arXiv:1810.00278; Chen L, 2020, AAAI CONF ARTIF INTE, V34, P7521; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Clark C, 2019, Arxiv, DOI arXiv:1905.10044; Coucke A, 2018, Arxiv, DOI arXiv:1805.10190; Deng Y, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2998, DOI 10.1145/3485447.3512020; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fernando AG, 2023, J RETAIL CONSUM SERV, V73, DOI 10.1016/j.jretconser.2023.103335; Hackl V, 2023, Arxiv, DOI arXiv:2308.02575; Hu YS, 2022, Arxiv, DOI arXiv:2203.08568; huggingface.co, t5-base-finetuned-boolq; huggingface.co, Roberta-base-boolq; Jansen BJ, 2009, J AM SOC INF SCI TEC, V60, P1358, DOI 10.1002/asi.21071; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kim S, 2020, Arxiv, DOI arXiv:2006.03533; Kim Y, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P193, DOI 10.1145/2556195.2556220; Kojima T, 2022, ADV NEUR IN; Larson S, 2022, Arxiv, DOI arXiv:2207.13211; Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209; Liu XK, 2019, Arxiv, DOI arXiv:1903.05566; Maqbool MH, 2022, IEEE INT C SEMANT CO, P217, DOI 10.1109/ICSC52841.2022.00043; Pan Y, 2022, P 23 ANN M SPEC INT, P630; Ponnusamy P, 2020, AAAI CONF ARTIF INTE, V34, P13180; Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689; Siro C, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2018, DOI 10.1145/3477495.3531798; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang J., 2015, Math Probl Eng, DOI [10.1055/2015956468, DOI 10.1055/2015956468]; Wang JY, 2023, Arxiv, DOI arXiv:2310.13552; Wei JS, 2022, ADV NEUR IN; Zhao RC, 2023, Arxiv, DOI arXiv:2305.03268; Zhu X, 2012, P 21 ACM INT C INF K, P1814	36	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1384-5810	1573-756X		DATA MIN KNOWL DISC	Data Min. Knowl. Discov.	2024 JUN 4	2024										10.1007/s10618-024-01039-6	http://dx.doi.org/10.1007/s10618-024-01039-6		JUN 2024	29	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TA5P5		hybrid			2024-07-03	WOS:001238552000001
J	Grodniewicz, JP; Hohol, M				Grodniewicz, J. P.; Hohol, Mateusz			Waiting for a digital therapist: three challenges on the path to psychotherapy delivered by artificial intelligence	FRONTIERS IN PSYCHIATRY			English	Article						artificial intelligence; mental health chatbots; psychotherapy; therapeutic alliance; narrow vs; general AI; large language models; Cognitive Behavioral Therapy (CBT); conversational agents	SELF-DETERMINATION; COMMON FACTORS; HEALTH	Growing demand for broadly accessible mental health care, together with the rapid development of new technologies, trigger discussions about the feasibility of psychotherapeutic interventions based on interactions with Conversational Artificial Intelligence (CAI). Many authors argue that while currently available CAI can be a useful supplement for human-delivered psychotherapy, it is not yet capable of delivering fully fledged psychotherapy on its own. The goal of this paper is to investigate what are the most important obstacles on our way to developing CAI systems capable of delivering psychotherapy in the future. To this end, we formulate and discuss three challenges central to this quest. Firstly, we might not be able to develop effective AI-based psychotherapy unless we deepen our understanding of what makes human-delivered psychotherapy effective. Secondly, assuming that it requires building a therapeutic relationship, it is not clear whether psychotherapy can be delivered by non-human agents. Thirdly, conducting psychotherapy might be a problem too complicated for narrow AI, i.e., AI proficient in dealing with only relatively simple and well-delineated tasks. If this is the case, we should not expect CAI to be capable of delivering fully-fledged psychotherapy until the so-called "general" or "human-like" AI is developed. While we believe that all these challenges can ultimately be overcome, we think that being mindful of them is crucial to ensure well-balanced and steady progress on our path to AI-based psychotherapy.	[Grodniewicz, J. P.; Hohol, Mateusz] Jagiellonian Univ, Copernicus Ctr Interdisciplinary Studies, Krakow, Poland	Jagiellonian University; Collegium Medicum Jagiellonian University	Grodniewicz, JP; Hohol, M (corresponding author), Jagiellonian Univ, Copernicus Ctr Interdisciplinary Studies, Krakow, Poland.	j.grodniewicz@gmail.com; mateusz.hohol@uj.edu.pl		Grodniewicz, J.P./0000-0001-7788-4236				Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828; Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021; Ahmad R, 2022, INFORM SYST FRONT, V24, P923, DOI 10.1007/s10796-022-10254-9; Allen SF, 2020, PSYCHIAT RES, V284, DOI 10.1016/j.psychres.2019.112697; Altman Sam, 2023, PLANNING AGI; [Anonymous], 2017, WHAT IS PSYCHOTHERAP; [Anonymous], 2022, MENTAL HLTH CHATBOT; [Anonymous], 1979, Cognitive therapy of depression; ARKOWITZ H, 1984, PSYCHOANALYTIC THERA; Askjer S, 2021, INTERNET INTERV, V25, DOI 10.1016/j.invent.2021.100404; Baker L.R., 2000, Persons and Bodies: A Constitution View; Beatty C, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.847991; Becker KD, 2011, ADM POLICY MENT HLTH, V38, P440, DOI 10.1007/s10488-010-0332-x; Bennion MR, 2020, J MED INTERNET RES, V22, DOI 10.2196/16794; Berry K, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.8252; Beutler L.E., 2000, Encyclopedia of Psychology, V3, P128; Blackwell A., 2020, TED TALK TEDXNATICK; Blandford A, 2019, INT J HUM-COMPUT ST, V131, P41, DOI 10.1016/j.ijhcs.2019.06.007; Bordin ES., 1979, PSYCHOTHERAPY THEORY, V16, P252, DOI 10.1037/h0085885; Bosma M., 2023, Chain-of-thought prompting elicits reasoning in large language models; Boucher EM, 2021, EXPERT REV MED DEVIC, V18, P37, DOI 10.1080/17434440.2021.2013200; Brown JEH, 2021, SSM-MENT HEALTH, V1, DOI 10.1016/j.ssmmh.2021.100017; Buchholz JL, 2020, J ANXIETY DISORD, V70, DOI 10.1016/j.janxdis.2020.102194; Buckman JR, 2010, PSYCHOTHER RES, V20, P247, DOI 10.1080/10503300903352693; Carey T.A., 2006, METHOD LEVELS PSYCHO; Carey TA, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00094; Carey TA, 2012, COGN BEH THER, V5, P47, DOI 10.1017/S1754470X12000037; Chekroud AM, 2021, WORLD PSYCHIATRY, V20, P154, DOI 10.1002/wps.20882; Clark D.A., 2013, WILEY HDB COGNITIVE, P1, DOI DOI 10.1002/9781118528563.WBCBT02; Cook JM, 2010, PSYCHOTHERAPY, V47, P260, DOI 10.1037/a0019788; Corcoran CM, 2018, WORLD PSYCHIATRY, V17, P67, DOI 10.1002/wps.20491; Craig TKJ, 2018, LANCET PSYCHIAT, V5, P31, DOI 10.1016/S2215-0366(17)30427-3; D'Alfonso S, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/21895; D'Alfonso S, 2020, CURR OPIN PSYCHOL, V36, P112, DOI 10.1016/j.copsyc.2020.04.005; Darcy A, 2022, EXPERT REV MED DEVIC, V19, P287, DOI 10.1080/17434440.2022.2075726; Darcy A, 2021, JMIR FORM RES, V5, DOI 10.2196/27868; Deci EL, 2000, PSYCHOL INQ, V11, P227, DOI 10.1207/S15327965PLI1104_01; Dellazizzo L, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00131; Dosovitsky G, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.735053; Dwyer DB, 2018, SCHIZOPHRENIA BULL, V44, P1060, DOI 10.1093/schbul/sby008; Elliott R., 2019, Psychotherapy relationships that work, V3rd, P245, DOI [10.1093/med-psych/9780190843953.003.0007, DOI 10.1093/MED-PSYCH/9780190843953.003.0007]; Emerson M., 2022, PSYCHE STUTTG; Ewbank MP, 2020, JAMA PSYCHIAT, V77, P35, DOI 10.1001/jamapsychiatry.2019.2664; expert survey on Progress in AI, 2022, 2022 EXP SURV PROGR; Farber BA., 2019, Psychotherapy relationships that work: Evidence-based therapist contributions, P288; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Fjelland R, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0494-4; Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Fluckiger C., 2019, PSYCHOTHERAPY RELATI, P24, DOI DOI 10.1093/MED-PSYCH/9780190843953.003.0002; Frank JD., 1991, PERSUASION HEALING C, V18; Gaffney H, 2020, DIGIT HEALTH, V6, DOI 10.1177/2055207620911580; Gaffney H, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/14166; Goldberg Simon B, 2022, PLOS Digit Health, V1, DOI 10.1371/journal.pdig.0000002; GOLDFRIED MR, 1980, AM PSYCHOL, V35, P991, DOI 10.1037/0003-066X.35.11.991; Goldman A., 2019, STANFORD ENCY PHILOS; Alonso SG, 2019, TELEMED E-HEALTH, V25, P533, DOI 10.1089/tmj.2018.0051; Graham S, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1094-0; Grodniewicz JP, 2023, AM J BIOETHICS, V23, P59, DOI 10.1080/15265161.2023.2191021; Haque A, 2018, Arxiv, DOI [arXiv:1811.08592, DOI 10.48550/ARXIV.1811.08592]; Harms JG, 2019, IEEE INTERNET COMPUT, V23, P13, DOI 10.1109/MIC.2018.2881519; Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806; He YH, 2023, J MED INTERNET RES, V25, DOI 10.2196/43862; He YH, 2022, J MED INTERNET RES, V24, DOI 10.2196/40719; Heffler B, 2009, PSYCHOTHER RES, V19, P283, DOI 10.1080/10503300902806673; Henderson C, 2013, AM J PUBLIC HEALTH, V103, P777, DOI 10.2105/AJPH.2012.301056; Henson P, 2019, HARVARD REV PSYCHIAT, V27, P268, DOI 10.1097/HRP.0000000000000224; Henson P, 2019, BJPSYCH OPEN, V5, DOI 10.1192/bjo.2018.86; Hofstadter D., 2022, ECONOMIST-NETHERLAND; Holohan M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.720476; Huijnen CAGJ, 2017, J AUTISM DEV DISORD, V47, P3079, DOI 10.1007/s10803-017-3235-9; Huston B., 2020, COULD ROBOT BE YOUR; Iter D., 2018, Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic, P136, DOI [DOI 10.18653/V1/W18-0615, 10.18653/v1/W18-0615]; KARASU TB, 1986, AM J PSYCHIAT, V143, P687; Kaveladze B., 2023, Digital therapeutics for mental health and addiction, P87, DOI [DOI 10.1016/B978-0-323-900454.00009-5, 10.1016/B978-0-323-90045-4.00009-5, DOI 10.1016/B978-0-323-90045-4.00009-5]; Kleinke CL., 1994, COMMON PRINCIPLES PS, V20; Kosinski M, 2023, Theory of mind may have spontaneously emerged in large language models; Kozima H., 2004, Artificial Life and Robotics, V8, P83, DOI 10.1007/s10015-004-0293-9; Lacewing M, 2014, CLIN PSYCHOL-SCI PR, V21, P154, DOI 10.1111/cpsp.12065; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Lederman R, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/31385; Legg S, 2007, Arxiv, DOI [arXiv:0706.3639, DOI 10.48550/ARXIV.0706.3639, 10.48550/ARXIV.0706.3639]; Leite I, 2014, INT J SOC ROBOT, V6, P329, DOI 10.1007/s12369-014-0227-1; Li YX, 2018, Arxiv, DOI arXiv:1810.06339; Lim SM, 2022, BEHAV THER, V53, P334, DOI 10.1016/j.beth.2021.09.007; Liu H, 2022, INTERNET INTERV, V27, DOI 10.1016/j.invent.2022.100495; Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636; Malinowska JK, 2021, MIND MACH, V31, P361, DOI 10.1007/s11023-021-09558-7; Mallory F., 2023, FICTIONALISM CHATBOT; Mansell W, 2018, REV PSICOTERAPIA, V29, P135; Markland D, 2005, J SOC CLIN PSYCHOL, V24, P811, DOI 10.1521/jscp.2005.24.6.811; Mastoras RE, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50002-9; Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746; Murphy ST, 2022, PSYCHOTHER RES, V32, P995, DOI 10.1080/10503307.2021.2025277; Nissen M, 2022, J MED INTERNET RES, V24, DOI 10.2196/32630; Norcross J.C., 1990, WHAT IS PSYCHOTHERAP, P218; Norcross JC., 2019, Psychotherapy relationships that work, vol 1, P1; Norcross JohnC., 2005, Handbook of Psychotherapy Integration, V2nd, DOI DOI 10.1093/MED:PSYCH/9780195165791.003.0001; Nurgalieva L., 2023, DIGITAL THERAPEUTICS, P189; Pandey Sumit, 2022, International Journal of Information Technology, P3757, DOI 10.1007/s41870-022-00999-6; Patel V, 2018, LANCET, V392, P1553, DOI 10.1016/S0140-6736(18)31612-X; Powers W.T., 1973, BEHAV CONTROL PERCEP, P296; POZNANSKI JJ, 1995, J COUNS PSYCHOL, V42, P411, DOI 10.1037/0022-0167.42.4.411; Prochaska J.O., 1984, SYSTEMS PSYCHOTHERAP, V2nd; Prochaska JJ, 2021, DRUG ALCOHOL DEPEN, V227, DOI 10.1016/j.drugalcdep.2021.108986; Prochaska JJ, 2021, J MED INTERNET RES, V23, DOI 10.2196/24850; Rehm J, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-0997-0; Rosenzweig S, 1936, AM J ORTHOPSYCHIAT, V6, P412, DOI 10.1111/j.1939-0025.1936.tb05248.x; Sedlakova J, 2023, AM J BIOETHICS, V23, P4, DOI 10.1080/15265161.2022.2048739; Silver D, 2021, ARTIF INTELL, V299, DOI 10.1016/j.artint.2021.103535; Skjuve M., 2022, International Journal of Human-Computer Studies, V168, P102903, DOI DOI 10.1016/J.IJHCS.2022.102903; Skjuve M, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102601; Society of Clinical Psychology, 2023, Treatments; Steel Z, 2014, INT J EPIDEMIOL, V43, P476, DOI 10.1093/ije/dyu038; Suharwardy Sanaa, 2023, AJOG Glob Rep, V3, P100165, DOI 10.1016/j.xagr.2023.100165; Tartakovsky E, 2016, PSYCHOTHER RES, V26, P352, DOI 10.1080/10503307.2014.989289; Tekin S., 2020, PHILOS TECHNOLOGY, V34, P447, DOI [DOI 10.1007/S13347-020-00395-7, 10.1007/s13347-020-00395-7]; Tekin S, 2023, TECHNOLOGY ETHICS PH; Thieme A, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3398069; Trachsel M., 2021, OXFORD HDB PSYCHOTHE, P744; Tremain H, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/17204; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; van Breda W., 2020, PREDICTIVE MODELING; van Breda W, 2018, INTERNET INTERV, V12, P100, DOI 10.1016/j.invent.2017.08.003; Wampold BE, 2015, GREAT PSYCHOTHERAPY DEBATE: THE EVIDENCE FOR WHAT MAKES PSYCHOTHERAPY WORK, 2ND EDITION, P1; Ware Shweta, 2020, Smart Health, V15, P91, DOI 10.1016/j.smhl.2019.100093; WEINBERGER J, 1995, CLIN PSYCHOL-SCI PR, V2, P45, DOI 10.1111/j.1468-2850.1995.tb00024.x; Weizenbaum J., 1976, Computer Power and Human Reason: From Judgment to Calculation; Wilmots E, 2020, PSYCHOL PSYCHOTHER-T, V93, P276, DOI 10.1111/papt.12232; Woebot Health, 2022, WOEB HLTH; World Health Organization, 2021, Mental Health Atlas 2020; Wrightson-Hester A-R., 2023, MANAGE YOUR LIFE ONL, DOI [10.31234/osf.io/zjw8p, DOI 10.31234/OSF.IO/ZJW8P]; Wysa-Everyday Mental Health, 2022, WYS EV MENT HLTH; Xiong JQ, 2020, J AFFECT DISORDERS, V277, P55, DOI 10.1016/j.jad.2020.08.001; Zuroff DC, 2007, PSYCHOTHER RES, V17, P137, DOI 10.1080/10503300600919380	138	11	11	17	29	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-0640			FRONT PSYCHIATRY	Front. Psychiatry	JUN 1	2023	14								1190084	10.3389/fpsyt.2023.1190084	http://dx.doi.org/10.3389/fpsyt.2023.1190084			12	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	I9JX4	37324824	Green Published, gold			2024-07-03	WOS:001005881300001
J	Jain, SS; Elias, P; Poterucha, T; Randazzo, M; Jimenez, FL; Khera, R; Perez, M; Ouyang, DV; Pirruccello, J; Salerno, M; Einstein, AJ; Avram, R; Tison, GH; Nadkarni, G; Natarajan, V; Pierson, E; Beecy, A; Kumaraiah, D; Haggerty, C; Silva, JNA; Maddox, TM				Jain, Sneha S.; Elias, Pierre; Poterucha, Timothy; Randazzo, Michael; Jimenez, Francisco Lopez; Khera, Rohan; Perez, Marco; Ouyang, David; Pirruccello, James; Salerno, Michael; Einstein, Andrew J.; Avram, Robert; Tison, Geoffrey H.; Nadkarni, Girish; Natarajan, Vivek; Pierson, Emma; Beecy, Ashley; Kumaraiah, Deepa; Haggerty, Chris; Silva, Jennifer N. Avari; Maddox, Thomas M.			Artificial Intelligence in Cardiovascular Care-Part 2: Applications JACC Review Topic of the Week	JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY			English	Review						artificial intelligence; cardiac imaging; clinical trials; deep learning; digital health; generative AI; implementation science; innovation; large language models; health equity; machine learning	HEALTH; AI; DISPARITIES; PREDICTION; GUIDELINES; MEDICINE; TRIAL; BIAS	Recent arti ficial intelligence (AI) advancements in cardiovascular care offer potential enhancements in effective diagnosis, treatment, and outcomes. More than 600 U.S. Food and Drug Administration -approved clinical AI algorithms now exist, with 10% focusing on cardiovascular applications, highlighting the growing opportunities for AI to augment care. This review discusses the latest advancements in the field of AI, with a particular focus on the utilization of multimodal inputs and the field of generative AI. Further discussions in this review involve an approach to understanding the larger context in which AI-augmented care may exist, and include a discussion of the need for rigorous evaluation, appropriate infrastructure for deployment, ethics and equity assessments, regulatory oversight, and viable business cases for deployment. Embracing this rapidly evolving technology while setting an appropriately high evaluation benchmark with careful and patient-centered implementation will be crucial for cardiology to leverage AI to enhance patient care and the provider experience. (J Am Coll Cardiol 2024;83:2487 -2496) (c) 2024 by the American College of Cardiology Foundation.	[Jain, Sneha S.; Perez, Marco; Salerno, Michael] Stanford Univ, Sch Med, Div Cardiol, Palo Alto, CA USA; [Elias, Pierre; Poterucha, Timothy; Einstein, Andrew J.; Kumaraiah, Deepa] Columbia Univ, Irving Med Ctr, Seymour Paul & Gloria Milstein Div Cardiol, New York, NY USA; [Elias, Pierre; Haggerty, Chris] Columbia Univ, Dept Biomed Informat, Irving Med Ctr, New York, NY USA; [Randazzo, Michael] Univ Chicago, Med Ctr, Div Cardiol, Chicago, IL USA; [Jimenez, Francisco Lopez] Mayo Clin, Coll Med, Dept Cardiol, Rochester, MN USA; [Khera, Rohan] Yale Sch Med, Div Cardiol, New Haven, CT USA; [Ouyang, David] Cedars Sinai Med Ctr, Div Cardiol, Los Angeles, CA USA; [Pirruccello, James; Tison, Geoffrey H.] Univ Calif San Francisco, Div Cardiol, San Francisco, CA USA; [Avram, Robert] Montreal Heart Inst, Div Cardiol, Montreal, PQ, Canada; [Nadkarni, Girish] Icahn Sch Med Mt Sinai, New York, NY USA; [Natarajan, Vivek] Google Hlth, Mountain View, CA USA; [Pierson, Emma] Cornell Tech, Dept Comp Sci, New York, NY USA; [Beecy, Ashley; Kumaraiah, Deepa; Haggerty, Chris] NewYork Presbyterian Hlth Syst, New York, NY USA; [Beecy, Ashley] Weill Cornell Med Coll, Div Cardiol, New York, NY USA; [Silva, Jennifer N. Avari; Maddox, Thomas M.] Washington Univ, Sch Med, Div Cardiol, St Louis, MO USA	Stanford University; NewYork-Presbyterian Hospital; Columbia University; NewYork-Presbyterian Hospital; Columbia University; University of Chicago; University of Chicago Medical Center; Mayo Clinic; Yale University; Cedars Sinai Medical Center; University of California System; University of California San Francisco; Universite de Montreal; Icahn School of Medicine at Mount Sinai; Cornell University; Weill Cornell Medicine; Washington University (WUSTL)	Maddox, TM (corresponding author), Washington Univ, BJC HealthCare, Sch Med, Mailstop 90-29-933,4590 Nash Way, St Louis, MO 63110 USA.	thomas.maddox@bjc.org	Jain, Sneha Shah/KHU-3667-2024	Jain, Sneha Shah/0000-0002-0592-1453	Eidos Therapeutics; Pfizer; Janssen; Edwards Lifesciences; New York Academy of Medicine; Google; Amyloidosis Foundation; American Heart Association [933452, 23SCISA1077494]; Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine; National Institutes of Health (NHLBI) [UG3HL165065]	Eidos Therapeutics; Pfizer(Pfizer); Janssen(Johnson & JohnsonJohnson & Johnson USAJanssen Biotech Inc); Edwards Lifesciences; New York Academy of Medicine; Google(Google Incorporated); Amyloidosis Foundation; American Heart Association(American Heart Association); Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine; National Institutes of Health (NHLBI)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI))	Dr Jain has consulting relationships with Bristol Myers Squibb, ARTIS Ventures, and Broadview Ventures. Dr Elias has research support provided to his institution from Eidos Therapeutics, Pfizer, Janssen, Edwards Lifesciences, New York Academy of Medicine, and Google. Dr Poterucha owns stock in Abbott Laboratories and Baxter International; and research support is provided to his institution from the Amyloidosis Foundation, American Heart Association (Award #933452 and #23SCISA1077494), Eidos Therapeutics, Pfizer, Janssen, Edwards Lifesciences, and the Glorney-Raisbeck Fellowship Award from the New York Academy of Medicine. Dr Avram is a co-inventor in the patent 63/208,406 (Method and System for Automated Analysis of Coronary Angiograms); and has received speaker fees from Abbott, Boston Scientific, Boehringer Ingelheim, and Novartis. Dr Avari Silva is the co-founder and consultant to and holds equity in SentiAR; the technology has been licensed by Washington University to SentiAR. Dr Maddox has received grant funding from the National Institutes of Health (NHLBI UG3HL165065: The Rhythm Evaluation for Anticoagulation with Continuous Monitoring of Atrial Fibrillation Trial [REACT-AF] ); has received honoraria and/or expense reim-bursement in the past 3 years from the University of Chicago, George Washington University, Baylor College of Medicine, the New York Cardiological Society, and Medscape (Dec 2022); has received compensation and travel expense reimbursement for American College of Cardiology leadership roles and meetings; is currently employed as a cardiologist and Vice President, Digital Products and Innovation at BJC HealthCare/Washingt on University School of Medicine, and in this capacity, he is advising Myia Labs, for which his employer is receiving equity compensation in the company, he is receiving no individual compensation from the company, and he is a compensated director for a New Mexico-based foundation, the J.F Maddox Foundation. All other authors have reported that they have no relationships relevant to the contents of this paper to disclose.	American Medical Association, 2023, CPT Professional 2024; Aristidou A, 2022, LANCET, V399, P620, DOI 10.1016/S0140-6736(22)00235-5; Badal K, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00279-9; Bannur S, 2023, Arxiv, DOI [arXiv:2301.04558, 10.48550/arXiv.2301.04558, DOI 10.48550/ARXIV.2301.04558]; Bedoya AD, 2022, J AM MED INFORM ASSN, V29, P1631, DOI 10.1093/jamia/ocac078; Beede E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376718; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen Melissa M, 2021, Radiol Artif Intell, V3, pe210030, DOI 10.1148/ryai.2021210030; Chouldechova A, 2017, BIG DATA-US, V5, P153, DOI 10.1089/big.2016.0047; Christensen M, 2023, Arxiv, DOI [arXiv:2308.15670, 10.48550/arXiv.2308.15670, DOI 10.48550/ARXIV.2308.15670]; Corbett-Davies S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P797, DOI 10.1145/3097983.3098095; Daneshjou R, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq6147; de Marvao A, 2020, FRONT CARDIOVASC MED, V6, DOI 10.3389/fcvm.2019.00195; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Executive Office of the President, 2023, Federal Register, V88, P75191; Foryciarz A, 2022, BMJ HEALTH CARE INFO, V29, DOI 10.1136/bmjhci-2021-100460; Gates D, 2024, Intelligence-Based Cardiology and Cardiac Surgery, P407; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Gonzalez-Smith J, 2022, NEJM Catal Innov Care Deliv., P3; Guo YT, 2019, J AM COLL CARDIOL, V74, P2365, DOI 10.1016/j.jacc.2019.08.019; He BY, 2023, NATURE, V616, P520, DOI 10.1038/s41586-023-05947-3; Ibrahim H, 2021, TRIALS, V22, DOI 10.1186/s13063-020-04951-6; Kashyap S, 2021, J AM MED INFORM ASSN, V28, P2445, DOI 10.1093/jamia/ocab154; Kevin Wu, 2023, NEJM AI, V1; Khan Bangul, 2023, Biomed Mater Devices, P1, DOI 10.1007/s44174-023-00063-2; Khor S, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.18495; Kleinberg J, 2016, Arxiv, DOI [arXiv:1609.05807, DOI 10.48550/ARXIV.1609.05807, 10.48550/arXiv.1609.05807]; Lehman E, 2023, Arxiv, DOI [arXiv:2302.08091, 10.48550/arXiv.2302.08091, DOI 10.48550/ARXIV.2302.08091]; Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x; Liu ZL, 2024, Arxiv, DOI [arXiv:2306.08666, DOI 10.48550/ARXIV.2306.08666, 10.48550/arXiv.2306.08666]; Loecher M, 2021, MED IMAGE ANAL, V74, DOI 10.1016/j.media.2021.102223; Lubitz SA, 2022, CIRCULATION, V146, P1415, DOI 10.1161/CIRCULATIONAHA.122.060291; Martin AR, 2019, NAT GENET, V51, P584, DOI 10.1038/s41588-019-0379-x; Medenilla A., 2023, PLoS Digital Health, V2; Mello MM, 2024, JAMA-J AM MED ASSOC, V331, P17, DOI 10.1001/jama.2023.25051; Mirza Fatima N, 2024, NEJM AI, V1; Movva R, 2023, Arxiv, DOI [arXiv:2304.09270, 10.48550/arXiv.2304.09270, DOI 10.48550/ARXIV.2304.09270]; Mullainathan S, 2022, Q J ECON, V137, P679, DOI 10.1093/qje/qjab046; Nelson A, 2002, J NATL MED ASSOC, V94, P666; Obermeyer Z, 2021, Algorithmic Bias Playbook; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Owens LM, 2024, FAM PRACT, V41, P86, DOI 10.1093/fampra/cmad092; Parikh RB, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00609-6; Perez MV, 2019, NEW ENGL J MED, V381, P1909, DOI 10.1056/NEJMoa1901183; Peterson PN, 2010, CIRC-CARDIOVASC QUAL, V3, P25, DOI 10.1161/CIRCOUTCOMES.109.854877; Pfohl SR, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103621; Pierson E, 2021, NAT MED, V27, P136, DOI 10.1038/s41591-020-01192-7; Radhakrishnan A, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-38125-0; Rivera SC, 2020, LANCET DIGIT HEALTH, V2, pE549, DOI [10.1016/S2589-7500(20)30219-3, 10.1136/bmj.m3210, 10.1038/s41591-020-1037-7]; Salsabili M, 2023, J MANAG CARE SPEC PH, V29, P685, DOI 10.18553/jmcp.2023.29.6.685; Schepart A, 2023, CARDIOVASC DIGIT HLT, V4, P101, DOI 10.1016/j.cvdhj.2023.04.003; Sculley D, 2015, ADV NEUR IN, V28; Sendak MP, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0253-3; Sengupta PP, 2020, JACC-CARDIOVASC IMAG, V13, P2017, DOI 10.1016/j.jcmg.2020.07.015; Shah NH, 2024, JAMA-J AM MED ASSOC, V331, P245, DOI 10.1001/jama.2023.26930; Shahian DM, 2018, ANN THORAC SURG, V105, P1411, DOI 10.1016/j.athoracsur.2018.03.002; Shanmugam D, 2023, Arxiv, DOI [arXiv:2110.04133, 10.48550/arXiv.2110.04133, DOI 10.48550/ARXIV.2110.04133]; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Soin A, 2022, Arxiv, DOI [arXiv:2202.02833, 10.48550/arXiv.2202.02833, DOI 10.48550/ARXIV.2202.02833]; Solomonides AE, 2022, J AM MED INFORM ASSN, V29, P585, DOI 10.1093/jamia/ocac006; Soto JT, 2022, EUR HEART J-DIGIT HL, V3, P380, DOI 10.1093/ehjdh/ztac033; Thawkar O, 2023, Arxiv, DOI [arXiv:2306.07971, 10.48550/arXiv.2306.07971, DOI 10.48550/ARXIV.2306.07971]; The Coalition for Health AI, 2023, Blueprint for Trustworthy AI: Implementation Guidance and Assurance for Healthcare; The White House, 2022, Blueprint for an AI bill of rights; Tierney AA, 2024, NEJM Catal Innov Care Deliv., V5, DOI [10.1056/cat.23.0404, DOI 10.1056/CAT.23.0404]; Tipton K, 2023, Impact of Healthcare Algorithms on Racial and Ethnic Disparities in Health and Healthcare; US Food and Drug Administration, Artificial intelligence & medical products: how CBER, CDER, CDRH, and OCP are working together; US Food and Drug Administration, 2019, Artificial intelligence and machine learning in software as a medical device; US Food and Drug Administration, Good machine learning practice for medical device development: guiding principles; van Smeden M, 2022, EUR HEART J, V43, P2921, DOI 10.1093/eurheartj/ehac238; Vyas DA, 2020, NEW ENGL J MED, V383, P874, DOI 10.1056/NEJMms2004740; Watson J, 2020, JAMIA OPEN, V3, P167, DOI 10.1093/jamiaopen/ooz046; Koh PW, 2021, Arxiv, DOI [arXiv:2012.07421, 10.48550/arXiv.2012.07421, DOI 10.48550/ARXIV.2012.07421]; Wessler BS, 2015, CIRC-CARDIOVASC QUAL, V8, P368, DOI 10.1161/CIRCOUTCOMES.115.001693; World Health Organization (WHO), 2021, Ethics and Governance of Artificial Intelligence for Health; Xie F, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103980; Yadlowsky S, 2018, ANN INTERN MED, V169, P20, DOI 10.7326/M17-3011; Yao XX, 2021, NAT MED, V27, P815, DOI 10.1038/s41591-021-01335-4; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; Zink A, 2023, medRxiv, DOI [10.1101/2023.03.31.23287926, 10.1101/2023.03.31.23287926v1, DOI 10.1101/2023.03.31.23287926V1, 10.1101/2023.03.31.23287926, DOI 10.1101/2023.03.31.23287926]	81	1	1	0	0	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0735-1097	1558-3597		J AM COLL CARDIOL	J. Am. Coll. Cardiol.	JUN 18	2024	83	24					2487	2496		10.1016/j.jacc.2024.03.401	http://dx.doi.org/10.1016/j.jacc.2024.03.401			10	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	WE7M8	38593945				2024-07-03	WOS:001253258800001
J	Nov, O; Singh, N; Mann, D				Nov, Oded; Singh, Nina; Mann, Devin			Putting ChatGPT's Medical Advice to the (Turing) Test: Survey Study	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; AI; ChatGPT; Chat Generative Pre-trained Transformer; large language model; patient-provider interaction; chatbot; feasibility; ethics; privacy; language model; machine learning	PATIENT; IMPACT	Background: Chatbots are being piloted to draft responses to patient questions, but patients' ability to distinguish between provider and chatbot responses and patients' trust in chatbots' functions are not well established. Objective: This study aimed to assess the feasibility of using ChatGPT (Chat Generative Pre-trained Transformer) or a similar artificial intelligence-based chatbot for patient-provider communication. Methods: A survey study was conducted in January 2023. Ten representative, nonadministrative patient-provider interactions were extracted from the electronic health record. Patients' questions were entered into ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient question was followed by a provider- or ChatGPT-generated response. Participants were informed that 5 responses were provider generated and 5 were chatbot generated. Participants were asked-and incentivized financially-to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale from 1-5. Results: A US-representative sample of 430 study participants aged 18 and older were recruited on Prolific, a crowdsourcing platform for academic studies. In all, 426 participants filled out the full survey. After removing participants who spent less than 3 minutes on the survey, 392 respondents remained. Overall, 53.3% (209/392) of respondents analyzed were women, and the average age was 47.1 (range 18-91) years. The correct classification of responses ranged between 49% (192/392) to 85.7% (336/392) for different questions. On average, chatbot responses were identified correctly in 65.5% (1284/1960) of the cases, and human provider responses were identified correctly in 65.1% (1276/1960) of the cases. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score 3.4 out of 5), with lower trust as the health-related complexity of the task in the questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower-risk health questions. It is important to continue studying patient-chatbot interaction as chatbots move from administrative to more clinical roles in health care.	[Nov, Oded] NYU, Tandon Sch Engn, Dept Technol Management, New York, NY USA; [Singh, Nina; Mann, Devin] NYU, Grossman Sch Med, Dept Populat Hlth, New York, NY USA; [Mann, Devin] NYU, Med Ctr Informat Technol, Langone Hlth, New York, NY USA; [Nov, Oded] NYU, Tandon Sch Engn, Dept Technol Management, 5 Metrotech, New York, NY 11201 USA	New York University; New York University Tandon School of Engineering; New York University; New York University; New York University; New York University Tandon School of Engineering	Nov, O (corresponding author), NYU, Tandon Sch Engn, Dept Technol Management, 5 Metrotech, New York, NY 11201 USA.	onov@nyu.edu		Mann, Devin/0000-0002-2099-0852; Singh, Nina/0000-0002-4623-2451	US National Science Foundation [1928614, 2129076]	US National Science Foundation(National Science Foundation (NSF))	Acknowledgments The authors receive financial support from the US National Science Foundation (awards 1928614 and 2129076) for the submitted work. The funding source had no further role in this study. We used the generative artificial intelligence tool ChatGPT (Chat Generative Pre-trained Transformer) by OpenAI [1] to draft the chatbot responses for the research survey.	Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; [Anonymous], 2022, OpenAI; [Anonymous], 2016, P 30 INT C NEUR INF, DOI DOI 10.5555/3157382.3157584; [Anonymous], 2023, DOCSGPT; Attia ZI, 2022, NAT MED, V28, P2497, DOI 10.1038/s41591-022-02053-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Bruni F, 2022, NEW YORK TIMES; Chang IC, 2022, INT J MED INFORM, V165, DOI 10.1016/j.ijmedinf.2022.104827; Dratsch T, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222176; Fisher RA, 1936, BMJ-BRIT MED J, V1936, P554; Gardner RL, 2019, J AM MED INFORM ASSN, V26, P106, DOI 10.1093/jamia/ocy145; Hogg HDJ, 2023, J MED INTERNET RES, V25, DOI 10.2196/39742; Holmgren AJ, 2022, J AM MED INFORM ASSN, V29, P453, DOI 10.1093/jamia/ocab268; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mann DM, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/34483; Marmor RA, 2018, APPL CLIN INFORM, V9, P11, DOI 10.1055/s-0037-1620263; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619871808; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Sebastian G., 2023, IJSPPC, V15, P1, DOI [10.4018/IJSPPC.325475, DOI 10.4018/IJSPPC.325475]; Sebastian G, 2023, J MED INTERNET RES, V25, DOI 10.2196/41430; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Stern J, 2022, WALL STREET J 1221; Turner BEW, 2023, MODERN HEALTHCARE; Winn AN, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.18561; Young AT, 2021, LANCET DIGIT HEALTH, V3, pE599, DOI 10.1016/S2589-7500(21)00132-1; Montenegro JLZ, 2019, EXPERT SYST APPL, V129, P56, DOI 10.1016/j.eswa.2019.03.054	32	26	26	11	30	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e46939	10.2196/46939	http://dx.doi.org/10.2196/46939			7	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	M9JT4	37428540	gold, Green Published			2024-07-03	WOS:001033309800002
J	Ishmam, MF; Shovon, MSH; Mridha, MF; Dey, N				Ishmam, Md. Farhan; Shovon, Md. Sakib Hossain; Mridha, M. F.; Dey, Nilanjan			From image to language: A critical analysis of Visual Question Answering (VQA) approaches, challenges, and opportunities	INFORMATION FUSION			English	Article						Visual Question Answering; Vision language pre-training; Multimodal learning; Multimodal large language models	FEATURE-EXTRACTION; NETWORK; ATTENTION; KNOWLEDGE; TOOL	The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre -trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre -training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.	[Ishmam, Md. Farhan] Islamic Univ Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh; [Ishmam, Md. Farhan; Shovon, Md. Sakib Hossain; Mridha, M. F.] Adv Machine Intelligence Res Lab, Dhaka, Bangladesh; [Shovon, Md. Sakib Hossain; Mridha, M. F.] Amer Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh; [Dey, Nilanjan] Techno Int New Town, Dept Comp Sci & Engn, Kolkata, India	American International University Bangladesh (AIUB)	Mridha, MF (corresponding author), Amer Int Univ, Dept Comp Sci & Engn, Dhaka, Bangladesh.	farhanishmam@iut-dhaka.edu; sakib.aiub.cs@gmail.com; firoz.mridha@aiub.edu; nilanjan.dey@tint.edu.in	Mridha, M. F/ABB-8376-2021	Mridha, M. F/0000-0001-5738-1631; , Md Farhan Ishmam/0009-0004-3725-0342	Advanced Machine Intelligence Research Lab (AMIRL)	Advanced Machine Intelligence Research Lab (AMIRL)	The authors would like to thank the Advanced Machine Intelligence Research Lab (AMIRL) for research and support supervision.	Acharya M, 2019, AAAI CONF ARTIF INTE, P8076; Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522; Ahmad T, 2021, J CLEAN PROD, V289, DOI 10.1016/j.jclepro.2021.125834; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Andreas J, 2016, Arxiv, DOI arXiv:1601.01705; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; [Anonymous], 2007, Artificial general intelligence; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Anwar S., 2019, J PRECOLLEGE ENG ED, V9, P19, DOI DOI 10.7771/2157-9288.1223; Arras L, 2022, INFORM FUSION, V81, P14, DOI 10.1016/j.inffus.2021.11.008; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Ba JMY, 2015, Arxiv, DOI arXiv:1412.7755; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Bansal Ankan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P51, DOI 10.1007/978-3-030-58589-1_4; Bao H., 2022, ADV NEURAL INF PROCE, V35, P32897, DOI DOI 10.1109/CVPR.2018.00636; Barra S, 2021, PATTERN RECOGN LETT, V151, P325, DOI 10.1016/j.patrec.2021.09.008; Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bigham J., 2010, P 23 ANN ACM S US IN, P333, DOI 10.1145/1866029.1866080; Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439; Bitton-Guetta N, 2023, Arxiv, DOI arXiv:2303.07274; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bongini P, 2020, IOP CONF SER-MAT SCI, V949, DOI 10.1088/1757-899X/949/1/012074; Bozinovski S., 1976, P S INF, V3, P121; Brady E., 2013, P SIGCHI C HUM FACT, P2117; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burton M.A., 2012, P 14 INT ACM SIGACCE, P135, DOI [DOI 10.1145/2384916.2384941, 10.1145/2384916.2384941]; Chandrasekar A., 2022, 2022 IEEE INT C SIGN, P1; Changpinyo S, 2023, Arxiv, DOI arXiv:2209.05401; Changpinyo S, 2022, Arxiv, DOI arXiv:2205.01883; Chao WL, 2018, PROC CVPR IEEE, P5716, DOI 10.1109/CVPR.2018.00599; Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269; Chen C., 2022, arXiv; Chen F. L., 2022, arXiv; Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5; Chen JY, 2021, Arxiv, DOI arXiv:2103.00070; Chen K, 2016, Arxiv, DOI [arXiv:1511.05960, DOI 10.48550/ARXIV.1511.05960,ARXIV]; Chen X, 2022, Arxiv, DOI arXiv:2209.06794; Chen XL, 2015, Arxiv, DOI arXiv:1504.00325; Chen Z, 2023, Arxiv, DOI [arXiv:2205.08534, DOI 10.48550/ARXIV.2205.08534]; Chen Z, 2021, LECT NOTES COMPUT SC, V12922, P146, DOI 10.1007/978-3-030-88361-4_9; Chou S.-H., 2020, P IEEE CVF WINT C AP, P1607; Chuang YS, 2020, Arxiv, DOI arXiv:1910.11559; Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dancette C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1554, DOI 10.1109/ICCV48922.2021.00160; Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding YH, 2023, Arxiv, DOI arXiv:2304.06447; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Dou ZY, 2022, PROC CVPR IEEE, P18145, DOI 10.1109/CVPR52688.2022.01763; Drossos K, 2020, INT CONF ACOUST SPEE, P736, DOI [10.1109/ICASSP40776.2020.9052990, 10.1109/icassp40776.2020.9052990]; Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637; Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; Farazi MR, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103985; Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441; Fukui A., 2016, arXiv; Fukushima K., 1982, Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition, V45, P267, DOI DOI 10.1007/978-3-642-46466-9_18; Biten AF, 2021, Arxiv, DOI arXiv:2112.12494; Gan Z., 2020, Advances in Neural Information Processing Systems, P6616; Gan Z, 2022, FOUND TRENDS COMPUT, V14, P163, DOI 10.1561/0600000105; Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127; Gao DF, 2023, IEEE T PATTERN ANAL, V45, P5561, DOI 10.1109/TPAMI.2022.3210780; Gao HY, 2015, ADV NEUR IN, V28; Gao P, 2023, Arxiv, DOI arXiv:2304.15010; Gao P, 2018, LECT NOTES COMPUT SC, V11205, P485, DOI 10.1007/978-3-030-01246-5_29; Gao SY, 2023, Arxiv, DOI arXiv:2301.09045; Garcia N, 2020, AAAI CONF ARTIF INTE, V34, P10826; Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gordon D, 2018, PROC CVPR IEEE, P4089, DOI 10.1109/CVPR.2018.00430; Goyal Y, 2016, Arxiv, DOI arXiv:1608.08974; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Guo JX, 2023, PROC CVPR IEEE, P10867, DOI 10.1109/CVPR52729.2023.01046; Gupta T., 2022, arXiv; Gurari Danna, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P417, DOI 10.1007/978-3-030-58520-4_25; Gurari D, 2019, PROC CVPR IEEE, P939, DOI 10.1109/CVPR.2019.00103; Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380; Gurari D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3511, DOI 10.1145/3025453.3025781; Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; Hasan S.A., 2018, P CLEF 2018 WORKING; Hassantabar S., 2018, Visual question answering: Datasets, methods, challenges and oppurtunities; He B, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P441, DOI 10.1109/ICRAE.2017.8291426; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XH, 2020, Arxiv, DOI arXiv:2003.10286; Hirota Y., 2022, P 2022 ACM C FAIRNES, P1280, DOI DOI 10.1145/3531146.3533184; Hirota Y, 2021, Arxiv, DOI arXiv:2106.13445; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; HONG ZQ, 1991, PATTERN RECOGN, V24, P211, DOI 10.1016/0031-3203(91)90063-B; Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748; Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153; Huang J. -H., 2019, arXiv; Huang JH, 2019, AAAI CONF ARTIF INTE, P8449; Huang SH, 2023, Arxiv, DOI arXiv:2302.14045; Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849; Tiong AMH, 2022, Arxiv, DOI arXiv:2210.08773; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Hyvarinen A, 1998, INT C PATT RECOG, P1268, DOI 10.1109/ICPR.1998.711932; Iashin V, 2020, IEEE COMPUT SOC CONF, P4117, DOI 10.1109/CVPRW50498.2020.00487; Ilievski I, 2016, Arxiv, DOI [arXiv:1604.01485, DOI 10.48550/ARXIV.1604.01485,ARXIV, 10.48550/arXiv.1604.01485,arXiv]; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Jain A, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2491, DOI 10.1145/3404835.3463259; Jang Y, 2017, PROC CVPR IEEE, P1359, DOI 10.1109/CVPR.2017.149; Jimenez C. E., 2022, arXiv; Jin JQ, 2015, Arxiv, DOI arXiv:1506.06272; Jin WJ, 2022, Arxiv, DOI arXiv:2110.08484; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Kafle K, 2019, FRONT ARTIF INTELL, V2, DOI 10.3389/frai.2019.00028; Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592; Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217; Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005; Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538; Kahou Samira Ebrahimi, 2017, arXiv, DOI DOI 10.48550/ARXIV.1710.07300; Kamel SM, 2023, ARAB J SCI ENG, V48, P10803, DOI 10.1007/s13369-023-07687-y; Kazemi V., 2017, arXiv; Kembhavi A, 2017, PROC CVPR IEEE, P5376, DOI 10.1109/CVPR.2017.571; Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15; Kim JH, 2017, Arxiv, DOI [arXiv:1610.04325, DOI 10.48550/ARXIV.1610.04325]; Kim JH, 2016, ADV NEUR IN, V29; Kim JH, 2018, ADV NEUR IN, V31; Kim W, 2021, PR MACH LEARN RES, V139; Kottur S., 2019, arXiv; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Kuhn R., 2003, Political Journalism: New Challenges, New Practices; Kumar A, 2016, PR MACH LEARN RES, V48; Gupta AK, 2017, Arxiv, DOI arXiv:1705.03865; Kurp P, 2008, COMMUN ACM, V51, P11, DOI 10.1145/1400181.1400186; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Lasecki W.S., 2013, P 15 INT ACM SIGACCE, P1, DOI DOI 10.1145/2513383.2517033; Lau JJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.251; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lei J., 2018, arXiv; Lerner B, 1999, PATTERN RECOGN LETT, V20, P7, DOI 10.1016/S0167-8655(98)00120-2; Lerner P, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3108, DOI 10.1145/3477495.3531753; Li CL, 2022, Arxiv, DOI arXiv:2205.12005; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336; Li JH, 2021, ADV NEUR IN, V34; Li JN, 2022, PR MACH LEARN RES; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li Q, 2018, Arxiv, DOI arXiv:1801.09041; Li W, 2022, Arxiv, DOI arXiv:2012.15409; Li X., 2020, Oscar: Object-semantics aligned pre-training for vision-language tasks, P121; Li YF, 2023, Arxiv, DOI arXiv:2305.10355; Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502; Li ZW, 2023, PROC CVPR IEEE, P14963, DOI 10.1109/CVPR52729.2023.01437; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin W, 2023, Arxiv, DOI arXiv:2303.10699; Lin ZH, 2023, ARTIF INTELL MED, V143, DOI 10.1016/j.artmed.2023.102611; Liu CC, 2023, Arxiv, DOI arXiv:2202.07630; Liu F, 2018, PROC CVPR IEEE, P8611, DOI 10.1109/CVPR.2018.00898; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu RT, 2019, PROC CVPR IEEE, P4180, DOI 10.1109/CVPR.2019.00431; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Z, 2022, arXiv; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Lowe D.G., 1999, P INT C COMP VIS, P1150, DOI [10.1109/ICCV.1999.790410, DOI 10.1109/ICCV.1999.790410]; Lu J., 2015, GitHub repository, V6; Lu JS, 2022, Arxiv, DOI arXiv:2206.08916; Lu JS, 2019, ADV NEUR IN, V32; Lu JS, 2016, ADV NEUR IN, V29; Lu P., 2021, arXiv; Lu P, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1880, DOI 10.1145/3219819.3220036; Lu P, 2018, AAAI CONF ARTIF INTE, P7218; Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400; Luo G., 2022, IEEE Trans. Image Process.; Ma J, 2024, Arxiv, DOI [arXiv:2307.11471, DOI 10.48550/ARXIV.2307.11471]; Ma L, 2016, AAAI CONF ARTIF INTE, P3567; Maaz M, 2023, Arxiv, DOI arXiv:2306.05424; Malinowski M, 2015, Arxiv, DOI arXiv:1410.8027; Malinowski M, 2014, ADV NEUR IN, V27; Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Manmadhan S, 2020, ARTIF INTELL REV, V53, P5705, DOI 10.1007/s10462-020-09832-7; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Masry A, 2022, Arxiv, DOI arXiv:2203.10244; Mathew M, 2022, IEEE WINT CONF APPL, P2582, DOI 10.1109/WACV51458.2022.00264; Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225; Methani N, 2020, IEEE WINT CONF APPL, P1516, DOI 10.1109/WACV45572.2020.9093523; Mezaris V, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P511; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936; Mishra A., 2019, 2019 INT C DOCUMENT; Mogadala Aditya, 2021, Journal of Artificial Intelligence Research, V71, P1183; Mori S., 1999, WILEY MICRO; Mostafazadeh N, 2016, Arxiv, DOI arXiv:1603.06059; Mun J, 2017, IEEE I CONF COMP VIS, P2886, DOI 10.1109/ICCV.2017.312; Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232; Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11; OpenAI, 2023, GPT-4 technical report; Ordonez V., 2011, Advances in Neural Information Processing Systems, P1143; Pandhre S, 2017, Arxiv, DOI arXiv:1709.08203; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3; Peng ZL, 2023, Arxiv, DOI [arXiv:2306.14824, 10.48550/arXiv.2306.14824]; Petroni F, 2021, Arxiv, DOI arXiv:2009.02252; Pfeiffer Jonas, 2021, arXiv; Pomerleau D., 1988, ADV NEURAL INFORM PR, P305; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Rafi Mahamudul Hasan, 2022, 2022 25th International Conference on Computer and Information Technology (ICCIT), P114, DOI 10.1109/ICCIT57492.2022.10055205; Rahman T, 2021, IEEE COMPUT SOC CONF, P1653, DOI 10.1109/CVPRW53098.2021.00181; Raven J.C., 1938, Raven's Progressive Matrices; Ren MY, 2015, ADV NEUR IN, V28; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rohrbach A, 2019, Arxiv, DOI arXiv:1809.02156; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Salewski L., 2020, INT WORKSHOP EXTENDI, P69; Salyers MP, 2017, J GEN INTERN MED, V32, P475, DOI 10.1007/s11606-016-3886-9; Sarkar Argho, 2021, 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS, P8660, DOI 10.1109/IGARSS47720.2021.9553578; Sarkar A., 2023, IEEE Trans. Geosci. Remote Sens.; Sarlashkar MN, 1998, SOUTHEAST SYMP SYSTE, P412, DOI 10.1109/SSST.1998.660107; Schwenk D, 2022, LECT NOTES COMPUT SC, V13668, P146, DOI 10.1007/978-3-031-20074-8_9; Shah S, 2019, AAAI CONF ARTIF INTE, P8876; Sharma H, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104327; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; Shrestha R, 2024, Arxiv, DOI arXiv:2004.05704; Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851; Song H., 2022, arXiv; Sophia J. Jinu, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1707, DOI 10.1109/ICESC51422.2021.9532611; Specia L., 2016, P 1 C MACH TRANSL, P543, DOI DOI 10.18653/V1/W16-2346; Srivastava Y., 2021, COMPUTER VISION IMAG, P75; Su WJ, 2020, Arxiv, DOI arXiv:1908.08530; Suhr A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P217, DOI 10.18653/v1/P17-2034; Suresh S, 2018, IEEE CONF TECHNOL ED, P41, DOI 10.1109/T4E.2018.00016; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]; Tanaka R., 2023, arXiv; Tandon N, 2014, AAAI CONF ARTIF INTE, P166; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401; Teney D, 2016, Arxiv, DOI arXiv:1611.05546; Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444; Teney D, 2017, IEEE SIGNAL PROC MAG, V34, P63, DOI 10.1109/MSP.2017.2739826; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Toor AS, 2019, PATTERN RECOGN LETT, V126, P111, DOI 10.1016/j.patrec.2018.02.013; Trott A, 2018, Arxiv, DOI arXiv:1712.08697; Tseng YY, 2022, LECT NOTES COMPUT SC, V13668, P575, DOI 10.1007/978-3-031-20074-8_33; Thapliyal AV, 2022, Arxiv, DOI arXiv:2205.12522; Vaswani A, 2017, ADV NEUR IN, V30; Vedd N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1640; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang AJ, 2023, Arxiv, DOI arXiv:2305.20087; Wang JF, 2022, Arxiv, DOI arXiv:2205.14100; Wang K. Y., 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06215; Wang P, 2022, 39 INT C MACHINE LEA; Wang P, 2023, Arxiv, DOI arXiv:2305.11172; Wang P, 2015, Arxiv, DOI arXiv:1511.02570; Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246; Wang P, 2017, PROC CVPR IEEE, P3909, DOI 10.1109/CVPR.2017.416; Wang WH, 2022, Arxiv, DOI arXiv:2208.10442; Wang ZR, 2022, Arxiv, DOI arXiv:2108.10904; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001; Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Xie N, 2019, Arxiv, DOI arXiv:1901.06706; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1645, DOI 10.1145/3123266.3123427; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu W., 2000, 6 INT C SPOK LANG PR, P202; Xue H., 2021, Adv. Neural Inf. Process. Syst., V34; Xue L., 2020, arXiv; Yang KP, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3113912; Yang PC, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P3480, DOI 10.1145/3503161.3548291; Yang ZK, 2021, NEUROCOMPUTING, V445, P121, DOI 10.1016/j.neucom.2021.02.092; Yang ZY, 2021, PROC CVPR IEEE, P8747, DOI 10.1109/CVPR46437.2021.00864; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Yin SK, 2023, Arxiv, DOI arXiv:2306.13549; Young P., 2014, P TACL, V2, P67, DOI DOI 10.1162/TACL_A_00166; Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446; Yu JH, 2022, Arxiv, DOI arXiv:2205.01917; Yu LC, 2015, Arxiv, DOI arXiv:1506.00278; Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340; Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644; Yuan D., 2021, arXiv; Yuan L., 2021, arXiv; Yuan ZH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3203314; Yun Heeseung, 2021, P IEEECVF INT C COMP, P2031; Yusuf AA, 2022, ARTIF INTELL REV, V55, P6277, DOI 10.1007/s10462-022-10151-2; Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688; Zeng GY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P376, DOI 10.1145/3474085.3475606; Zeng KH, 2017, AAAI CONF ARTIF INTE, P4334; Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546; Zhang DX, 2019, INFORM FUSION, V52, P268, DOI 10.1016/j.inffus.2019.03.005; Zhang K, 2024, Arxiv, DOI [arXiv:2305.17100, DOI 10.48550/ARXIV.2305.17100]; Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zhang XM, 2023, Arxiv, DOI arXiv:2305.10415; Zhao YQ, 2023, Arxiv, DOI arXiv:2305.16934; Zhong YY, 2022, Arxiv, DOI arXiv:2203.01225; Zhou BL, 2015, Arxiv, DOI arXiv:1512.02167; Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540; Zhuge MC, 2021, PROC CVPR IEEE, P12642, DOI 10.1109/CVPR46437.2021.01246	321	0	0	9	9	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	JUN	2024	106								102270	10.1016/j.inffus.2024.102270	http://dx.doi.org/10.1016/j.inffus.2024.102270		FEB 2024	32	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KD2O0		Green Submitted			2024-07-03	WOS:001177957700001
J	Kessel, M; Atkinson, C				Kessel, Marcus; Atkinson, Colin			Promoting open science in test-driven software experiments	JOURNAL OF SYSTEMS AND SOFTWARE			English	Article						Software; Engineering; Empirical; Experimentation; Observation; Behavior; Reproducibility; Replication; Data structures; Open science; Large language models; Machine learning; Generative artificial intelligence; Benchmark; Language-to-code; HumanEval; Automation; Measurement	EMPIRICAL-RESEARCH	A core principle of open science is the clear, concise and accessible publication of empirical data, including "raw"observational data as well as processed results. However, in empirical software engineering there are no established standards (de jure or de facto) for representing and "opening"observations collected in testdriven software experiments - that is, experiments involving the execution of software subjects in controlled scenarios. Execution data is therefore usually represented in ad hoc ways, often making it abstruse and difficult to access without significant manual effort. In this paper we present new data structures designed to address this problem by clearly defining, correlating and representing the stimuli and responses used to execute software subjects in test-driven experiments. To demonstrate their utility, we show how they can be used to promote the repetition, replication and reproduction of experimental evaluations of AI -based code completion tools. We also show how the proposed data structures facilitate the incremental expansion of execution data sets, and thus promote their repurposing for new experiments addressing new research questions.	[Kessel, Marcus; Atkinson, Colin] Univ Mannheim, D-68159 Mannheim, Germany	University of Mannheim	Kessel, M (corresponding author), Univ Mannheim, D-68159 Mannheim, Germany.	marcus.kessel@uni-mannheim.de; colin.atkinson@uni-mannheim.de		Atkinson, Colin/0000-0002-3164-5595; Kessel, Marcus/0000-0003-3088-2166				ACM, 2023, Artifact review and badging-version 1.0; Aghajanyan A, 2022, Arxiv, DOI [arXiv:2201.07520, 10.48550/arXiv.2201.07520]; Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Andrews JH, 2005, PROC INT CONF SOFTW, P402, DOI 10.1145/1062455.1062530; [Anonymous], 2016, Introduction to software testing; [Anonymous], 2022, The R Project for Statistical Computing; Arcuri A, 2014, SOFTW TEST VERIF REL, V24, P219, DOI 10.1002/stvr.1486; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bajracharya S, 2014, SCI COMPUT PROGRAM, V79, P241, DOI 10.1016/j.scico.2012.04.008; BASILI VR, 1986, IEEE T SOFTWARE ENG, V12, P733, DOI 10.1109/TSE.1986.6312975; Ben Allal L., 2022, A framework for the evaluation of code generation models; Caserta J., 2013, The Data Warehouseetl Toolkit: Practical Techniques for Extracting, Cleaning, Conforming, and Delivering Data; Cassano F., 2023, Completions Data Set: Multi-Programming Language Evaluation of Large Language Models of Code (MultiPL-E); Cassano F., 2023, Problem data set: Multi-programming language evaluation of large language models of code (MultiPL-E); Cassano F, 2023, IEEE T SOFTWARE ENG, V49, P3675, DOI 10.1109/TSE.2023.3267446; Chen M., 2021, arXiv; Danglot B, 2019, J SYST SOFTWARE, V157, DOI 10.1016/j.jss.2019.110398; Diamantopoulos T, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P488, DOI [10.1109/MSR.2016.061, 10.1145/2901739.2903492]; Dietrich J, 2017, J OBJECT TECHNOL, V16, DOI 10.5381/jot.2017.16.4.a1.; Dyer R, 2015, ACM T SOFTW ENG METH, V25, DOI 10.1145/2803171; Dyer R, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P422, DOI 10.1109/ICSE.2013.6606588; Ernst M.D., 2003, WODA 2003 ICSE WORKS, P24; ESE, 2023, Empirical software engineering-An international journal; ESEM, 2023, Empirical software engineering and measurement; Fernández DM, 2019, EMPIR SOFTW ENG, V24, P1057, DOI 10.1007/s10664-019-09712-x; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2014, ACM T SOFTW ENG METH, V24, DOI 10.1145/2685612; Fraser G, 2013, IEEE T SOFTWARE ENG, V39, P276, DOI 10.1109/TSE.2012.14; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gousios G, 2013, IEEE WORK CONF MIN S, P233, DOI 10.1109/MSR.2013.6624034; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; JUnit, 2022, JUnit; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Kessel M., 2023, Ph.D. thesis; Kessel Marcus, 2023, Zenodo, DOI 10.5281/ZENODO.8208246; Kessel M, 2022, J SYST SOFTWARE, V193, DOI 10.1016/j.jss.2022.111442; Kessel M, 2019, PROCEEDINGS OF THE 10TH ACM SIGSOFT INTERNATIONAL WORKSHOP ON AUTOMATING TEST CASE DESIGN, SELECTION, AND EVALUATION (A-TEST '19), P35, DOI 10.1145/3340433.3342825; Kessel M, 2019, IEEE INT WORK C SO, P56, DOI 10.1109/SCAM.2019.00015; Kessel M, 2019, IEEE INT WORK C SO, P193, DOI 10.1109/SCAM.2019.00030; Kocetkov D., 2022, arXiv; Kulal S, 2019, ADV NEUR IN, V32; Langdon WB, 2017, 2017 IEEE/ACM 10TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST), P5, DOI 10.1109/SBST.2017.1; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu J., 2023, 37 C NEUR INF PROC S; Lopes CV, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133908; Ma YX, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-020-09905-9; Maj Petr., 2021, 35th European Conference on Object-Oriented Programming (ECOOP 2021), V194, p6:1, DOI DOI 10.4230/LIPICS.ECOOP.2021.6; Markovtsev V, 2018, IEEE WORK CONF MIN S, P34, DOI 10.1145/3196398.3196464; Mendez D., 2020, Contemporary Empirical Methods in Software Engineering, P477; Minocher R., 2020, Reproducibility improves exponentially over 63 years of social learning research, DOI [10.31234/osf.io/4nzc7, DOI 10.31234/OSF.IO/4NZC7]; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Nong Y, 2023, IEEE T SOFTWARE ENG, V49, P1983, DOI 10.1109/TSE.2022.3207149; Palsberg J, 2018, COMPANION PROCEEDINGS FOR THE ISSTA/ECOOP 2018 WORKSHOPS, P100, DOI 10.1145/3236454.3236501; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; RICE HG, 1953, T AM MATH SOC, V74, P358, DOI 10.2307/1990888; Sajnani H, 2016, PROC INT CONF SOFTW, P1157, DOI 10.1145/2884781.2884877; Shamshiri S, 2015, IEEE INT CONF AUTOM, P201, DOI 10.1109/ASE.2015.86; Siegmund J, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P9, DOI 10.1109/ICSE.2015.24; Sonatype, 2022, Maven Central; The Apache Software Foundation, 2022, Apache ignite; Vaswani A, 2017, ADV NEUR IN, V30; Vogl S, 2021, 2021 IEEE/ACM 14TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST 2021), P28, DOI 10.1109/SBST52555.2021.00012; Wohlin C, 2003, LECT NOTES COMPUT SC, V2765, P7; Wohlin C., 2012, Experimentation in Software Engineering, DOI [10.1007/978-3-642-29044-2, DOI 10.1007/978-3-642-29044-2, 10.1007/978-3-642-29044-2.]; Wohlin C, 2021, INFORM SOFTWARE TECH, V133, DOI 10.1016/j.infsof.2021.106514; Zhang L, 2018, J COMPUT SCI TECH-CH, V33, P876, DOI 10.1007/s11390-018-1864-x	71	1	1	0	0	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0164-1212	1873-1228		J SYST SOFTWARE	J. Syst. Softw.	JUN	2024	212								111971	10.1016/j.jss.2024.111971	http://dx.doi.org/10.1016/j.jss.2024.111971		MAR 2024	20	Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QN8H8		hybrid			2024-07-03	WOS:001221638400001
J	Kavadella, A; Silva, MADD; Kaklamanos, EG; Stamatopoulos, V; Giannakopoulos, K; Kavadella, A				Kavadella, Argyro; Silva, Marco Antonio Dias da; Kaklamanos, Eleftherios G.; Stamatopoulos, Vasileios; Giannakopoulos, Kostis; Kavadella, Argyro			Evaluation of ChatGPT's Real-Life Implementation in Undergraduate Dental Education: Mixed Methods Study	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; large language models; LLM; natural language processing; artificial Intelligence; dental education; higher education; learning assignments; dental students; AI pedagogy; dentistry; university		Background: The recent artificial intelligence tool ChatGPT seems to offer a range of benefits in academic education while also raising concerns. Relevant literature encompasses issues of plagiarism and academic dishonesty, as well as pedagogy and educational affordances; yet, no real-life implementation of ChatGPT in the educational process has been reported to our knowledge Objective: This mixed methods study aimed to evaluate the implementation of ChatGPT in the educational process, both quantitatively and qualitatively. Methods: In March 2023, a total of 77 second-year dental students of the European University Cyprus were divided into 2 groups and asked to compose a learning assignment on "Radiation Biology and Radiation Protection in the Dental Office," working collaboratively in small subgroups, as part of the educational semester program of the Dentomaxillofacial Radiology module. Careful planning ensured a seamless integration of ChatGPT, addressing potential challenges. One group searched the internet for scientific resources to perform the task and the other group used ChatGPT for this purpose. Both groups developed a PowerPoint (Microsoft Corp) presentation based on their research and presented it in class. The ChatGPT group students additionally registered all interactions with the language model during the prompting process and evaluated the final outcome; they also answered an open-ended evaluation questionnaire, including questions on their learning experience. Finally, all students undertook a knowledge examination on the topic, and the grades between the 2 groups were compared statistically, whereas the free-text comments of the questionnaires were thematically analyzed. Results: Out of the 77 students, 39 were assigned to the ChatGPT group and 38 to the literature research group. Seventy students undertook the multiple choice question knowledge examination, and examination grades ranged from 5 to 10 on the 0-10 grading scale. The Mann-Whitney U test showed that students of the ChatGPT group performed significantly better (P=.045) than students of the literature research group. The evaluation questionnaires revealed the benefits (human-like interface, immediate response, and wide knowledge base), the limitations (need for rephrasing the prompts to get a relevant answer, general content, false citations, and incapability to provide images or videos), and the prospects (in education, clinical practice, continuing education, Conclusions: Students using ChatGPT for their learning assignments performed significantly better in the knowledge examination than their fellow students who used the literature research methodology. Students adapted quickly to the technological environment of the language model, recognized its opportunities and limitations, and used it creatively and efficiently. Implications for practice: the study underscores the adaptability of students to technological innovations including ChatGPT and its potential to enhance educational outcomes. Educators should consider integrating ChatGPT into curriculum design; awareness programs are warranted to educate both students and educators about the limitations of ChatGPT, encouraging critical engagement and responsible use.	[Kavadella, Argyro; Kaklamanos, Eleftherios G.; Giannakopoulos, Kostis; Kavadella, Argyro] European Univ Cyprus, Sch Dent, Nicosia, Cyprus; [Silva, Marco Antonio Dias da] Univ Fed Campina Grande, Res Grp Teleducat & Teledent, Campina Grande, Brazil; [Kaklamanos, Eleftherios G.] Aristotle Univ Thessaloniki, Sch Dent, Thessaloniki, Greece; [Kaklamanos, Eleftherios G.] Mohammed Bin Rashid Univ Med & Hlth Sci, Dubai, U Arab Emirates; [Stamatopoulos, Vasileios] Athena Res & Innovat Ctr, Informat Management Syst Inst, Athens, Greece; [Kavadella, Argyro; Kavadella, Argyro] European Univ Cyprus, Sch Dent, 6 Diogenous St, CY-2404 Engomi, Nicosia, Cyprus	European University Cyprus; Universidade Federal de Campina Grande; Aristotle University of Thessaloniki; European University Cyprus	Kavadella, A (corresponding author), European Univ Cyprus, Sch Dent, 6 Diogenous St, CY-2404 Engomi, Nicosia, Cyprus.	a.kavadella@euc.ac.cy	da Silva, Marco Antonio Dias/K-4730-2012	da Silva, Marco Antonio Dias/0000-0002-2774-4769; KAVADELLA, ARGYRO/0009-0003-0560-8373; Kaklamanos, Eleftherios G./0000-0002-0513-5110; Stamatopoulos, Vasileios/0000-0002-9044-796X				[Anonymous], 2022, Gen Z are not 'coddled.' They are highly collaborative, self-reliant and pragmatic, according to new Stanford-affiliated research.; [Anonymous], FREE 39+ student evaluation forms in PDF | Excel | MS word; [Anonymous], IL rubric for student essay evaluation; [Anonymous], 2023, Inclusive and gender-neutral language.; Ariyanti A., 2017, ADV SOCIAL SCI ED HU, DOI DOI 10.2991/ICTTE-17.2017.4; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Aubignat M, 2023, REV NEUROL-FRANCE, V179, P520, DOI 10.1016/j.neurol.2023.03.004; Bearman M, 2023, HIGH EDUC, V86, P369, DOI 10.1007/s10734-022-00937-2; Biggs J, 2012, HIGH EDUC RES DEV, V31, P39, DOI 10.1080/07294360.2012.642839; Bishop L., 2023, COMPUTER WROTE THIS; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Celik I, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107468; Chan CKY, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00411-8; Chavez MR, 2023, AM J OBSTET GYNECOL, V228, P706, DOI 10.1016/j.ajog.2023.03.010; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Currie G, 2023, RADIOGRAPHY, V29, P792, DOI 10.1016/j.radi.2023.05.011; Eldridge A., Britannica.; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fawns T., 2022, Postdigital Science and Education, V4, P711, DOI [DOI 10.1007/S42438-022-00302-7, 10.1007/s42438-022-00302-7]; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Ferres JML, 2023, DIAGN INTERV IMAG, V104, P263, DOI 10.1016/j.diii.2023.02.006; Fuchs K, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1166682; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gimpel H., 2023, Unlocking the power of generative AI models and systems such as GPT-4 and ChatGPT for higher education: A guide for students and lecturers; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Han E, 2019, AM J PHARM EDUC, V83, DOI 10.5688/ajpe6922; Hemachandran K, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1410448; Hollinderbaumer Anke, 2013, GMS Z Med Ausbild, V30, pDoc14, DOI 10.3205/zma000857; Islam NM, 2022, J DENT EDUC, V86, P1545, DOI 10.1002/jdd.13010; Israni ST, 2019, JAMA-J AM MED ASSOC, V321, P29, DOI 10.1001/jama.2018.19398; Khalil Mohammad, 2023, Learning and Collaboration Technologies: 10th International Conference, LCT 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Proceedings. Lecture Notes in Computer Science (14040), P475, DOI 10.1007/978-3-031-34411-4_32; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lazarus MD, 2024, ANAT SCI EDUC, V17, P249, DOI 10.1002/ase.2221; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Mynlieff M, 2014, CBE-LIFE SCI EDUC, V13, P311, DOI 10.1187/cbe.13-05-0097; Nazari N, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07014; Nisar S, 2023, ABOUT US; oxford, 7 unique characteristics of generation Z. Oxford Royale; Perera P., 2023, INT J RES INNOVATION, VVII, P306, DOI [10.47772/IJRISS.2023.7623, DOI 10.47772/IJRISS.2023.7623]; Prensky M., 2001, On the Horizon, V9, P1, DOI [10.1108/10748120110424816, DOI 10.1108/10748120110424816]; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Roe Y, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1728-2; Roganovic J, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11101480; Rudolph J, PREPRINT, DOI [10.37074/jalt.2023.6.1.23, DOI 10.37074/JALT.2023.6.1.23]; Sabzalieva E., 2023, ChatGPT and artificial intelligence in higher education quick start guide; Salas-Pilco SZ, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142013572; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scager K, 2016, CBE-LIFE SCI EDUC, V15, DOI 10.1187/cbe.16-07-0219; Schwendicke F, 2023, J DENT, V128, DOI 10.1016/j.jdent.2022.104363; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Turnbull D, 2021, EDUC INF TECHNOL, V26, P6401, DOI 10.1007/s10639-021-10633-w; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang XY, 2023, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1087174; Warren-Forward HM, 2018, RADIOGRAPHY, V24, P376, DOI 10.1016/j.radi.2018.05.011	60	3	3	26	26	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e51344	10.2196/51344	http://dx.doi.org/10.2196/51344			14	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IE0A1	38111256	gold			2024-07-03	WOS:001164519300002
J	Wang, CL; Thompson, J; Lee, B				Wang, Chenglong; Thompson, John; Lee, Bongshin			Data Formulator: AI-Powered Concept-Driven Visualization Authoring	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			English	Article						Data visualization; Temperature distribution; Urban areas; Visualization; Transforms; Histograms; Libraries; AI; visualization authoring; data transformation; programming by example; natural language; large language model	DESIGN; LYRA	With most modern visualization tools, authors need to transform their data into tidy formats to create visualizations they want. Because this requires experience with programming or separate data processing tools, data transformation remains a barrier in visualization authoring. To address this challenge, we present a new visualization paradigm, concept binding, that separates high-level visualization intents and low-level data transformation steps, leveraging an AI agent. We realize this paradigm in Data Formulator, an interactive visualization authoring tool. With Data Formulator, authors first define data concepts they plan to visualize using natural languages or examples, and then bind them to visual channels. Data Formulator then dispatches its AI-agent to automatically transform the input data to surface these concepts and generate desired visualizations. When presenting the results (transformed table and output visualizations) from the AI agent, Data Formulator provides feedback to help authors inspect and understand them. A user study with 10 participants shows that participants could learn and use Data Formulator to create visualizations that involve challenging data transformations, and presents interesting future research directions.	[Wang, Chenglong; Thompson, John; Lee, Bongshin] Microsoft Res, Redmond, WA 98052 USA	Microsoft	Wang, CL (corresponding author), Microsoft Res, Redmond, WA 98052 USA.	chenglong.wang@microsoft.com; johnthompson@microsoft.com; bongshin@microsoft.com						Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Barman S, 2016, ACM SIGPLAN NOTICES, V51, P748, DOI 10.1145/3022671.2984020; Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830; Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185; Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174; Chaudhuri S, 2021, FOUND TRENDS PROGRAM, V7, P158, DOI 10.1561/2500000049; Chen M., CoRR; Chen QC, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3563307; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Hendrycks D., 2021, P NEURAL INFORM PROC; Ji RY, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P1143, DOI 10.1145/3385412.3386025; Jin ZJ, 2020, PROC VLDB ENDOW, V13, P2368, DOI 10.14778/3407790.3407831; Jin ZJ, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P683, DOI 10.1145/3035918.3064034; Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363; Kery M. B., 2020, P 33 ANN ACM S US IN, P140, DOI [10.1145/3379337.34158429, DOI 10.1145/3379337.34158429, 10.1145/3379337.3415842, DOI 10.1145/3379337.3415842]; Kim D. H., CHI 20; Lai Yuhang, 2022, arXiv; Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751; Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151; Li TJJ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P577, DOI 10.1145/3332165.3347899; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010; Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315; Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697; Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848; Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924; Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240; Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470; Poesia G., 2022, 10 INT C LEARNING RE; Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]; Pu K, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545691; Raman V., 2001, VLDB 2001 P 27 INT C, P9; Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86; Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158; Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839; Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281; Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030; Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391; Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159; Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400; Stolte C., 2002, P 8 ACM SIGKDD INT C, P112, DOI [10.1145/775047.7750648, DOI 10.1145/775047.7750648, DOI 10.1145/775047.775064]; T. pandas development team, 2023, pandas-dev/pandas: Pandas, DOI [10.5281/zenodo.77415801,9, DOI 10.5281/ZENODO.77415801,9]; Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476; VanderPlas J., 2018, J OPEN SOURCE SOFTW, V3, P1057, DOI DOI 10.21105/JOSS.01057; Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249; Wang CL, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3371117; Wang CL, 2017, ACM SIGPLAN NOTICES, V52, P452, DOI [10.1145/3140587.3062365, 10.1145/3062341.3062365]; Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3; Wickham H, 2014, J STAT SOFTW, V59, P1; Wickham Hadley, 2024, CRAN; Wilkinson L., 2005, The Grammar of Graphics, Second Edition. Statistics and computing, VSecond, P8; Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648; Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191; Xiong Kai, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209470; Yan C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1539, DOI 10.1145/3318464.3389738; Zhang T., 2021, CHI 21 CHI C HUMAN F, P1; Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369; Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367	63	0	0	4	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1077-2626	1941-0506		IEEE T VIS COMPUT GR	IEEE Trans. Vis. Comput. Graph.	JAN	2024	30	1					1128	1138		10.1109/TVCG.2023.3326585	http://dx.doi.org/10.1109/TVCG.2023.3326585			11	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HJ3Z6	37871079	Green Submitted			2024-07-03	WOS:001159106500081
J	Yu, J; Qi, C				Yu, Jason; Qi, Cheryl			The Impact of Generative AI on Employment and Labor Productivity	REVIEW OF BUSINESS			English	Article						artificial intelligence; generative artificial intelligence; employment; labor productivity; industrial advancement; science and technology; society; large language model; machine learning; generative pre-trained transformer		Motivation: After the recent introduction of ChatGPT, the rise of generative artificial intelligence (GAI) has ignited discussions about its potential to disrupt employment and impact labor productivity. Our paper empirically examines the potential effects of GAI. Premise: Our paper showcases GAI's impact on employment and labor productivity in the United States. Approach: We investigate the 100 largest publicly traded U.S. companies. The key variable of GAI exposure is from Eisfeldt, Schubert, and Zhang (2023). Employment is measured by the number of employees or the number of employees scaled by total assets. Labor productivity is assessed using real sales per employee or operating income per employee. We employ a difference-in-differences methodology, comparing changes in firms with high GAI exposure to those with low GAI exposure, before and after the launch of ChatGPT. Results: Our findings indicate that the introduction of GAI has not had a negative impact on employment. Furthermore, GAI has created positive and statistically significant effects on labor productivity. Conclusion: We conclude that GAI has not decreased employment but has increased labor productivity. The impact of GAI extends beyond the business world. Our discovery highlights the revolutionary potential of GAI and encourages policy makers to utilize it to benefit and advance society. Consistency: Our research provides the latest empirical evidence on GAI's impact on employment and labor productivity. The findings suggest that GAI's adoption enhances labor productivity for businesses and creates employment stability. Our discovery has prevalent and profound influence on the present and future of our world.	[Yu, Jason] Livingston High Sch, Livingston, NJ 07039 USA; [Qi, Cheryl] Univ Ottawa, Ottawa, ON, Canada	University of Ottawa	Yu, J (corresponding author), Livingston High Sch, Livingston, NJ 07039 USA.	jasony.livingston@gmail.com; Qianru.Qi@telfer.uOttawa.ca						Acemoglu D, 2022, ECONOMETRICA, V90, P1973, DOI 10.3982/ECTA19815; Acemoglu D, 2020, J POLIT ECON, V128, P2188, DOI 10.1086/705716; Brynjolfsson E., 2023, National Bureau of Economic Research Working Paper 31161; Dauth W, 2021, J EUR ECON ASSOC, V19, P3104, DOI 10.1093/jeea/jvab012; Eisfeldt A. L., 2023, National Bureau of Economic Research working paper; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; OpenAI, 2023, GPT-4 Technical Report; Saetra HS, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102372	9	1	1	20	20	ST JOHNS UNIV BUSINESS RESEARCH INST	JAMAICA	BENT HALL, JAMAICA, NY 11439 USA	0034-6454			REV BUS	Rev. Bus.	JAN	2023	44	1					53	67						15	Business	Emerging Sources Citation Index (ESCI)	Business & Economics	LY8W0					2024-07-03	WOS:001190474400004
J	Hirosawa, T; Kawamura, R; Harada, Y; Mizuta, K; Tokumasu, K; Kaji, Y; Suzuki, T; Shimizu, T				Hirosawa, Takanobu; Kawamura, Ren; Harada, Yukinori; Mizuta, Kazuya; Tokumasu, Kazuki; Kaji, Yuki; Suzuki, Tomoharu; Shimizu, Taro			ChatGPT-Generated Differential Diagnosis Lists for Complex Case-Derived Clinical Vignettes: Diagnostic Accuracy Evaluation	JMIR MEDICAL INFORMATICS			English	Article						artificial intelligence; AI chatbot; ChatGPT; large language models; clinical decision support; natural language processing; diagnostic excellence; language model; vignette; case study; diagnostic; accuracy; decision support; diagnosis	ARTIFICIAL-INTELLIGENCE	Background: The diagnostic accuracy of differential diagnoses generated by artificial intelligence chatbots, including ChatGPT models, for complex clinical vignettes derived from general internal medicine (GIM) department case reports is unknown.Objective: This study aims to evaluate the accuracy of the differential diagnosis lists generated by both third-generation ChatGPT (ChatGPT-3.5) and fourth-generation ChatGPT (ChatGPT-4) by using case vignettes from case reports published by the Department of GIM of Dokkyo Medical University Hospital, Japan.Methods: We searched PubMed for case reports. Upon identification, physicians selected diagnostic cases, determined the final diagnosis, and displayed them into clinical vignettes. Physicians typed the determined text with the clinical vignettes in the ChatGPT-3.5 and ChatGPT-4 prompts to generate the top 10 differential diagnoses. The ChatGPT models were not specially trained or further reinforced for this task. Three GIM physicians from other medical institutions created differential diagnosis lists by reading the same clinical vignettes. We measured the rate of correct diagnosis within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and the top diagnosis.Results: In total, 52 case reports were analyzed. The rates of correct diagnosis by ChatGPT-4 within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and top diagnosis were 83% (43/52), 81% (42/52), and 60% (31/52), respectively. The rates of correct diagnosis by ChatGPT-3.5 within the top 10 differential diagnosis lists, top 5 differential diagnosis lists, and top diagnosis were 73% (38/52), 65% (34/52), and 42% (22/52), respectively. The rates of correct diagnosis by ChatGPT-4 were comparable to those by physicians within the top 10 (43/52, 83% vs 39/52, 75%, respectively; P=.47) and within the top 5 (42/52, 81% vs 35/52, 67%, respectively; P=.18) differential diagnosis lists and top diagnosis (31/52, 60% vs 26/52, 50%, respectively; P=.43) although the difference was not significant. The ChatGPT models' diagnostic accuracy did not significantly vary based on open access status or the publication date (before 2011 vs 2022).Conclusions: This study demonstrates the potential diagnostic accuracy of differential diagnosis lists generated using ChatGPT-3.5 and ChatGPT-4 for complex clinical vignettes from case reports published by the GIM department. The rate of correct diagnoses within the top 10 and top 5 differential diagnosis lists generated by ChatGPT-4 exceeds 80%. Although derived from a limited data set of case reports from a single department, our findings highlight the potential utility of ChatGPT-4 as a supplementary tool for physicians, particularly for those affiliated with the GIM department. Further investigations should explore the diagnostic accuracy of ChatGPT by using distinct case materials beyond its training data. Such efforts will provide a comprehensive insight into the role of artificial intelligence in enhancing clinical decision-making.	[Hirosawa, Takanobu; Kawamura, Ren; Harada, Yukinori; Mizuta, Kazuya; Shimizu, Taro] Dokkyo Med Univ, Dept Diagnost & Generalist Med, Mibu, Tochigi, Japan; [Tokumasu, Kazuki] Okayama Univ, Dept Gen Med, Grad Sch Med Dent & Pharmaceut Sci, Okayama, Japan; [Kaji, Yuki] Int Univ Hlth & Welf, Narita Hosp, Dept Gen Med, Chiba, Japan; [Suzuki, Tomoharu] Urasoe Gen Hosp, Dept Hosp Med, Urasoe, Okinawa, Japan; [Hirosawa, Takanobu] Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Shimotsuga, Tochigi 3210293, Japan	Dokkyo Medical University; Okayama University; International University of Health & Welfare; Dokkyo Medical University	Hirosawa, T (corresponding author), Dokkyo Med Univ, Dept Diagnost & Generalist Med, 880 Kitakobayashi, Shimotsuga, Tochigi 3210293, Japan.	hirosawa@dokkyomed.ac.jp	Hirosawa, Takanobu/AFS-0531-2022	Hirosawa, Takanobu/0000-0002-3573-8203; Kaji, Yuki/0000-0002-0267-9876; Kawamura, Ren/0000-0002-5632-3218; Tokumasu, Kazuki/0000-0001-9513-6864				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131; Balogh EP, 2015, IMPROVING DIAGNOSIS IN HEALTH CARE, P1, DOI 10.17226/21794; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Chen JH, 2022, JAMA-J AM MED ASSOC, V328, P709, DOI 10.1001/jama.2022.13735; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; Greenes RA, 2014, CLINICAL DECISION SUPPORT: THE ROAD TO BROAD ADOPTION, 2ND EDITION, P49; Harada Y, 2024, BMJ QUAL SAF, V33, P386, DOI 10.1136/bmjqs-2022-015436; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Hirosawa T, 2024, DIAGNOSIS, V11, P102, DOI 10.1515/dx-2023-0116; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Holmboe ES, 2014, DIAGNOSIS, V1, P111, DOI 10.1515/dx-2013-0029; Jinno Atsushi, 2018, BMJ Case Rep, V2018, DOI 10.1136/bcr-2017-223844; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kawamura R, 2022, JMIR MED INF, V10, DOI 10.2196/35225; Krupat E, 2017, MED EDUC, V51, P1127, DOI 10.1111/medu.13382; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Meunier PY, 2023, ANN FAM MED, V21, P57, DOI 10.1370/afm.2908; Riches N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148991; Schmieding ML, 2022, J MED INTERNET RES, V24, DOI 10.2196/31810; Skinner TR, 2016, INT J GEN MED, V9, P137, DOI 10.2147/IJGM.S96741; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wani SUD, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10040608; Zheng HY, 2023, AM J MED, V136, P725, DOI 10.1016/j.amjmed.2023.02.011; Zong MY, 2022, Arxiv, DOI arXiv:2212.00857	27	14	14	9	13	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2291-9694		JMIR MED INF	JMIR Med. Inf.		2023	11								e48808	10.2196/48808	http://dx.doi.org/10.2196/48808			11	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	U5WW1	37812468	Green Published, gold			2024-07-03	WOS:001085515100002
J	Kantor, J				Kantor, Jonathan			Digital health in dermatology	JAAD INTERNATIONAL			English	Editorial Material						artificial intelligence; ChatGPT; copilot; digital health; Google Bard; large language models; machine learning; medical education; Microsoft Bing; practice management; teledermatology; teledermoscopy; telemedicine; whole slide imaging	TELEDERMATOLOGY		[Kantor, Jonathan] Univ Penn, Ctr Global Hlth, Perelman Sch Med, Dept Dermatol, Philadelphia, PA USA; Univ Penn, Ctr Clin Epidemiol & Biostat, Perelman Sch Med, Philadelphia, PA USA; [Kantor, Jonathan] Florida Ctr Dermatol, St Augustine, FL USA; Alchemy Labs, Oxford, England; [Kantor, Jonathan] 1301 Plantat Isl Dr S, St Augustine, FL 32080 USA	University of Pennsylvania; University of Pennsylvania	Kantor, J (corresponding author), 1301 Plantat Isl Dr S, St Augustine, FL 32080 USA.	jonkantor@gmail.com						Burshtein J, 2023, JAAD INT, V12, P3, DOI 10.1016/j.jdin.2023.03.005; Lui BLJ, 2023, JAAD INT, V12, P46, DOI 10.1016/j.jdin.2023.04.005; Maloney ME, 2023, JAAD INT, V11, P140, DOI 10.1016/j.jdin.2023.02.010; Ong FL, 2023, JAAD INT, V11, P59, DOI 10.1016/j.jdin.2023.01.010; Schreidah CM, 2023, JAAD INT, V12, P24, DOI 10.1016/j.jdin.2023.02.017	5	1	1	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2666-3287		JAAD INT	JAAD Int.	DEC	2023	13						139	139		10.1016/j.jdin.2023.08.008	http://dx.doi.org/10.1016/j.jdin.2023.08.008			1	Dermatology	Emerging Sources Citation Index (ESCI)	Dermatology	TX8F4	37786788	Green Published, gold			2024-07-03	WOS:001244642800018
J	Temsah, MH; Jamal, A; Alhasan, K; Aljamaan, F; Altamimi, I; Malki, KH; Temsah, A; Ohannessian, R; Al-Eyadhy, A				Temsah, Mohamad-Hani; Jamal, Amr; Alhasan, Khalid; Aljamaan, Fadi; Altamimi, Ibraheem; Malki, Khalid H.; Temsah, Abdulrahman; Ohannessian, Robin; Al-Eyadhy, Ayman			Transforming Virtual Healthcare: The Potentials of ChatGPT-4omni in Telemedicine	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Editorial Material						patient communication; digital health innovations; ai in healthcare; large language models (llm); health information privacy; data privacy; natural language processing; virtual healthcare; telemedicine; chatgpt-4o		The introduction of OpenAI's ChatGPT-4omni (GPT-4o) represents a potential advancement in virtual healthcare and telemedicine. GPT-4o excels in processing audio, visual, and textual data in real time, offering possible enhancements in understanding natural language in both English and non-English contexts. Furthermore, the new "Temporary Chat" feature may improve privacy and data confidentiality during interactions, potentially increasing integration with healthcare systems. These innovations promise to enhance communication clarity, facilitate the integration of medical images, and increase data privacy in online consultations. This editorial explores some future implications of these advancements for telemedicine, highlighting the necessity for further research on reliability and the integration of advanced language models with human expertise.	[Temsah, Mohamad-Hani] King Saud Univ Med City, King Saud Univ, Coll Med, Pediat Dept,Pediat Intens Care Unit, Riyadh, Saudi Arabia; [Jamal, Amr] King Saud Univ, Family & Community Med, Riyadh, Saudi Arabia; [Alhasan, Khalid] King Saud Univ, Pediat Nephrol, Riyadh, Saudi Arabia; [Aljamaan, Fadi] King Saud Univ, Coll Med, Crit Care Dept, Riyadh, Saudi Arabia; [Altamimi, Ibraheem] King Saud Univ, Coll Med, Riyadh, Saudi Arabia; [Malki, Khalid H.] King Saud Univ, Coll Med, Dept Otolaryngol, Riyadh, Saudi Arabia; [Temsah, Abdulrahman] Alfaisal Univ, Coll Engn, Software Engn Dept, Riyadh, Saudi Arabia; [Ohannessian, Robin] Vickino Inst Telehlth, Digital Hlth, Vickino, Armenia; [Al-Eyadhy, Ayman] King Saud Univ, Coll Med, Dept Pediat, Pediat Intens Care Unit, Riyadh, Saudi Arabia; [Al-Eyadhy, Ayman] King Saud Univ Med City, Pediat Intens Care Unit, Riyadh, Saudi Arabia	King Saud University; King Saud University; King Saud University; King Saud University; King Saud University; King Saud University; Alfaisal University; King Saud University; King Saud University	Temsah, MH (corresponding author), King Saud Univ Med City, King Saud Univ, Coll Med, Pediat Dept,Pediat Intens Care Unit, Riyadh, Saudi Arabia.	temsah1@yahoo.com						Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Beltrami Eric J, 2024, J Am Acad Dermatol, V90, P879, DOI 10.1016/j.jaad.2023.02.052; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Nguyen MLT, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-07547-9; Ohannessian R, 2020, TELEMED E-HEALTH, V26, P574, DOI 10.1089/tmj.2019.0072; Ong Jasmine Chiat Ling, 2024, Lancet Digit Health, V6, pe428, DOI 10.1016/S2589-7500(24)00061-X; Open AI, 2024, How can I access GPT-4, GPT-4 Turbo and GPT-4o?; Open AI, 2024, Memory and new controls for ChatGPT; Sheth S, 2024, J AM ACAD ORTHOP SUR, V32, P205, DOI 10.5435/JAAOS-D-23-00787; Snoswell CL, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231169055; Teixeira da Silva JA, 2023, PATIENT EDUC COUNS, V115, DOI 10.1016/j.pec.2023.107940; Temsah MH, 2024, J MED SYST, V48, DOI 10.1007/s10916-024-02072-0; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812; Temsah MH, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39384; Temsah R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.47469; Tukur M, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2022-100676	18	0	0	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 30	2024	16	5							e61377	10.7759/cureus.61377	http://dx.doi.org/10.7759/cureus.61377			4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	TL7B5	38817799	Green Accepted, gold			2024-07-03	WOS:001241471500022
J	Blease, C; Torous, J; Mcmillan, B; Hagglund, M; Mandl, KD				Blease, Charlotte; Torous, John; Mcmillan, Brian; Hagglund, Maria; Mandl, Kenneth D.			Generative Language Models and Open Notes: Exploring the Promise and Limitations	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; generative language models; large language models; medical education; Open Notes; online record access; patient-centered care; empathy; language model; documentation; communication tool; clinical documentation	ELECTRONIC HEALTH RECORDS; PATIENTS ONLINE ACCESS; EXPERIENCES; ATTITUDES	Patients' online record access (ORA) is growing worldwide. In some countries, including the United States and Sweden, access is advanced with patients obtaining rapid access to their full records on the web including laboratory and test results, lists of prescribed medications, vaccinations, and even the very narrative reports written by clinicians (the latter, commonly referred to as "open notes"). In the United States, patient's ORA is also available in a downloadable form for use with other apps. While survey studies have shown that some patients report many benefits from ORA, there remain challenges with implementation around writing clinical documentation that patients may now read. With ORA, the functionality of the record is evolving; it is no longer only an aide memoire for doctors but also a communication tool for patients. Studies suggest that clinicians are changing how they write documentation, inviting worries about accuracy and completeness. Other concerns include work burdens; while few objective studies have examined the impact of ORA on workload, some research suggests that clinicians are spending more time writing notes and answering queries related to patients' records. Aimed at addressing some of these concerns, clinician and patient education strategies have been proposed. In this viewpoint paper, we explore these approaches and suggest another longer-term strategy: the use of generative artificial intelligence (AI) to support clinicians in documenting narrative summaries that patients will find easier to understand. Applied to narrative clinical documentation, we suggest that such approaches may significantly help preserve the accuracy of notes, strengthen writing clarity and signals of empathy and patient-centered care, and serve as a buffer against documentation work burdens. However, we also consider the current risks associated with existing generative AI. We emphasize that for this innovation to play a key role in ORA, the cocreation of clinical notes will be imperative. We also caution that clinicians will need to be supported in how to work alongside generative AI to optimize its considerable potential.	[Blease, Charlotte; Hagglund, Maria] Uppsala Univ, Dept Womens & Childrens Hlth, Uppsala, Sweden; [Blease, Charlotte; Torous, John] Beth Israel Deaconess Med Ctr, Dept Psychiat, Digital Psychiat, Boston, MA USA; [Mcmillan, Brian] Univ Manchester, Ctr Primary Care & Hlth Serv Res, Manchester, Lancashire, England; [Hagglund, Maria] Uppsala Univ Hosp, Medtech Sci & Innovat Ctr, Uppsala, Sweden; [Mandl, Kenneth D.] Harvard Med Sch, Boston Childrens Hosp, Computat Hlth Informat Program, Boston, MA USA; [Blease, Charlotte] Uppsala Univ, Dept Womens & Childrens Hlth, Box 256, S-75105 Uppsala, Sweden	Uppsala University; Harvard University; Beth Israel Deaconess Medical Center; University of Manchester; Uppsala University; Uppsala University Hospital; Harvard University; Harvard Medical School; Boston Children's Hospital; Uppsala University	Blease, C (corresponding author), Uppsala Univ, Dept Womens & Childrens Hlth, Box 256, S-75105 Uppsala, Sweden.	charlotteblease@gmail.com	Hägglund, Maria/IUQ-2130-2023	Hägglund, Maria/0000-0002-6839-3651; Torous, John/0000-0002-5362-7937; Mandl, Kenneth/0000-0002-9781-0477; BLEASE, CHARLOTTE/0000-0002-0205-1165; McMillan, Brian/0000-0002-0683-3877				Adams K., Becker's Health IT; Adams K., 2023, MedCity News; Avenanti A, 2010, CURR BIOL, V20, P1018, DOI 10.1016/j.cub.2010.03.071; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Batson CD, 1997, J PERS SOC PSYCHOL, V72, P105, DOI 10.1037/0022-3514.72.1.105; Bell SK, 2021, J PATIENT SAF, V17, pE791, DOI 10.1097/PTS.0000000000000494; Bernstein J, 2022, CLIN ORTHOP RELAT R, V480, P1653, DOI 10.1097/CORR.0000000000002344; Blease C, 2023, BMJ MENTAL HEALTH, V26, DOI 10.1136/bmjment-2023-300884; Blease C, 2022, BMJ-BRIT MED J, V379, DOI 10.1136/bmj-2021-069861; Blease C, 2022, JAMA-J AM MED ASSOC, V327, P717, DOI 10.1001/jama.2021.23179; Blease C, 2022, J MED ETHICS, V48, P785, DOI 10.1136/medethics-2021-107275; Blease C, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.2823; Blease C, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.577896; Blease C, 2019, J MED INTERNET RES, V21, DOI 10.2196/12802; Blease CR, 2020, LANCET PSYCHIAT, V7, P924, DOI 10.1016/S2215-0366(20)30032-8; Bourgeois FT, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155948; Boyd E., 2023, Introducing GPT-4 in Azure OpenAI service; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Colivicchi Q, 2023, GPs abandon legal challenge over patient records access; Denneson LM, 2019, J AM MED INFORM ASSN, V26, P3, DOI 10.1093/jamia/ocy134; DePeau-Wilson M., 2023, MEDPAGE TODAY; DesRoches CM, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.1753; DesRoches CM, 2019, ANN INTERN MED, V171, P69, DOI 10.7326/M18-3197; Dijkstra AF, 2008, MED EDUC, V42, P1021, DOI 10.1111/j.1365-2923.2008.03150.x; Dobscha SK, 2019, PSYCHIAT SERV, V70, P474, DOI 10.1176/appi.ps.201800416; Dobscha SK, 2016, GEN HOSP PSYCHIAT, V38, P89, DOI 10.1016/j.genhosppsych.2015.08.001; Domaney NM, 2018, ACAD PSYCHIATR, V42, P648, DOI 10.1007/s40596-018-0939-x; Duma N, 2018, J ONCOL PRACT, V14, P35, DOI 10.1200/JOP.2017.025288; Ferguson K, 2023, JMIR MED INF, V11, DOI 10.2196/43567; Fisher M, 2016, COGNITIVE SCI, V40, P1251, DOI 10.1111/cogs.12280; Geller SE, 2011, J WOMENS HEALTH, V20, P315, DOI 10.1089/jwh.2010.2469; Goldberg C, 2023, The AI Revolution in Medicine: GPT-4 and Beyond; Golz C, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/31408; Hägglund M, 2022, BMJ-BRIT MED J, V378, DOI 10.1136/bmj-2022-071531; Hägglund M, 2017, STUD HEALTH TECHNOL, V245, P723, DOI 10.3233/978-1-61499-830-3-723; Hannan A., Do you want to see what your doctor or nurse has written about you or check your GP Electronic Health Record?; Hein IM, 2015, BMC MED ETHICS, V16, DOI 10.1186/s12910-015-0067-z; Heins A, 2010, J PAIN, V11, P692, DOI 10.1016/j.jpain.2009.10.017; Himmelstein G, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2021.44967; Kocaballi AB, 2020, J AM MED INFORM ASSN, V27, P1695, DOI 10.1093/jamia/ocaa131; Kujala S, 2022, J MED INTERNET RES, V24, DOI 10.2196/37438; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lubell J, 2023, What does it mean for med ed?; Mahood SC, 2011, CAN FAM PHYSICIAN, V57, P983; McMillan B, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2022-100722; McMillan B, 2018, J MED INTERNET RES, V20, DOI 10.2196/11293; Meier-Diedrich E, 2023, JMIR RES PROTOC, V12, DOI 10.2196/46722; Mold F, 2015, BRIT J GEN PRACT, V65, pE141, DOI 10.3399/bjgp15X683941; Moll J, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.9492; Nielsen HG, 2009, EDUC PRIM CARE, V20, P353, DOI 10.1080/14739879.2009.11493817; opennotes, Preparing medical students and their teachers for shared medical records; Petersson L, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/10521; Salmi L, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n426; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Steitz BD, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.29553; Stillman M, 2023, JAMA-J AM MED ASSOC, V330, P223, DOI 10.1001/jama.2023.11629; Sun M, 2022, HEALTH AFFAIR, V41, P203, DOI 10.1377/hlthaff.2021.01423; tinyurl, Keeping records; Torous J, 2020, Psychology Today; Trivers R, 2000, ANN NY ACAD SCI, V907, P114; Walker J, 2019, J MED INTERNET RES, V21, DOI 10.2196/13876; Watts G, 2012, BRIT MED J, V344, DOI 10.1136/bmj.e3445; Xu XJ, 2009, J NEUROSCI, V29, P8525, DOI 10.1523/JNEUROSCI.2418-09.2009; Zack T, 2023, medRxiv, DOI [10.1101/2023.07.13.23292577, 10.1101/2023.07.13.23292577v2, DOI 10.1101/2023.07.13.23292577V2]; Zanaboni P, 2020, J MED INTERNET RES, V22, DOI 10.2196/16144	65	3	3	15	15	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e51183	10.2196/51183	http://dx.doi.org/10.2196/51183			9	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	FM3A8	38175688	Green Published, gold			2024-07-03	WOS:001146165900001
J	Zheng, JW; Fischer, M				Zheng, Junwen; Fischer, Martin			Dynamic prompt-based virtual assistant framework for BIM information search	AUTOMATION IN CONSTRUCTION			English	Article						Building information modeling; Generative pre-trained transformer; Virtual assistant; Information search; Natural language processing; Artificial intelligence; BIMS-GPT; Prompt engineering; Large language model; Information retrieval	LANGUAGE; MANAGEMENT; RETRIEVAL	Efficient information search from building information models (BIMs) requires deep BIM knowledge or extensive engineering efforts for building natural language (NL)-based interfaces. To address this challenge, this paper introduces a dynamic prompt-based virtual assistant framework dubbed "BIMS-GPT" that integrates generative pre-trained transformer (GPT) technologies, supporting NL-based BIM search. To understand users' NL queries, extract relevant information from BIM databases, and deliver NL responses along with 3D visualizations, a dynamic prompt-based process was developed. In a case study, BIMS-GPT's functionality is demonstrated through a virtual assistant prototype for a hospital building. When evaluated with a BIM query dataset, the approach achieves accuracy rates of 99.5% for classifying NL queries with incorporating 2% of the data in prompts. This paper contributes to the advancement of effective and versatile virtual assistants for BIMs in the construction industry as it significantly enhances BIM accessibility while reducing the engineering and training data prerequisites for processing NL queries.	[Zheng, Junwen] Stanford Univ, Dept Civil & Environm Engn, Stanford, CA 94305 USA; [Fischer, Martin] Stanford Univ, Engn, Stanford, CA USA; [Fischer, Martin] Stanford Univ, Civil & Environm Engn, Stanford, CA USA	Stanford University; Stanford University; Stanford University	Zheng, JW (corresponding author), Stanford Univ, Dept Civil & Environm Engn, Stanford, CA 94305 USA.	junwenz@stanford.edu			Center for Integrated Facility Engineering (CIFE) at Stanford University [2022-10]	Center for Integrated Facility Engineering (CIFE) at Stanford University(Stanford University)	This work is financially supported by the Center for Integrated Facility Engineering (CIFE) at Stanford University (grants 2022-10) . The authors are grateful to Microdesk and Autodesk, Inc., for granting access to the hospital BIM and cloud credits. The first author extends his gratitude to Prof. Monica Lam, George Liu (Stanford University) ; Dr. Yi Wang (Autodesk) ; and Dr. Jeff Chan (Microdesk) for their invaluable intellectual companionship. The authors are grateful to the anonymous reviewers for their contribution to this work.	[Anonymous], 2021, ISO 16739-1:2018; [Anonymous], 2022, Genie-Server: The Home Server Version of Almond; [Anonymous], 2022, Revit software; [Anonymous], 2023, INTR CHATGPT; Ariono B, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12111912; Becerik-Gerber B, 2012, J CONSTR ENG M, V138, P431, DOI 10.1061/(ASCE)CO.1943-7862.0000433; Beetz J, 2009, AI EDAM, V23, P89, DOI 10.1017/S0890060409000122; Borrmann A., 2018, Building information modeling: technology foundations and industry practice, V1st, DOI [DOI 10.1007/978-3-319-92862-3_1, 10.1007/978-3-319-92862-3_1, 10.1007/978-3-319-92862-3, DOI 10.1007/978-3-319-92862-3]; Borrmann A, 2009, J COMPUT CIVIL ENG, V23, P34, DOI 10.1061/(ASCE)0887-3801(2009)23:1(34); Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryde D, 2013, INT J PROJ MANAG, V31, P971, DOI 10.1016/j.ijproman.2012.12.001; Chen KL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144771; Demian Peter, 2016, International Journal of 3-D Information Modeling, V5, P67, DOI 10.4018/IJ3DIM.2016010105; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding YX, 2022, AUTOMAT CONSTR, V136, DOI 10.1016/j.autcon.2022.104169; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Durdyev S, 2022, J BUILD ENG, V46, DOI 10.1016/j.jobe.2021.103736; Elghaish F, 2022, AUTOMAT CONSTR, V140, DOI 10.1016/j.autcon.2022.104320; Gao G, 2015, AUTOMAT CONSTR, V56, P14, DOI 10.1016/j.autcon.2015.04.006; Hosseini MR, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001492; Isikdag U., 2007, BRINGING ITC KNOWLED, P135; Kunz J, 2020, CONSTR MANAG ECON, V38, P355, DOI 10.1080/01446193.2020.1714068; Lin J.R.., 2013, P 30 CIB W78 INT, P280; Lin JR, 2016, COMPUT-AIDED CIV INF, V31, P18, DOI 10.1111/mice.12151; Lin YC, 2014, J CIV ENG MANAG, V20, P186, DOI 10.3846/13923730.2013.801887; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Love PED, 2013, AUTOMAT CONSTR, V35, P208, DOI 10.1016/j.autcon.2013.05.008; Mikolov T, 2013, COMPUTING RES REPOSI; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Ning Wang, 2021, J. Comput. Civ. Eng., P425, DOI DOI 10.1061/9780784483893.053; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Preidel Cornelius, 2017, Visualization in Engineering, V5, DOI 10.1186/s40327-017-0055-0; PULLUM GK, 1982, LINGUIST PHILOS, V4, P471, DOI 10.1007/BF00360802; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250; Sacks R., 2018, Handbook, A Guide to Building Information Modeling for Owners, Designers, Engineers, Contractors, and Facility Managers, DOI [10.1002/9781119287568, DOI 10.1002/9781119287568]; Saka AB, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2022.101869; Sangyun Shin, 2021, Proceedings of the 18th International Conference on Computing in Civil and Building Engineering. ICCCBE 2020. Lecture Notes in Civil Engineering (LNCE 98), P123, DOI 10.1007/978-3-030-51295-8_11; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Shin S, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002138; Shin S, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: COMPUTER APPLICATIONS, P992, DOI 10.1061/9780784482865.105; Ullah K., 2019, Emerald Reach Proceedings Series, P297, DOI DOI 10.1108/S2516-285320190000002052; Wan-Li Lee, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-016-0035-9; Wang N., 2021, EG ICE 2021 WORK INT, P228; Wang N., 2020, EG ICE 2020 WORKSH I, P275, DOI DOI 10.14279/DEPOSITONCE-9977; Wang N, 2022, AUTOMAT CONSTR, V141, DOI 10.1016/j.autcon.2022.104403; Wang N, 2022, J COMPUT CIVIL ENG, V36, DOI 10.1061/(ASCE)CP.1943-5487.0001019; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Wu SF, 2019, COMPUT IND, V108, P73, DOI 10.1016/j.compind.2019.02.016; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Xu X, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58445; Yang XJ, 2023, Arxiv, DOI arXiv:2302.08081; Zhoui H., 2019, 26 INT WORKSH INT CO; Zong MY, 2022, Arxiv, DOI arXiv:2212.00857; Zou Y, 2017, SAFETY SCI, V97, P88, DOI 10.1016/j.ssci.2015.12.027	56	3	3	44	63	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0926-5805	1872-7891		AUTOMAT CONSTR	Autom. Constr.	NOV	2023	155								105067	10.1016/j.autcon.2023.105067	http://dx.doi.org/10.1016/j.autcon.2023.105067		AUG 2023	24	Construction & Building Technology; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	W0PN8					2024-07-03	WOS:001088738700001
C	Burov, V; Soshnikov, D			IEEE	Burov, Vasiliy; Soshnikov, Dmitry			FidoNet and Generative AI: A New Approach to Museumification of Historical Content Resources	2023 8TH IEEE HISTORY OF ELECTROTECHNOLOGY CONFERENCE, HISTELCON	IEEE History of Telecommunications Conference		English	Proceedings Paper	8th IEEE History of Electrotechnology Conference (IEEE HISTELCON)	SEP 07-09, 2023	Florence, ITALY	IEEE, Hist Comm, IEEE Italy Sect, Life Members Affin Grp, Sci & Techn Fdn Florence, IEEE Reg 8, Univ Florence, Soc Italiana Elettronica, Soc Italiana Elettromagnetismo		FidoNet; echos; echomail; newsgroups; content representation; user generated content; UCG; machine learning; large language model; LLM; generative AI; artificial intelligence; ChatGPT; GPT model; virtual museum; cybernetic immortality		This report considers the problem of visual representation of historical content resources based on user-generated content for museumification of the most important information resources in the history of digital networks development. The paper proposes an approach based on generative AI and shows its implementation in relation to FidoNet.	[Burov, Vasiliy] Estonto Lab, Yerevan, Armenia; [Soshnikov, Dmitry] Estonto Lab, Astana, Kazakhstan		Burov, V (corresponding author), Estonto Lab, Yerevan, Armenia.	vasiliy.burov@gmail.com; dmitri@soshnikov.com						BUSH R, 1993, COMMUN ACM, V36, P31, DOI 10.1145/163381.163383; Butow Eric E., 1996, CONTENT ANAL RULE EN; Cignoni Giovanni Antonio, 2021, 2021 7 IEEE HIST ELE; Hauben M.Hauben., 1997, Netizens: On the History and Impact of Usenet and the Internet; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Shliazhko O., 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; TURCHIN V, 1990, KYBERNETES, V19, P63, DOI 10.1108/eb005843; Wagner Wynn., 1985, History of Echomail	9	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2770-8349		979-8-3503-3464-7	IEEE History of Tele			2023							129	132		10.1109/HISTELCON56357.2023.10365937	http://dx.doi.org/10.1109/HISTELCON56357.2023.10365937			4	History & Philosophy Of Science	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	History & Philosophy of Science	BW5OI					2024-07-03	WOS:001164186900032
J	Delsoz, M; Madadi, Y; Raja, H; Munir, WM; Tamm, B; Mehravaran, S; Soleimani, M; Djalilian, A; Yousefi, S				Delsoz, Mohammad; Madadi, Yeganeh; Raja, Hina; Munir, Wuqaas M.; Tamm, Brendan; Mehravaran, Shiva; Soleimani, Mohammad; Djalilian, Ali; Yousefi, Siamak			Performance of ChatGPT in Diagnosis of Corneal Eye Diseases	CORNEA			English	Article						ChatGPT; large language models; generative pretrained transformer; artificial intelligence; corneal eye diseases; provisional diagnosis	DIABETIC-RETINOPATHY	Purpose:The aim of this study was to assess the capabilities of ChatGPT-4.0 and ChatGPT-3.5 for diagnosing corneal eye diseases based on case reports and compare with human experts.Methods:We randomly selected 20 cases of corneal diseases including corneal infections, dystrophies, and degenerations from a publicly accessible online database from the University of Iowa. We then input the text of each case description into ChatGPT-4.0 and ChatGPT-3.5 and asked for a provisional diagnosis. We finally evaluated the responses based on the correct diagnoses, compared them with the diagnoses made by 3 corneal specialists (human experts), and evaluated interobserver agreements.Results:The provisional diagnosis accuracy based on ChatGPT-4.0 was 85% (17 correct of 20 cases), whereas the accuracy of ChatGPT-3.5 was 60% (12 correct cases of 20). The accuracy of 3 corneal specialists compared with ChatGPT-4.0 and ChatGPT-3.5 was 100% (20 cases, P = 0.23, P = 0.0033), 90% (18 cases, P = 0.99, P = 0.6), and 90% (18 cases, P = 0.99, P = 0.6), respectively. The interobserver agreement between ChatGPT-4.0 and ChatGPT-3.5 was 65% (13 cases), whereas the interobserver agreement between ChatGPT-4.0 and 3 corneal specialists was 85% (17 cases), 80% (16 cases), and 75% (15 cases), respectively. However, the interobserver agreement between ChatGPT-3.5 and each of 3 corneal specialists was 60% (12 cases).Conclusions:The accuracy of ChatGPT-4.0 in diagnosing patients with various corneal conditions was markedly improved than ChatGPT-3.5 and promising for potential clinical integration. A balanced approach that combines artificial intelligence-generated insights with clinical expertise holds a key role for unveiling its full potential in eye care.	[Delsoz, Mohammad; Madadi, Yeganeh; Raja, Hina; Yousefi, Siamak] Univ Tennessee, Hamilton Eye Inst, Dept Ophthalmol, Hlth Sci Ctr, Memphis, TN USA; [Munir, Wuqaas M.; Tamm, Brendan] Univ Maryland, Sch Med, Dept Ophthalmol & Visual Sci, Baltimore, MD USA; [Mehravaran, Shiva] Morgan State Univ, Sch Comp Math & Nat Sci, Dept Biol, Baltimore, MD USA; [Soleimani, Mohammad; Djalilian, Ali] Univ Illinois, Dept Ophthalmol & Visual Sci, Chicago, IL USA; [Soleimani, Mohammad] Univ Tehran Med Sci, Farabi Eye Hosp, Eye Res Ctr, Tehran, Iran; [Yousefi, Siamak] Univ Tennessee, Hlth Sci Ctr, Dept Genet Genom & Informat, Memphis, TN USA; [Yousefi, Siamak] Univ Tennessee, Hamilton Eye Inst, Dept Ophthalmol, Dept Genet Genom & Informat,Hlth Sci Ctr, 930 Madison Ave,Suite 471, Memphis, TN 38163 USA	University of Tennessee System; University of Tennessee Health Science Center; University System of Maryland; University of Maryland Baltimore; Morgan State University; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; Tehran University of Medical Sciences; University of Tennessee System; University of Tennessee Health Science Center; University of Tennessee System; University of Tennessee Health Science Center	Yousefi, S (corresponding author), Univ Tennessee, Hamilton Eye Inst, Dept Ophthalmol, Dept Genet Genom & Informat,Hlth Sci Ctr, 930 Madison Ave,Suite 471, Memphis, TN 38163 USA.	Delsoz_mohammad@yahoo.com; yeganeh.madadi@gmail.com; hinaraja65@gmail.com; wmunir@som.umaryland.edu; btamm@som.umaryland.edu; shiva.mehravaran@morgan.edu; msolei2@uic.edu; adjalili@uic.edu; siamak.yousefi@uthsc.edu	Madadi, Yeganeh/JUV-2768-2023	Delsoz, Mohammad/0000-0001-5638-2034; Yousefi, Siamak/0000-0001-8633-5730	NIH [R01EY033005, R21EY031725]; Research to Prevent Blindness, New York; Hamilton Eye Institute	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Research to Prevent Blindness, New York(Research to Prevent Blindness (RPB)); Hamilton Eye Institute	Supported by NIH Grants R01EY033005 (S.Y.) and R21EY031725 (S.Y.); grants from Research to Prevent Blindness, New York (S.Y.); and supports from the Hamilton Eye Institute (S.Y.). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Abdelmotaal H, 2023, OCUL SURF, V28, P90, DOI 10.1016/j.jtos.2023.01.005; Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964; Al-Timemy AH, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101689; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Cleveland Clinic, Corneal Disease; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; Gelston CD, 2019, J EDUC EVAL HEALTH P, V16, DOI 10.3352/jeehp.2019.16.25; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kamiya K, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2019-031313; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu PR, 2021, CURR MED SCI, V41, P1105, DOI 10.1007/s11596-021-2474-3; Lubbad M., 2023, GPT-4 Parameters: Unlimited Guide NLP's Game-Changer; Madadi Y., 2023, medRxiv; Matos PAW, 2023, SEMIN OPHTHALMOL, V38, P226, DOI 10.1080/08820538.2022.2139625; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; OpenAI, 2022, Introducing chatgpt; Ortiz S., 2023, ZDNET Tech; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Ramponi M., 2022, AssemblyAI; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Solomon SD, 2022, OPHTHALMOLOGY, V129, pE114, DOI 10.1016/j.ophtha.2022.07.012; Thakur A, 2020, OPHTHALMOL GLAUCOMA, V3, P262, DOI 10.1016/j.ogla.2020.04.012; Ting DSJ, 2021, BRIT J OPHTHALMOL, V105, P158, DOI 10.1136/bjophthalmol-2019-315651; Yang AY, 2018, YALE J BIOL MED, V91, P13; Yousefi S, 2023, J OPHTHAL VIS RES, V18, P97, DOI 10.18502/jovr.v18i1.12730; Yousefi S, 2020, OPHTHALMOLOGY, V127, P1170, DOI 10.1016/j.ophtha.2020.03.008; Yousefi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205998	33	3	3	5	5	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0277-3740	1536-4798		CORNEA	Cornea	MAY	2024	43	5					664	670		10.1097/ICO.0000000000003492	http://dx.doi.org/10.1097/ICO.0000000000003492			7	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	SR7H7	38391243	Green Published, Green Submitted			2024-07-03	WOS:001236238000015
C	Rajbhoj, A; Somase, A; Kulkarni, P; Kulkarni, V		Chakrabarti, SK; Rastogi, A; Ghosh, S; Komondoor, R; Medicherla, RK; Kumar, L; Godboley, S		Rajbhoj, Asha; Somase, Akanksha; Kulkarni, Piyush; Kulkarni, Vinay			Accelerating Software Development Using Generative AI: ChatGPT Case Study	PROCEEDINGS OF THE 17TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, ISEC 2024			English	Proceedings Paper	17th Innovations in Software Engineering Conference (ISEC)	FEB 22-24, 2024	IIITB Bangalore, Bangalore, INDIA	ACM India SIGSOFT Chapter, ACM In Cooperat, IIITB Bangalore, Ctr Technol Res & Innovat Digital Governance, TCS Res, Microsoft, IBM, ABB, Google, ISoft, ACM Chapter Conference	IIITB Bangalore	AI in SDLC; Large Language Models; Generative AI; ChatGPT; SDLC automation; Automated Software Development		The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.	[Rajbhoj, Asha; Somase, Akanksha; Kulkarni, Piyush; Kulkarni, Vinay] Tata Consultancy Serv, TCS Res, Pune, Maharashtra, India	Tata Sons; Tata Consultancy Services Limited (TCS)	Rajbhoj, A (corresponding author), Tata Consultancy Serv, TCS Res, Pune, Maharashtra, India.	asha.rajbhoj@tcs.com; akanksha.somase@tcs.com; piyush.kulkarni3@tcs.com; vinay.vkulkarni@tcs.com		Somase, Akanksha/0009-0000-5670-2069; Kulkarni, Vinay/0000-0003-1570-1339				Ahmad A, 2023, 27TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, EASE 2023, P279, DOI 10.1145/3593434.3593468; Aljanabi M., 2023, Mesopotamian Journal of Cyber Security, V2023, P16, DOI [10.58496/MJCS/2023/003, DOI 10.58496/MJCS/2023/003]; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Friedman N., 2021, Introducing github copilot: your ai pair programmer; Galanos T, 2023, Arxiv, DOI [arXiv:2303.07519, DOI 10.48550/ARXIV.2303.07519, 10.48550/arXiv.2303.07519]; Halstead M. H., 1977, Elements of Software Science (Operating and programming systems series; Liu Aiwei, 2023, arXiv; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; OpenAI, 2023, Introducing chatgpt; Pilipiszyn A., 2021, Gpt-3 powers the next generation of apps; Pothukuchi Ameya S., 2023, International Journal of Creative Research Thoughts, V11; Pudari R, 2023, Arxiv, DOI arXiv:2303.04142; Rajbhoj Asha, 2023, P 31 IEEE INT REQUIR, P180, DOI [10.1109/RE57278.2023.00026, DOI 10.1109/RE57278.2023.00026]; Rajkumar N., arXiv, DOI DOI 10.48550/ARXIV.2204.00498; Reifer DJ, 2000, IEEE SOFTWARE, V17, P57, DOI 10.1109/52.895169; Ruan K, 2023, Intern Req Engg Work, P170, DOI 10.1109/REW57809.2023.00035; Talasbek Arailym L, 2023, Suleyman Demirel University Bulletin: Natural and Technical Sciences, V62, P5; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Whittle J, 2014, IEEE SOFTWARE, V31, P79, DOI 10.1109/MS.2013.65; Yetistiren B, 2022, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, PROMISE 2022, P62, DOI 10.1145/3558489.3559072; Zaremba W., 2021, Openai codex; Zhang JZ, 2023, Arxiv, DOI arXiv:2304.12562	27	0	0	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1767-3				2024									5	10.1145/3641399.3641403	http://dx.doi.org/10.1145/3641399.3641403			11	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6ID					2024-07-03	WOS:001174625700005
C	Denny, P; Becker, BA; Leinonen, J; Prather, J			ACM	Denny, Paul; Becker, Brett A.; Leinonen, Juho; Prather, James			Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?	PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1			English	Proceedings Paper	28th Annual Conference on Innovation and Technology in Computer Science Education (ITiCSE)	JUL 08-12, 2023	Univ Turku, Turku, FINLAND	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ, ACM Europe Council, Informat Europe	Univ Turku	AI; artificial intelligence; ChatGPT; computer programming; computer science education; computing education; Copilot; deep learning; generative AI; large language models; LLM; machine learning		Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text. However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance. Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges. In this talk, we begin by discussing several concrete and researchbacked opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longerterm, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these *Randomly ordered by the spin of a roulette wheel, the results of which were eventually confirmed as valid, reliable and replicable by ChatGPT Plus on the fourth attempt (GPT4 March 23, 2023 version). No other artificial intelligence was used in the authoring of this document. discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fastchanging landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.	[Denny, Paul; Leinonen, Juho] Univ Auckland, Auckland, New Zealand; [Becker, Brett A.] Univ Coll Dublin, Dublin, Ireland; [Prather, James] Abilene Christian Univ, Abilene, TX USA	University of Auckland; University College Dublin; Abilene Christian University	Denny, P (corresponding author), Univ Auckland, Auckland, New Zealand.	paul@cs.auckland.ac.nz; brett.becker@ucd.ie; juho.leinonen@auckland.ac.nz; james.prather@acu.edu	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449; Denny, Paul/0000-0002-5150-9806; Prather, James/0000-0003-2807-6042				Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Becker BA, 2021, COMMUN ACM, V64, P27, DOI 10.1145/3469115; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Denny Paul, 2021, ACE '21:Proceedings of the 23rd Australasian Computing Education Conference, P88, DOI 10.1145/3441636.3442309; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny P, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P146, DOI 10.1145/3059009.3059033; Denny P, 2018, ITICSE'18: PROCEEDINGS OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P4, DOI 10.1145/3197091.3197141; Denny P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173885; Denny Paul, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445696, 10.1145/3411764, DOI 10.1145/3411764]; Denny Paul, 2020, P 2020 ACM C INNOVAT, P480; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Prather James, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P2, DOI 10.1145/3372782.3406263; Prather J, 2023, Arxiv, DOI arXiv:2304.02491; Prather J, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P531, DOI 10.1145/3287324.3287374; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957	18	5	5	15	33	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0138-2				2023							3	4		10.1145/3587102.3588773	http://dx.doi.org/10.1145/3587102.3588773			2	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BV5PJ					2024-07-03	WOS:001051691300002
J	Li, YJ; Shi, JJ; Zhang, Z				Li, Youjia; Shi, Jianjun; Zhang, Zheng			An Approach for Rapid Source Code Development Based on ChatGPT and Prompt Engineering	IEEE ACCESS			English	Article						Codes; Chatbots; Natural languages; Source coding; Software; Task analysis; Computational modeling; Software development management; Large language models; ChatGPT; prompt engineering; code generation; software development; large language models		Code generation stands as a powerful technique in modern software development, improving development efficiency, reducing errors, and fostering standardization and consistency. Recently, ChatGPT has exhibited immense potential in automatic code generation. However, existing researches on code generation lack guidance for practical software development process. In this study, we utilized ChatGPT to develop a web-based code generation platform consisting of key components: User Interface, Prompt Builder, and Backend Service. Specifically, Prompt Builder dynamically generated comprehensive prompts to enhance model generation performance. We conducted experiments on 2 datasets to evaluate the performance of code generation in our approach. through 8 widely used metrics. The results demonstrate that (1) our Prompt Builder is effective, resulting in a 65.06% improvement in the exact match (EM), a 38.45% improvement in Bilingual Evaluation Understudy (BLEU), a 15.70% improvement in CodeBLEU, and a 50.64% improvement in Pass@1. (2) In real development scenarios, 98.5% of test cases can be validated through manual validation, highlighting the genuine assistance provided by the ChatGPT-based code generation approach.	[Li, Youjia; Shi, Jianjun] Purple Mt Labs, Nanjing 211111, Jiangsu, Peoples R China; [Zhang, Zheng] Informat Engn Univ, State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China	PLA Information Engineering University	Zhang, Z (corresponding author), Informat Engn Univ, State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Henan, Peoples R China.	ponyzhang@126.com			Science and Technology Project of the State Grid Corporation of China	Science and Technology Project of the State Grid Corporation of China	No Statement Available	Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; Al-Hawawreh M, 2023, CLUSTER COMPUT, V26, P3421, DOI 10.1007/s10586-023-04124-5; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Asaduzzaman M, 2014, PROC IEEE INT CONF S, P71, DOI 10.1109/ICSME.2014.29; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Chintagunta B, 2021, P 6 MACHINE LEARNING, P354; Chiu Ke-Li, 2021, arXiv; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao SR, 2023, Arxiv, DOI [arXiv:2307.09793, 10.48550/arXiv.2307.09793]; Guo L, 2022, J COMPUT ASSIST LEAR, V38, P811, DOI 10.1111/jcal.12650; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Jackson I, 2022, Arxiv, DOI arXiv:2202.12107; Li J, 2023, Arxiv, DOI arXiv:2302.06144; Li Z, 2020, PROCEDIA COMPUT SCI, V166, P279, DOI 10.1016/j.procs.2020.02.099; Liu Y, 2024, Arxiv, DOI arXiv:2302.09587; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Narasimhan A, 2021, Arxiv, DOI arXiv:2108.10168; OpenAI, 2023, Gpt-4 is openai's most advanced system, producing safer and more useful responses; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Peng M., 2023, GPT-3.5 Turbo Fine-Tuning and API Updates; Phan Long N., 2021, Cotext: Multi-task learning with code-text transformer; Prenner JA, 2021, Arxiv, DOI [arXiv:2111.03922, DOI 10.48550/ARXIV.2111.03922]; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Remountakis M, 2023, INFORMATION, V14, DOI 10.3390/info14090504; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984; [杨博 Yang Bo], 2020, [软件学报, Journal of Software], V31, P1435; Yin PC, 2018, Arxiv, DOI arXiv:1810.02720; Zan DG, 2022, Arxiv, DOI arXiv:2206.06888	37	0	0	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						53074	53087		10.1109/ACCESS.2024.3385682	http://dx.doi.org/10.1109/ACCESS.2024.3385682			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	OF1F1		gold			2024-07-03	WOS:001205752200001
J	Kaplan, DM; Palitsky, R; Alvarez, SJA; Pozzo, NS; Greenleaf, N; Atkinson, CA; Lam, WA				Kaplan, Deanna M.; Palitsky, Roman; Alvarez, Santiago J. Arconada; Pozzo, Nicole S.; Greenleaf, N.; Atkinson, Ciara A.; Lam, Wilbur A.			What's in a Name? Experimental Evidence of Gender Bias in Recommendation Letters Generated by ChatGPT	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						chatbot; generative artificial intelligence; generative AI; gender bias; large language models; letters of recommendation; recommendation letter; language model; chatbots; artificial intelligence; AI; gender-based language; human written; real-world; scenario	STEREOTYPES; FEMALE	Background: Artificial intelligence chatbots such as ChatGPT (OpenAI) have garnered excitement about their potential for delegating writing tasks ordinarily performed by humans. Many of these tasks (eg, writing recommendation letters) have social and professional ramifications, making the potential social biases in ChatGPT's underlying language model a serious concern. Objective: Three preregistered studies used the text analysis program Linguistic Inquiry and Word Count to investigate gender bias in recommendation letters written by ChatGPT in human -use sessions (N=1400 total letters). Methods: We conducted analyses using 22 existing Linguistic Inquiry and Word Count dictionaries, as well as 6 newly created dictionaries based on systematic reviews of gender bias in recommendation letters, to compare recommendation letters generated for the 200 most historically popular "male" and "female" names in the United States. Study 1 used 3 different letter -writing prompts intended to accentuate professional accomplishments associated with male stereotypes, female stereotypes, or neither. Study 2 examined whether lengthening each of the 3 prompts while holding the between -prompt word count constant modified the extent of bias. Study 3 examined the variability within letters generated for the same name and prompts. We hypothesized that when prompted with gender -stereotyped professional accomplishments, ChatGPT would evidence gender -based language differences replicating those found in systematic reviews of human -written recommendation letters (eg, more affiliative, social, and communal language for female names; more agentic and skill -based language for male names). Results: Significant differences in language between letters generated for female versus male names were observed across all prompts, including the prompt hypothesized to be neutral, and across nearly all language categories tested. Historically female names received significantly more social referents (5/6, 83% of prompts), communal or doubt -raising language (4/6, 67% of prompts), personal pronouns (4/6, 67% of prompts), and clout language (5/6, 83% of prompts). Contradicting the study hypotheses, some gender differences (eg, achievement language and agentic language) were significant in both the hypothesized and nonhypothesized directions, depending on the prompt. Heteroscedasticity between male and female names was observed in multiple linguistic categories, with greater variance for historically female names than for historically male names. Conclusions: ChatGPT reproduces many gender -based language biases that have been reliably identified in investigations of human -written reference letters, although these differences vary across prompts and language categories. Caution should be taken when using ChatGPT for tasks that have social consequences, such as reference letter writing. The methods developed in this study may be useful for ongoing bias testing among progressive generations of chatbots across a range of real -world scenarios. Trial Registration: OSF Registries osf.io/ztv96; https://osf.io/ztv96	[Kaplan, Deanna M.; Pozzo, Nicole S.] Emory Univ, Sch Med, Dept Family & Prevent Med, Atlanta, GA 30329 USA; [Palitsky, Roman] Emory Univ, Woodruff Hlth Sci Ctr, Emory Spiritual Hlth, Atlanta, GA 30329 USA; [Alvarez, Santiago J. Arconada; Greenleaf, N.] Emory Univ, Sch Med, Atlanta, GA USA; [Atkinson, Ciara A.] Univ Arizona, Dept Campus Recreat, Tucson, AZ USA; [Lam, Wilbur A.] Georgia Inst Technol, Wallace Coulter Dept Biomed Engn H, Atlanta, GA USA; [Lam, Wilbur A.] Emory Univ, Atlanta, GA USA; [Kaplan, Deanna M.] Emory Univ, Sch Med, Dept Family & Prevent Med, Adm Off, Wesley Woods Campus,1841 Clifton Rd NE,5th Floor, Atlanta, GA 30329 USA	Emory University; Emory University; Emory University; University of Arizona; University System of Georgia; Georgia Institute of Technology; Emory University; Emory University	Kaplan, DM (corresponding author), Emory Univ, Sch Med, Dept Family & Prevent Med, Adm Off, Wesley Woods Campus,1841 Clifton Rd NE,5th Floor, Atlanta, GA 30329 USA.	deanna.m.kaplan@emory.edu		Lam, Wilbur/0000-0002-0325-7990; Arconada Alvarez, Santiago Jose/0000-0003-0737-6679; Palitsky, Roman/0000-0002-0415-6411; Greenleaf, Morgan/0000-0003-1569-5696				[Anonymous], TOP NAMES LAST 100 Y; [Anonymous], 2010, Avoiding unintended gender bias in letters of recommendation; [Anonymous], 2023, Diversity and STEM: Women, Minorities, and Persons with Disabilities; [Anonymous], 2023, MediumJan 16; [Anonymous], Avoiding gender bias in reference writing; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Bogost Ian., 2023, Atlantic; Boyd R. L., 2022, The Development and Psychometric Properties of LIWC-22, DOI DOI 10.13140/RG.2.2.23890.43205; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chaloner K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P25; Chaturvedi O., 2023, TechstoryApr 27; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Connor RA, 2016, The Cambridge Handbook of the Psychology of Prejudice; Dolci Tommaso, 2022, 2022 IEEE Eighth International Conference on Big Data Computing Service and Applications (BigDataService), P175, DOI 10.1109/BigDataService55688.2022.00036; Dutt K, 2016, NAT GEOSCI, V9, P805, DOI [10.1038/NGEO2819, 10.1038/ngeo2819]; Eaton AA, 2020, SEX ROLES, V82, P127, DOI 10.1007/s11199-019-01052-w; England P, 2020, P NATL ACAD SCI USA, V117, P6990, DOI 10.1073/pnas.1918891117; Filippou P, 2019, UROLOGY, V134, P56, DOI 10.1016/j.urology.2019.05.065; Girgis MY, 2023, J SURG EDUC, V80, P127, DOI 10.1016/j.jsurg.2022.08.021; Glick P, 1996, J PERS SOC PSYCHOL, V70, P491, DOI 10.1037/0022-3514.70.3.491; Grimm LJ, 2020, J AM COLL RADIOL, V17, P64, DOI 10.1016/j.jacr.2019.08.008; Hire and retain a diverse team, Textio; Hoffman A, 2020, AM J SURG, V219, P932, DOI 10.1016/j.amjsurg.2019.08.005; Jordan KN, 2019, P NATL ACAD SCI USA, V116, P3476, DOI 10.1073/pnas.1811987116; Kacewicz E, 2014, J LANG SOC PSYCHOL, V33, P125, DOI 10.1177/0261927X13502654; Kaplan DM, 2023, Open Science FrameworkJun 12; Khan S, 2023, POSTGRAD MED J, V99, P272, DOI 10.1136/postgradmedj-2021-140045; Koch AJ, 2015, J APPL PSYCHOL, V100, P128, DOI 10.1037/a0036734; Kretchmar J., 2016, Professional School Counseling, V20, P1096, DOI [DOI 10.5330/1096-2409-20.1.102, 10.5330/10962409-20.1.102, DOI 10.5330/10962409-20.1.102]; Madera JM, 2019, J BUS PSYCHOL, V34, P287, DOI 10.1007/s10869-018-9541-1; Marwan Y, 2017, J SURG EDUC, V74, P762, DOI 10.1016/j.jsurg.2017.01.006; Moss-Racusin CA, 2012, P NATL ACAD SCI USA, V109, P16474, DOI 10.1073/pnas.1211286109; Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668; Schmader T, 2007, SEX ROLES, V57, P509, DOI 10.1007/s11199-007-9291-4; Trix F, 2003, DISCOURSE SOC, V14, P191, DOI 10.1177/0957926503014002277; Turrentine FE, 2019, J AM COLL SURGEONS, V228, P356, DOI 10.1016/j.jamcollsurg.2018.12.020; Vayansky I, 2020, INFORM SYST, V94, DOI 10.1016/j.is.2020.101582; Zwebner Y, 2017, J PERS SOC PSYCHOL, V112, P527, DOI 10.1037/pspa0000076	39	1	1	12	12	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAR 5	2024	26								e51837	10.2196/51837	http://dx.doi.org/10.2196/51837			14	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	KY0E9	38441945	gold			2024-07-03	WOS:001183401600003
J	Takagi, S; Koda, M; Watari, T				Takagi, Soshi; Koda, Masahide; Watari, Takashi			The Performance of ChatGPT-4V in Interpreting Images and Tables in the Japanese Medical Licensing Exam	JMIR MEDICAL EDUCATION			English	Editorial Material						ChatGPT; medical licensing examination; generative artificial intelligence; medical education; large language model; images; tables; artificial intelligence; AI; Japanese; reliability; medical application; medical applications; diagnostic; diagnostics; online data; web-based data			[Takagi, Soshi] Shimane Univ, Fac Med, Izumo, Japan; [Koda, Masahide] Okayama Univ, Grad Sch Med Dent & Pharmaceut Sci, Colearning Community Healthcare Reinnovat Off, Okayama, Japan; [Watari, Takashi] Shimane Univ Hosp, Gen Med Ctr, 89-1 Enya, Izumo 6938501, Japan; [Watari, Takashi] Kyoto Univ Hosp, Integrated Clin Educ Ctr, Kyoto, Japan	Shimane University; Okayama University; Shimane University; Kyoto University	Watari, T (corresponding author), Shimane Univ Hosp, Gen Med Ctr, 89-1 Enya, Izumo 6938501, Japan.	wataritari@gmail.com		Koda, Masahide/0000-0002-4652-6994; Takagi, Soshi/0009-0004-3211-1626				[Anonymous], 2023, Gpt-4v(ision) system card; [Anonymous], 2023, Searching questions Article in Japanese.; [Anonymous], 2023, Announcement of successful passage of the 117th National Medical Examination; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Introducing ChatGPT, 2022, OpenAI.; Liu FX, 2024, Arxiv, DOI arXiv:2306.14565; Shi YX, 2023, Arxiv, DOI arXiv:2310.16809; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Wu Y, 2023, Arxiv, DOI arXiv:2310.16534; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	10	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e54283	10.2196/54283	http://dx.doi.org/10.2196/54283			4	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	TL4W1	38787024	gold			2024-07-03	WOS:001241414100001
J	Hsu, HY; Hsu, KC; Hou, SY; Wu, CL; Hsieh, YW; Cheng, YD				Hsu, Hsing-Yu; Hsu, Kai-Cheng; Hou, Shih-Yen; Wu, Ching-Lung; Hsieh, Yow-Wen; Cheng, Yih-Dih			Examining Real-World Medication Consultations and Drug-Herb Interactions: ChatGPT Performance Evaluation	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; large language model; natural language processing; real-world medication consultation questions; NLP; drug-herb interactions; pharmacist; LLM; language models; chat generative pre-trained transformer		Background: Since OpenAI released ChatGPT, with its strong capability in handling natural tasks and its user-friendly interface, it has garnered significant attention. Objective: A prospective analysis is required to evaluate the accuracy and appropriateness of medication consultation responses generated by ChatGPT. Methods: A prospective cross-sectional study was conducted by the pharmacy department of a medical center in Taiwan. The test data set comprised retrospective medication consultation questions collected from February 1, 2023, to February 28, 2023, along with common questions about drug-herb interactions. Two distinct sets of questions were tested: real-world medication consultation questions and common questions about interactions between traditional Chinese and Western medicines. We used the conventional double-review mechanism. The appropriateness of each response from ChatGPT was assessed by 2 experienced pharmacists. In the event of a discrepancy between the assessments, a third pharmacist stepped in to make the final decision. Results: Of 293 real-world medication consultation questions, a random selection of 80 was used to evaluate ChatGPT's performance. ChatGPT exhibited a higher appropriateness rate in responding to public medication consultation questions compared to those asked by health care providers in a hospital setting (31/51, 61% vs 20/51, 39%; P=.01). Conclusions: The findings from this study suggest that ChatGPT could potentially be used for answering basic medication consultation questions. Our analysis of the erroneous information allowed us to identify potential medical risks associated with certain questions; this problem deserves our close attention.	[Hsu, Hsing-Yu; Hsieh, Yow-Wen; Cheng, Yih-Dih] China Med Univ Hosp, Dept Pharm, 2 Yuh Der Rd, Taichung 404327, Taiwan; [Hsu, Hsing-Yu] Natl Taiwan Univ, Grad Inst Clin Pharm, Coll Med, Taipei, Taiwan; [Hsu, Kai-Cheng; Hou, Shih-Yen] China Med Univ Hosp, Artificial Intelligence Ctr, Taichung, Taiwan; [Hsu, Kai-Cheng] China Med Univ, Dept Med, Taichung, Taiwan; [Wu, Ching-Lung; Hsieh, Yow-Wen; Cheng, Yih-Dih] China Med Univ, Sch Pharm, Coll Pharm, Taichung, Taiwan	China Medical University Taiwan; China Medical University Hospital - Taiwan; National Taiwan University; China Medical University Taiwan; China Medical University Hospital - Taiwan; China Medical University Taiwan; China Medical University Taiwan	Hsieh, YW (corresponding author), China Med Univ Hosp, Dept Pharm, 2 Yuh Der Rd, Taichung 404327, Taiwan.	yowenhsieh@gmail.com		Cheng, Yih-Dih/0000-0003-1542-6760; Hsu, Hsing-Yu/0000-0003-4424-9476; Hsieh, Yow-Wen/0000-0002-0523-3482				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], Ceftriaxone prescribing information; [Anonymous], CHATGPT OPT LANG MOD; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; CNBC, Google is asking employees to test potential ChatGPT competitors, including a chatbot called 'Apprentice Bard'; Cuschieri S, 2019, SAUDI J ANAESTH, V13, P31, DOI 10.4103/sja.SJA_543_18; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Khullar D, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.10309; Kim SG, 2023, MAX PLAST RECONSTR S, V45, DOI 10.1186/s40902-023-00381-x; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.02.23285399; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Vaswani A, 2017, ADV NEUR IN, V30; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	24	6	6	4	5	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e48433	10.2196/48433	http://dx.doi.org/10.2196/48433			7	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	GX1M6	37561097	gold, Green Published			2024-07-03	WOS:001155880300006
J	Bartal, A; Jagodnik, KM; Chan, SJ; Dekel, S				Bartal, Alon; Jagodnik, Kathleen M.; Chan, Sabrina J.; Dekel, Sharon			AI and narrative embeddings detect PTSD following childbirth via birth stories	SCIENTIFIC REPORTS			English	Article						Birth narratives; Birth trauma; ChatGPT; Childbirth-related post-traumatic stress disorder (CB-PTSD); Maternal mental health; Natural language processing (NLP); Postpartum PTSD; Pre-trained large language model (PLM)	POSTTRAUMATIC-STRESS-DISORDER; CARE; CHATGPT; MEMORY; PCL-5	Free-text analysis using machine learning (ML)-based natural language processing (NLP) shows promise for diagnosing psychiatric conditions. Chat Generative Pre-trained Transformer (ChatGPT) has demonstrated preliminary initial feasibility for this purpose; however, whether it can accurately assess mental illness remains to be determined. This study evaluates the effectiveness of ChatGPT and the text-embedding-ada-002 (ADA) model in detecting post-traumatic stress disorder following childbirth (CB-PTSD), a maternal postpartum mental illness affecting millions of women annually, with no standard screening protocol. Using a sample of 1295 women who gave birth in the last six months and were 18+ years old, recruited through hospital announcements, social media, and professional organizations, we explore ChatGPT's and ADA's potential to screen for CB-PTSD by analyzing maternal childbirth narratives. The PTSD Checklist for DSM-5 (PCL-5; cutoff 31) was used to assess CB-PTSD. By developing an ML model that utilizes numerical vector representation of the ADA model, we identify CB-PTSD via narrative classification. Our model outperformed (F1 score: 0.81) ChatGPT and six previously published large text-embedding models trained on mental health or clinical domains data, suggesting that the ADA model can be harnessed to identify CB-PTSD. Our modeling approach could be generalized to assess other mental health disorders.	[Bartal, Alon; Jagodnik, Kathleen M.] Bar Ilan Univ, Sch Business Adm, IL-5290002 Ramat Gan, Israel; [Jagodnik, Kathleen M.; Chan, Sabrina J.; Dekel, Sharon] Massachusetts Gen Hosp, Dept Psychiat, Boston, MA 02114 USA; [Jagodnik, Kathleen M.; Dekel, Sharon] Harvard Med Sch, Dept Psychiat, Boston, MA 02115 USA	Bar Ilan University; Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School	Dekel, S (corresponding author), Massachusetts Gen Hosp, Dept Psychiat, Boston, MA 02114 USA.; Dekel, S (corresponding author), Harvard Med Sch, Dept Psychiat, Boston, MA 02115 USA.	sdekel@mgh.harvard.edu			Data Science Institute (DSI) at Bar-Ilan University; Data Science Institute (DSI) at Bar-Ilan University - Mortimer B. Zuckerman STEM Leadership Program postdoctoral fellowship [R01HD108619, R21HD109546, R21HD100817]; National Institutes of Health (NIH) National Institute of Child Health and Human Development (NICHD)	Data Science Institute (DSI) at Bar-Ilan University; Data Science Institute (DSI) at Bar-Ilan University - Mortimer B. Zuckerman STEM Leadership Program postdoctoral fellowship; National Institutes of Health (NIH) National Institute of Child Health and Human Development (NICHD)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD))	A.B. was supported by the Data Science Institute (DSI) at Bar-Ilan University. K.M.J. was funded by a Mortimer B. Zuckerman STEM Leadership Program postdoctoral fellowship. S.D. was funded by National Institutes of Health (NIH) National Institute of Child Health and Human Development (NICHD) grants R01HD108619, R21HD109546, and R21HD100817.	Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Alvarez-Conrad J, 2001, APPL COGNITIVE PSYCH, V15, pS159, DOI 10.1002/acp.839; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; Anokye R, 2018, ANN GEN PSYCHIATR, V17, DOI 10.1186/s12991-018-0188-0; Arora I. H., 2024, Am. J. Obstetr. Gynecol., DOI [10.1016/j.ajog.2023.11.1229, DOI 10.1016/J.AJOG.2023.11.1229]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bartal A, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2022.100834; Bartal A, 2020, BIOINFORMATICS, V36, P3932, DOI 10.1093/bioinformatics/btaa240; Belser C. A., 2023, Comparison of natural language processing models for depression detection in chatbot dialogues; Blevins CA, 2015, J TRAUMA STRESS, V28, P489, DOI 10.1002/jts.22059; Booker JA, 2018, J TRAUMA STRESS, V31, P273, DOI 10.1002/jts.22271; Boorman RJ, 2014, MIDWIFERY, V30, P255, DOI 10.1016/j.midw.2013.03.001; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chan SJ, 2022, AM J OBSTET GYNECOL, V227, P656, DOI 10.1016/j.ajog.2022.05.051; Chan SJ, 2020, PSYCHIAT RES, V290, DOI 10.1016/j.psychres.2020.113090; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Crespo M, 2016, PSYCHOL TRAUMA-US, V8, P149, DOI 10.1037/tra0000041; Danner M., 2023, 2023 62 ANN C SOC IN; Davis C., 1962, Numer. Math, V4, P343, DOI [10.1007/BF01386329, DOI 10.1007/BF01386329]; Dekel S., 2016, Massachusetts General Hospital Comprehensive Clinical Psychiatry, V2nd, P380; Dekel S., 2024, Nature Ment. Health. Accepted.; Dekel S, 2024, AM J OBSTET GYNECOL, V230, DOI 10.1016/j.ajog.2023.12.013; Dekel S, 2020, ARCH WOMEN MENT HLTH, V23, P557, DOI 10.1007/s00737-019-01006-x; Dekel S, 2019, ARCH WOMEN MENT HLTH, V22, P119, DOI 10.1007/s00737-018-0853-y; Dekel S, 2013, PSYCHOL TRAUMA-US, V5, P26, DOI 10.1037/a0022750; Farhat F., 2023, Annals of Biomedical Engineering, P1; Forkus SR, 2023, CLIN PSYCHOL-SCI PR, V30, P110, DOI 10.1037/cps0000111; Fu J, 2021, BIOMED ENG ONLINE, V20, DOI 10.1186/s12938-021-00915-2; Galido PV, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38166; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Iyengar AS, 2022, INT J GYNECOL OBSTET, V158, P759, DOI 10.1002/ijgo.14280; Jagodnik KM, 2024, J AFFECT DISORDERS, V348, P17, DOI 10.1016/j.jad.2023.12.010; Ji SX, 2023, Arxiv, DOI arXiv:2304.10447; Ji SX, 2021, Arxiv, DOI arXiv:2110.15621; Jones A, 2022, MATERN CHILD HLTH J, V26, P1030, DOI 10.1007/s10995-022-03399-1; Krüger-Gottschalk A, 2017, BMC PSYCHIATRY, V17, DOI 10.1186/s12888-017-1541-6; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Levis M, 2021, PSYCHOL MED, V51, P1382, DOI 10.1017/S0033291720000173; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Liu N, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.772592; Luca D. L., 2019, Math. Policy Res., V1; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Lyons-Ruth K, 2022, CHILD DEV PERSPECT, V16, P10, DOI 10.1111/cdep.12442; Mayopoulos GA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-92985-4; Mayopoulos GA, 2021, J AFFECT DISORDERS, V282, P122, DOI 10.1016/j.jad.2020.12.101; O'Kearney R, 2006, J TRAUMA STRESS, V19, P81, DOI 10.1002/jts.20099; Orovou E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255689; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Sachdeva J, 2022, J ACAD CONSULT-LIAIS, V63, P485, DOI 10.1016/j.jaclp.2022.04.005; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Sohail SS, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101675; Sohail SS, 2024, ANN BIOMED ENG, V52, P1131, DOI 10.1007/s10439-023-03335-6; Sommerlad S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256681; Thiel F, 2021, J ANXIETY DISORD, V77, DOI 10.1016/j.janxdis.2020.102342; Thiel F, 2020, ARCH WOMEN MENT HLTH, V23, P189, DOI 10.1007/s00737-019-00978-0; Thiel Freya, 2018, Prim Care Companion CNS Disord, V20, DOI 10.4088/PCC.18m02322; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Van Sieleghem S, 2022, EARLY HUM DEV, V174, DOI 10.1016/j.earlhumdev.2022.105667; Vanaken L, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.558044; Vigod SN, 2020, WORLD PSYCHIATRY, V19, P328, DOI 10.1002/wps.20775; Wang L, 2022, JMIR MED INF, V10, DOI 10.2196/38161; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wortmann JH, 2016, PSYCHOL ASSESSMENT, V28, P1392, DOI 10.1037/pas0000260; Yildiz PD, 2017, J AFFECT DISORDERS, V208, P634, DOI 10.1016/j.jad.2016.10.009	67	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 11	2024	14	1							8336	10.1038/s41598-024-54242-2	http://dx.doi.org/10.1038/s41598-024-54242-2			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	NO5U6	38605073	Green Published, Green Submitted, gold			2024-07-03	WOS:001201413300029
J	Busch, F; Han, TY; Makowski, MR; Truhn, D; Bressem, KK; Adams, L				Busch, Felix; Han, Tianyu; Makowski, Marcus R.; Truhn, Daniel; Bressem, Keno K.; Adams, Lisa			Integrating Text and Image Analysis: Exploring GPT-4V's Capabilities in Advanced Radiological Applications Across Subspecialties	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						GPT-4; ChatGPT; Generative Pre-Trained Transformer; multimodal large language models; artificial intelligence; AI applications in medicine; diagnostic radiology; clinical decision support systems; generative AI; medical image analysis		This study demonstrates that GPT-4V outperforms GPT-4 across radiology subspecialties in analyzing 207 cases with 1312 images from the Radiological Society of North America Case Collection.	[Busch, Felix] Charite Univ Med Berlin, Dept Neuroradiol, Charitepl 1, D-10117 Berlin, Germany; [Busch, Felix] Free Univ Berlin, Charitepl 1, D-10117 Berlin, Germany; [Busch, Felix] Humboldt Univ, Charitepl 1, D-10117 Berlin, Germany; [Han, Tianyu; Truhn, Daniel] Univ Hosp Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany; [Makowski, Marcus R.; Adams, Lisa] Tech Univ Munich, Dept Diagnost & Intervent Radiol, Klinikum Rechts Isar, Munich, Germany; [Bressem, Keno K.] Tech Univ Munich, Inst Radiol & Nucl Med, German Heart Ctr Munich, Munich, Germany	Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; RWTH Aachen University; RWTH Aachen University Hospital; Technical University of Munich; German Heart Centre Munich; Technical University of Munich	Busch, F (corresponding author), Charite Univ Med Berlin, Dept Neuroradiol, Charitepl 1, D-10117 Berlin, Germany.; Busch, F (corresponding author), Free Univ Berlin, Charitepl 1, D-10117 Berlin, Germany.; Busch, F (corresponding author), Humboldt Univ, Charitepl 1, D-10117 Berlin, Germany.	felix.busch@charite.de	Busch, Felix/ABE-1064-2022	Busch, Felix/0000-0001-9770-8555; Bressem, Keno/0000-0001-9249-8624; Han, Tianyu/0000-0002-8636-6462				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; [Anonymous], 2023, Openai; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Moor M, 2023, Arxiv, DOI arXiv:2307.15189; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; RSNA Case Collection, about us; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421	7	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAY 1	2024	26								e54948	10.2196/54948	http://dx.doi.org/10.2196/54948			4	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	RG0Y0	38691404	Green Submitted, Green Accepted, gold			2024-07-03	WOS:001226407700002
J	Haber, Y; Levkovich, I; Hadar-Shoval, D; Elyoseph, Z				Haber, Yuval; Levkovich, Inbar; Hadar-Shoval, Dorit; Elyoseph, Zohar			The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy	JMIR MENTAL HEALTH			English	Article						psychoanalysis; generative artificial intelligence; psychotherapy; large language models; narcissism; narcissist; narcissistic; perception; perceptions; critical thinking; transparency; autonomy; mental health; interpersonal; LLM; LLMs; language model; language models; artificial intelligence; generative; AI; ethic; ethics; ethical		This paper explores a significant shift in the field of mental health in general and psychotherapy in particular following generative artificial intelligence's new capabilities in processing and generating humanlike language. Following Freud, this lingo-technological development is conceptualized as the "fourth narcissistic blow" that science inflicts on humanity. We argue that this narcissistic blow has a potentially dramatic influence on perceptions of human society, interrelationships, and the self. We should, accordingly, expect dramatic changes in perceptions of the therapeutic act following the emergence of what we term the artificial third in the field of psychotherapy. The introduction of an artificial third marks a critical juncture, prompting us to ask the following important core questions that address two basic elements of critical thinking, namely, transparency and autonomy: (1) What is this new artificial presence in therapy relationships? (2) How does it reshape our perception of ourselves and our interpersonal dynamics? and (3) What remains of the irreplaceable human elements at the core of therapy? Given the ethical implications that arise from these questions, this paper proposes that the artificial third can be a valuable asset when applied with insight and ethical consideration, enhancing but not replacing the human touch in therapy.	[Haber, Yuval] Bar Ilan Univ, PhD Program Hermeneut & Cultural Studies, Interdisciplinary Studies Unit, Ramat Gan, Israel; [Levkovich, Inbar] Tel Hai Acad Coll, Kiryat Shmona, Israel; [Hadar-Shoval, Dorit] Max Stern Yezreel Valley Coll, Dept Psychol & Educ Counseling, Emek Yezreel, Israel; [Elyoseph, Zohar] Imperial Coll London, Fac Med, Dept Brain Sci, Fulham Palace Rd, London W6 8RF, England; [Elyoseph, Zohar] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Emek Yezreel, Israel	Bar Ilan University; Tel Hai Academic College; Imperial College London	Elyoseph, Z (corresponding author), Imperial Coll London, Fac Med, Dept Brain Sci, Fulham Palace Rd, London W6 8RF, England.; Elyoseph, Z (corresponding author), Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Emek Yezreel, Israel.	zohare@yvc.ac.il		Elyoseph, Zohar/0000-0002-5717-4074; Levkovich, Inbar/0000-0003-1582-3889				Asman O, 2023, AM J BIOETHICS, V23, P62, DOI 10.1080/15265161.2023.2191046; Austin J.L., 1975, DO THINGS WORDS; Bar Nes A, 2022, J AM PSYCHOANAL ASS, V70, P903, DOI 10.1177/00030651221124803; Barry Laurence., Foucault and Postmodern Conceptions of Reason, P2020, DOI DOI 10.1007/978-3-030-48943-4; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Byrow Y, 2020, CLIN PSYCHOL REV, V75, DOI 10.1016/j.cpr.2019.101812; Carlbring P, 2023, INTERNET INTERV, V32, DOI 10.1016/j.invent.2023.100621; Coghlan S, 2024, J COMMUN GENET, V15, P13, DOI 10.1007/s12687-023-00678-4; Cohen IG, 2023, AM J BIOETHICS, V23, P8, DOI 10.1080/15265161.2023.2233357; Copernicus Weinert F, 2008, Darwin, and Freud: Revolutions in the History and Philosophy of Science.; Cuijpers P, 2019, ANNU REV CLIN PSYCHO, V15, P207, DOI 10.1146/annurev-clinpsy-050718-095424; Elyoseph Z, 2024, JMIR Preprints, DOI [10.2196/preprints.58011, DOI 10.2196/PREPRINTS.58011]; Elyoseph Z, 2024, JMIR MENT HEALTH, V11, DOI 10.2196/53043; Elyoseph Z, 2024, JMIR MENT HEALTH, V11, DOI 10.2196/54369; Elyoseph Z, 2024, AM J BIOETHICS, V24, P57, DOI 10.1080/15265161.2023.2278546; Elyoseph Z, 2024, FAM MED COMMUNITY HE, V12, DOI 10.1136/fmch-2023-002583; Elyoseph Z, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1213141; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Felzmann H, 2020, SCI ENG ETHICS, V26, P3333, DOI 10.1007/s11948-020-00276-4; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Fogelin RJ, 2020, Taking Wittgenstein at His Word: A Textual Study.; Foucault M, 2019, What Is Enlightenment, P382; Freud S., 2004, Studies on hysteria; Freud Sigmund., 1955, STANDARD EDITION COM, V17, P135; Garibay OO, 2023, INT J HUM-COMPUT INT, DOI 10.1080/10447318.2022.2153320; Grodniewicz JP, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1190084; Hadar-Shoval D, 2024, JMIR MENT HEALTH, V11, DOI 10.2196/55988; Hadar-Shoval D, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1234397; Hatem R, 2023, JAMA INTERN MED, V183, P1177, DOI 10.1001/jamainternmed.2023.4231; Hodgkinson Stacy, 2017, Pediatrics, V139, DOI 10.1542/peds.2015-1175; Kuhn T.S., 2012, STRUCTURE SCI REVOLU; Laitinen A, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.705164; Laplanche J., 2018, The Language of Psychoanalysis.; Levkovich I, 2023, FAM MED COMMUNITY HE, V11, DOI 10.1136/fmch-2023-002391; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; McGuinness B.F.s., 1961, TRACTATUS LOGICO PHI; Nahum D., 2019, Advances in Psychiatry, P471, DOI [DOI 10.1007/978-3-319-70554-5_29, 10.1007/978-3-319-70554-5, DOI 10.1007/978-3-319-70554-5]; Nefdt RM, 2023, BIOL PHILOS, V38, DOI 10.1007/s10539-023-09903-3; Nobus D, 2020, Key Concepts of Lacanian Psychoanalysis.; Ogden TH, 2004, PSYCHOANAL QUART, V73, P167, DOI 10.1002/j.2167-4086.2004.tb00156.x; Pilecki Brian, 2015, Psychodyn Psychiatry, V43, P463, DOI 10.1521/pdps.2015.43.3.463; Romano MF, 2023, NEUROLOGY, V101, P1058, DOI 10.1212/WNL.0000000000207967; Sedlakova J, 2023, AM J BIOETHICS, V23, P4, DOI 10.1080/15265161.2022.2048739; Spinard A, 2024, BMC PSYCHIATRY, V24, DOI 10.1186/s12888-024-05570-0; Sun J, 2023, ASIAN J PSYCHIATR, V87, DOI 10.1016/j.ajp.2023.103705; Tal A, 2023, AM J BIOETHICS, V23, P74, DOI 10.1080/15265161.2023.2250297; Van Heerden AC, 2023, JAMA PSYCHIAT, V80, P662, DOI 10.1001/jamapsychiatry.2023.1253; Wilson E.O., 1975, P1; Winnicott DW, 2000, Identity: A Reader, P144; Xu ST, 2023, COMPUT METH PROG BIO, V241, DOI 10.1016/j.cmpb.2023.107746; Zajko M, 2023, SURVEILL SOC, V21, P246; Zhou WK, 2023, J MARK ANAL, V11, P693, DOI 10.1057/s41270-023-00250-6; Zubala A, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.600070	53	3	3	4	4	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2368-7959			JMIR MENT HEALTH	JMIR Ment. Health		2024	11								e54781	10.2196/54781	http://dx.doi.org/10.2196/54781			9	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	SH0B9	38787297	gold			2024-07-03	WOS:001233436400001
J	Mousavi, R; Gu, B				Mousavi, Reza; Gu, Bin			Resilience Messaging: The Effect of Governors' Social Media Communications on Community Compliance During a Public Health Crisis	INFORMATION SYSTEMS RESEARCH			English	Article; Early Access						disaster management; social media; community compliance; resilience communication; inspirational leadership; large language models (LLM); natural language processing (NLP); generative artificial intelligence (generative AI); dynamic panel data model; controlled experiment	TRANSFORMATIONAL LEADERSHIP; PERSONALITY; PRODUCTIVITY; INVESTMENTS; INFORMATION; TECHNOLOGY; EVACUATION; HOME	When managing major disasters, authorities may ask residents to comply with certain guidelines that change community members' daily routines. In these situations, authorities often appeal to resilience, which refers to the ability to recover from challenges. In this study, we examine whether embedding resilience-related words (resilience messaging) in governors' social media posts increases community compliance with government guidelines in the context of the COVID-19 disaster. First, we conducted a secondary data analysis using a panel data set of U.S. states. This analysis included community mobility data, governors' tweets, official county tweets, approval ratings, new COVID-19 cases, and states' response data for the period between February 2020 and August 2021 (81 weeks). We measure community compliance using the time residents spent at home and the time they spent at retail places, according to community mobility data. We also conducted an online controlled experiment to complement our secondary data analysis in order to identify the underlying mechanism. We show that governors' resilience messaging increases community compliance (12.5% increase in time spent at home and 11% increase in avoiding unnecessary trips). We also find that the effect of resilience messaging on community compliance is mediated by residents' perceptions of inspirational leadership.	[Mousavi, Reza] Univ Virginia, McIntire Sch Commerce, Charlottesville, VA 22903 USA; [Gu, Bin] Boston Univ, Questrom Sch Business, Boston, MA 02215 USA	University of Virginia; Boston University	Mousavi, R (corresponding author), Univ Virginia, McIntire Sch Commerce, Charlottesville, VA 22903 USA.	mousavi@virginia.edu; bgu@bu.edu	wang, yi/JYO-8193-2024; zhang, ling/JXW-6931-2024; chen, jiayi/KHV-5520-2024; wang, hongyuan/JWP-2279-2024; chen, yan/JRY-4645-2023; lei, lei/JSL-3106-2023; lin, qing/JTU-4293-2023; Yang, Lili/JTT-5215-2023; Zhang, Kai/KBD-3312-2024; LEI, LEI/JTS-4675-2023; zhang, xu/JXX-7692-2024; Gu, Bingxin/JNS-4761-2023	Yang, Lili/0009-0008-2926-484X; Gu, Bingxin/0009-0005-5667-1430; Mousavi, Reza/0000-0002-1990-7767; Gu, Bin/0000-0002-0396-8899				Abbasi A, 2019, INFORM SYST RES, V30, P1007, DOI 10.1287/isre.2019.0847; ADAMS J, 1991, BRIT J SOCIOL, V42, P478, DOI 10.2307/591193; Agarwal R, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2107873118; Ahmad F, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3365211; Antonakis J, 2022, MANAGEMENT SCI, V68, P6355; Aral S, 2012, INFORM SYST RES, V23, P849, DOI 10.1287/isre.1110.0408; ARELLANO M, 1995, J ECONOMETRICS, V68, P29, DOI 10.1016/0304-4076(94)01642-D; Bapna R, 2013, MANAGE SCI, V59, P641, DOI 10.1287/mnsc.1120.1586; Bass B.M., 1999, Eur. J. Work. Organ. Psychol., V8, P9, DOI DOI 10.1080/135943299398410; BASS BM, 1985, ORGAN DYN, V13, P26, DOI 10.1016/0090-2616(85)90028-2; Bhargava HK, 2014, MANAGE SCI, V60, P2543, DOI 10.1287/mnsc.2014.1934; Blundell R, 1998, J ECONOMETRICS, V87, P115, DOI 10.1016/S0304-4076(98)00009-8; Burns JM, 2005, LEADERSHIP-LONDON, V1, P11, DOI 10.1177/1742715005049347; Buzzanell P., 2018, ENGAGING THEORIES IS, V2nd, P98, DOI DOI 10.4324/9781315204321-9; Buzzanell PM, 2010, J COMMUN, V60, P1, DOI 10.1111/j.1460-2466.2009.01469.x; Carolan BV, 2018, INT J ADOLESC YOUTH, V23, P334, DOI 10.1080/02673843.2017.1371615; Chung DJ, 2019, MANAGE SCI, V65, P5197, DOI 10.1287/mnsc.2018.3189; Crayne MP, 2021, AM PSYCHOL, V76, P462, DOI 10.1037/amp0000715; Driscoll JC, 1998, REV ECON STAT, V80, P549, DOI 10.1162/003465398557825; Fayoumi A, 2021, EMERGING TECHNOLOGIE; Frese M, 2003, PERS PSYCHOL, V56, P671, DOI 10.1111/j.1744-6570.2003.tb00754.x; Friborg O, 2005, INT J METH PSYCH RES, V14, P29, DOI 10.1002/mpr.15; Gao Y, 2021, INFORM SYST RES, DOI 10.1287/isre.2021.1092; Goes PB, 2014, INFORM SYST RES, V25, P222, DOI 10.1287/isre.2013.0512; Gollwitzer A, 2020, NAT HUM BEHAV, V4, P1186, DOI 10.1038/s41562-020-00977-7; Gong J, 2023, MANUFACTURING SERVIC, V25, P884; Greenwood BN, 2017, MIS QUART, V41, P163, DOI 10.25300/MISQ/2017/41.1.08; Griffin-Padgett DR, 2010, COMMUN MONOGR, V77, P376, DOI 10.1080/03637751.2010.502536; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Grossman G, 2020, P NATL ACAD SCI USA, V117, P24144, DOI 10.1073/pnas.2007835117; Hale T, 2020, 2020034 OXF U BLAV S; Haman M, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05540; Haman M, 2021, CAN J POLIT SCI, V54, P134, DOI 10.1017/S0008423921000020; Hoechle D, 2007, STATA J, V7, P281, DOI 10.1177/1536867X0700700301; Joshi A, 2009, ORGAN SCI, V20, P240, DOI 10.1287/Orsc.1080.0383; Kitchens B, 2018, INFORM SYST RES, V29, P928, DOI 10.1287/isre.2017.0754; KOBASA SC, 1979, J PERS SOC PSYCHOL, V37, P1, DOI 10.1037/0022-3514.37.1.1; Lenz Gabriel., 2012, FOLLOW LEADER VOTERS, DOI DOI 10.1093/POQ/NFT014; Lucas K, 2012, J FAM COMMUN, V12, P189, DOI 10.1080/15267431.2012.687196; Lupia A., 1998, The democratic dilemma: Can citizens learn what they need to know?; Manuell ME, 2011, DISASTERS, V35, P417, DOI 10.1111/j.1467-7717.2010.01219.x; Moreland A, 2020, MMWR-MORBID MORTAL W, V69, P1198, DOI 10.15585/mmwr.mm6935a2; Mousavi R, 2019, INFORM SYST RES, V30, P133, DOI 10.1287/isre.2018.0791; Oshio A, 2018, PERS INDIV DIFFER, V127, P54, DOI 10.1016/j.paid.2018.01.048; Peer E, 2014, BEHAV RES METHODS, V46, P1023, DOI 10.3758/s13428-013-0434-y; Popkin Samuel., 1994, The Reasoning Voter: Communication and Persuasion in Presidential Campaigns; Rafferty AE, 2004, LEADERSHIP QUART, V15, P329, DOI 10.1016/j.leaqua.2004.02.009; Rajesh N, 2016, INT CONF INTELL SYS; Riad JK, 1999, J APPL SOC PSYCHOL, V29, P918, DOI 10.1111/j.1559-1816.1999.tb00132.x; Richardson GE, 2002, J CLIN PSYCHOL, V58, P307, DOI 10.1002/jclp.10020; Roodman D, 2009, STATA J, V9, P86, DOI 10.1177/1536867X0900900106; RUTTER M, 1985, BRIT J PSYCHIAT, V147, P598, DOI 10.1192/bjp.147.6.598; Sahni T, 2017, INT CONF COMMUN SYST, P548, DOI 10.1109/COMSNETS.2017.7945451; Scharp KM, 2020, J APPL COMMUN RES, V48, P207, DOI 10.1080/00909882.2020.1734225; SMIRCICH L, 1982, J APPL BEHAV SCI, V18, P257, DOI 10.1177/002188638201800303; Suryaningtyas D., 2019, Academy of Strategic Management Journal, V18, P1; Tambe P, 2012, INFORM SYST RES, V23, P599, DOI 10.1287/isre.1110.0398; Tekumalla, 2020, P 1 WORKSH NLP COVID, DOI [10.18653/v1/2020.nlpcovid19-2.25, DOI 10.18653/V1/2020.NLPCOVID19-2.25]; Vaishnavi S, 2007, PSYCHIAT RES, V152, P293, DOI 10.1016/j.psychres.2007.01.006; Valero JN, 2015, DISASTER PREV MANAG, V24, P4, DOI 10.1108/DPM-04-2014-0060; Venetis MK, 2020, J APPL COMMUN RES, V48, P49, DOI 10.1080/00909882.2019.1706098; Wang XY, 2022, J ASSOC INF SCI TECH, V73, P726, DOI 10.1002/asi.24576; Wasserman D, 2021, Introducing the 2021 Cook Political Report Partisan Voter Index; Williams GA, 2017, COMMUN STUD, V68, P385, DOI 10.1080/10510974.2017.1340901; Wooldridge JM, 2010, ECONOMETRIC ANALYSIS OF CROSS SECTION AND PANEL DATA, 2ND EDITION, P3; Yang K, 2023, INFORM SYSTEMS RES, V34, P194; Yin DZ, 2021, MIS QUART, V45, P1059, DOI 10.25300/MISQ/2021/15363; Yin DZ, 2014, MIS QUART, V38, P539, DOI 10.25300/MISQ/2014/38.2.10	68	3	3	72	134	INFORMS	CATONSVILLE	5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA	1047-7047	1526-5536		INFORM SYST RES	Inf. Syst. Res.	2023 JUL 20	2023										10.1287/isre.2021.0599	http://dx.doi.org/10.1287/isre.2021.0599		JUL 2023	24	Information Science & Library Science; Management	Social Science Citation Index (SSCI)	Information Science & Library Science; Business & Economics	N2ZS5					2024-07-03	WOS:001035762300001
J	Noda, M; Ueno, T; Koshu, R; Takaso, Y; Shimada, MD; Saito, C; Sugimoto, H; Fushiki, H; Ito, M; Nomura, A; Yoshizaki, T				Noda, Masao; Ueno, Takayoshi; Koshu, Ryota; Takaso, Yuji; Shimada, Mari Dias; Saito, Chizu; Sugimoto, Hisashi; Fushiki, Hiroaki; Ito, Makoto; Nomura, Akihiro; Yoshizaki, Tomokazu			Performance of GPT-4V in Answering the Japanese Otolaryngology Board Certification Examination Questions: Evaluation Study	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; GPT-4v; large language model; otolaryngology; GPT; ChatGPT; LLM; LLMs; language model; language models; head; respiratory; ENT: ear; nose; throat; neck; NLP; natural language processing; image; images; exam; exams; examination; examinations; answer; answers; answering; response; responses		Background: Artificial intelligence models can learn from medical literature and clinical cases and generate answers that rival human experts. However, challenges remain in the analysis of complex data containing images and diagrams. Objective: This study aims to assess the answering capabilities and accuracy of ChatGPT-4 Vision (GPT-4V) for a set of 100 questions, including image-based questions, from the 2023 otolaryngology board certification examination. Methods: Answers to 100 questions from the 2023 otolaryngology board certification examination, including image-based questions, were generated using GPT-4V. The accuracy rate was evaluated using different prompts, and the presence of images, clinical area of the questions, and variations in the answer content were examined. Results: The accuracy rate for text-only input was, on average, 24.7% but improved to 47.3% with the addition of English translation and prompts (P<.001). The average nonresponse rate for text-only input was 46.3%; this decreased to 2.7% with the addition of English translation and prompts (P<.001). The accuracy rate was lower for image-based questions than for text-only questions across all types of input, with a relatively high nonresponse rate. General questions and questions from the fields of head and neck allergies and nasal allergies had relatively high accuracy rates, which increased with the addition of translation and prompts. In terms of content, questions related to anatomy had the highest accuracy rate. For all content types, the addition of translation and prompts increased the accuracy rate. As for the performance based on image-based questions, the average of correct answer rate with text-only input was 30.4%, and that with text-plus-image input was 41.3% (P=.02). Conclusions: Examination of artificial intelligence's answering capabilities for the otolaryngology board certification examination improves our understanding of its potential and limitations in this field. Although the improvement was noted with the addition of translation and prompts, the accuracy rate for image-based questions was lower than that for text-based questions, suggesting room for improvement in GPT-4V at this stage. Furthermore, text-plus-image input answers a higher rate in image-based questions. Our findings imply the usefulness and potential of GPT-4V in medicine; however, future consideration of safe use methods is needed.	[Noda, Masao; Koshu, Ryota; Takaso, Yuji; Shimada, Mari Dias; Saito, Chizu; Ito, Makoto] Jichi Med Univ, Dept Otolaryngol Head & Neck Surg, Shimotsuke, Japan; [Noda, Masao; Ueno, Takayoshi; Takaso, Yuji; Sugimoto, Hisashi; Yoshizaki, Tomokazu] Kanazawa Univ, Dept Otolaryngol & Head & Neck Surg, Kanazawa, Japan; [Fushiki, Hiroaki] Mejiro Univ, Ear Inst Clin, Dept Otolaryngol, Saitama, Japan; [Nomura, Akihiro] Kanazawa Univ, Coll Transdisciplinary Sci Innovat, Kanazawa, Japan; [Noda, Masao] Jichi Med Univ, Dept Otolaryngol & Head & Neck Surg, Yakushiji 3311-1, Shimotsuke 3290498, Japan	Jichi Medical University; Kanazawa University; Kanazawa University; Jichi Medical University	Noda, M (corresponding author), Jichi Med Univ, Dept Otolaryngol & Head & Neck Surg, Yakushiji 3311-1, Shimotsuke 3290498, Japan.	doforanabdosuc@gmail.com		Noda, Masao/0000-0001-6281-2782; Nomura, Akihiro/0000-0001-6647-8240; Fushiki, Hiroaki/0009-0003-4120-8641; KOSHU, RYOTA/0009-0007-0127-9137				[Anonymous], 2023, Gpt-4v(ision) system card; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bsharat SM, 2024, Arxiv, DOI arXiv:2312.16171; Ebrahimian M, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100815; Haddad F, 2024, JMIR MED EDUC, V10, DOI 10.2196/50842; Herrmann-Werner A, 2024, J MED INTERNET RES, V26, DOI 10.2196/52113; jstage, Answers to multiple-choice questions for the 35rd Specialist Certification Examination; Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42924; Knopp MI, 2023, JMIR MED EDUC, V9, DOI 10.2196/50373; Kunitsu Y, 2023, JMIR MED EDUC, V9, DOI 10.2196/48452; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Nakao T, 2023, medRxiv, DOI [10.1101/2023.11.07.23298133, 10.1101/2023.11.07.23298133, DOI 10.1101/2023.11.07.23298133]; Noda M, 2023, Nippon Jibiinkoka Tokeibugeka Gakkai Kaiho (Tokyo), V126, P1217, DOI [10.3950/jibiinkotokeibu.126.11_1217, DOI 10.3950/JIBIINKOTOKEIBU.126.11_1217]; Ohta K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50369; OpenAI, 2023, Gpt-4 technical report, P1, DOI DOI 10.48550/ARXIV.2303.08774; Razdan S, 2023, INT J IMPOT RES, DOI 10.1038/s41443-023-00797-z; Rizzo MG, 2024, J ORTHOP, V50, P70, DOI 10.1016/j.jor.2023.11.056; Sakai D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.49903; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Tanaka Yudai, 2024, PLOS Digit Health, V3, pe0000433, DOI 10.1371/journal.pdig.0000433; Torres-Zegarra BC, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.30; Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Watari T, 2023, JMIR MED EDUC, V9, DOI 10.2196/52202; Yanagita Y, 2023, JMIR FORM RES, V7, DOI 10.2196/48023	26	2	2	4	4	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e57054	10.2196/57054	http://dx.doi.org/10.2196/57054			9	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	MT2M7	38546736	gold, Green Published			2024-07-03	WOS:001195821100001
J	Horiuchi, D; Tatekawa, H; Oura, T; Oue, S; Walston, SL; Takita, H; Matsushita, S; Mitsuyama, Y; Shimono, T; Miki, Y; Ueda, D				Horiuchi, Daisuke; Tatekawa, Hiroyuki; Oura, Tatsushi; Oue, Satoshi; Walston, Shannon L.; Takita, Hirotaka; Matsushita, Shu; Mitsuyama, Yasuhito; Shimono, Taro; Miki, Yukio; Ueda, Daiju			Comparing the Diagnostic Performance of GPT-4-based ChatGPT, GPT-4V-based ChatGPT, and Radiologists in Challenging Neuroradiology Cases	CLINICAL NEURORADIOLOGY			English	Article; Early Access						Artificial intelligence; Chat Generative Pre-trained Transformer (ChatGPT); Generative Pre-trained Transformer-4 (GPT-4); Generative Pre-trained Transformer-4 with vision (GPT-4V); Large language models		Purpose To compare the diagnostic performance among Generative Pre-trained Transformer (GPT)-4-based ChatGPT, GPT-4 with vision (GPT-4V) based ChatGPT, and radiologists in challenging neuroradiology cases. Methods We collected 32 consecutive "Freiburg Neuropathology Case Conference" cases from the journal Clinical Neuroradiology between March 2016 and December 2023. We input the medical history and imaging findings into GPT-4-based ChatGPT and the medical history and images into GPT-4V-based ChatGPT, then both generated a diagnosis for each case. Six radiologists (three radiology residents and three board-certified radiologists) independently reviewed all cases and provided diagnoses. ChatGPT and radiologists' diagnostic accuracy rates were evaluated based on the published ground truth. Chi-square tests were performed to compare the diagnostic accuracy of GPT-4-based ChatGPT, GPT-4V-based ChatGPT, and radiologists. Results GPT-4 and GPT-4V-based ChatGPTs achieved accuracy rates of 22% (7/32) and 16% (5/32), respectively. Radiologists achieved the following accuracy rates: three radiology residents 28% (9/32), 31% (10/32), and 28% (9/32); and three board-certified radiologists 38% (12/32), 47% (15/32), and 44% (14/32). GPT-4-based ChatGPT's diagnostic accuracy was lower than each radiologist, although not significantly (all p > 0.07). GPT-4V-based ChatGPT's diagnostic accuracy was also lower than each radiologist and significantly lower than two board-certified radiologists (p = 0.02 and 0.03) (not significant for radiology residents and one board-certified radiologist [all p > 0.09]). Conclusion While GPT-4-based ChatGPT demonstrated relatively higher diagnostic performance than GPT-4V-based ChatGPT, the diagnostic performance of GPT-4 and GPT-4V-based ChatGPTs did not reach the performance level of either radiology residents or board-certified radiologists in challenging neuroradiology cases.	[Horiuchi, Daisuke; Tatekawa, Hiroyuki; Oura, Tatsushi; Oue, Satoshi; Walston, Shannon L.; Takita, Hirotaka; Matsushita, Shu; Mitsuyama, Yasuhito; Shimono, Taro; Miki, Yukio; Ueda, Daiju] Osaka Metropolitan Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Osaka, Japan; [Ueda, Daiju] Osaka Metropolitan Univ, Ctr Hlth Sci Innovat, Osaka, Japan	Osaka Metropolitan University; Osaka Metropolitan University	Ueda, D (corresponding author), Osaka Metropolitan Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Osaka, Japan.; Ueda, D (corresponding author), Osaka Metropolitan Univ, Ctr Hlth Sci Innovat, Osaka, Japan.	ai.labo.ocu@gmail.com	Ueda, Daiju/AAG-2167-2021	Ueda, Daiju/0000-0002-3878-3616; Takita, Hirotaka/0000-0003-2860-4503; Shimono, Taro/0000-0001-5847-6587; Matsushita, Shu/0000-0003-1132-9736; Tatekawa, Hiroyuki/0000-0002-8050-4895; Mitsuyama, Yasuhito/0000-0001-7979-2300; Walston, Shannon/0000-0002-7268-8313; Horiuchi, Daisuke/0000-0002-8929-8098; Miki, Yukio/0000-0003-0621-0044	Guerbet	Guerbet	Our manuscript was developed with the assistance of ChatGPT, a language model based on the GPT-4 architecture (February 13, 2024 Version; OpenAI; https://chat.openai.com/). However, all outputs generated by ChatGPT were reviewed and approved by the authors.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2021, World Health Organization Classification of Tumours of the Central Nervous System; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bossuyt PM, 2015, RADIOLOGY, V277, P826, DOI 10.1148/radiol.2015151516; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Doostkam S, 2020, CLIN NEURORADIOL, V30, P879, DOI 10.1007/s00062-020-00973-4; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hendee WR, 2010, RADIOLOGY, V257, P240, DOI 10.1148/radiol.10100063; Horiuchi D, 2023, medRxiv, DOI [10.1101/2023.12.07.23299707, 10.1101/2023.12.07.23299707, DOI 10.1101/2023.12.07.23299707]; Horiuchi D, 2024, NEURORADIOLOGY, V66, P73, DOI 10.1007/s00234-023-03252-4; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Juluru K, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210013; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Li David, 2023, Radiology, V308, pe232082, DOI 10.1148/radiol.232082; Li H, 2023, CLIN IMAG, V101, P137, DOI 10.1016/j.clinimag.2023.06.008; Mallio CA, 2023, RADIOL MED, V128, P808, DOI 10.1007/s11547-023-01651-4; McCarthy CJ, 2023, J VASC INTERV RADIOL, V34, P1760, DOI 10.1016/j.jvir.2023.05.037; Nakaura T, 2024, JPN J RADIOL, DOI 10.1007/s11604-024-01552-0; OpenAI, 2023, Gpt-4v(ision) system card; Osborn AG, 2022, AM J NEURORADIOL, DOI 10.3174/ajnr.A7462; Osborn AG., 2023, Osborns brain: imaging, pathology, and anatomy, V3; Patel SH, 2019, AM J NEURORADIOL, V40, P1252, DOI 10.3174/ajnr.A6125; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Sasaki F, 2024, J VASC INTERV RADIOL, V35, DOI 10.1016/j.jvir.2023.11.014; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Ueda D., 2024, BMC Digital Health, V2, P4, DOI [10.1186/s44247-023-00058-5, DOI 10.1186/S44247-023-00058-5]; Ueda D, 2024, JPN J RADIOL, V42, P3, DOI 10.1007/s11604-023-01474-3; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Ueda D, 2019, JPN J RADIOL, V37, P15, DOI 10.1007/s11604-018-0795-3	36	0	0	1	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1869-1439	1869-1447		CLIN NEURORADIOL	Clin. Neuroradiol.	2024 MAY 28	2024										10.1007/s00062-024-01426-y	http://dx.doi.org/10.1007/s00062-024-01426-y		MAY 2024	9	Clinical Neurology; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	SJ9Y2	38806794				2024-07-03	WOS:001234215500001
J	Wang, SQG; Mo, CG; Chen, Y; Dai, XL; Wang, HY; Shen, XL				Wang, Shangqiguo; Mo, Changgeng; Chen, Yuan; Dai, Xiaolu; Wang, Huiyi; Shen, Xiaoli			Exploring the Performance of ChatGPT-4 in the Taiwan Audiologist Qualification Examination: Preliminary Observational Study Highlighting the Potential of AI Chatbots in Hearing Care	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; medical education; artificial intelligence; AI; audiology; hearing care; natural language processing; large language model; Taiwan; hearing; hearing specialist; audiologist; examination; information accuracy; educational technology; healthcare services; chatbot; health care services		Background: Artificial intelligence (AI) chatbots, such as ChatGPT-4, have shown immense potential for application across various aspects of medicine, including medical education, clinical practice, and research. Objective: This study aimed to evaluate the performance of ChatGPT-4 in the 2023 Taiwan Audiologist Qualification Examination, thereby preliminarily exploring the potential utility of AI chatbots in the fields of audiology and hearing care services. Methods: ChatGPT-4 was tasked to provide answers and reasoning for the 2023 Taiwan Audiologist Qualification Examination. The examination encompassed six subjects: (1) basic auditory science, (2) behavioral audiology, (3) electrophysiological audiology, (4) principles and practice of hearing devices, (5) health and rehabilitation of the auditory and balance systems, and (6) auditory and speech communication disorders (including professional ethics). Each subject included 50 multiple-choice questions, with the exception of behavioral audiology, which had 49 questions, amounting to a total of 299 questions. Results: The correct answer rates across the 6 subjects were as follows: 88% for basic auditory science, 63% for behavioral audiology, 58% for electrophysiological audiology, 72% for principles and practice of hearing devices, 80% for health and rehabilitation of the auditory and balance systems, and 86% for auditory and speech communication disorders (including professional ethics). The overall accuracy rate for the 299 questions was 75%, which surpasses the examination's passing criteria of an average 60% accuracy rate across all subjects. A comprehensive review of ChatGPT-4's responses indicated that incorrect answers were predominantly due to information errors. Conclusions: ChatGPT-4 demonstrated a robust performance in the Taiwan Audiologist Qualification Examination, showcasing effective logical reasoning skills. Our results suggest that with enhanced information accuracy, ChatGPT-4's performance could be further improved. This study indicates significant potential for the application of AI chatbots in audiology and hearing care services.	[Wang, Shangqiguo] Univ Hong Kong, Fac Educ, Human Commun Learning & Dev Unit, Hong Kong, Peoples R China; [Mo, Changgeng] Chinese Univ Hong Kong, Fac Med, Dept Otorhinolaryngol Head & Neck Surg, Hong Kong, Peoples R China; [Chen, Yuan] Educ Univ Hong Kong, Dept Special Educ & Counselling, Hong Kong, Peoples R China; [Dai, Xiaolu] Hong Kong Baptist Univ, Dept Social Work, Hong Kong, Peoples R China; [Wang, Huiyi] Zhejiang Univ, Childrens Hosp, Sch Med, Dept Med Serv, Hangzhou, Peoples R China; [Shen, Xiaoli] Ningbo Coll, Hlth Sch, Dept Hlth & Early Childhood Care, Ningbo, Peoples R China	University of Hong Kong; Chinese University of Hong Kong; Education University of Hong Kong (EdUHK); Hong Kong Baptist University; Zhejiang University; Ningbo University of Technology	Chen, Y (corresponding author), Educ Univ Hong Kong, Dept Special Educ & Counselling, Hong Kong, Peoples R China.	cheny@eduhk.hk		Dai, Xiaolu/0000-0002-0442-8130; Mo, Changgeng/0000-0002-2160-5485; CHEN, Yuan/0000-0001-6706-0962				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Durrant J, 1995, Bases of Hearing Science, P294; ELLIOTT LL, 1962, J ACOUST SOC AM, V34, P1108, DOI 10.1121/1.1918253; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Kleebayoon A, 2023, CLIN EXP DERMATOL, DOI 10.1093/ced/llad202; Kochanek K, 2023, PREPRINT, DOI [10.1101/2023.11.22.23298893, DOI 10.1101/2023.11.22.23298893]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Ministry of Examination ROC (Taiwan), 2023, Post-examination question inquiry platform; OpenAI, 2023, CHATGPT; Oztermeli AD, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000034673; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sooful P, 2023, Hear J, V76, P000, DOI [10.1097/01.HJ.0000995264.80206.87, DOI 10.1097/01.HJ.0000995264.80206.87]; Swanepoel De Wet, 2023, Hear J, V76, P26, DOI DOI 10.1097/01.HJ.0000927336.03567.3; Taira Kazuya, 2023, JMIR Nurs, V6, pe47305, DOI 10.2196/47305; Tal A, 2023, AM J BIOETHICS, V23, P74, DOI 10.1080/15265161.2023.2250297; Vaid A, 2023, LANCET DIGIT HEALTH, V5, pE855, DOI 10.1016/S2589-7500(23)00202-9; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Wang XF, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100905; Wasmann JWA, 2021, EAR HEARING, V42, P1499, DOI 10.1097/AUD.0000000000001041; Watari T, 2023, JMIR MED EDUC, V9, DOI 10.2196/52202; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589	34	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e55595	10.2196/55595	http://dx.doi.org/10.2196/55595			10	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	TL0J3	38693697	gold, Green Published			2024-07-03	WOS:001241297100001
J	Baglivo, F; De Angelis, L; Casigliani, V; Arzilli, G; Privitera, GP; Rizzo, C				Baglivo, Francesco; De Angelis, Luigi; Casigliani, Virginia; Arzilli, Guglielmo; Privitera, Gaetano Pierpaolo; Rizzo, Caterina			Exploring the Possible Use of AI Chatbots in Public Health Education: Feasibility Study	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; chatbots; medical education; vaccination; public health; medical students; large language model; generative AI; ChatGPT; Google Bard; AI chatbot; health education; health care; medical training; educational support tool; chatbot model		Background: Artificial intelligence (AI) is a rapidly developing field with the potential to transform various aspects of health care and public health, including medical training. During the "Hygiene and Public Health" course for fifth-year medical students, a practical training session was conducted on vaccination using AI chatbots as an educational supportive tool. Before receiving specific training on vaccination, the students were given a web-based test extracted from the Italian National Medical Residency Test. After completing the test, a critical correction of each question was performed assisted by AI chatbots.Objective: The main aim of this study was to identify whether AI chatbots can be considered educational support tools for training in public health. The secondary objective was to assess the performance of different AI chatbots on complex multiple-choice medical questions in the Italian language.Methods: A test composed of 15 multiple-choice questions on vaccination was extracted from the Italian National Medical Residency Test using targeted keywords and administered to medical students via Google Forms and to different AI chatbot models (Bing Chat, ChatGPT, Chatsonic, Google Bard, and YouChat). The correction of the test was conducted in the classroom, focusing on the critical evaluation of the explanations provided by the chatbot. A Mann-Whitney U test was conducted to compare the performances of medical students and AI chatbots. Student feedback was collected anonymously at the end of the training experience.Results: In total, 36 medical students and 5 AI chatbot models completed the test. The students achieved an average score of 8.22 (SD 2.65) out of 15, while the AI chatbots scored an average of 12.22 (SD 2.77). The results indicated a statistically significant difference in performance between the 2 groups (U=49.5, P<.001), with a large effect size (r=0.69). When divided by question type (direct, scenario-based, and negative), significant differences were observed in direct (P<.001) and scenario-based (P<.001) questions, but not in negative questions (P=.48). The students reported a high level of satisfaction (7.9/10) with the educational experience, expressing a strong desire to repeat the experience (7.6/10).Conclusions: This study demonstrated the efficacy of AI chatbots in answering complex medical questions related to vaccination and providing valuable educational support. Their performance significantly surpassed that of medical students in direct and scenario-based questions. The responsible and critical use of AI chatbots can enhance medical education, making it an essential aspect to integrate into the educational system.	[Baglivo, Francesco; De Angelis, Luigi; Casigliani, Virginia; Arzilli, Guglielmo; Privitera, Gaetano Pierpaolo; Rizzo, Caterina] Univ Pisa, Dept Translat Res & New Technol Med & Surg, Pisa, PI, Italy; [Privitera, Gaetano Pierpaolo] Natl Inst Hlth, Training Off, Rome, Italy; [Baglivo, Francesco] Univ Pisa, Dept Translat Res & New Technol Med & Surg, Via San Zeno 35, I-56123 Pisa, PI, Italy	University of Pisa; Istituto Superiore di Sanita (ISS); University of Pisa	Baglivo, F (corresponding author), Univ Pisa, Dept Translat Res & New Technol Med & Surg, Via San Zeno 35, I-56123 Pisa, PI, Italy.	f.baglivo@studenti.unipi.it	Rizzo, Caterina/H-4092-2012; Arzilli, Guglielmo/JDW-2714-2023	Rizzo, Caterina/0000-0002-5583-7508; Casigliani, Virginia/0000-0002-4184-2648; Arzilli, Guglielmo/0000-0003-1258-1650; Baglivo, Francesco/0000-0001-9391-7966; De Angelis, Luigi/0009-0005-6136-6596; PRIVITERA, GAETANO PIERPAOLO/0000-0002-8638-2462				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Bard, 2023, About us; Chaiyo Y, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL ARTS, MEDIA AND TECHNOLOGY (ICDAMT): DIGITAL ECONOMY FOR SUSTAINABLE GROWTH, P178, DOI 10.1109/ICDAMT.2017.7904957; ChatGPT, 2023, US; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Cooper A, 2023, NEW ENGL J MED, V389, P385, DOI 10.1056/NEJMp2304993; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee KY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00843-6; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Mentalcapacitylawandpolicy, About Us; Mheidly N, 2020, J PUBLIC HEALTH POL, V41, P410, DOI 10.1057/s41271-020-00247-w; Microsoft, 2023, Bing Chat; Moldt JA, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2182659; OpenAI, GPT-4 Technical Report; Rai S, 2023, Fortune; Rauschert E. S. J., 2019, Bull. Ecol. Soc. America, V100, pe01468, DOI [10.1002/bes2.1468, DOI 10.1002/BES2.1468]; Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schachner T, 2020, J MED INTERNET RES, V22, DOI 10.2196/20701; ScholarAI, 2023, about us; Tarchi L, 2021, ITAL J MED, V15, P99, DOI 10.4081/itjm.2021.1470; Thangaraju P, 2019, CUKUROVA MED J, V44, P1150, DOI 10.17826/cumj.514157; World Health Organization, 2022, Global competency framework for universal health coverage; writesonic, 2023, Chatsonic-best ChatGPT alternative for content creation; you, 2023, about us; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712	31	5	5	19	25	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e51421	10.2196/51421	http://dx.doi.org/10.2196/51421			10	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Y8BN2	37910155	Green Published, gold			2024-07-03	WOS:001107458100002
J	Qureshi, R; Irfan, M; Ali, H; Khan, A; Nittala, AS; Ali, S; Shah, AB; Gondal, TM; Sadak, F; Shah, ZB; Hadi, MU; Khan, S; Al-Tashi, Q; Wu, J; Bermak, A; Alam, T				Qureshi, Rizwan; Irfan, Muhammad; Ali, Hazrat; Khan, Arshad; Nittala, Aditya Shekhar; Ali, Shawkat; Shah, Abbas; Gondal, Taimoor Muzaffar; Sadak, Ferhat; Shah, Zubair; Hadi, Muhammad Usman; Khan, Sheheryar; Al-Tashi, Qasem; Wu, Jia; Bermak, Amine; Alam, Tanvir			Artificial Intelligence and Biosensors in Healthcare and Its Clinical Relevance: A Review	IEEE ACCESS			English	Review						Medical services; Machine learning; Biological system modeling; Predictive models; Biosensors; Medical diagnostic imaging; Data models; Artificial intelligence; explainable AI; medical imaging; domain adaptation; biosensors; federated learning; big data analytics; large language models	DRUG-SENSITIVITY; DATA FUSION; BIG DATA; CHALLENGES; NETWORK; ALGORITHMS; DISCOVERY; RESOURCE; GENOMICS; PRIVACY	Data generated from sources such as wearable sensors, medical imaging, personal health records, and public health organizations have resulted in a massive information increase in the medical sciences over the last decade. Advances in computational hardware, such as cloud computing, graphical processing units (GPUs), Field-programmable gate arrays (FPGAs) and tensor processing units (TPUs), provide the means to utilize these data. Consequently, an array of sophisticated Artificial Intelligence (AI) techniques have been devised to extract valuable insights from the extensive datasets in the healthcare industry. Here, we present an overview of recent progress in AI and biosensors in medical and life sciences. We discuss the role of machine learning in medical imaging, precision medicine, and biosensors for the Internet of Things (IoT). We review the latest advancements in wearable biosensing technologies. These innovative solutions employ AI to assist in monitoring of bodily electro-physiological and electro-chemical signals, as well as in disease diagnosis. These advancements exemplify the trend towards personalized medicine, delivering highly effective, cost-efficient, and precise point-of-care treatment.Furthermore, an overview of the advances in computing technologies, such as accelerated AI, edge computing, and federated learning for medical data, are also documented. Finally, we investigate challenges in data-driven AI approaches, the potential issues generated by biosensors and IoT-based healthcare, and the distribution shifts that occur among different data modalities, concluding with an overview of future prospects.	[Qureshi, Rizwan; Al-Tashi, Qasem; Wu, Jia] Univ Texas Houston, MD Anderson Canc Ctr, Dept Imaging Phys, Houston, TX 77030 USA; [Irfan, Muhammad] Ghulam Ishaq Khan Inst Engn Sci & Technol GIKI, Fac Elect Engn, Swabi 23460, Pakistan; [Ali, Hazrat; Khan, Arshad; Shah, Zubair; Bermak, Amine; Alam, Tanvir] Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar; [Nittala, Aditya Shekhar] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada; [Ali, Shawkat] King Abdullah Univ Sci & Technol, Dept Elect & Comp Engn, Thuwal 23955, Saudi Arabia; [Shah, Abbas] Mehran Univ Engn & Technol, Dept Elect Engn, Jamshoro 76062, Pakistan; [Gondal, Taimoor Muzaffar] Super Univ Lahore, Fac Engn, Lahore 54000, Pakistan; [Sadak, Ferhat] Sorbonne Univ, Inst Syst Intelligents & Robot, CNRS, ISIR, F-75005 Paris, France; [Sadak, Ferhat] Bartin Univ, Dept Mech Engn, TR-74100 Bartin, Turkiye; Ulster Univ, Nanotechnol & Integrated Bioengn Ctr NIBEC, Sch Engn, Belfast BT15 1AP, North Ireland; Hong Kong Polytech Univ, Sch Profess Educ & Execut Dev, Hong Kong, Peoples R China	University of Texas System; UTMD Anderson Cancer Center; University of Texas Health Science Center Houston; Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; University of Calgary; King Abdullah University of Science & Technology; Mehran University Engineering & Technology; Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS); Bartin University; Ulster University; Hong Kong Polytechnic University	Alam, T (corresponding author), Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar.	talam@hbku.edu.qa	Gondal, Taimoor Muzaffar/V-9108-2019; Hadi, Muhammad Usman/K-2083-2019; Qureshi, Rizwan/AFS-3131-2022; AL-TASHI, QASEM/O-1632-2019; Ali, Hazrat/J-2920-2019; SADAK, FERHAT/CAG-0189-2022; Khan, Arshad/GLS-8736-2022; khan, Sheheryar/JZD-4895-2024; khan, sheheryar/AAV-2517-2021	Gondal, Taimoor Muzaffar/0000-0002-4088-4651; Hadi, Muhammad Usman/0000-0002-3363-2886; Qureshi, Rizwan/0000-0002-0039-982X; AL-TASHI, QASEM/0000-0001-7208-693X; Ali, Hazrat/0000-0003-3058-5794; SADAK, FERHAT/0000-0003-2391-4836; Khan, Arshad/0000-0003-2858-4653; khan, sheheryar/0000-0002-1975-4334	Research Grants Council of the Hong Kong SAR [UGC/FDS24/E18/22]; Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar; Qatar National Library (QNL), Qatar	Research Grants Council of the Hong Kong SAR(Hong Kong Research Grants Council); Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar(Qatar Foundation (QF)); Qatar National Library (QNL), Qatar	This work was supported in part by the Research Grants Council of the Hong Kong SAR under Grant UGC/FDS24/E18/22; and in part by Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar. Open access publication of this article was funded by the Qatar National Library (QNL), Qatar.	Abadi M., 2016, Tensorflow: A system for large-scale machine learning, V16, P265; Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027; Adadi A., 2020, Advances in Intelligent Systems and Computing, V1076, P327, DOI [DOI 10.1007/978-981-15-0947-631/FIGURES/1, 10.1007/978-981-15-0947-6_31, DOI 10.1007/978-981-15-0947-6_31, 10.1007/978-981-15-0947-6_31/FIGURES/1, DOI 10.1007/978-981-15-0947-6_31/FIGURES/1]; Ahmad W, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-13658-4; Ali H., 2022, Insights into Imaging, V13, P1; Ali Hazrat, 2022, Stud Health Technol Inform, V295, P201, DOI 10.3233/SHTI220697; Ali O, 2022, IEEE T CIRCUITS-II, V69, P4593, DOI 10.1109/TCSII.2022.3181132; Amal S, 2022, FRONT CARDIOVASC MED, V9, DOI 10.3389/fcvm.2022.840262; [Anonymous], 2023, BERG BIOTECHNOLOGY C; [Anonymous], 2023, ATOMWISE AI CO DRUG; [Anonymous], 2019, Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD); [Anonymous], 2012, Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium; Arsene CTC, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902833; Bairagya D., 2021, HYBRID ARTIFICIAL IN, P311; Bandodkar AJ, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav3294; Bender A, 2020, DRUG DISCOV TODAY, V26, P511, DOI 10.1016/j.drudis.2020.12.009; Bernal G, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P160, DOI 10.1145/3267242.3267268; Bica I, 2021, ADV NEUR IN, V34; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Boehm KM, 2022, NAT CANCER, V3, P723, DOI 10.1038/s43018-022-00388-9; Boggust A., 2022, P 2022 CHI C HUMAN F, P1; Bonawitz K, 2019, Arxiv, DOI arXiv:1902.01046; Bouhaddou M, 2016, NATURE, V540, pE9, DOI 10.1038/nature20580; Cai Q, 2019, IEEE ACCESS, V7, P133583, DOI 10.1109/ACCESS.2019.2941419; Callahan A, 2017, KEY ADVANCES IN CLINICAL INFORMATICS: TRANSFORMING HEALTH CARE THROUGH HEALTH INFORMATION TECHNOLOGY, P279, DOI 10.1016/B978-0-12-809523-2.00019-4; Callaway E, 2022, NATURE, V611, P211, DOI 10.1038/d41586-022-03539-1; Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113; Celi LA, 2008, CRIT CARE, V12, DOI 10.1186/cc7140; Chatterjee A, 2019, STROKE, V50; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Chen M., 2012, ARXIV; Chen Y, 2022, BMC MICROBIOL, V22, DOI 10.1186/s12866-022-02591-1; Chin L, 2011, NAT MED, V17, P297, DOI 10.1038/nm.2323; Choi D, 2020, Arxiv, DOI arXiv:1907.05550; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34; Cirkovic A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18097; Claassen J, 2019, NEW ENGL J MED, V380, P2497, DOI 10.1056/NEJMoa1812757; Cui FY, 2020, ACS SENSORS, V5, P3346, DOI 10.1021/acssensors.0c01424; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dayan I, 2021, NAT MED, V27, P1735, DOI 10.1038/s41591-021-01506-3; Dennis JM, 2019, LANCET DIABETES ENDO, V7, P442, DOI 10.1016/S2213-8587(19)30087-7; Dhruba A. R., 2021, COMPUT MATH METHOD M, P1; Dimitrov DV, 2016, HEALTHC INFORM RES, V22, P156; Doran D, 2017, Arxiv, DOI [arXiv:1710.00794, DOI 10.48550/ARXIV.1710.00794, 10.48550/arXiv.1710.00794]; Fawzi A, 2022, NATURE, V610, P47, DOI 10.1038/s41586-022-05172-4; Feingold EA, 2004, SCIENCE, V306, P636, DOI 10.1126/science.1105136; Fiscon G, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0613-y; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fröhlich H, 2018, BMC MED, V16, DOI 10.1186/s12916-018-1122-7; Froomkin, 2019, Arizona Law Review, V61, P33, DOI [10.2139/ssrn.3114347, DOI 10.2139/SSRN.3114347]; Gao J, 2020, NEURAL COMPUT, V32, P829, DOI 10.1162/neco_a_01273; Gaudillère M, 2021, DIABETES METAB, V47, DOI 10.1016/j.diabet.2021.101251; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Hafner M, 2017, NAT BIOTECHNOL, V35, P500, DOI 10.1038/nbt.3882; Haick H, 2021, ACS NANO, V15, P3557, DOI 10.1021/acsnano.1c00085; Hariharan G., 2020, GLOBAL HEALTHCARE IS, P95; Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x; Hassan MK, 2018, COMPUT ELECTR ENG, V70, P1034, DOI 10.1016/j.compeleceng.2018.02.032; He X, 2021, Arxiv, DOI [arXiv:1908.00709, DOI 10.1016/J.KNOSYS.2020.106622]; He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34; Jeyaraj PR, 2022, IETE J RES, V68, P1435, DOI 10.1080/03772063.2019.1649215; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Junaid S. B., APPL SCI; Kailkhura B, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0248-2; Karmaker SK, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3470918; Karolus Jakob, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3457142; Khan A, 2022, IEEE INT SYMP CIRC S, P1759, DOI 10.1109/ISCAS48785.2022.9937335; Khan A, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P341, DOI 10.1145/3332165.3347892; Khurana U, 2018, AAAI CONF ARTIF INTE, P3407; Kumari P, 2017, BIOSENS BIOELECTRON, V90, P298, DOI 10.1016/j.bios.2016.12.001; Kyono Trent, 2021, Advances in Neural Information Processing Systems, V34; Kyono Trent, 2020, Advances in Neural Information Processing Systems, V33, P1501; Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697; Langer SG, 2011, J DIGIT IMAGING, V24, P203, DOI 10.1007/s10278-010-9311-8; Lee SC, 2017, HEALTHC TECHNOL LETT, V4, P168, DOI 10.1049/htl.2017.0066; Li RM, 2019, JMIR MED INF, V7, DOI 10.2196/10788; Li ZP, 2020, IEEE CONSUM ELECTR M, V9, P8, DOI 10.1109/MCE.2019.2959108; Lobodzinski SS, 2013, PROG CARDIOVASC DIS, V56, P224, DOI 10.1016/j.pcad.2013.08.006; Lyskov S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063906; Ma YH, 2021, IEEE T MED IMAGING, V40, P3955, DOI 10.1109/TMI.2021.3101937; Magliacane S., 2018, P ADV NEUR INF PROC, V31, P1; Malwitz J., 2022, FALL RISK SCREEN DEV; Manickam P, 2022, BIOSENSORS-BASEL, V12, DOI 10.3390/bios12080562; Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722; Massat MB, 2018, APPL RADIOL, V47, P22; Mazura JC, 2012, J DIGIT IMAGING, V25, P347, DOI 10.1007/s10278-011-9429-3; Meskó B, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00333-z; Morris Garrett M., 2008, V443, P365, DOI 10.1007/978-1-59745-177-2_19; Moult J, 2005, CURR OPIN STRUC BIOL, V15, P285, DOI 10.1016/j.sbi.2005.05.011; Nasir N., 2023, Intell. Syst. Appl., V17; Navarro FCP, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-019-1724-1; Nittala A. S., 2021, NATURE COMMUN, V12, P1; Nittala AS, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376366; Nittala Aditya Shekhar, 2022, CHI C HUM FACTORS CO, P1; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pandey AK, 2020, IEEE ACCESS, V8, P40612, DOI 10.1109/ACCESS.2020.2976687; Panwar H, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110190; Papadatos G, 2015, J COMPUT AID MOL DES, V29, P885, DOI 10.1007/s10822-015-9860-5; Park SM, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.707581; Patil HK, 2014, IEEE INT CONGR BIG, P762, DOI 10.1109/BigData.Congress.2014.112; Pereira T, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9070827; Philippidis A., 2019, GEN EDGE, V1, P113; Qureshi R, 2023, IEEE ACM T COMPUT BI, V20, P238, DOI 10.1109/TCBB.2022.3141697; Hoffman RR, 2019, Arxiv, DOI arXiv:1812.04608; Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3; Rajan S. P., 2022, SMART SYSTEMS IND AP, P173; Ramesh J, 2021, HEALTHC TECHNOL LETT, V8, P45, DOI 10.1049/htl2.12010; Rawat B., 2023, Aptisi Transactions on Management (ATM), V7, P86, DOI [10.33050/atm.v7i1.1819, DOI 10.33050/ATM.V7I1.1819]; Ricci Lara M. A., 2022, NAT COMMUN, V13, P1; Ristevski B, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2017-0030; Sadak O, 2022, IEEE ACCESS, V10, P98633, DOI 10.1109/ACCESS.2022.3207207; Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264; Saponas TS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P515; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Sharma A., 2021, DATA ANALYTICS BIOIN, P281; Shaukat A, 2021, ENDOSC INT OPEN, V09, pE263, DOI 10.1055/a-1321-1317; Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198; Shimizu H, 2020, CANCER SCI, V111, P1452, DOI 10.1111/cas.14377; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Shwartz-Ziv R, 2017, Arxiv, DOI [arXiv:1703.00810, 10.48550/arXiv.1703.00810]; Sun YZ, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207358; Sundararajan Mukund, 2020, ICML, P9269; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629; Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW); Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003; Tuzel O., 2016, Advances in neural information processing systems., P469; Van Mechelen I, 2010, CHEMOMETR INTELL LAB, V104, P83, DOI 10.1016/j.chemolab.2010.04.012; Vayena E, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002689; Villanueva I, 2018, P IEEE 20 INT C E HL, P1; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vourvopoulos A, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P647, DOI 10.1145/3341162.3348383; Wang K., 2016, SCI PROGRAMMING-NETH, P1; Wang S., 2023, arXiv; Wang Yan., SCI ADV, V6, peabb7043; Waring J, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101822; Wen W, 2016, ADV NEUR IN, V29; Xu J, 2021, J HEALTHC INFORM RES, V5, P1, DOI 10.1007/s41666-020-00082-4; Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016; Yang WJ, 2013, NUCLEIC ACIDS RES, V41, pD955, DOI 10.1093/nar/gks1111; Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552; Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009; Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016; Yim O, 2015, QUANT METH PSYCHOL, V11, P8, DOI 10.20982/tqmp.11.1.p008; Yosinski J, 2014, ADV NEUR IN, V27; Zhang B, 2013, SCI REP-UK, V3, DOI 10.1038/srep01836; Zhang SS, 2019, IEEE REV BIOMED ENG, V12, P194, DOI 10.1109/RBME.2018.2864254; Zhou DD, 2022, J BIOMED INFORM, V133, DOI 10.1016/j.jbi.2022.104147; Zhu S., 2021, INT J MED INFORM, DOI [DOI 10.1016/J.IJMEDINF.2022.104828, 10.1016/j.ijmedinf.2022.104828]; Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	156	9	9	18	38	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						61600	61620		10.1109/ACCESS.2023.3285596	http://dx.doi.org/10.1109/ACCESS.2023.3285596			21	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	L0LL0		gold, Green Submitted			2024-07-03	WOS:001020255700001
J	Longo, L; Brcic, M; Cabitza, F; Choi, J; Confalonieri, R; Del Ser, J; Guidotti, R; Hayashi, Y; Herrera, F; Holzinger, A; Jiang, RC; Khosravi, H; Lecue, F; Malgieri, G; Paez, A; Samek, W; Schneider, J; Speith, T; Stumpf, S				Longo, Luca; Brcic, Mario; Cabitza, Federico; Choi, Jaesik; Confalonieri, Roberto; Del Ser, Javier; Guidotti, Riccardo; Hayashi, Yoichi; Herrera, Francisco; Holzinger, Andreas; Jiang, Richard; Khosravi, Hassan; Lecue, Freddy; Malgieri, Gianclaudio; Paez, Andres; Samek, Wojciech; Schneider, Johannes; Speith, Timo; Stumpf, Simone			Explainable Artificial Intelligence (XAI) 2.0: A manifesto of open challenges and interdisciplinary research directions	INFORMATION FUSION			English	Article						Explainable artificial intelligence; XAI; Interpretability; Manifesto; Open challenges; Interdisciplinarity; Ethical AI; Large language models; Trustworthy AI; Responsible AI; Generative AI; Multi-faceted explanations; -based; Causality; Actionable XAI; Falsifiability	BLACK-BOX; AI; REPRESENTATION; CLASSIFICATION; ARGUMENTATION; EXPLANATIONS; TAXONOMY; LEARNER; SYSTEMS	Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.	[Longo, Luca] Artificial Intelligence & Cognit Load Res Lab, Dublin, Ireland; [Longo, Luca] Technol Univ Dublin, Sch Comp Sci, Dublin, Ireland; [Brcic, Mario] Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia; [Cabitza, Federico] Univ Milano Bicocca, Milan, Italy; [Cabitza, Federico] IRCCS Osped Galeazzi St Ambrogio, Milan, Italy; [Choi, Jaesik] Korea Adv Inst Sci & Technol KAIST, Kim Jaechul Grad Sch AI, Daejeon, South Korea; [Choi, Jaesik] INEEJI Corp, Seongnam, South Korea; [Confalonieri, Roberto] Univ Padua, Dept Math, Padua, Italy; [Del Ser, Javier] TECNALIA, Basque Res & Technol Alliance BRTA, Derio, Spain; [Del Ser, Javier] Univ Basque Country, UPV EHU, Bilbao, Spain; [Del Ser, Javier; Herrera, Francisco] Univ Granada, DaSCI Andalusian Inst Data Sci & Computat Intellig, Dept Comp Sci & Artificial Intelligence, Granada, Spain; [Guidotti, Riccardo] Univ Pisa, Pisa, Italy; [Hayashi, Yoichi] Meiji Univ, Dept Comp Sci, Tokyo, Japan; [Holzinger, Andreas] Univ Nat Resources & Life Sci Vienna, Human Ctr AI Lab, Vienna, Austria; [Jiang, Richard] Univ Lancaster, Sch Comp & Commun, Lancaster, England; [Khosravi, Hassan] Univ Queensland, Brisbane, Australia; [Lecue, Freddy] INRIA, Natl Inst Res Digital Sci & Technol, Sophia Antipolis, France; [Malgieri, Gianclaudio] Leiden Univ, eLaw Ctr Law & Digital Technol, Leiden, Netherlands; [Paez, Andres] Univ Andes, Dept Philosophy, Bogota, Colombia; [Paez, Andres] Univ Los Andes, Ctr Res & Format Artificial Intelligence CinfonIA, Bogota, Colombia; [Samek, Wojciech] Tech Univ Berlin, Berlin, Germany; [Samek, Wojciech] Fraunhofer Heinrich Hertz Inst, Berlin, Germany; [Samek, Wojciech] Berlin Inst Fdn Learning & Data BIFOLD, Berlin, Germany; [Schneider, Johannes] Univ Liechtenstein, Dept Informat Syst & Comp Sci, Vaduz, Liechtenstein; [Speith, Timo] Univ Bayreuth, Dept Philosophy, Bayreuth, Germany; [Speith, Timo] Saarland Univ, Ctr Perspicuous Comp, Saarbrucken, Germany; [Stumpf, Simone] Univ Glasgow, Sch Comp Sci, Glasgow, Scotland	University of Zagreb; University of Milano-Bicocca; Korea Advanced Institute of Science & Technology (KAIST); University of Padua; University of Basque Country; University of Granada; University of Pisa; Meiji University; BOKU University; Lancaster University; University of Queensland; Inria; Leiden University; Leiden University - Excl LUMC; Universidad de los Andes (Colombia); Universidad de los Andes (Colombia); Technical University of Berlin; Fraunhofer Gesellschaft; University of Liechtenstein; University of Bayreuth; Saarland University; University of Glasgow	Longo, L (corresponding author), Technol Univ Dublin, Sch Comp Sci, Dublin, Ireland.	luca.longo@tudublin.ie	Páez, Andrés/AAG-1010-2021; Cabitza, Federico/JCO-4001-2023; Jiang, Richard/IXW-6120-2023; Longo, Luca/AFU-7537-2022	Páez, Andrés/0000-0002-4602-7490; Jiang, Richard/0000-0003-1721-9474; Longo, Luca/0000-0002-2718-5426; Speith, Timo/0000-0002-6675-154X	Volkswagen Foundation [AZ 9B830, AZ 98509, AZ 98514]; DFG [389792660, TRR 248]; Centro para el Desarrollo Tecnologico Industrial'(CDTI); European Union [AI4ES, CER -20211030]; Basque Government [IT1456-22]; Spanish grant [PID2020-119478GB-I00, 2022-0-00984]; Institute of Information & Communi- cations Technology Planning & Evaluation (IITP) - Korea government (MSIT) [ERC-2018-ADG G.A. 834756, G.A. 871042, 3264 del 28/12/2021]; European Commission under the NextGeneration EU programme National Recovery and Resilience Plan; Italian RI for Social Mining [PE00000013, FIS00001966]; Italian Project Fondo Italiano per la Scienza [FWF P-32554, 2022 PNRR 1409/22]; Italian project PRIN [H53D23008090001, KI-FOR 5363]; MUR; German Research Foundation (DFG);  [BIRD231830]	Volkswagen Foundation(Volkswagen); DFG(German Research Foundation (DFG)); Centro para el Desarrollo Tecnologico Industrial'(CDTI); European Union(European Union (EU)); Basque Government(Basque Government); Spanish grant(Spanish Government); Institute of Information & Communi- cations Technology Planning & Evaluation (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); European Commission under the NextGeneration EU programme National Recovery and Resilience Plan; Italian RI for Social Mining; Italian Project Fondo Italiano per la Scienza; Italian project PRIN(Ministry of Education, Universities and Research (MIUR)Research Projects of National Relevance (PRIN)); MUR(Ministry of Education, Universities and Research (MIUR)); German Research Foundation (DFG)(German Research Foundation (DFG)); 	T. Speith acknowledges funding support provided by the Volkswa- gen Foundation grants AZ 9B830, AZ 98509, and AZ 98514 "Explain- able Intelligent Systems" (EIS; https://explainable-intelligent.systems) and by the DFG grant 389792660 as part of TRR 248 (https://perspicuous-computing.science) . J. Del Ser acknowledges funding support from the 'Centro para el Desarrollo Tecnologico Industrial' (CDTI) , by the European Union (AI4ES, grant no. CER -20211030) , and by the Basque Government (MATHMODE, ref. IT1456-22) . F. Herrera acknowledges funding support by the Spanish grant PID2020-119478GB-I00 funded by MCIN/AEI/10.13039/501100011033. R. Confalonieri acknowledges funding support from the 'Neuro- symbolic XAI' project (BIRD231830) . J. Choi is supported by the Institute of Information & Communi- cations Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00984) . R. Guidotti acknowledges funding support provided by the funding schemes ERC-2018-ADG G.A. 834756 "XAI: Science and technology for the eXplanation of AI decision making" (https://xai-project.eu/) , "INFRAIA-01-2018-2019 - Integrating Activities for Advanced Commu- nities", G.A. 871042, "SoBigData++: European Integrated Infrastruc- ture for Social Mining and Big Data Analytics" (http:// www.sobigdata. eu) , by the European Commission under the NextGeneration EU pro-gramme National Recovery and Resilience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR) - Project: "SoBigData.it - Strengthen- ing the Italian RI for Social Mining and Big Data Analytics"- Prot. IR0000013 - Avviso n. 3264 del 28/12/2021, and M4C2-Investimento 1.3, Partenariato Esteso PE00000013-"FAIR-Future Artificial Intel- ligence Research"- Spoke 1 "Human-centered AI", and by the Italian Project Fondo Italiano per la Scienza FIS00001966 MIMOSA. A. Holzinger acknowledges funding support by the XAI Project of the Austrian Science Fund FWF P-32554. F. Cabitza acknowledges funding support provided by the Italian project PRIN 2022 PNRR 1409/22, InXAID-Interaction with eX- plainable Artificial Intelligence in (medical) Decision making. CUP: H53D23008090001 funded by MUR. W. Samek acknowledges funding support from the German Research Foundation (DFG) as research unit DeSBi (KI-FOR 5363) .	Abdi S, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P360, DOI 10.1145/3375462.3375520; Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156; Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190; Achtibat R, 2024, Arxiv, DOI arXiv:2402.05602; Achtibat R, 2023, NAT MACH INTELL, V5, P1006, DOI 10.1038/s42256-023-00711-8; Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Agarwal C, 2022, ADV NEURAL INFORM PR, V35, P15784; Ahmed T, 2023, INFORMATION, V14, DOI 10.3390/info14090489; AI High-Level Expert Group, 2019, B-1049 Brussels; Ali A, 2022, PR MACH LEARN RES, P435; Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; Amari SI, 2016, APPL MATH SCI, V194, P1, DOI 10.1007/978-4-431-55978-8; [Anonymous], 2009, On Epistemology; Antoniadi AM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11115088; Arik SO, 2021, AAAI CONF ARTIF INTE, V35, P6679; Arras L, 2022, INFORM FUSION, V81, P14, DOI 10.1016/j.inffus.2021.11.008; Arya V, 2019, Arxiv, DOI arXiv:1909.03012; Augustin Maximilian, 2022, NEURIPS, P3; Austin LM, 2015, WORLD WITHOUT PRIVACY: WHAT LAW CAN AND SHOULD DO?, P131; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Badreddine S, 2022, ARTIF INTELL, V303, DOI 10.1016/j.artint.2021.103649; Baker RS, 2022, INT J ARTIF INTELL E, V32, P1052, DOI 10.1007/s40593-021-00285-9; Bansal Gagan, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445717; Bárcena JLC, 2023, COMPUT COMMUN, V210, P356, DOI 10.1016/j.comcom.2023.07.039; Baroni P, 2011, KNOWL ENG REV, V26, P365, DOI 10.1017/S0269888911000166; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Baum K., 2022, Philosophy and Technology, V35, P1, DOI DOI 10.1007/S13347-022-00510-W; Baum K., 2018, INT S ARTIFICIAL INT, P1; Baum K, 2019, ELECTRON P THEOR COM, P34, DOI 10.4204/EPTCS.286.4; Bayamlioglu Emre, 2018, Eur. Data Prot. L. Rev., V4, P433; Beckers S., 2022, P 1 C CAUS LEARN REA, P90, DOI DOI 10.48550/ARXIV.2201.13169; Bewley T., 2022, P 21 INT C AUTONOMOU, P118; Black Sid, 2022, arXiv; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bodker K., 2009, Participatory IT design: Designing for business and workplace realities; Bodria F, 2023, DATA MIN KNOWL DISC, V37, P1719, DOI 10.1007/s10618-023-00933-9; Boenisch F, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.729663; Bourtoule Lucas, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P141, DOI 10.1109/SP40001.2021.00019; Boutin V., 2023, INT C MACHINE LEARNI; Brcic M, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3603371; Bricken Trenton, 2023, Towards Monosemanticity: Decomposing Language Models with Dictionary Learning; Bruckert S, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.507973; Bull S, 2020, IEEE T LEARN TECHNOL, V13, P425, DOI 10.1109/TLT.2020.2978473; Bunt A, 2012, P 2012 ACM INT C INT, P169, DOI [10.1145/2166966.2166996., DOI 10.1145/2166966.2166996, 10.1145/2166966.2166996]; Bussmann N, 2021, COMPUT ECON, V57, P203, DOI 10.1007/s10614-020-10042-0; Cabitza Federico, 2021, Exploring Innovation in a Digital World: Cultural and Organizational Challenges. Lecture Notes in Information Systems and Organisation (51), P36, DOI 10.1007/978-3-030-87842-9_4; Cabitza F, 2023, ARTIF INTELL MED, V138, DOI 10.1016/j.artmed.2023.102506; Cabitza F, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118888; Cabitza F, 2022, LECT NOTES COMPUT SC, V13480, P31, DOI 10.1007/978-3-031-14463-9_3; Cabitza F, 2021, INT J HUM-COMPUT ST, V155, DOI 10.1016/j.ijhcs.2021.102696; Cammarata N., 2020, Thread: Circuits, DOI DOI 10.23915/DISTILL.00024; Cao LB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3502289; Carter JA, 2016, EPISTEMIC REASONS, NORMS AND GOALS, P423; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832; Chazette L, 2021, INT REQUIR ENG CONF, P197, DOI 10.1109/RE51729.2021.00025; Chazette L, 2020, REQUIR ENG, V25, P493, DOI 10.1007/s00766-020-00333-1; Chen CF, 2019, ADV NEUR IN, V32; Chou YL, 2022, INFORM FUSION, V81, P59, DOI 10.1016/j.inffus.2021.11.003; Cinquini M, 2024, Arxiv, DOI arXiv:2212.05256; Clinciu M.-A., 2019, P 1 WORKSH INT NAT L, P8, DOI [DOI 10.18653/V1/W19-8403, 10.18653/v1/W19-8403]; Coalition for Health AI, 2023, BLUEPRINT TRUSTWORTH; Cohen J, 2019, Between Truth and Power. The Legal Constructions of Informational Capitalism; Confalonieri R, 2024, IEEE INTELL SYST, V39, P18, DOI 10.1109/MIS.2023.3334639; Confalonieri R, 2021, ARTIF INTELL, V296, DOI 10.1016/j.artint.2021.103471; Confalonieri R, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1391; CostanzaChock S, 2020, INFORM POL, P1; Creel KA, 2020, PHILOS SCI, V87, P568, DOI 10.1086/709729; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Crook B, 2023, Intern Req Engg Work, P316, DOI 10.1109/REW57809.2023.00060; Cyras K., 2021, P 30 INT JOINT C ART, P4392, DOI DOI 10.24963/IJCAI.2021/600; de Graaf M., 2017, P AAAI FALL S, P19; de Vries H., 2019, VISUALLY GROUNDED IN; Deiseroth B, 2023, Arxiv, DOI arXiv:2301.08110; Del Ser J, 2024, INFORM SCIENCES, V655, DOI 10.1016/j.ins.2023.119898; Desmarais MC, 2012, USER MODEL USER-ADAP, V22, P9, DOI 10.1007/s11257-011-9106-8; Díaz-Rodríguez N, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101896; Dodge J, 2019, PROCEEDINGS OF IUI 2019, P275, DOI 10.1145/3301275.3302310; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040; du Boulay B, 2016, IEEE INTELL SYST, V31, P76, DOI 10.1109/MIS.2016.93; Du W., 2001, Proceedings of the 2001 workshop on New security paradigms, P13; Durán JM, 2021, ARTIF INTELL, V297, DOI 10.1016/j.artint.2021.103498; Ehsan U, 2022, PREPRINT; El Zini J, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3529755; Elgin CZ, 2017, TRUE ENOUGH, P1, DOI 10.7551/mitpress/9780262036535.001.0001; Elhage Nelson, 2021, A mathematical framework for transformer circuits; Erasmus Adrian, 2021, Philos Technol, V34, P833, DOI 10.1007/s13347-020-00435-2; Fernandez A, 2019, IEEE COMPUT INTELL M, V14, P69, DOI 10.1109/MCI.2018.2881645; Ferrario A, 2022, IEEE ACCESS, V10, P82736, DOI 10.1109/ACCESS.2022.3196917; Flack JC, 2012, PHILOS T R SOC B, V367, P1802, DOI 10.1098/rstb.2011.0214; Fleisher W, 2022, EPISTEME-J INDIV SOC, V19, P534, DOI 10.1017/epi.2022.39; Freiesleben Timo, 2023, Explainable Artificial Intelligence: First World Conference, xAI 2023, Proceedings. Communications in Computer and Information Science (1901), P48, DOI 10.1007/978-3-031-44064-9_3; Fürnkranz J, 2020, MACH LEARN, V109, P853, DOI 10.1007/s10994-019-05856-5; Gao YY, 2022, Arxiv, DOI [arXiv:2212.03954, 10.48550/ARXIV.2212.03954]; Garreau D, 2020, PR MACH LEARN RES, V108, P1287; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Ghosh B., 2019, P IJCAI 2019 WORKSHO, P14; Gollob C, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091509; Gorishniy Y, 2021, ADV NEUR IN, V34; Graziani M, 2023, ARTIF INTELL REV, V56, P3473, DOI 10.1007/s10462-022-10256-8; Gregory J, 2003, INT J ENG EDUC, V19, P62; Grinsztajn L., 2022, Advances in Neural Information Processing Systems, V35, P507, DOI [10.48550/arXiv.2207.08815, DOI 10.48550/ARXIV.2207.08815]; Guidotti R, 2022, DATA MIN KNOWL DISC, DOI 10.1007/s10618-022-00831-6; Guidotti R, 2021, ARTIF INTELL, V291, DOI 10.1016/j.artint.2020.103428; Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Hamilton K., 2022, Semant. Web., P1; Hamon R, 2022, IEEE COMPUT INTELL M, V17, P72, DOI 10.1109/MCI.2021.3129960; Hamon R, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P549, DOI 10.1145/3442188.3445917; Han T., 2020, Adv. Neural Inf. Process. Syst, V35; Hancock G., 2021, HDB HUMAN FACTORS ER, P203, DOI DOI 10.1002/9781119636113.CH7; Haresamudram K, 2023, COMPUTER, V56, P93, DOI 10.1109/MC.2022.3213181; Hatwell J, 2020, ARTIF INTELL REV, V53, P5747, DOI 10.1007/s10462-020-09833-6; Hedstrom A., 2023, Journal of Machine Learning Research, V24, P1; Henin C., 2021, AI Ethics., V1, P463; Henin C, 2022, AI SOC, V37, P1397, DOI 10.1007/s00146-021-01251-8; Heuillet A, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106685; Hinder F, 2020, Arxiv, DOI arXiv:2006.12822; Hiremath G., 2018, INT J ADV RES IDEAS, V4, P37; Holmes W, 2022, INT J ARTIF INTELL E, V32, P504, DOI 10.1007/s40593-021-00239-1; Holstein K, 2019, J LEARN ANAL, V6, P27, DOI 10.18608/jla.2019.62.3; Holzinger A., 2022, Eur. Res. Consort. Informatics Math.(ERCIM) News, V130, P40; Holzinger A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22083043; Holzinger A, 2021, COMM COM INF SC, V1524, P427, DOI 10.1007/978-3-030-93736-2_33; Holzinger A, 2022, INFORM FUSION, V79, P263, DOI 10.1016/j.inffus.2021.10.007; Huang X., 2023, 26 EUROPEAN C ARTIFI, V372, P1100; Huang X, 2020, Arxiv, DOI [arXiv:2012.06678, 10.48550/arXiv.2012.06678, DOI 10.48550/ARXIV.2012.06678]; Huang XX, 2023, Arxiv, DOI arXiv:2306.03048; Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215; Juric M, 2020, 2020 43RD INTERNATIONAL CONVENTION ON INFORMATION, COMMUNICATION AND ELECTRONIC TECHNOLOGY (MIPRO 2020), P1254; Kästner L, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P169, DOI 10.1109/REW53955.2021.00031; Kaminski M.E., 2020, Int. Data Priv. Law., P19; Keane M. T., 2021, P 13 INT JOINT C ART, P4466; Khalifa K, 2012, PHILOS SCI, V79, P15, DOI 10.1086/663235; Khan A, 2023, Arxiv, DOI arXiv:2212.00622; Khosravi H, 2019, J LEARN ANAL, V6, P91, DOI 10.18608/jla.2019.63.12; Kim B, 2018, PR MACH LEARN RES, V80; Kirchenbauer J., 2023, P 40 INT C MACHINE L; Kizilcec R.F, 2022, The ethics of artificial intelligence in education, P174; Kizilcec RF, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2390, DOI 10.1145/2858036.2858402; Klinger T, 2020, Arxiv, DOI arXiv:2006.09437; Köhl MA, 2019, INT REQUIR ENG CONF, P363, DOI 10.1109/RE.2019.00046; Koh PW, 2020, ICML, P5338; Krajna Agneza, 2022, 2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)., P859, DOI 10.23919/MIPRO55190.2022.9803681; Krajna A., 2022, arXiv; Krakauer D., 2014, BioScience, V64, P351, DOI DOI 10.1093/BIOSCI/BIU024; Krakauer D.C., 2023, Front. Complex Syst., V1, DOI [10.3389/fcpxs.2023.1235202, DOI 10.3389/FCPXS.2023.1235202]; Krishnan M., 2020, Philosophy & Technology, V33, P487, DOI [10.1007/s13347019003729, DOI 10.1007/S13347019003729, DOI 10.1007/S13347-019-00372-9]; Kuppa A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206780; Kvanvig J., 2009, EPISTEMIC VALUE, P339; Langer M, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P164, DOI 10.1109/REW53955.2021.00030; Langer M, 2021, ARTIF INTELL, V296, DOI 10.1016/j.artint.2021.103473; Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4; Lapuschkin S, 2017, IEEE INT CONF COMP V, P1629, DOI 10.1109/ICCVW.2017.191; Leavitt M.L., 2020, NEURIPS 2020 WORKSHO; Lecue F, 2020, SEMANT WEB, V11, P41, DOI 10.3233/SW-190374; Lipton P., 2009, SCI UNDERSTANDING PH, P43, DOI DOI 10.2307/J.CTT9QH59S.6; Lipton ZC., 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340; Liu ZM, 2023, Arxiv, DOI [arXiv:2305.08746, DOI 10.48550/ARXIV.2305.08746]; Liz-Domínguez M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245569; Lombrozo T., 2019, Varieties of Understanding: New Perspectives from Philosophy, Psychology, and Theology, P209, DOI DOI 10.1093/OSO/9780190860974.003.0011; Longo Luca, 2012, User Modeling, Adaptation, and Personalization. Proceedings 20th International Conference, UMAP 2012, P369, DOI 10.1007/978-3-642-31454-4_38; Longo L, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.883321; Longo L, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106514; Longo L, 2020, ADV INTELL SYST COMP, V1068, P1, DOI 10.1007/978-3-030-31787-4_1; Longo L, 2016, LECT NOTES COMPUT SC, V9605, P183, DOI 10.1007/978-3-319-50478-0_9; Longo L, 2015, COMP MED SY, P364, DOI 10.1109/CBMS.2015.67; Lucic A, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P90, DOI 10.1145/3351095.3372824; Luckin R., 2016, Intelligence unleashed. An argument for AI in education; Lundberg SM, 2017, ADV NEUR IN, V30; Machlev R, 2022, ENERGY AI, V9, DOI 10.1016/j.egyai.2022.100169; Malgieri G, 2021, Law Bus, V1, P16; Malgieri G, 2023, J CONSUM MARK, V40, P209, DOI 10.1108/JCM-03-2021-4571; Mantelero A, 2022, Beyond data: human rights, ethical and social impact assessment in ai; Mao J., 2019, 7 INT C LEARNING REP; Markus AF, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103655; Marques-Silva J, 2024, Arxiv, DOI [arXiv:2307.07514, 10.48550/arXiv.2307.07514, DOI 10.48550/ARXIV.2307.07514]; Mei Y, 2023, IEEE T EVOLUT COMPUT, V27, P621, DOI 10.1109/TEVC.2022.3225509; Meske C, 2022, INFORM SYST MANAGE, V39, P53, DOI 10.1080/10580530.2020.1849465; Metta C., 2022, P HHAI2022 AUGMENTIN, V354, P258; Miller T., 2017, P IJCAI 2017 WORKSHO, V36, P36, DOI DOI 10.1016/J.FOODCHEM.2017.11.091; Miller T, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P333, DOI 10.1145/3593013.3594001; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Minh D, 2022, ARTIF INTELL REV, V55, P3503, DOI 10.1007/s10462-021-10088-y; Mishra S, 2023, Arxiv, DOI arXiv:2111.00358; Mittelstadt B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P279, DOI 10.1145/3287560.3287574; Mizrahi M, 2012, PHILOS STUD, V160, P237, DOI 10.1007/s11098-011-9716-3; Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166; Mollmann TB, 2017, ANN FOREST SCI, V74, DOI 10.1007/s13595-017-0670-x; Müller H, 2021, ARTIF INTELL, V300, DOI 10.1016/j.artint.2021.103546; Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116; Nanda N, 2023, Arxiv, DOI arXiv:2301.05217; Natale Simone, 2021, Deceitful media: Artificial intelligence and social life after the Turing test; Nauta M, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3583558; Nauta M, 2021, PROC CVPR IEEE, P14928, DOI 10.1109/CVPR46437.2021.01469; Newman J., 2023, CLTC White Paper Series.; Nguyen Anh, 2016, P NEURIPS 2016, V29, P3387, DOI DOI 10.5555/3157382.3157477; Nguyen TT, 2022, Arxiv, DOI [arXiv:2209.02299, DOI 10.48550/ARXIV.2209.02299]; Nielsen IE, 2022, IEEE SIGNAL PROC MAG, V39, P73, DOI 10.1109/MSP.2022.3142719; Oksuz AC, 2023, Arxiv, DOI arXiv:2302.02162; Olah C., 2020, DISTILL, V5, DOI [10.2 3915/distill.00024.001, DOI 10.23915/DISTILL.00024.001]; Páez A, 2019, MIND MACH, V29, P441, DOI 10.1007/s11023-019-09502-w; Pahde F, 2023, LECT NOTES COMPUT SC, V14221, P596, DOI 10.1007/978-3-031-43895-0_56; Palladino N, 2023, TELECOMMUN POLICY, V47, DOI 10.1016/j.telpol.2022.102479; Papenmeier A, 2019, Arxiv, DOI [arXiv:1907.12652, DOI 10.48550/ARXIV.1907.12652]; Paris C.L, 1991, Natural Language Generation in Artificial Intelligence and Computational Linguistics, P49; Pirozelli P., 2022, Philos. Technol, V35, P23; Pritchard D., 2008, Knowing the Answer, Understanding and Epistemic Value.; Qiu LY, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3594, DOI 10.1145/3485447.3512254; Quine W, 1953, From a Logical Point of View; Hoffman RR, 2019, Arxiv, DOI arXiv:1812.04608; Rauker T, 2023, 2023 IEEE CONFERENCE ON SECURE AND TRUSTWORTHY MACHINE LEARNING, SATML, P464, DOI 10.1109/SaTML54575.2023.00039; Rawal Atul, 2022, IEEE Transactions on Artificial Intelligence, V3, P852, DOI 10.1109/TAI.2021.3133846; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rizzo L., 2018, P 26 AIAI IRISH C AR, P138; Rizzo L., 2018, P 2 WORKSHOP ADV ARG, P11; Rizzo L, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113220; Rizzo L, 2018, LECT NOTES ARTIF INT, V11298, P197, DOI 10.1007/978-3-030-03840-3_15; Robbins S, 2019, MIND MACH, V29, P495, DOI 10.1007/s11023-019-09509-3; Rodríguez-Barroso N, 2023, INFORM FUSION, V90, P148, DOI 10.1016/j.inffus.2022.09.011; Rojat T, 2021, Arxiv, DOI arXiv:2104.00950; Rokach L, 2016, INFORM FUSION, V27, P111, DOI 10.1016/j.inffus.2015.06.005; Rudin C., 2019, HARVARD DATA SCI REV, V1, DOI [DOI 10.1162/99608F92.5A8A3A3D, 10.1162/99608f92.5a8a3a3d]; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Rymarczyk D, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1420, DOI 10.1145/3447548.3467245; S Band Shahab, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101286; Sachan S, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113100; Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483; Sanchez P., 2022, C CAUSAL LEARNING RE; Sarker MK, 2021, AI COMMUN, V34, P197, DOI 10.3233/AIC-210084; Schneider J., 2021, DATASCIENCE ANALYTIC, P89; Schneider Johanes, 2019, EUROPEAN C INFORM SY; Schneider J, 2023, Arxiv, DOI arXiv:2005.13635; Schneider J, 2024, Arxiv, DOI arXiv:2302.00722; Schneider J, 2023, DATA MIN KNOWL DISC, DOI 10.1007/s10618-023-00920-0; Schneider J, 2022, IEEE SEC PRIV WORKS, P66, DOI 10.1109/SPW54247.2022.9833874; Schneider J, 2022, ICAART, P44, DOI 10.5220/0010768300003116; Schneider J, 2023, MACH LEARN, V112, P4167, DOI 10.1007/s10994-022-06157-0; Schwalbe G, 2023, DATA MIN KNOWL DISC, DOI 10.1007/s10618-022-00867-8; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Seuss D., 2021, arXiv; Sevillano-García I, 2023, INT J INTELL SYST, V2023, DOI 10.1155/2023/8068569; Sharma S., 2022, Carbon Res., V1, P21, DOI DOI 10.1007/S44246-022-00021-5; Simonyan Karen, 2014, WORKSH INT C LEARN R, P2; Singh A, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P81, DOI 10.1145/3051457.3051466; Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830; Sokol K, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P56, DOI 10.1145/3351095.3372870; Speith Timo, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2239, DOI 10.1145/3531146.3534639; Speith T, 2023, Intern Req Engg Work, P325, DOI 10.1109/REW57809.2023.00061; Speith T, 2022, INT REQUIR ENG CONF, P92, DOI 10.1109/REW56159.2022.00024; Strevens M, 2013, STUD HIST PHILOS SCI, V44, P510, DOI 10.1016/j.shpsa.2012.12.005; Sullivan E, 2022, BRIT J PHILOS SCI, V73, P109, DOI 10.1093/bjps/axz035; SWARTOUT W, 1991, IEEE EXPERT, V6, P58, DOI 10.1109/64.87686; Theissler A, 2022, IEEE ACCESS, V10, P100700, DOI 10.1109/ACCESS.2022.3207765; Thornton S., 2023, The Stanford Encyclopedia of Philosophy.; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tiddi I, 2022, ARTIF INTELL, V302, DOI 10.1016/j.artint.2021.103627; Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314; Topal MO, 2021, Arxiv, DOI arXiv:2102.08036; Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X; van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151; VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369; Vassiliades A, 2021, KNOWL ENG REV, V36, DOI 10.1017/S0269888921000011; Vielhaben J, 2024, PATTERN RECOGN, V150, DOI 10.1016/j.patcog.2024.110309; Vilone G., 2022, 1 INT WORKSHOP ARGUM, V3209; Vilone G, 2022, IFIP ADV INF COMM TE, V646, P447, DOI 10.1007/978-3-031-08333-4_36; Vilone G, 2021, MACH LEARN KNOW EXTR, V3, P615, DOI 10.3390/make3030032; Vilone G, 2021, INFORM FUSION, V76, P89, DOI 10.1016/j.inffus.2021.05.009; Weber L, 2023, INFORM FUSION, V92, P154, DOI 10.1016/j.inffus.2022.11.013; Weller A., 2019, Lecture Notes in Computer Science, V11700, P23, DOI [10.1007/978-3-030-28954-62, DOI 10.1007/978-3-030-28954-62]; Wilsdon L, 2022, Carissa veliz, privacy is power: Why and how you should take back control of your data; Yampolski R.V., 2020, Journal of Artificial Intelligence and Consciousness, V7, P277, DOI DOI 10.1142/S2705078520500150; Yampolskiy RV, 2017, PHYS SCRIPTA, V92, DOI 10.1088/1402-4896/aa7ca8; Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016; Yang L, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3626235; Yeh CK, 2019, ADV NEUR IN, V32; Yeom SK, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107899; Yi Kexin, 2020, Clevrer: Collision events for video representation and reasoning; Yuan JY, 2023, IEEE T PATTERN ANAL, V45, P11540, DOI 10.1109/TPAMI.2023.3286184; Zarlenga M. E., 2022, arXiv; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zednik C., 2021, Philosophy & technology, V34, P265, DOI [DOI 10.1007/S13347-019-00382-7, 10.1007/s13347-019-00382-7]; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeng ZW, 2018, AAAI CONF ARTIF INTE, P8044; Zerilli J, 2022, PHILOS SCI, V89, P1, DOI 10.1017/psa.2021.13; Zhang SD, 2023, Arxiv, DOI [arXiv:2305.14699, 10.48550/arXiv.2305.14699, DOI 10.48550/ARXIV.2305.14699]; Zhong ZQ, 2023, Arxiv, DOI arXiv:2306.17844; Zhou JL, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050593; Zhu B., 2023, INT C MACHINE LEARNI, V202, P43037; Zimmermann RS, 2024, Arxiv, DOI arXiv:2307.05471	293	10	10	13	13	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	JUN	2024	106								102301	10.1016/j.inffus.2024.102301	http://dx.doi.org/10.1016/j.inffus.2024.102301		FEB 2024	22	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NJ3N7		Green Submitted, hybrid			2024-07-03	WOS:001200047100001
C	Becker, BA; Denny, P; Finnie-Ansley, J; Luxton-Reilly, A; Prather, J; Santos, EA			ACM	Becker, Brett A.; Denny, Paul; Finnie-Ansley, James; Luxton-Reilly, Andrew; Prather, James; Santos, Eddie Antonio			Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation	PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023			English	Proceedings Paper	54th Annual ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS)	MAR 15-18, 2023	Toronto, CANADA	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		AI; AlphaCode; Amazon; artificial intelligence; code generation; CodeWhisperer; Codex; Copilot; CS1; CS2; GitHub; Google; GPT-3; introductory programming; large language model; LLM; machine learning; Midjourney; novice programmers; OpenAI; programming; Tabnine		The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.	[Becker, Brett A.; Santos, Eddie Antonio] Univ Coll Dublin, Dublin, Ireland; [Denny, Paul; Finnie-Ansley, James; Luxton-Reilly, Andrew] Univ Auckland, Auckland, New Zealand; [Prather, James] Abilene Christian Univ, Abilene, TX 79699 USA	University College Dublin; University of Auckland; Abilene Christian University	Becker, BA (corresponding author), Univ Coll Dublin, Dublin, Ireland.	brett.becker@ucd.ie; paul@cs.auckland.ac.nz; james.finnie-ansley@auckland.ac.nz; a.luxton-reilly@auckland.ac.nz; james.prather@acu.edu; eddie.santos@ucdconnect.ie	Luxton-Reilly, Andrew/ABC-5342-2021	Luxton-Reilly, Andrew/0000-0001-8269-2909; Finnie-Ansley, James/0000-0002-4279-6284; Denny, Paul/0000-0002-5150-9806				Ankur Desai, 2022, Introducing Amazon CodeWhisperer, the ML-powered Coding Companion; Beck K., 2000, Extreme Programming Explained: Embrace Change; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Becker BA, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P338, DOI 10.1145/3287324.3287432; Bender E. M., 2019, FUT ART INT LANG ETH; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Corda Stefano, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2210, 10.48550/arXiv.2210]; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Denny Paul, 2020, P 2020 ACM C INNOVAT, P480; Eckerdal A., 2005, SIGCSE Bulletin, V37, P89, DOI 10.1145/1151954.1067473; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Heikkila Melissa, 2022, DeepMind has Predicted the Structure of Almost Every Protein Known to Science; HEMBREE R, 1986, J RES MATH EDUC, V17, P83, DOI 10.2307/749255; Indriasari TD, 2020, ACM T COMPUT EDUC, V20, DOI 10.1145/3403935; Karvelas I, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P759, DOI 10.1145/3328778.3366882; Khlaaf H, 2022, Arxiv, DOI [arXiv:2207.14157, 10.48550/ARXIV.2207.14157, DOI 10.48550/ARXIV.2207.ARXIV, DOI 10.48550/ARXIV.2207.14157]; Knorr EM, 2019, PROCEEDINGS OF THE 24TH WESTERN CANADIAN CONFERENCE ON COMPUTING EDUCATION (WCCCE '19), DOI 10.1145/3314994.3325083; Lam J, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P703, DOI 10.1145/3478431.3499391; Lewkowycz Aitor, 2022, arXiv; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Luxton-Reilly A., 2016, Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education, P284, DOI DOI 10.1145/2899415.2899432; Luxton-Reilly A, 2018, ITICSE 2018 COMPANION: PROCEEDINGS COMPANION OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P55, DOI 10.1145/3293881.3295779; Luxton-Reilly A, 2009, COMPUT SCI EDUC, V19, P209, DOI 10.1080/08993400903384844; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; McDowell C., 2002, SIGCSE Bulletin, V34, P38, DOI 10.1145/563517.563353; Minelli R, 2015, INT C PROGRAM COMPRE, P25, DOI 10.1109/ICPC.2015.12; Dakhel AM, 2022, Arxiv, DOI [arXiv:2206.15331, DOI 10.48550/ARXIV.2206.15331]; Moroz E. A., 2022, 2022 C RUSS YOUNG RE, P386, DOI [10.1109/ElConRus54750.2022.9755659, DOI 10.1109/ELCONRUS54750.2022.9755659]; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pettit Raymond, 2017, Journal of Computing Sciences in Colleges, V32, P113; Ramesh A., 2022, arXiv; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Simon, 2016, P 2016 ITICSE WORK G, P57, DOI DOI 10.1145/3024906.3024910; SOLOWAY E, 1986, COMMUN ACM, V29, P850, DOI 10.1145/6592.6594; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Thompson Errol, 2006, P 19 ANN C NATL ADVI, P291; Towell Dwayne, 2010, ACET Journal of Computer Education and Research, V6; Vaithilingam Priyan, 2022, CHI C HUM FACT COMP, P1; Winters T, 2022, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2022, VOL 1, P2, DOI 10.1145/3502718.3534205; Xie B, 2019, COMPUT SCI EDUC, V29, P205, DOI 10.1080/08993408.2019.1565235	43	54	54	12	12	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9431-4				2023							500	506		10.1145/3545945.3569759	http://dx.doi.org/10.1145/3545945.3569759			7	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW2KI		Bronze			2024-07-03	WOS:001117817800074
J	Cavari, A; Mate, A; Sebok, M				Cavari, Amnon; Mate, Akos; Sebok, Miklos			Staying on the democratic script? A deep learning analysis of the speechmaking of US presidents(sic)(sic)(sic)Palabras Clave	POLICY STUDIES JOURNAL			English	Article; Early Access						content analysis; deep learning; large language models; policy agendas; state of the union addresses; (sic)(sic)(sic)(sic); (sic)(sic)(sic)(sic)(sic)(sic); Agendas politicas; Presidencia estadounidense; Aprendizaje profundo	POLICY; PRESIDENTS; GOVERNMENT; AGENDA; NETHERLANDS; FULFILLMENT; DYNAMICS	Dynamic agenda representation assumes a linkage between the policy emphases prescribed by various democratic inputs (electoral promises and public opinion polls) and policy agendas ranging from the media to executive orders. An extrapolation of this idea would propose that, in the U.S. context, policy emphasis in major programmatic messages such as State of the Union addresses would be followed by the president's day-to-day communication. We investigate this congruence with a new database of presidential speeches that, for the first time, offers a deep learning-enhanced sentence-level policy topic coding of various forms of the speeches U.S. presidents made from Truman to Trump (for a total count of 16,523 speeches divided into nearly 2 million individual sentences). Using this database, we demonstrate that presidents' occasional, day-to-day remarks strongly correlate with the annual policy messages-in this sense, presidents are staying on the democratic script. ?"()""令".断??咨纲.库?库句offspring?杜鲁朗普(16,523 篇?200 句offspring).库??偶--?仍(democratic script). La representacion dinamica de la agenda supone un vinculo entre los enfasis politicos prescritos por diversos aportes democraticos (promesas electorales y encuestas de opinion publica) y agendas politicas que van desde los medios hasta las ordenes ejecutivas. Una extrapolacion de esta idea propondria que, en el contexto estadounidense, el enfasis politico en los principales mensajes programaticos, como los discursos sobre el Estado de la Union, seria seguido por la comunicacion diaria del presidente. Investigamos esta congruencia con una nueva base de datos de discursos presidenciales que, por primera vez, ofrece una codificacion de temas politicos a nivel de oracion mejorada con aprendizaje profundo de varias formas de los discursos que pronunciaron los presidentes de Estados Unidos, desde Truman hasta Trump (para un recuento total de 16,523 discursos divididos en casi 2 millones de frases individuales). Utilizando esta base de datos, demostramos que los comentarios ocasionales y cotidianos de los presidentes se correlacionan fuertemente con los mensajes politicos anuales; en este sentido, los presidentes se apegan al guion democratico.	[Cavari, Amnon] Reichman Univ, Lauder Sch Govt Diplomacy & Strategy, Herzliyya, Israel; [Mate, Akos; Sebok, Miklos] Ctr Social Sci, Dept Govt & Publ Policy, Budapest, Hungary; [Cavari, Amnon] Reichman Univ, 8 HaUniv St,POB 167, IL-46150 Herzliyya, Israel	Reichman University; Hungarian Academy of Sciences; Hungarian Research Network; HUN-REN Centre for Social Sciences; Reichman University	Cavari, A (corresponding author), Reichman Univ, 8 HaUniv St,POB 167, IL-46150 Herzliyya, Israel.	cavari@runi.ac.il			Artificial Intelligence National Laboratory of Hungary [101008468]; European Union [RRF- 2.3.1- 21- 2022- 00004]; Hungarian Academy of Sciences: V-Shift Momentum Project; Israel Science Foundation [1271/18]	Artificial Intelligence National Laboratory of Hungary; European Union(European Union (EU)); Hungarian Academy of Sciences: V-Shift Momentum Project; Israel Science Foundation(Israel Science Foundation)	Artificial Intelligence National Laboratory of Hungary, Grant/Award Number: 101008468; European Union, Grant/Award Number: RRF- 2.3.1- 21- 2022- 00004; Hungarian Academy of Sciences: V-Shift Momentum Project; Israel Science Foundation, Grant/Award Number: 1271/18	Barabas J, 2008, PRES STUD Q, V38, P195, DOI 10.1111/j.1741-5705.2008.02636.x; Barrett AW, 2004, AM POLIT RES, V32, P338, DOI 10.1177/1532673X03260580; Baum MA, 1999, AM POLIT SCI REV, V93, P99, DOI 10.2307/2585763; Baumgartner Frank R., 2019, Comparative Policy Agendas, P3; Bevan S., 2019, COMP POLICY AGENDAS, P17, DOI DOI 10.1093/OSO/9780198835332.003.0002; Bevan S, 2020, POLICY STUD J, V48, P111, DOI 10.1111/psj.12231; Bevan S, 2014, EUR J POLIT RES, V53, P37, DOI 10.1111/1475-6765.12023; Blumenthal Sidney., 1980, The Permanent Campaign: Inside the World of Elite Political Operatives; Boydstun AE., 2013, Making the News: Politics, the Media, and Agenda Setting; BUDGE I, 1990, AM POLIT SCI REV, V84, P111, DOI 10.2307/1963632; Campbell Karlyn Kohrs., 2008, Deeds Done in Words: Presidential Rhetoric and the Genres of Governance; Canes-Wrone Brandice., 2006, WHO LEADS WHOM PRESI; Cavari A., 2017, The Party Politics of Presidential Rhetoric; Cavari A, 2023, RES POLITICS, V10, DOI 10.1177/20531680231181750; Cavari A, 2021, AM POLIT RES, V49, P666, DOI 10.1177/1532673X211022630; Cavari A, 2013, POLIT RES QUART, V66, P336, DOI 10.1177/1065912912448931; Cohen BernardC., 1963, PRESS FOREIGN POLICY; Cohen JE, 2008, PRESIDENCY IN THE ERA OF 24-HOUR NEWS, P1; COHEN JE, 1995, AM J POLIT SCI, V39, P87, DOI 10.2307/2111759; Cohen JeffreyE., 2010, GOING LOCAL PRESIDEN; Cummins J, 2008, SOC SCI J, V45, P365, DOI 10.1016/j.soscij.2008.07.004; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Edwards GC, 2012, OVERREACH: LEADERSHIP IN THE OBAMA PRESIDENCY, P1; Edwards G.C., 2021, Changing their minds?: Donald Trump and presidential leadership; Edwards G.C., 2003, DEAF EARS LIMITS BUL; Edwards GeorgeC., 2016, Predicting the Presidency: The Potential of Persuasive Leadership; Edwards III GC, 2009, STRATEGIC PRESIDENT: PERSUASION AND OPPORTUNITY IN PRESIDENTIAL LEADERSHIP, P1; Eissler Rebecca., 2019, Comparative Policy Agendas: Theory, Tools, Data, P184; Eshbaugh-Soha M, 2005, POLIT RES QUART, V58, P127, DOI 10.2307/3595602; Eshbaugh-Soha M., 2011, Congress and the Presidency, V38, P301; Eshbaugh-Soha M, 2022, AM POLIT RES, V50, P117, DOI 10.1177/1532673X211042283; Eshbaugh-Soha Matthew., 2004, Congress the Presidency, V31, P181; Eshbaugh-Soha Matthew., 2016, Going Public and Presidential Leadership; FETT PJ, 1992, WESTERN POLIT QUART, V45, P895, DOI 10.2307/448817; FETT PJ, 1994, J POLIT, V56, P502, DOI 10.2307/2132151; Fontaine SA, 2020, PRES STUD Q, V50, P507, DOI 10.1111/psq.12676; Gergen David., 2008, Eyewitness to Power the Essence of Leadership Nixon to Clinton; Haeder SF, 2022, PRES STUD Q, V52, P436, DOI 10.1111/psq.12780; Heith Diane J., 2020, The End of the Rhetorical Presidency? Presidential Leadership in the Trump Era; Heith DianeJ., 2013, PRESIDENTIAL ROAD SH; Hoffman D.R., 2006, Addressing the State of the Union: The evolution and impact of the president's big speech; Jennings W, 2011, COMP POLIT STUD, V44, P1001, DOI 10.1177/0010414011405165; Jennings W, 2011, POLIT STUD-LONDON, V59, P74, DOI 10.1111/j.1467-9248.2010.00859.x; Jennings W, 2009, AM J POLIT SCI, V53, P838, DOI 10.1111/j.1540-5907.2009.00404.x; Jones B.D., 2023, Policy agendas project: codebook; Kernell Samuel., 2007, Going Public: New Strategies of Presidential Leadership, VFourth; Körösényi A, 2018, INTERSECTIONS-E EUR, V4, P115, DOI 10.17356/ieejsp.v4i1.130; Kumar M.J., 2007, Managing the president's message: The White House communications operation; Light PaulC., 1999, PRESIDENTS AGENDA; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loftis MW, 2020, POLICY STUD J, V48, P184, DOI 10.1111/psj.12245; Lovett J, 2015, POLICY STUD J, V43, P22, DOI 10.1111/psj.12087; Manin Bernard., 1999, DEMOCRACY ACCOUNTABI; Mansbridge J, 2003, AM POLIT SCI REV, V97, P515, DOI 10.1017/S0003055403000856; Mortensen PB, 2011, COMP POLIT STUD, V44, P973, DOI 10.1177/0010414011405162; Newman B, 2010, ELECT STUD, V29, P144, DOI 10.1016/j.electstud.2009.07.003; O'Brien SB, 2020, CONGR PRESIDENCY, V47, P148, DOI 10.1080/07343469.2019.1677118; Ornstein N.J., 2000, The permanent campaign and its future; Ostrom Charles., 2021, "Explaining Presidential Approval, 1993-2020: An Examination of the Clinton, Bush, Obama and Trump Presidencies, DOI [10.31124/advance.16575062.v1, DOI 10.31124/ADVANCE.16575062.V1]; Ouyang Yu., 2020, Trump, Twitter, and the American Democracy, P131; Peake JS, 2001, POLIT RES QUART, V54, P69, DOI 10.1177/106591290105400104; Rottinghaus B., 2010, PROVISIONAL PULPIT M; Royed TJ, 1996, BRIT J POLIT SCI, V26, P45, DOI 10.1017/S0007123400007419; Russell A, 2022, AM POLIT RES, V50, P545, DOI 10.1177/1532673X221074359; Sebok M, 2021, POLIT ANAL, V29, P236, DOI 10.1017/pan.2020.27; Sebok Miklos., 2022, Quality Quantity, V56, P3621; Thomson R, 2001, EUR J POLIT RES, V40, P171, DOI 10.1111/1475-6765.00595; Vaswani A, 2017, ADV NEUR IN, V30; Villalobos JD, 2012, PRES STUD Q, V42, P549, DOI 10.1111/j.1741-5705.2012.03992.x; Wankmüller S, 2022, SOCIOL METHOD RES, DOI 10.1177/00491241221134527; Whitford AndrewB., 2009, PRESIDENTIAL RHETORI; Wood B.Dan., 2007, POLITICS EC LEADERSH; Wood BD, 1998, AM POLIT SCI REV, V92, P173, DOI 10.2307/2585936; Yates J, 2005, POLIT RES QUART, V58, P577, DOI 10.2307/3595643	74	0	0	5	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0190-292X	1541-0072		POLICY STUD J	Policy Stud. J.	2024 APR 20	2024										10.1111/psj.12534	http://dx.doi.org/10.1111/psj.12534		APR 2024	21	Political Science; Public Administration	Social Science Citation Index (SSCI)	Government & Law; Public Administration	OD2T8		hybrid			2024-07-03	WOS:001205262900001
J	Kumar, M; Mani, UA; Tripathi, P; Saalim, M; Roy, S				Kumar, Mukesh; Mani, Utsav Anand; Tripathi, Pranjal; Saalim, Mohd; Roy, Sneha			Artificial Hallucinations by Google Bard: Think Before You Leap	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						artificial hallucinations; large language models; deep learning artificial intelligence; artificial intelligence in medicine; medical education research; manuscript writing; chat gpt; google bard; ai and robotics in healthcare; ai & robotics in healthcare		One of the critical challenges posed by artificial intelligence (AI) tools like Google Bard (Google LLC, Mountain View, California, United States) is the potential for "artificial hallucinations." These refer to instances where an AI chatbot generates fictional, erroneous, or unsubstantiated information in response to queries. In research, such inaccuracies can lead to the propagation of misinformation and undermine the credibility of scientific literature. The experience presented here highlights the importance of crosschecking the information provided by AI tools with reliable sources and maintaining a cautious approach when utilizing these tools in research writing.	[Kumar, Mukesh; Mani, Utsav Anand; Saalim, Mohd] King Georges Med Univ, Emergency Med, Lucknow, India; [Tripathi, Pranjal] King Georges Med Univ, Psychiat, Lucknow, India; [Roy, Sneha] King Georges Med Univ, Med, Lucknow, India	King George's Medical University; King George's Medical University; King George's Medical University	Mani, UA (corresponding author), King Georges Med Univ, Emergency Med, Lucknow, India.	utsavanandmani.kgmu@gmail.com	Mani, Utsav Anand/KOC-2540-2024	Mani, Utsav Anand/0000-0002-1075-7192				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Altamimi I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40922; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812	5	6	6	25	48	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 10	2023	15	8								10.7759/cureus.43313	http://dx.doi.org/10.7759/cureus.43313			4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Q0KC2	37700993	gold, Green Published			2024-07-03	WOS:001054475400008
J	Younesi, A; Ansari, M; Fazli, M; Ejlali, A; Shafique, M; Henkel, J				Younesi, Abolfazl; Ansari, Mohsen; Fazli, Mohammadamin; Ejlali, Alireza; Shafique, Muhammad; Henkel, Jorg			A Comprehensive Survey of Convolutions in Deep Learning: Applications, Challenges, and Future Trends	IEEE ACCESS			English	Article						Deep learning; DNN; CNN; machine learning; vision transformers; GAN; attention; computer vision; LLM; large language model; transformer; dilated convolution; depthwise,NAS,NAT; object detection; 6D vision; vision language model	NEURAL ARCHITECTURE SEARCH; MEDICAL IMAGE SEGMENTATION; OBJECT DETECTION; SELF-ATTENTION; SEMANTIC SEGMENTATION; CAPSULE NETWORKS; POSE ESTIMATION; SHIFT-INVARIANT; CLASSIFICATION; CNN	In today's digital age, Convolutional Neural Networks (CNNs), a subset of Deep Learning (DL), are widely used for various computer vision tasks such as image classification, object detection, and image segmentation. There are numerous types of CNNs designed to meet specific needs and requirements, including 1D, 2D, and 3D CNNs, as well as dilated, grouped, attention, depthwise convolutions, and NAS, among others. Each type of CNN has its unique structure and characteristics, making it suitable for specific tasks. It's crucial to gain a thorough understanding and perform a comparative analysis of these different CNN types to understand their strengths and weaknesses. Furthermore, studying the performance, limitations, and practical applications of each type of CNN can aid in the development of new and improved architectures in the future. We also dive into the platforms and frameworks that researchers utilize for their research or development from various perspectives. Additionally, we explore the main research fields of CNN like 6D vision, generative models, and meta-learning. This survey paper provides a comprehensive examination and comparison of various CNN architectures, highlighting their architectural differences and emphasizing their respective advantages, disadvantages, applications, challenges, and future trends.	[Younesi, Abolfazl; Ansari, Mohsen; Fazli, Mohammadamin; Ejlali, Alireza] Sharif Univ Technol, Dept Comp Sci & Engn, Tehran 1136511155, Iran; [Shafique, Muhammad] New York Univ NYU Abu Dhabi, Div Engn, eBrainLab, Abu Dhabi, U Arab Emirates; [Henkel, Jorg] Karlsruhe Inst Technol KIT, Dept Comp Sci, D-76131 Karlsruhe, Germany	Sharif University of Technology; Helmholtz Association; Karlsruhe Institute of Technology	Ansari, M (corresponding author), Sharif Univ Technol, Dept Comp Sci & Engn, Tehran 1136511155, Iran.	ansari@sharif.edu	Ansari, Mohsen/AAH-1306-2020; Younesi, Abolfazl/KTH-8983-2024	Ansari, Mohsen/0000-0002-4670-8608; Younesi, Abolfazl/0009-0003-0052-6475; Shafique, Muhammad/0000-0002-2607-8135	New York University Abu Dhabi (NYUAD) Center for Artificial Intelligence and Robotics (CAIR)	New York University Abu Dhabi (NYUAD) Center for Artificial Intelligence and Robotics (CAIR)	No Statement Available	Abdelnour J, 2023, IEEE T PATTERN ANAL, V45, P4997, DOI 10.1109/TPAMI.2022.3194311; Abdigapporov S, 2023, IEEE ACCESS, V11, P37637, DOI 10.1109/ACCESS.2023.3266284; Ahmed Taha, 2021, Indonesian J. Electr. Eng. Comput. Sci., V22, P1177, DOI [DOI 10.11591/IJEECS.V22.12.PP1177-1190, 10.11591/ijeecs.v22.i2.pp1177-1190]; Ajala S, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13010041; Akram Adeel, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1483, DOI 10.1109/CompComm.2018.8780648; AL-Alimi D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212525; Alam M, 2020, NEUROCOMPUTING, V417, P302, DOI 10.1016/j.neucom.2020.07.053; Alayrac Jean-Baptiste, 2020, NEURIPS, V3; Alazab M, 2022, IEEE T IND INFORM, V18, P3501, DOI 10.1109/TII.2021.3119038; Alhassan AM, 2020, IEEE ACCESS, V8, P201741, DOI 10.1109/ACCESS.2020.3035803; Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8; Amjoud AB, 2023, IEEE ACCESS, V11, P35479, DOI 10.1109/ACCESS.2023.3266093; Anilkumar P, 2023, IEEE ACCESS, V11, P106688, DOI 10.1109/ACCESS.2023.3318867; Anwar SM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1088-1; Anwar T., 2020, 2020 IEEE 23 INT MUL, P1, DOI DOI 10.1109/INMIC50486.2020.9318212; Ashwath VA, 2023, IEEE ACCESS, V11, P78402, DOI 10.1109/ACCESS.2023.3299850; Aswani AR, 2022, IEEE INT SYMP CIRC S, P3458, DOI 10.1109/ISCAS48785.2022.9937284; Azari MS, 2023, IEEE ACCESS, V11, P12887, DOI 10.1109/ACCESS.2023.3239784; Bao F, 2023, PROC CVPR IEEE, P22669, DOI 10.1109/CVPR52729.2023.02171; Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254; Batool A, 2023, IEEE ACCESS, V11, P37203, DOI 10.1109/ACCESS.2023.3266511; Baum ZMC, 2023, IEEE T MED IMAGING, V42, P823, DOI 10.1109/TMI.2022.3218147; Bavu É, 2019, INT CONF ACOUST SPEE, P5686, DOI [10.1109/icassp.2019.8682378, 10.1109/ICASSP.2019.8682378]; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Berkeley Vision, 2012, Caffe | Deep Learning Framework; Biehler M, 2023, IEEE T AUTOM SCI ENG, DOI 10.1109/TASE.2023.3345807; Bilen C, 2018, IEEE T SIGNAL PROCES, V66, P5604, DOI 10.1109/TSP.2018.2869113; Bing XY, 2019, IEEE ACCESS, V7, P145030, DOI 10.1109/ACCESS.2019.2944862; Biswas SK, 2016, IEEE T PATTERN ANAL, V38, P546, DOI 10.1109/TPAMI.2015.2453950; Buroni G, 2021, IEEE ACCESS, V9, P77359, DOI 10.1109/ACCESS.2021.3083412; Cai WT, 2023, IEEE ACM T COMPUT BI, V20, P2530, DOI 10.1109/TCBB.2022.3198284; Cai ZP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8261, DOI 10.1109/ICCV48922.2021.00817; Cao HQ, 2023, Arxiv, DOI [arXiv:2209.02646, 10.48550/arXiv.2209.02646, DOI 10.48550/ARXIV.2209.02646]; Cao WG, 2021, CHINA COMMUN, V18, P108, DOI 10.23919/JCC.2021.01.010; Cao ZY, 2019, IEEE ACCESS, V7, P166109, DOI 10.1109/ACCESS.2019.2953465; Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858; Chainer, Chainer: A Flexible Framework for Neural Networks; Chalmers E, 2018, IEEE T NEUR NET LEAR, V29, P2259, DOI 10.1109/TNNLS.2017.2690910; Chen HQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093094; Chen HT, 2024, IEEE T NEUR NET LEAR, V35, P2969, DOI 10.1109/TNNLS.2023.3290974; Chen HT, 2023, IEEE T KNOWL DATA EN, V35, P7263, DOI 10.1109/TKDE.2022.3188335; Chen JN, 2022, PROC CVPR IEEE, P12125, DOI 10.1109/CVPR52688.2022.01182; Chen QQ, 2020, IEEE ACCESS, V8, P171912, DOI 10.1109/ACCESS.2020.3024658; Chen SL, 2023, IEEE ACCESS, V11, P127388, DOI 10.1109/ACCESS.2023.3332269; Chen SM, 2024, IEEE T NEUR NET LEAR, V35, P4516, DOI 10.1109/TNNLS.2022.3155602; Chen TY, 2022, PROC CVPR IEEE, P9991, DOI 10.1109/CVPR52688.2022.00976; Chen XY, 2021, IEEE T MED IMAGING, V40, P3867, DOI 10.1109/TMI.2021.3099509; Chen YZ, 2019, IEEE ACCESS, V7, P78991, DOI 10.1109/ACCESS.2019.2922679; Cheng G, 2023, IEEE T PATTERN ANAL, V45, P4650, DOI 10.1109/TPAMI.2022.3193587; Chenhan Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11860, DOI 10.1109/CVPR42600.2020.01188; Chitty-Venkata KT, 2023, IEEE ACCESS, V11, P25217, DOI 10.1109/ACCESS.2023.3253818; Chitty-Venkata KT, 2022, IEEE ACCESS, V10, P108374, DOI 10.1109/ACCESS.2022.3212767; Cho H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11149, DOI 10.1109/ICCV48922.2021.01098; Choi W, 2023, PROC CVPR IEEE, P3779, DOI 10.1109/CVPR52729.2023.00368; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Chungath TT, 2024, IEEE J OCEANIC ENG, V49, P294, DOI 10.1109/JOE.2022.3221127; Comminiello D, 2019, INT CONF ACOUST SPEE, P7745, DOI 10.1109/ICASSP.2019.8683403; Cong RM, 2023, IEEE T CIRC SYST VID, V33, P534, DOI 10.1109/TCSVT.2022.3205182; Coskun H, 2023, IEEE T PATTERN ANAL, V45, P6659, DOI 10.1109/TPAMI.2021.3058606; Dai XR, 2022, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP43922.2022.9746324; De Lange M, 2022, IEEE T PATTERN ANAL, V44, P3366, DOI 10.1109/TPAMI.2021.3057446; deeplearning4j, Eclipse DeepLearning4.J.; Del Pup F, 2023, IEEE ACCESS, V11, P144180, DOI 10.1109/ACCESS.2023.3344531; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng Y, 2020, IEEE OPEN J COMP SOC, V1, P62, DOI 10.1109/OJCS.2020.2996184; Depeursinge A, 2017, IEEE T IMAGE PROCESS, V26, P1626, DOI 10.1109/TIP.2017.2655438; Ding CT, 2023, PROC CVPR IEEE, P7756, DOI 10.1109/CVPR52729.2023.00749; Ding ZX, 2022, IEEE T NEUR NET LEAR, V33, P5004, DOI 10.1109/TNNLS.2021.3067028; Djilali YAD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15394, DOI 10.1109/ICCV48922.2021.01513; Dong HT, 2023, IEEE ACCESS, V11, P41467, DOI 10.1109/ACCESS.2023.3270807; Dong YS, 2022, IEEE T IMAGE PROCESS, V31, P485, DOI 10.1109/TIP.2021.3130539; Doshi K., 2023, PROC IEEE C DEPENDAB, P1, DOI [DOI 10.1109/DSC61021.2023.10354099, 10.1109/DSC61021.2023.10354099]; Duan JW, 2021, IEEE ACCESS, V9, P96353, DOI 10.1109/ACCESS.2021.3094972; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; Elhoseny M, 2020, CIRC SYST SIGNAL PR, V39, P611, DOI 10.1007/s00034-019-01234-7; Elsken T, 2019, Arxiv, DOI [arXiv:1808.05377, 10.48550/arXiv.1808.05377]; Fan WZ, 2019, IEEE SIGNAL PROC LET, V26, P342, DOI 10.1109/LSP.2019.2890965; Fang F, 2020, IEEE T IMAGE PROCESS, V29, P2052, DOI 10.1109/TIP.2019.2947792; Feng LJ, 2021, IEEE T NEUR NET LEAR, V32, P2506, DOI 10.1109/TNNLS.2020.3006322; Feng YQ, 2019, IEEE ACCESS, V7, P91009, DOI 10.1109/ACCESS.2019.2926972; Fu Y., 2019, PROC 12 INT C IMAGE, P1, DOI DOI 10.1109/CISP-BMEI48845.2019.8965991; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fujieda S, 2018, Arxiv, DOI arXiv:1805.08620; Howard AG, 2017, Arxiv, DOI arXiv:1704.04861; Gao KL, 2022, IEEE T IMAGE PROCESS, V31, P3449, DOI 10.1109/TIP.2022.3169689; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Gao TZ, 2022, IEEE T INTELL VEHICL, V7, P240, DOI 10.1109/TIV.2022.3143954; Gao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2866, DOI 10.1109/ICCV48922.2021.00288; Garcia-Martin R, 2023, IEEE ACCESS, V11, P22060, DOI 10.1109/ACCESS.2023.3252009; Gaudillière V, 2023, IEEE INT C INT ROBOT, P5858, DOI 10.1109/IROS55552.2023.10342399; Ghaderzadeh M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6677314; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; GitHub, 2024, Apache/MXNet; Gong C, 2022, IEEE T PATTERN ANAL, V44, P2841, DOI 10.1109/TPAMI.2020.3044997; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow I. J., 2014, arXiv, DOI DOI 10.48550/ARXIV.1406.2661; Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562; Guo GY, 2021, PROC CVPR IEEE, P7399, DOI 10.1109/CVPR46437.2021.00732; Guo TT, 2022, IEEE ACCESS, V10, P58869, DOI 10.1109/ACCESS.2022.3179517; Guo Yuanhui, 2022, 2022 International Conference on Machine Learning, Cloud Computing and Intelligent Mining (MLCCIM), P452, DOI 10.1109/MLCCIM55934.2022.00083; Guo Y, 2022, IEEE T PATTERN ANAL, V44, P6501, DOI 10.1109/TPAMI.2021.3086914; Gupta MR, 2007, PATTERN RECOGN, V40, P389, DOI 10.1016/j.patcog.2006.04.043; Ha MH, 2021, IEEE ACCESS, V9, P6164, DOI 10.1109/ACCESS.2020.3048741; Haase Daniel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14588, DOI 10.1109/CVPR42600.2020.01461; Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004; Han JW, 2021, IEEE T PATTERN ANAL, V43, P1423, DOI 10.1109/TPAMI.2019.2949562; Han K, 2021, Arxiv, DOI arXiv:2103.00112; Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247; Han KJ, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P54, DOI [10.1109/ASRU46091.2019.9003730, 10.1109/asru46091.2019.9003730]; Hao J., 2023, PROC INT C COMPUT EN, P106, DOI DOI 10.1109/CEDL60560.2023.00029; Haridas P, 2020, IEEE ACCESS, V8, P136307, DOI 10.1109/ACCESS.2020.3011909; Harsh P., 2021, PROC INT C INTELL TE, P1, DOI DOI 10.1109/CONIT51480.2021.9498422; Hatamizadeh A, 2022, PROC CVPR IEEE, P10011, DOI 10.1109/CVPR52688.2022.00978; He GQ, 2020, IEEE ACCESS, V8, P67735, DOI 10.1109/ACCESS.2020.2985991; He JP, 2022, IEEE COMPUT SOC CONF, P3849, DOI 10.1109/CVPRW56347.2022.00430; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824; He L, 2024, IEEE ACCESS, V12, P7911, DOI 10.1109/ACCESS.2023.3349017; He X, 2019, IEEE GEOSCI REMOTE S, V16, P1884, DOI 10.1109/LGRS.2019.2911322; He Y., 2023, IEEE Trans. Pattern Anal. Mach. Intell., DOI [10.1109/TPAM1.2023.3334614, DOI 10.1109/TPAM1.2023.3334614]; He YF, 2023, IEEE I CONF COMP VIS, P5628, DOI 10.1109/ICCV51070.2023.00520; He ZX, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010228; Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209; Hilmizen Naufal, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P26, DOI 10.1109/ISRITI51436.2020.9315478; Hnewa M, 2021, IEEE SIGNAL PROC MAG, V38, P53, DOI 10.1109/MSP.2020.2984801; Hodan Tomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11700, DOI 10.1109/CVPR42600.2020.01172; Hong G, 2021, ANN FAM MED, V19, P447, DOI 10.1370/afm.2713; Hoque A, 2020, IEEE REGION 10 SYMP, P1030; Hoque S, 2021, IEEE ACCESS, V9, P143746, DOI 10.1109/ACCESS.2021.3114399; Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209; Hu G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041429; Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292; Hu ZY, 2020, IEEE ACCESS, V8, P182720, DOI 10.1109/ACCESS.2020.3029220; Huang C, 2022, IEEE T PATTERN ANAL, V44, P5335, DOI 10.1109/TPAMI.2021.3067359; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang J., 2017, arXiv, DOI 10.48550/arXiv.1611.10012; Huang SY, 2021, PROC CVPR IEEE, P983, DOI 10.1109/CVPR46437.2021.00104; Huang W., 2021, PROC IEEE 3 INT C FR, P301, DOI DOI 10.1109/ICFTIC54370.2021.9647279; Huang YW, 2020, IEEE T IMAGE PROCESS, V29, P8187, DOI 10.1109/TIP.2020.3011557; Huang YJ, 2018, I S BIOMED IMAGING, P195, DOI 10.1109/ISBI.2018.8363553; Ibrahem H, 2021, IEEE ACCESS, V9, P38742, DOI 10.1109/ACCESS.2021.3064372; Ienco D, 2020, IEEE ACCESS, V8, P179547, DOI 10.1109/ACCESS.2020.3024133; Irshad MT, 2021, IEEE ACCESS, V9, P22662, DOI 10.1109/ACCESS.2021.3054843; Ji W, 2023, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR52729.2023.00112; Jiang J, 2010, COMPUT MED IMAG GRAP, V34, P617, DOI 10.1016/j.compmedimag.2010.07.003; Jiang ZC, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/7529893; Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201; Jimenez-Carretero D, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006238; Jin B, 2020, IEEE ACCESS, V8, P123649, DOI 10.1109/ACCESS.2020.3005687; Jin N, 2020, IEEE ACCESS, V8, P77060, DOI 10.1109/ACCESS.2020.2989428; Ju AY, 2022, EAI ENDORSED TRANS S, V9, DOI 10.4108/eai.19-11-2021.172214; Kaddar B, 2021, IEEE ACCESS, V9, P105892, DOI 10.1109/ACCESS.2021.3099952; Kakillioglu B, 2020, IEEE ACCESS, V8, P27393, DOI 10.1109/ACCESS.2020.2971950; Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436; Kande GB, 2024, IEEE ACCESS, V12, P534, DOI 10.1109/ACCESS.2023.3347196; Kang J, 2022, IEEE ACCESS, V10, P20118, DOI 10.1109/ACCESS.2022.3149052; Kara A., 2021, Sakarya Univ. J. Comput. Inf. Sci., V4, P216, DOI DOI 10.35377/SAUCIS.04.02.912154; Karnewar A, 2023, PROC CVPR IEEE, P18423, DOI 10.1109/CVPR52729.2023.01767; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Kelenyi B, 2023, IEEE ACCESS, V11, P7947, DOI 10.1109/ACCESS.2023.3238901; Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044; Keras, 2019, Home-Keras Documentation; Khan A, 2023, Arxiv, DOI [arXiv:2305.09880, DOI 10.48550/ARXIV.2305.09880]; Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6; Khan I, 2020, IEEE ACCESS, V8, P10262, DOI 10.1109/ACCESS.2020.2964726; Khan MZ, 2021, IEEE ACCESS, V9, P83002, DOI 10.1109/ACCESS.2021.3086530; Khan S, 2021, IEEE ACCESS, V9, P10657, DOI 10.1109/ACCESS.2020.3048172; Kim D, 2024, IEEE ACCESS, V12, P13912, DOI 10.1109/ACCESS.2024.3355542; Kim Jun-Hwa, 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10095516; Kim MC, 2022, IEEE ACCESS, V10, P77099, DOI 10.1109/ACCESS.2022.3192451; Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269; Kiranyaz S, 2019, INT CONF ACOUST SPEE, P8360, DOI 10.1109/ICASSP.2019.8682194; Klos S., 2022, J. Phys., Conf. Ser., V2198; Kolaghassi R, 2021, IEEE ACCESS, V9, P113788, DOI 10.1109/ACCESS.2021.3104464; Krichen M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080151; Kuang LD, 2020, IEEE T MED IMAGING, V39, P844, DOI 10.1109/TMI.2019.2936046; Kulkarni Uday, 2022, 2022 Sixth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P610, DOI 10.1109/I-SMAC55078.2022.9987264; Kumar A, 2021, ADV PHARM BULL, V11, P414, DOI 10.34172/apb.2021.049; Kumar K, 2021, IEEE SIGNAL PROC LET, V28, P1410, DOI 10.1109/LSP.2021.3093862; Kwon B, 2022, IEEE ACCESS, V10, P89732, DOI 10.1109/ACCESS.2022.3201139; Ladi S. K., 2022, PROC IEEE 2 INT S SU, P1, DOI [10.1109/SSSC56467.2022.10051566, DOI 10.1109/SSSC56467.2022.10051566]; Lai CJ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060887; Lamba S., 2022, PROC 2 INT C ADV COM, P2054, DOI [DOI 10.1109/ICACITE53722.2022.9823799, 10.1109/ICACITES3722.2022.9823799, DOI 10.1109/ICACITES3722.2022.9823799]; Lang P, 2022, IEEE J-STARS, V15, P6615, DOI 10.1109/JSTARS.2022.3195074; Li G, 2020, IEEE ACCESS, V8, P27495, DOI 10.1109/ACCESS.2020.2971760; Li Hui, 2023, 2023 8th International Conference on Information Systems Engineering (ICISE), P358, DOI 10.1109/ICISE60366.2023.00082; Li H., 2022, PROC 4 INT C DATA DR, P1, DOI DOI 10.1109/DOCS55193.2022.9967481; Li H, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3295461; Li HT, 2023, PROC CVPR IEEE, P24417, DOI 10.1109/CVPR52729.2023.02339; Li L, 2020, IEEE ACCESS, V8, P147463, DOI 10.1109/ACCESS.2020.3011366; Li QQ, 2018, IEEE INT C BIOINFORM, P680, DOI 10.1109/BIBM.2018.8621284; Li RB, 2022, PROC CVPR IEEE, P16938, DOI 10.1109/CVPR52688.2022.01645; Li XB, 2023, IEEE T NEUR NET LEAR, V34, P215, DOI [10.1109/TNNLS.2021.3093319, 10.1145/3583740.3626615]; Li YL, 2020, IEEE T IMAGE PROCESS, V29, P3092, DOI 10.1109/TIP.2019.2957850; Li YY, 2023, IEEE I CONF COMP VIS, P16843, DOI 10.1109/ICCV51070.2023.01549; Li Y, 2019, INT J COMPUT VISION, pNIL_20; Li Y, 2019, IEEE T IMAGE PROCESS, V28, P5881, DOI 10.1109/TIP.2019.2922854; Li Z., 2023, PROC 2 INT C MACH LE, P250, DOI [DOI 10.1109/MLCCIM60412.2023.00042, 10.1109/mlccim60412.2023.00042]; Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827; Li ZK, 2023, IEEE I CONF COMP VIS, P17019, DOI 10.1109/ICCV51070.2023.01565; Li ZK, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3301007; Liang A, 2023, IEEE ACCESS, V11, P36184, DOI 10.1109/ACCESS.2023.3266340; Liang LL, 2013, IEEE T IMAGE PROCESS, V22, P5168, DOI 10.1109/TIP.2013.2283146; Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0; Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160; Lin TY, 2015, Arxiv, DOI arXiv:1405.0312; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337; Liu JH, 2023, PROC CVPR IEEE, P6252, DOI 10.1109/CVPR52729.2023.00605; Liu PJ, 2019, IEEE ACCESS, V7, P74973, DOI 10.1109/ACCESS.2019.2921451; Liu Q, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13101962; Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197; Liu SC, 2022, INT CONF ACOUST SPEE, P8802, DOI 10.1109/ICASSP43922.2022.9746947; Liu Y, 2021, AI MAG, V42, P19, DOI 10.1609/aimag.v42i2.15095; Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172; Liu Y, 2022, PROC CVPR IEEE, P3032, DOI 10.1109/CVPR52688.2022.00305; Liu YX, 2023, IEEE ACCESS, V11, P5528, DOI 10.1109/ACCESS.2023.3237268; Liu YQ, 2023, IEEE T NEUR NET LEAR, V34, P550, DOI 10.1109/TNNLS.2021.3100554; Liu ZA, 2023, PROC CVPR IEEE, P8578, DOI 10.1109/CVPR52729.2023.00829; Liu ZH, 2023, COMPLEX INTELL SYST, V9, P1001, DOI 10.1007/s40747-022-00815-5; Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045; Lu YH, 2020, CHIN CONT DECIS CONF, P1931, DOI [10.1109/CCDC49329.2020.9164580, 10.1109/ccdc49329.2020.9164580]; Lv G, 2023, IMAGE VISION COMPUT, V136, DOI 10.1016/j.imavis.2023.104751; Ma PR, 2024, IEEE T CIRC SYST VID, V34, P3409, DOI 10.1109/TCSVT.2023.3324648; Ma SJ, 2019, IEEE ACCESS, V7, P57023, DOI 10.1109/ACCESS.2019.2912072; Ma ZJ, 2020, IEEE ACCESS, V8, P12942, DOI 10.1109/ACCESS.2019.2961715; Madhasu N., 2023, PROC 7 INT C COMPUT, P1, DOI [DOI 10.1109/CSITSS60515.2023.10384657, 10.1109/csitss60515.2023.10384657]; Maher Ahmed H., 2022, IAES Int. J. Artif. Intell., V11, P485, DOI DOI 10.11591/IJAI.V11.I2.PP485-493; Mandal PK, 2024, Arxiv, DOI arXiv:2401.00390; Maniatopoulos A, 2021, INFORMATION, V12, DOI 10.3390/info12120513; Mao C, 2021, IEEE ACCESS, V9, P39608, DOI 10.1109/ACCESS.2021.3064362; Mao WH, 2023, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP49359.2023.10222365; Marchisio A, 2022, IEEE ACCESS, V10, P109043, DOI 10.1109/ACCESS.2022.3214312; Mehta S, 2022, Arxiv, DOI [arXiv:2110.02178, DOI 10.48550/ARXIV.2110.02178]; Mellor J., 2020, arXiv; Memon J, 2020, IEEE ACCESS, V8, P142642, DOI 10.1109/ACCESS.2020.3012542; Meng LC, 2022, PROC CVPR IEEE, P12299, DOI 10.1109/CVPR52688.2022.01199; Miao Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7806, DOI 10.1109/CVPR42600.2020.00783; Mills KG, 2021, IEEE ACCESS, V9, P110962, DOI 10.1109/ACCESS.2021.3101975; Min ZX, 2023, PROC CVPR IEEE, P21404, DOI 10.1109/CVPR52729.2023.02050; Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Mohamed NA, 2020, IEEE ST CONF RES DEV, P333, DOI 10.1109/SCOReD50371.2020.9250928; Mputu HS, 2024, IEEE ACCESS, V12, P8283, DOI 10.1109/ACCESS.2024.3352745; Nagib AM, 2024, IEEE J SEL AREA COMM, V42, P310, DOI 10.1109/JSAC.2023.3336191; NAGY G, 1987, IEEE T PATTERN ANAL, V9, P710, DOI 10.1109/TPAMI.1987.4767969; Nakajo R, 2018, FRONT NEUROROBOTICS, V12, P1, DOI 10.3389/fnbot.2018.00046; Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883; Oguntola I, 2018, IEEE HIGH PERF EXTR; Omid-Zohoor A, 2018, IEEE T CIRC SYST VID, V28, P1102, DOI 10.1109/TCSVT.2017.2653187; Ong KL, 2023, IEEE ACCESS, V11, P108571, DOI 10.1109/ACCESS.2023.3321122; Onita D, 2023, IEEE ACCESS, V11, P28751, DOI 10.1109/ACCESS.2023.3260771; Ooi XP, 2023, IEEE IMAGE PROC, P1305, DOI 10.1109/ICIP49359.2023.10222446; OpenCV, 2019, OpenCV Library; Othman G., 2020, J. Soft Comput. Data Mining, V1, P31; Ouyang X, 2019, IEEE ACCESS, V7, P40757, DOI 10.1109/ACCESS.2019.2906654; Oyelade ON, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98978-7; Paglinawan Charmaine C., 2023, 2023 15th International Conference on Computer and Automation Engineering (ICCAE), P260, DOI 10.1109/ICCAE56788.2023.10111387; Pan XJ, 2021, PROC CVPR IEEE, P11637, DOI 10.1109/CVPR46437.2021.01147; Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015; Papanastasiou G, 2023, Arxiv, DOI arXiv:2307.12775; Papari G, 2012, IEEE T IMAGE PROCESS, V21, P2931, DOI 10.1109/TIP.2011.2179060; Park J, 2000, IEEE T PATTERN ANAL, V22, P400, DOI 10.1109/34.845383; Park S, 2023, IEEE ACCESS, V11, P60028, DOI 10.1109/ACCESS.2023.3284539; Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014; Pei YT, 2021, IEEE T PATTERN ANAL, V43, P1239, DOI 10.1109/TPAMI.2019.2950923; Peng YJ, 2020, IEEE ACCESS, V8, P30969, DOI 10.1109/ACCESS.2020.2973003; Phan Trung V., 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P146, DOI 10.1109/ICAIIC48513.2020.9065240; Prakash CD, 2021, IEEE T IMAGE PROCESS, V30, P9220, DOI 10.1109/TIP.2021.3124155; Prasetyo Eko, 2021, 2021 International Conference on Artificial Intelligence and Computer Science Technology (ICAICST), P157, DOI 10.1109/ICAICST53116.2021.9497822; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Pun CM, 2004, IEEE T PATTERN ANAL, V26, P1228, DOI 10.1109/TPAMI.2004.67; PyTorch Organisation, 2023, about us; Qayyum A, 2020, IEEE ACCESS, V8, P169794, DOI 10.1109/ACCESS.2020.3024277; Radford A, 2021, PR MACH LEARN RES, V139; Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098; Rämö J, 2014, IEEE SIGNAL PROC LET, V21, P301, DOI 10.1109/LSP.2014.2301557; Ramzan F, 2020, IEEE ACCESS, V8, P103697, DOI 10.1109/ACCESS.2020.2998901; Ran W., 2023, PROC IEEECVF C COMPU, P6559, DOI [DOI 10.1109/CVPRW59228.2023.00697, 10.1109/CVPRW59228.2023.00697]; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Rao YM, 2023, IEEE T PATTERN ANAL, V45, P10883, DOI 10.1109/TPAMI.2023.3263826; Redmon J, 2016, Arxiv, DOI arXiv:1506.02640; Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, 10.1109/TPAMI.2016.2577031, DOI 10.1109/TPAMI.2016.2577031]; Rhee CH, 2022, IEEE ACCESS, V10, P13259, DOI 10.1109/ACCESS.2022.3147483; Ridnik T, 2021, Arxiv, DOI [arXiv:2104.10972, DOI 10.48550/ARXIV.2104.10972]; Riti YF, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P54, DOI 10.1109/ICITISEE.2016.7803047; Rong J, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/7844472; Roque T, 2018, IEEE T MED IMAGING, V37, P724, DOI 10.1109/TMI.2017.2779811; Roy SK, 2021, IEEE ACCESS, V9, P118419, DOI 10.1109/ACCESS.2021.3107626; Sahin C, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103898; Saleh FS, 2018, IEEE T PATTERN ANAL, V40, P1382, DOI 10.1109/TPAMI.2017.2713785; Sandhiya B, 2021, INT CO SIG PROC COMM, P238, DOI 10.1109/ICSPC51351.2021.9451747; Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1; Sasipriyaa N., 2023, PROC INT C COMPUT CO, P1, DOI [10.1109/ICCCI56745.2023,10128520, DOI 10.1109/ICCCI56745.2023,10128520]; Saxena A., 2020, J. Artif. Intell. Syst., V2, P53, DOI DOI 10.33969/AIS.2020.21005; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; Sekanina L, 2021, IEEE ACCESS, V9, P151337, DOI 10.1109/ACCESS.2021.3126685; Selamet F, 2022, IEEE ACCESS, V10, P126030, DOI 10.1109/ACCESS.2022.3224037; Setyati E., 2021, Knowl. Eng. Data Sci., V4, P138, DOI DOI 10.17977/UM018V4I22021P138-144; Seum A, 2020, PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P234, DOI 10.1109/ICECE51571.2020.9393129; Shaheen K, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01603-6; Shan Y, 2008, IEEE T PATTERN ANAL, V30, P700, DOI 10.1109/TPAMI.2007.70728; Shao JQ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093039; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Shasha Yang, 2021, E3S Web of Conferences, V267, DOI 10.1051/e3sconf/202126701038; Shen DH, 2022, EAI ENDORSED TRANS S, V9, DOI 10.4108/eai.17-12-2021.172439; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]; Shi C, 2020, IEEE ACCESS, V8, P149162, DOI 10.1109/ACCESS.2020.3014975; Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020; Singh A, 2021, IEEE ACCESS, V9, P131583, DOI 10.1109/ACCESS.2021.3112996; Singh S. K., 2023, PROC 24 INT C DIGIT, P1, DOI DOI 10.1109/DSP58604.2023.10167937; Sistaninejhad Bagher, 2023, Comput Math Methods Med, V2023, P7091301, DOI 10.1155/2023/7091301; Sohail A, 2022, IEEE ACCESS, V10, P134557, DOI 10.1109/ACCESS.2022.3230983; Song KY, 2023, PROC CVPR IEEE, P11848, DOI 10.1109/CVPR52729.2023.01140; Song LY, 2018, IEEE T IMAGE PROCESS, V27, P6025, DOI 10.1109/TIP.2018.2864920; Song YS, 2022, Arxiv, DOI [arXiv:2205.06743, DOI 10.1145/3582688]; Sriram S, 2020, IEEE CONF COMPUT, P740, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162661; Sugiyono Agung Yuwono, 2023, Procedia Computer Science, V227, P932, DOI 10.1016/j.procs.2023.10.600; Sultonov F, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12041953; Sun S, 2020, INT J COMPUT COMMUN, V15, DOI 10.15837/ijccc.2020.1.3712; Sun TT, 2019, IEEE ACCESS, V7, P54472, DOI 10.1109/ACCESS.2019.2913316; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan H., 2019, ARXIV; Tan MX, 2019, PR MACH LEARN RES, V97; Tang HY, 2022, 2022 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, COMPUTER VISION AND MACHINE LEARNING (ICICML), P258, DOI 10.1109/ICICML57342.2022.10009711; Tang YH, 2022, PROC CVPR IEEE, P12155, DOI 10.1109/CVPR52688.2022.01185; Tao ZY, 2021, IEEE SIGNAL PROC LET, V28, P1215, DOI 10.1109/LSP.2021.3088052; tensorflow, TensorFlow Lite; TensorFlow, 2019, about us; Terven J, 2023, MACH LEARN KNOW EXTR, V5, P1680, DOI 10.3390/make5040083; Thakur S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102920; Thapliyal T., 2023, PROC 1 INT C ADV ELE, P1, DOI [DOI 10.1109/ICAEECI58247.2023.10370919, 10.1109/icaeeci58247.2023.10370919]; Tian L, 2020, IEEE T IMAGE PROCESS, V29, P8429, DOI 10.1109/TIP.2020.3013168; Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717; Tian-Hao Wu, 2021, 2021 3rd World Symposium on Artificial Intelligence (WSAI), P24, DOI 10.1109/WSAI51899.2021.9486316; Tiwari A, 2023, INT J APPL EARTH OBS, V118, DOI 10.1016/j.jag.2023.103270; Tomosada H, 2021, IEEE ACCESS, V9, P135224, DOI 10.1109/ACCESS.2021.3116194; Tran T, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay092; Ullah F, 2024, IEEE J-STARS, V17, P3878, DOI 10.1109/JSTARS.2024.3353551; Vadera S, 2022, IEEE ACCESS, V10, P63280, DOI 10.1109/ACCESS.2022.3182659; van Dyck LE, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.750639; Vandenhende S, 2022, IEEE T PATTERN ANAL, V44, P3614, DOI 10.1109/TPAMI.2021.3054719; Vani N., 2022, PROC INT C BUS ANAL, P1, DOI DOI 10.1109/ICBATS54253.2022.9759036; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vaudrey T., 2008, PROC 23 INT C IMAGE, P1, DOI DOI 10.1109/IVCNZ.2008.4762126; Veksler VD, 2022, TOP COGN SCI, V14, P702, DOI 10.1111/tops.12571; Veres M, 2020, IEEE T INTELL TRANSP, V21, P3152, DOI 10.1109/TITS.2019.2929020; Wang D, 2023, IEEE T IMAGE PROCESS, V32, P2536, DOI 10.1109/TIP.2023.3270104; Wang F, 2022, IEEE ACCESS, V10, P129823, DOI 10.1109/ACCESS.2022.3228044; Wang H, 2022, IEEE T IMAGE PROCESS, V31, P2962, DOI 10.1109/TIP.2022.3162099; Wang JY, 2022, IEEE T CIRC SYST VID, V32, P4224, DOI 10.1109/TCSVT.2021.3128275; Wang LF, 2021, IEEE ACCESS, V9, P67634, DOI 10.1109/ACCESS.2021.3075953; Wang LY, 2024, Arxiv, DOI arXiv:2302.00487; Wang LY, 2022, IEEE T NEUR NET LEAR, V33, P1925, DOI 10.1109/TNNLS.2021.3111019; Wang LD, 2019, IEEE ACCESS, V7, P69559, DOI 10.1109/ACCESS.2019.2912226; Wang N, 2023, IEEE T MED IMAGING, V42, P2740, DOI 10.1109/TMI.2023.3264433; Wang TF, 2022, Arxiv, DOI arXiv:2205.12952; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Wang XS, 2023, IEEE T NEUR NET LEAR, V34, P6887, DOI 10.1109/TNNLS.2022.3215633; Wang Yuxin, 2023, 2023 4th International Conference on Electronic Communication and Artificial Intelligence (ICECAI), P336, DOI 10.1109/ICECAI58670.2023.10176715; Wang Y, 2022, IEEE ACCESS, V10, P133936, DOI 10.1109/ACCESS.2022.3230894; Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y; Wang YQ, 2020, Arxiv, DOI [arXiv:1904.05046, DOI 10.48550/ARXIV.1904.05046]; Wang Y, 2022, IEEE ACCESS, V10, P74620, DOI 10.1109/ACCESS.2022.3190966; Wei C, 2023, IEEE T NEUR NET LEAR, V34, P8441, DOI 10.1109/TNNLS.2022.3151160; Wei J, 2021, PROC CVPR IEEE, P5989, DOI 10.1109/CVPR46437.2021.00593; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698; Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991; Weng Y, 2019, IEEE ACCESS, V7, P38495, DOI 10.1109/ACCESS.2019.2906369; White C., 2023, arXiv; Williams T, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P233, DOI [10.1109/ICMLA.2016.0046, 10.1109/ICMLA.2016.36]; Woo B, 2021, 2021 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), DOI 10.1109/ICEIC51217.2021.9369797; Wu YY, 2021, IEEE ACCESS, V9, P45853, DOI 10.1109/ACCESS.2021.3067055; Wu ZY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041096; Wu ZH, 2024, IEEE T NEUR NET LEAR, V35, P961, DOI 10.1109/TNNLS.2022.3178180; Xia HB, 2020, IEEE ACCESS, V8, P184614, DOI 10.1109/ACCESS.2020.3029694; Xiang Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13833, DOI 10.1109/CVPR42600.2020.01385; Xie JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P132, DOI 10.1109/ICCV48922.2021.00020; Xie L., 2023, PROC IEEE INT C ACOU, P1, DOI DOI 10.1109/ICASSP49357.2023.10097186; Xie LS, 2022, IEEE J BIOMED HEALTH, V26, P5013, DOI 10.1109/JBHI.2022.3192277; Xie ZG, 2023, IEEE ACCESS, V11, P16526, DOI 10.1109/ACCESS.2023.3246127; Xu J., 2021, arXiv; Xu JJ, 2023, IEEE T PATTERN ANAL, V45, P9654, DOI 10.1109/TPAMI.2023.3262140; Xu JL, 2022, PROC CVPR IEEE, P9427, DOI 10.1109/CVPR52688.2022.00922; Xu R, 2022, IEEE T CIRC SYST VID, V32, P8674, DOI 10.1109/TCSVT.2022.3196550; Xu S, 2020, CHIN CONTR CONF, P7458, DOI 10.23919/CCC50068.2020.9189610; Xu XT, 2023, IEEE ACCESS, V11, P144722, DOI 10.1109/ACCESS.2023.3345790; Xue CH, 2021, ALZHEIMERS RES THER, V13, DOI 10.1186/s13195-021-00888-3; Xue MQ, 2022, PROC CVPR IEEE, P150, DOI 10.1109/CVPR52688.2022.00025; Yamazaki Y, 2020, IEEE ACCESS, V8, P101398, DOI 10.1109/ACCESS.2020.2998776; Yan CX, 2024, IEEE T PATTERN ANAL, V46, P1530, DOI 10.1109/TPAMI.2021.3140070; Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843; Yan ZC, 2021, PROC CVPR IEEE, P15134, DOI 10.1109/CVPR46437.2021.01489; Yang CL, 2022, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR52688.2022.01169; Yang G, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5888299; Yang XB, 2020, IEEE ACCESS, V8, P151555, DOI 10.1109/ACCESS.2020.3017560; Yang Y, 2020, IEEE ACCESS, V8, P147580, DOI 10.1109/ACCESS.2020.3015209; Yang Z, 2023, IEEE T IMAGE PROCESS, V32, P321, DOI 10.1109/TIP.2022.3228162; Yangsheng Tian, 2020, 2020 5th International Conference on Control, Robotics and Cybernetics (CRC), P139, DOI 10.1109/CRC51253.2020.9253492; Ye SZ, 2023, IEEE T MED IMAGING, V42, P3348, DOI 10.1109/TMI.2023.3283517; You CY, 2022, IEEE T MED IMAGING, V41, P2228, DOI 10.1109/TMI.2022.3161829; Younesi A, 2023, Arxiv, DOI arXiv:2310.18928; Young G., 1964, Plastics, V3, P15; Yu HY, 2021, 2021 6TH INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA 2021), P560, DOI 10.1109/ICSGEA53208.2021.00132; Yu RX, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124211; Yu XH, 2022, PROC CVPR IEEE, P4858, DOI 10.1109/CVPR52688.2022.00482; Yuan Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11540, DOI 10.1109/CVPR42600.2020.01156; Yuan XY, 2019, AAAI CONF ARTIF INTE, P1682; Yuan ZX, 2022, IEEE T CIRC SYST VID, V32, P2068, DOI 10.1109/TCSVT.2021.3082763; Zafar A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178643; Zare S, 2023, IEEE ACCESS, V11, P137758, DOI 10.1109/ACCESS.2023.3339775; Zeng JH, 2022, IEEE ACCESS, V10, P86510, DOI 10.1109/ACCESS.2022.3198999; Zhan FN, 2019, PROC CVPR IEEE, P3648, DOI 10.1109/CVPR.2019.00377; Zhang AS, 2023, IEEE ACCESS, V11, P61929, DOI 10.1109/ACCESS.2023.3287940; Zhang CX, 2023, IEEE ACCESS, V11, P14202, DOI 10.1109/ACCESS.2023.3243574; Zhang FY, 2023, IEEE T IMAGE PROCESS, V32, P4757, DOI 10.1109/TIP.2023.3305090; Zhang JY, 2019, IEEE ACCESS, V7, P179118, DOI 10.1109/ACCESS.2019.2958671; Zhang L, 2023, IEEE T IMAGE PROCESS, V32, P2107, DOI 10.1109/TIP.2023.3263112; Zhang L, 2019, IEEE ACCESS, V7, P109729, DOI 10.1109/ACCESS.2018.2865613; Zhang Peng, 2021, 2021 CIE International Conference on Radar (Radar), P2529, DOI 10.1109/Radar53847.2021.10027883; Zhang QS, 2021, IEEE T PATTERN ANAL, V43, P3416, DOI 10.1109/TPAMI.2020.2982882; Zhang WX, 2021, IEEE ACCESS, V9, P28976, DOI 10.1109/ACCESS.2021.3058648; Zhang XR, 2022, CMC-COMPUT MATER CON, V72, P1123, DOI 10.32604/cmc.2022.024589; Zhang XB, 2021, IEEE T PATTERN ANAL, V43, P2891, DOI 10.1109/TPAMI.2020.3020300; Zhang XT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P631, DOI 10.1109/ICCV48922.2021.00069; Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203; Zhang YY, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3269692; Zhang ZF, 2021, INT C PATT RECOG, P10305, DOI 10.1109/ICPR48806.2021.9412173; Zhao F, 2020, IEEE ACCESS, V8, P68000, DOI 10.1109/ACCESS.2020.2985098; Zhao Hengshuang, 2017, arXiv, DOI DOI 10.48550/ARXIV.1612.01105; Zhao KJ, 2022, IEEE ACCESS, V10, P69250, DOI 10.1109/ACCESS.2021.3127913; Zhao TL, 2020, IEEE T IMAGE PROCESS, V29, P6357, DOI 10.1109/TIP.2020.2990483; Zhao Y, 2023, IEEE J BIOMED HEALTH, V27, P3912, DOI 10.1109/JBHI.2023.3273609; Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110; Zhao YQ, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3341841; Zhao ZF, 2020, IEEE ACCESS, V8, P20503, DOI 10.1109/ACCESS.2020.2969290; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865; Zheng XW, 2021, IEEE T PATTERN ANAL, V43, P2936, DOI 10.1109/TPAMI.2021.3065138; Zheng Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P625, DOI 10.1007/978-3-030-58598-3_37; Zheng YP, 2023, IEEE ACCESS, V11, P36290, DOI 10.1109/ACCESS.2023.3266251; Zhihang Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11930, DOI 10.1109/CVPR42600.2020.01195; Zhou HY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06146-2; Zhou KW, 2022, Arxiv, DOI arXiv:2203.14936; Zhou Q, 2016, IEEE T PATTERN ANAL, V38, P266, DOI 10.1109/TPAMI.2015.2452911; Zhou T., 2023, IEEE Trans. Games, DOI DOI 10.1109/TG.2023.3272386; Zhou WJ, 2021, IEEE T IMAGE PROCESS, V30, P7790, DOI 10.1109/TIP.2021.3109518; Zhou X., 2023, ACM Trans. Recommender Syst., V1, P1, DOI 10.1145/3591469; Zhou Y, 2017, Arxiv, DOI arXiv:1711.06396; Zhu HY, 2021, COMPLEX INTELL SYST, V7, P639, DOI 10.1007/s40747-020-00247-z; Zhu JT, 2020, IEEE ACCESS, V8, P171542, DOI 10.1109/ACCESS.2020.3024991; Zhu L, 2022, PROC CVPR IEEE, P14617, DOI 10.1109/CVPR52688.2022.01423; Zhu LC, 2022, IEEE T PATTERN ANAL, V44, P273, DOI 10.1109/TPAMI.2020.3007511; Zou L, 2022, IEEE T IMAGE PROCESS, V31, P6907, DOI 10.1109/TIP.2022.3216980	456	0	0	18	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						41180	41218		10.1109/ACCESS.2024.3376441	http://dx.doi.org/10.1109/ACCESS.2024.3376441			39	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	MF6M3		Green Submitted, gold			2024-07-03	WOS:001192251300001
J	Kernberg, A; Gold, JA; Mohan, V				Kernberg, Annessa; Gold, Jeffrey A.; Mohan, Vishnu			Using ChatGPT-4 to Create Structured Medical Notes From Audio Recordings of Physician-Patient Encounters: Comparative Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						generative AI; generative artificial intelligence; ChatGPT; simulation; large language model; clinical documentation; quality; accuracy; reproducibility; publicly available; medical note; medical notes; generation; medical documentation; documentation; documentations; AI; artificial intelligence; transcript; transcripts; ChatGPT-4	SPEECH RECOGNITION; DOCUMENTATION; EFFICIENCY; IMPACT	Background: Medical documentation plays a crucial role in clinical practice, facilitating accurate patient management and communication among health care professionals. However, inaccuracies in medical notes can lead to miscommunication and diagnostic errors. Additionally, the demands of documentation contribute to physician burnout. Although intermediaries like medical scribes and speech recognition software have been used to ease this burden, they have limitations in terms of accuracy and addressing provider-specific metrics. The integration of ambient artificial intelligence (AI)-powered solutions offers a promising way to improve documentation while fitting seamlessly into existing workflows. Objective: This study aims to assess the accuracy and quality of Subjective, Objective, Assessment, and Plan (SOAP) notes generated by ChatGPT-4, an AI model, using established transcripts of History and Physical Examination as the gold standard. We seek to identify potential errors and evaluate the model's performance across different categories. Methods: We conducted simulated patient-provider encounters representing various ambulatory specialties and transcribed the audio files. Key reportable elements were identified, and ChatGPT-4 was used to generate SOAP notes based on these transcripts. Three versions of each note were created and compared to the gold standard via chart review; errors generated from the comparison were categorized as omissions, incorrect information, or additions. We compared the accuracy of data elements across versions, transcript length, and data categories. Additionally, we assessed note quality using the Physician Documentation Quality Instrument Results: Although ChatGPT-4 consistently generated SOAP-style notes, there were, on average, 23.6 errors per clinical case, with errors of omission (86%) being the most common, followed by addition errors (10.5%) and inclusion of incorrect facts (3.2%). There was significant variance between replicates of the same case, with only 52.9% of data elements reported correctly across all 3 replicates. The accuracy of data elements varied across cases, with the highest accuracy observed in the "Objective" section. Consequently, the measure of note quality, assessed by PDQI, demonstrated intra- and intercase variance. Finally, the accuracy of ChatGPT-4 was inversely correlated to both the transcript length (P=.05) and the number of scorable data elements Conclusions: Our study reveals substantial variability in errors, accuracy, and note quality generated by ChatGPT-4. Errors were not limited to specific sections, and the inconsistency in error types across replicates complicated predictability. Transcript length and data complexity were inversely correlated with note accuracy, raising concerns about the model's effectiveness in handling complex medical cases. The quality and reliability of clinical notes produced by ChatGPT-4 do not meet the standards required for clinical use. Although AI holds promise in health care, caution should be exercised before widespread adoption. Further research is needed to address accuracy, variability, and potential errors. ChatGPT-4, while valuable in various applications, should not be considered a safe alternative to human-generated clinical documentation at this time.	[Kernberg, Annessa; Gold, Jeffrey A.; Mohan, Vishnu] Oregon Hlth & Sci Univ, Dept Med Informat & Clin Epidemiol, 3181 SW Sam Jackson Pk Rd, Portland, OR 97239 USA	Oregon Health & Science University	Mohan, V (corresponding author), Oregon Hlth & Sci Univ, Dept Med Informat & Clin Epidemiol, 3181 SW Sam Jackson Pk Rd, Portland, OR 97239 USA.	mohanV@ohsu.edu						Ahuja AS, 2019, PEERJ, V7, DOI 10.7717/peerj.7702; Artis KA, 2019, CRIT CARE MED, V47, P403, DOI 10.1097/CCM.0000000000003557; Bell SK, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.5867; Corby S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01560-4; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Florig ST, 2022, JAMA-J AM MED ASSOC, V328, P1350, DOI 10.1001/jama.2022.13558; Florig Sarah T, 2021, AMIA Annu Symp Proc, V2021, P457; Gaffney A, 2022, JAMA INTERN MED, V182, P564, DOI 10.1001/jamainternmed.2022.0372; Gidwani R, 2017, ANN FAM MED, V15, P427, DOI 10.1370/afm.2122; Goss FR, 2019, INT J MED INFORM, V130, DOI 10.1016/j.ijmedinf.2019.07.017; Guo Q, 2024, ICSE 24 P 46 IEEE AC, DOI [10.1145/3597503.3623306, DOI 10.1145/3597503.3623306]; Hickenlooper J, Clinical documentation strategies 2023; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hodgson T, 2017, J AM MED INFORM ASSN, V24, P1127, DOI 10.1093/jamia/ocx073; Jhaveri P, 2022, ACAD PEDIATR, V22, P289, DOI 10.1016/j.acap.2021.05.004; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kroth PJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9609; Lewis Karen L, 2017, Adv Simul (Lond), V2, P10, DOI 10.1186/s41077-017-0043-4; Mohr DN, 2003, J AM MED INFORM ASSN, V10, P85, DOI 10.1197/jamia.M1130; Ouyang SY, 2023, Arxiv, DOI arXiv:2308.02828; Peng K, 2023, SSRN Journal, P1, DOI [10.2139/ssrn.4390455, DOI 10.2139/SSRN.4390455]; Pranaat Robert, 2017, JMIR Med Inform, V5, pe30, DOI 10.2196/medinform.7883; Preiksaitis C, 2023, NAT MED, V29, P1296, DOI 10.1038/s41591-023-02341-4; Rule Adam, 2021, AMIA Annu Symp Proc, V2021, P1059; Stetson PD, 2012, APPL CLIN INFORM, V3, P164, DOI 10.4338/ACI-2011-11-RA-0070; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479	27	0	0	4	4	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	APR 22	2024	26								e54419	10.2196/54419	http://dx.doi.org/10.2196/54419			11	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	PY1Q0	38648636	gold			2024-07-03	WOS:001217552200001
J	Forner, D; Ozcan, S				Forner, Dominik; Ozcan, Sercan			Examination of Overlapping Boundaries of Innovation Systems Using Deep Neural Network and Natural Language Processing	IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT			English	Article; Early Access						Technological innovation; Economics; Biological system modeling; Semantics; Silicon; Reliability; Natural language processing; Artificial intelligence (AI); artificial neural network; deep learning; economic systems; innovation policy; large language model (LLM); natural language processing; systems of innovation; topic modeling	RESEARCH-AND-DEVELOPMENT; TECHNOLOGICAL-INNOVATION; SECTORAL SYSTEMS; TRIPLE-HELIX; NATIONAL SYSTEMS; OFFSHORE WIND; CATCH-UP; ENVIRONMENTAL-REGULATION; MULTILEVEL PERSPECTIVE; REGIONAL SYSTEMS	Systems of innovation (SI) studies previously considered innovation at different geographical levels and with different foci on actors and processes. However, the boundaries of the SI concepts are becoming blurry and shifting due to technological and economic factors, globalization and interdependence between countries and firms. Previous literature has limitations to address shifting boundaries by assessing SI literature holistically. This study set out to understand the overlaps of SI concepts. It aims at delimiting the SI field, delineating boundaries and at determining the topics underlying the SI and overlaps. Context-specific synergies become transparent, enabling decision-makers and researchers to consider economic interrelationships in a topic-specific and cross-system perspective. The study uses deep learning in combination with natural language processing on data consisting of 2380 SI literature related article abstracts retrieved from Web of Science and EBSCO research databases to capture the semantic context of topics, whereas external information is used to cross-validate interrelationships and to observe topic distribution. The findings reveal significant proportions of overlaps between SI apart from regional and technological systems. Various topics that are discussed within the SI literature such as industrial clusters and structures is a common topic for all SI. This illustrates that economic topics are contextually or theoretically not bound to a system but distributed across the entire literature. We therefore provide a structured framework to illustrate SI overlaps and to address topic synergies. Our study contributes to the body of literature where SI boundaries are investigated specifically to the determination of system overlaps, reasoning of their identical SI characteristics and examination of cross-system thematic synergies.	[Forner, Dominik] Univ Portsmouth, Fac Business & Law, Strategy Enterprise & Innovat, Portsmouth PO1 3DE, England; [Ozcan, Sercan] Univ Portsmouth, Fac Business & Law, Portsmouth PO1 3DE, England; [Ozcan, Sercan] Bahcesehir Univ, Dept Engn Management, TR-34349 Istanbul, Turkiye	University of Portsmouth; University of Portsmouth; Bahcesehir University	Forner, D (corresponding author), Univ Portsmouth, Fac Business & Law, Strategy Enterprise & Innovat, Portsmouth PO1 3DE, England.	dominik.forner@myport.ac.uk; sercan.ozcan@port.ac.uk	Forner, Dominik/ABB-2123-2020	Forner, Dominik/0000-0001-7100-4998; Ozcan, Sercan/0000-0002-0482-7529				Acs ZJ, 2017, J TECHNOL TRANSFER, V42, P997, DOI 10.1007/s10961-016-9481-8; Acs ZJ, 2014, RES POLICY, V43, P476, DOI 10.1016/j.respol.2013.08.016; Afzal MNI, 2014, INT REV APPL ECON, V28, P507, DOI 10.1080/02692171.2014.896880; Agrawal A, 2003, INT J IND ORGAN, V21, P1227, DOI 10.1016/S0167-7187(03)00081-X; Alkemade F, 2015, RES POLICY, V44, P1763, DOI 10.1016/j.respol.2015.01.007; Amable B, 2000, REV INT POLIT ECON, V7, P645, DOI 10.1080/096922900750034572; Aminullah E, 2012, ASIAN J TECHNOL INNO, V20, P99, DOI 10.1080/19761597.2012.683946; Andersson M, 2019, RESOUR POLICY, V63, DOI 10.1016/j.resourpol.2019.101403; Andersson M, 2017, ENVIRON INNOV SOC TR, V25, P142, DOI 10.1016/j.eist.2017.03.001; Asheim BT, 2011, REG STUD, V45, P875, DOI 10.1080/00343404.2011.596701; Asheim BT, 2005, RES POLICY, V34, P1173, DOI 10.1016/j.respol.2005.03.013; Babai D. O., 2018, Econ. Law, V2, P34; Bai JH, 2013, REG STUD, V47, P773, DOI 10.1080/00343404.2011.591784; Bassis NF, 2018, J EVOL ECON, V28, P1053, DOI 10.1007/s00191-018-0600-6; Baudry M, 2006, RES POLICY, V35, P324, DOI 10.1016/j.respol.2005.12.004; Bergek A, 2008, TECHNOL ANAL STRATEG, V20, P575, DOI 10.1080/09537320802292768; Bergek A, 2008, RES POLICY, V37, P407, DOI 10.1016/j.respol.2007.12.003; Bergek A, 2008, TECHNOVATION, V28, P20, DOI 10.1016/j.technovation.2007.07.008; Bergek A, 2015, ENVIRON INNOV SOC TR, V16, P51, DOI 10.1016/j.eist.2015.07.003; Berman A, 2020, REG STUD, V54, P677, DOI 10.1080/00343404.2019.1672865; Bhatia S., 2016, Proceedings of the 26th International Conference on Computational Linguistics (COLING 2016), P953; Binz C, 2017, RES POLICY, V46, P1284, DOI 10.1016/j.respol.2017.05.012; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Breschi S, 2000, ECON J, V110, P388, DOI 10.1111/1468-0297.00530; Breznitz D, 2007, RES POLICY, V36, P1465, DOI 10.1016/j.respol.2007.06.006; BROWN WB, 1989, IEEE T ENG MANAGE, V36, P11, DOI 10.1109/17.19977; Campbell D. M., 2018, Public Health Res. Pract., V28, P2016; Carayannis EG, 2016, EXPERT SYST APPL, V62, P63, DOI 10.1016/j.eswa.2016.06.017; Carlsson B., 1997, In search of a useful technology policy- general lessons and key issues for policy makers Technological Systems and Industrial Dynamics, P299, DOI 10.1007/978-1-4615-6133-011; Carlsson B., 1995, TECHNOLOGICAL SYSTEM, P21; Chiarini Tulio, 2012, Nova econ., V22, P307, DOI 10.1590/S0103-63512012000200004; Christensen JF, 2005, RES POLICY, V34, P1533, DOI 10.1016/j.respol.2005.07.002; Colombo MG, 2002, RES POLICY, V31, P1103, DOI 10.1016/S0048-7333(01)00178-0; Consoli D, 2009, J EVOL ECON, V19, P297, DOI 10.1007/s00191-008-0127-3; Consoli D, 2008, IND INNOV, V15, P579, DOI 10.1080/13662710802550893; Cooke P, 1997, RES POLICY, V26, P475, DOI 10.1016/S0048-7333(97)00025-5; COOKE P, 1992, GEOFORUM, V23, P365, DOI 10.1016/0016-7185(92)90048-9; Cooke P, 1998, ENVIRON PLANN A, V30, P1563, DOI 10.1068/a301563; Crescenzi R, 2017, INT J URBAN REGIONAL, V41, P1010, DOI 10.1111/1468-2427.12554; Crespo NF, 2016, J BUS RES, V69, P5265, DOI 10.1016/j.jbusres.2016.04.123; Cuhls K, 2009, TECHNOL FORECAST SOC, V76, P1187, DOI 10.1016/j.techfore.2009.07.010; de Waal M, 2017, IT-INF TECHNOL, V59, P263, DOI 10.1515/itit-2017-0012; Dosi G., 1988, Technical Change and Economic Theory; Eastwood C, 2017, J RURAL STUD, V49, P1, DOI 10.1016/j.jrurstud.2016.11.008; Edmunds LD, 2019, HEALTH RES POLICY SY, V17, DOI 10.1186/s12961-019-0414-5; Edquist C, 2019, RES POLICY, V48, P869, DOI 10.1016/j.respol.2018.10.008; Edquist Charles., 1997, SYSTEMS INNOVATION T, DOI DOI 10.1016/S0024-6301(98)90244-8; Edsand HE, 2017, TECHNOL SOC, V49, P1, DOI 10.1016/j.techsoc.2017.01.002; Eklund M, 2017, IMP J, V11, P417, DOI 10.1108/IMP-04-2016-0005; Ervits I, 2018, MULTINATL BUS REV, V26, P25, DOI 10.1108/MBR-07-2017-0052; Ferdinands Gerbrich, 2020, Active learning for screening prioritization in systematic reviews-A simulation study; Ferrier F, 1805, Du Gouvernement Considere Dans Ses Rapports Avec Le Commerce; Fielke S, 2017, OUTLOOK AGR, V46, P117, DOI 10.1177/0030727017708490; FREEMAN C, 1995, CAMBRIDGE J ECON, V19, P5; Freeman C., 1988, TECHNICAL CHANGE EC; Fritsch M, 2011, REG STUD, V45, P905, DOI 10.1080/00343400802251494; Frolov A. V., 2018, Outlines Glob. Transformations, Politics, Econ., Law, V11, P151; Gabaldón-Estevan D, 2014, J CLEAN PROD, V70, P242, DOI 10.1016/j.jclepro.2014.02.018; Gao SJ, 2001, INT J TECHNOL MANAGE, V22, P568, DOI 10.1504/IJTM.2001.002978; Garb Y, 2014, AGR SYST, V128, P13, DOI 10.1016/j.agsy.2014.04.003; Geels FW, 2004, RES POLICY, V33, P897, DOI 10.1016/j.respol.2004.01.015; Ghazinoory S, 2020, TECHNOL FORECAST SOC, V150, DOI 10.1016/j.techfore.2019.119749; Giurca A, 2018, ENVIRON INNOV SOC TR, V26, P1, DOI 10.1016/j.eist.2017.09.001; Gosens J, 2015, J CLEAN PROD, V86, P378, DOI 10.1016/j.jclepro.2014.08.029; Guan HL, 2016, J INTELL FUZZY SYST, V31, P1319, DOI 10.3233/IFS-162198; Gupta P, 2019, AAAI CONF ARTIF INTE, P6505; Haase R, 2013, ENERG POLICY, V61, P1595, DOI 10.1016/j.enpol.2013.06.029; Hage J, 2000, ORGAN STUD, V21, P971, DOI 10.1177/0170840600215006; Hartwich F, 2010, AGRIBUSINESS, V26, P425, DOI 10.1002/agr.20231; Hekkert MP, 2007, TECHNOL FORECAST SOC, V74, P413, DOI 10.1016/j.techfore.2006.03.002; Hellsmark H, 2009, ENERG POLICY, V37, P5597, DOI 10.1016/j.enpol.2009.08.023; Herrmann AM, 2011, RES POLICY, V40, P687, DOI 10.1016/j.respol.2011.02.004; Hipp A, 2020, RES POLICY, V49, DOI 10.1016/j.respol.2019.103876; Hirsch-Kreinsen H, 2011, IND INNOV, V18, P351, DOI 10.1080/13662716.2011.573954; Hlibko S., 2019, Acta Innov., V33, P73; Hoppmann J, 2014, RES POLICY, V43, P1422, DOI 10.1016/j.respol.2014.01.014; Hu MC, 2011, SCIENTOMETRICS, V88, P949, DOI 10.1007/s11192-011-0427-5; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Hudec O, 2015, QUAL INNOV PROSPER, V19, P55, DOI 10.12776/QIP.V19I2.593; Isaac ME, 2012, AGR SYST, V109, P9, DOI 10.1016/j.agsy.2012.01.011; Islam N, 2009, TECHNOL FORECAST SOC, V76, P128, DOI 10.1016/j.techfore.2008.03.021; Ivanova I, 2019, J KNOWL ECON, V10, P18, DOI 10.1007/s13132-017-0480-2; Ivanova I, 2017, TECHNOL FORECAST SOC, V120, P77, DOI 10.1016/j.techfore.2017.04.007; Ivanova IA, 2014, TECHNOL FORECAST SOC, V86, P143, DOI 10.1016/j.techfore.2013.08.022; Ivanova IA, 2014, SCIENTOMETRICS, V99, P927, DOI 10.1007/s11192-014-1241-7; Jaaniste L, 2009, AUST J PUBL ADMIN, V68, P272, DOI 10.1111/j.1467-8500.2009.00639.x; Jacobsson S, 2013, ENERG POLICY, V63, P1182, DOI 10.1016/j.enpol.2013.08.077; Jarsky V, 2015, FOREST POLICY ECON, V59, P56, DOI 10.1016/j.forpol.2015.05.012; Jiang H, 2012, INFORM TECHNOL MANAG, V13, P251, DOI 10.1007/s10799-012-0133-x; Jiao H, 2016, TECHNOL FORECAST SOC, V110, P13, DOI 10.1016/j.techfore.2016.03.025; Jin W, 2019, J CLEAN PROD, V211, P61, DOI 10.1016/j.jclepro.2018.11.172; Joachims T., 2006, P 12 ACM SIGKDD INT, P217, DOI [10.1145/1150402.1150429, DOI 10.1145/1150402.1150429]; Johnsen HCG, 2004, SYST PRACT ACT RES, V17, P207, DOI 10.1023/B:SPAA.0000031698.50541.f9; Jung M, 2010, IND CORP CHANGE, V19, P1037, DOI 10.1093/icc/dtp054; Jurowetzki R, 2018, EUR J DEV RES, V30, P364, DOI 10.1057/s41287-018-0137-4; Kamara LI, 2019, AGR SYST, V176, DOI 10.1016/j.agsy.2019.102673; Kamunyori S, 2010, BMC INT HEALTH HUM R, V10, DOI 10.1186/1472-698X-10-S1-S5; Kang D., 2019, Journal of Open Innovation: Technology, Market, and Complexity, V5, P82, DOI DOI 10.3390/JOITMC5040082; Kempton L, 2019, EUR PLAN STUD, V27, P2248, DOI 10.1080/09654313.2019.1628183; Kim YJ, 2019, ENERG POLICY, V134, DOI 10.1016/j.enpol.2019.110942; Kim YZ, 2008, GLOBAL ECON REV, V37, P135, DOI 10.1080/12265080802021151; Kivimaa P, 2016, RES POLICY, V45, P205, DOI 10.1016/j.respol.2015.09.008; Kolishchuk O., 2020, Path Sci., V6, P2001; Korhonen J, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103785; Kristinsson K, 2008, IND INNOV, V15, P297, DOI 10.1080/13662710802040903; Kukk P, 2016, RES POLICY, V45, P70, DOI 10.1016/j.respol.2016.01.016; Lander B, 2014, REV POLICY RES, V31, P390, DOI 10.1111/ropr.12086; Lau Jey Han, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, P1536; Lau JH, 2016, P 1 WORKSH REPR LEAR, P78, DOI DOI 10.18653/V1/W16-1609; Lee PC, 2010, INNOV-MANAG POLICY P, V12, P26, DOI 10.5172/impp.12.1.26; Leydesdorff L, 2000, RES POLICY, V29, P243, DOI 10.1016/S0048-7333(99)00063-3; Leydesdorff L, 2014, J ASSOC INF SCI TECH, V65, P386, DOI 10.1002/asi.22973; Li D, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11102982; Li H, 2018, SUSTAIN CITIES SOC, V42, P355, DOI 10.1016/j.scs.2018.07.001; List Friedrich., 1841, Das nationale System der politischen Okonomie; Ljovkina A. O., 2019, Resources, V8, P1; Lundvall B.A., 1988, TECHNICAL CHANGE EC; Lundvall BÅ, 2002, RES POLICY, V31, P213, DOI 10.1016/S0048-7333(01)00137-8; Lundvall Bengt-Ake., 1999, INT STUDIES MANAGEME, V29, P60, DOI DOI 10.1080/00208825.1999.11656763; Lyu LC, 2019, J GEOGR SCI, V29, P1283, DOI 10.1007/s11442-019-1659-1; Makkonen T, 2016, EUR PLAN STUD, V24, P1623, DOI 10.1080/09654313.2016.1184626; Malerba F, 2002, RES POLICY, V31, P247, DOI 10.1016/S0048-7333(01)00139-1; Malerba F, 2005, ECON INNOV NEW TECH, V14, P63, DOI 10.1080/1043859042000228688; Mapila MATJ, 2012, DEV SO AFR, V29, P303, DOI 10.1080/0376835X.2012.675699; Markard J, 2008, RES POLICY, V37, P596, DOI 10.1016/j.respol.2008.01.004; Martin R, 2014, DISP, V50, P24, DOI 10.1080/02513625.2014.926722; Marx K., 1845, Collected Works, V4th, P265; Mayer H, 2016, CITIES, V51, P11, DOI 10.1016/j.cities.2016.01.005; Megnigbeto E., 2019, Journal of Industry -University Collaboration, V1, P96, DOI [10.1108/JIUC-03-2019-0008, DOI 10.1108/JIUC-03-2019-0008]; Mêgnigbêto E, 2018, J INFORMETR, V12, P1118, DOI 10.1016/j.joi.2018.09.005; Mesropyan VR, 2014, SCI TECH INF PROCESS, V41, P38, DOI 10.3103/S0147688214010080; Meyer-Krahmer F, 1998, RES POLICY, V27, P835, DOI 10.1016/S0048-7333(98)00094-8; Minguillo D, 2015, SCIENTOMETRICS, V102, P701, DOI 10.1007/s11192-014-1435-z; Moodysson J, 2017, SCI PUBL POLICY, V44, P382, DOI 10.1093/scipol/scw071; Moore J, 1996, FORTUNE, V133, P142; Moors EHM, 2018, TECHNOL FORECAST SOC, V128, P133, DOI 10.1016/j.techfore.2017.11.011; Muilerman S, 2018, INT J AGR SUSTAIN, V16, P167, DOI 10.1080/14735903.2018.1440469; Muller E, 2001, RES POLICY, V30, P1501, DOI 10.1016/S0048-7333(01)00164-0; Musiolik J, 2012, TECHNOL FORECAST SOC, V79, P1032, DOI 10.1016/j.techfore.2012.01.003; Narula R, 2016, MULTINATL BUS REV, V24, P249, DOI 10.1108/MBR-07-2016-0026; Nelson R., 1988, TECHNICAL CHANGE EC, P312; Ngila D, 2017, S AFR J SCI, V113, DOI 10.17159/sajs.2017/20170050; Nour SSOM, 2014, J KNOWL ECON, V5, P481, DOI 10.1007/s13132-014-0196-5; Nykvist B, 2013, ENERG POLICY, V55, P683, DOI 10.1016/j.enpol.2012.12.026; Oh DS, 2016, TECHNOVATION, V54, P1, DOI 10.1016/j.technovation.2016.02.004; Olsson L, 2015, J CLEAN PROD, V98, P107, DOI 10.1016/j.jclepro.2014.02.015; Oltra V, 2009, TECHNOL FORECAST SOC, V76, P567, DOI 10.1016/j.techfore.2008.03.025; Page L., 1999, Technical report, DOI [10.1007/978-3-319-08789-4_10, DOI 10.1109/IISWC.2012.6402911]; Parker R., 2011, ENGLISH GIGAWORD; Pechlaner H, 2012, TOUR REV, V67, P22, DOI 10.1108/16605371211236123; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Perry M, 2014, INNOV-ORGAN MANAG, V16, P286, DOI 10.1080/14479338.2014.11081989; Pittaway L, 2004, INT J MANAG REV, V5-6, P137, DOI 10.1111/j.1460-8545.2004.00101.x; Pradella Lucia., 2014, Globalization and the Critique of Political Economy: New Insights from Marxs Writings; Pugh R, 2018, ENVIRON PLAN C-POLIT, V36, P530, DOI 10.1177/2399654417717069; Putri Destyariani Liana, 2015, Procedia Earth and Planetary Science, V14, P136, DOI 10.1016/j.proeps.2015.07.094; Rakas M, 2019, RES POLICY, V48, DOI 10.1016/j.respol.2019.04.011; Rehurek R., 2011, Gensim-python framework for vector space modelling., V3, P2; Reichardt K, 2016, TECHNOL FORECAST SOC, V106, P11, DOI 10.1016/j.techfore.2016.01.029; Resende Marco Flávio da Cunha, 2016, Brazil. J. Polit. Econ., V36, P748, DOI 10.1590/0101-31572016v36n04a05; Sauer A, 2017, TECHNOL FORECAST SOC, V125, P321, DOI 10.1016/j.techfore.2016.08.017; Schut M, 2014, CROP PROT, V56, P98, DOI 10.1016/j.cropro.2013.11.017; Shmatko N, 2016, FORESIGHT, V18, P340, DOI 10.1108/FS-02-2014-0014; Somasekharan J., 2014, Agricultural Econ. Res. Rev., V27; Su Y, 2018, RENEW SUST ENERG REV, V89, P27, DOI 10.1016/j.rser.2018.03.005; Suominen A, 2019, EUR J INNOV MANAG, V22, P335, DOI 10.1108/EJIM-12-2017-0188; Teixeira AAC, 2014, CAMB J ECON, V38, P181, DOI 10.1093/cje/bet022; Teng TW, 2019, COGN SYST RES, V56, P159, DOI 10.1016/j.cogsys.2018.10.034; Tigabu AD, 2015, TECHNOL FORECAST SOC, V90, P318, DOI 10.1016/j.techfore.2013.10.011; Tödtling F, 2009, TECHNOVATION, V29, P59, DOI 10.1016/j.technovation.2008.05.002; Trippl M, 2009, ENVIRON PLANN A, V41, P1217, DOI 10.1068/a4129; Turner JA, 2017, OUTLOOK AGR, V46, P125, DOI 10.1177/0030727017708500; Uriona-Maldonado M, 2012, SCIENTOMETRICS, V91, P977, DOI 10.1007/s11192-012-0653-5; van de Schoot R, 2021, NAT MACH INTELL, V3, P125, DOI 10.1038/s42256-020-00287-7; van Welie MJ, 2019, ENVIRON INNOV SOC TR, V33, P196, DOI 10.1016/j.eist.2019.06.002; Vargas-Canales JM, 2019, REV CHAPINGO SER CIE, V25, P425, DOI 10.5154/r.rchscfa.2018.12.092; Verhees B, 2015, RENEW SUST ENERG REV, V47, P816, DOI 10.1016/j.rser.2015.02.036; Viotti EB, 2002, TECHNOL FORECAST SOC, V69, P653, DOI 10.1016/S0040-1625(01)00167-6; Wang D, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103385; Watanabe K, 2020, THEOR COMPUT SYST, V64, P1273, DOI 10.1007/s00224-020-09980-x; Weber KM, 2012, RES POLICY, V41, P1037, DOI 10.1016/j.respol.2011.10.015; Whicher A., 2017, Strategic Design Research Journal, V10, P117; Wong CY, 2012, J INFORMETR, V6, P55, DOI 10.1016/j.joi.2011.07.001; Yli-Renko H, 1998, SMALL BUS ECON, V11, P253, DOI 10.1023/A:1007909027839	184	1	1	14	21	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9391	1558-0040		IEEE T ENG MANAGE	IEEE Trans. Eng. Manage.	2023 SEP 18	2023										10.1109/TEM.2023.3310198	http://dx.doi.org/10.1109/TEM.2023.3310198		SEP 2023	15	Business; Engineering, Industrial; Management	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Business & Economics; Engineering	S6AY5					2024-07-03	WOS:001071982700001
J	Azeem, MI; Abualhaija, S				Azeem, Muhammad Ilyas; Abualhaija, Sallam			A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs	EMPIRICAL SOFTWARE ENGINEERING			English	Article						Requirements engineering (RE); The general data protection regulation (GDPR); Regulatory compliance; Data processing agreements (DPAs); Artificial intelligence (AI); Natural language processing (NLP); Classification; Large language models (LLMs); Few-shot learning (FSL); Data augmentation	AGREEMENT	Specifying legal requirements for software systems to ensure their compliance with the applicable regulations is a major concern of requirements engineering. Personal data which is collected by an organization is often shared with other organizations to perform certain processing activities. In such cases, the General Data Protection Regulation (GDPR) requires issuing a data processing agreement (DPA) which regulates the processing and further ensures that personal data remains protected. Violating GDPR can lead to huge fines reaching to billions of Euros. Software systems involving personal data processing must adhere to the legal obligations stipulated both at a general level in GDPR as well as the obligations outlined in DPAs highlighting specific business. In other words, a DPA is yet another source from which requirements engineers can elicit legal requirements. However, the DPA must be complete according to GDPR to ensure that the elicited requirements cover the complete set of obligations. Therefore, checking the completeness of DPAs is a prerequisite step towards developing a compliant system. Analyzing DPAs with respect to GDPR entirely manually is time consuming and requires adequate legal expertise. In this paper, we propose an automation strategy that addresses the completeness checking of DPAs against GDPR provisions as a text classification problem. Specifically, we pursue ten alternative solutions which are enabled by different technologies, namely traditional machine learning, deep learning, language modeling, and few-shot learning. The goal of our work is to empirically examine how these different technologies fare in the legal domain. We computed F 2 \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$_2$$\end{document} score on a set of 30 real DPAs. Our evaluation shows that best-performing solutions yield F 2 \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$_2$$\end{document} score of 86.7% and 89.7% are based on pre-trained BERT and RoBERTa language models. Our analysis further shows that other alternative solutions based on deep learning (e.g., BiLSTM) and few-shot learning (e.g., SetFit) can achieve comparable accuracy, yet are more efficient to develop.	[Azeem, Muhammad Ilyas; Abualhaija, Sallam] Univ Luxembourg, SnT, Esch Sur Alzette, Luxembourg	University of Luxembourg	Abualhaija, S (corresponding author), Univ Luxembourg, SnT, Esch Sur Alzette, Luxembourg.	ilyasazeem@live.com; sallam.abualhaija@uni.lu		Abualhaija, Sallam/0000-0001-6095-447X	Fonds National de la Recherche Luxembourg [BRIDGES/19/IS/13759068/ARTAGO]; Linklaters and Luxembourg's National Research Fund [NCER22/IS/16570468/NCER-FT]; Luxembourg National Research Fund (FNR)	Fonds National de la Recherche Luxembourg(Luxembourg National Research Fund); Linklaters and Luxembourg's National Research Fund; Luxembourg National Research Fund (FNR)(Luxembourg National Research Fund)	This paper was supported by Linklaters and Luxembourg's National Research Fund under grant BRIDGES/19/IS/13759068/ARTAGO. This research was further funded in whole, or in part, by the Luxembourg National Research Fund (FNR), grant reference NCER22/IS/16570468/NCER-FT. For the purpose of open access, and in fulfillment of the obligations arising from the grant agreement, the author has applied a Creative Commons Attribution 4.0 International (CC BY 4.0) license to any Author Accepted Manuscript version arising from this submission.	Abualhaija S, 2022, 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022), P39, DOI 10.1109/RE54965.2022.00011; Akhigbe O, 2022, SOFTW SYST MODEL, V21, P1613, DOI 10.1007/s10270-021-00949-z; Al-Kaswan A, 2023, Arxiv, DOI arXiv:2302.13149; Alhoshan W, 2023, INFORM SOFTWARE TECH, V159, DOI 10.1016/j.infsof.2023.107202; Amaral O, 2021, IEEE Trans Softw Eng; Amaral O, 2023, 2023 IEEE 31 INT REQ, P53, DOI [10.1109/RE57278.2023.00015, DOI 10.1109/RE57278.2023.00015]; Amaral O, 2021, 2021 IEEE 29 INT REQ; Arora C, 2019, EMPIR SOFTW ENG, V24, P2509, DOI 10.1007/s10664-019-09693-x; Barati M, 2020 INT S NETW COMP, P1; Barati M, 2020, IEEE ACCESS, V8, P119697, DOI 10.1109/ACCESS.2020.3005509; Bashir S, 2023, LECT NOTES COMPUT SC, V13975, P105, DOI 10.1007/978-3-031-29786-1_8; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Berry DM, 2017, 2017 IEEE 25TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P284, DOI 10.1109/REW.2017.25; Bhatia J, 2019, Require Eng, V24; Bird S., 2006, PAPER PRESENTED COLI, P69, DOI [10.48550/arXiv.cs/0205028, DOI 10.3115/1225403.1225421, 10.3115/1225403.1225421]; Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070; Breaux TD, 2022, 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022), P101, DOI 10.1109/RE54965.2022.00016; Breitbarth Paul, 2019, Network Security, V2019, P11, DOI 10.1016/S1353-4858(19)30084-4; Cejas OA, 2023, IEEE T SOFTWARE ENG, V49, P4282, DOI 10.1109/TSE.2023.3288901; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Dalpiaz F, 2018, LECT NOTES COMPUT SC, V10753, P119, DOI 10.1007/978-3-319-77243-1_8; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; EUR-Lex, 2018, Directive (EU) 2018/2001 of the European parliament and of the council of 11 december 2018 on the promotion of the use of energy from renew- able sources, DOI DOI 10.1007/3-540-47891-4_10; European Union, 2018, Justice and Consumers; Feal A, 2021, Data Protection and Privacy, Volume 13: Data Protection and Artificial Intelligence, V13, P1; Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI [10.7551/mitpress/7287.001.0001, DOI 10.7551/MITPRESS/7287.001.0001]; Ferrari Alessio, 2014, Requirements Engineering: Foundation for Software Quality. 20th International Working Conference, REFSQ 2014. Proceedings: LNCS 8396, P23, DOI 10.1007/978-3-319-05843-6_3; Freitas M. D. C., 2018, J. Inf. Syst. Eng. Manage., V3, P30, DOI 10.20897/jisem/3941; Gebauer M, 2023, Arxiv, DOI arXiv:2305.15006; Ghanavati S, 2014, INT REQUIR ENG CONF, P73, DOI 10.1109/RE.2014.6912249; Gokaslan A., 2019, Openwebtext corpus; Halterman A, 2023, Arxiv, DOI arXiv:2304.01331; Halterman A, 2023, Arxiv, DOI arXiv:2303.16028; Ingolfo S, 2014, INT REQUIR ENG CONF, P313, DOI 10.1109/RE.2014.6912273; Islam QN, 2015, Mastering PyCharm; Ji YS, 2011, J COMPUT SCI TECH-CH, V26, P81, DOI 10.1007/s11390-011-9417-6; Johansson E, 2019, ACRN Journal of Finance and Risk Perspectives, V8, P71; Kashyap AR, 2024, Arxiv, DOI arXiv:2305.12641; Pushp PK, 2017, Arxiv, DOI arXiv:1712.05972; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Li BH, 2022, AI OPEN, V3, P71, DOI 10.1016/j.aiopen.2022.03.001; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luitel D, 2023, LECT NOTES COMPUT SC, V13975, P87, DOI 10.1007/978-3-031-29786-1_7; Matulevicius Raimundas, 2020, Advanced Information Systems Engineering. CAiSE Forum 2020. Proceedings. Lecture Notes in Business Information Processing (LNBIP 386), P100, DOI 10.1007/978-3-030-58135-0_9; Maxwell JC, 2012, REQUIR ENG, V17, P99, DOI 10.1007/s00766-012-0152-5; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Montgomery L, 2022, REQUIR ENG, V27, P183, DOI 10.1007/s00766-021-00367-z; Nagel S, 2016, Cc-news; Otto PN, 2007, INT REQUIR ENG CONF, P5, DOI 10.1109/RE.2007.65; Pantlin N, 2018, COMPUT LAW SECUR REV, V34, P881, DOI 10.1016/j.clsr.2018.06.009; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pullonen P, 2019, SOFTW SYST MODEL, V18, P3235, DOI 10.1007/s10270-019-00718-z; Rasiman R, 2022, LECT NOTES COMPUT SC, V13216, P35, DOI 10.1007/978-3-030-98464-9_4; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Schick T, 2022, T ASSOC COMPUT LING, V10, P716, DOI 10.1162/tacl_a_00485; Singhal A, 2022, P 1 INT C AI ENG SOF, P145, DOI DOI 10.1145/3522664.3528604; Sleimi A, 2019, INT REQUIR ENG CONF, P319, DOI 10.1109/RE.2019.00041; Soltana G, 2018, SOFTW SYST MODEL, V17, P851, DOI 10.1007/s10270-016-0542-0; Soltana G, 2014, LECT NOTES COMPUT SC, V8767, P450, DOI 10.1007/978-3-319-11653-2_28; Torre D, 2021, SOFTW SYST MODEL, V20, P2071, DOI 10.1007/s10270-021-00935-5; Torre D, 2020, INT REQUIR ENG CONF, P136, DOI 10.1109/RE48521.2020.00025; Torre D, 2019, 2019 ACM/IEEE 22ND INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS (MODELS 2019), P1, DOI 10.1109/MODELS.2019.00-20; Tunstall L, 2022, P 36 C NEUR INF PROC; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Viera AJ, 2005, FAM MED, V37, P360; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zeni N, 2015, REQUIR ENG, V20, P1, DOI 10.1007/s00766-013-0181-8; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11; Zowghi D., 2002, International Workshop on Requirements Engineering: Foundations for Software Quality, P155	71	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1382-3256	1573-7616		EMPIR SOFTW ENG	Empir. Softw. Eng.	JUL	2024	29	4							96	10.1007/s10664-024-10491-3	http://dx.doi.org/10.1007/s10664-024-10491-3			31	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UL4T9		hybrid			2024-07-03	WOS:001248208700001
J	Bozkurt, A				Bozkurt, Aras			Tell Me Your Prompts and I Will Make Them True: The Alchemy of Prompt Engineering and Generative AI	OPEN PRAXIS			English	Article						prompt engineering; cocreation; human-AI interaction; generative AI; GenAI; artificial intelligence; AI; AIEd; education; higher education; educational technology; generative pre-trained transformer; GPT; ChatGPT; large language models; LLMs; natural language processing; NLP		This paper explores the emerging field of prompt engineering within generative AI, emphasizing its role as a critical intersection between art and science. Prompt engineering is identified as the key to unlocking the full potential of generative AI technologies by optimizing human-AI communication. Through a comprehensive analysis of the related literature, this study illustrates how prompt engineering transcends mere technical manipulation, requiring a blend of creativity, strategic thinking, and a deep understanding of generative AI capabilities. This paper provides various strategies for crafting effective prompts, from simple to sophisticated techniques, highlighting the importance of ethical considerations and the potential risks associated with prompt manipulation. By establishing a set of principles and guidelines, this paper aims to advance prompt engineering as a discipline essential for enhancing AI's functionality and reliability and, with this justification, introduces the 'Prompt Engineering for Gen[i]e rative AI Framework'. After all, this paper calls for a multidisciplinary approach to prompt engineering, advocating for its recognition and development as a pivotal component of AI literacy and application. Through this exploration, this paper intends to contribute to the evolving dialogue on the integration of human creativity with generative AI capabilities, offering insights into the future of effective and ethical AI interaction.	[Bozkurt, Aras] Anadolu Univ, Eskisehir, Turkiye	Anadolu University	Bozkurt, A (corresponding author), Anadolu Univ, Eskisehir, Turkiye.	arasbozkurt@gmail.com	BOZKURT, Aras/O-3654-2017	BOZKURT, Aras/0000-0002-4520-642X	Anadolu University [SBA-2023-1852]	Anadolu University(Anadolu University)	This paper is funded by Anadolu University with grant number SBA-2023-1852.	[Anonymous], 1637, Discourse on the Method of Rightly Conducting One's Reason and of Seeking Truth in the Sciences; Ansari AN, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12223-4; Bozkurt A., 2023, Asian Journal of Distance Education, V18, pi, DOI [10.5281/zenodo.8174941, DOI 10.5281/ZENODO.8174941]; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P53, DOI [10.5281/zenodo.7636568, DOI 10.5281/ZENODO.7636568]; Bozkurt A., 2023, Asian Journal of Distance Education, DOI [DOI 10.5281/ZENODO.7716416, 10.5281/zenodo.7716416]; Bozkurt A, 2024, OPEN PRAX, V16, P1, DOI 10.55982/openpraxis.16.1.654; Bozkurt A, 2023, OPEN PRAX, V15, P178, DOI 10.55982/openpraxis.15.3.579; Bozkurt A, 2023, OPEN PRAX, V15, P261, DOI 10.55982/openpraxis.15.4.609; Bsharat SM, 2024, Arxiv, DOI arXiv:2312.16171; Chen BH, 2024, Arxiv, DOI [arXiv:2310.14735, 10.48550/arXiv.2310.14735]; Dang H, 2022, Arxiv, DOI arXiv:2209.01390; Diao SZ, 2024, Arxiv, DOI arXiv:2302.12246; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Gates B, 2023, The Age of AI has begun; Johnson WL, 2023, INT J ARTIF INTELL E, DOI 10.1007/s40593-023-00367-w; Kakun A, 2023, Modern Engineering and Innovative Technologies, V1, P117, DOI [10.30890/2567-5273.2023-29-01-052, DOI 10.30890/2567-5273.2023-29-01-052]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li ZK, 2023, Arxiv, DOI [arXiv:2302.11520, 10.48550/arXiv.2302.11520, DOI 10.48550/ARXIV.2302.11520]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Y, 2024, Arxiv, DOI [arXiv:2305.13860, DOI 10.48550/ARXIV.2305.13860, 10.48550/arXiv.2305.13860]; Liu Z., 2023, WEB C, P417, DOI DOI 10.1145/3543507.3583386; Lo L. S., 2023, Internet Reference Services Quarterly, V27, P203, DOI DOI 10.1080/10875301.2023.2227621; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; McGuire A., 2023, Irish Journal of Technology Enhanced Learning, V7, P21, DOI [10.22554/ijtel.v7i2.131, DOI 10.22554/IJTEL.V7I2.131]; Merriam-Webster, 2024, Art; O'Connor S, 2024, NURSE EDUC PRACT, V74, DOI 10.1016/j.nepr.2023.103825; OpenAI, 2022, Introducing chatgpt; OpenAI, 2023, ChatGPT can now see, hear, and speak; OpenAI, 2023, Prompt Engineering; Paranjape B, 2023, Arxiv, DOI arXiv:2303.09014; Sari T., 2024, Journal of Educational Technology and Online Learning, V7, P102, DOI [10.31681/jetol.1308022, DOI 10.31681/JETOL.1308022]; Sharma R. C., 2024, Transforming Education With Generative AI: Prompt Engineering and Synthetic Content Creation, DOI [10.4018/979-8-3693-1351-0, DOI 10.4018/979-8-3693-1351-0]; Velasquez-Henao J.D., 2023, Dyna, V90, P9, DOI [10.15446/dyna.v90n230.111700, DOI 10.15446/DYNA.V90N230.111700]; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yong G, 2023, COMPUT-AIDED CIV INF, V38, P1536, DOI 10.1111/mice.12954; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	40	0	0	3	3	INT COUNCIL OPEN & DISTANCE EDUCATION	OSLO	LILLEAKERVEIEN 23, OSLO, 0283, NORWAY	2304-070X			OPEN PRAX	Open Prax.		2024	16	2					111	118		10.55982/openpraxis.16.2.661	http://dx.doi.org/10.55982/openpraxis.16.2.661			8	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	TO9Z7		gold			2024-07-03	WOS:001242333800001
J	Bozkurt, A				Bozkurt, Aras			Unleashing the Potential of Generative AI, Conversational Agents and Chatbots in Educational Praxis: A Systematic Review and Bibliometric Analysis of GenAI in Education	OPEN PRAXIS			English	Review						Generative AI; GenAI; artificial intelligence; AI; chatbots; conversational agents; education; teaching; learning; higher education; educational technology; GPT; generative pre-trained transformer; ChatGPT; large language models; LLMs; natural language processing; systematic review; bibliometric analysis	ARTIFICIAL-INTELLIGENCE	In the rapidly evolving landscape of education, the pivotal axis around which transformation revolves is human-AI interaction. In this sense, this paper adopts a data mining and analytic approach to understand what the related literature tells us regarding the trends and patterns of generative AI research in educational praxis. Accordingly, this systematic exploration spotlights the following research themes: Interaction and communication with generative AI-powered chatbots; impact of the LLMs and generative AI on teaching and learning, conversational educational agents and their opportunities, challenges, and implications; leveraging Generative AI for enhancing social and cognitive learning processes; promoting AI literacy for unleashing future opportunities; harnessing Generative AI to expand academic capabilities, and lastly, augmenting educational experiences through human-AI interaction. Beyond the identified research themes and patterns, this paper argues that emotional intelligence, AI literacy, and prompt engineering are the trending research topics that require further exploration. Accordingly, it's in this praxis that emotional intelligence emerges as a pivotal attribute, as AI technologies often struggle to comprehend and respond to the nuanced emotional cues. Generative AI literacy then takes center stage, becoming an indispensable asset in an era permeated with AI technologies, equipping students with the tools to critically engage with AI systems, thereby ensuring they become active, discerning users of these powerful tools. Concurrently, prompt engineering, the art of crafting queries that yield precise and valuable responses from AI systems, empowers both educators and students to maximize the utility of AI-driven educational resources.	[Bozkurt, Aras] Anadolu Univ, Eskisehir, Turkiye	Anadolu University	Bozkurt, A (corresponding author), Anadolu Univ, Eskisehir, Turkiye.	arasbozkurt@gmail.com	BOZKURT, Aras/O-3654-2017	BOZKURT, Aras/0000-0002-4520-642X	Anadolu University [SBA-2023-1852]	Anadolu University(Anadolu University)	This paper is funded by Anadolu University with grant number SBA-2023-1852.	[Anonymous], 2002, Information Visualization in Data Mining and Knowledge Discovery; Ansari AN, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12223-4; Bahroun Z, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151712983; Bozkurt A., 2023, Asian Journal of Distance Education, V18, pi, DOI [10.5281/zenodo.8174941, DOI 10.5281/ZENODO.8174941]; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P53, DOI [10.5281/zenodo.7636568, DOI 10.5281/ZENODO.7636568]; Bozkurt A., 2023, Asian Journal of Distance Education, DOI [DOI 10.5281/ZENODO.7716416, 10.5281/zenodo.7716416]; Bozkurt A., 2023, Encyclopedia of Postdigital Science and Education, DOI [10.1007/978-3-031-35469-4_2-2, DOI 10.1007/978-3-031-35469-4_2-2]; Bozkurt A, 2023, OPEN PRAX, V15, P178, DOI 10.55982/openpraxis.15.3.579; Dempere J, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1206936; Donthu N, 2021, J BUS RES, V133, P285, DOI 10.1016/j.jbusres.2021.04.070; enocak D., 2023, Pakistan Journal of Education, V40, P67; Feldman R., 2007, The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data, DOI DOI 10.1017/CBO9780511546914; Gough D., 2012, An introduction to systematic reviews; Griffith E., 2023, NEW YORK TIMES; Hansen DL, 2011, ANALYZING SOCIAL MEDIA NETWORKS WITH NODEXL: INSIGHTS FROM A CONNECTED WORLD, P11, DOI 10.1016/B978-0-12-382229-1.00002-3; Lambert J, 2023, COMPUT SCH, DOI 10.1080/07380569.2023.2256710; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Montenegro-Rueda M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080153; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; pek I., 2023, Educational Process: International Journal, V12, P26, DOI [10.22521/edupij.2023.123.2, DOI 10.22521/EDUPIJ.2023.123.2]; Pradana M, 2023, COGENT EDUC, V10, DOI 10.1080/2331186X.2023.2243134; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Schulman J, 2022, Introducing chatgpt; Thurmond VA, 2001, J NURS SCHOLARSHIP, V33, P253, DOI 10.1111/j.1547-5069.2001.00253.x; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Yan LX, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13370; Yu H, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1183162	28	4	4	168	184	INT COUNCIL OPEN & DISTANCE EDUCATION	OSLO	LILLEAKERVEIEN 23, OSLO, 0283, NORWAY	2304-070X			OPEN PRAX	Open Prax.		2023	15	4					261	270		10.55982/openpraxis.15.4.609	http://dx.doi.org/10.55982/openpraxis.15.4.609			10	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Z5ZZ8		gold			2024-07-03	WOS:001112866700002
J	Hájek, A; Horák, A				Hajek, Adam; Horak, Ales			CzeGPT-2-Training New Model for Czech Generative Text Processing Evaluated With the Summarization Task	IEEE ACCESS			English	Article						Task analysis; Training; Measurement; Transformers; Decoding; Computational modeling; Vocabulary; Natural language processing; Modeling; Performance evaluation; Text analysis; Text recognition; Question answering (information retrieval); Czech; GPT-2; large language model; model evaluation; model training; summarization		Automatic text summarization (ATS), alongside neural machine translation or question answering, is one of the leading tasks in Natural Language Processing (NLP). In recent years, ATS has experienced significant development, especially in the English NLP world. Modern approaches are mainly based on the versatile Transformer architecture proposed by Vaswani et al. in 2017, which has revolutionized the field, and was later tuned and adjusted to various needs of different tasks. Non-mainstream languages, with Czech taken as a representative, on the other hand, are a little bit behind these efforts and tend to use lighter or heuristic methods. With the new CzeGPT-2 model and abstractive summarizer, we would like to take a step forward detailing the process of training a GPT-2 generative transformer model for a new language with a comprehensive evaluation of the task of Czech summarization and pointing out the benefits of this approach. We also present an in-depth analysis of the errors in generated summaries, allowing to locate the model's weak spots.	[Hajek, Adam; Horak, Ales] Masaryk Univ, Fac Informat, Nat Language Proc Ctr, Brno 60200, Czech Republic	Masaryk University Brno	Horák, A (corresponding author), Masaryk Univ, Fac Informat, Nat Language Proc Ctr, Brno 60200, Czech Republic.			Hajek, Adam/0009-0008-3638-2959	Ministry of Education of the Czech Republic (CR) within the LINDAT-CLARIAH-CZ Project	Ministry of Education of the Czech Republic (CR) within the LINDAT-CLARIAH-CZ Project	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alammar J., 2018, The Illustrated Transformer; Alomari A. S., 2023, IEEE Access, V11; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bojanowski P, 2017, Arxiv, DOI [arXiv:1607.04606, DOI 10.48550/ARXIV.1607.04606]; Dalal M, 2019, Arxiv, DOI arXiv:1910.07737; Demirci D, 2022, IEEE ACCESS, V10, P58488, DOI 10.1109/ACCESS.2022.3179384; Dudy Shiran, 2020, Proc Conf Empir Methods Nat Lang Process, V2020, P131, DOI 10.18653/v1/2020.eval4nlp-1.13; Ghadimi A, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116292; Guillou P., 2020, Tech. Rep; han B., 2023, IEEE Access, V11; Ireland S., 2022, ABOUT US, P2890; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Koh J. Ju, 2023, ACM Comput.Surv., V55, P1; Krotil M., 2022, M.S. thesis; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu P., P 60 ANN M ASS COMP, V1; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; Lux K.M., 2020, P 1 WORKSH EV COMP N, P1; Marek P., 2021, Prague Bull Math Linguist, V116, P5; Moratanch N, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016); Smith LN, 2018, Arxiv, DOI [arXiv:1708.07120, 10.48550/ARXIV.1708.07120]; Naismith B., 2023, P 18 WORKSHOP INNOVA, P394, DOI DOI 10.18653/V1/2023.BEA-1.32; Park K, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P133; Radford A., 2018, Improvinglanguage understanding by generative pre-training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sanchez-Gomez JM, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116769; Sido J, 2021, Arxiv, DOI arXiv:2103.13031; Straka J., 2021, inText, Speech, and Dialogue, P197, DOI [10.1007/978-3-030-83527-9_17#citeas[18]Small-E-Czech,Seznam, DOI 10.1007/978-3-030-83527-9_17#CITEAS[18]SMALL-E-CZECH,SEZNAM]; Straka M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3488; Sutskever I., 2011, Proceedings of the 28th International Conference on Machine Learning (ICML-11), P1017; uyen C., 2019, Gradient; Wang CG, 2019, Arxiv, DOI [arXiv:1904.09408, DOI 10.48550/ARXIV.1904.09408]; Wies N., 2021, Proc. Int. Conf. Mach. Learn, P11170; Wolf T, 2020, Transformers: Perplexity of Fixed-length Models; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Zhang MR, 2023, Arxiv, DOI arXiv:2305.13534	39	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						34570	34581		10.1109/ACCESS.2024.3371689	http://dx.doi.org/10.1109/ACCESS.2024.3371689			12	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	KE7F3		gold			2024-07-03	WOS:001178339600001
J	Shen, TY; Sun, JL; Kong, SH; Wang, YT; Li, JJ; Li, X; Wang, FY				Shen, Tianyu; Sun, Jinlin; Kong, Shihan; Wang, Yutong; Li, Juanjuan; Li, Xuan; Wang, Fei-Yue			The Journey/DAO/TAO of Embodied Intelligence: From Large Models to Foundation Intelligence and Parallel Intelligence	IEEE-CAA JOURNAL OF AUTOMATICA SINICA			English	Article						Artificial intelligence; Chatbots; Autonomous systems; Intelligent systems; Robots; Digital humans; Robot kinematics; Learning (artificial intelligence); Biological system modeling; Computational modeling; Human-robot interaction; Complex systems; Deep learning; Reinforcement learning; Large language models	METAVERSES; SYSTEMS; CHATGPT	The tremendous impact of large models represented by ChatGPT [1]-[3] makes it necessary to consider the practical applications of such models [4]. However, for an artificial intelligence (AI) to truly evolve, it needs to possess a physical "body" to transition from the virtual world to the real world and evolve through interaction with the real environments. In this context, "embodied intelligence" has sparked a new wave of research and technology, leading AI beyond the digital realm into a new paradigm that can actively act and perceive in a physical environment through tangible entities such as robots and automated devices [5].	[Shen, Tianyu] Beijing Univ Chem Technol, Coll Informat Sci & Technol, Beijing 100029, Peoples R China; [Sun, Jinlin] Jiangsu Univ, Sch Elect & Informat Engn, Zhenjiang 212013, Peoples R China; [Kong, Shihan] Peking Univ, Coll Engn, Dept Adv Mfg & Robot, State Key Lab Turbulence & Complex Syst, Beijing 100871, Peoples R China; [Wang, Yutong; Li, Juanjuan] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China; [Li, Xuan] Peng Cheng Lab, Shenzhen 518000, Peoples R China; [Wang, Fei-Yue] Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China; [Wang, Fei-Yue] Macau Univ Sci & Technol, Fac Innovat Engn, Macau 999078, Peoples R China	Beijing University of Chemical Technology; Jiangsu University; Peking University; Chinese Academy of Sciences; Institute of Automation, CAS; Peng Cheng Laboratory; Chinese Academy of Sciences; Institute of Automation, CAS; Macau University of Science & Technology	Li, X (corresponding author), Peng Cheng Lab, Shenzhen 518000, Peoples R China.; Wang, FY (corresponding author), Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.	tianyu.shen@buct.edu.cn; jsun@ujs.edu.cn; kongshihan@pku.edu.cn; yutong.wang@ia.ac.cn; juanjuan.li@ia.ac.cn; lix05@pcl.ac.cn; feiyue.wang@ia.ac.cn		Wang, Yutong/0000-0001-7429-031X; li, juan juan/0000-0002-0827-0449; Kong, Shihan/0000-0002-6714-1313	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Brown N., 2023, C ROBOT LEARNING, P287; Cui YD, 2024, IEEE T INTELL VEHICL, V9, P1450, DOI 10.1109/TIV.2023.3327715; Gupta A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25874-z; Jin DD, 2020, NAT MACH INTELL, V2, P663, DOI 10.1038/s42256-020-00250-6; Li JJ, 2023, IEEE-CAA J AUTOMATIC, V10, P2183, DOI 10.1109/JAS.2023.124056; Li X., 2023, 2023 IEEE INT C SYST, P1; Li X, 2023, IEEE T SYST MAN CY-S, V53, P5545, DOI 10.1109/TSMC.2023.3273896; Li X, 2023, IEEE T SYST MAN CY-S, V53, P2148, DOI 10.1109/TSMC.2022.3228594; Li X, 2022, IEEE INTELL SYST, V37, P18, DOI 10.1109/MIS.2022.3197950; Li Y., PARALLEL LEARNING PE; Liu YH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249930; Lu JW, 2020, IEEE-CAA J AUTOMATIC, V7, P1662, DOI 10.1109/JAS.2020.1003426; Miao Y. Lv, PARALLEL LEARNING OV; Shah D, 2023, C ROBOT LEARNING, P492; Shen Y, 2022, IEEE-CAA J AUTOMATIC, V9, P2047, DOI 10.1109/JAS.2022.106115; Tian X., 2023, IEEE Transactions on Intelligent Vehicles, P1, DOI [10.1109/TIV.2023.3341223.13F.-Y, DOI 10.1109/TIV.2023.3341223.13F.-Y]; Tian YL, 2023, IEEE T INTELL VEHICL, V8, P4198, DOI 10.1109/TIV.2023.3307012; Turing J., 1950, Computing machinery and intelligence, pp29; Wang F.-Y., 2022, CAA J.Autom. Sinica, V9, P2063; Wang F.-Y., 1994, Shadow systems: A new concept for nested and embedded co-simulation for intelligent systems; Wang F.-Y., 2022, CAA J. Autom. Sinica, V9, P1899; Wang F.-Y, 2004, Decis. Control, V23, P74; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P831, DOI 10.1109/JAS.2023.123552; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang FY, 2022, IEEE-CAA J AUTOMATIC, V9, P2043, DOI 10.1109/JAS.2022.106106; [王飞跃 Wang Feiyue], 2024, [中国科学院院刊, Bulletin of the Chinese Academy of Sciences], V39, P27; Wang X, 2022, IEEE INTELL SYST, V37, P97, DOI 10.1109/MIS.2022.3196592; Wang Y., CHATGPT BUILDING KNO; Wang ZR, 2023, IEEE T INTELL VEHICL, V8, P2619, DOI 10.1109/TIV.2023.3264812; Wei QL, 2020, IEEE-CAA J AUTOMATIC, V7, P919, DOI 10.1109/JAS.2020.1003216; Yang J., 2022, CAA J. Autom. Sinica, V9, P2043	31	0	0	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9266	2329-9274		IEEE-CAA J AUTOMATIC	IEEE-CAA J. Automatica Sin.	JUN	2024	11	6					1313	1316		10.1109/JAS.2024.124407	http://dx.doi.org/10.1109/JAS.2024.124407			4	Automation & Control Systems	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems	ST6L7		Bronze			2024-07-03	WOS:001236736400013
J	Olivato, M; Putelli, L; Arici, N; Gerevini, AE; Lavelli, A; Serina, I				Olivato, Matteo; Putelli, Luca; Arici, Nicola; Emilio Gerevini, Alfonso; Lavelli, Alberto; Serina, Ivan			Language Models for Hierarchical Classification of Radiology Reports With Attention Mechanisms, BERT, and GPT-4	IEEE ACCESS			English	Article						Radiology; Task analysis; Computed tomography; Biological system modeling; Training; Lung; Data models; Deep learning; Large language models; Attention mechanism; BERT; BioBIT; deep learning; GPT-4; large language models; natural language processing; Italian language; prompt engineering; radiology reports; Italian radiology reports; text classification		Radiology reports are a valuable source of textual information used to improve clinical care and support research. In recent years, deep learning techniques have been shown to be effective in classifying radiology reports. This article investigates the use of deep learning techniques with attention mechanisms to achieve better performance in the classification of radiology reports. We focus on various Natural Language Processing approaches, such as LSTM with Attention, BERT, and GPT-4, evaluated on a chest tomography report dataset regarding neoplastic diseases collected from an Italian hospital. In particular, we compare the results with a previous machine learning system, showing that models based on attention mechanisms can achieve higher performance. The Attention Mechanism allows us to identify the most relevant bits of text used by the model to make its predictions. We show that our model achieves state-of-the-art results on the hierarchical classification of radiology reports. Moreover, we evaluate the performance of GPT-4 on the classification of these reports in a zero-shot setup through prompt engineering, showing interesting results even with a small context and a non-English language. Our findings suggest that deep learning techniques with attention mechanisms may be successful in the classification of radiology reports even in non-English languages for which it is not possible to leverage on large text corpus.	[Olivato, Matteo; Putelli, Luca; Arici, Nicola; Emilio Gerevini, Alfonso; Serina, Ivan] Univ Brescia, Dept Informat Engn, I-25121 Brescia, Italy; [Lavelli, Alberto] Fdn Bruno Kessler, I-38123 Trento, Italy	University of Brescia; Fondazione Bruno Kessler	Olivato, M; Gerevini, AE (corresponding author), Univ Brescia, Dept Informat Engn, I-25121 Brescia, Italy.	matteo.olivato@unibs.it; alfonso.gerevini@unibs.it		Putelli, Luca/0009-0008-5055-6812; Lavelli, Alberto/0000-0002-7175-6804				Abadi M., 2015, TensorFlow: Large-scale machine learning on het- erogeneous systems; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Al-Saqqa S., 2019, P 2019 INT C ART INT, P39, DOI DOI 10.1145/3388218.3388229; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2023, GPT-4 System Card; Arici N, 2023, LECT NOTES ARTIF INT, V13796, P457, DOI 10.1007/978-3-031-27181-6_32; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Baktash JA, 2023, Arxiv, DOI arXiv:2305.03195; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buonocore TM, 2023, J BIOMED INFORM, V144, DOI 10.1016/j.jbi.2023.104431; Casey A, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1184919; Casey A, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01533-7; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chiari M, 2021, LECT NOTES ARTIF INT, P318, DOI 10.1007/978-3-030-77211-6_36; Choi JH, 2022, J LEGAL EDUC, V71, P387; Chollet F., 2015, About us; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Donnelly LF, 2022, SEMIN ULTRASOUND CT, V43, P176, DOI 10.1053/j.sult.2022.02.007; Fanni SC, 2023, EUR J RADIOL OPEN, V11, DOI 10.1016/j.ejro.2023.100512; Fink MA, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220055; Galbusera F, 2023, GLOB SPINE J, V13, P1257, DOI 10.1177/21925682211026910; Gerevini AE, 2023, IEEE ACCESS, V11, P83905, DOI 10.1109/ACCESS.2023.3296260; Gerevini AE, 2018, ARTIF INTELL MED, V91, P72, DOI 10.1016/j.artmed.2018.05.006; Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015; Hassanzadeh H., 2018, P AM MED INF ASS ANN; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jianqiong Xiao, 2020, 2020 Proceedings of IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P1285, DOI 10.1109/ICAICA50127.2020.9182390; Kadlec R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P908; Li Y, 2018, STUD BIG DATA, V26, P83, DOI 10.1007/978-3-319-53817-4_4; Liu ZL, 2023, Arxiv, DOI arXiv:2307.13693; Long JY, 2023, Arxiv, DOI arXiv:2305.08291; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; McDonald R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1849; Mehmood T., 2019, P 6 IT C COMP LING, V2481; Mehmood T, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15020079; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Miller MI, 2022, NEUROCRIT CARE, V37, P291, DOI 10.1007/s12028-022-01513-3; Moller AG, 2024, Arxiv, DOI arXiv:2304.13861; Mozayan A, 2021, RADIOGRAPHICS, V41, P1446, DOI 10.1148/rg.2021200113; Mullenbach J., 2018, P NAACL, P1101, DOI [10.18653/v1/n18-1100. arXiv: 1802.05695, DOI 10.18653/V1/N18-1100.ARXIV:1802.05695]; Cuong NV, 2014, J MACH LEARN RES, V15, P981; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Olivato Matteo, 2022, Procedia Comput Sci, V207, P1232, DOI 10.1016/j.procs.2022.09.179; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pianta E., 2008, P INT C LANG RES EV; Praful Bharadiya J., 2023, European Journal of Technology, P58, DOI [10.47672/ejt.1473, DOI 10.47672/EJT.1473]; Putelli A., 2022, P CEUR WORKSH, V3277, P16; Putelli L., 2019, P 6 IT C COMP LING, V2481; Putelli L, 2021, LECT NOTES ARTIF INT, P367, DOI 10.1007/978-3-030-77211-6_42; Putelli L, 2019, LECT NOTES COMPUT SC, V11946, P445, DOI 10.1007/978-3-030-35166-3_32; Radford A., 2019, arXiv; Radford K., 2018, OpenAI Blog; Radford K., 2019, OpenAI Blog; Raffel C., 2015, arXiv; Raj Aditya, 2023, 2023 IEEE World Conference on Applied Intelligence and Computing (AIC), P300, DOI 10.1109/AIC57670.2023.10263979; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063; Shin B, 2017, IEEE IJCNN, P4363, DOI 10.1109/IJCNN.2017.7966408; Sun H, 2023, Arxiv, DOI arXiv:2309.06553; Tarwani KM., 2017, INT J ENG TRENDS TEC, V48, P301, DOI [10.14445/22315381/IJETT-V48P253, DOI 10.14445/22315381/IJETT-V48P253]; Vaswani A, 2017, ADV NEUR IN, V30; Wang YS, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-018-0723-6; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zhou A. I., 2023, P 11 INT C LEARN REP; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	73	0	0	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						69710	69727		10.1109/ACCESS.2024.3402066	http://dx.doi.org/10.1109/ACCESS.2024.3402066			18	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	RV8K7					2024-07-03	WOS:001230526200001
C	Asesh, A; Duga, M		Cardona, M; Solanki, VK		Asesh, Aishwarya; Duga, Meenal			Computational Optimizations in LLMs	2023 IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLIED NETWORK TECHNOLOGIES, ICMLANT			English	Proceedings Paper	IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT)	DEC 14-15, 2023	ELECTR NETWORK	IEEE, Univ Don Bosco El Salvador, IEEE El Salvador Sect		Large Language Models (LLM); Chatbot Generative Pre-trained Transformer (Chat GPT); Natural Language Processing (NLP); Parameter-Efficient Transfer Learning (PETL); Neural Networks (NN); Sentiment Analysis; Model Calibration; Fine-tuning; Side-tuning; Sequence-to-Sequence RNN		Over recent years, the proliferation of microblogging and textual messaging platforms has led to an exponential surge in textual data, necessitating advanced, automated techniques for sentiment elucidation. Contemporary methodologies, despite their efficacy, often demand substantial computational expenditure and manifest pronounced over-fitting in scenarios involving non-standard dataset distributions. Parameter-Efficient Transfer Learning (PETL) has emerged as a promising strategy to mitigate the exorbitant computational overheads associated with large-scale model training, albeit not without its computational burden. This research, an extension of extant literature, introduces a pioneering MINIature Orthogonal Network (MINION) approach. It synergistically couples a diminutive sequence-to-sequence recurrent neural network (RNN) with a static transformer model, eschewing the need for backpropagation through the voluminous transformer. Experimental results affirm that MINION ensures a notable reduction in computational requisites in juxtaposition with antecedent implementations and comprehensive model fine-tuning, simultaneously curtailing model over-assurance while preserving commendable accuracy metrics in sentiment categorization tasks.	[Asesh, Aishwarya; Duga, Meenal] Univ Penn, Salt Lake City, UT 19104 USA		Asesh, A (corresponding author), Univ Penn, Salt Lake City, UT 19104 USA.	a.asesh@gmail.com; meenal.dugar@utah.edu						Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Guo CA, 2017, PR MACH LEARN RES, V70; Kingma D. P., 2017, ARXIV; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Nixon J., 2020, Measuring Calibration in Deep Learning; Segaran Toby., 2009, BEAUTIFUL DATA STORI; Vaicenavicius J, 2019, PR MACH LEARN RES, V89; Wang S, 2023, Arxiv, DOI [arXiv:2305.15348, 10.48550/arXiv.2305.15348]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38	13	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0391-9				2023							18	22		10.1109/ICMLANT59547.2023.10372971	http://dx.doi.org/10.1109/ICMLANT59547.2023.10372971			5	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IE					2024-07-03	WOS:001161329500004
J	Prather, J; Reeves, BN; Denny, P; Becker, BA; Leinonen, J; Luxton-Reilly, A; Powell, G; Finnie-Ansley, J; Santos, EA				Prather, James; Reeves, Brent N.; Denny, Paul; Becker, Brett A.; Leinonen, Juho; Luxton-Reilly, Andrew; Powell, Garrett; Finnie-Ansley, James; Santos, Eddie Antonio			"It's Weird That it KnowsWhat I Want": Usability and Interactions with Copilot for Novice Programmers	ACM TRANSACTIONS ON COMPUTER-HUMAN INTERACTION			English	Article						AI; Artificial Intelligence; automatic code generation; Codex; Copilot; CS1; GitHub; GPT-3; HCI; introductory programming; large language models; LLM; novice programming; OpenAI		Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.	[Prather, James; Reeves, Brent N.; Powell, Garrett] Abilene Christian Univ, Abilene, TX 79699 USA; [Denny, Paul; Leinonen, Juho; Luxton-Reilly, Andrew; Finnie-Ansley, James] Univ Auckland, Auckland, New Zealand; [Becker, Brett A.; Santos, Eddie Antonio] Univ Coll Dublin, Dublin, Ireland	Abilene Christian University; University of Auckland; University College Dublin	Prather, J (corresponding author), Abilene Christian Univ, Abilene, TX 79699 USA.		Leinonen, Juho/D-2162-2018; Luxton-Reilly, Andrew/ABC-5342-2021	Leinonen, Juho/0000-0001-6829-9449; Luxton-Reilly, Andrew/0000-0001-8269-2909; Santos, Eddie Antonio/0000-0001-5337-715X; Reeves, Brent/0000-0001-5781-1136; Prather, James/0000-0003-2807-6042; Denny, Paul/0000-0002-5150-9806; Powell, Garrett/0000-0002-3221-7015; Finnie-Ansley, James/0000-0002-4279-6284				Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156; Agarwal A., 2009, CHI 09 HUM FACT COMP, DOI DOI 10.1145/1520340.1520420; Albluwi I, 2020, ACM T COMPUT EDUC, V20, DOI 10.1145/3371156; Allen Joe Michael, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P349, DOI 10.1145/3408877.3432551; Ankur Desai, 2022, Introducing Amazon CodeWhisperer, the ML-powered Coding Companion; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Baniassad Elisa, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P1062, DOI 10.1145/3408877.3432430; Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Beck K., 2000, Extreme Programming Explained: Embrace Change; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Becker BA, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P338, DOI 10.1145/3287324.3287432; Becker BA, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P634, DOI 10.1145/3159450.3159453; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Bender E. M., 2019, FUTURE ARTIFICIAL IN; Biderman S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2933, DOI 10.1145/3511808.3557079; Bird C, 2023, COMMUN ACM, V66, P56, DOI 10.1145/3589996; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Braun V, 2022, QUAL PSYCHOL, V9, P3, DOI 10.1037/qup0000196; Braun V, 2019, QUAL RES SPORT EXERC, V11, P589, DOI 10.1080/2159676X.2019.1628806; Brave S, 2009, HUM FACTORS ERGON, P53; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camp Tracy, 2017, ACM Inroads, V8, P44, DOI 10.1145/3084362; Chen M., 2021, arXiv; CLANCEY WJ, 1983, ARTIF INTELL, V20, P215, DOI 10.1016/0004-3702(83)90008-5; Code4Me, 2022, Code4Me; Crichton W, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445257; Crow T., 2018, P 20 AUSTRALASIAN CO, P53, DOI [DOI 10.1145/3160489.3160492, 10.1145/3160489.3160492]; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Denny Paul, 2021, ACE '21:Proceedings of the 23rd Australasian Computing Education Conference, P88, DOI 10.1145/3441636.3442309; Denny P, 2023, Arxiv, DOI arXiv:2306.02608; Denny P, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P948, DOI 10.1145/3478431.3499314; Denny Paul, 2012, P 17 ACM ANN C INNOV, P75, DOI DOI 10.1145/2325296.2325318; Denny Paul, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445696, 10.1145/3411764, DOI 10.1145/3411764]; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Duran R, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3483843; Ericsson K.A., 1993, Protocol analysis: Verbal reports as data, revised edn; Ernst NA, 2022, IEEE SOFTWARE, V39, P106, DOI 10.1109/MS.2021.3133805; FauxPilot, 2023, FauxPilot-An Open-source Alternative to GitHub Copilot server; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gaweda AM, 2020, PROCEEDINGS OF THE TWENTY-SECOND AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE'20, P105, DOI 10.1145/3373165.3373177; GitHub, 2021, GitHub copilot your AI pair programmer; Given L. M., 2015, 100 questions (and answers) about qualitative research; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Hellas A, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P238, DOI 10.1145/3059009.3059065; Irwin MS, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P208, DOI 10.1145/3300115.3309517; Jayagopal D, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545659; Karvelas I, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P759, DOI 10.1145/3328778.3366882; Kazerouni Ayaan M., 2019, SIGCSE '19: Proceedings of the 50th ACM Technical Symposium on Computer Science Education, DOI 10.1145/3287324.3293794; Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711; Kinnunen P., 2010, P 6 INT WORKSH COMP, P77, DOI DOI 10.1145/1839594.1839609; Kinnunen Paivi, 2011, P 7 INT WORKSH COMP, P19, DOI DOI 10.1145/2016911.2016917; Lee Michael J, 2011, ACM ICER, P109, DOI [10.1145/2016911.2016934, DOI 10.1145/2016911.2016934]; Leinonen A, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P84, DOI 10.1145/3287324.3287378; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Leinonen J, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P885, DOI 10.1145/3478431.3499372; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Loksa D, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3487050; Loksa D, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER'16), P83, DOI 10.1145/2960310.2960334; Loksa D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1449, DOI 10.1145/2858036.2858252; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Mahdaoui M., 2022, Procedia Computer Science, V198, P391, DOI [DOI 10.1016/J.PROCS.2021.12.259, 10.1016/j.procs.2021.12.259]; Malmi Lauri, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P36, DOI 10.1145/3372782.3406279; Margolis J., 2002, UNLOCKING CLUBHOUSE; McBroom J, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3469885; McCabe DL, 2001, ETHICS BEHAV, V11, P219, DOI 10.1207/S15327019EB1103_2; McCartney R, 2007, ITICSE 2007: 12TH ANNUAL CONFERENCE ON INNOVATION & TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P156, DOI 10.1145/1269900.1268831; McDonald Nora, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359174; McDowell C., 2002, SIGCSE Bulletin, V34, P38, DOI 10.1145/563517.563353; Morrison B.B., 2015, P 11 ANN INT C INT C, P21, DOI DOI 10.1145/2787622.2787733; OpenAI, 2022, Introducing chatgpt; OpenAI, 2022, Dalle 2; Ormerod T., 1990, Psychology of Programming, P63, DOI DOI 10.1016/B978-0-12-350772-3.50009-4; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pearce Hammond, 2022, arXiv, DOI [10.48550/arXiv.2202.01142, DOI 10.48550/ARXIV.2202.01142]; Pechorina Yulia, 2023, P 25 AUSTR COMP ED C, P59, DOI [10.1145/3576123.3576130, DOI 10.1145/3576123.3576130]; Peng Sida, 2023, arXiv, DOI DOI 10.48550/ARXIV.2302.06590; Prather James, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P164, DOI 10.1145/3501385.3543970; Prather James, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P2, DOI 10.1145/3372782.3406263; Prather J, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P531, DOI 10.1145/3287324.3287374; Prather J, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P41, DOI 10.1145/3230977.3230981; Prather J, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P74, DOI 10.1145/3105726.3106169; Reeves B, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P299, DOI 10.1145/3587102.3588805; Rittmayer A. D., 2008, SWE-AWE CASEE Overviews, P1; Roselli D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P539, DOI 10.1145/3308560.3317590; Salva R J., 2022, Preview: Referencing public code in github copilot | the github blog; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI [arXiv:2303.09325, DOI 10.48550/ARXIV.2303.09325]; Simon, 2016, P 2016 ITICSE WORK G, P57, DOI DOI 10.1145/3024906.3024910; SOLOWAY E, 1986, COMMUN ACM, V29, P850, DOI 10.1145/6592.6594; Sweller J., 1994, LEARN INSTR, V4, P295, DOI [10.1016/0959-4752(94)90003-5, DOI 10.1016/0959-4752(94)90003-5]; Tabnine, 2023, AI Assistant for Software Developers; Tang L, 2022, LECT NOTES COMPUT SC, V13356, P612, DOI 10.1007/978-3-031-11647-6_127; Taylor R, 2022, arXiv; The Joseph Saveri Law Firm and Matthew Butterick, 2022, GitHub Copilot Litigation; Vaithilingam P., 2022, P CHI C HUMAN FACTOR, P1; Vodrahalli K, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P763, DOI 10.1145/3514094.3534150; Wang DD, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934212, 10.1145/3290605.3300831]; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830; Yorke J, 2022, STUD HIGH EDUC, V47, P53, DOI 10.1080/03075079.2020.1730313; Zaremba W., 2021, Openai codex; Zhang SR, 2022, Arxiv, DOI [arXiv:2206.05442, 10.48550/ARXIV.2206.05442, DOI 10.48550/ARXIV.2206.05442]	109	5	5	23	23	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	1073-0516	1557-7325		ACM T COMPUT-HUM INT	ACM Trans. Comput.-Hum. Interact.	FEB	2024	31	1							4	10.1145/3617367	http://dx.doi.org/10.1145/3617367			31	Computer Science, Cybernetics; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EC7K2		Green Submitted			2024-07-03	WOS:001136778900004
J	Fujita, M; Kawanami, Y; Miyazawa, K; Kinoshita, M; Sawai, K; Yamasaki, F; Matsui, T; Endo, K; Ishiguro, S; Kitano, H				Fujita, Masahiro; Kawanami, Yasunori; Miyazawa, Kiyokazu; Kinoshita, Masaya; Sawai, Kunihito; Yamasaki, Fuminori; Matsui, Tatsuya; Endo, Ken; Ishiguro, Shu; Kitano, Hiroaki			Stories of QRIO and PINO, and Beyond: Lessons Learned from Small Humanoid Projects From R&D to Business	INTERNATIONAL JOURNAL OF HUMANOID ROBOTICS			English	Article						QRIO; PINO; zero moment point; whole-body motion control; force control; series-elastic actuator; genetic algorithm; behavior control architecture; cognitive developmental robotics; OPEN-R; OpenPINO; Digital-Twin; prosthesis; intelligence dynamics; multi-modal large language model	ROBOT; DESIGN; BEHAVIOR; MODEL	In 1997, Sony announced AIBO, a fully autonomous small quadruped robot for home entertainment, and in 1999 the company began selling it as a consumer product. Soon after development, two small humanoid robots were announced. One was QRIO by Sony, which is about 60cm height body with dynamical bipedal walking and whole-body cooperative control. The other was PINO by the ERATO Kitano Symbiotic Systems Project, which is about 70cm height body, Open HW/SW with inexpensive off-the-shelf component. In this paper, we revisit the two humanoids and nearly 20-year-old technologies, and discuss what were done 20 years ago, what have been achieved and what challenges are ahead.	[Fujita, Masahiro; Kawanami, Yasunori; Miyazawa, Kiyokazu; Kinoshita, Masaya] Sony Grp Corp, Technol Infrastruct Ctr, AI Technol Div, 2-10-1 Osaki, Shinagawa, Tokyo, Japan; [Sawai, Kunihito] Sony Grp Corp, Creat Ctr, Creat Platform, 1-7-1 Konan,Minato Ku, Tokyo, Japan; [Yamasaki, Fuminori] iXs Co Ltd, 7-7 Shin Kawasaki, Kawasaki, Kanagawa, Japan; [Matsui, Tatsuya] Flower Robot Inc, J House 301, Tokyo, Japan; [Endo, Ken; Kitano, Hiroaki] Sony Comp Sci Labs Inc, 3-14-13 Higashigotanda, Tokyo, Japan; [Endo, Ken] XiBorg Inc, 402,6-34-3 Jingumae, Tokyo, Japan; [Ishiguro, Shu] Chiba Inst Technol, Future Robot Technol Ctr, 2-17-1 Tsudanuma, Narashino, Chiba 2750016, Japan; [Kitano, Hiroaki] Sony Grp Corp, 1-7-1 Konan,Minato Ku, Tokyo, Japan; [Kitano, Hiroaki] Okinawa Inst Sci & Technol, Grad Sch, 1919-1 Tancha, Okinawa 9040495, Japan	Sony Corporation; Chiba Institute of Technology; Okinawa Institute of Science & Technology Graduate University	Fujita, M (corresponding author), Sony Grp Corp, Technol Infrastruct Ctr, AI Technol Div, 2-10-1 Osaki, Shinagawa, Tokyo, Japan.	Masahiro.fujita@sony.com; Yasunori.kawanami@sony.com; Kiyokazu.Miyazawa@sony.com; Masaya.A.Kinoshita@sony.com; Kunihito.Sawai@sony.com; yamasaki@ixs.co.jp; matsui@flower-robotics.com; ken.f.endo@sony.com; shu_i@mvi.biglobe.ne.jp; Hiroaki.kitano@sony.com		Kawanami, Yasunori/0009-0002-6426-3451; Yamasaki, Fuminori/0009-0004-8217-3833; MIYAZAWA, KIYOKAZU/0009-0003-3449-175X; Fujita, Masahiro/0009-0006-4646-6975; Kitano, Hiroaki/0000-0002-3589-1953; Sawai, Kunihito/0009-0004-5510-2220				AIBO, 1999, WIKIPEDIA; Akyurek E., 2023, ARXIV; [Anonymous], Atlas: The Worlds Most Dynamic Humanoid; Aoyama K, 2005, IEEE INT CONF ROBOT, P3814; Apple, 2023, APPLE A17 PRO; Azuma H., 1992, DEV PSYCHOL; Bommasani Rishi, 2021, ARXIV210807258; Brohan A., 2022, ARXIV; Brohan A., 2023, ARXIV; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Csikszentmihalyi M., 1996, Creativity: flow and the psychology of discovery and invention; Dodge S, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3306241; Driess D., 2023, ARXIV; Endo K, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2678, DOI 10.1109/IRDS.2002.1041674; Endo K, 2009, IEEE ENG MED BIO, P5034, DOI 10.1109/IEMBS.2009.5333697; Figure, FIGUREAI; Flower Robotics Inc, US; Friston K, 2021, NEURAL NETWORKS, V144, P573, DOI 10.1016/j.neunet.2021.09.011; Fujita M, 2001, INT J ROBOT RES, V20, P781, DOI 10.1177/02783640122068092; Fujita M, 2005, SPRINGER TRAC ADV RO, V15, P355; Fujita M., 1997, Proceedings of the First International Conference on Autonomous Agents, P435, DOI 10.1145/267658.267764; Fujita M, 2003, IEEE ASME INT C ADV, P938; Fujita M, 2007, PHILOS T R SOC A, V365, P21, DOI 10.1098/rsta.2006.1923; Fujita M., 1999, ROBOT AUTON SYST, V19, P119; Fujita M, 2009, AUTON AGENT MULTI-AG, V19, P248, DOI 10.1007/s10458-009-9076-y; Grimmer M, 2012, IEEE INT CONF ROBOT, P2463, DOI 10.1109/ICRA.2012.6224967; Gutmann JS, 2005, IEEE-RAS INT C HUMAN, P26; Ha D., 2018, ARXIV; Haruno M, 2001, NEURAL COMPUT, V13, P2201, DOI 10.1162/089976601750541778; Hirai K, 1998, IEEE INT CONF ROBOT, P1321, DOI 10.1109/ROBOT.1998.677288; Hoshino Y., 2011, J ROBOT SOC JPN, V29, P77; Hotta H., 2021, DOUBLE HARVEST; Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912; Inaba M, 2000, INT J ROBOT RES, V19, P933, DOI 10.1177/02783640022067878; Inamura T, 2004, INT J ROBOT RES, V23, P363, DOI 10.1177/0278364904042199; Ishiguro H., 2018, GEMINOID STUDIES SCI; iXs Co. Ltd., US; Kamikawa Y, 2021, IEEE INT C INT ROBOT, P894, DOI 10.1109/IROS51168.2021.9636196; Kawamoto K., 2009, P 9 INT C EPIGENETIC, P73; Khreich W, 2012, INFORM SCIENCES, V197, P105, DOI 10.1016/j.ins.2012.02.017; Kitano H., 2004, INT J HUM ROBOT, V1, P449; Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7; Liu H, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.250502; Ma Xiaomeng, 1987, MECH LANGUAGE ACQUIS; Mack CA, 2011, IEEE T SEMICONDUCT M, V24, P202, DOI 10.1109/TSM.2010.2096437; Mahankali A., 2023, ARXIV; Mathijssen G, 2015, IEEE-ASME T MECH, V20, P594, DOI 10.1109/TMECH.2014.2307122; Matsuo Y, 2022, NEURAL NETWORKS, V152, P267, DOI 10.1016/j.neunet.2022.03.037; Mermillod M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00504; Miyashita T., 1998, P 1998 BSMEE INT S C, P349; Miyazawa K., 2022, Patent No. [US20220149695A1, 20220149695]; Nagasaka K., 2019, HUMANOID ROBOTICS RE, P187, DOI DOI 10.1007/978-94-007-6046-2_16; Nagasaka K., 2012, P 18 ROB S, P134; Nagasaka K, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2303, DOI 10.1109/IROS.2008.4650680; Nagasaka K, 2010, IEEE INT CONF ROBOT, P3377, DOI 10.1109/ROBOT.2010.5509474; Nakanishi J, 2019, COMPUT HUM BEHAV, V93, P106, DOI 10.1016/j.chb.2018.10.008; OpenAI, FUNCTION CALLING OTH; Padalkar A., 2023, ARXIV; Penzlin B, 2020, AT-AUTOM, V68, P410, DOI 10.1515/auto-2020-0008; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rheinberg F, 2020, MOTIV SCI, V6, P199, DOI 10.1037/mot0000165; RoboCup Federation, ROBOCUP HUMANOID LEA; ROS, ROS ROBOT OPERATING; Sabe K., 2012, 12 IEEE RAS INT C HU, P18; Sawada T, 2004, IEEE-RAS INT C HUMAN, P450; Sawai K., 2004, J ROBOT SOC JPN, V22, P979; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Sony Group Corporation, 2018, SONY GROUP ETHICS GU; Stohmaier E., 2004, TOP500 SUPERCOMPUTER; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Suzuki H, 2018, IEEE ROBOT AUTOM LET, V3, P4281, DOI 10.1109/LRA.2018.2864771; Takasugi, 2023, ARXIV; Tani J, 2003, IEEE T SYST MAN CY A, V33, P481, DOI 10.1109/TSMCA.2003.809171; Tani J, 2003, NEURAL NETWORKS, V16, P11, DOI 10.1016/S0893-6080(02)00214-9; Taniguchi T, 2023, ADV ROBOTICS, V37, P780, DOI 10.1080/01691864.2023.2225232; TESLA, 2022, ROBOTICS; Tolstikhin I, 2021, ADV NEUR IN, V34; Vaswani A, 2017, ADV NEUR IN, V30; Wikipedia, WIFI; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; XiBorg Inc, US; Yamasaki F, 2003, ADV ROBOTICS, V17, P779, DOI 10.1163/156855303322395208; Yamasaki F., 2000, Robot Soccer World Cup, P269; Yu WH, 2022, PROC CVPR IEEE, P10809, DOI 10.1109/CVPR52688.2022.01055; Zhou J, 2020, OPEN, V1, P57, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; ZMP Inc, ZMP ROBOT EVERYTHING	86	0	0	10	10	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0219-8436	1793-6942		INT J HUM ROBOT	Int. J. Humanoid Robot.	FEB	2024	21	01								10.1142/S0219843623500275	http://dx.doi.org/10.1142/S0219843623500275		JAN 2024	53	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	JN8E1					2024-07-03	WOS:001143105800001
J	Zsidai, B; Hilkert, AS; Kaarre, J; Narup, E; Senorski, EH; Grassi, A; Ley, C; Longo, UG; Herbst, E; Hirschmann, MT; Kopf, S; Seil, R; Tischer, T; Samuelsson, K; Feldt, R				Zsidai, Balint; Hilkert, Ann-Sophie; Kaarre, Janina; Narup, Eric; Senorski, Eric Hamrin; Grassi, Alberto; Ley, Christophe; Longo, Umile Giuseppe; Herbst, Elmar; Hirschmann, Michael T.; Kopf, Sebastian; Seil, Romain; Tischer, Thomas; Samuelsson, Kristian; Feldt, Robert		ESSKA Artificial Intelligence	A practical guide to the implementation of AI in orthopaedic research - part 1: opportunities in clinical application and overcoming existing challenges	JOURNAL OF EXPERIMENTAL ORTHOPAEDICS			English	Review						Artificial intelligence; AI; Machine learning; ML; Large language models; Ethics; Explainability; Decision support systems; Digital twins; Provenance; Generalizability; Learning series; Orthopaedics; Research methods	ARTIFICIAL-INTELLIGENCE; NEURAL-NETWORKS; DEEP; MODEL	Artificial intelligence (AI) has the potential to transform medical research by improving disease diagnosis, clinical decision-making, and outcome prediction. Despite the rapid adoption of AI and machine learning (ML) in other domains and industry, deployment in medical research and clinical practice poses several challenges due to the inherent characteristics and barriers of the healthcare sector. Therefore, researchers aiming to perform AI-intensive studies require a fundamental understanding of the key concepts, biases, and clinical safety concerns associated with the use of AI. Through the analysis of large, multimodal datasets, AI has the potential to revolutionize orthopaedic research, with new insights regarding the optimal diagnosis and management of patients affected musculoskeletal injury and disease. The article is the first in a series introducing fundamental concepts and best practices to guide healthcare professionals and researcher interested in performing AI-intensive orthopaedic research studies. The vast potential of AI in orthopaedics is illustrated through examples involving disease- or injury-specific outcome prediction, medical image analysis, clinical decision support systems and digital twin technology. Furthermore, it is essential to address the role of human involvement in training unbiased, generalizable AI models, their explainability in high-risk clinical settings and the implementation of expert oversight and clinical safety measures for failure. In conclusion, the opportunities and challenges of AI in medicine are presented to ensure the safe and ethical deployment of AI models for orthopaedic research and clinical application.Level of evidence IV	[Zsidai, Balint; Kaarre, Janina; Narup, Eric; Senorski, Eric Hamrin; Samuelsson, Kristian] Sahlgrenska Sports Med Ctr, Gothenburg, Sweden; [Zsidai, Balint; Kaarre, Janina; Narup, Eric; Grassi, Alberto; Samuelsson, Kristian; Feldt, Robert] Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Orthopaed, Gothenburg, Sweden; [Hilkert, Ann-Sophie] Chalmers Univ Technol, Dept Comp Sci & Engn, Gothenburg, Sweden; [Hilkert, Ann-Sophie] Medfield Diagnost AB, Gothenburg, Sweden; [Kaarre, Janina] Univ Pittsburgh, UPMC Freddie Fu Sports Med Ctr, Dept Orthopaed Surg, Pittsburgh, PA USA; [Senorski, Eric Hamrin] Univ Gothenburg, Inst Neurosci & Physiol, Sahlgrenska Acad, Dept Hlth & Rehabil, Gothenburg, Sweden; [Senorski, Eric Hamrin] Sportrehab Sports Med Clin, Gothenburg, Sweden; [Grassi, Alberto] IRCCS Ist Ortoped Rizzoli, IIa Clin Ortoped & Traumatol, Bologna, Italy; [Ley, Christophe] Univ Luxembourg, Dept Math, Esch Sur Alzette, Luxembourg; [Longo, Umile Giuseppe] Campus Biomed Univ, Dept Orthopaed & Trauma Surg, Rome, Italy; [Herbst, Elmar] Univ Hosp Munster, Dept Trauma Hand & Reconstruct Surg, Munster, Germany; [Hirschmann, Michael T.] Kantonsspital Baselland, Dept Orthoped Surg & Traumatol, Head Knee Surg & DKF Head Res, CH-4101 Basel, Switzerland; [Kopf, Sebastian] Univ Hosp Brandenburg adH, Ctr Orthopaed & Traumatol, Brandenburg Med Sch Theodor Fontane, D-14770 Brandenburg, Germany; [Kopf, Sebastian] Brandenburg Med Sch Theodor Fontane, Fac Hlth Sci Brandenburg, D-14770 Brandenburg, Germany; [Seil, Romain] Ctr Hosp Luxembourg, Dept Orthopaed Surg, Luxembourg, Luxembourg; [Seil, Romain] Luxembourg Inst Hlth, Luxembourg, Luxembourg; [Tischer, Thomas] Malteser Waldkrankenhaus St Marien, Clin Orthopaed & Trauma Surg, Erlangen, Germany; [Samuelsson, Kristian] Sahlgrens Univ Hosp, Dept Orthopaed, Molndal, Sweden	University of Gothenburg; Chalmers University of Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; University of Gothenburg; University of Luxembourg; University Campus Bio-Medico - Rome Italy; University of Munster; Kantonsspital Baselland; Luxembourg Hospital Center; Luxembourg Institute of Health; Sahlgrenska University Hospital	Zsidai, B (corresponding author), Sahlgrenska Sports Med Ctr, Gothenburg, Sweden.; Zsidai, B (corresponding author), Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Orthopaed, Gothenburg, Sweden.	balint.zsidai@gu.se	Ley, Christophe/AAA-2566-2022; Longo, Umile Giuseppe/K-9147-2016; Seil, Romain/AAX-7873-2020; Senorski, Eric Hamrin/AAA-2913-2019; Kopf, Sebastian/H-1188-2014	Senorski, Eric Hamrin/0000-0002-9340-0147; Kopf, Sebastian/0000-0003-4373-7144; Zsidai, Balint/0000-0002-5697-6577	University of Gothenburg	University of Gothenburg	Open access funding provided by University of Gothenburg. No funding was obtained for the current study.	Abdar M, 2021, INFORM FUSION, V76, P243, DOI 10.1016/j.inffus.2021.05.008; Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Autor DH, 2003, Q J ECON, V118, P1279, DOI 10.1162/003355303322552801; Bareinboim E., 2022, Probabilistic and causal inference: the works of judea pearl, P507, DOI DOI 10.1145/3501714.3501743; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Biron DR, 2020, J AM ACAD ORTHOP SUR, V28, pE580, DOI 10.5435/JAAOS-D-19-00395; Bjelland O, 2022, IEEE ACCESS, V10, P45029, DOI 10.1109/ACCESS.2022.3170108; Björnsson B, 2019, GENOME MED, V12, DOI 10.1186/s13073-019-0701-3; Brinker TJ, 2019, EUR J CANCER, V119, P11, DOI 10.1016/j.ejca.2019.05.023; Burns C., 2022, arXiv; Cao J, 2022, NAT MACH INTELL, V4, P1121, DOI 10.1038/s42256-022-00563-8; Carmo LOE, 2021, BONE JOINT OPEN, V2, P879, DOI 10.1302/2633-1462.210.BJO-2021-0133; Challen R, 2019, BMJ QUAL SAF, V28, P231, DOI 10.1136/bmjqs-2018-008370; Collins GS, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-048008; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Fritz B, 2020, SKELETAL RADIOL, V49, P1207, DOI 10.1007/s00256-020-03410-2; Guermazi A, 2022, RADIOLOGY, V302, P627, DOI 10.1148/radiol.210937; Hernigou P, 2021, INT ORTHOP, V45, P2209, DOI 10.1007/s00264-021-05175-2; Kop M., 2021, EU Artificial Intelligence Act: The European Approach to AI; Lavin A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33128-9; Ley C, 2022, KNEE SURG SPORT TR A, V30, P753, DOI 10.1007/s00167-022-06896-6; Liu XX, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m3164; Loyola-González O, 2019, IEEE ACCESS, V7, P154096, DOI 10.1109/ACCESS.2019.2949286; Martin RK, 2022, KNEE SURG SPORT TR A, V30, P368, DOI 10.1007/s00167-021-06828-w; Martin RK, 2022, J BONE JOINT SURG AM, V104, P145, DOI 10.2106/JBJS.21.00113; Martin RK, 2022, KNEE SURG SPORT TR A, V30, P361, DOI 10.1007/s00167-021-06741-2; Martin RK, 2021, J ISAKOS, V6, P1, DOI 10.1136/jisakos-2020-000572; McDonnell JM, 2021, BONE JOINT J, V103B, P1442, DOI 10.1302/0301-620X.103B9.BJJ-2021-0192.R1; Medina G, 2021, SKELETAL RADIOL, V50, P683, DOI 10.1007/s00256-020-03599-2; Mincu D, 2022, NAT MACH INTELL, V4, P916, DOI 10.1038/s42256-022-00559-4; Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ramkumar PN, 2022, AM J SPORT MED, V50, P1166, DOI 10.1177/03635465211008648; Rivera SC, 2020, LANCET DIGIT HEALTH, V2, pE549, DOI [10.1016/S2589-7500(20)30219-3, 10.1136/bmj.m3210, 10.1038/s41591-020-1037-7]; Roscher R, 2020, IEEE ACCESS, V8, P42200, DOI 10.1109/ACCESS.2020.2976199; Seah JCY, 2021, LANCET DIGIT HEALTH, V3, pE496, DOI 10.1016/S2589-7500(21)00106-0; Senorski EH, 2019, BRIT J SPORT MED, V53, DOI 10.1136/bjsports-2018-100024; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Siontis KC, 2021, NAT REV CARDIOL, V18, P465, DOI 10.1038/s41569-020-00503-2; Sounderajah V, 2020, NAT MED, V26, P807, DOI 10.1038/s41591-020-0941-1; Strom P, 2020, LANCET ONCOL, V21, P222, DOI 10.1016/S1470-2045(19)30738-7; Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152; Tran A, 2022, EUR RADIOL, V32, P8394, DOI 10.1007/s00330-022-08923-z; Van Eetvelde H, 2021, J EXP ORTHOP, V8, DOI 10.1186/s40634-021-00346-x; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]	48	3	3	5	5	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2197-1153		J EXP ORTHOP	J Exp. Orthop.	NOV 16	2023	10	1							117	10.1186/s40634-023-00683-z	http://dx.doi.org/10.1186/s40634-023-00683-z			9	Orthopedics; Surgery	Emerging Sources Citation Index (ESCI)	Orthopedics; Surgery	Y4HH5	37968370	gold, Green Published			2024-07-03	WOS:001104884500002
C	Kazemitabaar, M; Chow, J; Ma, CKT; Ericson, BJ; Weintrop, D; Grossman, T			ACM	Kazemitabaar, Majeed; Chow, Justin; Ma, Carl Ka To; Ericson, Barbara J.; Weintrop, David; Grossman, Tovi			Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Large Language Models; AI Coding Assistants; AI-Assisted Pair-Programming; OpenAI Codex; GPT-3; ChatGPT; Copilot; Introductory Programming; K-12 Computer Science Education	SCRATCH; LANGUAGES; THINKING; SKILLS; K-12	AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modifcation tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.	[Kazemitabaar, Majeed; Chow, Justin; Ma, Carl Ka To; Grossman, Tovi] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Ericson, Barbara J.] Univ Michigan, Sch Informat, Ann Arbor, MI USA; [Weintrop, David] Univ Maryland, Coll Educ, College Pk, MD USA	University of Toronto; University of Michigan System; University of Michigan; University System of Maryland; University of Maryland College Park	Kazemitabaar, M (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.	majeed@dgp.toronto.edu; justinchow@dgp.toronto.edu; cma@dgp.toronto.edu; barbarer@umich.edu; weintrop@umd.edu; tovi@dgp.toronto.edu		Weintrop, David/0000-0002-3009-3899; Ericson, Barbara/0000-0001-6881-8341; Kazemitabaar, Majeed/0000-0001-6118-7938				Altadmri A., 2015, P 46 ACM TECHN S COM, P522, DOI DOI 10.1145/2676723.2677258; Amazon Web Services, 2022, CODEWHISPERER ML POW; [Anonymous], 2006, Proceedings of the ACM symposium on User interface software and technology (UIST '06), DOI DOI 10.1145/1166253.1166275; [Anonymous], 2008, Proc. International Workshop on Computing Education Research; [Anonymous], 2012, Proceedings of the ninth annual international conference on International computing education research, DOI DOI 10.1145/2361276.2361291; Ball T, 2019, SPLASH-E'19: PROCEEDINGS OF THE 2019 ACM SIGPLAN SYMPOSIUM ON SPLASH-E, P7, DOI 10.1145/3358711.3361630; Ballard Bruce W., 1979, ANN C ACM, P228, DOI [10.1145/800177.810072, DOI 10.1145/800177.810072]; Balog M., 2016, arXiv preprint arXiv:1611.01989; Bau David, 2015, Proceedings of the 14th International Conference on Interaction Design and Children, P445, DOI 10.1145/2771839.2771875; Becker Brett A, 2019, P 50 ACM TECHN S COM, P338; Begel A, 2005, 2005 IEEE SYMPOSIUM ON VISUAL LANGUAGE AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P99, DOI 10.1109/VLHCC.2005.58; Begel Andrew, 1996, LOGOBLOCKS GRAPHICAL, V2; Benda K., 2012, ACM T COMPUT EDUC, V12, P1, DOI DOI 10.1145/2382564.2382567; BIERMANN AW, 1983, INT J MAN MACH STUD, V18, P71, DOI 10.1016/S0020-7373(83)80005-4; Bruhn M, 2009, AM ECON J-APPL ECON, V1, P200, DOI 10.1257/app.1.4.200; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chilana PK, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1462, DOI 10.1145/2858036.2858323; Chowdhery A., 2022, ARXIV220402311; Cooper S., 2000, CONSORTIUM COMPUTING, V15, P107, DOI DOI 10.5555/364133.364161; Desai A, 2016, PROC INT CONF SOFTW, P345, DOI 10.1145/2884781.2884786; Dijkstra Edsger W, 1979, PROGRAM CONSTRUCTION, P51; Dragicevic P., 2015, THESIS; Du Boulay B., 1986, Journal of Educational Computing Research, V2, P57, DOI 10.2190/3LFX-9RRF-67T8-UVK9; Duran R, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3483843; Durán R, 2018, SPR GEOL, P185, DOI 10.1007/978-3-319-57852-1_11; Ericson BJ, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P60, DOI 10.1145/3230977.3231000; Ericson BJ, 2017, 17TH KOLI CALLING INTERNATIONAL CONFERENCE ON COMPUTING EDUCATION RESEARCH (KOLI CALLING 2017), P20, DOI 10.1145/3141880.3141895; Falloon G, 2016, J COMPUT ASSIST LEAR, V32, P576, DOI 10.1111/jcal.12155; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Fessakis G, 2013, COMPUT EDUC, V63, P87, DOI 10.1016/j.compedu.2012.11.016; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Franklin Diana, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P14, DOI 10.1145/3372782.3406256; Github, 2022, COP YOUR PAIR PROGR; Grover S, 2013, EDUC RESEARCHER, V42, P38, DOI 10.3102/0013189X12463051; GULWANI S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI [DOI 10.1145/1925844.1926423, DOI 10.1145/1926385.1926423]; Gulwani S, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P803, DOI 10.1145/2588555.2612177; Hristova M., 2003, SIGCSE Bulletin, V35, P153, DOI 10.1145/792548.611956; Hutchins E. L., 1985, Human-Computer Interaction, V1, P311, DOI [10.1207/s15327051hci0104_2, DOI 10.1207/S15327051HCI0104_2]; Jaccard P., 1901, Bull Soc Vaudoise Sci Nat, V37, P547, DOI [DOI 10.5169/SEALS-266450, 10.5169/seals-266450]; Jayagopal Dhanya, 2022, P 35 ANN ACM S US IN, P1; Jiang E, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503564; Kalelioglu F, 2015, COMPUT HUM BEHAV, V52, P200, DOI 10.1016/j.chb.2015.05.047; Kalelioglu F, 2014, INFORM EDUC, V13, P33; Kazemitabaar Majeed, 2023, P 54 ACM TECHN S COM; Kinnunen P., 2010, P 6 INT WORKSH COMP, P77, DOI DOI 10.1145/1839594.1839609; Kinnunen Paivi, 2011, P 7 INT WORKSH COMP, P19, DOI DOI 10.1145/2016911.2016917; Kirschner PA, 2006, EDUC PSYCHOL-US, V41, P75, DOI 10.1207/s15326985ep4102_1; Knoll R., 2006, COMPANION 21 ACM SIG, P542, DOI DOI 10.1145/1176617.1176628; Kölling M, 2015, PROCEEDINGS OF THE 10TH WORKSHOP IN PRIMARY AND SECONDARY COMPUTING EDUCATION, WIPSCE 2015, P29, DOI 10.1145/2818314.2818331; KUMAR D, 2013, P 18 ACM C INN TECHN, P183, DOI DOI 10.1109/DCOSS.2013.52; Landhäusser M, 2017, AUTOMAT SOFTW ENG, V24, P839, DOI 10.1007/s10515-016-0202-1; Le Vu, 2013, MobiSys '13; Lee Irene, 2011, ACM Inroads, V2, P32, DOI 10.1145/1929887.1929902; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Ling W, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P599; Lister R, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P161, DOI 10.1145/1595496.1562930; Lu S., 2021, arXiv, P2021; Luxton-Reilly A, 2018, ITICSE 2018 COMPANION: PROCEEDINGS COMPANION OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P55, DOI 10.1145/3293881.3295779; MacKenzie I. S., 2012, Human-computer interaction: An empirical research perspective; Majeed K, 2022, PROCEEDINGS OF THE 2022 ACM INTERACTION DESIGN AND CHILDREN, IDC 2022, P261, DOI 10.1145/3501712.3529733; Mayer R. E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9781139547369, 10.1017/CBO9781139547369.017]; MILLER RB, 1988, CONTEMP EDUC PSYCHOL, V13, P348, DOI 10.1016/0361-476X(88)90034-3; Myers BA, 2004, COMMUN ACM, V47, P47, DOI 10.1145/1015864.1015888; Pane J., 2002, PROGRAMMING SYSTEM C; Pane JF, 2006, HUM COM INT, V9, P31; Parsons D., 2006, Australasian Computing Education Conference, V52, P157; Popat S, 2019, COMPUT EDUC, V128, P365, DOI 10.1016/j.compedu.2018.10.005; Price D., 2000, IUI 2000. 2000 International Conference on Intelligent User Interfaces, P207, DOI 10.1145/325737.325845; Psycharis S, 2017, INSTR SCI, V45, P583, DOI 10.1007/s11251-017-9421-5; Qian YZ, 2017, ACM T COMPUT EDUC, V18, DOI 10.1145/3077618; Quirk Chris, 2015, P 53 ANN M ASS COMP, V1, P878; Raghothaman M, 2016, PROC INT CONF SOFTW, P357, DOI 10.1145/2884781.2884808; Raza Mohammad, 2015, IJCAI 2015; Resnick M., 2015, Bright/Medium. doi, DOI DOI 10.4018/IJPOP.2015010101; Resnick M., 2014, P 3 INT CONSTRUCTION, P13; Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779; Rodrigo MMT, 2009, FIFTH INTERNATIONAL COMPUTING EDUCATION RESEARCH WORKSHOP - ICER 2009, P75; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schlegel V, 2019, PROCEEDINGS OF IUI 2019, P30, DOI 10.1145/3301275.3302267; Sirkia T, 2012, Proceedings of the 12th Koli Calling International Conference on Computing Education Research, P19; Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1; Sun J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P212, DOI 10.1145/3490099.3511119; Tabnine, 2022, TABN AI ASS SOFTW DE; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; van Merriënboer JJG, 2003, EDUC PSYCHOL-US, V38, P5, DOI 10.1207/S15326985EP3801_2; Vaswani A, 2017, ADV NEUR IN, V30; Vygotsky L., 1978, Mind in society: The development of higher psychological processes, DOI [DOI 10.2307/J.CTVJF9VZ4, 10.2307/j.ctvjf9vz4]; Webb M, 2017, EDUC INF TECHNOL, V22, P445, DOI 10.1007/s10639-016-9493-x; Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215; Wolber D, 2011, SIGCSE 11: PROCEEDINGS OF THE 42ND ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P601; Yin PC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P440, DOI 10.18653/v1/P17-1041; Zhi R, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P51, DOI 10.1145/3291279.3339419; Zhong V., 2017, ARXIV170900103	94	28	28	21	32	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580919	http://dx.doi.org/10.1145/3544548.3580919			23	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Submitted			2024-07-03	WOS:001037809504017
J	Bozkurt, A				Bozkurt, Aras			GenAI et al.: Cocreation, Authorship, Ownership, Academic Ethics and Integrity in a Time of Generative AI	OPEN PRAXIS			English	Article						Generative AI; GenAI; artificial intelligence; AI; AIEd; chatbots; conversational agents; education; teaching; learning; higher education; educational technology; GPT; generative pre-trained transformer; ChatGPT; large language models; LLMs; natural language processing; collaboration; cocreating; academic writing; transparency in research; authorship; ownership; ethics; academic integrity	CHATGPT	This paper investigates the complex interplay between generative artificial intelligence (AI) and human intellect in academic writing and publishing. It examines the 'organic versus synthetic' paradox, emphasizing the implications of using generative AI tools in educational and academic integrity contexts. The paper critiques the prevalent 'publish or perish' culture in academia, highlighting the need for systemic reevaluation due to generative AI's emerging role in academic writing and reporting. It delves into the legal and ethical challenges of authorship and ownership, especially in relation to copyright laws and AI -generated content. The paper discusses generative AI's diverse roles and advocates for transparent reporting to uphold academic integrity. Additionally, it calls for a broader examination of generative AI tools and stresses the need for new mechanisms to identify generative AI use and ensure adherence to academic integrity and ethics. The implications of generative AI are also explored, suggesting the need for innovative AI -inclusive strategies in academia. The paper concludes by emphasizing the significance of generative AI in various informationprocessing domains, highlighting the urgency to adapt and transform academic practices in an era of rapid generative AI -driven change.	[Bozkurt, Aras] Tripura Univ, Agartala, Tripura, India	Tripura University	Bozkurt, A (corresponding author), Tripura Univ, Agartala, Tripura, India.	arasbozkurt@gmail.com	BOZKURT, Aras/O-3654-2017	BOZKURT, Aras/0000-0002-4520-642X	Anadolu University [SBA -2023-1852]	Anadolu University(Anadolu University)	This paper is funded by Anadolu University with grant number SBA -2023-1852.	Ali MJ, 2023, SEMIN OPHTHALMOL, V38, P403, DOI 10.1080/08820538.2023.2193444; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2021, The fundamental values of academic integrity; Ansari AN, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12223-4; Arachchige APM, 2023, NUCL MED MOLEC IMAG, V57, P213, DOI 10.1007/s13139-023-00816-3; Bakla A., 2023, Transforming the Language Teaching Experience in the Age of AI, P89, DOI [10.4018/978-1-6684-9893-4.ch005, DOI 10.4018/978-1-6684-9893-4.CH005]; Bhatia G, 2023, ASIAN J PSYCHIATR, V84, DOI 10.1016/j.ajp.2023.103564; Bin-Nashwan SA, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102370; Bozkurt A., 2023, Research, writing, and creative process in open and distance education: Tales from the field, P101, DOI [10.11647/OBP.0356, DOI 10.11647/OBP.0356]; Bozkurt A., 2023, Asian Journal of Distance Education, V18, pi, DOI [10.5281/zenodo.8174941, DOI 10.5281/ZENODO.8174941]; Bozkurt A., 2023, Asian Journal of Distance Education, V18, P53, DOI [10.5281/zenodo.7636568, DOI 10.5281/ZENODO.7636568]; Bozkurt A., 2023, Asian Journal of Distance Education, DOI [DOI 10.5281/ZENODO.7716416, 10.5281/zenodo.7716416]; Bozkurt A, 2023, OPEN PRAX, V15, P178, DOI 10.55982/openpraxis.15.3.579; Bozkurt A, 2023, OPEN PRAX, V15, P261, DOI 10.55982/openpraxis.15.4.609; Concannon F., 2023, Irish Journal of Technology Enhanced Learning, V7, DOI [10.22554/ijtel.v7i1.116, DOI 10.22554/IJTEL.V7I1.116]; COPE (Committee on Publication Ethics), 2023, AUTH CONTR; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; CSE, 2022, Recommendations for promoting integrity in scientific journal publications; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; da Silva JAT, 2023, LEARN PUBL, V36, P453, DOI 10.1002/leap.1547; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; Dempere J, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1206936; Dien J, 2023, BIOL PSYCHOL, V181, DOI 10.1016/j.biopsycho.2023.108621; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Farrelly T, 2023, EDUC SCI, V13, DOI 10.3390/educsci13111109; Gates B., 2023, Gates Notes; HARARI Y.N., 2023, The Economist; Herbold Steffen, 2023, Sci Rep, V13, P18617, DOI 10.1038/s41598-023-45644-9; ICMJE, 2024, Defining the Role of Authors and Contributors; ICMJE (International Committee of Medical Journal Editors), 2022, REC; Ide K, 2023, J EPIDEMIOL, V33, P381, DOI 10.2188/jea.JE20230030; Imran M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13605; Jarrah AM, 2023, ONLINE J COMMUN MEDI, V13, DOI 10.30935/ojcmt/13572; Kirwan A, 2023, IRISH EDUC STUD, DOI 10.1080/03323315.2023.2284901; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; McGuire A., 2023, Irish Journal of Technology Enhanced Learning, V7, P21, DOI [10.22554/ijtel.v7i2.131, DOI 10.22554/IJTEL.V7I2.131]; Nagarkar Shubhada, 2023, Indian J Med Ethics, VVIII, P93, DOI 10.20529/IJME.2023.029; O'Connor S, 2023, NURSE EDUC PRACT, V67, DOI 10.1016/j.nepr.2023.103572; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OpenAI, 2022, OpenA I; Rahimi F, 2023, ANN BIOMED ENG, V51, P2340, DOI 10.1007/s10439-023-03260-8; Schroeder R., 2023, Inside Higher Ed; Semrl N, 2023, HUM REPROD, V38, P2281, DOI 10.1093/humrep/dead207; Sharma R. C., 2024, Transforming Education With Generative AI: Prompt Engineering and Synthetic Content Creation, DOI [10.4018/979-8-3693-1351-0, DOI 10.4018/979-8-3693-1351-0]; Siegerink B, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103599; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Tang GY, 2023, IRISH J MED SCI, V192, P3195, DOI 10.1007/s11845-023-03374-x; Tang GY, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2180359; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Weissman J., 2023, Inside Higher Ed; Zielinski C., 2023, Chatbots, ChatGPT, and scholarly manuscripts: WAME recommendations on ChatGPT and Chatbots in relation to scholarly publications, DOI [10.25100/cm.v54i3.5868, DOI 10.25100/CM.V54I3.5868]	59	2	2	32	32	INT COUNCIL OPEN & DISTANCE EDUCATION	OSLO	LILLEAKERVEIEN 23, OSLO, 0283, NORWAY	2304-070X			OPEN PRAX	Open Prax.		2024	16	1					1	10		10.55982/openpraxis.16.1.654	http://dx.doi.org/10.55982/openpraxis.16.1.654			10	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	NZ8G5		gold			2024-07-03	WOS:001204361200009
C	Tarau, P				Tarau, Paul			Natlog: Embedding Logic Programming into the Python Deep-Learning Ecosystem	ELECTRONIC PROCEEDINGS IN THEORETICAL COMPUTER SCIENCE			English	Proceedings Paper	39th International Conference on Logic Programming (ICLP)	JUL 09-15, 2023	Imperial Coll London, London, ENGLAND		Imperial Coll London	embedding of logic programming in the Python ecosystem; high-level inter-paradigm data exchanges; coroutining with logic engines; logic-based neuro-symbolic computing; logic grammars as prompt-generators for Large Language Models; logic-based neural network configuration and training		Driven by expressiveness commonalities of Python and our Python-based embedded logic-based language Natlog, we design high-level interaction patterns between equivalent language constructs and data types on the two sides. By directly connecting generators and backtracking, nested tuples and terms, coroutines and first-class logic engines, reflection and meta-interpretation, we enable logic-based language constructs to access the full power of the Python ecosystem. We show the effectiveness of our design via Natlog apps working as orchestrators for JAX and Pytorch pipelines and as DCG-driven GPT3 and DALL.E prompt generators.	[Tarau, Paul] Univ North Texas, Denton, TX 76205 USA	University of North Texas System; University of North Texas Denton	Tarau, P (corresponding author), Univ North Texas, Denton, TX 76205 USA.	paul.tarau@unt.edu						Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; CompVis Machine Vision & Learning Research Group at LMU Munich, 2018, Stable Diffusion; De Raedt L, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2468; Sarker MK, 2021, Arxiv, DOI arXiv:2105.05330; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Ramesh A, 2021, Arxiv, DOI [arXiv:2102.12092, 10.48550/arXiv.2102.12092]; Tarau P, 2000, LECT NOTES ARTIF INT, V1861, P1225; Tarau Paul, 1999, The Logic Programming Paradigm: a 25 Year Perspective, P33, DOI [DOI 10.1007/978-3-642-60085-2.2, 10.1007/978-3-642-60085-2'2]; Tarau Paul, 2021, P 37 INT C LOGIC PRO, DOI DOI 10.4204/EPTCS.345.27; Thmpson Jeff, 2019, Yield Prolog; Vaswani A, 2017, ADV NEUR IN, V30	12	0	0	0	0	OPEN PUBL ASSOC	SYDNEY	OPEN PUBL ASSOC, SYDNEY, 00000, AUSTRALIA	2075-2180			ELECTRON P THEOR COM	Electron. Proc. Theor. Comput. Sci.		2023		385					141	154		10.4204/EPTCS.385.15	http://dx.doi.org/10.4204/EPTCS.385.15			14	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	HP3K9		gold, Green Submitted			2024-07-03	WOS:001160667500008
J	Johnston, EW; Goldberg, SN				Johnston, Edward W.; Goldberg, S. Nahum			Photodynamic Therapy for Abdominopelvic Abscesses	RADIOLOGY			English	Editorial Material							LARGE LANGUAGE MODELS		[Johnston, Edward W.] Royal Marsden NHS Fdn Trust, Dept Intervent Radiol, 203 Fulham Rd, London SW3 6JJ, England; [Johnston, Edward W.] Inst Canc Res, Comp Assisted Intervent Radiol, London, England; [Goldberg, S. Nahum] Hadassah Hebrew Univ, Med Ctr, Radiol, Jerusalem, Israel; [Goldberg, S. Nahum] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Boston, MA USA	Royal Marsden NHS Foundation Trust; University of London; Institute of Cancer Research - UK; Royal Marsden NHS Foundation Trust; Hebrew University of Jerusalem; Hadassah University Medical Center; Harvard University; Harvard Medical School; Beth Israel Deaconess Medical Center	Johnston, EW (corresponding author), Royal Marsden NHS Fdn Trust, Dept Intervent Radiol, 203 Fulham Rd, London SW3 6JJ, England.; Johnston, EW (corresponding author), Inst Canc Res, Comp Assisted Intervent Radiol, London, England.	ed.johnston@rmh.nhs.uk		Goldberg, S. Nahum/0000-0003-2940-9822				[Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bard, Google; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Haugen BR, 2016, THYROID, V26, P1, DOI 10.1089/thy.2015.0020; Kulkarni PA, 2023, JAMA-J AM MED ASSOC, V330, P317, DOI 10.1001/jama.2023.11440; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167; Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Moon JH, 2022, IEEE J BIOMED HEALTH, V26, P6070, DOI 10.1109/JBHI.2022.3207502; Moy L, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.239024; Mukherjee P, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.231147; OpenAI, ChatGPT 4.0; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Tariq R, 2024, GASTROENTEROLOGY, V166, P220, DOI 10.1053/j.gastro.2023.08.033; Tessler FN, 2017, J AM COLL RADIOL, V14, P587, DOI 10.1016/j.jacr.2017.01.046; Tong WJ, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.13674; Ye Z, 2022, 2022 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT, P277, DOI 10.1109/WI-IAT55865.2022.00047	23	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	MAR	2024	310	3							e240408	10.1148/radiol.240408	http://dx.doi.org/10.1148/radiol.240408			3	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	OR3U4	38501955				2024-07-03	WOS:001208969200019
J	de Schryver, GM				de Schryver, Gilles-Maurice			Generative AI and Lexicography: The Current State of the Art Using ChatGPT	INTERNATIONAL JOURNAL OF LEXICOGRAPHY			English	Review						Lexicography; Artificial Intelligence (AI); Large Language Model (LLM); Generative AI; Generative Pre-Trained Transformer (GPT); Chatbot; ChatGPT; Bard; Bing Chat; Claude; Stable Diffusion; Prompt; Bias; Hallucination; Black Box; Non-Deterministic Output; Memorisation; COBUILD; Full-sentence defining style; Authentic-like example sentences		In this article, all ten papers and talks that have been devoted to the use of ChatGPT in lexicography so far are critically analysed, their results tabulated and cross-compared, from which the leading trends are determined. Extrapolating from the trendlines, a single short but robust new prompt is fine-tuned with which articles from different word classes are generated fully-automatically for a dictionary which compares favourably to the best practice in dictionary compilation. The conclusion is that a new age, that of the successful application of generative AI in lexicography, has dawned.	[de Schryver, Gilles-Maurice] Univ Ghent, UGent Ctr Bantu Studies BantUGent, Ghent, Belgium; [de Schryver, Gilles-Maurice] Language & Translat Technol Team LT3, Ghent, Belgium; [de Schryver, Gilles-Maurice] Univ Pretoria, Dept African Languages, Pretoria, South Africa	Ghent University; University of Pretoria	de Schryver, GM (corresponding author), Univ Ghent, UGent Ctr Bantu Studies BantUGent, Ghent, Belgium.; de Schryver, GM (corresponding author), Language & Translat Technol Team LT3, Ghent, Belgium.; de Schryver, GM (corresponding author), Univ Pretoria, Dept African Languages, Pretoria, South Africa.	gillesmaurice.deschryver@UGent.be						[Anonymous], 2023, THE ECONOMIST   0422; [Anonymous], 2023, THE ECONOMIST   0419; [Anonymous], 2023, MACMILLAN DICT CLOSE; Arredondo P., 2023, GPT-4 Passes the Bar Exam: What That Means for Artificial Intelligence Tools in the Legal Profession'; Atkins B.T. Sue., 2010, P 15 EURALEX INT C 6, P549; Baisa Vit, 2019, ELECT LEXICOGRAPHY 2, P805; Barnbrook Geoff., 2002, STUDIES CORPUS LINGU; Barrett Grant, 2023, 24 BIENN C DICT SOC; BBC, 2023, BBC             0713; Chang K.K., 2023, SPEAK MEMORY ARCHAEO; Chomsky N., 2023, NEW YORK TIMES; Chomsky N, 1957, SYNTACTIC STRUCTURES; Clear Jeremy., 1987, LOOKING ACCOUNT COBU, P41; COBUILD, 2023, COLLINS COBUILD ADV; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; de Schryver, 2023, 8 EL LEX 21 CENT C B; de Schryver Gilles-Maurice., 2010, LINGUISTICS SERIES; de Schryver Gilles-Maurice., 2024, CAMBRIDGE HDB DICT; de Schryver Gilles-Maurice, 2010, WAY WORDS RECENT ADV, V2, P3; de Schryver Gilles-Maurice, 2023, 20 CODH SEM CTR OP D; De Schryver GM, 2003, INT J LEXICOGR, V16, P143, DOI 10.1093/ijl/16.2.143; Fazackerley A., 2023, The Observer; Fox G., 1987, LOOKING UP, P137; Hanks, 1987, Looking up: An account of the COBUILD Project in lexical computing and the development of the Collins COBUILD English language dictionary, P116; Hanks Patrick., 2002, LEXICOGRAPHY NATURAL, P156; Hargraves Orin, 2021, 23 BIENN C DICT SOC; Hornby AS., 2020, Oxford advanced learner's dictionary of current English; Jakubicek, 2023, P ELEX 2023 C EL LEX, P508; Jakubiek Milos., 2021, EUR 19 C EUR ASS LEX, P65; Jakubiek Milos, 2013, 7 INT CORP LING C, P125; Kilgarriff A., 2001, P COLLOCATION COMPUT, P32; Kilgarriff A., 2004, P 11 EURALEX INT C, P105, DOI DOI 10.1007/S40607-014-0009-9; KILGARRIFF A., 2008, P 13 EURALEX INT C S, P425; Kilgarriff A., 2014, LEXICOGRAPHY, V1, P7, DOI DOI 10.1007/S40607-014-0009-9; Kilgarriff A, 2007, COMPUT LINGUIST, V33, P147, DOI 10.1162/coli.2007.33.1.147; Kilgarriff Adam., 2010, RECENT ADV LEXICAL T, P299; Kosem, 2014, P 16 EURALEX INT C U, P355; Lew Robert., HUM SOC SCI COMMUN; Liang, 2021, ARXIV; Liang Y., 2023, arXiv; McIntosh Colin., 2023, CAMBRIDGE THESAURUS; McKean E., 2023, P 16 INT C AS ASS LE, P10; Merken Sara, 2023, REUTERS         0626; Moon Rosamund., 1987, LOOKING UP, P86; Nichols Wendalyn, 2023, ELEX 2023 C EL LEX 2; O'Connor Brendan H., 2023, CONVERSATION    0612; Phoodai Chayanon, 2023, P ELEX 2023 C EL LEX, P335; Reuters, 2023, REUTERS         0524; Rundell M., 2012, Electronic Lexicography, P15; Rundell M., 2012, Proceedings of the 15th Euralex International Congress, P47; Rundell M, 2011, STUD CORPUS LINGUIST, V45, P257; Rundell Michael., 2023, P 16 INT C AS ASS LE, P1; Rundell Michael., 2012, MACMILLAN ED; Schulman J, 2022, Introducing chatgpt; Shen Y, 2023, arXiv; Sinclair John., 1987, Collins COBUILD English language dictionary; Sinclair McH John., 1987, LOOKING ACCOUNT COBU, P104; The Economist, 2023, THE ECONOMIST   0606; Tran Hanh Thi Hong, 2023, ELECT LEXICOGRAPHY 2, P19; U.S. Copyright Office, 2023, FED REGISTER; van der Meer Geart., 1996, 7 EURALEX INT C LEX, P423; Varantola K., 2002, Lexicography and Natural Language Processing A Festschrift in Honour of B.T.S. Atkins, P30; Vossen P., 2022, VU Magazine22 December; Vossen Piek., 1998, EuroWordNet: A Multilingual Database with Lexical Semantic Networks; Wiegand H E., 2010, Worterbuch zur Lexikographie und Worterbuchforschung; Wiegand H.E., 1989, Worterbucher. Ein internationales Handbuch zur Lexikographie, P409	66	7	7	33	80	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0950-3846	1477-4577		INT J LEXICOGR	Int. J. Lexicogr.	DEC 13	2023	36	4					355	387		10.1093/ijl/ecad021	http://dx.doi.org/10.1093/ijl/ecad021		OCT 2023	33	Linguistics; Language & Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics	CS4F0		Bronze			2024-07-03	WOS:001076722200001
J	Schopow, N; Osterhoff, G; Baur, D				Schopow, Nikolas; Osterhoff, Georg; Baur, David			Applications of the Natural Language Processing Tool ChatGPT in Clinical Practice: Comparative Study and Augmented Systematic Review	JMIR MEDICAL INFORMATICS			English	Review						natural language processing; clinical practice; systematic review; healthcare; health care; GPT-3; GPT-4; large language models; artificial intelligence; machine learning; clinical decision support systems; language model; NLP; ChatGPT; systematic; review methods; review methodology; text; unstructured; extract; extraction		Background: This research integrates a comparative analysis of the performance of human researchers and OpenAI's ChatGPT in systematic review tasks and describes an assessment of the application of natural language processing (NLP) models in clinical practice through a review of 5 studies.Objective: This study aimed to evaluate the reliability between ChatGPT and human researchers in extracting key information from clinical articles, and to investigate the practical use of NLP in clinical settings as evidenced by selected studies. Methods: The study design comprised a systematic review of clinical articles executed independently by human researchers and ChatGPT. The level of agreement between and within raters for parameter extraction was assessed using the Fleiss and Cohen kappa statistics. Results: The comparative analysis revealed a high degree of concordance between ChatGPT and human researchers for most parameters, with less agreement for study design, clinical task, and clinical implementation. The review identified 5 significant studies that demonstrated the diverse applications of NLP in clinical settings. These studies' findings highlight the potential of NLP to improve clinical efficiency and patient outcomes in various contexts, from enhancing allergy detection and classification to improving quality metrics in psychotherapy treatments for veterans with posttraumatic stress disorder.Conclusions: Our findings underscore the potential of NLP models, including ChatGPT, in performing systematic reviews and other clinical tasks. Despite certain limitations, NLP models present a promising avenue for enhancing health care efficiency and accuracy. Future studies must focus on broadening the range of clinical applications and exploring the ethical considerations of implementing NLP applications in health care settings.	[Schopow, Nikolas; Osterhoff, Georg; Baur, David] Univ Hosp Leipzig, Dept Orthoped Trauma Surg & Plast Surg, Leipzig, Germany; [Schopow, Nikolas] Univ Hosp Leipzig, Dept Orthoped Trauma Surg & Plast Surg, Liebigstr 20, D-04103 Leipzig, Germany	Leipzig University; Leipzig University	Schopow, N (corresponding author), Univ Hosp Leipzig, Dept Orthoped Trauma Surg & Plast Surg, Liebigstr 20, D-04103 Leipzig, Germany.	schopow@medizin.uni-leipzig.de	Osterhoff, Georg/IXW-9149-2023	Osterhoff, Georg/0000-0001-5051-0998				Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Beam AL, 2018, JAMA-J AM MED ASSOC, V319, P1317, DOI 10.1001/jama.2017.18391; Berge GT, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02101-x; Berman AN, 2021, CLIN CARDIOL, V44, P1296, DOI 10.1002/clc.23687; Bramer WM, 2016, J MED LIBR ASSOC, V104, P240, DOI 10.3163/1536-5050.104.3.014; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Elkin PL, 2021, J MED INTERNET RES, V23, DOI 10.2196/28946; Feng YY, 2022, J AM MED INFORM ASSN, V29, P1425, DOI 10.1093/jamia/ocac066; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Fu SY, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103526; Gotzsche PC, 2012, BMJ-BRIT MED J, V345, DOI 10.1136/bmj.e7031; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Higgins J.P.T., 2008, Cochrane handbook for systematic reviews of interventions: Cocharne Book Series, DOI DOI 10.1002/9780470712184; Higgins JPT, 2020, COCHRANE HDB SYSTEMA; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang M, 2011, J AM MED INFORM ASSN, V18, P601, DOI 10.1136/amiajnl-2011-000163; Larsen PO, 2010, SCIENTOMETRICS, V84, P575, DOI 10.1007/s11192-010-0202-z; Lederman A, 2022, J AM MED INFORM ASSN, V29, P1810, DOI 10.1093/jamia/ocac121; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Marchesin Stefano, 2022, J Pathol Inform, V13, P100139, DOI 10.1016/j.jpi.2022.100139; Marshall IJ, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1074-9; Meystre S M, 2008, Yearb Med Inform, P128; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Odisho AY, 2019, JCO CLIN CANCER INFO, V3, DOI 10.1200/CCI.18.00084; OpenAI, ABOUT US; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Reddy V, 2023, CURR OPIN SUPPORT PA, V17, P125, DOI 10.1097/SPC.0000000000000645; Shiner B, 2022, J EVAL CLIN PRACT, V28, P520, DOI 10.1111/jep.13587; Shivade C, 2014, J AM MED INFORM ASSN, V21, P221, DOI 10.1136/amiajnl-2013-001935; Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039; Tsafnat G, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-74; Vaswani A, 2017, ADV NEUR IN, V30; Waffenschmidt S, 2013, J CLIN EPIDEMIOL, V66, P660, DOI 10.1016/j.jclinepi.2012.11.011; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Weng WH, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0556-8; Yan MY, 2022, J AM MED INFORM ASSN, V29, P559, DOI 10.1093/jamia/ocab236	39	3	3	13	14	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2291-9694		JMIR MED INF	JMIR Med. Inf.		2023	11								e48933	10.2196/48933	http://dx.doi.org/10.2196/48933			12	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	Z9XL4	38015610	gold, Green Published			2024-07-03	WOS:001115534200003
J	Kocon, J; Cichecki, I; Kaszyca, O; Kochanek, M; Szydlo, D; Baran, J; Bielaniewicz, J; Gruza, M; Janz, A; Kanclerz, K; Kocon, A; Koptyra, B; Mieleszczenko-Kowszewicz, W; Milkowski, P; Oleksy, M; Piasecki, M; Radlinski, L; Wojtasik, K; Wozniak, S; Kazienko, P				Kocon, Jan; Cichecki, Igor; Kaszyca, Oliwier; Kochanek, Mateusz; Szydlo, Dominika; Baran, Joanna; Bielaniewicz, Julita; Gruza, Marcin; Janz, Arkadiusz; Kanclerz, Kamil; Kocon, Anna; Koptyra, Bartlomiej; Mieleszczenko-Kowszewicz, Wiktoria; Milkowski, Piotr; Oleksy, Marcin; Piasecki, Maciej; Radlinski, Lukasz; Wojtasik, Konrad; Wozniak, Stanislaw; Kazienko, Przemyslaw			ChatGPT: Jack of all trades, master of none	INFORMATION FUSION			English	Article						ChatGPT; GPT-4; Natural language processing (NLP); Semantic NLP tasks; Pragmatic NLP tasks; Subjective NLP tasks; Natural language inference (NLI); Sentiment analysis; Offensive content; Emotion recognition; Humor detection; Stance detection; Word sense disambiguation (WSD); Question answering (QA); Model personalization; Text classification; SOTA analysis; Large language model; Prompting		OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. The first contact with the chatbot reveals its ability to provide detailed and precise answers in various areas. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few -shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established.	[Kocon, Jan; Cichecki, Igor; Kaszyca, Oliwier; Kochanek, Mateusz; Szydlo, Dominika; Baran, Joanna; Bielaniewicz, Julita; Gruza, Marcin; Janz, Arkadiusz; Kanclerz, Kamil; Kocon, Anna; Koptyra, Bartlomiej; Mieleszczenko-Kowszewicz, Wiktoria; Milkowski, Piotr; Oleksy, Marcin; Piasecki, Maciej; Radlinski, Lukasz; Wojtasik, Konrad; Wozniak, Stanislaw; Kazienko, Przemyslaw] Wroclaw Univ Sci & Technol, Dept Artificial Intelligence, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland	Wroclaw University of Science & Technology	Kocon, J (corresponding author), Wroclaw Univ Sci & Technol, Dept Artificial Intelligence, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.	jan.kocon@pwr.edu.pl; kazienko@pwr.edu.pl	Kocon, Jan/IXN-3388-2023; Kazienko, Przemysław/F-1849-2014; Kanclerz, Kamil/ABD-3695-2021; Wojtasik, Konrad/JKO-6284-2023	Kocon, Jan/0000-0002-7665-6896; Kazienko, Przemysław/0000-0001-5868-356X; Kanclerz, Kamil/0000-0002-7375-7544; Wojtasik, Konrad/0000-0002-5715-5201; Piasecki, Maciej/0000-0003-1503-0993	National Science Centre, Poland [2021/41/B/ST6/04471]; Polish Ministry of Education and Science, CLARIN-PL; European Regional Development Fund; Department of Artificial Intelligence, Wroclaw University of Science and Technology; Polish Ministry of Education and Science; European Union under the Horizon Europe;  [POIR.04.02.00-00C002/19];  [POIR.01.01. 01-00-0288/22];  [101086321]	National Science Centre, Poland(National Science Centre, Poland); Polish Ministry of Education and Science, CLARIN-PL; European Regional Development Fund(European Union (EU)); Department of Artificial Intelligence, Wroclaw University of Science and Technology; Polish Ministry of Education and Science(Ministry of Science and Higher Education, Poland); European Union under the Horizon Europe; ; ; 	This work was financed by (1) the National Science Centre, Poland, project no. 2021/41/B/ST6/04471 (JK, PK); (2) the Polish Ministry of Education and Science, CLARIN-PL; (3) the European Regional Development Fund as a part of the 2014-2020 Smart Growth Operational Programme, projects no. POIR.04.02.00-00C002/19 and POIR.01.01. 01-00-0288/22; (4) the statutory funds of the Department of Artificial Intelligence, Wroclaw University of Science and Technology; (5) the Polish Ministry of Education and Science within the programme "International Projects Co-Funded"; (6) the European Union under the Horizon Europe, grant no. 101086321 (OMINO). However, the views and opinions expressed are those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Executive Agency. Neither the European Union nor European Research Executive Agency can be held responsible for them.	Alshemali B, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105210; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; Annamoradnejad I, 2022, Arxiv, DOI [arXiv:2004.12765, DOI 10.48550/ARXIV.2004.12765]; Antaki F, 2023, medRxiv, DOI [10.1101/2023.01.22.23284882, 10.1101/2023.01.22.23284882, DOI 10.1101/2023.01.22.23284882]; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Azaria A., 2022, ChatGPT Usage and Limitations; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Barba E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1492; Barbieri F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1644; Bielaniewicz J, 2022, INT CONF DAT MIN WOR, P967, DOI 10.1109/ICDMW58026.2022.00125; Blum-Kulka Shoshana., 2011, Discourse Studies: A Multidisciplinary Introduction, V2nd, P143; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Brown Tom, 2020, NIPS, V33, P1877; Lipton ZC, 2015, Arxiv, DOI arXiv:1506.00019; Castillo-Gonzalez W., 2022, METAVERSE BASIC APPL, V2, P29; Chen YR, 2023, Arxiv, DOI [arXiv:2212.10522, 10.48550/arXiv.2212.10522]; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Edmonds P., 2001, P SENSEVAL 2 2 INT W, P1; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Firth JR, 1957, Selected Papers of J. R. Firth, P10; Ganegedara T., 2018, Natural Language Processing with Tensorflow: Teach Language to Machines Using Python's Deep Learning Library; Ganesan A.V., P 2021 C N AM CHAPT; Gao C.A., 2022, BIORXIV, DOI [10.1101/2022.12.23.521610,bioRxiv, DOI 10.1101/2022.12.23.521610,BIORXIV]; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Gillioz Anthony, 2020, 2020 15th Conference on Computer Science and Information Systems (FedCSIS), P179, DOI 10.15439/2020F20; Gilson A, 2022, medRxiv, DOI [10.1101/2022.12.23.22283901, 10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; Hidalgo JMG, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P240, DOI 10.1109/ICMLA.2012.211; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8; He P., 2021, arXiv; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Johnson R., 2016, PR MACH LEARN RES, P526; Kanclerz K., 2022, P 1 WORKSHOP PERSPEC, P37; Kanclerz K., 2021, Long Papers, V1, P5915; Karanjai R., 2022, arXiv; Karfi I.E., 2022, INT J ADV COMPUT SC, V13; Kazienko P, 2023, INFORM FUSION, V94, P43, DOI 10.1016/j.inffus.2023.01.010; Kilgarriff A, 2000, LANGUAGE, V76, P706, DOI 10.2307/417141; Kivlichan I.D., 2021, arXiv; Kocon J, 2021, IEEE DATA MINING, P1168, DOI 10.1109/ICDM51629.2021.00140; Kocon J, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102643; Kocon Jan, 2019, P 23 C COMPUTATIONAL, P980, DOI DOI 10.18653/V1/K19-1092; Korczynski W, 2022, INT CONF DAT MIN WOR, P419, DOI 10.1109/ICDMW58026.2022.00062; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kumar P, 2022, ONLINE INFORM REV, V46, P1242, DOI 10.1108/OIR-03-2021-0184; Kung T. H., 2022, medRxiv; Kutela B., 2023, CHATGPTS SCI WRITING; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Li YF, 2023, Arxiv, DOI arXiv:2206.02336; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078; Liu P.J., 2018, 6 INT C LEARNING REP; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038; Loureiro D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P251; Lund B., 2023, Chatting about ChatGPT: How may AI and GPT impact academia and libraries?; Milkowski P, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), DOI 10.1109/PerComWorkshops53856.2022.9767502; Milkowski P, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P248; Moro A., 2015, P 9 INT WORKSHOP SEM, P288; Morris Charles William., 1938, International Encyclopedia of Unified Science, V1, P1; Navigli R., 2013, P 7 INT WORKSH SEM E, V2, P222; Ngo A., 2022, P 1 WORKSHOP PERSPEC, P46; Ni JJ, 2023, ARTIF INTELL REV, V56, P3055, DOI 10.1007/s10462-022-10248-8; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Patra B., 2022, arXiv, DOI 10.48550/arXiv.2210.14867; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Perlman A. M., 2022, The Implications of OpenAI's Assistant for Legal Services and Society; Phillips T., 2022, P INT C LEARN AN KNO, P54; Pilehvar M.T., 2019, P 2019 C N AM CHAPT, V1, P2; Pradhan S, 2007, P 4 INT WORKSH SEM E, P87; Price I., 2020, P 4 WORKSH ONL AB HA, P114, DOI [10.18653/v1/2020.alw-1.15, DOI 10.18653/V1/2020.ALW-1.15,ONLINE]; Puerto H, 2023, Arxiv, DOI arXiv:2112.01922; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI Blog; Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99; Rahman W., 2020, P 58 ANN M ASS COMP, P5; Rajpurkar P, 2018, Arxiv, DOI arXiv:1806.03822; Sahmoud T., 2022, arXiv, DOI 10.48550/arXiv.2206.02443; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Siddiqui R., 2019, Sarcasmania: Sarcasm exposed; Snyder B, 2004, SENSEVAL, P41; Srivastava Aarohi, 2022, arXiv; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tabone W., 2023, Using ChatGPT for human-computer interaction research: A primer; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang SN, 2021, Arxiv, DOI arXiv:2104.14690; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wenzlaff K., 2022, SSRN Scholarly Paper, DOI [10.2139/ssrn.4302443, DOI 10.2139/SSRN.4302443]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1391, DOI 10.1145/3038912.3052591; Xu YC, 2018, Arxiv, DOI arXiv:1711.04964; Zhao L., 2022, arXiv, DOI 10.48550/arXiv.2204.04282; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]; Zoph B., 2022, arXiv	105	69	69	69	172	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	NOV	2023	99								101861	10.1016/j.inffus.2023.101861	http://dx.doi.org/10.1016/j.inffus.2023.101861		JUN 2023	37	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	L7RA5		hybrid, Green Submitted			2024-07-03	WOS:001025183100001
J	Mann, SP; Earp, BD; Moller, N; Suren, V; Savulescu, J				Mann, Sebastian Porsdam; Earp, Brian D.; Moller, Nikolaj; Suren, Vynn; Savulescu, Julian			AUTOGEN and the Ethics of Co-Creation with Personalized LLMs-Reply to the Commentaries	AMERICAN JOURNAL OF BIOETHICS			English	Letter							LARGE LANGUAGE MODELS; ACADEMIC ENHANCEMENT; GENERATIVE AI		[Mann, Sebastian Porsdam; Earp, Brian D.] Univ Oxford, Oxford, England; [Moller, Nikolaj] Univ Oxford, Uehiro Ctr Pract Eth, Oxford, England; [Suren, Vynn; Savulescu, Julian] Natl Univ Singapore, Singapore, Singapore	University of Oxford; University of Oxford; National University of Singapore	Mann, SP (corresponding author), Univ Oxford, Oxford, England.	sebastian.porsdammann@law.ox.ac.uk		Savulescu, Julian/0000-0003-1691-6403	Singapore Ministry of Health's National Medical Research Council under its Enablers & Infrastructure Support for Clinical Trials-Related Activities Funding Initiative (NMRC Project) [MOH-000951-00]	Singapore Ministry of Health's National Medical Research Council under its Enablers & Infrastructure Support for Clinical Trials-Related Activities Funding Initiative (NMRC Project)	This research is supported by the Singapore Ministry of Health's National Medical Research Council under its Enablers & Infrastructure Support for Clinical Trials-Related Activities Funding Initiative (NMRC Project No.MOH-000951-00).	Allen JW, 2024, J MED ETHICS, V50, P77, DOI 10.1136/jme-2023-109347; [Anonymous], 2024, J MED ETHICS; Bakker MA, 2022, ARXIV; Earp B. D. S., PERSONALIZING AI RED; Earp BD, 2023, AM J BIOETHICS, DOI 10.1080/15265161.2023.2296402; Erler A, 2023, AM J BIOETHICS, V23, P94, DOI 10.1080/15265161.2023.2250291; Ganguli D., 2023, arXiv; GRICE HP, 1969, PHILOS REV, V78, P147, DOI 10.2307/2184179; Grice P., 1968, Foundations of Language, V4, P225, DOI DOI 10.1007/978-94-009-2727-8_2; Kar RB, 2019, HARVARD LAW REV, V132, P1135; Laacke S, 2023, AM J BIOETHICS, V23, P60, DOI 10.1080/15265161.2023.2250292; Liedtke W, 2004, OUD HOLLAND, V117, P48, DOI 10.1163/187501704X00278; Mann SP, 2023, AM J BIOETHICS, V23, P28, DOI 10.1080/15265161.2023.2233356; Mann SP, 2018, ETHICS EDUC, V13, P251, DOI 10.1080/17449642.2018.1443050; Mcmillan J, 2023, AM J BIOETHICS, V23, P42, DOI 10.1080/15265161.2023.2249852; Nyholm S, 2023, AM J BIOETHICS, V23, P44, DOI 10.1080/15265161.2023.2249846; Nyholm Sven, 2024, Camb Q Healthc Ethics, V33, P76, DOI 10.1017/S0963180123000464; Ostertag G, 2023, AM J BIOETHICS, V23, P91, DOI 10.1080/15265161.2023.2249851; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Piantadosi S. T., 2022, arXiv; Mann SP, 2023, NAT MACH INTELL, V5, P472, DOI 10.1038/s42256-023-00653-1; Resnik DB, 2023, AM J BIOETHICS, V23, P50, DOI 10.1080/15265161.2023.2250276; Sorin V., 2023, medRxiv; Tietze Hans., 1939, PARNASSUS-POETRY REV, V11, P34, DOI [10.2307/772019, DOI 10.2307/772019]; United Nations, 1969, VIENNA CONVENTION LA; Van Veen Dave, 2023, Res Sq, DOI 10.21203/rs.3.rs-3483777/v1; Varma S, 2023, AM J BIOETHICS, V23, P105, DOI 10.1080/15265161.2023.2250286; Zhang T, 2023, ARXIV; Zohny H, 2023, AM J BIOETHICS, V23, P96, DOI 10.1080/15265161.2023.2250315	29	0	0	8	8	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1526-5161	1536-0075		AM J BIOETHICS	Am. J. Bioeth.	MAR 3	2024	24	3					W6	W14		10.1080/15265161.2024.2308175	http://dx.doi.org/10.1080/15265161.2024.2308175		FEB 2024	9	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	KB4D9	38346141	hybrid			2024-07-03	WOS:001160788500001
J	Bell, S				Bell, Steven			The write algorithm: promoting responsible artificial intelligence usage and accountability in academic writing	BMC MEDICINE			English	Editorial Material							LARGE LANGUAGE MODELS; CHATGPT		[Bell, Steven] Univ Cambridge, Precis Breast Canc Inst, Dept Oncol, Cambridge, England; [Bell, Steven] Univ Cambridge, Canc Res UK Cambridge Ctr, Li Ka Shing Ctr, Cambridge, England	University of Cambridge; Cancer Research UK; University of Cambridge; CRUK Cambridge Institute	Bell, S (corresponding author), Univ Cambridge, Precis Breast Canc Inst, Dept Oncol, Cambridge, England.; Bell, S (corresponding author), Univ Cambridge, Canc Res UK Cambridge Ctr, Li Ka Shing Ctr, Cambridge, England.	scb81@medschl.cam.ac.uk						Brainard J, 2023, SCIENCE, V379, P740, DOI 10.1126/science.adh2762; Carr EJ, 2023, LANCET INFECT DIS, V23, P781, DOI 10.1016/S1473-3099(23)00290-6; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; International Committee of Medical Journal Editors, 2023, REC COND REP ED PUBL; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Peng YF, 2023, NAT MED, V29, P1593, DOI 10.1038/s41591-023-02366-9; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6	10	3	3	11	18	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1741-7015			BMC MED	BMC Med.	SEP 4	2023	21	1							334	10.1186/s12916-023-03039-7	http://dx.doi.org/10.1186/s12916-023-03039-7			4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	R3FI0	37667296	Green Published, gold			2024-07-03	WOS:001063237800006
J	Leung, TI; Cardoso, TD; Mavragani, A; Eysenbach, G				Leung, Tiffany, I; Cardoso, Taiane de Azevedo; Mavragani, Amaryllis; Eysenbach, Gunther			Best Practices for Using AI Tools as an Author, Peer Reviewer, or Editor	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Editorial Material						publishing; open access publishing; open science; publication policy; science editing; scholarly publishing; scientific publishing; research; scientific research; editorial; artificial intelligence; AI	LARGE LANGUAGE MODELS; CHATGPT	The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution. In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications' editorial policies on these issues. We further detail JMIR Publications' approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.	[Leung, Tiffany, I; Cardoso, Taiane de Azevedo; Mavragani, Amaryllis; Eysenbach, Gunther] JMIR Publicat Inc, Toronto, ON, Canada; [Leung, Tiffany, I] Southern Illinois Univ, Sch Med, Dept Internal Med, Springfield, IL USA; [Eysenbach, Gunther] Univ Victoria, Victoria, BC, Canada; [Leung, Tiffany, I] JMIR Publicat Inc, 130 Queens Quay East,Unit 1100, Toronto, ON M5A 0P6, Canada	Southern Illinois University System; Southern Illinois University; University of Victoria	Leung, TI (corresponding author), JMIR Publicat Inc, 130 Queens Quay East,Unit 1100, Toronto, ON M5A 0P6, Canada.	tiffany.leung@jmir.org	Leung, Tiffany I./K-8472-2019; Mavragani, Amaryllis/N-1417-2017	Leung, Tiffany I./0000-0002-6007-4023; Mavragani, Amaryllis/0000-0001-6106-0873				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Addington S, 2023, SSRN Journal, DOI [10.2139/ssrn.4425678, DOI 10.2139/SSRN.4425678]; Anderson R, 2023, SSP C DEBATE AI INTE; [Anonymous], CRediT-Contributor Roles Taxonomy; [Anonymous], 2023, Do you allow the the use of ChatGPT or other generative language models and how should this be reported?; [Anonymous], 2023, AI ACT STEP CLOS 1 R; [Anonymous], 2023, Gpt-4 Technical Report; [Anonymous], 2023, The use of generative artificial intelligence technologies is prohibited for the NIH peer review process; [Anonymous], 2023, Chatbots, generative AI, and scholarly manuscripts; [Anonymous], 2023, EU AI Act: first regulation on artificial intelligence; [Anonymous], 2023, Authorship and AI tools; [Anonymous], Peer-review (FAQs for reviewers); [Anonymous], Publishing ethics; Coiera EW, 2023, MED J AUSTRALIA, V219, P98, DOI 10.5694/mja2.51992; COPE Council, 2006, COPE flowcharts and infographics-plagiarism in a published article-English, DOI [10.24318/cope.2019.2.2, DOI 10.24318/COPE.2019.2.2]; da Silva JAT, 2023, LEARN PUBL, V36, P453, DOI 10.1002/leap.1547; Editorial Director, 2023, Copyright, licensing, attribution of TOC images; Editorial Director, 2023, What is open peer-review?; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; GPTZero, US; Hira R., 2023, National Academy of Medicine; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; JMIR Copyediting Team, 2023, How should the "Acknowledgments"section be formatted?; JMIR Editorial Team, 2023, how to write a high-quality peer review; Landis G, 2023, Science Editor; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; McNutt MK, 2018, P NATL ACAD SCI USA, V115, P2557, DOI 10.1073/pnas.1715374115; Merz JF., 2023, CHATGPT JUST MAKES S; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; OpenAI, ABOUT US; Parsons CE, 2021, TRENDS COGN SCI, V25, P639, DOI 10.1016/j.tics.2021.05.003; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Taylor & Francis Editor Resources, 2020, About us; Terms of service, 2023, Antropic Console; Terms of use, 2023, OpenAI; Zakrzewski C., 2023, Washington Post	44	5	5	46	70	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	AUG 31	2023	25								e51584	10.2196/51584	http://dx.doi.org/10.2196/51584			8	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	T5KR4	37651164	Green Published, gold			2024-07-03	WOS:001078379700004
J	Gebre, TS; Beni, L; Wasehun, ET; Dorbu, FE				Gebre, Tewodros Syum; Beni, Leila; Tsehaye Wasehun, Eden; Dorbu, Freda Elikem			AI-Integrated Traffic Information System: A Synergistic Approach of Physics Informed Neural Network and GPT-4 for Traffic Estimation and Real-Time Assistance	IEEE ACCESS			English	Article						Sensors; Biological neural networks; Real-time systems; Mathematical models; Predictive models; Information systems; Sensor systems; Traffic control; Traffic congestion; Intelligent transportation systems; Artificial intelligence; Natural language processing; AI-integrated traffic information system; physics informed neural network (PINN); traffic state estimation (TSE); traffic data processing; GPT-4; prompt engineering; natural language processing (NLP); large language models (LLM); foundation models		Traffic management systems have primarily relied on live traffic sensors for real-time traffic guidance. However, this dependence often results in uneven service delivery due to the limited scope of sensor coverage or potential sensor failures. This research introduces a novel approach to overcome this limitation by synergistically integrating a Physics-Informed Neural Network-based Traffic State Estimator (PINN-TSE) with a powerful Natural Language Processing model, GPT-4. The purpose of this integration is to provide a seamless and personalized user experience, while ensuring accurate traffic density prediction even in areas with limited data availability. The innovative PINN-TSE model was developed and tested, demonstrating a promising level of precision with a Mean Absolute Error of less than four vehicles per mile in traffic density estimation. This performance underlines the model's ability to provide dependable traffic information, even in regions where conventional traffic sensors may be sparsely distributed or data communication is likely to be interrupted. Furthermore, the incorporation of GPT-4 enhances user interactions by understanding and responding to inquiries in a manner akin to human conversation. This not only provides precise traffic updates but also interprets user intentions for a tailored experience. The results of this research showcase an AI-integrated traffic guidance system that outperforms traditional methods in terms of traffic estimation, personalization, and reliability. While the study primarily focuses on a single road segment, the methodology shows promising potential for expansion to network-level traffic guidance, offering even greater accuracy and usability. This paves the way for a smarter and more efficient approach to traffic management in the future.	[Gebre, Tewodros Syum; Tsehaye Wasehun, Eden] North Carolina A&T State Univ, Coll Sci & Technol, Appl Sci & Technol Program, Greensboro, NC 27411 USA; [Beni, Leila] North Carolina A&T State Univ, Coll Sci & Technol, Geomat Program, Greensboro, NC 27411 USA; [Dorbu, Freda Elikem] North Carolina A&T State Univ, Dept Computat Data Sci & Engn, Greensboro, NC 27411 USA	University of North Carolina; North Carolina A&T State University; University of North Carolina; North Carolina A&T State University; University of North Carolina; North Carolina A&T State University	Beni, L (corresponding author), North Carolina A&T State Univ, Coll Sci & Technol, Geomat Program, Greensboro, NC 27411 USA.	lhashemibeni@ncat.edu		Gebre, Tewodros Syum/0000-0003-4508-2700	North Carolina Department of Transportation (NC DOT)	North Carolina Department of Transportation (NC DOT)	No Statement Available	Abbas Z, 2018, IEEE INT CONGR BIG, P57, DOI 10.1109/BigDataCongress.2018.00015; Alkork S., 2023, P 5 INT C BIOENG SMA, P1; [Anonymous], 2023, The Roadway Safety Problem; [Anonymous], 2023, Transport: Overview; Cai SZ, 2021, J FLUID MECH, V915, DOI 10.1017/jfm.2021.135; Dhingra G., 2019, Int. J. Eng. Adv. Technol. (IJEAT), V8, P146; Féraud R, 2002, NEURAL NETWORKS, V15, P237, DOI 10.1016/S0893-6080(01)00127-7; Greenshields B.D., 1935, P HIGHWAY RES BOARD, V4, P448; Hejtmánek L, 2018, INT J HUM-COMPUT ST, V116, P15, DOI 10.1016/j.ijhcs.2018.04.006; Huang AJ, 2023, IEEE OPEN J INTEL TR, V4, P279, DOI 10.1109/OJITS.2023.3268026; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Jeon J, 2023, COMPUT EDUC, V206, DOI 10.1016/j.compedu.2023.104898; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khoo HL, 2016, TRAVEL BEHAV SOC, V3, P59, DOI 10.1016/j.tbs.2015.08.004; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Kuwahara M, 2021, TRANSPORT RES C-EMER, V127, DOI 10.1016/j.trc.2021.103158; Lin X, 2023, ADULT LEARN, DOI 10.1177/10451595231184928; Liu Y, 2021, COMMUN TRANSP RES, V1, DOI 10.1016/j.commtr.2021.100012; Loumiotis I., 2018, P S E EUR DES AUT CO, P1; Lu JW, 2023, TRANSPORT RES C-EMER, V153, DOI 10.1016/j.trc.2023.104224; Mao ZP, 2020, COMPUT METHOD APPL M, V360, DOI 10.1016/j.cma.2019.112789; Martinez FJ, 2010, IEEE INTEL TRANSP SY, V2, P6, DOI 10.1109/MITS.2010.938166; Mo ZB, 2021, TRANSPORT RES C-EMER, V130, DOI 10.1016/j.trc.2021.103240; More R, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P52, DOI 10.1109/CAST.2016.7914939; Office of Operations, 2023, Active Traffic Management; Passow BN, 2013, IEEE INT C INTELL TR, P1402, DOI 10.1109/ITSC.2013.6728427; Patire AD, 2015, TRANSPORT RES C-EMER, V58, P325, DOI 10.1016/j.trc.2015.02.011; Raissi M., 2017, arXiv, DOI 10.48550/ARXIV.1711.10566; Shi RY, 2021, Arxiv, DOI arXiv:2101.06580; Talal M, 2020, VEH COMMUN, V25, DOI 10.1016/j.vehcom.2020.100280; Tedjopurnomo DA, 2022, IEEE T KNOWL DATA EN, V34, P1544, DOI 10.1109/TKDE.2020.3001195; Usama M, 2022, ALGORITHMS, V15, DOI 10.3390/a15120447; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Waheed U. B., 2020, P EAGE ANN C EXH, P1; Yang L, 2021, J COMPUT PHYS, V425, DOI 10.1016/j.jcp.2020.109913; Yasdi R, 1999, NEURAL COMPUT APPL, V8, P135, DOI 10.1007/s005210050015; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Yin ML, 2021, COMPUT METHOD APPL M, V375, DOI 10.1016/j.cma.2020.113603; Yin XY, 2022, IEEE T INTELL TRANSP, V23, P4927, DOI 10.1109/TITS.2021.3054840; Yuan Y, 2021, TRANSPORT RES B-METH, V146, P88, DOI 10.1016/j.trb.2021.02.007	40	0	0	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						65869	65882		10.1109/ACCESS.2024.3399094	http://dx.doi.org/10.1109/ACCESS.2024.3399094			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	RE7L5		gold			2024-07-03	WOS:001226056700001
J	Lanotte, F; O'Brien, MK; Jayaraman, A				Lanotte, Francesco; O'Brien, Megan K.; Jayaraman, Arun			AI in Rehabilitation Medicine: Opportunities and Challenges	ANNALS OF REHABILITATION MEDICINE-ARM			English	Article						Machine learning; Rehabilitation outcome; Wearable devices; Computer vision; systems; Precision medicine	LARGE LANGUAGE MODELS; ARTIFICIAL-INTELLIGENCE; HEALTH-CARE; PREDICTION; VALIDATION; MOBILITY; SYSTEM	Artificial intelligence (AI) tools are increasingly able to learn from larger and more complex data, thus allowing clinicians and scientists to gain new insights from the information they collect about their patients every day. In rehabilitation medicine, AI can be used to find patterns in huge amounts of healthcare data. These patterns can then be leveraged at the individual level, to design personalized care strategies and interventions to optimize each patient's outcomes. However, building effective AI tools requires many careful considerations about how we collect and handle data, how we train the models, and how we interpret results. In this perspective, we discuss some of the current opportunities and challenges for AI in rehabilitation. We first review recent trends in AI for the screening, diagnosis, treatment, and continuous monitoring of disease or injury, with a special focus on the different types of healthcare data used for these applications. We then examine potential barriers to designing and integrating AI into the clinical workflow, and we propose an end-to-end framework to address these barriers and guide the development of effective AI for rehabilitation. Finally, we present ideas for future work to pave the way for AI implementation in real-world rehabilitation practices.	[Lanotte, Francesco; O'Brien, Megan K.; Jayaraman, Arun] Shirley Ryan AbilityLab, Max Nader Lab Rehabil Technol & Outcomes Res, Chicago, IL USA; [Lanotte, Francesco; O'Brien, Megan K.; Jayaraman, Arun] Northwestern Univ, Dept Phys Med & Rehabil, Chicago, IL 60611 USA; [Jayaraman, Arun] Shirley Ryan AbilityLab, Max Nader Lab Rehabil Technol & Outcomes Res, 355 E Erie St, Chicago, IL 60611 USA	Shirley Ryan AbilityLab; Northwestern University; Shirley Ryan AbilityLab	Jayaraman, A (corresponding author), Shirley Ryan AbilityLab, Max Nader Lab Rehabil Technol & Outcomes Res, 355 E Erie St, Chicago, IL 60611 USA.	ajayaraman@sralab.org	Lanotte, Francesco/U-9575-2019	Lanotte, Francesco/0000-0001-8978-1074; OBRIEN, MEGAN/0000-0001-8069-365X; jayaraman, arun/0000-0002-9302-6693	National Institute on Disability, Independent Living, and Rehabilitation Research [90REG E0010]	National Institute on Disability, Independent Living, and Rehabilitation Research(United States Department of Health & Human Services)	This work was supported by the National Institute on Disability, Independent Living, and Rehabilitation Research (90REG E0010) .	Adans-Dester C.P., 2022, Neurorehabilitation Technology, P467, DOI DOI 10.1007/978-3-031-08995-4_21; Adans-Dester C, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00328-w; Adde L, 2010, DEV MED CHILD NEUROL, V52, P773, DOI 10.1111/j.1469-8749.2010.03629.x; Adib F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P837, DOI 10.1145/2702123.2702200; Agrawal R, 2020, HEREDITY, V124, P525, DOI 10.1038/s41437-020-0303-2; Alaa AM, 2019, ADV NEUR IN, V32; Albert MV, 2014, PM&R, V6, P1120, DOI 10.1016/j.pmrj.2014.06.006; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Atallah L, 2011, IEEE T BIOMED CIRC S, V5, P320, DOI 10.1109/TBCAS.2011.2160540; Bacciu D, 2017, ENG APPL ARTIF INTEL, V66, P60, DOI 10.1016/j.engappai.2017.08.018; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Bellazzi R, 2008, INT J MED INFORM, V77, P81, DOI 10.1016/j.ijmedinf.2006.11.006; Bland MD, 2012, ARCH PHYS MED REHAB, V93, P1441, DOI 10.1016/j.apmr.2012.02.029; Boe AJ, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0210-1; Brom H, 2020, J NURS CARE QUAL, V35, P27, DOI 10.1097/NCQ.0000000000000412; Busch TD, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0031-2; Che ZP, 2017, IEEE DATA MINING, P787, DOI 10.1109/ICDM.2017.93; Chen PHC, 2019, NAT MATER, V18, P410, DOI 10.1038/s41563-019-0345-0; Chen RJ, 2021, NAT BIOMED ENG, V5, P493, DOI 10.1038/s41551-021-00751-8; Cramer Eric M, 2019, EGEMS (Wash DC), V7, P49, DOI 10.5334/egems.307; Custer MG, 2019, AM J OCCUP THER, V73, DOI 10.5014/ajot.2019.031997; Delahanty RJ, 2019, ANN EMERG MED, V73, P334, DOI 10.1016/j.annemergmed.2018.11.036; Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593; Du C, 2021, IEEE ENG MED BIO, P281, DOI 10.1109/EMBC46164.2021.9629569; Ehrmann DE, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00753-7; Engelhard MM, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2022.54303; Flores AM, 2021, CIRC RES, V128, P1833, DOI 10.1161/CIRCRESAHA.121.318224; French MA, 2022, ARCH PHYS MED REHAB, V103, P1233, DOI 10.1016/j.apmr.2022.01.154; Fusca M, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071167; Gautam A, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2020.2972523; Ghomrawi HMK, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00890-z; Gold R, 2010, ACAD RADIOL, V17, P1079, DOI 10.1016/j.acra.2010.05.021; Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616; Hafer JF, 2023, J BIOMECH, V157, DOI 10.1016/j.jbiomech.2023.111714; Haque A, 2020, NATURE, V585, P193, DOI 10.1038/s41586-020-2669-y; Harari Y, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00704-3; Henderson CE, 2022, ARCH PHYS MED REHAB, V103, pS189, DOI 10.1016/j.apmr.2020.10.127; Herrero JG, 2010, Contextual and human factors in information fusion, P79; Hsieh KL, 2023, J GERONTOL A-BIOL, V78, P861, DOI 10.1093/gerona/glac116; Jasiewicz JM, 2006, GAIT POSTURE, V24, P502, DOI 10.1016/j.gaitpost.2005.12.017; Jensen PB, 2012, NAT REV GENET, V13, P395, DOI 10.1038/nrg3208; Kim J, 2020, IEEE T NEUR SYS REH, V28, P1282, DOI 10.1109/TNSRE.2020.2990824; Kim WS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158640; Kohane IS, 2021, J MED INTERNET RES, V23, DOI 10.2196/22219; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Krishnan R, 2022, NAT BIOMED ENG, V6, P1346, DOI 10.1038/s41551-022-00914-1; Kucukboyaci NE, 2018, ARCH PHYS MED REHAB, V99, P2365, DOI 10.1016/j.apmr.2017.11.016; Lam WWT, 2023, J NEUROENG REHABIL, V20, DOI 10.1186/s12984-023-01186-9; Landi I, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0301-z; Lanotte F, 2023, PHYSIOL MEAS, V44, DOI 10.1088/1361-6579/aceecf; Liew SL, 2023, NEUROLOGY, V100, pE2103, DOI 10.1212/WNL.0000000000207219; Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286; Liuzzi P, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35744-x; Lonini L, 2017, JMIR Rehabil Assist Technol, V4, P8; Lonini Luca, 2022, Digit Biomark, V6, P9, DOI 10.1159/000520732; Lonini L, 2021, IEEE J TRANSL ENG HE, V9, DOI 10.1109/JTEHM.2021.3058841; Lonini L, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0071-z; Lonini L, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P133, DOI 10.1145/3123024.3123098; Lundquist CB, 2021, NEUROREHAB NEURAL RE, V35, P68, DOI 10.1177/1545968320971763; Luo Z., 2018, MACH LEARN HEALTHCAR, V85, P1; Moshawrab M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020828; Murphy C, 2023, J SPINAL CORD MED, V46, P341, DOI 10.1080/10790268.2023.2198926; Nazmi N, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081304; O'Brien MK, 2022, IEEE J TRANSL ENG HE, V10, DOI 10.1109/JTEHM.2022.3208585; O'Brien Megan K, 2021, Digit Biomark, V5, P167, DOI 10.1159/000517144; O'Brien Megan K, 2017, J Med Internet Res, V19, pe184, DOI 10.2196/jmir.7385; Panebianco GP, 2018, GAIT POSTURE, V66, P76, DOI 10.1016/j.gaitpost.2018.08.025; Panwar N, 2016, TELEMED E-HEALTH, V22, P198, DOI 10.1089/tmj.2015.0068; Parimbelli E, 2023, ARTIF INTELL MED, V135, DOI 10.1016/j.artmed.2022.102471; Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0; Prates MOR, 2020, NEURAL COMPUT APPL, V32, P6363, DOI 10.1007/s00521-019-04144-6; Ramspek CL, 2021, CLIN KIDNEY J, V14, P49, DOI 10.1093/ckj/sfaa188; Rantz M, 2017, J AM MED DIR ASSOC, V18, P860, DOI 10.1016/j.jamda.2017.05.012; Reda R, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P5, DOI 10.1145/3194658.3194668; Saeb S, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/gix019; Sahiner B, 2023, BRIT J RADIOL, V96, DOI 10.1259/bjr.20220878; Sato K, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223549; Scrutinio D, 2017, STROKE, V48, P3308, DOI 10.1161/STROKEAHA.117.018058; Shawen N, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00684-4; Shen C, 2020, ICML 20 P 37 INT C M, P8730; Sibley KG, 2021, J PARKINSON DIS, V11, pS83, DOI 10.3233/JPD-202402; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Smith MC, 2022, NEUROREHAB NEURAL RE, V36, P461, DOI 10.1177/15459683221085287; Solana-Lavalle G, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105793; Stenum J, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008935; Stinear CM, 2019, STROKE, V50, P3314, DOI 10.1161/STROKEAHA.119.025696; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Turgeman L, 2017, EXPERT SYST APPL, V78, P376, DOI 10.1016/j.eswa.2017.02.023; van der Schaar M, 2018, Annual report of the chief medical officer, 2018. Health 2040-better health within reach; van Lier HG, 2020, BEHAV RES METHODS, V52, P607, DOI 10.3758/s13428-019-01263-9; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]; Vranas KC, 2017, CRIT CARE MED, V45, P1607, DOI 10.1097/CCM.0000000000002548; Warmerdam E, 2020, LANCET NEUROL, V19, P462, DOI 10.1016/S1474-4422(19)30397-7; Williams DR, 2010, ANN NY ACAD SCI, V1186, P69, DOI 10.1111/j.1749-6632.2009.05339.x; Xu S, 2022, SCI TRANSL MED, V14, DOI 10.1126/scitranslmed.abn6036; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang YZ, 2022, NAT MED, V28, P2207, DOI 10.1038/s41591-022-01932-x; Ye CY, 2020, INT J MED INFORM, V137, DOI 10.1016/j.ijmedinf.2020.104105; Yoon J, 2020, IEEE J BIOMED HEALTH, V24, P2378, DOI 10.1109/JBHI.2020.2980262; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Yu L, 2022, EMERG MARK FINANC TR, V58, P472, DOI 10.1080/1540496X.2020.1825935; Zhang G, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.754169; Zijlstra W, 2003, GAIT POSTURE, V18, P1, DOI 10.1016/S0966-6362(02)00190-X	104	0	0	4	4	KOREAN ACAD REHABILITATION MEDICINE	SEOUL	5F, YOUNGHAN BLDG, 742-22 BANPO-DONG, SEOCHO-GU, SEOUL, 137-040, SOUTH KOREA		2234-0653		ANN REHABIL MED-ARM	Ann. Rehabil. Med.-ARM	DEC	2023	47	6					444	458		10.5535/arm.23131	http://dx.doi.org/10.5535/arm.23131			15	Rehabilitation	Emerging Sources Citation Index (ESCI)	Rehabilitation	PK9Y3	38093518	gold			2024-07-03	WOS:001214102000001
J	Alshami, A; Elsayed, M; Ali, E; Eltoukhy, AEE; Zayed, T				Alshami, Ahmad; Elsayed, Moustafa; Ali, Eslam; Eltoukhy, Abdelrahman E. E.; Zayed, Tarek			Harnessing the Power of ChatGPT for Automating Systematic Review Process: Methodology, Case Study, Limitations, and Future Directions	SYSTEMS			English	Review						ChatGPT; systematic review; automation; Internet of Things (IoT); article filtration; article categorization; information extraction; content analysis	LARGE LANGUAGE MODELS; HEALTH-CARE	Systematic reviews (SR) are crucial in synthesizing and analyzing existing scientific literature to inform evidence-based decision-making. However, traditional SR methods often have limitations, including a lack of automation and decision support, resulting in time-consuming and error-prone reviews. To address these limitations and drive the field forward, we harness the power of the revolutionary language model, ChatGPT, which has demonstrated remarkable capabilities in various scientific writing tasks. By utilizing ChatGPT's natural language processing abilities, our objective is to automate and streamline the steps involved in traditional SR, explicitly focusing on literature search, screening, data extraction, and content analysis. Therefore, our methodology comprises four modules: (1) Preparation of Boolean research terms and article collection, (2) Abstract screening and articles categorization, (3) Full-text filtering and information extraction, and (4) Content analysis to identify trends, challenges, gaps, and proposed solutions. Throughout each step, our focus has been on providing quantitative analyses to strengthen the robustness of the review process. To illustrate the practical application of our method, we have chosen the topic of IoT applications in water and wastewater management and quality monitoring due to its critical importance and the dearth of comprehensive reviews in this field. The findings demonstrate the potential of ChatGPT in bridging the gap between traditional SR methods and AI language models, resulting in enhanced efficiency and reliability of SR processes. Notably, ChatGPT exhibits exceptional performance in filtering and categorizing relevant articles, leading to significant time and effort savings. Our quantitative assessment reveals the following: (1) the overall accuracy of ChatGPT for article discarding and classification is 88%, and (2) the F-1 scores of ChatGPT for article discarding and classification are 91% and 88%, respectively, compared to expert assessments. However, we identify limitations in its suitability for article extraction. Overall, this research contributes valuable insights to the field of SR, empowering researchers to conduct more comprehensive and reliable reviews while advancing knowledge and decision-making across various domains.	[Alshami, Ahmad] Florida State Univ, FAMU FSU Coll Engn, Dept Civil & Environm Engn, Tallahassee, FL 32013 USA; [Elsayed, Moustafa] Florida A&M Univ, FAMU FSU Coll Engn, Dept Civil & Environm Engn, Tallahassee, FL 32013 USA; [Ali, Eslam; Zayed, Tarek] Hong Kong Polytech Univ, Fac Construct & Environm, Dept Bldg & Real Estate, Kowloon TU428, Hong Kong, Peoples R China; [Ali, Eslam] Cairo Univ, Fac Engn, Publ Works Dept, Geomat Lab, Giza 12613, Egypt; [Eltoukhy, Abdelrahman E. E.] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom TU428, Hong Kong, Peoples R China	State University System of Florida; Florida A&M University; Florida State University; State University System of Florida; Florida State University; Florida A&M University; Hong Kong Polytechnic University; Egyptian Knowledge Bank (EKB); Cairo University; Hong Kong Polytechnic University	Ali, E (corresponding author), Hong Kong Polytech Univ, Fac Construct & Environm, Dept Bldg & Real Estate, Kowloon TU428, Hong Kong, Peoples R China.; Ali, E (corresponding author), Cairo Univ, Fac Engn, Publ Works Dept, Geomat Lab, Giza 12613, Egypt.; Eltoukhy, AEE (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hung Hom TU428, Hong Kong, Peoples R China.	aaa21a@fsu.edu; moustafa1.elsayed@famu.edu; eslam.a.saleh@connect.polyu.hk; abdelrahman.eltoukhy@polyu.edu.hk; tarek.zayed@polyu.edu.hk	Zayed, Tarek/L-6437-2018	Zayed, Tarek/0000-0003-3249-7712; Alshami, Ahmad/0000-0002-4593-5489; Eslam, Saleh/0000-0002-2468-1176; Elsayed, Moustafa Y./0000-0002-1243-0740; Eltoukhy, Abdelrahman/0000-0001-5714-3641				Aarseth W, 2017, INT J PROJ MANAG, V35, P1071, DOI 10.1016/j.ijproman.2016.11.006; Abdelkader EM, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13030800; Abu-Odah H, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10071344; Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Alshami A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142114036; Araújo AG, 2020, J CLEAN PROD, V256, DOI 10.1016/j.jclepro.2020.120350; Aromataris E, 2014, AM J NURS, V114, P49, DOI 10.1097/01.NAJ.0000446779.99522.f6; Aydin O., 2022, SSRN ELECT J, DOI [10.2139/ssrn.4308687, DOI 10.2139/SSRN.4308687]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Elshaboury N, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19084496; Eltoukhy AEE, 2017, IND MANAGE DATA SYST, V117, P1201, DOI 10.1108/IMDS-09-2016-0358; Fang T, 2023, Arxiv, DOI arXiv:2304.01746; FitzGerald C, 2017, BMC MED ETHICS, V18, DOI 10.1186/s12910-017-0179-8; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Haluza D, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11030120; Hassan LK, 2021, COMPUT OPER RES, V127, DOI 10.1016/j.cor.2020.105137; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Hussein M, 2021, J CLEAN PROD, V310, DOI 10.1016/j.jclepro.2021.127503; Jan FRNL, 2022, WATER-SUI, V14, DOI 10.3390/w14030309; Karam A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191912287; Khosravi H, 2023, Arxiv, DOI arXiv:2304.05436; Kitchenham B., 2004, Keele, U.K., Keele Univ., VVolume 33, P1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Meline T., 2006, CONT ISSUES COMMUNIC, V33, P21, DOI [10.1044/cicsd_33_S_21, 10.1044/cicsd33S21]; Michalski Adrian, 2022, Procedia Computer Science, P1036, DOI 10.1016/j.procs.2021.12.107; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; MULROW CD, 1994, BRIT MED J, V309, P597, DOI 10.1136/bmj.309.6954.597; Needleman IG, 2002, J CLIN PERIODONTOL, V29, P6, DOI 10.1034/j.1600-051X.29.s3.15.x; Paré G, 2015, INFORM MANAGE-AMSTER, V52, P183, DOI 10.1016/j.im.2014.08.008; Prieto SA, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13040857; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sarkis-Onofre R, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-021-01671-z; Shaban IA, 2023, AUTOMAT CONSTR, V149, DOI 10.1016/j.autcon.2022.104710; Silva M, 2015, PROCEDIA COMPUT SCI, V64, P792, DOI 10.1016/j.procs.2015.08.630; Singh M, 2021, MATER TODAY-PROC, V46, P5211, DOI 10.1016/j.matpr.2020.08.588; Taiwo R, 2023, J CLEAN PROD, V398, DOI 10.1016/j.jclepro.2023.136653; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wohlin C., 2014, Proceedings of the 18th international conference on evaluation and assessment in software engineering, P1, DOI DOI 10.1145/2601248.2601268; Yang XJ, 2023, Arxiv, DOI arXiv:2302.08081; You HX, 2023, Arxiv, DOI arXiv:2304.11018; Yuan YH, 2009, AM J GASTROENTEROL, V104, P1086, DOI 10.1038/ajg.2009.118; Zeng GP, 2020, COMMUN STAT-THEOR M, V49, P2080, DOI 10.1080/03610926.2019.1568485; Zhai Xiaoming, 2023, XRDS: Crossroads, The ACM Magazine for Students, P42, DOI 10.1145/3589649; Zheng HY, 2023, AM J MED, V136, P725, DOI 10.1016/j.amjmed.2023.02.011; Zulkifli CZ, 2022, WATER-SUI, V14, DOI 10.3390/w14223621	53	15	15	20	69	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-8954		SYSTEMS-BASEL	Systems-Basel	JUL	2023	11	7							351	10.3390/systems11070351	http://dx.doi.org/10.3390/systems11070351			37	Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	N3XR4		gold			2024-07-03	WOS:001036385600001
J	Perez-Lopez, R; Laleh, NG; Mahmood, F; Kather, JN				Perez-Lopez, Raquel; Laleh, Narmin Ghaffari; Mahmood, Faisal; Kather, Jakob Nikolas			A guide to artificial intelligence for cancer researchers	NATURE REVIEWS CANCER			English	Review							MULTIMODAL DATA INTEGRATION; LARGE LANGUAGE MODELS; OPEN-SOURCE PLATFORM; PAN-CANCER; MICROSATELLITE INSTABILITY; FOUNDATION MODEL; NEURAL-NETWORKS; IMAGE; PREDICTION; DISCOVERY	Artificial intelligence (AI) has been commoditized. It has evolved from a specialty resource to a readily accessible tool for cancer researchers. AI-based tools can boost research productivity in daily workflows, but can also extract hidden information from existing data, thereby enabling new scientific discoveries. Building a basic literacy in these tools is useful for every cancer researcher. Researchers with a traditional biological science focus can use AI-based tools through off-the-shelf software, whereas those who are more computationally inclined can develop their own AI-based software pipelines. In this article, we provide a practical guide for non-computational cancer researchers to understand how AI-based tools can benefit them. We convey general principles of AI for applications in image analysis, natural language processing and drug discovery. In addition, we give examples of how non-computational researchers can get started on the journey to productively use AI in their own work. This Review provides an introductory guide to artificial intelligence (AI)-based tools for non-computational cancer researchers. Here, Perez-Lopez et al. outline the general principles of AI for image analysis, natural language processing and drug discovery, as well as how researchers can get started with each of them.	[Perez-Lopez, Raquel] Vall dHebron Barcelona Hosp Campus, Vall dHebron Inst Oncol, Radi Grp, Barcelona, Spain; [Laleh, Narmin Ghaffari; Kather, Jakob Nikolas] Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Mahmood, Faisal] Brigham & Womens Hosp, Harvard Med Sch, Dept Pathol, Boston, MA USA; [Mahmood, Faisal] Massachusetts Gen Hosp, Harvard Med Sch, Dept Pathol, Boston, MA USA; [Mahmood, Faisal] Broad Inst Harvard, Canc Program, Cambridge, MA USA; [Mahmood, Faisal] MIT, Cambridge, MA USA; [Mahmood, Faisal] Dana Farber Canc Inst, Canc Data Sci Program, Boston, MA USA; [Mahmood, Faisal] Harvard Med Sch, Dept Biomed Informat, Boston, MA USA; [Mahmood, Faisal] Harvard Univ, Harvard Data Sci Initiat, Cambridge, MA USA; [Kather, Jakob Nikolas] Univ Hosp Dresden, Dept Med 1, Dresden, Germany; [Kather, Jakob Nikolas] Univ Hosp Heidelberg, Natl Ctr Tumour Dis NCT, Med Oncol, Heidelberg, Germany	Vall d'Hebron Institut d'Oncologia (VHIO); Technische Universitat Dresden; Harvard University; Brigham & Women's Hospital; Harvard Medical School; Harvard University; Harvard Medical School; Massachusetts General Hospital; Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute; Massachusetts Institute of Technology (MIT); Harvard University; Dana-Farber Cancer Institute; Harvard University; Harvard Medical School; Harvard University; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg	Kather, JN (corresponding author), Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany.; Kather, JN (corresponding author), Univ Hosp Dresden, Dept Med 1, Dresden, Germany.; Kather, JN (corresponding author), Univ Hosp Heidelberg, Natl Ctr Tumour Dis NCT, Med Oncol, Heidelberg, Germany.	jakob_nikolas.kather@tu-dresden.de	Kather, Jakob Nikolas/D-4279-2015; Mahmood, Faisal/C-1021-2015	Kather, Jakob Nikolas/0000-0002-3730-5348; Perez-Lopez, Raquel/0000-0002-9176-0130; Mahmood, Faisal/0000-0001-7587-1562	LaCaixa Foundation, a CRIS Foundation Talent Award [TALENT19-05]; FERO Foundation [PI18/01395, PI21/01019]; Prostate Cancer Foundation [18YOUN19]; Asociacin Espaola Contra el Cancer (AECC) [PRYCO211023SERR]; German Cancer Aid [70115166]; German Federal Ministry of Education and Research [01KD2104C, 01EO2101, 01KD2215A, 031L0312A]; TANGERINE [01KT2302]; German Academic Exchange Service [57616814]; German Federal Joint Committee [01VSF21048]; European Union; European Research Council (ERC) [101114631]; National Institute for Health and Care Research (NIHR) [NIHR203331]	LaCaixa Foundation, a CRIS Foundation Talent Award; FERO Foundation; Prostate Cancer Foundation; Asociacin Espaola Contra el Cancer (AECC); German Cancer Aid(Deutsche Krebshilfe); German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); TANGERINE; German Academic Exchange Service(Deutscher Akademischer Austausch Dienst (DAAD)); German Federal Joint Committee; European Union(European Union (EU)); European Research Council (ERC)(European Research Council (ERC)); National Institute for Health and Care Research (NIHR)(National Institutes of Health Research (NIHR))	R.P.-L. is supported by LaCaixa Foundation, a CRIS Foundation Talent Award (TALENT19-05), the FERO Foundation, the Instituto de Salud Carlos III-Investigacion en Salud (PI18/01395 and PI21/01019), the Prostate Cancer Foundation (18YOUN19) and the Asociacion Espanola Contra el Cancer (AECC) (PRYCO211023SERR). J.N.K. is supported by the German Cancer Aid (DECADE, 70115166), the German Federal Ministry of Education and Research (PEARL, 01KD2104C; CAMINO, 01EO2101; SWAG, 01KD2215A; TRANSFORM LIVER, 031L0312A; and TANGERINE, 01KT2302 through ERA-NET Transcan), the German Academic Exchange Service (SECAI, 57616814), the German Federal Joint Committee (TransplantKI, 01VSF21048), the European Union's Horizon Europe and innovation programme (ODELIA, 101057091; and GENIAL, 101096312), the European Research Council (ERC; NADIR, 101114631) and the National Institute for Health and Care Research (NIHR; NIHR203331) Leeds Biomedical Research Centre. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR or the Department of Health and Social Care. This work was funded by the European Union. Views and opinions expressed are, however, those of the authors only and do not necessarily reflect those of the European Union. Neither the European Union nor the granting authority can be held responsible for them.	Adalsteinsson VA, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00965-y; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; Alloghani M, 2020, Supervised and Unsupervised Learning for Data Science, P3, DOI [10.1007/978-3-030-22475-2_1, DOI 10.1007/978-3-030-22475-2_1]; Amirrashedi M, 2021, COMPUT MED IMAG GRAP, V94, DOI 10.1016/j.compmedimag.2021.102010; Anaya J, 2024, NAT BIOMED ENG, V8, DOI 10.1038/s41551-023-01120-3; Anil R., 2024, ARXIV, p2312.11805, DOI [10.48550/arXiv.2312.11805, DOI 10.48550/ARXIV.2312.11805]; [Anonymous], 2023, NAT BIOTECHNOL, V41, P1361, DOI 10.1038/s41587-023-02002-4; [Anonymous], 2023, NATURE, V622, P217, DOI 10.1038/d41586-023-03172-6; Arnold C, 2023, NATURE, V622, P15, DOI 10.1038/d41586-023-02984-w; Arslan S, 2024, COMMUN MED-LONDON, V4, DOI 10.1038/s43856-024-00471-5; Balaguer A., 2024, PREPRINT, DOI DOI 10.48550/ARXIV.2401.08406; Bankhead P, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17204-5; Barrio-Hernandez I, 2023, NATURE, V622, P637, DOI 10.1038/s41586-023-06510-w; Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002; Beck AH, 2011, SCI TRANSL MED, V3, DOI 10.1126/scitranslmed.3002564; Belthangady C, 2019, NAT METHODS, V16, P1215, DOI 10.1038/s41592-019-0458-z; Bera K, 2022, NAT REV CLIN ONCOL, V19, P132, DOI 10.1038/s41571-021-00560-7; Betge J, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30722-9; Bilal M, 2021, LANCET DIGIT HEALTH, V3, pE763, DOI 10.1016/S2589-7500(21)00180-1; Binder A, 2021, NAT MACH INTELL, V3, P355, DOI 10.1038/s42256-021-00303-4; Boehm KM, 2022, NAT CANCER, V3, P723, DOI 10.1038/s43018-022-00388-9; Boehm KM, 2022, NAT REV CANCER, V22, P114, DOI 10.1038/s41568-021-00408-3; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Brown T. B., 2020, PREPRINT, DOI [arXiv:2005.01416, DOI 10.48550/ARXIV.2005.01416]; Bruker Corporation, 2024, ARTIFICIAL INTELLIGE; Bubeck S., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12712; Callaway E, 2022, NATURE, V604, P234, DOI 10.1038/d41586-022-00997-5; Campanella G., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2310.07033; Campanella G, 2019, NAT MED, V25, P1301, DOI 10.1038/s41591-019-0508-1; Castelo-Branco L, 2023, ANN ONCOL, V34, P1097, DOI 10.1016/j.annonc.2023.10.001; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chen BB, 2019, NAT BIOTECHNOL, V37, P1332, DOI 10.1038/s41587-019-0280-2; Chen RJ, 2024, NAT MED, DOI 10.1038/s41591-024-02857-3; Chen RJ, 2022, CANCER CELL, V40, P865, DOI 10.1016/j.ccell.2022.07.004; Chen S., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2204.03257; Cheng J, 2023, SCIENCE, V381, P1303, DOI 10.1126/science.adg7492; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Chui M., 2023, MCKINSEY; Cifci D, 2022, J PATHOL, V257, P430, DOI 10.1002/path.5898; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Coudray N, 2018, NAT MED, V24, P1559, DOI 10.1038/s41591-018-0177-5; Dell'Acqua F., 2023, Harvard Business School Technology & Operations Management Unit Working Paper, No. 24-013; Derraz B, 2024, NPJ PRECIS ONCOL, V8, DOI 10.1038/s41698-024-00517-w; Dike HU, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P322, DOI 10.1109/CBS.2018.8612259; Dolezal JM, 2023, NPJ PRECIS ONCOL, V7, DOI 10.1038/s41698-023-00399-4; Echle A, 2022, ESMO OPEN, V7, DOI 10.1016/j.esmoop.2022.100400; Echle A, 2021, BRIT J CANCER, V124, P686, DOI 10.1038/s41416-020-01122-x; Echle A, 2020, GASTROENTEROLOGY, V159, P1406, DOI 10.1053/j.gastro.2020.06.021; Edlund C, 2021, NAT METHODS, V18, P1038, DOI 10.1038/s41592-021-01249-6; El Nahhas O. S. M., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2312.10944; Extance A, 2023, NATURE, V623, P474, DOI 10.1038/d41586-023-03507-3; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Ferber D, 2024, EUR UROL ONCOL, V7, P157, DOI 10.1016/j.euo.2023.09.019; Filiot A., 2023, Pathology, DOI [10.1101/2023.07.21.23292757, DOI 10.1101/2023.07.21.23292757]; Foersch S, 2023, NAT MED, V29, DOI 10.1038/s41591-022-02134-1; Fu Y, 2020, NAT CANCER, V1, P800, DOI 10.1038/s43018-020-0085-8; Galon J, 2006, SCIENCE, V313, P1960, DOI 10.1126/science.1129139; Garcia-Ruiz A, 2024, CELL REP MED, V5, DOI 10.1016/j.xcrm.2024.101464; Gawehn E, 2016, MOL INFORM, V35, P3, DOI 10.1002/minf.201501008; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gómez-de-Mariscal E, 2021, NAT METHODS, V18, P1192, DOI 10.1038/s41592-021-01262-9; Goode Adam, 2013, J Pathol Inform, V4, P27, DOI 10.4103/2153-3539.119005; Greenson JK, 2009, AM J SURG PATHOL, V33, P126, DOI 10.1097/PAS.0b013e31817ec2b1; Hamm CA, 2019, EUR RADIOL, V29, P3338, DOI 10.1007/s00330-019-06205-9; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang X, 2024, NAT REV GENET, V25, P61, DOI 10.1038/s41576-023-00636-3; Hutson M, 2023, NAT BIOTECHNOL, V41, P1494, DOI 10.1038/s41587-023-02029-7; Jain MS, 2020, NAT MACH INTELL, V2, P356, DOI 10.1038/s42256-020-0190-5; Janizek JD, 2023, NAT BIOMED ENG, V7, P811, DOI 10.1038/s41551-023-01034-0; Jayatunga MKP, 2022, NAT REV DRUG DISCOV, V21, P174, DOI 10.1038/d41573-022-00025-1; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Jiang T, 2020, BEHAV THER, V51, P675, DOI 10.1016/j.beth.2020.05.002; Jiang XF, 2024, LANCET DIGIT HEALTH, V6, pe33, DOI 10.1016/S2589-7500(23)00208-X; Jorge Cardoso M., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2211.02701; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kather JN, 2020, NAT CANCER, V1, P789, DOI 10.1038/s43018-020-0087-6; Kather JN, 2019, NAT MED, V25, P1054, DOI 10.1038/s41591-019-0462-y; Kaufmann E, 2023, NATURE, V620, P982, DOI 10.1038/s41586-023-06419-4; Khader F, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.230806; Khan A, 2023, ARTIF INTELL REV, V56, pS2917, DOI 10.1007/s10462-023-10595-0; Kleppe A, 2022, LANCET ONCOL, V23, P1221, DOI 10.1016/S1470-2045(22)00391-6; Krishnan R, 2022, NAT BIOMED ENG, V6, P1346, DOI 10.1038/s41551-022-00914-1; Laleh NG, 2023, CLIN CANCER RES, V29, P316, DOI 10.1158/1078-0432.CCR-22-0390; Lång K, 2023, LANCET ONCOL, V24, P936, DOI 10.1016/S1470-2045(23)00298-X; Li C., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2306.00890; Ligero M, 2021, EUR RADIOL, V31, P1460, DOI 10.1007/s00330-020-07174-0; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Lin YC, 2017, J MAGN RESON IMAGING, V46, P483, DOI 10.1002/jmri.25583; Linkert M, 2010, J CELL BIOL, V189, P777, DOI 10.1083/jcb.201004104; Lipkova J, 2022, CANCER CELL, V40, P1095, DOI 10.1016/j.ccell.2022.09.012; Liu H., 2023, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.2304.08485; Loeffler CML, 2022, FRONT GENET, V12, DOI 10.3389/fgene.2021.806386; Lu L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26990-6; Lu M. Y., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2312.07814; Lu MY, 2021, NATURE, V594, P106, DOI 10.1038/s41586-021-03512-4; Lu MY, 2021, NAT BIOMED ENG, V5, P555, DOI 10.1038/s41551-020-00682-w; Martinez K, 2005, IEEE IMAGE PROC, P2485; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Nunez LM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76686-y; Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115; Mock M, 2023, NATURE, V621, P467, DOI 10.1038/d41586-023-02896-9; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Morin O, 2021, NAT CANCER, V2, P709, DOI 10.1038/s43018-021-00236-2; Müller J, 2022, RADIOTHER ONCOL, V169, P96, DOI 10.1016/j.radonc.2022.02.020; Mullowney MW, 2023, NAT REV DRUG DISCOV, V22, P895, DOI 10.1038/s41573-023-00774-7; Nasteski V, 2017, HORIZONS B, V4, P51, DOI [DOI 10.20544/HORIZONS.B.04.1.17.P05, 10.20544/horizons.b.04.1.17.p05]; Niehues JM, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.100980; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2311.16452; Park T, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46485-2; Paszke A, 2019, ADV NEUR IN, V32; Pawlicki T. F., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P63, DOI 10.1109/ICNN.1988.23913; Pedersen A, 2021, IEEE ACCESS, V9, P58216, DOI 10.1109/ACCESS.2021.3072231; Plass M, 2023, J PATHOL CLIN RES, V9, P251, DOI 10.1002/cjp2.322; Pocock J, 2022, COMMUN MED-LONDON, V2, DOI 10.1038/s43856-022-00186-5; Rajput D, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05156-9; Reis JS, 2023, JNCI-J NATL CANCER I, V115, P608, DOI 10.1093/jnci/djad048; Ren JT, 2021, ACTA ONCOL, V60, P1399, DOI 10.1080/0284186X.2021.1949034; Rueden CT, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1934-z; Sapsford RogerVictor Ju pp., 2006, DATA COLLECTION ANAL, V2nd; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/nmeth.2019, 10.1038/NMETH.2019]; Schirris Y, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102464; Schmauch B, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17678-4; Schmidt U, 2018, LECT NOTES COMPUT SC, V11071, P265, DOI 10.1007/978-3-030-00934-2_30; Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089; Shamai G, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.7700; Shifai N, 2024, J AM ACAD DERMATOL, V90, P1057, DOI 10.1016/j.jaad.2023.12.062; Shmatko A, 2022, NAT CANCER, V3, P1026, DOI 10.1038/s43018-022-00436-4; Shurrab S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1045; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Subbiah V, 2023, NAT MED, V29, P49, DOI 10.1038/s41591-022-02160-z; Sushil M., 2024, NEJM AI, V1, pAIdbp2300110, DOI [10.1056/AIdbp2300110, DOI 10.1056/AIDBP2300110]; Swanson K, 2024, NAT MACH INTELL, V6, DOI 10.1038/s42256-024-00809-7; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tisman G., 2023, DIGIT MED HEALTHC TE, DOI [10.5772/dmht.19, DOI 10.5772/DMHT.19]; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Trebeschi S, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.609054; Truhn D, 2024, J PATHOL, V262, P310, DOI 10.1002/path.6232; Truhn D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-47500-2; Truhn D, 2023, NAT MED, DOI 10.1038/s41591-023-02594-z; Unger M, 2024, GENOME MED, V16, DOI 10.1186/s13073-024-01315-6; Unger M, 2024, BMC MED GENOMICS, V17, DOI 10.1186/s12920-024-01796-9; US FDA, 2023, Artificial intelligence and machine learning (AI/ML)-enabled medical devices; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Vanguri RS, 2022, NAT CANCER, V3, P1151, DOI 10.1038/s43018-022-00416-8; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vega DM, 2021, ANN ONCOL, V32, P1626, DOI 10.1016/j.annonc.2021.09.016; Vert JP, 2023, NAT BIOTECHNOL, V41, P750, DOI 10.1038/s41587-023-01789-6; Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z; Vorontsov E., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2309.07778; Wagner SJ, 2023, CANCER CELL, V41, P1650, DOI 10.1016/j.ccell.2023.08.002; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Wang XY, 2023, MED IMAGE ANAL, V83, DOI 10.1016/j.media.2022.102645; Wang XY, 2022, MED IMAGE ANAL, V81, DOI 10.1016/j.media.2022.102559; Webster P, 2023, NAT MED, DOI 10.1038/s41591-023-02700-1; Wiest I. C., 2023, BIORXIV, DOI [10.1101/2023.12.07.23299648, DOI 10.1101/2023.12.07.23299648]; Wong CH, 2019, BIOSTATISTICS, V20, P273, DOI 10.1093/biostatistics/kxx069; Wong F, 2023, NATURE, DOI 10.1038/s41586-023-06887-8; Xu Hongming, 2022, J Pathol Inform, V13, P100105, DOI 10.1016/j.jpi.2022.100105; Yala A, 2022, NAT MED, V28, P136, DOI 10.1038/s41591-021-01599-w; Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9; Yamashita R, 2021, LANCET ONCOL, V22, P132, DOI 10.1016/S1470-2045(20)30535-0; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang X, 2019, CHEM REV, V119, P10520, DOI 10.1021/acs.chemrev.8b00728; Yu AC, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210064; Yuan C, 2019, J AM MED INFORM ASSN, V26, P294, DOI 10.1093/jamia/ocy178; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zeng QH, 2023, LANCET ONCOL, V24, P1411, DOI 10.1016/S1470-2045(23)00468-0; Zhang ZY, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21254-9; Zhao YF, 2009, STAT MED, V28, P3294, DOI 10.1002/sim.3720; Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x; Zinn PO, 2018, CLIN CANCER RES, V24, P6288, DOI 10.1158/1078-0432.CCR-17-3420; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	174	0	0	6	6	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1474-175X	1474-1768		NAT REV CANCER	Nat. Rev. Cancer	JUN	2024	24	6					427	441		10.1038/s41568-024-00694-7	http://dx.doi.org/10.1038/s41568-024-00694-7		MAY 2024	15	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	SP4E9	38755439				2024-07-03	WOS:001226605400001
